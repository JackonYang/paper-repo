{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490700"
                        ],
                        "name": "Boris Babenko",
                        "slug": "Boris-Babenko",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Babenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Babenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 104
                            }
                        ],
                        "text": "Struck [4] achieves very good results (over 0.9 in most sequences), and outperforms other trackers like MILTrack, OAB, SemiBoost [6] and FragTrack [23]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] argue for the use of precision plots."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "The sequences twinings and cliffbar have large scale changes, so we compare with versions of MILTrack [3], Online Ada-Boost (OAB) [3, Sec."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "Some notable examples use Semi-Supervised Learning [6] and Multiple Instance Learning [3] (MILTrack) to handle this."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 58
                            }
                        ],
                        "text": "Many use established learning algorithms such as Boosting [6, 3], Support Vector Machines (SVM) [5], or Random Forests [7], and adapt them to online training."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12424827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "201631fbc3f7d7cb2c1ddfaf82278cad5e44f2f9",
            "isKey": true,
            "numCitedBy": 1997,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of tracking an object in a video given its location in the first frame and no other information. Recently, a class of tracking techniques called \u201ctracking by detection\u201d has been shown to give promising results at real-time speeds. These methods train a discriminative classifier in an online manner to separate the object from the background. This classifier bootstraps itself by using the current tracker state to extract positive and negative examples from the current frame. Slight inaccuracies in the tracker can therefore lead to incorrectly labeled training examples, which degrade the classifier and can cause drift. In this paper, we show that using Multiple Instance Learning (MIL) instead of traditional supervised learning avoids these problems and can therefore lead to a more robust tracker with fewer parameter tweaks. We propose a novel online MIL algorithm for object tracking that achieves superior results with real-time performance. We present thorough experimental results (both qualitative and quantitative) on a number of challenging video clips."
            },
            "slug": "Robust-Object-Tracking-with-Online-Multiple-Babenko-Yang",
            "title": {
                "fragments": [],
                "text": "Robust Object Tracking with Online Multiple Instance Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that using Multiple Instance Learning (MIL) instead of traditional supervised learning avoids these problems and can therefore lead to a more robust tracker with fewer parameter tweaks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145551629"
                        ],
                        "name": "H. Grabner",
                        "slug": "H.-Grabner",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Grabner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Grabner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695579"
                        ],
                        "name": "C. Leistner",
                        "slug": "C.-Leistner",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Leistner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leistner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 104
                            }
                        ],
                        "text": "Struck [4] achieves very good results (over 0.9 in most sequences), and outperforms other trackers like MILTrack, OAB, SemiBoost [6] and FragTrack [23]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "Some notable examples use Semi-Supervised Learning [6] and Multiple Instance Learning [3] (MILTrack) to handle this."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "9 in most sequences), and outperforms other trackers like MILTrack, OAB, SemiBoost [6] and FragTrack [23]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 58
                            }
                        ],
                        "text": "Many use established learning algorithms such as Boosting [6, 3], Support Vector Machines (SVM) [5], or Random Forests [7], and adapt them to online training."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11989316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27d69a2d96600efb66fd907d8287ca3b6e734c59",
            "isKey": true,
            "numCitedBy": 1242,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, on-line adaptation of binary classifiers for tracking have been investigated. On-line learning allows for simple classifiers since only the current view of the object from its surrounding background needs to be discriminiated. However, on-line adaption faces one key problem: Each update of the tracker may introduce an error which, finally, can lead to tracking failure (drifting). The contribution of this paper is a novel on-line semi-supervised boosting method which significantly alleviates the drifting problem in tracking applications. This allows to limit the drifting problem while still staying adaptive to appearance changes. The main idea is to formulate the update process in a semi-supervised fashion as combined decision of a given prior and an on-line classifier. This comes without any parameter tuning. In the experiments, we demonstrate real-time tracking of our SemiBoost tracker on several challenging test sequences where our tracker outperforms other on-line tracking methods."
            },
            "slug": "Semi-supervised-On-Line-Boosting-for-Robust-Grabner-Leistner",
            "title": {
                "fragments": [],
                "text": "Semi-supervised On-Line Boosting for Robust Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The main idea is to formulate the update process in a semi-supervised fashion as combined decision of a given prior and an on-line classifier, without any parameter tuning, which significantly alleviates the drifting problem in tracking applications."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144711958"
                        ],
                        "name": "David A. Ross",
                        "slug": "David-A.-Ross",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ross",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Ross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153239384"
                        ],
                        "name": "Jongwoo Lim",
                        "slug": "Jongwoo-Lim",
                        "structuredName": {
                            "firstName": "Jongwoo",
                            "lastName": "Lim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jongwoo Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2900733"
                        ],
                        "name": "Ruei-Sung Lin",
                        "slug": "Ruei-Sung-Lin",
                        "structuredName": {
                            "firstName": "Ruei-Sung",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruei-Sung Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "4] and IVT [22] that track through scale."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1089627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "505f48d8236eb25f871da272c2ac2fe4b41ea289",
            "isKey": false,
            "numCitedBy": 3063,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nVisual tracking, in essence, deals with non-stationary image streams that change over time. While most existing algorithms are able to track objects well in controlled environments, they usually fail in the presence of significant variation of the object\u2019s appearance or surrounding illumination. One reason for such failures is that many algorithms employ fixed appearance models of the target. Such models are trained using only appearance data available before tracking begins, which in practice limits the range of appearances that are modeled, and ignores the large volume of information (such as shape changes or specific lighting conditions) that becomes available during tracking. In this paper, we present a tracking method that incrementally learns a low-dimensional subspace representation, efficiently adapting online to changes in the appearance of the target. The model update, based on incremental algorithms for principal component analysis, includes two important features: a method for correctly updating the sample mean, and a forgetting factor to ensure less modeling power is expended fitting older observations. Both of these features contribute measurably to improving overall tracking performance. Numerous experiments demonstrate the effectiveness of the proposed tracking algorithm in indoor and outdoor environments where the target objects undergo large changes in pose, scale, and illumination.\n"
            },
            "slug": "Incremental-Learning-for-Robust-Visual-Tracking-Ross-Lim",
            "title": {
                "fragments": [],
                "text": "Incremental Learning for Robust Visual Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A tracking method that incrementally learns a low-dimensional subspace representation, efficiently adapting online to changes in the appearance of the target, and includes a method for correctly updating the sample mean and a forgetting factor to ensure less modeling power is expended fitting older observations."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708802"
                        ],
                        "name": "D. Bolme",
                        "slug": "D.-Bolme",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bolme",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bolme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143905691"
                        ],
                        "name": "J. Beveridge",
                        "slug": "J.-Beveridge",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Beveridge",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beveridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694404"
                        ],
                        "name": "B. Draper",
                        "slug": "B.-Draper",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Draper",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Draper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733571"
                        ],
                        "name": "Y. Lui",
                        "slug": "Y.-Lui",
                        "structuredName": {
                            "firstName": "Yui",
                            "lastName": "Lui",
                            "middleNames": [
                                "Man"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lui"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 121
                            }
                        ],
                        "text": "This is a kind of correlation filter that has been proposed recently, called Minimum Output Sum of Squared Error (MOSSE) [12, 15], with a single training image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "The Minimum Output Sum of Squared Error (MOSSE) filter [12] has been shown to be competitive with the methods outlined before, but at a fraction of the complexity, and runs at impressive speeds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 93
                            }
                        ],
                        "text": "Also closely related are adaptive correlation filters, rooted on classical signal processing [15, 12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 302,
                                "start": 297
                            }
                        ],
                        "text": "It produces a linear classifier that does not make use of the Kernel Trick, so we can compute w explicitly, instead of implicitly as \u03b1. Plugging it into the KRLS equations, we obtain:\nThis is a kind of correlation filter that has been proposed recently, called Minimum Output Sum of Squared Error (MOSSE) [12, 15], with a single training image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 13
                            }
                        ],
                        "text": "We called it MOSSE2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "We found that MOSSE [12] is tuned only for 64 \u00d7 64 images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 218
                            }
                        ],
                        "text": "Although they are useful and provide interesting insights, it may still be desirable to compute the responses at many locations, for example to allow more robust mode seeking or to evaluate the quality of the response [12]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2451356,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "70c3c9b9a40ca55264e454586dca2a6cf416f6e0",
            "isKey": true,
            "numCitedBy": 2219,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Although not commonly used, correlation filters can track complex objects through rotations, occlusions and other distractions at over 20 times the rate of current state-of-the-art techniques. The oldest and simplest correlation filters use simple templates and generally fail when applied to tracking. More modern approaches such as ASEF and UMACE perform better, but their training needs are poorly suited to tracking. Visual tracking requires robust filters to be trained from a single frame and dynamically adapted as the appearance of the target object changes. This paper presents a new type of correlation filter, a Minimum Output Sum of Squared Error (MOSSE) filter, which produces stable correlation filters when initialized using a single frame. A tracker based upon MOSSE filters is robust to variations in lighting, scale, pose, and nonrigid deformations while operating at 669 frames per second. Occlusion is detected based upon the peak-to-sidelobe ratio, which enables the tracker to pause and resume where it left off when the object reappears."
            },
            "slug": "Visual-object-tracking-using-adaptive-correlation-Bolme-Beveridge",
            "title": {
                "fragments": [],
                "text": "Visual object tracking using adaptive correlation filters"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new type of correlation filter is presented, a Minimum Output Sum of Squared Error (MOSSE) filter, which produces stable correlation filters when initialized using a single frame, which enables the tracker to pause and resume where it left off when the object reappears."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38547813"
                        ],
                        "name": "A. Yilmaz",
                        "slug": "A.-Yilmaz",
                        "structuredName": {
                            "firstName": "Alper",
                            "lastName": "Yilmaz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yilmaz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2805147"
                        ],
                        "name": "O. Javed",
                        "slug": "O.-Javed",
                        "structuredName": {
                            "firstName": "Omar",
                            "lastName": "Javed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Javed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "[10] use branchand-bound optimization to find the maximum of a classifier\u2019s response without 1 We refer the reader to 2 reviews: [8] is more in-depth, while [9, Sec."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11962297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "caa0fd34e50bb417fae3ee32f667e78fe5b198bc",
            "isKey": false,
            "numCitedBy": 5314,
            "numCiting": 181,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this article is to review the state-of-the-art tracking methods, classify them into different categories, and identify new trends. Object tracking, in general, is a challenging problem. Difficulties in tracking objects can arise due to abrupt object motion, changing appearance patterns of both the object and the scene, nonrigid object structures, object-to-object and object-to-scene occlusions, and camera motion. Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Typically, assumptions are made to constrain the tracking problem in the context of a particular application. In this survey, we categorize the tracking methods on the basis of the object and motion representations used, provide detailed descriptions of representative methods in each category, and examine their pros and cons. Moreover, we discuss the important issues related to tracking including the use of appropriate image features, selection of motion models, and detection of objects."
            },
            "slug": "Object-tracking:-A-survey-Yilmaz-Javed",
            "title": {
                "fragments": [],
                "text": "Object tracking: A survey"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The goal of this article is to review the state-of-the-art tracking methods, classify them into different categories, and identify new trends to discuss the important issues related to tracking including the use of appropriate image features, selection of motion models, and detection of objects."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2187954"
                        ],
                        "name": "Hanxuan Yang",
                        "slug": "Hanxuan-Yang",
                        "structuredName": {
                            "firstName": "Hanxuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanxuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144082425"
                        ],
                        "name": "L. Shao",
                        "slug": "L.-Shao",
                        "structuredName": {
                            "firstName": "Ling",
                            "lastName": "Shao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057490886"
                        ],
                        "name": "Feng Zheng",
                        "slug": "Feng-Zheng",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693997"
                        ],
                        "name": "Liang Wang",
                        "slug": "Liang-Wang",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145541940"
                        ],
                        "name": "Zhan Song",
                        "slug": "Zhan-Song",
                        "structuredName": {
                            "firstName": "Zhan",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhan Song"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4338802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2bcf2bd59219d89f335cbc8d1dd4f431076b4c4c",
            "isKey": false,
            "numCitedBy": 610,
            "numCiting": 141,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recent-advances-and-trends-in-visual-tracking:-A-Yang-Shao",
            "title": {
                "fragments": [],
                "text": "Recent advances and trends in visual tracking: A review"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741702"
                        ],
                        "name": "Amir Saffari",
                        "slug": "Amir-Saffari",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Saffari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amir Saffari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695579"
                        ],
                        "name": "C. Leistner",
                        "slug": "C.-Leistner",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Leistner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leistner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48716704"
                        ],
                        "name": "Jakob Santner",
                        "slug": "Jakob-Santner",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Santner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Santner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3152684"
                        ],
                        "name": "Martin Godec",
                        "slug": "Martin-Godec",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Godec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Godec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "Many use established learning algorithms such as Boosting [6, 3], Support Vector Machines (SVM) [5], or Random Forests [7], and adapt them to online training."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7724157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7633c95812dea716917e8b23b84df18e7b03614e",
            "isKey": false,
            "numCitedBy": 499,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Random Forests (RFs) are frequently used in many computer vision and machine learning applications. Their popularity is mainly driven by their high computational efficiency during both training and evaluation while achieving state-of-the-art results. However, in most applications RFs are used off-line. This limits their usability for many practical problems, for instance, when training data arrives sequentially or the underlying distribution is continuously changing. In this paper, we propose a novel on-line random forest algorithm. We combine ideas from on-line bagging, extremely randomized forests and propose an on-line decision tree growing procedure. Additionally, we add a temporal weighting scheme for adaptively discarding some trees based on their out-of-bag-error in given time intervals and consequently growing of new trees. The experiments on common machine learning data sets show that our algorithm converges to the performance of the off-line RF. Additionally, we conduct experiments for visual tracking, where we demonstrate real-time state-of-the-art performance on well-known scenarios and show good performance in case of occlusions and appearance changes where we outperform trackers based on on-line boosting. Finally, we demonstrate the usability of on-line RFs on the task of interactive real-time segmentation."
            },
            "slug": "On-line-Random-Forests-Saffari-Leistner",
            "title": {
                "fragments": [],
                "text": "On-line Random Forests"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel on-line random forest algorithm is proposed that combines ideas from on-lines bagging, extremely randomized forests and propose an on- line decision tree growing procedure and adds a temporal weighting scheme for adaptively discarding some trees based on their out-of-bag-error in given time intervals and consequently growing of new trees."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8142777"
                        ],
                        "name": "R. Patnaik",
                        "slug": "R.-Patnaik",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Patnaik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Patnaik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34925745"
                        ],
                        "name": "D. Casasent",
                        "slug": "D.-Casasent",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Casasent",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Casasent"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Patnaik and Casasent [16] investigate this problem, and show that, given the Fourier representation of an image, many classical filters cannot be kernelized."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 55
                            }
                        ],
                        "text": "As of this writing, this is a topic of active research [10, 11, 16]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 120296105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06e78273b4dbfe6b7ff56df16892782f01fac5bb",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "General object recognition involves recognizing an object in a scene in the presence of several distortions and when its location is not known. Since the location of the test object in the scene is unknown, a classifier needs to be applied for different locations of the object over the test input. In this scenario, distortion-invariant filters (DIFs) are attractive, since they can be applied (efficiently and fast) for different shifts using the fast Fourier transform (FFT). A single DIF handles different object distortions (e.g. all aspect views and some range of scale and depression angle). In this paper, we show a new approach that combines DIFs and the kernel technique (to form \"kernel DIFs\"), addresses the need for fast on-line filter shifts, and improves performance. We consider polynomial and Gaussian kernels (polynomial results are emphasized here). We consider kernel versions of the synthetic discriminant function (SDF) filter and DIFs that minimize an energy function such as the minimum average correlation energy (MACE) filter. We provide insight into and compare several different formulations of kernel DIFs. We emphasize proper formulations of kernel DIFs and provide data in many cases to show that they perform better. We recall that kernel SDF filters are the most computationally efficient ones and thus emphasize them. We use the performance of the minimum noise and correlation energy (MINACE) filter as the baseline to which we compare kernel SDF filter results. We consider the classification of two true-class objects and the rejection of unseen clutter and unseen confuser-class objects with full 360\u00b0 aspect view distortions and with a range of scale distortions present (shifts of all test images are addressed for the first time, for kernel DIFs); we use CAD (computer-aided design) infrared (IR) data to synthesize objects with the necessary distortions and we use only problematic (blob) real IR clutter data."
            },
            "slug": "Fast-FFT-based-distortion-invariant-kernel-filters-Patnaik-Casasent",
            "title": {
                "fragments": [],
                "text": "Fast FFT-based distortion-invariant kernel filters for general object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper shows a new approach that combines DIFs and the kernel technique, addresses the need for fast on-line filter shifts, and improves performance of kernel SDF filters, which are the most computationally efficient ones."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885768"
                        ],
                        "name": "M. Chli",
                        "slug": "M.-Chli",
                        "structuredName": {
                            "firstName": "Margarita",
                            "lastName": "Chli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052135690"
                        ],
                        "name": "A. Davison",
                        "slug": "A.-Davison",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Davison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Davison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4518583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04554de05a3a9ebb1890d25aaa7e34544a0d32a7",
            "isKey": false,
            "numCitedBy": 1119,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In the matching tasks which form an integral part of all types of tracking and geometrical vision, there are invariably priors available on the absolute and/or relative image locations of features of interest. Usually, these priors are used post-hoc in the process of resolving feature matches and obtaining final scene estimates, via `first get candidate matches, then resolve' consensus algorithms such as RANSAC. In this paper we show that the dramatically different approach of using priors dynamically to guide a feature by feature matching search can achieve global matching with much fewer image processing operations and lower overall computational cost. Essentially, we put image processing into the loopof the search for global consensus. In particular, our approach is able to cope with significant image ambiguity thanks to a dynamic mixture of Gaussians treatment. In our fully Bayesian algorithm, the choice of the most efficient search action at each step is guided intuitively and rigorously by expected Shannon information gain. We demonstrate the algorithm in feature matching as part of a sequential SLAM system for 3D camera tracking. Robust, real-time matching can be achieved even in the previously unmanageable case of jerky, rapid motion necessitating weak motion modelling and large search regions."
            },
            "slug": "Active-Matching-Chli-Davison",
            "title": {
                "fragments": [],
                "text": "Active Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the dramatically different approach of using priors dynamically to guide a feature by feature matching search can achieve global matching with much fewer image processing operations and lower overall computational cost."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40029556"
                        ],
                        "name": "A. Zamir",
                        "slug": "A.-Zamir",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Zamir",
                            "middleNames": [
                                "Roshan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zamir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707795"
                        ],
                        "name": "Afshin Dehghan",
                        "slug": "Afshin-Dehghan",
                        "structuredName": {
                            "firstName": "Afshin",
                            "lastName": "Dehghan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Afshin Dehghan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 72
                            }
                        ],
                        "text": "Even though some settings allow for strong assumptions about the target [1, 2], sometimes it is desirable to track an object with little a-priori knowledge."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18601825,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d95d505a959c9fc8090cb84287dce92128fce63e",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Data association is an essential component of any human tracking system. The majority of current methods, such as bipartite matching, incorporate a limited-temporal-locality of the sequence into the data association problem, which makes them inherently prone to IDswitches and difficulties caused by long-term occlusion, cluttered background, and crowded scenes.We propose an approach to data association which incorporates both motion and appearance in a global manner. Unlike limited-temporal-locality methods which incorporate a few frames into the data association problem, we incorporate the whole temporal span and solve the data association problem for one object at a time, while implicitly incorporating the rest of the objects. In order to achieve this, we utilize Generalized Minimum Clique Graphs to solve the optimization problem of our data association method. Our proposed method yields a better formulated approach to data association which is supported by our superior results. Experiments show the proposed method makes significant improvements in tracking in the diverse sequences of Town Center [1], TUD-crossing [2], TUD-Stadtmitte [2], PETS2009 [3], and a new sequence called Parking Lot compared to the state of the art methods."
            },
            "slug": "GMCP-Tracker:-Global-Multi-object-Tracking-Using-Zamir-Dehghan",
            "title": {
                "fragments": [],
                "text": "GMCP-Tracker: Global Multi-object Tracking Using Generalized Minimum Clique Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes an approach to data association which incorporates both motion and appearance in a global manner and utilizes Generalized Minimum Clique Graphs to solve the optimization problem of the data association method."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758219"
                        ],
                        "name": "Matthew B. Blaschko",
                        "slug": "Matthew-B.-Blaschko",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Blaschko",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew B. Blaschko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] use branchand-bound optimization to find the maximum of a classifier\u2019s response without 1 We refer the reader to 2 reviews: [8] is more in-depth, while [9, Sec."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 55
                            }
                        ],
                        "text": "As of this writing, this is a topic of active research [10, 11, 16]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6131848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54b224478a63e33441c651175c522f3702062fc4",
            "isKey": false,
            "numCitedBy": 799,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Most successful object recognition systems rely on binary classification, deciding only if an object is present or not, but not providing information on the actual object location. To perform localization, one can take a sliding window approach, but this strongly increases the computational cost, because the classifier function has to be evaluated over a large set of candidate subwindows. In this paper, we propose a simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages. It converges to a globally optimal solution typically in sublinear time. We show how our method is applicable to different object detection and retrieval scenarios. The achieved speedup allows the use of classifiers for localization that formerly were considered too slow for this task, such as SVMs with a spatial pyramid kernel or nearest neighbor classifiers based on the chi2-distance. We demonstrate state-of-the-art performance of the resulting systems on the UIUC Cars dataset, the PASCAL VOC 2006 dataset and in the PASCAL VOC 2007 competition."
            },
            "slug": "Beyond-sliding-windows:-Object-localization-by-Lampert-Blaschko",
            "title": {
                "fragments": [],
                "text": "Beyond sliding windows: Object localization by efficient subwindow search"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages and converges to a globally optimal solution typically in sublinear time is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31982493"
                        ],
                        "name": "Amit Adam",
                        "slug": "Amit-Adam",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amit Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747801"
                        ],
                        "name": "E. Rivlin",
                        "slug": "E.-Rivlin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Rivlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rivlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782918"
                        ],
                        "name": "I. Shimshoni",
                        "slug": "I.-Shimshoni",
                        "structuredName": {
                            "firstName": "Ilan",
                            "lastName": "Shimshoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Shimshoni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 137
                            }
                        ],
                        "text": "Struck [4] achieves very good results (over 0.9 in most sequences), and outperforms other trackers like MILTrack, OAB, SemiBoost [6] and FragTrack [23]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "9 in most sequences), and outperforms other trackers like MILTrack, OAB, SemiBoost [6] and FragTrack [23]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206590783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15cd7d675e499d6e53014916d7cf4a1714341f6a",
            "isKey": true,
            "numCitedBy": 1532,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel algorithm (which we call \"Frag- Track\") for tracking an object in a video sequence. The template object is represented by multiple image fragments or patches. The patches are arbitrary and are not based on an object model (in contrast with traditional use of modelbased parts e.g. limbs and torso in human tracking). Every patch votes on the possible positions and scales of the object in the current frame, by comparing its histogram with the corresponding image patch histogram. We then minimize a robust statistic in order to combine the vote maps of the multiple patches. A key tool enabling the application of our algorithm to tracking is the integral histogram data structure [18]. Its use allows to extract histograms of multiple rectangular regions in the image in a very efficient manner. Our algorithm overcomes several difficulties which cannot be handled by traditional histogram-based algorithms [8, 6]. First, by robustly combining multiple patch votes, we are able to handle partial occlusions or pose change. Second, the geometric relations between the template patches allow us to take into account the spatial distribution of the pixel intensities - information which is lost in traditional histogram-based algorithms. Third, as noted by [18], tracking large targets has the same computational cost as tracking small targets. We present extensive experimental results on challenging sequences, which demonstrate the robust tracking achieved by our algorithm (even with the use of only gray-scale (noncolor) information)."
            },
            "slug": "Robust-Fragments-based-Tracking-using-the-Integral-Adam-Rivlin",
            "title": {
                "fragments": [],
                "text": "Robust Fragments-based Tracking using the Integral Histogram"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel algorithm for tracking an object in a video sequence represented by multiple image fragments or patches, which is able to handle partial occlusions or pose change and overcomes several difficulties which cannot be handled by traditional histogram-based algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708802"
                        ],
                        "name": "D. Bolme",
                        "slug": "D.-Bolme",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bolme",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bolme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694404"
                        ],
                        "name": "B. Draper",
                        "slug": "B.-Draper",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Draper",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Draper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143905691"
                        ],
                        "name": "J. Beveridge",
                        "slug": "J.-Beveridge",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Beveridge",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beveridge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 121
                            }
                        ],
                        "text": "This is a kind of correlation filter that has been proposed recently, called Minimum Output Sum of Squared Error (MOSSE) [12, 15], with a single training image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 41
                            }
                        ],
                        "text": "The Minimum Output Sum of Squared Error (MOSSE) filter [12] has been shown to be competitive with the methods outlined before, but at a fraction of the complexity, and runs at impressive speeds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 93
                            }
                        ],
                        "text": "Also closely related are adaptive correlation filters, rooted on classical signal processing [15, 12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 302,
                                "start": 297
                            }
                        ],
                        "text": "It produces a linear classifier that does not make use of the Kernel Trick, so we can compute w explicitly, instead of implicitly as \u03b1. Plugging it into the KRLS equations, we obtain:\nThis is a kind of correlation filter that has been proposed recently, called Minimum Output Sum of Squared Error (MOSSE) [12, 15], with a single training image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 13
                            }
                        ],
                        "text": "We called it MOSSE2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 14
                            }
                        ],
                        "text": "We found that MOSSE [12] is tuned only for 64 \u00d7 64 images."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6098097,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0133c3f08dbf21a76cd0a329f635bf5cdf2ce924",
            "isKey": true,
            "numCitedBy": 87,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a class of correlation filters called average of synthetic exact filters (ASEF). For ASEF, the correlation output is completely specified for each training image. This is in marked contrast to prior methods such as synthetic discriminant functions (SDFs) which only specify a single output value per training image. Advantages of ASEF training include: insensitivity to over-fitting, greater flexibility with regard to training images, and more robust behavior in the presence of structured backgrounds. The theory and design of ASEF filters is presented using eye localization on the FERET database as an example task. ASEF is compared to other popular correlation filters including SDF, MACE, OTF, and UMACE, and with other eye localization methods including Gabor Jets and the OpenCV cascade classifier. ASEF is shown to outperform all these methods, locating the eye to within the radius of the iris approximately 98.5% of the time."
            },
            "slug": "Average-of-Synthetic-Exact-Filters-Bolme-Draper",
            "title": {
                "fragments": [],
                "text": "Average of Synthetic Exact Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A class of correlation filters called average of synthetic exact filters (ASEF), which is in marked contrast to prior methods such as synthetic discriminant functions (SDFs) which only specify a single output value per training image, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8142777"
                        ],
                        "name": "R. Patnaik",
                        "slug": "R.-Patnaik",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Patnaik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Patnaik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "The work that comes closest to the goal of efficiently computing non-linear kernels at all locations is by Patnaik [20]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Patnaik and Casasent [16] investigate this problem, and show that, given the Fourier representation of an image, many classical filters cannot be kernelized."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2898469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbeea7f8cd6da10beef5f2703946f2101845b378",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "General object recognition is a specific application of pattern recognition, in which an object in a background must be classified in the presence of several distortions such as aspect-view differences, scale differences, and depression-angle differences. Since the object can be present at different locations in the test input, a classification algorithm must be applied to all possible object locations in the test input. We emphasize one type of classifier, the distortion-invariant filter (DIF), for fast object recognition, since it can be applied to all possible object locations using a fast Fourier transform (FFT) correlation. We refer to distortion-invariant correlation filters simply as DIFs. DIFs all use a combination of training-set images that are representative of the expected distortions in the test set. \nIn this dissertation, we consider a new approach that combines DIFs and the higher-order kernel technique; these form what we refer to as \"kernel DIFs.\" Our objective is to develop higher-order classifiers that can be applied (efficiently and fast) to all possible locations of the object in the test input. All prior kernel DIFs ignored the issue of efficient filter shifts. We detail which kernel DIF formulations are computational realistic to use and why. We discuss the proper way to synthesize DIFs and kernel DIFs for the wide area search case (i.e., when a small filter must be applied to a much larger test input) and the preferable way to perform wide area search with these filters; this is new. We use computer-aided design (CAD) simulated infrared (IR) object imagery and real IR clutter imagery to obtain test results. Our test results on IR data show that a particular kernel DIF, the kernel SDF filter and its new \"preprocessed\" version, is promising, in terms of both test-set performance and on-line calculations, and is emphasized in this dissertation. We examine the recognition of object variants. We also quantify the effect of different constant-valued object backgrounds in training and tests and the effect of non-constant clutter near the test objects on performance scores; these affect the target-to-background contrast ratio and have not been addressed in any prior DIF IR tests."
            },
            "slug": "Distortion-invariant-kernel-correlation-filters-for-Patnaik",
            "title": {
                "fragments": [],
                "text": "Distortion-invariant kernel correlation filters for general object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The test results on IR data show that a particular kernel DIF, the kernel SDF filter and its new \"preprocessed\" version, is promising, in terms of both test-set performance and on-line calculations, and is emphasized in this dissertation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143848064"
                        ],
                        "name": "Jo\u00e3o F. Henriques",
                        "slug": "Jo\u00e3o-F.-Henriques",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Henriques",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o F. Henriques"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144489408"
                        ],
                        "name": "Rui Caseiro",
                        "slug": "Rui-Caseiro",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Caseiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Caseiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2182210"
                        ],
                        "name": "Jorge P. Batista",
                        "slug": "Jorge-P.-Batista",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Batista",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge P. Batista"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12127879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4358be4a4475afb4f2da4f2c476aa55543effaf",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Multiple object tracking has been formulated recently as a global optimization problem, and solved efficiently with optimal methods such as the Hungarian Algorithm. A severe limitation is the inability to model multiple objects that are merged into a single measurement, and track them as a group, while retaining optimality. This work presents a new graph structure that encodes these multiple-match events as standard one-to-one matches, allowing computation of the solution in polynomial time. Since identities are lost when objects merge, an efficient method to identify groups is also presented, as a flow circulation problem. The problem of tracking individual objects across groups is then posed as a standard optimal assignment. Experiments show increased performance on the PETS 2006 and 2009 datasets compared to state-of-the-art algorithms."
            },
            "slug": "Globally-optimal-solution-to-multi-object-tracking-Henriques-Caseiro",
            "title": {
                "fragments": [],
                "text": "Globally optimal solution to multi-object tracking with merged measurements"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new graph structure is presented that encodes multiple-match events as standard one-to-one matches, allowing computation of the solution in polynomial time, and an efficient method to identify groups is also presented, as a flow circulation problem."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3236386"
                        ],
                        "name": "Varun Gulshan",
                        "slug": "Varun-Gulshan",
                        "structuredName": {
                            "firstName": "Varun",
                            "lastName": "Gulshan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varun Gulshan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 123
                            }
                        ],
                        "text": "An alternative is to use linear classification in a first stage, and then non-linear classification on promising locations [13, 14], but the results can be suboptimal."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206769604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9c7ab03bdb5fee15174d910d7fea14a16b086b7",
            "isKey": false,
            "numCitedBy": 883,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Our objective is to obtain a state-of-the art object category detector by employing a state-of-the-art image classifier to search for the object in all possible image sub-windows. We use multiple kernel learning of Varma and Ray (ICCV 2007) to learn an optimal combination of exponential \u03c72 kernels, each of which captures a different feature channel. Our features include the distribution of edges, dense and sparse visual words, and feature descriptors at different levels of spatial organization."
            },
            "slug": "Multiple-kernels-for-object-detection-Vedaldi-Gulshan",
            "title": {
                "fragments": [],
                "text": "Multiple kernels for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "This work uses multiple kernel learning of Varma and Ray (ICCV 2007) to learn an optimal combination of exponential \u03c72 kernels, each of which captures a different feature channel."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820887"
                        ],
                        "name": "Hedi Harzallah",
                        "slug": "Hedi-Harzallah",
                        "structuredName": {
                            "firstName": "Hedi",
                            "lastName": "Harzallah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hedi Harzallah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 123
                            }
                        ],
                        "text": "An alternative is to use linear classification in a first stage, and then non-linear classification on promising locations [13, 14], but the results can be suboptimal."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8879271,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fae850e7b85e91b11a2874252ec617c3cb064c6",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a combined approach for object localization and classification. Our contribution is twofold. (a) A contextual combination of localization and classification which shows that classification can improve detection and vice versa. (b) An efficient two stage sliding window object localization method that combines the efficiency of a linear classifier with the robustness of a sophisticated non-linear one. Experimental results evaluate the parameters of our two stage sliding window approach and show that our combined object localization and classification methods outperform the state-of-the-art on the PASCAL VOC 2007 and 2008 datasets."
            },
            "slug": "Combining-efficient-object-localization-and-image-Harzallah-Jurie",
            "title": {
                "fragments": [],
                "text": "Combining efficient object localization and image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An efficient two stage sliding window object localization method that combines the efficiency of a linear classifier with the robustness of a sophisticated non-linear one and shows that classification can improve detection and vice versa is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686506"
                        ],
                        "name": "A. Atiya",
                        "slug": "A.-Atiya",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Atiya",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Atiya"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 134
                            }
                        ],
                        "text": "Because they can be interpreted as linear classifiers, there is the question of whether correlation filters can take advantage of the Kernel Trick to classify on richer non-linear feature spaces."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 62
                            }
                        ],
                        "text": "It produces a linear classifier that does not make use of the Kernel Trick, so we can compute w explicitly, instead of implicitly as \u03b1. Plugging it into the KRLS equations, we obtain:\nThis is a kind of correlation filter that has been proposed recently, called Minimum Output Sum of Squared Error (MOSSE) [12, 15], with a single training image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "It is well known that the Kernel Trick [18] can improve performance further, by allowing classification on a rich high-dimensional feature space."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 71
                            }
                        ],
                        "text": "We also show that classification on non-linear feature spaces with the Kernel Trick can be done as efficiently as in the original image space."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 89
                            }
                        ],
                        "text": "As we have shown, Circulant matrices are the key enabling factor to extend them with the Kernel Trick."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7406938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ff61b8e097ccdb784a35b466ba9e130c2502513",
            "isKey": true,
            "numCitedBy": 5521,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Chapters 2\u20137 make up Part II of the book: artificial neural networks. After introducing the basic concepts of neurons and artificial neuron learning rules in Chapter 2, Chapter 3 describes a particular formalism, based on signal-plus-noise, for the learning problem in general. After presenting the basic neural network types this chapter reviews the principal algorithms for error function minimization/optimization and shows how these learning issues are addressed in various supervised models. Chapter 4 deals with issues in unsupervised learning networks, such as the Hebbian learning rule, principal component learning, and learning vector quantization. Various techniques and learning paradigms are covered in Chapters 3\u20136, and especially the properties and relative merits of the multilayer perceptron networks, radial basis function networks, self-organizing feature maps and reinforcement learning are discussed in the respective four chapters. Chapter 7 presents an in-depth examination of performance issues in supervised learning, such as accuracy, complexity, convergence, weight initialization, architecture selection, and active learning. Par III (Chapters 8\u201315) offers an extensive presentation of techniques and issues in evolutionary computing. Besides the introduction to the basic concepts in evolutionary computing, it elaborates on the more important and most frequently used techniques on evolutionary computing paradigm, such as genetic algorithms, genetic programming, evolutionary programming, evolutionary strategies, differential evolution, cultural evolution, and co-evolution, including design aspects, representation, operators and performance issues of each paradigm. The differences between evolutionary computing and classical optimization are also explained. Part IV (Chapters 16 and 17) introduces swarm intelligence. It provides a representative selection of recent literature on swarm intelligence in a coherent and readable form. It illustrates the similarities and differences between swarm optimization and evolutionary computing. Both particle swarm optimization and ant colonies optimization are discussed in the two chapters, which serve as a guide to bringing together existing work to enlighten the readers, and to lay a foundation for any further studies. Part V (Chapters 18\u201321) presents fuzzy systems, with topics ranging from fuzzy sets, fuzzy inference systems, fuzzy controllers, to rough sets. The basic terminology, underlying motivation and key mathematical models used in the field are covered to illustrate how these mathematical tools can be used to handle vagueness and uncertainty. This book is clearly written and it brings together the latest concepts in computational intelligence in a friendly and complete format for undergraduate/postgraduate students as well as professionals new to the field. With about 250 pages covering such a wide variety of topics, it would be impossible to handle everything at a great length. Nonetheless, this book is an excellent choice for readers who wish to familiarize themselves with computational intelligence techniques or for an overview/introductory course in the field of computational intelligence. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond\u2014Bernhard Sch\u00f6lkopf and Alexander Smola, (MIT Press, Cambridge, MA, 2002, ISBN 0-262-19475-9). Reviewed by Amir F. Atiya."
            },
            "slug": "Learning-with-Kernels:-Support-Vector-Machines,-and-Atiya",
            "title": {
                "fragments": [],
                "text": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This book is an excellent choice for readers who wish to familiarize themselves with computational intelligence techniques or for an overview/introductory course in the field of computational intelligence."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365442"
                        ],
                        "name": "B. Alexe",
                        "slug": "B.-Alexe",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Alexe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Alexe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35427418"
                        ],
                        "name": "V. Petrescu",
                        "slug": "V.-Petrescu",
                        "structuredName": {
                            "firstName": "Viviana",
                            "lastName": "Petrescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Petrescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 55
                            }
                        ],
                        "text": "As of this writing, this is a topic of active research [10, 11, 16]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[11] propose a method that can efficiently find the most similar subwindows between two images, which is a related problem."
                    },
                    "intents": []
                }
            ],
            "corpusId": 581181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5533e6728f82f30e64fa8af991028822b310ce9",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a computationally efficient technique to compute the distance of high-dimensional appearance descriptor vectors between image windows. The method exploits the relation between appearance distance and spatial overlap. We derive an upper bound on appearance distance given the spatial overlap of two windows in an image, and use it to bound the distances of many pairs between two images. We propose algorithms that build on these basic operations to efficiently solve tasks relevant to many computer vision applications, such as finding all pairs of windows between two images with distance smaller than a threshold, or finding the single pair with the smallest distance. In experiments on the PASCAL VOC 07 dataset, our algorithms accurately solve these problems while greatly reducing the number of appearance distances computed, and achieve larger speedups than approximate nearest neighbour algorithms based on trees [18] and on hashing [21]. For example, our algorithm finds the most similar pair of windows between two images while computing only 1% of all distances on average."
            },
            "slug": "Exploiting-spatial-overlap-to-efficiently-compute-Alexe-Petrescu",
            "title": {
                "fragments": [],
                "text": "Exploiting spatial overlap to efficiently compute appearance distances between image windows"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work derives an upper bound on appearance distance given the spatial overlap of two windows in an image, and uses it to bound the distances of many pairs between two images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40188005"
                        ],
                        "name": "Peng Zhang",
                        "slug": "Peng-Zhang",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47918185"
                        ],
                        "name": "Jing Peng",
                        "slug": "Jing-Peng",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Peng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 240766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b066702a859165fb4c42d35456154aff74da3bba",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines (SVMs) and regularized least squares (RLS) are two recent promising techniques for classification. SVMs implement the structure risk minimization principle and use the kernel trick to extend it to the nonlinear case. On the one hand, RLS minimizes a regularized functional directly in a reproducing kernel Hilbert space defined by a kernel. While both have a sound mathematical foundation, RLS is strikingly simple. On the other hand, SVMs in general have a sparse representation of solutions. In addition, the performance of SVMs has been well documented but little can be said of RLS. This paper applies these two techniques to a collection of data sets and presents results demonstrating virtual identical performance by the two methods."
            },
            "slug": "SVM-vs-regularized-least-squares-classification-Zhang-Peng",
            "title": {
                "fragments": [],
                "text": "SVM vs regularized least squares classification"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper applies support vector machines and regularized least squares to a collection of data sets and presents results demonstrating virtual identical performance by the two methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815078"
                        ],
                        "name": "S. Avidan",
                        "slug": "S.-Avidan",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Avidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Avidan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Almost all of the proposed methods have one thing in common: a sparse sampling strategy [3, 5\u20137]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A very successful approach has been tracking-by-detection [3\u20137]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Due to computational constraints, only a handful of random samples are collected [3\u20137]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Many use established learning algorithms such as Boosting [6, 3], Support Vector Machines (SVM) [5], or Random Forests [7], and adapt them to online training."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8281525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "836d5ddbecdb51f9ca21255743e399a267f7f6a4",
            "isKey": true,
            "numCitedBy": 761,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Tracking (SVT) integrates the Support Vector Machine (SVM) classifier into an optic-flow-based tracker. Instead of minimizing an intensity difference function between successive frames, SVT maximizes the SVM classification score. To account for large motions between successive frames, we build pyramids from the support vectors and use a coarse-to-fine approach in the classification stage. We show results of using SVT for vehicle tracking in image sequences."
            },
            "slug": "Support-vector-tracking-Avidan",
            "title": {
                "fragments": [],
                "text": "Support vector tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "Support Vector Tracking integrates the Support Vector Machine (SVM) classifier into an optic-flow-based tracker and maximizes the SVM classification score to account for large motions between successive frames."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "There are a couple of different definitions of C(u) that we will find useful [19]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "Since the product C(u)v represents convolution of vectors u and v [19], it can be computed in the Fourier domain, using"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "Some operations on matrices of the form C(u), like multiplication and inversion, can be done element-wise on the vectors u, if they are transformed to the Fourier domain [19]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "The properties of circulant matrices make them particularly amenable to manipulation, since their sums, products and inverses are also circulant [19]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 51861878,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "79d1b330f0ef51f63ecb9b291dd5a05de5a858c0",
            "isKey": true,
            "numCitedBy": 2100,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "The fundamental theorems on the asymptotic behavior of eigenvalues, inverses, and products of banded Toeplitz matrices and Toeplitz matrices with absolutely summable elements are derived in a tutorial manner. Mathematical elegance and generality are sacrificed for conceptual simplicity and insight in the hope of making these results available to engineers lacking either the background or endurance to attack the mathematical literature on the subject. By limiting the generality of the matrices considered, the essential ideas and results can be conveyed in a more intuitive manner without the mathematical machinery required for the most general cases. As an application the results are applied to the study of the covariance matrices and their factors of linear models of discrete time random processes."
            },
            "slug": "Toeplitz-and-Circulant-Matrices:-A-Review-Gray",
            "title": {
                "fragments": [],
                "text": "Toeplitz and Circulant Matrices: A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The fundamental theorems on the asymptotic behavior of eigenvalues, inverses, and products of banded Toeplitz matrices and Toepler matrices with absolutely summable elements are derived in a tutorial manner in the hope of making these results available to engineers lacking either the background or endurance to attack the mathematical literature on the subject."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Commun. Inf. Theory"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "Then, RLS with Kernels (KRLS) has the simple closed form solution [17]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "Many use established learning algorithms such as Boosting [6, 3], Support Vector Machines (SVM) [5], or Random Forests [7], and adapt them to online training."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "It has been shown that, in many practical problems, RLS offers equivalent classification performance to SVM [17]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "This framework includes the popular Support Vector Machine (SVM), which uses the hinge loss L(y, f(x)) = max (0, 1\u2212 yf(x))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "Going even further, Hare et al. [4] propose Struck, an online version of Structured Output SVM."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Regularized least-squares classification"
            },
            "venue": {
                "fragments": [],
                "text": "Nato Science Series Sub Series III: Computer and Systems Sciences"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62062125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09b028e77aa5f3d3175c4059e4ba57326c317e48",
            "isKey": false,
            "numCitedBy": 397,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Toeplitz-And-Circulant-Matrices:-A-Review-and-in-Gray",
            "title": {
                "fragments": [],
                "text": "Toeplitz And Circulant Matrices: A Review (Foundations and Trends(R) in Communications and Information Theory)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 24,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Exploiting-the-Circulant-Structure-of-with-Kernels-Henriques-Caseiro/5b4e50860d61095bb5fb65eaa367b131923917be?sort=total-citations"
}