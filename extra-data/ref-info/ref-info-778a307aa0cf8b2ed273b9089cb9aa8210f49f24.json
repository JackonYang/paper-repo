{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061646861"
                        ],
                        "name": "Stephan Fischer",
                        "slug": "Stephan-Fischer",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephan Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739319"
                        ],
                        "name": "R. Lienhart",
                        "slug": "R.-Lienhart",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Lienhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lienhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750165"
                        ],
                        "name": "W. Effelsberg",
                        "slug": "W.-Effelsberg",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Effelsberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Effelsberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3168975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96840df6de2afaf6ede9e788c0eb54a9171d1aab",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Film genres in digital video can be detected automatically. In a three-step approach we analyze first the syntactic properties of digital films: color statistics, cut detection, camera motion, object motion and audio. In a second step we use these statistics to derive at a more abstract level film style attributes such as camera panning and zooming, speech and music. These are distinguishing properties for film genres, e.g. newscasts vs. sports vs. commercials. In the third and final step we map the detected style attributes to film genres. Algorithms for the three steps are presented in detail, and we report on initial experience with real videos. It is our goal to automatically classify the large body of existing video for easier access in digital video-on-demand databases."
            },
            "slug": "Automatic-recognition-of-film-genres-Fischer-Lienhart",
            "title": {
                "fragments": [],
                "text": "Automatic recognition of film genres"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is the goal to automatically classify the large body of existing video for easier access in digital video-on-demand databases."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2019875"
                        ],
                        "name": "A. Shio",
                        "slug": "A.-Shio",
                        "structuredName": {
                            "firstName": "Akio",
                            "lastName": "Shio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49052113"
                        ],
                        "name": "S. Akamatsu",
                        "slug": "S.-Akamatsu",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Akamatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Akamatsu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1565945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e94d1ff801fce49eea8d8aa51a477b130ca755de",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "An effective algorithm for character recognition in scene images is studied. Scene images are segmented into regions by an image segmentation method based on adaptive thresholding. Character candidate regions are detected by observing gray-level differences between adjacent regions. To ensure extraction of multisegment characters as well as single-segment characters, character pattern candidates are obtained by associating the detected regions according to their positions and gray levels. A character recognition process selects patterns with high similarities by calculating the similarities between character pattern candidates and the standard patterns in a dictionary and then comparing the similarities to the thresholds. A relaxational approach to determine character patterns updates the similarities by evaluating the interactions between categories of patterns, and finally character patterns and their recognition results are obtained. Highly promising experimental results have been obtained using the method on 100 images involving characters of different sizes and formats under uncontrolled lighting. >"
            },
            "slug": "Recognizing-Characters-in-Scene-Images-Ohya-Shio",
            "title": {
                "fragments": [],
                "text": "Recognizing Characters in Scene Images"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "An effective algorithm for character recognition in scene images is studied and highly promising experimental results have been obtained using the method on 100 images involving characters of different sizes and formats under uncontrolled lighting."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743808"
                        ],
                        "name": "S. Smoliar",
                        "slug": "S.-Smoliar",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smoliar",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Smoliar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36502813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b00e70c64f2cc19cd893067c6e209ea47f37ee6",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer-assisted content-based indexing is a critical enabling technology and currently a bottleneck in productive use of video resources. This paper presents the Video Classification Project, an effort toward automating content-based video indexing and retrieval, at the Institute of Systems Science of the National University of Singapore. We discuss in detail three goals of the project: image processing tools for video parsing, feature extraction and retrieval; a knowledge-based approach to representing video content; and stratified tools which allow greater flexibility in browsing a video resource, either before or after performing specific retrieval operations."
            },
            "slug": "Developing-power-tools-for-video-indexing-and-Zhang-Smoliar",
            "title": {
                "fragments": [],
                "text": "Developing power tools for video indexing and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Video Classification Project is presented, an effort toward automating content-based video indexing and retrieval, at the Institute of Systems Science of the National University of Singapore."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784312"
                        ],
                        "name": "C. Low",
                        "slug": "C.-Low",
                        "structuredName": {
                            "firstName": "Chien",
                            "lastName": "Low",
                            "middleNames": [
                                "Yong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Low"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743808"
                        ],
                        "name": "S. Smoliar",
                        "slug": "S.-Smoliar",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smoliar",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Smoliar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588714"
                        ],
                        "name": "D. Zhong",
                        "slug": "D.-Zhong",
                        "structuredName": {
                            "firstName": "Di",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zhong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2469411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16daa3e4fd7fb7c3b8fa843ca79ef27a34ebce1f",
            "isKey": false,
            "numCitedBy": 399,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an integrated solution for computer assisted video parsing and content-based video retrieval and browsing. The uniqueness and effectiveness of this solution lies in its use of video content information provided by a parsing process driven by visual feature analysis. More specifically, parsing will temporally segment and abstract a video source, based on low-level image analyses; then retrieval and browsing of video will be based on key-frames selected during abstraction and spatial-temporal variations of visual features, as well as some shot-level semantics derived from camera operation and motion analysis. These processes, as well as video retrieval and browsing tools, are presented in detail as functions of an integrated system. Also, experimental results on automatic key-frame detection are given."
            },
            "slug": "Video-parsing,-retrieval-and-browsing:-an-and-Zhang-Low",
            "title": {
                "fragments": [],
                "text": "Video parsing, retrieval and browsing: an integrated and content-based solution"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper presents an integrated solution for computer assisted video parsing and content-based video retrieval and browsing that uses video content information provided by a parsing process driven by visual feature analysis."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152736800"
                        ],
                        "name": "M. Smith",
                        "slug": "M.-Smith",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15525071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94c4141cdd7615e8e6fccbfa864abd518a62efd8",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital video is rapidly becoming an important source for information, entertainment and a host of multimedia applications. With the size of these collections growing to thousands of hours, technology is needed to effectively browse segments in a short time without losing the content of the video. We propose a method to extract the significant audio and video information and create a \u201cskim\u201d video which represents a short synopsis of the original. The extraction of significant information, such as specific objects, audio keywords and relevant video structure, is made possible through the integration of techniques in image and language understanding. The resulting skim is much smaller, and retains the essential content of the original segment. This research is sponsored by the National Science Foundation under grant no. IRI9411299, the National Space and Aeronautics Administration, and the Advanced Research Projects Agency. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of the United States Government."
            },
            "slug": "Video-Skimming-for-Quick-Browsing-based-on-Audio-Smith",
            "title": {
                "fragments": [],
                "text": "Video Skimming for Quick Browsing based on Audio and Image Characterization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The extraction of significant information, such as specific objects, audio keywords and relevant video structure, is made possible through the integration of techniques in image and language understanding and a \u201cskim\u201d video is proposed which represents a short synopsis of the original."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109459020"
                        ],
                        "name": "Justin Miller",
                        "slug": "Justin-Miller",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Justin Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152951590"
                        ],
                        "name": "Kevin Mai",
                        "slug": "Kevin-Mai",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Mai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Mai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13437176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e37e7533b1689127f5eb151694f4add687767f96",
            "isKey": false,
            "numCitedBy": 577,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach to the detection and classification of scene breaks in video sequences. Our method can detect and classify a variety of scene breaks, including cuts, fades, dissolves and wipes, even in sequences involving significant motion. We detect the appearance of intensity edges that are distant from edges in the previous frame. A global motion computation is used to handle camera or object motion. The algorithms we propose withstand compression artifacts such as those introduced by JPEG and MPEG, even at very high compression rates. Experimental evidence demonstrates that our method can detect and classify scene breaks that are difficult to detect with previous approaches. An initial implementation runs at approximately 2 frames per second on a Sun workstation."
            },
            "slug": "A-feature-based-algorithm-for-detecting-and-scene-Zabih-Miller",
            "title": {
                "fragments": [],
                "text": "A feature-based algorithm for detecting and classifying scene breaks"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A new approach to the detection and classification of scene breaks in video sequences that can withstand compression artifacts such as those introduced by JPEG and MPEG, even at very high compression rates."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2211839"
                        ],
                        "name": "D. L. Gall",
                        "slug": "D.-L.-Gall",
                        "structuredName": {
                            "firstName": "Didier",
                            "lastName": "Gall",
                            "middleNames": [
                                "J.",
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. L. Gall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 652286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bafe1e3aba293f978ec0f44599d7d62eca9206c",
            "isKey": false,
            "numCitedBy": 2458,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The Moving Picture Experts Group (MPEG) standard addresses compression of video signals at approximately 1.5M-bits. MPEG is a generic standard and is independent of any particular applications. Applications of compressed video on digital storage media include asymmetric applications such as electronic publishing, games and entertainment. Symmetric applications of digital video include video mail, video conferencing, videotelephone and production of electronic publishing. Design of the MPEG algorithm presents a difficult challenge since quality requirements demand high compression that cannot be achieved with only intraframe coding. The algorithm\u2019s random access requirement, however, is best satisfied with pure intraframe coding. MPEG uses predictive and interpolative coding techniques to answer this challenge. Extensive details are presented."
            },
            "slug": "MPEG:-a-video-compression-standard-for-multimedia-Gall",
            "title": {
                "fragments": [],
                "text": "MPEG: a video compression standard for multimedia applications"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Design of the MPEG algorithm presents a difficult challenge since quality requirements demand high compression that cannot be achieved with only intraframe coding, and the algorithm\u2019s random access requirement is best satisfied with pure intraframes coding."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738392"
                        ],
                        "name": "Arthur R. Pope",
                        "slug": "Arthur-R.-Pope",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Pope",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur R. Pope"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14957603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd3f910c90cf4bb41c008bf869af9655809bcba7",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Vista is a software environment supporting the modular implementation and execution of computer vision algorithms. Because it is extensible, portable, and freely available, Vista is an appropriate medium for the exchange of standard implementations of algorithms. This paper, an overview of Vista, describes its file format, its data abstraction, its conventions for UNIX filter programs and library routines, and its user interface toolkit. Unlike systems that are designed principally to support image processing, Vista provides for the easy creation and use of arbitrary data types, such as are needed for many areas of computer vision research.<<ETX>>"
            },
            "slug": "Vista:-a-software-environment-for-computer-vision-Pope-Lowe",
            "title": {
                "fragments": [],
                "text": "Vista: a software environment for computer vision research"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An overview of Vista is described, which describes its file format, its data abstraction, its conventions for UNIX filter programs and library routines, and its user interface toolkit."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068153936"
                        ],
                        "name": "S. L. Horowitz",
                        "slug": "S.-L.-Horowitz",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Horowitz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. L. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32760436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9c8cc989558e6f464ac184743c67ccccad9bb12",
            "isKey": false,
            "numCitedBy": 569,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In the past, picture segmentation has been performed by merging small primitive regions or by recursively splitting the whole picture. This paper combines the two approaches with significant increase in processing speed while maintaining small memory requirements. The data structure is described in detail and examples of implementations are given."
            },
            "slug": "Picture-Segmentation-by-a-Tree-Traversal-Algorithm-Horowitz-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Picture Segmentation by a Tree Traversal Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper combines the two approaches with significant increase in processing speed while maintaining small memory requirements and the data structure is described in detail."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13284142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec",
            "isKey": false,
            "numCitedBy": 27658,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge."
            },
            "slug": "A-Computational-Approach-to-Edge-Detection-Canny",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a natural uncertainty principle between detection and localization performance, which are the two main goals, and with this principle a single operator shape is derived which is optimal at any scale."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2926874"
                        ],
                        "name": "W. B. Pennebaker",
                        "slug": "W.-B.-Pennebaker",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pennebaker",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. B. Pennebaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2848535"
                        ],
                        "name": "Joan L. Mitchell",
                        "slug": "Joan-L.-Mitchell",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan L. Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60826306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9c521df97e54ffa1c597915e808e7f67bb7cc54",
            "isKey": false,
            "numCitedBy": 3343,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Foreword. Acknowledgments. Trademarks. Introduction. Image Concepts and Vocabulary. Aspects of the Human Visual Systems. The Discrete Cosine Transform (DCT). Image Compression Systems. JPEG Modes of Operation. JPEG Syntax and Data Organization. Entropy Coding Concepts. JPEG Binary Arithmetic Coding. JPEG Coding Models. JPEG Huffman Entropy Coding. Arithmetic Coding Statistical. More on Arithmetic Coding. Probability Estimation. Compression Performance. JPEG Enhancements. JPEG Applications and Vendors. Overview of CCITT, ISO, and IEC. History of JPEG. Other Image Compression Standards. Possible Future JPEG Directions. Appendix A. Appendix B. References. Index."
            },
            "slug": "JPEG:-Still-Image-Data-Compression-Standard-Pennebaker-Mitchell",
            "title": {
                "fragments": [],
                "text": "JPEG: Still Image Data Compression Standard"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This chapter discusses JPEG Syntax and Data Organization, the history of JPEG, and some of the aspects of the Human Visual Systems that make up JPEG."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153312185"
                        ],
                        "name": "S. Mori",
                        "slug": "S.-Mori",
                        "structuredName": {
                            "firstName": "Shunji",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686714"
                        ],
                        "name": "Kazuhiko Yamamoto",
                        "slug": "Kazuhiko-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhiko",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiko Yamamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58021636,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0627cb9872115ea4c4d3484538a2f440923d8f13",
            "isKey": false,
            "numCitedBy": 940,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Research and development of OCR systems are considered from a historical point of view. The historical development of commercial systems is included. Both template matching and structure analysis approaches to R&D are considered. It is noted that the two approaches are coming closer and tending to merge. Commercial products are divided into three generations, for each of which some representative OCR systems are chosen and described in some detail. Some comments are made on recent techniques applied to OCR, such as expert systems and neural networks, and some open problems are indicated. The authors' views and hopes regarding future trends are presented. >"
            },
            "slug": "Historical-review-of-OCR-research-and-development-Mori-Suen",
            "title": {
                "fragments": [],
                "text": "Historical review of OCR research and development"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Both template matching and structure analysis approaches to R&D are considered and it is noted that the two approaches are coming closer and tending to merge."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52309453"
                        ],
                        "name": "\uc624\uc2b9\uc900",
                        "slug": "\uc624\uc2b9\uc900",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\uc624\uc2b9\uc900",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\uc624\uc2b9\uc900"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57533289,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33d8f440bbabe002c3aa54a38d332160c78b62b0",
            "isKey": false,
            "numCitedBy": 563,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "[\uc11c\ud3c9]\u300cDigital-Video-Processing\u300d-\uc624\uc2b9\uc900",
            "title": {
                "fragments": [],
                "text": "[\uc11c\ud3c9]\u300cDigital Video Processing\u300d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Methods of Automatic Character Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Methods of Automatic Character Recognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Suen , Kazuhiko Yamamoto , \u201c Historical Review of OCR Research and Development \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "The MoCA Workbench \u201d , University of Mannheim , Computer Science Department , Technical Report TR - 34 - 95 , November 1996"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The MoCA Workbench"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report TR-34-95,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introduction to Vista Programming Tools"
            },
            "venue": {
                "fragments": [],
                "text": "Introduction to Vista Programming Tools"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture Segmentation by a Traversal Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graphics Image Process. 1, pp. 360-372"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ", \" Picture Segmentation by a Traversal Algorithm \""
            },
            "venue": {
                "fragments": [],
                "text": "Comput . Graphics Image Process"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Murat Tekalp , \u201c Digital Video Processing \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Int . Workshop Industrial Applications of Machine Vision and Machine Intelligence"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gray Scale Image Processing Technology Applied to Vehicle License Number Recognition System"
            },
            "venue": {
                "fragments": [],
                "text": "in Proc. Int. Workshop Industrial Applications of Machine Vision and Machine Intelligence,"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Automatic-text-recognition-in-digital-videos-Lienhart-Stuber/778a307aa0cf8b2ed273b9089cb9aa8210f49f24?sort=total-citations"
}