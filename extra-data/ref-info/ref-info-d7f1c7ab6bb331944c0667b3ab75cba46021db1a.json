{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "(Hurst, 2000)\nAfter the completion of the tasks outlined above, one knows how to read the information in the table, but one does not yet know what is being said (in the example of Figure 1, for instance, we already know that \u201clife\u201d, \u201cwild buckweat\u201d and \u201cannual\u201d have to be read conjointly, but we do\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, those who have either avoided committing themselves to a specific context and hence not exploited the full potential of interpretation [ 20 ]; or have taken interpretation to deep levels (including in terms of the guarantee it can give of the quality of the results achieved) but to do so have made their systems dysfunctional in any context other than their own limited one (to use Ferguson\u2019s [11] or Kornfeld and Wattecamps [29] ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hurst [ 20 ]. Each data cell is connected with the first attribute cell above and next to it. Semantic webs are built on the content of attribute cells."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hurst [ 20 ] identifies two major interpretation steps that can be performed before interpretation becomes contextspecific."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Evaluation: Precision and recall in terms of the total number of attribute cells and data cells accurately identified; these two measures may be normalized as suggested by Hurst [ 20 ]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Table 5 Deriving categories (presented in Hurst [ 20 ])"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2000) measures the results of functional analysis by computing performance and recall in the classification of attributes and data cells; because attribute cells are less common in tables but mistakes in their recognition are more serious, these two measures can be normalized with the weight\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hurst [ 20 ] measures the results of functional analysis by computing performance and recall on the classification of cells as attributes or data; because attribute cells tend to be less frequent in tables but mistakes in their recognition are more serious, the author suggests normalizing the two using the relative weight of attribute and data cells in the test set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This information can be discovered in the document itself, in models of the domain which the document\u2019s content comes from or is about, or from world knowledge.\u201d Hurst [ 20 ]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In these tables, among the types of relationships identified in Hurst [ 20 ] and seen in Sect."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 172
                            }
                        ],
                        "text": "Evaluation: precision and recall in terms of the total number of attribute cells and data cells accurately identified; these two measures may be normalised as suggested by Hurst (2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 20
                            }
                        ],
                        "text": "According to Mathew Hurst (2000), several models can be used to represent a table."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 142
                            }
                        ],
                        "text": "Identifying relationships: In the accounting tables that hold mostly numbers, of those types of relationships between the cells identified in Hurst (2000), the most common are:\n\u2013 partitive relationships, e.g. intangible assets are a part of assets \u2013 quantitative value relations, e.g. intangible\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hurst [ 20 ] tries three different approaches: a set of heuristics (considering the physical model of the table, the semantic types of its content, and a comparison of the content with the text in the document), a Na\u00a8 classification (with physical and content-related attributes derived from comparison with surrounding text and titles) and a pattern-based classification (which implies a definition of physical patterns for each cell on ..."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2000)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2000) identifies two major interpretation steps (c.f. Table 4) that can be performed before interpretation becomes context-specific."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5481713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ba28bb5c79f9115b3f3b62593feedf1d73b3027",
            "isKey": true,
            "numCitedBy": 94,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis looks at the issues relating to the development of technology capable of processing tables as they appear in textual documents so that their contents may be accessed and further interpreted by standard information extraction and natural language processing systems. The thesis offers a formal description of the table and the description and evaluation of a system which provides instances of that model for table examples. There are three parts to the thesis. The first looks at tables in general terms, suggests where their complexities are to be found, and reviews the literature dealing with research into tables in other fields. The second part introduces a layered model of the table and provides some notational equipment for encoding tables in these component layers. The final part discusses the design, implementation and evaluation of a system which produces an instance of the model for the tables found in a document. It also discusses the design and collection of a corpus of tables used for the training and evaluation of the system. The thesis catalogues a laxge number of phenomena discovered in the corpus collected during the research and provides appropriate terminology."
            },
            "slug": "The-interpretation-of-tables-in-texts-Hurst",
            "title": {
                "fragments": [],
                "text": "The interpretation of tables in texts"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This thesis looks at the issues relating to the development of technology capable of processing tables as they appear in textual documents so that their contents may be accessed and further interpreted by standard information extraction and natural language processing systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689847"
                        ],
                        "name": "Jean-Yves Ramel",
                        "slug": "Jean-Yves-Ramel",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Ramel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Ramel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719698"
                        ],
                        "name": "M. Crucianu",
                        "slug": "M.-Crucianu",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Crucianu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Crucianu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145645182"
                        ],
                        "name": "N. Vincent",
                        "slug": "N.-Vincent",
                        "structuredName": {
                            "firstName": "Nicole",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38138508"
                        ],
                        "name": "C. Faure",
                        "slug": "C.-Faure",
                        "structuredName": {
                            "firstName": "Claudie",
                            "lastName": "Faure",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faure"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "So we will derive blocks of text that are sufficiently close, much in the way that is done in [ 34 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(H) [ 34 ] agree with Klein et al. [28] that \u201cdifferent perceived regularities complete each other to let the reader detect the presence of a table and identify its structure.\u201d Their method is sensitive to rectangular gridlines that may delimit all the cells of the table or only a few; they believe more sparsely delimited tables tend to have more regular text blocks, to which their method is also sensitive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18293386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "275d79256336a53141e6602d5fdf736139e90b8f",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We are concerned with the extraction of tables from exchange format representations of very diverse composite documents. We put forward a flexible representation scheme for complex tables, based on a clear distinction between the physical layout of a table and its logical structure. Relying on this scheme, we develop a new method for the detection and the extraction of tables by an analysis of the graphic lines. To deal with tables that lack all or most of the graphic marks, one must focus on the regularities of the text elements alone. We propose such a method, based on a multi-level analysis of the layout of text components on a page. A general graph representation of the relative positions of blocks of text is exploited."
            },
            "slug": "Detection,-extraction-and-representation-of-tables-Ramel-Crucianu",
            "title": {
                "fragments": [],
                "text": "Detection, extraction and representation of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A flexible representation scheme for complex tables is put forward, based on a clear distinction between the physical layout of a table and its logical structure, and a new method for the detection and the extraction of tables by an analysis of the graphic lines is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145658132"
                        ],
                        "name": "David Pinto",
                        "slug": "David-Pinto",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876441"
                        ],
                        "name": "Xing Wei",
                        "slug": "Xing-Wei",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Pinto et al. (2003)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As demonstrated in these works, a simple heuristic approach is sufficient to guarantee very good results in this task."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "(T) Pinto et al. (2003) begin by assigning a label to each line that indicates its function as data, header or caption; they also characterise it on the presence of white space, content type and on the presence of certain separator characters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We propose a possible solution to this problem in Section 5.5.2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1092004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6991606a1a9d5c285af385ee9159fd46cc14048e",
            "isKey": true,
            "numCitedBy": 440,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to find tables and extract information from them is a necessary component of data mining, question answering, and other information retrieval tasks. Documents often contain tables in order to communicate densely packed, multi-dimensional information. Tables do this by employing layout patterns to efficiently indicate fields and records in two-dimensional form.Their rich combination of formatting and content present difficulties for traditional language modeling techniques, however. This paper presents the use of conditional random fields (CRFs) for table extraction, and compares them with hidden Markov models (HMMs). Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better. We show experimental results on plain-text government statistical reports in which tables are located with 92% F1, and their constituent lines are classified into 12 table-related categories with 94% accuracy. We also discuss future work on undirected graphical models for segmenting columns, finding cells, and classifying them as data cells or label cells."
            },
            "slug": "Table-extraction-using-conditional-random-fields-Pinto-McCallum",
            "title": {
                "fragments": [],
                "text": "Table extraction using conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better, and are compared with hidden Markov models (HMMs)."
            },
            "venue": {
                "fragments": [],
                "text": "DG.O"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901883"
                        ],
                        "name": "Shona Douglas",
                        "slug": "Shona-Douglas",
                        "structuredName": {
                            "firstName": "Shona",
                            "lastName": "Douglas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shona Douglas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 106
                            }
                        ],
                        "text": "A heuristic classifies as attribute the first line which has all (or all but the first) column filled in.\nHurst and Douglas (1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 102
                            }
                        ],
                        "text": "As demonstrated in these works, a simple heuristic approach is sufficient to guarantee very good results in this task."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 14091058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "971af881cefc0bccb7f47046095d0a92f0de3152",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a prototype system for assigning table cells to their proper place in the logical structure of the table, based on a simple model of table structure combined with a number of measures of cohesion between cells. A framework is presented for examining the effect of particular variables on the performance of the system, and preliminary results are presented showing the effect of cohesion measures based on the simplest domain-independent analyses, with the aim allowing future comparison with more knowledge-intensive analyses based on natural language processing. These baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as we require. Future work will pursue the aim of more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells."
            },
            "slug": "Layout-and-language:-preliminary-investigations-in-Hurst-Douglas",
            "title": {
                "fragments": [],
                "text": "Layout and language: preliminary investigations in recognizing the structure of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "B baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as it is suggested that more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells are needed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 1
                            }
                        ],
                        "text": "(Hurst, 2000)\nAfter the completion of the tasks outlined above, one knows how to read the information in the table, but one does not yet know what is being said (in the example of Figure 1, for instance, we already know that \u201clife\u201d, \u201cwild buckweat\u201d and \u201cannual\u201d have to be read conjointly, but we do\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 28
                            }
                        ],
                        "text": "To address this problem, in Hu et al (2000) ground truth has been generated by all four authors: \u201cA line was classified as table or nontable if three or four votes (out of four) classified it in that way\u201d."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 145
                            }
                        ],
                        "text": "\u2026measures the results of functional analysis by computing performance and recall in the classification of attributes and data cells; because attribute cells are less common in tables but mistakes in their recognition are more serious, these two measures can be normalized with the weight of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As demonstrated in these works, a simple heuristic approach is sufficient to guarantee very good results in this task."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "Apart from these more standard measurements, to evaluate location Hu et al. (2000) and Cesarini et al.\n(2002) take \u201ca measure of the similarity of two documents (the recognised document and its ground truth) in terms of their table structure\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 10
                            }
                        ],
                        "text": "Hurst (2000) identifies two major interpretation steps (c.f. Table 4) that can be performed before interpretation becomes context-specific."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37293831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edbd577d793a083de4f337acac992ec7837609e0",
            "isKey": true,
            "numCitedBy": 90,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An important step towards the goal of table understanding is a method for reliable table detection. This paper describes a general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables. A dynamic programming algorithm is given to solve the resulting optimization problem. This high-level framework is independent of any particular table quality measure and independent of the document medium. Moreover, it does not rely on the presence of ruling lines or other table delimiters. We also present table quality measures based on white space correlation and vertical connected component analysis. These measures can be applied equally well to ASCII text and scanned images. We report on some preliminary experiments using this method to detect tables in both ASCII text and scanned images, yielding promising results. We present detailed evaluation of these results using three different criteria which by themselves pose interesting research questions."
            },
            "slug": "Medium-independent-table-detection-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Medium-independent table detection"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables is described and a dynamic programming algorithm is given to solve the resulting optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34996245"
                        ],
                        "name": "B. Klein",
                        "slug": "B.-Klein",
                        "structuredName": {
                            "firstName": "Bertin",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2602600"
                        ],
                        "name": "Serdar G\u00f6kkus",
                        "slug": "Serdar-G\u00f6kkus",
                        "structuredName": {
                            "firstName": "Serdar",
                            "lastName": "G\u00f6kkus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serdar G\u00f6kkus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(H) [34] agree with Klein et al. [ 28 ] that \u201cdifferent perceived regularities complete each other to let the reader detect the presence of a table and identify its structure.\u201d Their method is sensitive to rectangular gridlines that may delimit all the cells of the table or only a few; they believe more sparsely delimited tables tend to have more regular text blocks, to which their method is also sensitive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "(T) Klein et al. (2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Tables will have a number of similar cells is above given a threshold. (T) Klein et al. [ 28 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42252433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea049d0fc3995977b52c10be08fc288789b86ac1",
            "isKey": true,
            "numCitedBy": 37,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents. Searching for a set of known table headers (approach 1) works rather well in a significant number of documents. But this approach (though it is implemented tolerant to OCR errors) is not tolerant enough towards some kinds of even minor aberrations. This not only decreases the recognition results, but also, even worse, makes users feel uncomfortable. Pragmatically trying to mimic for what the human eyes might key, leads to our two further, complementary approaches: searching for layout structures which resemble parts of columns (approach 2), and searching for groupings of similar lines (approach 3). The suitability of the approaches for our system requires them to be very simple to implement and simple to explain to users, computationally cheap, and combinable. In the domain of health insurances who receive huge amounts of so called medical liquidations on a daily basis we obtain very good results. On document samples representative for the every day practice of five customers-health insurance companies-tables were spotted as good and as fast as the customers expected the system to be. We thus consider our current approaches as a step towards cognitive adequacy."
            },
            "slug": "Three-approaches-to-\"industrial\"-table-spotting-Klein-G\u00f6kkus",
            "title": {
                "fragments": [],
                "text": "Three approaches to \"industrial\" table spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents, and considers the current approaches as a step towards cognitive adequacy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2494216"
                        ],
                        "name": "P. Pyreddy",
                        "slug": "P.-Pyreddy",
                        "structuredName": {
                            "firstName": "Pallavi",
                            "lastName": "Pyreddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pyreddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13991200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d674f1289f336d88c4ab93e7204a345a302ed2eb",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables form an important kind of data element in text retrieval. Often, the gist of an entire news article or other exposition can be concisely captured in tabular form. In this paper, we examine the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities. More specifically, we exploit the structural information in a document to identify tables and their component fields and let the users query based on these fields. Our empirical results have demonstrated that heuristic method based table extraction and component tagging can be performed effectively and efficiently. Moreover, our experiments in retrieval using the TINTIN system have strongly indicated that such structural decomposition can facilitate better representation of user\u2019s information needs and hence more effective retrieval of tables."
            },
            "slug": "TINTIN:-a-system-for-retrieval-in-text-tables-Pyreddy-Croft",
            "title": {
                "fragments": [],
                "text": "TINTIN: a system for retrieval in text tables"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper examines the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities and demonstrates that heuristic method based table extraction and component tagging can be performed effectively and efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "DL '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2261082"
                        ],
                        "name": "Tetsuya Nasukawa",
                        "slug": "Tetsuya-Nasukawa",
                        "structuredName": {
                            "firstName": "Tetsuya",
                            "lastName": "Nasukawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tetsuya Nasukawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "(Hurst, 2000)\nAfter the completion of the tasks outlined above, one knows how to read the information in the table, but one does not yet know what is being said (in the example of Figure 1, for instance, we already know that \u201clife\u201d, \u201cwild buckweat\u201d and \u201cannual\u201d have to be read conjointly, but we do\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2000) measures the results of functional analysis by computing performance and recall in the classification of attributes and data cells; because attribute cells are less common in tables but mistakes in their recognition are more serious, these two measures can be normalized with the weight\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 172
                            }
                        ],
                        "text": "Evaluation: precision and recall in terms of the total number of attribute cells and data cells accurately identified; these two measures may be normalised as suggested by Hurst (2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 20
                            }
                        ],
                        "text": "According to Mathew Hurst (2000), several models can be used to represent a table."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 142
                            }
                        ],
                        "text": "Identifying relationships: In the accounting tables that hold mostly numbers, of those types of relationships between the cells identified in Hurst (2000), the most common are:\n\u2013 partitive relationships, e.g. intangible assets are a part of assets \u2013 quantitative value relations, e.g. intangible\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2000)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2000) identifies two major interpretation steps (c.f. Table 4) that can be performed before interpretation becomes context-specific."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12776597,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "1b186f9e467e2ce797edffb85ca30bca34fa4952",
            "isKey": true,
            "numCitedBy": 31,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Complex documents stored in a flat or partially marked up file format require layout sensitive preprocessing before any natural language processing can be carried out on their textual content. Contemporary technology for the discovery of basic textual units is based on either spatial or other content insensitive methods. However, there are many cases where knowledge of both the language and layout is required in order to establish the boundaries of the basic textual blocks. This paper describes a number of these cases and proposes the application of a general method combining knowledge about language with knowledge about the spatial arrangement of text. We claim that the comprehensive understanding of layout can only be achieved through the exploitation of layout knowledge and language knowledge in an inter-dependent manner."
            },
            "slug": "Layout-and-Language:-Integrating-Spatial-and-for-Hurst-Nasukawa",
            "title": {
                "fragments": [],
                "text": "Layout and Language: Integrating Spatial and Linguistic Knowledge for Layout Understanding Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is claimed that the comprehensive understanding of layout can only be achieved through the exploitation of layout knowledge and language knowledge in an inter-dependent manner."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901883"
                        ],
                        "name": "Shona Douglas",
                        "slug": "Shona-Douglas",
                        "structuredName": {
                            "firstName": "Shona",
                            "lastName": "Douglas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shona Douglas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054489514"
                        ],
                        "name": "David Quinn",
                        "slug": "David-Quinn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Quinn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Quinn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 249
                            }
                        ],
                        "text": "\u2026context, the function of each cell is determined by a set of heuristics based on the coordinates of each cell, the semantic type of its content within the context\u2019s specific language, and a Boolean for whether there is a semantic connection between the content of each cell and the table\u2019s title."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 0
                            }
                        ],
                        "text": "Science Application International Corporation (1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 42
                            }
                        ],
                        "text": "The groups formed constitute each data cell\u2019s reading path."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 120
                            }
                        ],
                        "text": "An algorithm will then merge vertically aligned cells which contents would be too large for the horizontal space available in the column."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Douglas et al. (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "(T) Douglas et al (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 4
                            }
                        ],
                        "text": "(T) Douglas et al. (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 44
                            }
                        ],
                        "text": "(I) Science Application International Corporation (1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 23
                            }
                        ],
                        "text": "A similar heuristic to Douglas et al. (1995) determines whether text blocks are possible table columns; such blocks are presented to an optical character recognition software (OCR) and each of their lines is characterised on the number of words it contains (0, 1, >1); then the neighbourhood of a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18944899,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "211d7cdfbff8f379ad4885e96f4b68d0d9bc9b9e",
            "isKey": true,
            "numCitedBy": 19,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Figure 2:A generic table with terminology (`*' representsoptionality)3.2VariationsonTableLayoutDi erent layout arrangements can b e thought of as expressing functional asp ects of the relation, usingsomesimple heuristicsab outthewaygroupingandorderingmay b eexpressedintodimensions.Because we conventionally read tables from the left and from the top, we distinguish theleft marginandtopmarginoftablesasareasthetableinwhichhigh-precedencedomains areplaced(seeFigure 2).A given layout supp orts a certainreading order.This reading order reectsthe way inwhich domains are organised and sp eci cally thegroupsandordersin which domains can b e easilyusedaskeysin cho osing and reading/constructing a tuple from the table; the reading order is thusthe emb o diment of the decision structure we identi ed as the functional part of the table.Thus,while a single canonical form may have many layouts, a given canonical form plus functionalinformation will have a much reducedrange of felicitous layouts.These typical constraints on laoutwillb eusedlaterinourpro cessingheuristics.First,wepresentarep ertoireoftransformations ofsimple tables in terms of which we can analyse the variations in layout that o ccur.RotationThis transformation is b est describ ed by example:StandardslumpValue75mmv1ST1125mmv275mmv3ST2125mmv4!Standard75mm125mmValueST1v1v2v34"
            },
            "slug": "Using-Natural-Language-Processing-for-Identifying-Douglas-Hurst",
            "title": {
                "fragments": [],
                "text": "Using Natural Language Processing for Identifying and Interpreting Tables in Plain Text"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "While a single canonical form may have many layouts, a given canonical form plus functional information will have a much reducedrange of felicitous layouts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 4
                            }
                        ],
                        "text": "(T) Kieninger (1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 6
                            }
                        ],
                        "text": "(T/I) Kieninger (1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 102
                            }
                        ],
                        "text": "Rather than relative word position as a first step to column identification (as would Tupaj (1996) or Kieninger (1998)), this author begins by using a language model to concatenate different words into cells, with which columns and rows are searched for."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(Douglas usa semantic analysis \u2013 po\u0302r cruz)"
                    },
                    "intents": []
                }
            ],
            "corpusId": 206405589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "108030474840ce5e1086cc8ef598ff3e6c13693c",
            "isKey": true,
            "numCitedBy": 120,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient approach to identify tabular structures within either electronic or paper documents. The resulting T-Recs system takes word bounding box information as input, and outputs the corresponding logical text block units. Starting with an arbitrary word as block seed the algorithm recursively expands this block to all words that interleave with their vertical neighbors. Since even smallest gaps of table columns prevent their words from mutual interleaving, this initial segmentation is able to identify and isolate such columns. In order to deal with some inherent segmentation errors caused by isolated lines, overhanging words, or cells spawning more than one column, a series of postprocessing steps is added. These steps benefit form a very simple distinction between type 1 and type 2 blocks: type 1 blocks are those of at most one word per line, all others are of type 2. This distinction allows the selective application of heuristics to each group of blocks. The conjoint decomposition of column blocks into subsets of table cells leads to the final block segmentation of a homogeneous abstraction level. These segments serve the final layout analysis which identifies table environments and cells that are stretching over several rows and/or columns."
            },
            "slug": "Table-structure-recognition-based-on-robust-block-Kieninger",
            "title": {
                "fragments": [],
                "text": "Table structure recognition based on robust block segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An efficient approach to identify tabular structures within either electronic or paper documents by taking word bounding box information as input, and outputs the corresponding logical text block units through the T-Recs system."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105434437"
                        ],
                        "name": "Scott Tupaj",
                        "slug": "Scott-Tupaj",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Tupaj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Tupaj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110396962"
                        ],
                        "name": "Zhong Shi",
                        "slug": "Zhong-Shi",
                        "structuredName": {
                            "firstName": "Zhong",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhong Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145923790"
                        ],
                        "name": "D. H. Chang",
                        "slug": "D.-H.-Chang",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Chang",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 4
                            }
                        ],
                        "text": "(T) Tupaj et al (1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 33
                            }
                        ],
                        "text": "We will summarize the approaches of different authors to this task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 71
                            }
                        ],
                        "text": "Aiming at information retrieval, a set of heuristics classifies each line as attribute or data by comparing it with average characteristics taken from all table line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 76
                            }
                        ],
                        "text": "An algorithm will then merge vertically aligned cells which contents would be too large for the horizontal space available in the column."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 175
                            }
                        ],
                        "text": "\u2026table\u2019s physical model: Pyreddi and Croft\u2019s (1997) measured them in terms of the number of lines correctly tagged; Wang et al. (2000-2002) took the same measurements on cells; Tupaj et al (1996) and Chen et al (2000) consider full tables as well; and Ng et al (1999) take full table, column and row."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "(I) Tupaj et al. (1996)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18379904,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebeade30e54c102bf7d806739ea0f963ba07a20e",
            "isKey": true,
            "numCitedBy": 42,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents work done in locating and extracting tables and their contents from document images. While most research in the area of table analysis and recognition has focused on analyzing the raster image, our approach builds upon the advances in optical character recognition (OCR) software to preserve the layout of tabular data by means of white space. By using methods to analyze the geometry, syntax, and the semantics of the character data, as well as utilizing some well-known image processing techniques, we are able to 1) isolate embedded tables from documents, and 2) identify table components uch as title blocks, table entries, and footer blocks. Furthermore, the table analysis techniques presented in this paper can also be applied when analyzing blocks of text isolated by traditional methods such as connected component analysis[1] or bounding box [2]."
            },
            "slug": "Extracting-Tabular-Information-From-Text-Files-Tupaj-Shi",
            "title": {
                "fragments": [],
                "text": "Extracting Tabular Information From Text Files"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The approach builds upon the advances in optical character recognition software to preserve the layout of tabular data by means of white space to isolate embedded tables from documents and identify table components uch as title blocks, table entries, and footer blocks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2456613"
                        ],
                        "name": "J. H. Shamilian",
                        "slug": "J.-H.-Shamilian",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shamilian",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Shamilian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1394247998"
                        ],
                        "name": "T. Wood",
                        "slug": "T.-Wood",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Wood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wood"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 60
                            }
                        ],
                        "text": "Ferguson (1997) Kornfeld and Wattecamps (1998) Hurst (2000) Shamillian et al. (1997)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 4
                            }
                        ],
                        "text": "(I) Shamillian et al. (1997). Again a model based system, where the black pixel distribution of each line in the document is compared against the user-supplied table line."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 4
                            }
                        ],
                        "text": "(I) Shamillian et al. (1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 4
                            }
                        ],
                        "text": "(I) Shamillian et al. (1997). In the user supplied model table-row, column delimiters are found in the white space gaps; these delimiters are then applied to the table."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206775234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ad7b7fe1c5e346b1cb9034af4fa18b5afe4d45e",
            "isKey": true,
            "numCitedBy": 55,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles. In these tables, textual data are presented in record lines made up of fixed-width fields. Tables often do not rely on line-art (ruled lines) to delimit fields, and in this way differ crucially from fixed forms. Our system performs these steps: copes with multiple tables per page; identifies records within tables; segments records into fields; and recognizes characters within fields, constrained by field-specific contextual knowledge. Obstacles to good performance on tables include small print, tight line-spacing, poor-quality text (such as photocopies), and line-art or background patterns that touch the text. Precise skew-correction and pitch-estimation, and high-performance OCR using neural nets proved crucial in overcoming these obstacles. The most significant technical advances in this work appear to be algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts. This GUI has been ergonomically designed to make efficient and intuitive use of exemplary images, so that the skill and manual effort required to retarget the system to new table layouts are held to a minimum. The system has been applied in this way to more than 400 distinct tabular layouts. During the last three years the system has read over fifty million records with high accuracy."
            },
            "slug": "A-retargetable-table-reader-Shamilian-Baird",
            "title": {
                "fragments": [],
                "text": "A retargetable table reader"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles, and algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 159
                            }
                        ],
                        "text": "And all systems seen so far, which do not count on the presence of line-art or existing mark-up, fail to attribute to their rightful columns those cells which \u201cextent only spans a subset of the values that its interpretation must be applied to\u201d (Hurst (2003))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7630958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af42cc46f93bc9cf413770af4f7243f54a31336e",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. While techniques for evaluating the performance of lower-level document analysis tasks such as optical character recognition have gained acceptance in the literature, attempts to formalize the problem for higher-level algorithms, while receiving a fair amount of attention in terms of theory, have generally been less successful in practice, perhaps owing to their complexity. In this paper, we introduce intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition. We also present the results of several small experiments, demonstrating how well the methodologies work and the useful sorts of feedback they provide. We first consider the table detection problem. Here algorithms can yield various classes of errors, including non-table regions improperly labeled as tables (insertion errors), tables missed completely (deletion errors), larger tables broken into a number of smaller ones (splitting errors), and groups of smaller tables combined to form larger ones (merging errors). This leads naturally to the use of an edit distance approach for assessing the results of table detection. Next we address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, \u201cgraph probing,\u201d for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks as well."
            },
            "slug": "Evaluating-the-performance-of-table-processing-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Evaluating the performance of table processing algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition are introduced and a new paradigm, \u201cgraph probing,\u201d is described for comparing the results returned by the recognition system and the representation created during ground-truthing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2291388"
                        ],
                        "name": "J. Wnek",
                        "slug": "J.-Wnek",
                        "structuredName": {
                            "firstName": "Janusz",
                            "lastName": "Wnek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wnek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299868"
                        ],
                        "name": "R. Price",
                        "slug": "R.-Price",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Price"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29755962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bc245c2ce76f44908821eef66b990f9bb91cdad",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Intelligent document understanding (IDU) systems convert scanned document pages into an electronic format which preserves layout and logical document structure in addition to document content. MOst of the IDU experimental systems, however, lack the capability of full exploitation of recognition results. In this paper we present an integrated IDU system that processes documents all the way from recognition to full utilization using standard generalized markup language (SGML). The standardization and widespread use of SGML-based tools provides the means for filling the gap between document recognition and seamless document reuse. The conversion process involves OCR of a multipage document, document structure analysis, processing of tabular data and mathematical expressions, and generation of the final SGML description. Document structure analysis is reduce here to parsing OCR results and recreating document structure by performing fuzzy searches for standard phrases and format analysis. Tabular data processing utilizes OCR results with positional data, horizontal lines and heuristic rules to determine cell boundaries and contents. Recognition of mathematical expressions involves OCR on an extended symbol set, and equation structure recognition via transformations on a tree representation. The transformations are ordered and involve connecting of separated symbols, context-sensitive OCR correction, extraction of horizontally aligned subexpressions, subscript and superscript processing, and a general processing of symbols detected above or below the target symbol."
            },
            "slug": "Automated-conversion-of-structured-documents-into-Wnek-Price",
            "title": {
                "fragments": [],
                "text": "Automated conversion of structured documents into SGML"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An integrated IDU system that processes documents all the way from recognition to full utilization using standard generalized markup language (SGML), the means for filling the gap between document recognition and seamless document reuse."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Hu et al. (2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(Douglas usa semantic analysis \u2013 po\u0302r cruz)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Hu et al. (2001) assume the left most column in the table is a header."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 160
                            }
                        ],
                        "text": "Evaluation: recall and precision based on databasetype queries aimed at asserting the quality of the derived structural model of the table, similar to proposed Hu et al. (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 151
                            }
                        ],
                        "text": "The Table 3 below presents a classification of the functional analysis methods outlined above in terms of: the type of indicia taken into account and the method used to reach a decision."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As demonstrated in these works, a simple heuristic approach is sufficient to guarantee very good results in this task."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 148
                            }
                        ],
                        "text": "There are examples of tablelike portions of documents that different users might classify differently (e.g. EDP\u2019s organizational chart in Figure 2); Hu et al. (2001b) provide several cases where \u201cthere is significant disagreement between ground-truthers\u201d and explore the reasons for it."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Hu et al. (2001) also proposed an evaluation model that is resistant to the difficulties in ground-truthing tables and that can be used on other the other table related tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 4
                            }
                        ],
                        "text": "(T) Hu et al. (2001)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 41490827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e9383c894019f34e8cd77b68b89af5c1d42c7e9",
            "isKey": true,
            "numCitedBy": 71,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are an important means for communicating information in written media, and understanding such tables is a challenging problem in document layout analysis. In this paper we describe a general solution to the problem of recognizing the structure of a detected table region. First hierarchial clustering is used to identify columns and then spatial and lexical criteria to classify headers. We also address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, 'random graph probing,' for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "slug": "Table-structure-recognition-and-its-evaluation-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Table structure recognition and its evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new paradigm, 'random graph probing,' is described for comparing the results returned by the recognition system and the representation created during ground-truthing, which could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772839"
                        ],
                        "name": "A. Jorge",
                        "slug": "A.-Jorge",
                        "structuredName": {
                            "firstName": "Al\u00edpio",
                            "lastName": "Jorge",
                            "middleNames": [
                                "M\u00e1rio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jorge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66444903"
                        ],
                        "name": "L. Torgo",
                        "slug": "L.-Torgo",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Torgo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Torgo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 157
                            }
                        ],
                        "text": "Aiming at information extraction, Ferguson (1998) takes those measurements on the number of tables that are properly handled by their extraction system; and Silva et al. (2003) on the number of lines that belong to those tables holding the information to be extracted."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 150
                            }
                        ],
                        "text": "\u2026pdf, ASCII, or OCR output) containing several graphical elements, including charts and organizational charts, detects within it the existing tables (Silva et al. 2003), segments these into cells, distinguishes the cells that describe the content of the table and relates them to those that contain\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 25
                            }
                        ],
                        "text": "It has been detailed in (Silva et al (2003b))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9081075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "862c8302d3ef971934d17843873fd300046b3669",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The information contained in companies\u2019 financial statements is valuable to several users. Much of the relevant information in such documents is contained in tables and is currently mainly extracted by hand. We propose a method that accomplishes a prior step of the task of automatically extracting information from tables in documents: selecting the lines that are likely to belong to tables. Our method has been developed by empirically analyzing a set of Portuguese companies\u2019 financial statements using statistical and data mining techniques. Empirical evaluation indicates that more than 99% of table lines are selected after discarding at least 50% of all lines. The method can cope with the complexity of styles used in assembling information on paper and adapt its performance accordingly, thus maximizing its results."
            },
            "slug": "Automatic-Selection-of-Table-Areas-in-Documents-for-Silva-Jorge",
            "title": {
                "fragments": [],
                "text": "Automatic Selection of Table Areas in Documents for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A method that accomplishes a prior step of the task of automatically extracting information from tables in documents: selecting the lines that are likely to belong to tables by evaluating a set of Portuguese companies\u2019 financial statements."
            },
            "venue": {
                "fragments": [],
                "text": "EPIA"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35155791"
                        ],
                        "name": "William A. Kornfeld",
                        "slug": "William-A.-Kornfeld",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Kornfeld",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William A. Kornfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152697317"
                        ],
                        "name": "J. Wattecamps",
                        "slug": "J.-Wattecamps",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wattecamps",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wattecamps"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10974046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "675519b637ca69534a7ffd8829f05ce774885e26",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Information retrieval of ASCLI documents generally refers to retrieval based on linear patterns found in the source documents. We have developed a method for recognizing and extracting tabular data, inthis case financial tables. Tables are extracted using a version of the LR(k) parsing algorithm adapted for this purpose. Because of sloppiness in the construction of tables, somewhat less than 100% of the tables can be retrieved automatically; a method has been found to integrate the parsing algorithm into amodule analogous to a programming language debugger that allows operators to quickly correct defects in the source document. This paper describes an application in commercial use."
            },
            "slug": "Automatically-locating,-extracting-and-analyzing-Kornfeld-Wattecamps",
            "title": {
                "fragments": [],
                "text": "Automatically locating, extracting and analyzing tabular data"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A method has been found to integrate the parsing algorithm into amodule analogous to a programming language debugger that allows operators to quickly correct defects in the source document."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 4
                            }
                        ],
                        "text": "(H) Wang and Hu (2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We will also analyse intra block consistency in terms of relative location and alignment, as Rammel (2003) does, but also the content type and content length as Wang and Hu [ 49 ] do. These intra-consistency measurements will be presented to a classifier that will determine for each block how likely it is that it is a true table block."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "these measures, we cannot take them over the overall detected table (this risk is mostly absent in Wang and Hu [ 49 ] HTML inputs)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Different learning algorithms were tested, namely Naive\u2013Bayes, Maximum Entropy Classifier, a decision tree built by the C45 algorithm and the Winnow classifier, the latest having achieved better performance. (H) Wang and Hu [ 49 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Wang and Hu [ 49 ] measured the consistency of the columns and rows of each table in terms of: the content type of each cell (numerical, date, alphabetical or other) and the content length; they also considered the average and standard deviation of the number of filled in cells per row and column, to decide whether a candidate table area was a table or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2061833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d89945f77470b6a1dabd1f224f10b7d096fd9435",
            "isKey": true,
            "numCitedBy": 227,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a commonly used presentation scheme, especially for describing relational information. However, table understanding remains an open problem. In this paper, we consider the problem of table detection in web documents. Its potential applications include web mining, knowledge management, and web content summarization and delivery to narrow-bandwidth devices. We describe a machine learning based approach to classify each given table entity as either genuine or non-genuine. Various features reflecting the layout as well as content characteristics of tables are studied.In order to facilitate the training and evaluation of our table classifier, we designed a novel web document table ground truthing protocol and used it to build a large table ground truth database. The database consists of 1,393 HTML files collected from hundreds of different web sites and contains 11,477 leaf TABLE elements, out of which 1,740 are genuine tables. Experiments were conducted using the cross validation method and an F-measure of 95.89% was achieved."
            },
            "slug": "A-machine-learning-based-approach-for-table-on-the-Wang-Hu",
            "title": {
                "fragments": [],
                "text": "A machine learning based approach for table detection on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A machine learning based approach to classify each given table entity as either genuine or non-genuine, and designed a novel web document table ground truthing protocol and used it to build a large table ground truth database."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772839"
                        ],
                        "name": "A. Jorge",
                        "slug": "A.-Jorge",
                        "structuredName": {
                            "firstName": "Al\u00edpio",
                            "lastName": "Jorge",
                            "middleNames": [
                                "M\u00e1rio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jorge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66444903"
                        ],
                        "name": "L. Torgo",
                        "slug": "L.-Torgo",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Torgo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Torgo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 157
                            }
                        ],
                        "text": "Aiming at information extraction, Ferguson (1998) takes those measurements on the number of tables that are properly handled by their extraction system; and Silva et al. (2003) on the number of lines that belong to those tables holding the information to be extracted."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 150
                            }
                        ],
                        "text": "\u2026pdf, ASCII, or OCR output) containing several graphical elements, including charts and organizational charts, detects within it the existing tables (Silva et al. 2003), segments these into cells, distinguishes the cells that describe the content of the table and relates them to those that contain\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 25
                            }
                        ],
                        "text": "It has been detailed in (Silva et al (2003b))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17729940,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c379a594600b94bf02d2df81450f00b582c210a",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Information contained in companies\u2019 financial statements is valuable to support a variety of decisions. In such documents, much of the relevant information is contained in tables and is extracted mainly by hand. We propose a method that accomplishes a preliminary step of the task of automatically extracting information from tables in documents: selecting the lines which are likely to belong to the tables containing the information to be extracted. Our method has been developed by empirically analysing a set of Portuguese companies\u2019 financial statements, using statistical and data mining techniques. Empirical evaluation indicates that more than 99% of the table lines are selected after discarding at least 50% of them. The method can cope with the complexity of styles used in assembling information on paper and adapt its performance accordingly, thus maximizing its results."
            },
            "slug": "Selection-of-Table-Areas-for-Information-Extraction-Silva-Jorge",
            "title": {
                "fragments": [],
                "text": "Selection of Table Areas for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method that accomplishes a preliminary step of the task of automatically extracting information from tables in documents: selecting the lines which are likely to belong to the tables containing the information to be extracted."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145329865"
                        ],
                        "name": "Minoru Yoshida",
                        "slug": "Minoru-Yoshida",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Yoshida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minoru Yoshida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768754"
                        ],
                        "name": "Kentaro Torisawa",
                        "slug": "Kentaro-Torisawa",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Torisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kentaro Torisawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737901"
                        ],
                        "name": "Junichi Tsujii",
                        "slug": "Junichi-Tsujii",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Tsujii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junichi Tsujii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15867784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2985934cf5161c1fb6cecc8728dbd155cb6d278a",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web (WWW) allows a person to access a great amount of data provided by a wide variety of entities. However, the content varies widely in expression. This makes it difficult to browse many pages effectively, even if the contents of the pages are quite similar. This study is the first step toward the reduction of such variety of WWW contents. The method proposed in this paper enables us to easily obtain information about similar objects scattered over the WWW. We focus on the tables contained in the WWW pages and propose a method to integrate them according to the category of objects presented in each table. The table integrated in a uniform format enables us to easily compare the objects of different locations and styles of expressions."
            },
            "slug": "A-method-to-integrate-tables-of-the-World-Wide-Web-Yoshida-Torisawa",
            "title": {
                "fragments": [],
                "text": "A method to integrate tables of the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This study focuses on the tables contained in the WWW pages and proposes a method to integrate them according to the category of objects presented in each table, which enables us to easily compare the objects of different locations and styles of expressions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944286"
                        ],
                        "name": "D. Rus",
                        "slug": "D.-Rus",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Rus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34736316"
                        ],
                        "name": "K. Summers",
                        "slug": "K.-Summers",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Summers",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Summers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60453794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "283fbac96fc1f7460a5f8105c6afae6835807883",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present and analyze efficient algorithms for the automated recognition and interpretation of layout structures in electronic documents. The key idea is to use the patterns in the distribution of white space in a document to recognize and interpret its components. The recognition algorithm divides the document into a hierarchy of logical elements; the interpretation algorithms classify these divisions as base-text, tables, indented lists, polygonal drawings, and graphs. We present experimental data and discuss an information access application. Our methodology allows the automatic markup of documents\\footnote{For instance in the SGML format} and the creation of multi-level indices and browsing tools for electronic libraries."
            },
            "slug": "Using-White-Space-for-Automated-Document-Rus-Summers",
            "title": {
                "fragments": [],
                "text": "Using White Space for Automated Document Structuring"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The key idea is to use the patterns in the distribution of white space in a document to recognize and interpret its components to allow the automatic markup of documents and the creation of multi-level indices and browsing tools for electronic libraries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135000"
                        ],
                        "name": "Claudia Wenzel",
                        "slug": "Claudia-Wenzel",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Wenzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claudia Wenzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3314853"
                        ],
                        "name": "Wolfgang Tersteegen",
                        "slug": "Wolfgang-Tersteegen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Tersteegen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Tersteegen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13833989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9a7b1c80b1c7d20a4c1c2a30d87f5a6c6ab169e",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The ScanTab system represents a knowledge-based approach to table recognition in scanned documents. In contrast to most systems which recognize tables by grouping layout information, our system uses predefined information about which table types may appear in the documents. This enables a very accurate detection able to cope with distorted tables and tables providing little layout information, e.g., no lines, bad alignment, or few rows. Table recognition starts with the detection of the table header. Afterwards, this header is compared with table headers of known reference tables. Having determined the correct reference table, the information kept in the knowledge base is utilized to compute the complete table structure. A graphical user interface allows an easy and fast specification of reference tables."
            },
            "slug": "Precise-Table-Recognition-by-Making-Use-of-Tables-Wenzel-Tersteegen",
            "title": {
                "fragments": [],
                "text": "Precise Table Recognition by Making Use of Reference Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The ScanTab system represents a knowledge-based approach to table recognition in scanned documents that enables a very accurate detection able to cope with distorted tables and tables providing little layout information, e.g., no lines, bad alignment, or few rows."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3314853"
                        ],
                        "name": "Wolfgang Tersteegen",
                        "slug": "Wolfgang-Tersteegen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Tersteegen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Tersteegen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 184
                            }
                        ],
                        "text": "We will also adapt this step to characterize column alignment by measuring the percentage of cells that share beginning, middle or end position (a metric similar to the one applied by Tersteegen and Wenzel (1998))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As demonstrated in these works, a simple heuristic approach is sufficient to guarantee very good results in this task."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Tersteegen and Wenzel (1998) begin by segmenting German business letters into non-text and text regions and these are presented to an OCR."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 4
                            }
                        ],
                        "text": "(I) Tersteegen and Wenzel (1998) present an interesting exception to the traditional independence of the five table related tasks \u2013 functional analysis precedes the location algorithm to locate table headers within the document (see section 3.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 4
                            }
                        ],
                        "text": "(I) Tersteegen and Wenzel (1998)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16393808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e7ae10037c80c0b3b12cecba0e3ce6d676ca26f",
            "isKey": true,
            "numCitedBy": 11,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The ScanTab system represents a knowledge-based approach to table recognition in scanned documents. In contrast to most systems which recognize tables by grouping layout information, our system uses predefined information about which table types may appear. This enables a very accurate detection able to cope with distorted tables and tables providing little layout information, e.g., no lines, bad alignment, or few rows. Table recognition starts with the detection of the table header. Afterwards, this header is compared with table headers of known reference tables. Having determined the correct reference table, the information kept in the knowledge base is utilized to compute the complete table structure. A graphical user interface allows an easy and fast specification of reference tables."
            },
            "slug": "SCANTAB:-TABLE-RECOGNITION-BY-REFERENCE-TABLES-Tersteegen",
            "title": {
                "fragments": [],
                "text": "SCANTAB: TABLE RECOGNITION BY REFERENCE TABLES"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The ScanTab system represents a knowledge-based approach to table recognition in scanned documents that enables a very accurate detection able to cope with distorted tables and tables providing little layout information, e.g., no lines, bad alignment, or few rows."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122689890"
                        ],
                        "name": "Lee S. Jensen",
                        "slug": "Lee-S.-Jensen",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Jensen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lee S. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Chen et al. (2000)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 198
                            }
                        ],
                        "text": "\u2026table\u2019s physical model: Pyreddi and Croft\u2019s (1997) measured them in terms of the number of lines correctly tagged; Wang et al. (2000-2002) took the same measurements on cells; Tupaj et al (1996) and Chen et al (2000) consider full tables as well; and Ng et al (1999) take full table, column and row."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 4
                            }
                        ],
                        "text": "(H) Chen et al. (2000)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2313483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0909fee90833e20913adb553bf6667c9a3b854b0",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A program that makes an existing website look like a database is called a wrapper. Wrapper learning is the problem of learning website wrappers from examples. We present a wrapper-learning system called WL2 that can exploit several different representations of a document. Examples of such different representations include DOM-level and token-level representations, as well as two-dimensional geometric views of the rendered page (for tabular data) and representations of the visual appearance of text asm it will be rendered. Additionally, the learning system is modular, and can be easily adapted to new domains and tasks. The learning system described is part of an \"industrial-strength\" wrapper management system that is in active use at WhizBang Labs. Controlled experiments show that the learner has broader coverage and a faster learning rate than earlier wrapper-learning systems."
            },
            "slug": "A-flexible-learning-system-for-wrapping-tables-and-Cohen-Hurst",
            "title": {
                "fragments": [],
                "text": "A flexible learning system for wrapping tables and lists in HTML documents"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A wrapper-learning system called WL2 that can exploit several different representations of a document, including DOM-level and token-level representations, as well as two-dimensional geometric views of the rendered page and representations of the visual appearance of text asm it will be rendered."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768769"
                        ],
                        "name": "F. Cesarini",
                        "slug": "F.-Cesarini",
                        "structuredName": {
                            "firstName": "Francesca",
                            "lastName": "Cesarini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cesarini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285734"
                        ],
                        "name": "S. Marinai",
                        "slug": "S.-Marinai",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Marinai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marinai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608269"
                        ],
                        "name": "L. Sarti",
                        "slug": "L.-Sarti",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Sarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Both measures are positively correlated with the total areas that iss correctly identified as tables and negatively correlated with the total area of non-tables that is identified."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 87
                            }
                        ],
                        "text": "Apart from these more standard measurements, to evaluate location Hu et al. (2000) and Cesarini et al.\n(2002) take \u201ca measure of the similarity of two documents (the recognised document and its ground truth) in terms of their table structure\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 4
                            }
                        ],
                        "text": "(I) Cesarini et al. (2002) have created a table location method that finds tables within a common output of document image analysis systems, an X-Y tree, specifically they work from a Modified X-Y tree they had developed in previous research."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1551166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56d3298d06b3eb5d479b33d8d9e59eff774965f4",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach for table location in document images. The documents are described by means of a hierarchical representation that is based on the MXY tree. The presence of a table is hypothesized by searching parallel lines in the MXY tree of the page. This hypothesis is afterwards verified by locating perpendicular lines or white spaces in the region included between the parallel lines. Lastly, located tables can be merged on the basis of proximity and similarity criteria. The use of an optimization method, that relies on the definition of an appropriate table location index, allows us to identify, the optimal values of thresholds involved in the algorithm. In this way the algorithm can be adapted to recognize tables with different features by maximizing the performance on an appropriate training set. The algorithm has been evaluated on two data-sets containing more than 1500 pages, and comparing its results with the tables identified by two commercial OCRs."
            },
            "slug": "Trainable-table-location-in-document-images-Cesarini-Marinai",
            "title": {
                "fragments": [],
                "text": "Trainable table location in document images"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An approach for table location in document images is described by means of a hierarchical representation that is based on the MXY tree and the use of an optimization method allows us to identify the optimal values of thresholds involved in the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Wang et al. (2002) propose to combine three measures that are similar to Hu et al\u2019s by weighing them by the costs of the errors made in the graphical, functional and physical models of the table."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3331857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc8d85dec47348c81d894ff9ea729b28aef88650",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we define the table detection problem as a probability optimization problem. We begin, as we do in our previous algorithm, finding and validating each detected table candidates. We proceed to compute a set of probability measurements for each of the table entities. The computation of the probability measurements takes into consideration tables, table text separators and table neighboring text blocks. Then, an iterative updating method is used to optimize the page segmentation probability to obtain the final result. This new algorithm shows a great improvement over our previous algorithm. The training and testing data set for the algorithm include 1, 125 document pages having 518 table entities and a total of 10, 934 cell entities. Compared with our previous work, it raised the accuracy rate to 95.67% from 90.32% and to 97.05% from 92.04%."
            },
            "slug": "Table-Detection-via-Probability-Optimization-Wang-Phillips",
            "title": {
                "fragments": [],
                "text": "Table Detection via Probability Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper defines the table detection problem as a probability optimization problem, and proceeds to compute a set of probability measurements for each of the table entities, taking into consideration tables, table text separators and table neighboring text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3216372"
                        ],
                        "name": "Chung Yong Lim",
                        "slug": "Chung-Yong-Lim",
                        "structuredName": {
                            "firstName": "Chung",
                            "lastName": "Lim",
                            "middleNames": [
                                "Yong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung Yong Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054350109"
                        ],
                        "name": "Jessica Li Teng Koo",
                        "slug": "Jessica-Li-Teng-Koo",
                        "structuredName": {
                            "firstName": "Jessica",
                            "lastName": "Koo",
                            "middleNames": [
                                "Li",
                                "Teng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jessica Li Teng Koo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 52
                            }
                        ],
                        "text": "In (2003) the author aims at aggregating these cells into columns and rows."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 249
                            }
                        ],
                        "text": "\u2026table\u2019s physical model: Pyreddi and Croft\u2019s (1997) measured them in terms of the number of lines correctly tagged; Wang et al. (2000-2002) took the same measurements on cells; Tupaj et al (1996) and Chen et al (2000) consider full tables as well; and Ng et al (1999) take full table, column and row."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 7
                            }
                        ],
                        "text": "The same is applied to columns."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16206198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d937270157cabb23288ce6a948275f4aeeaa827",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real-world texts contain tables. In order to process these texts correctly and extract the information contained within the tables, it is important to identify the presence and structure of tables. In this paper, we present a new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables. When tested on Wall Street Journal news documents, our learning approach outperforms a deterministic table recognition algorithm that identifies table recognition algorithm that identifies tables based on a fixed set of conditions. Our learning approach is also more flexible and easily adaptable to texts in different domains with different table characteristics."
            },
            "slug": "Learning-to-Recognize-Tables-in-Free-Text-Ng-Lim",
            "title": {
                "fragments": [],
                "text": "Learning to Recognize Tables in Free Text"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables, outperforms a deterministic table recognition algorithm that identifies tables based on a fixed set of conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(Douglas usa semantic analysis \u2013 po\u0302r cruz)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 4
                            }
                        ],
                        "text": "(I) Wang et al. (2001)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 628973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd7e243fb7041c582a479116a11126904f2be010",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We first describe an automatic table ground truth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms. Then a novel background analysis-based, coarse-to-fine table identification algorithm and an X-Y cut table decomposition algorithm are described. We discuss an experimental protocol to evaluate the table detection algorithms. For a total of 1,125 document pages having 518 table entities and a total of 10,941 cell entities, our table detection algorithm takes line, word segmentation results as input and obtains around 90% cell correct detection rates."
            },
            "slug": "Automatic-table-ground-truth-generation-and-a-table-Wang-Haralick",
            "title": {
                "fragments": [],
                "text": "Automatic table ground truth generation and a background-analysis-based table structure extraction method"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An automatic table groundtruth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms and an X-Y cut table decomposition algorithm are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153924342"
                        ],
                        "name": "Hsin-Hsi Chen",
                        "slug": "Hsin-Hsi-Chen",
                        "structuredName": {
                            "firstName": "Hsin-Hsi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsin-Hsi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072526610"
                        ],
                        "name": "Shih-Chung Tsai",
                        "slug": "Shih-Chung-Tsai",
                        "structuredName": {
                            "firstName": "Shih-Chung",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Chung Tsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949513"
                        ],
                        "name": "Jin-He Tsai",
                        "slug": "Jin-He-Tsai",
                        "structuredName": {
                            "firstName": "Jin-He",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin-He Tsai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6844025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "578c63514136ac5b9af0144bcfe06efcfdd3099c",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a very common presentation scheme, but few papers touch on table extraction in text data mining. This paper focuses on mining tables from large-scale HTML texts. Table filtering, recognition, interpretation, and presentation are discussed. Heuristic rules and cell similarities are employed to identify tables. The F-measure of table recognition is 86.50%. We also propose an algorithm to capture attribute-value relationships among table cells. Finally, more structured data is extracted and presented."
            },
            "slug": "Mining-Tables-from-Large-Scale-HTML-Texts-Chen-Tsai",
            "title": {
                "fragments": [],
                "text": "Mining Tables from Large Scale HTML Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper focuses on mining tables from large-scale HTML texts by using heuristic rules and cell similarities to identify tables and proposes an algorithm to capture attribute-value relationships among table cells."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "(Hurst, 2000)\nAfter the completion of the tasks outlined above, one knows how to read the information in the table, but one does not yet know what is being said (in the example of Figure 1, for instance, we already know that \u201clife\u201d, \u201cwild buckweat\u201d and \u201cannual\u201d have to be read conjointly, but we do\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2000) measures the results of functional analysis by computing performance and recall in the classification of attributes and data cells; because attribute cells are less common in tables but mistakes in their recognition are more serious, these two measures can be normalized with the weight\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 172
                            }
                        ],
                        "text": "Evaluation: precision and recall in terms of the total number of attribute cells and data cells accurately identified; these two measures may be normalised as suggested by Hurst (2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 20
                            }
                        ],
                        "text": "According to Mathew Hurst (2000), several models can be used to represent a table."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 142
                            }
                        ],
                        "text": "Identifying relationships: In the accounting tables that hold mostly numbers, of those types of relationships between the cells identified in Hurst (2000), the most common are:\n\u2013 partitive relationships, e.g. intangible assets are a part of assets \u2013 quantitative value relations, e.g. intangible\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2000)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2000) identifies two major interpretation steps (c.f. Table 4) that can be performed before interpretation becomes context-specific."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28689838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed11aa01933bb23a019129c44a35bc32b593e6cd",
            "isKey": true,
            "numCitedBy": 25,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to accurately detect those areas in plain text documents that consist of contiguous text is an important pre- process to many applications. This paper introduces a novel method that uses both spatial and linguistic knowledge in an accurate manner to provide an initial analysis of the document. This initial analysis may then be extended to provide a complete analysis of the text areas in the document."
            },
            "slug": "Layout-and-language:-an-efficient-algorithm-for-on-Hurst",
            "title": {
                "fragments": [],
                "text": "Layout and language: an efficient algorithm for detecting text blocks based on spatial and linguistic evidence"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper introduces a novel method that uses both spatial and linguistic knowledge in an accurate manner to provide an initial analysis of the document that may then be extended to provide a completeAnalysis of the text areas in the document."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Hu et al. (2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Hu et al. (2001) assume the left most column in the table is a header."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 160
                            }
                        ],
                        "text": "Evaluation: recall and precision based on databasetype queries aimed at asserting the quality of the derived structural model of the table, similar to proposed Hu et al. (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 148
                            }
                        ],
                        "text": "There are examples of tablelike portions of documents that different users might classify differently (e.g. EDP\u2019s organizational chart in Figure 2); Hu et al. (2001b) provide several cases where \u201cthere is significant disagreement between ground-truthers\u201d and explore the reasons for it."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Hu et al. (2001) also proposed an evaluation model that is resistant to the difficulties in ground-truthing tables and that can be used on other the other table related tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 4
                            }
                        ],
                        "text": "(T) Hu et al. (2001)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16106027,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "9e16dcd290d9ab780107270c666d71c00e569b22",
            "isKey": true,
            "numCitedBy": 95,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The principle that for every document analysis task there exists a mechanism for creating well-defined ground-truth is a widely held tenet. Past experience with standard datasets providing ground-truth for character recognition and page segmentation tasks supports this belief. In the process of attempting to evaluate several table recognition algorithms we have been developing, however, we have uncovered a number of serious hurdles connected with the ground-truthing of tables. This problem may, in fact, be much more difficult than it appears. We present a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "slug": "Why-table-ground-truthing-is-hard-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Why table ground-truthing is hard"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 144
                            }
                        ],
                        "text": "\u2026applied and is assessed through different means, although relative word position has become the most common, probably because they are the most appropriate for non-Manhattan tables; use of some sort\nof parameter is still common, but all are pre defined; application of data induced or\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 146
                            }
                        ],
                        "text": "\u2026taken at different levels of the table\u2019s physical model: Pyreddi and Croft\u2019s (1997) measured them in terms of the number of lines correctly tagged; Wang et al. (2000-2002) took the same measurements on cells; Tupaj et al (1996) and Chen et al (2000) consider full tables as well; and Ng et al\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3181078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c582c2971395c3957a4152956081bb52e78be259",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an improved zone content classification method. Motivated by our novel background-analysis-based table identification research, we added two new features to the feature vector from one previously published method [7]. The new features are the total area of large horizontal and large vertical blank blocks and the number of text glyphs in the zone. A binary decision tree is used to assign a zone class on the basis of its feature vector. The training and testing data sets for the algorithm include images drawn from the UWCDROM-III document image database. The classifier is able to classify each given scientific and technical document zone into one of the nine classes, text classes (of font size pt and font size pt), math, table, halftone, map/drawing, ruling, logo, and others. The improved zone classification method raised the accuracy rate to from and reduced the median false alarm rate to from . 1 Problem Statement Let ! be a set of zone entities. Let \" be a set of content labels, such as text, table, math, etc. The function #%$&!(')\" associates each element of * with a label. The function +,$-!.'0/ specifies measurements made on each element of ! , where / is the measurement space. The zone content classification problem can be formulated as follows: Given a zone set ! and a content label set \" , find a classification function #1$2!3'4\" , that has the maximum probability: 576 # 6 !98;: + 6 !98 8 (1) In our current approach, we assume conditional independence between the zone classifications, so the probability in Equation 1 may be decomposed as 576 # 6 !98;: + 6 !98 8= @ A B 576 # 6DC 8;: + 6DC 8 8 (2) The problem can be solved by maximizing each individual probability 576 # 6DC 8;: + 6DC 8 8 in Equation 2, where CFE ! . In our zone content classification experiment, the elements in set ! are zone groundtruth entities from UWCDROM III document image database [6]. The elements of set \" are text with font size GIH J pt, text with font size KLH M pt, math, table, halftone, map/drawing, ruling, logo, and others. + 6DC 8 is a feature vector generated for C , where CNE ! . We used a decision tree classifier to compute the probability in Equation 2 and make the assignment. 2 Related Work and Paper Organization A complete document image understanding system can transform paper documents into a hierarchical representation of their structure and content. The transformed document representation enables document interchange, editing, browsing, indexing, filing and retrieval. The zone classification technique plays the key role in the success of such a document understanding system. Not only is it useful for successive applications such as OCR, table understanding, etc, but it can be used to assist and validate document segmentation. In the literature, Sivaramakrishnan et. al [7] extracted features for each zone such as run length mean and variance, spatial mean and variance, fraction of the total number of black pixels in the zone, and the zone width ratio for each zone. They used the decision tree classifier to assign a zone class on the basis of its feature vector. They did their experiments on MPO M document images from UWCDROM I image database. Liang et. al [5] developed a feature based zone classifier using only the knowledge of the widths and the heights of the connected components within a given zone. Le et. al [4] proposed an automated labeling of zones from scanned images with labels such as titles, authors, affiliations and abstracts. The labeling is based on features calculated from optical character recognition(OCR) output, neural network models, machine learning methods, and a set of rules that is derived from an analysis of the page layout for each journal and from generic typesetting knowledge for English text. We developed a novel background-analysis-based table identification technique. We repeated Sivaramakrishnan et. al\u2019s work [7] on a larger database with a goal to improve its performance on table zone classification. Although some background analysis techniques can be found in the literature([1],[2]), none of them, to our knowledge, has been used in the table identification problem. We added two new features: the total area of large horizontal and vertical blank blocks and the number of text glyphs in the given zone, to the original feature vector. We improved the accuracy rate and reduced the false alarm rates for most of the nine classes. The rest of this paper is divided into Q sections. section 3 gives the definitions of large horizontal and large vertical blank blocks. The two new features are described in section 4. A brief introduction to the decision tree classifier is given in section 5. The experimental results are reported in section 6. Our conclusion and statement of future work are discussed in section 7."
            },
            "slug": "IMPROVEMENT-OF-ZONE-CONTENT-CLASSIFICATION-BY-USING-Wang-Phillips",
            "title": {
                "fragments": [],
                "text": "IMPROVEMENT OF ZONE CONTENT CLASSIFICATION BY USING BACKGROUND ANALYSIS"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The improved zone content classification method raised the accuracy rate and reduced the median false alarm rate and the total area of large horizontal and large vertical blank blocks and the number of text glyphs in the zone."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35074265"
                        ],
                        "name": "J. Handley",
                        "slug": "J.-Handley",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Handley",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Handley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 4
                            }
                        ],
                        "text": "(I) Green and Krishnamoorthy (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 0
                            }
                        ],
                        "text": "Green and Krishnamoorthy (1995)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 31720553,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c730e6636e4245e2e282725d3c62a307e442eb02",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A table in a document is a rectilinear arrangement of cells where each cell contains a sequence of words. Several lines of text may compose one cell. Cells may be delimited by horizontal or vertical lines, but often this is not the case. A table analysis system is described which reconstructs table formatting information from table images whether or not the cells are explicitly delimited. Inputs to the system are word bounding boxes and any horizontal and vertical lines that delimit cells. Using a sequence of carefully-crafted rules, multi-line cells and their interrelationships are found even though no explicit delimiters are visible. This robust system is a component of a commercial document recognition system."
            },
            "slug": "Table-analysis-for-multiline-cell-identification-Handley",
            "title": {
                "fragments": [],
                "text": "Table analysis for multiline cell identification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A table analysis system is described which reconstructs table formatting information from table images whether or not the cells are explicitly delimited, and is a component of a commercial document recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793699"
                        ],
                        "name": "R. Zanibbi",
                        "slug": "R.-Zanibbi",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zanibbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zanibbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683822"
                        ],
                        "name": "J. Cordy",
                        "slug": "J.-Cordy",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cordy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cordy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 4
                            }
                        ],
                        "text": "(H) Wang and Hu (2002)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14319498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6e4c5aa32fd8180d336ce2b6ea8bf3194678636",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 102,
            "paperAbstract": {
                "fragments": [],
                "text": "Table characteristics vary widely. Consequently, a great variety of computational approaches have been applied to table recognition. In this survey, the table recognition literature is presented as an interaction of table models, observations, transformations and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables, and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup, transformations alter or restructure data, and inferences generate and test hypotheses. This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "slug": "A-Survey-of-Table-Recognition-:-Models-,-,-,-and-Zanibbi-Blostein",
            "title": {
                "fragments": [],
                "text": "A Survey of Table Recognition : Models , Observations , Transformations , and Inferences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793699"
                        ],
                        "name": "R. Zanibbi",
                        "slug": "R.-Zanibbi",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zanibbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zanibbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683822"
                        ],
                        "name": "J. Cordy",
                        "slug": "J.-Cordy",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cordy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cordy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42236309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c92be1e0a4ecb0c0ee28aa7da9ec0a39611e5bc",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.Table characteristics vary widely. Consequently, a great variety of computational approaches have been applied to table recognition. In this survey, the table recognition literature is presented as an interaction of table models, observations, transformations, and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup, transformations alter or restructure data, and inferences generate and test hypotheses. This presentation clarifies both the decisions made by a table recognizer and the assumptions and inferencing techniques that underlie these decisions."
            },
            "slug": "A-survey-of-table-recognition-Zanibbi-Blostein",
            "title": {
                "fragments": [],
                "text": "A survey of table recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This presentation clarifies both the decisions made by a table recognizer and the assumptions and inferencing techniques that underlie these decisions."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis and Recognition"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118129669"
                        ],
                        "name": "Ana Costa e Silva",
                        "slug": "Ana-Costa-e-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Costa e Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31492660"
                        ],
                        "name": "M. B. Ramos",
                        "slug": "M.-B.-Ramos",
                        "structuredName": {
                            "firstName": "Margarida",
                            "lastName": "Ramos",
                            "middleNames": [
                                "Brites"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. B. Ramos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 270
                            }
                        ],
                        "text": "We aim this interpretation to take into account the specificities of the national accounting environment of each country and hope to adapt XBRL (eXtensible Business Reporting Language) jurisdictional taxonomies as a plug in-plug out source of this accounting knowledge (Silva et al. 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16220136,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "8a0448735089e51e2eea6d3136ea04a808fd66f0",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Banco de Portugal (BdP) produces statistics to allow an in-depth understanding of the Portuguese economical situation and to comply with international requirements. With this purpose, the BdP collects high amounts of detailed data from a wide array of institutions, much of which derives from their accounting systems. The quality of this process is improved through the use of standard means of reporting. After providing a brief history of the reporting standards utilized by the BdP over time, we look into how XML allowed a great improvement over preceding standards. Finally, we identify an area within the BdP?s reporting standards that needs improvement, that by non-financial corporations, and elaborate on how an XBRL-based reporting standard might best be implemented in Portugal. Given the increasing level of accounting internationalisation, the question can hardly be kept within national boundaries, so our favoured approach is inserted into a European and a Global strategy."
            },
            "slug": "Reporting-standards-for-statistical-purposes:-the-Silva-Ramos",
            "title": {
                "fragments": [],
                "text": "Reporting standards for statistical purposes: the experience of Banco de Portugal"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736334"
                        ],
                        "name": "A. Buchsbaum",
                        "slug": "A.-Buchsbaum",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Buchsbaum",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buchsbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40433852"
                        ],
                        "name": "D. Caldwell",
                        "slug": "D.-Caldwell",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Caldwell",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Caldwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48078658"
                        ],
                        "name": "G. Fowler",
                        "slug": "G.-Fowler",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Fowler",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Fowler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144963537"
                        ],
                        "name": "S. Muthukrishnan",
                        "slug": "S.-Muthukrishnan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Muthukrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muthukrishnan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7461751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10ae2d947b79c09585cf9abe18c4404adf03631d",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of compressing massive tables. We devise a novel compression paradigm\u2014training for lossless compression\u2014 which assumes that the data exhibit dependencies that can be learned by examining a small amount of training material. We develop an experimental methodology to test the approach. Our result is a system, pzip, which outperforms gzip by factors of two in compression size and both compression and uncompression time for various tabular data. Pzip is now in production use in an AT&T network traffic data warehouse."
            },
            "slug": "Engineering-the-compression-of-massive-tables:-an-Buchsbaum-Caldwell",
            "title": {
                "fragments": [],
                "text": "Engineering the compression of massive tables: an experimental approach"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel compression paradigm is devised\u2014training for lossless compression\u2014 which assumes that the data exhibit dependencies that can be learned by examining a small amount of training material, and which outperforms gzip in compression size and both compression and uncompression time for various tabular data."
            },
            "venue": {
                "fragments": [],
                "text": "SODA '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(Douglas usa semantic analysis \u2013 po\u0302r cruz)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 143
                            }
                        ],
                        "text": "\u2026aligned because of the editing environments the tables were produced in, we will allow different tolerance in assigning cells to columns than Hurst (2003) did: we will be more tolerant when a narrow cell is vertically aligned with only one cell above or below it (i.e. narrow cells will be\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 142
                            }
                        ],
                        "text": "Evaluation: we will measure our ability to group cells in one same column using both precision and recall both at cell level, as suggested by Hurst (2003), and at column level, by measuring recall and precision on the total number of proto-links crossing the whole table that were correctly\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 225
                            }
                        ],
                        "text": "For example an ASCII input does not hold any tags pointing to potential tables or differences in font size to hint concept hierarchy; and even if it is OCR error free, it is subject to other ambiguities such as misalignment (Hurst 2003); as such, it can be considered a poorer input type."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 22
                            }
                        ],
                        "text": "An exception would be Hurst (2001, 2003)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 39
                            }
                        ],
                        "text": "Take the Table 5 that was presented in Hurst (2003): there are 16 rows and 6 columns, however 5 rows contain only one cell, i.e. 17 link threads traverse the table and this is our ground-truth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hurst (2003) proposes a new element on which to take these measurements for evaluating the quality of column and line identification within the physical model of the table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 244
                            }
                        ],
                        "text": "And all systems seen so far, which do not count on the presence of line-art or existing mark-up, fail to attribute to their rightful columns those cells which \u201cextent only spans a subset of the values that its interpretation must be applied to\u201d (Hurst (2003))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1649340,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a7be096a4ed48b143691bdd2deeae585afebc4d6",
            "isKey": true,
            "numCitedBy": 25,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an approach to deriving an abstractgeometric model of a table from a physical representation.The technique developed uses a graph of constraints betweencells which must be satisfied in order to determinetheir relative horizontal and vertical position. The methodis evaluated with a test set of tables drawn from US Securitiesand Exchange Commission (SEC) filings."
            },
            "slug": "A-constraint-based-approach-to-table-structure-Hurst",
            "title": {
                "fragments": [],
                "text": "A constraint-based approach to table structure derivation"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An approach to deriving an abstractgeometric model of a table from a physical representation using a graph of constraints which must be satisfied in order to determinate the relative horizontal and vertical position."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 186
                            }
                        ],
                        "text": "There are several methods to doing this string matching; as in the future we may wish to apply OCR on paper documents and spelling mistakes do occur, an error resistant method, of which Lopresti and Wilfong (1999) is an example, will be preferable."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 904873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fc7342a2cf207cc7a237aca7a53913d845d7177",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Approximate string matching is an important paradigm in domains ranging from speech recognition to information retrieval and molecular biology. We introduce a new formalism for a class of applications that takes two strings as input, each specified in terms of a particular domain, and performs a comparison motivated by constraints derived from a third, possibly different domain. This issue arises, for example, when searching multimedia databases built using imperfect recognition technologies (e.g., speech, optical character, and handwriting recognition). We present a polynomial time algorithm for solving the problem, and describe several variations that can also be solved efficiently."
            },
            "slug": "Cross-domain-approximate-string-matching-Lopresti-Wilfong",
            "title": {
                "fragments": [],
                "text": "Cross-domain approximate string matching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work introduces a new formalism for a class of applications that takes two strings as input, each specified in terms of a particular domain, and performs a comparison motivated by constraints derived from a third, possibly different domain."
            },
            "venue": {
                "fragments": [],
                "text": "6th International Symposium on String Processing and Information Retrieval. 5th International Workshop on Groupware (Cat. No.PR00268)"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 0
                            }
                        ],
                        "text": "Green and Krishnamoorthy (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "Unlike Green and Krishnamoorthy\u2019s method [12], which allows detection of any table surrounded by the specified delimiter, this method only finds tables with a fixed number of columns and predetermined field length."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 4
                            }
                        ],
                        "text": "(I) Green and Krishnamoorthy (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 7
                            }
                        ],
                        "text": "Unlike Green and Krishnamoorthy\u2019s method, which allows detection of any table surrounded by the specified delimiter, this method only finds tables with a fixed number of columns and predetermined field length."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "(Format of input documents is I) Green and Krishnamoorthy [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-based of printed tables"
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of International Conference of Document Analysis and Recognition 95 (ICDAR95), pp. 214\u2013217. Montreal, Canada,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 0
                            }
                        ],
                        "text": "Green and Krishnamoorthy (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "Unlike Green and Krishnamoorthy\u2019s method [12], which allows detection of any table surrounded by the specified delimiter, this method only finds tables with a fixed number of columns and predetermined field length."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 4
                            }
                        ],
                        "text": "(I) Green and Krishnamoorthy (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 7
                            }
                        ],
                        "text": "Unlike Green and Krishnamoorthy\u2019s method, which allows detection of any table surrounded by the specified delimiter, this method only finds tables with a fixed number of columns and predetermined field length."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "(Format of input documents is I) Green and Krishnamoorthy [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-based of printed tables"
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of International Conference of Document Analysis and Recognition 95 (ICDAR95), pp. 214\u2013217. Montreal, Canada,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 4
                            }
                        ],
                        "text": "(X) Ferguson (1997) analyses column header rows to determine approximate column boundaries, thereafter extracting each line until the end of the table is detected."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "However, it will not detect tables with spanning cells or table lines where only one table column is filled in.\n(X) Ferguson (1997) and Kornfeld and Wattecamps (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 94
                            }
                        ],
                        "text": "On the other hand, notice that the steps mentioned above are different from those outlined by Ferguson (1997) and Kornfeld and Wattecamps (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 207
                            }
                        ],
                        "text": "The currency thus obtained will be tested: arithmetic relations among items of different tables will be verified and the coherence of certain ratios will be accompanied (in a way similar to that outlined by Ferguson 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Ferguson (1997) and Kornfeld and Wattecamps (1998) developed context specific solutions for the problem of extracting information from American companies\u2019 financial statements published on the internet in a poor XMLbased format (the SEC filings)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parsing Financial Statements Efficiently and Accurately Using C and Prolog"
            },
            "venue": {
                "fragments": [],
                "text": "Practical Applications of Prolog Conference '97"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 4
                            }
                        ],
                        "text": "(I) Green and Krishnamoorthy (1995). Users provide a model of the relevant tables, which includes a description of the type of line or space gap that separates the tables from the rest of the document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 0
                            }
                        ],
                        "text": "Green and Krishnamoorthy (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 4
                            }
                        ],
                        "text": "(I) Green and Krishnamoorthy (1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 0
                            }
                        ],
                        "text": "Green and Krishnamoorthy (1995). A user-built model of the table maps relationship between each table area"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 4
                            }
                        ],
                        "text": "(I) Green and Krishnamoorthy (1995). The user provides a table model with the characteristics of the relevant tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modelbased of Printed Tables"
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of International Conference of Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 41
                            }
                        ],
                        "text": "The method, which was first presented in Silva (2003) and which schema is shown in Figure 3, takes as input a document (e.g. pdf, ASCII, or OCR output) containing several graphical elements, including charts and organizational charts, detects within it the existing tables (Silva et al. 2003), segments these into cells, distinguishes the cells that describe the content of the table and relates them to those that contain the data; finally it interprets\nthe results to identify the relevant items and extracts them to a database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "The method, which was first presented in Silva [38] and the schema is shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 157
                            }
                        ],
                        "text": "Aiming at information extraction, Ferguson (1998) takes those measurements on the number of tables that are properly handled by their extraction system; and Silva et al. (2003) on the number of lines that belong to those tables holding the information to be extracted."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 270
                            }
                        ],
                        "text": "We aim this interpretation to take into account the specificities of the national accounting environment of each country and hope to adapt XBRL (eXtensible Business Reporting Language) jurisdictional taxonomies as a plug in-plug out source of this accounting knowledge (Silva et al. 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 25
                            }
                        ],
                        "text": "It has been detailed in (Silva et al (2003b))."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Extracting information from tables in text\u2014 an application to financial statements of Portuguese companies"
            },
            "venue": {
                "fragments": [],
                "text": "Thesis for Masters in Science in Data Analysis and Decision Support Systems, Faculty of Economics of the University of Oporto, Portugal"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The First Company Law Directive"
            },
            "venue": {
                "fragments": [],
                "text": "The First Company Law Directive"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Directive 2003 / 58 / EC of the European Parliament and Council of 15 July 2003 amending Council Directive 68 / 151 / EEC , as regards disclosure requirements in respect of certain types of companies"
            },
            "venue": {
                "fragments": [],
                "text": "Off J Eur Commun L"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SA: Relatorio e contas consolidadas 2000"
            },
            "venue": {
                "fragments": [],
                "text": "SA: Relatorio e contas consolidadas 2000"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "International financial reporting standards (IFRS), general purpose financial reporting for profitoriented entities (GP)"
            },
            "venue": {
                "fragments": [],
                "text": "International financial reporting standards (IFRS), general purpose financial reporting for profitoriented entities (GP)"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Layout and Language: An Efficient Algorithm for Text Block Detection based on Spatial and Linguistic Evidence\u201d, in Document Recognition and Retrieval VIII"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SPIE, Volume"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "International Financial Reporting Standards (IFRS), General Purpose Financial Reporting for Profit-Oriented Entities (GP)"
            },
            "venue": {
                "fragments": [],
                "text": "International Financial Reporting Standards (IFRS), General Purpose Financial Reporting for Profit-Oriented Entities (GP)"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relat\u00f3rio e contas consolidadas 2000"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Auto Industrial , Relatorio e contas consolidadas 2000"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Why Table GroundTruthing is Hard"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition (IC-"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 157
                            }
                        ],
                        "text": "Aiming at information extraction, Ferguson (1998) takes those measurements on the number of tables that are properly handled by their extraction system; and Silva et al. (2003) on the number of lines that belong to those tables holding the information to be extracted."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 41
                            }
                        ],
                        "text": "The method, which was first presented in Silva (2003) and which schema is shown in Figure 3, takes as input a document (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Design of an end-to-end method to extract information from tables"
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Symposium on String Processing and Information Retrieval,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 28
                            }
                        ],
                        "text": "To address this problem, in Hu et al (2000) ground truth has been generated by all four authors: \u201cA line was classified as table or nontable if three or four votes (out of four) classified it in that way\u201d."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "Apart from these more standard measurements, to evaluate location Hu et al. (2000) and Cesarini et al.\n(2002) take \u201ca measure of the similarity of two documents (the recognised document and its ground truth) in terms of their table structure\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Medium-Independent Table Detection\u201d, in Document Recognition and Retrieval VII"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SPIE,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A paperto-html table converting system"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Document Analysis Systems, (DAS'98)"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 22
                            }
                        ],
                        "text": "An exception would be Hurst (2001, 2003)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Layout and Language: An Efficient Algorithm for Text Block Detection based on Spatial and Linguistic Evidence"
            },
            "venue": {
                "fragments": [],
                "text": "Document Recognition and Retrieval VIII, Proceedings of SPIE"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "ings or a page\u2019s header or footer [6] has an interesting approach for identification of recurrent headers and footers and other background patterns, which we will consider in future work."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Background pattern recognition in multi-page PDF document"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Third International Workshop in Document Analysis and its Applications, DLIA 2003, Edinburgh, UK"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A cognitive model for table editing\u201d, Technical report OSU-CISRC6/89-TR 26, Computer and Information Science Research Centre"
            },
            "venue": {
                "fragments": [],
                "text": "Ohio State University,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Auto Industrial"
            },
            "venue": {
                "fragments": [],
                "text": "Auto Industrial"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relat\u00f3rio e contas consolidadas 2000"
            },
            "venue": {
                "fragments": [],
                "text": "Auto Industrial"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 118
                            }
                        ],
                        "text": "It can work well in contexts with uniform tables, such as that of journals or books and some industrial applications (Baum et al. (2003)), as it would in Figure 11 and Figure 12."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document layout problems facing the aerospace industry"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Third International Workshop in Document Analysis and its Applications,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A paper-to-html table converting system"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Document Analysis Systems,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Directive 2003/58/EC of the European Parliament and Council of 15 July 2003 amending Council Directive 68/151/EEC, as regards disclosure requirements in respect of certain types of companies"
            },
            "venue": {
                "fragments": [],
                "text": "Official Journal of the European Communities L"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "These measures have nonetheless been taken at different levels of the table\u2019s physical model: Pyreddi and Croft\u2019s [33] measured them in terms of the number of lines correctly tagged; Wang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 93
                            }
                        ],
                        "text": "These measures have nonetheless been taken at different levels of the table\u2019s physical model: Pyreddi and Croft\u2019s (1997) measured them in terms of the number of lines correctly tagged; Wang et al. (2000-2002) took the same measurements on cells; Tupaj et al (1996) and Chen et al (2000) consider full tables as well; and Ng et al (1999) take full table, column and row."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "W.B.C.: A system for retrieval in text tables, Technical report 105, Center for Intelligent Information Retrieval, Department of Computer Science, University"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 1
                            }
                        ],
                        "text": "(Cameron, 1989)\nThe two main elements behind this definition are that there exist simultaneously linear visual clues in the form of columns and rows that represent logical connections; as such there is a relationship between the relative position of the items and their conceptual relationship."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 52
                            }
                        ],
                        "text": "Information contained in these reports is valuable to the decision-making of a variety of agents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A cognitive model for table editing"
            },
            "venue": {
                "fragments": [],
                "text": "A cognitive model for table editing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relat\u00f3rio e contas consolidadas 2000"
            },
            "venue": {
                "fragments": [],
                "text": "Relat\u00f3rio e contas consolidadas 2000"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 45
                            }
                        ],
                        "text": "Apart from these more standard measurements, to evaluate location Hu et al. (2000) and Cesarini et al.\n(2002) take \u201ca measure of the similarity of two documents (the recognised document and its ground truth) in terms of their table structure\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Extracting information from tables in text -an application to financial statements of Portuguese companies \" , Thesis for Masters in Science in Data Analysis and Decision Support Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Extracting information from tables in text -an application to financial statements of Portuguese companies \" , Thesis for Masters in Science in Data Analysis and Decision Support Systems"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As demonstrated in these works, a simple heuristic approach is sufficient to guarantee very good results in this task."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 1
                            }
                        ],
                        "text": "(Thompson, 1996)\nThe purpose of this task is to connect each data cell to all attribute cells that characterize it, thus grouping those cells that have to be read conjointly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A tables manifesto"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SGMK Europe"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 30,
            "methodology": 29,
            "result": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 69,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Design-of-an-end-to-end-method-to-extract-from-Silva-Jorge/d7f1c7ab6bb331944c0667b3ab75cba46021db1a?sort=total-citations"
}