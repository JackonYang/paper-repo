{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 77
                            }
                        ],
                        "text": "The recent success of special purpose algorithms for support vector machines [16, 17, 6] indicate that such approaches may produce improvement for S(3)VM as well."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15140283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68c4749d9d3f1724aa01778d69a3774c732ca44c",
            "isKey": false,
            "numCitedBy": 844,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The Support Vector Machine (SVM) is a new and very promising classification technique developed by Vapnik and his group at AT\\&T Bell Labs. This new learning algorithm can be seen as an alternative training technique for Polynomial, Radial Basis Function and Multi-Layer Perceptron classifiers. An interesting property of this approach is that it is an approximate implementation of the Structural Risk Minimization (SRM) induction principle. The derivation of Support Vector Machines, its relationship with SRM, and its geometrical insight, are discussed in this paper. Training a SVM is equivalent to solve a quadratic programming problem with linear and box constraints in a number of variables equal to the number of data points. When the number of data points exceeds few thousands the problem is very challenging, because the quadratic form is completely dense, so the memory needed to store the problem grows with the square of the number of data points. Therefore, training problems arising in some real applications with large data sets are impossible to load into memory, and cannot be solved using standard non-linear constrained optimization algorithms. We present a decomposition algorithm that can be used to train SVM''s over large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of, and also establish the stopping criteria for the algorithm. We present previous approaches, as well as results and important details of our implementation of the algorithm using a second-order variant of the Reduced Gradient Method as the solver of the sub-problems. As an application of SVM''s, we present preliminary results we obtained applying SVM to the problem of detecting frontal human faces in real images."
            },
            "slug": "Support-Vector-Machines:-Training-and-Applications-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines: Training and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Preliminary results are presented obtained applying SVM to the problem of detecting frontal human faces in real images, and the main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of, and also establish the stopping criteria for the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052864185"
                        ],
                        "name": "P. Bradley",
                        "slug": "P.-Bradley",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Bradley",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bradley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747026"
                        ],
                        "name": "O. Mangasarian",
                        "slug": "O.-Mangasarian",
                        "structuredName": {
                            "firstName": "Olvi",
                            "lastName": "Mangasarian",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mangasarian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 125
                            }
                        ],
                        "text": "Empirical comparisons of the approaches have not found any significant difference in generalization between the formulations [5, 7, 3, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5885974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23d9a5273bd9e08eb68cf3b097836d718e91d70c",
            "isKey": false,
            "numCitedBy": 1053,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational comparison is made between two feature selection approaches for nding a separating plane that discriminates between two point sets in an n-dimensional feature space that utilizes as few of the n features (dimensions) as possible. In the concave minimization approach [19, 5] a separating plane is generated by minimizing a weighted sum of distances of misclassi ed points to two parallel planes that bound the sets and which determine the separating plane midway between them. Furthermore, the number of dimensions of the space used to determine the plane is minimized. In the support vector machine approach [27, 7, 1, 10, 24, 28], in addition to minimizing the weighted sum of distances of misclassi ed points to the bounding planes, we also maximize the distance between the two bounding planes that generate the separating plane. Computational results show that feature suppression is an indirect consequence of the support vector machine approach when an appropriate norm is used. Numerical tests on 6 public data sets show that classi ers trained by the concave minimization approach and those trained by a support vector machine have comparable 10fold cross-validation correctness. However, in all data sets tested, the classi ers obtained by the concave minimization approach selected fewer problem features than those trained by a support vector machine."
            },
            "slug": "Feature-Selection-via-Concave-Minimization-and-Bradley-Mangasarian",
            "title": {
                "fragments": [],
                "text": "Feature Selection via Concave Minimization and Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Numerical tests on 6 public data sets show that classi ers trained by the concave minimization approach and those trained by a support vector machine have comparable 10fold cross-validation correctness."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052864185"
                        ],
                        "name": "P. Bradley",
                        "slug": "P.-Bradley",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Bradley",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bradley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747026"
                        ],
                        "name": "O. Mangasarian",
                        "slug": "O.-Mangasarian",
                        "structuredName": {
                            "firstName": "Olvi",
                            "lastName": "Mangasarian",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mangasarian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 77
                            }
                        ],
                        "text": "The recent success of special purpose algorithms for support vector machines [16, 17, 6] indicate that such approaches may produce improvement for S(3)VM as well."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17784771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "557aeb897fa4a6b23bd610f0a7ee9e2f5dfd8316",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A linear support vector machine formulation is used to generate a fast, finitely-terminating linear-programming algorithm for discriminating between two massive sets in n-dimen-sional space, where the number of points can be orders of magnitude larger than n. The algorithm creates a succession of sufficiently small linear programs that separate chunks of the data at a time. The key idea is that a small number of support vectors, corresponding to linear programming constraints with positive dual variables, are carried over between the successive small linear programs, each of which containing a chunk of the data. We prove that this procedure is monotonic and terminates in a finite number of steps at an exact solution that leads to an optimal separating plane for the entire dataset. Numerical results on fully dense publicly available datasets, numbering 20,000 to 1 million points in 32-dimensional space, confirm the theoretical results and demonstrate the ability to handle very large problems"
            },
            "slug": "Massive-data-discrimination-via-linear-support-Bradley-Mangasarian",
            "title": {
                "fragments": [],
                "text": "Massive data discrimination via linear support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Numerical results on fully dense publicly available datasets, numbering 20,000 to 1 million points in 32-dimensional space, confirm the theoretical results and demonstrate the ability to handle very large problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647543"
                        ],
                        "name": "Erin J. Bredensteiner",
                        "slug": "Erin-J.-Bredensteiner",
                        "structuredName": {
                            "firstName": "Erin",
                            "lastName": "Bredensteiner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erin J. Bredensteiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145728220"
                        ],
                        "name": "K. Bennett",
                        "slug": "K.-Bennett",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Bennett",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bennett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "In all ten problems, S3VM never performed significantly worse than RLP."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 62
                            }
                        ],
                        "text": "The problem becomes the following robust linear program (RLP) [2, 7, 1]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "Using RLP alone on the training data results in the separation shown in Figure 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "One major benefit of RLP over GOP is dimensionality reduction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "The Robust Linear Programming (RLP) approach to SVM is identical to GOP except the margin term is changed from the 2-norm \u2016w\u2016\n2 to the 1-norm, \u2016w\u2016 1 =\n\u2211n j=1 |wj|."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Another benefit of RLP over GOP is that it can be solved using linear programming instead of quadratic programming."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 125
                            }
                        ],
                        "text": "Empirical comparisons of the approaches have not found any significant difference in generalization between the formulations [5, 7, 3, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "The problem becomes the following robust linear program (RLP) [2, 7, 1]:\nmin w,b,s,\u03b7 C\n\u2113 \u2211\ni=1\n\u03b7i +\nn \u2211\nj=1\nsj\ns.t. yi[w \u00b7 xi \u2212 b] + \u03b7i \u2265 1 \u03b7i \u2265 0, i = 1, . . . , \u2113 \u2212sj  = wj  = sj , j = 1, . . . , n.\n(5)\nThe RLP formulation is a useful variation of SVM with some nice characteristics."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "The left picture in Figure 2 shows the solution found by RLP. Note that when the working set points are added, the resulting separation has very a small margin."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "The same C parameter was used for each data set in both the RLP and S3VM problems1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "But RLP forces more of the weights to be 0 due to the properties of the 1-norm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "Both RLP and GOP minimize the magnitude of the weights w."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15871727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "547f61c0571ecd771ed171c8d9602c916c0a2525",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Decision trees for classification can be constructed using mathematical programming. Within decision tree algorithms, the feature minimization problem is to construct accurate decisions using as few features or attributes within each decision as possible. Feature minimization is an important aspect of data mining since it helps identify what attributes are important and helps produce accurate and interpretable decision trees. In feature minimization with bounded accuracy, we minimize the number of features using a given misclassification error tolerance. This problem can be formulated as a parametric bilinear program and is shown to be NP-complete. A parametric FrankWolfe method is used to solve the bilinear subproblems. The resulting minimization algorithm produces more compact, accurate, and interpretable trees. This procedure can be applied to many different error functions. Formulations and results for two error functions are given. One method, FM RLP-P, dramatically reduced the number of features of one dataset from 147 to 2 while maintaining an 83.6% testing accuracy. Computational results compare favorably with the standard univariate decision tree method, C4.5, as well as with linear programming methods of tree construction."
            },
            "slug": "Feature-minimization-within-decision-trees-Bredensteiner-Bennett",
            "title": {
                "fragments": [],
                "text": "Feature minimization within decision trees"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work reduces the number of features of one dataset from 147 to 2 while maintaining an 83.6% testing accuracy and shows that the resulting minimization algorithm produces more compact, accurate, and interpretable trees."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145039030"
                        ],
                        "name": "J. Platt",
                        "slug": "J.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 77
                            }
                        ],
                        "text": "The recent success of special purpose algorithms for support vector machines [16, 17, 6] indicate that such approaches may produce improvement for S(3)VM as well."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 577580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53fcc056f79e04daf11eb798a7238e93699665aa",
            "isKey": false,
            "numCitedBy": 2854,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new algorithm for training support vector machines: Sequential Minimal Optimization, or SMO. Training a support vector machine requires the solution of a very large quadratic programming (QP) optimization problem. SMO breaks this large QP problem into a series of smallest possible QP problems. These small QP problems are solved analytically, which avoids using a time-consuming numerical QP optimization as an inner loop. The amount of memory required for SMO is linear in the training set size, which allows SMO to handle very large training sets. Because matrix computation is avoided, SMO scales somewhere between linear and quadratic in the training set size for various test problems, while the standard chunking SVM algorithm scales somewhere between linear and cubic in the training set size. SMO\u2019s computation time is dominated by SVM evaluation, hence SMO is fastest for linear SVMs and sparse data sets. On realworld sparse data sets, SMO can be more than 1000 times faster than the chunking algorithm."
            },
            "slug": "Sequential-Minimal-Optimization-:-A-Fast-Algorithm-Platt",
            "title": {
                "fragments": [],
                "text": "Sequential Minimal Optimization : A Fast Algorithm for Training Support Vector Machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102645360"
                        ],
                        "name": "Thilo-Thomas Friel",
                        "slug": "Thilo-Thomas-Friel",
                        "structuredName": {
                            "firstName": "Thilo-Thomas",
                            "lastName": "Friel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thilo-Thomas Friel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072395569"
                        ],
                        "name": "R. Harrison",
                        "slug": "R.-Harrison",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Harrison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Harrison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 125
                            }
                        ],
                        "text": "Empirical comparisons of the approaches have not found any significant difference in generalization between the formulations [5, 7, 3, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 90
                            }
                        ],
                        "text": "Both approaches can be extended to handle nonlinear discrimination using kernel functions [8, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118742920,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "02835af8ac7c40592770c775b31b249091721cf5",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Three novel algorithms are presented; the linear programming (LP) machine for pattern classification, the LP machine for regression estimation and the set-reduction (SR) algorithm. The LP machine is a learning machine which achieves solutions as good as the SV machine by only maximising a linear cost-function (SV machine are based on quadratic programming). The set-reduction algorithm improves the speed and accuracy of LP machines, SV machines and other related algorithms. An LP machines's decisions are optimal in the sense that it implements Vapnick's (Vapnick and Chervonekis in 1979, Vapnick 1995) structural risk minimisation (SRM) principle. The LP machine has a number of attractive and interesting properties like a high generalisation ability, fast learning based on linear optimisation, capacity control, and a self organisation property. \n The SR algorithm is an efficient method to improve speed in a LP machine, SV machine and related algorithms, VC bounds are known to be loose bounds. The SR algorithm allows to construct optimal support vector machines by determining the necessary and sufficient number of support patterns. The algorithm does also give tighter VC bounds (for bounds of which are a function of the number of support patterns)"
            },
            "slug": "Linear-Programming-Support-Vector-Machines-for-and-Friel-Harrison",
            "title": {
                "fragments": [],
                "text": "Linear Programming Support Vector Machines for Pattern Classification and Regression Estimation: and The SR Algorithm: Improving Speed and Tightness of VC Bounds in SV Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Three novel algorithms are presented; the linear programming (LP) machine for pattern classification, the LP machine for regression estimation and the set-reduction (SR) algorithm, an efficient method to improve speed in a LP machine, SV machine and related algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37789458"
                        ],
                        "name": "A. Bensaid",
                        "slug": "A.-Bensaid",
                        "structuredName": {
                            "firstName": "Amine",
                            "lastName": "Bensaid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bensaid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25887296"
                        ],
                        "name": "L. Hall",
                        "slug": "L.-Hall",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Hall",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4929024"
                        ],
                        "name": "J. Bezdek",
                        "slug": "J.-Bezdek",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bezdek",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bezdek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7159032"
                        ],
                        "name": "L. Clarke",
                        "slug": "L.-Clarke",
                        "structuredName": {
                            "firstName": "Laurence",
                            "lastName": "Clarke",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Clarke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6244875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1c23aac5e4968c146cbc2d1ac9d3178ad253e57",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Partially-supervised-clustering-for-image-Bensaid-Hall",
            "title": {
                "fragments": [],
                "text": "Partially supervised clustering for image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145728220"
                        ],
                        "name": "K. Bennett",
                        "slug": "K.-Bennett",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Bennett",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116668597"
                        ],
                        "name": "Donghui Wu",
                        "slug": "Donghui-Wu",
                        "structuredName": {
                            "firstName": "Donghui",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donghui Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2894031"
                        ],
                        "name": "Leonardo Auslender",
                        "slug": "Leonardo-Auslender",
                        "structuredName": {
                            "firstName": "Leonardo",
                            "lastName": "Auslender",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leonardo Auslender"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 125
                            }
                        ],
                        "text": "Empirical comparisons of the approaches have not found any significant difference in generalization between the formulations [5, 7, 3, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15043488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a64fec49a357f1b206eeabdb3f79ec041eaed61",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a support vector decision tree method for customer targeting in the framework of large databases (database marketing). The goal is to provide a tool to identify the best customers based on historical data. This tool is then used to forecast the best potential customers among a pool of prospects. We begin by regressively constructing a decision tree. Each decision consists of a linear combination of independent attributes. A linear program motivated by the support vector machine method from Vapnik's statistical learning theory is used to construct each decision. This linear program automatically selects the relevant subset of attributes for each decision. Each customer is scored based on the decision tree. A gain chart table is used to verify the goodness-of-fit of the targeting, to determine the likely prospects and the expected utility or profit. Successful results are given for three industrial problems."
            },
            "slug": "On-support-vector-decision-trees-for-database-Bennett-Wu",
            "title": {
                "fragments": [],
                "text": "On support vector decision trees for database marketing"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A support vector decision tree method for customer targeting in the framework of large databases (database marketing) is introduced to provide a tool to identify the best customers based on historical data."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145728220"
                        ],
                        "name": "K. Bennett",
                        "slug": "K.-Bennett",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Bennett",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747026"
                        ],
                        "name": "O. Mangasarian",
                        "slug": "O.-Mangasarian",
                        "structuredName": {
                            "firstName": "Olvi",
                            "lastName": "Mangasarian",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mangasarian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "In all ten problems, S3VM never performed significantly worse than RLP."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 62
                            }
                        ],
                        "text": "The problem becomes the following robust linear program (RLP) [2, 7, 1]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "Using RLP alone on the training data results in the separation shown in Figure 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "One major benefit of RLP over GOP is dimensionality reduction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "The Robust Linear Programming (RLP) approach to SVM is identical to GOP except the margin term is changed from the 2-norm \u2016w\u2016\n2 to the 1-norm, \u2016w\u2016 1 =\n\u2211n j=1 |wj|."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Another benefit of RLP over GOP is that it can be solved using linear programming instead of quadratic programming."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "The problem becomes the following robust linear program (RLP) [2, 7, 1]:\nmin w,b,s,\u03b7 C\n\u2113 \u2211\ni=1\n\u03b7i +\nn \u2211\nj=1\nsj\ns.t. yi[w \u00b7 xi \u2212 b] + \u03b7i \u2265 1 \u03b7i \u2265 0, i = 1, . . . , \u2113 \u2212sj  = wj  = sj , j = 1, . . . , n.\n(5)\nThe RLP formulation is a useful variation of SVM with some nice characteristics."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "The left picture in Figure 2 shows the solution found by RLP. Note that when the working set points are added, the resulting separation has very a small margin."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "The same C parameter was used for each data set in both the RLP and S3VM problems1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "But RLP forces more of the weights to be 0 due to the properties of the 1-norm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "Both RLP and GOP minimize the magnitude of the weights w."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15917152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c5e562437ee94fb6e4d60ec559386dd0a433513",
            "isKey": false,
            "numCitedBy": 796,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A single linear programming formulation is proposed which generates a plane that of minimizes an average sum of misclassified points belonging to two disjoint points sets in n-dimensional real space. When the convex hulls of the two sets are also disjoint, the plane completely separates the two sets. When the convex hulls intersect, our linear program, unlike all previously proposed linear programs, is guaranteed to generate some error-minimizing plane, without the imposition of extraneous normalization constraints that inevitably fail to handle certain cases. The effectiveness of the proposed linear program has been demonstrated by successfully testing it on a number of databases. In addition, it has been used in conjunction with the multisurface method of piecewise-linear separation to train a feed-forward neural network with a single hidden layer."
            },
            "slug": "Robust-linear-programming-discrimination-of-two-Bennett-Mangasarian",
            "title": {
                "fragments": [],
                "text": "Robust linear programming discrimination of two linearly inseparable sets"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A single linear programming formulation is proposed which generates a plane that of minimizes an average sum of misclassified points belonging to two disjoint points sets in n-dimensional real space, without the imposition of extraneous normalization constraints that inevitably fail to handle certain cases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40796961"
                        ],
                        "name": "S. Odewahn",
                        "slug": "S.-Odewahn",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Odewahn",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Odewahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146664116"
                        ],
                        "name": "E. B. Stockwell",
                        "slug": "E.-B.-Stockwell",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Stockwell",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. B. Stockwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52351543"
                        ],
                        "name": "R. Pennington",
                        "slug": "R.-Pennington",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Pennington",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91292961"
                        ],
                        "name": "R. Humphreys",
                        "slug": "R.-Humphreys",
                        "structuredName": {
                            "firstName": "Roberta",
                            "lastName": "Humphreys",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Humphreys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97008165"
                        ],
                        "name": "W. Zumach",
                        "slug": "W.-Zumach",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Zumach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zumach"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "We also tested S(3)VM on ten real-world data sets (eight from [14] and the bright and dim galaxy sets from [15])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 227291542,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "890b602a8442205d82e965352150ee4247839ec7",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Many of today\u2019s most relevant astrophysical problems concerning galactic structure and dynamics, environmental effects on galaxy formation and maintenance, and the large-scale distribution of matter in the Universe are approached in a statistical fashion using deep surveys of stars and galaxies over large areas of the sky. Some of the deepest and most complete galaxy catalogs such as those by Shane & Wirtanen (1967), Zwicky et al. (1961\u20131968), and Nilson (1973) have been compiled through visual inspection of photographic surveys. More recent efforts by Dickey et al. (1987), Heydon-Dumbleton et al. (1989), Slezak et al. (1988) and Rhee (1990) have used fast scanning machines and automated image detection and classification techniques to compile galaxy catalogs in specific areas of the sky."
            },
            "slug": "Automated-star/galaxy-discrimination-with-neural-Odewahn-Stockwell",
            "title": {
                "fragments": [],
                "text": "Automated star/galaxy discrimination with neural networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052864185"
                        ],
                        "name": "P. Bradley",
                        "slug": "P.-Bradley",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Bradley",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bradley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747026"
                        ],
                        "name": "O. Mangasarian",
                        "slug": "O.-Mangasarian",
                        "structuredName": {
                            "firstName": "Olvi",
                            "lastName": "Mangasarian",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mangasarian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057308049"
                        ],
                        "name": "J. Rosen",
                        "slug": "J.-Rosen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Rosen",
                            "middleNames": [
                                "Ben"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rosen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "The results in [13] can be used to show that minimizing \u2016w\u20161 corresponds to maximizing the separation margin using the infinity norm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12621316,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3ebf610010d16832c015bf80427b669ba8715084",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A theoretically justifiable fast finite successive linear approximation algorithm is proposed for obtaining a parsimonious solutionto a corrupted linear system Ax=b+p, where the corruption p is due to noise or error in measurement. The proposedlinear-programming-based algorithm finds a solution x by parametrically minimizing the number of nonzeroelements in x and the error \u2016Ax-b-p\u20161.Numerical tests on a signal-processing-based exampleindicate that the proposed method is comparable to a method that parametrically minimizesthe 1-norm of the solution x and the error \u2016Ax-b-p\u20161, and that both methods are superior, byorders of magnitude, to solutions obtained by least squares as well by combinatorially choosing an optimal solution with a specific number of nonzero elements."
            },
            "slug": "Parsimonious-Least-Norm-Approximation-Bradley-Mangasarian",
            "title": {
                "fragments": [],
                "text": "Parsimonious Least Norm Approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Numerical tests on a signal-processing-based example indicate that the proposed method is comparable to a method that parametrically minimizes the 1-norm of the solution x and the error \u2016Ax-b-p\u20161, and that both methods are superior, by orders of magnitude, to solutions obtained by least squares."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Optim. Appl."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787993"
                        ],
                        "name": "R. Fourer",
                        "slug": "R.-Fourer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fourer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fourer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847322"
                        ],
                        "name": "B. Kernighan",
                        "slug": "B.-Kernighan",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kernighan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kernighan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "Using the mathematical programming modeling language AMPL [11], we were able to express the problem in thirty lines of code plus a data file and solve it using CPLEX."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60753226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "912a2dc05a3e0f5fc778f4d0ed18286d005c1ab1",
            "isKey": false,
            "numCitedBy": 3537,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Practical large-scale mathematical programming involves more than just the application of an algorithm to minimize or maximize an objective function. Before any optimizing routine can be invoked, considerable effort must be expended to formulate the underlying model and to generate the requisite computational data structures. AMPL is a new language designed to make these steps easier and less error-prone. AMPL closely resembles the symbolic algebraic notation that many modelers use to describe mathematical programs, yet it is regular and formal enough to be processed by a computer system; it is particularly notable for the generality of its syntax and for the variety of its indexing operations. We have implemented an efficient translator that takes as input a linear AMPL model and associated data, and produces output suitable for standard linear programming optimizers. Both the language and the translator admit straightforward extensions to more general mathematical programs that incorporate nonlinear expressions or discrete variables."
            },
            "slug": "AMPL:-A-Modeling-Language-for-Mathematical-Fourer-Kernighan",
            "title": {
                "fragments": [],
                "text": "AMPL: A Modeling Language for Mathematical Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An efficient translator is implemented that takes as input a linear AMPL model and associated data, and produces output suitable for standard linear programming optimizers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145298005"
                        ],
                        "name": "Catherine Blake",
                        "slug": "Catherine-Blake",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Blake"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "We also tested S(3)VM on ten real-world data sets (eight from [14] and the bright and dim galaxy sets from [15])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62622768,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e068be31ded63600aea068eacd12931efd2a1029",
            "isKey": false,
            "numCitedBy": 13446,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "UCI-Repository-of-machine-learning-databases-Blake",
            "title": {
                "fragments": [],
                "text": "UCI Repository of machine learning databases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 97
                            }
                        ],
                        "text": "In general the classes will not be separable, so the generalized optimal plane (GOP) problem (4) [9, 20] is used."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 91
                            }
                        ],
                        "text": "If the working set is empty the method becomes the standard SVM approach to classification [20, 9, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 164
                            }
                        ],
                        "text": "According to the principles of structural risk minimization, SVM minimize both the empirical misclassification rate and the capacity of the classification function [19, 20] using the training data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38757,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "Indeed,the theoretical results in [19] support these hypotheses."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "These computational solutions are identical to those presented in [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Our empirical results combined with the theoretical results in [19], indicate that transduction via ORM constitutes a very promising research direction."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "Consider the simple problem given in Figure 20 of [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 164
                            }
                        ],
                        "text": "According to the principles of structural risk minimization, SVM minimize both the empirical misclassification rate and the capacity of the classification function [19, 20] using the training data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 102
                            }
                        ],
                        "text": "The capacity control provided by the margin maximization is imperative to achieve good generalization [21, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59746611,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "78ecaabe915ba7df950671d36f92678192802df4",
            "isKey": true,
            "numCitedBy": 516,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimation-of-Dependences-Based-on-Empirical-Data:-Vapnik",
            "title": {
                "fragments": [],
                "text": "Estimation of Dependences Based on Empirical Data: Springer Series in Statistics (Springer Series in Statistics)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644344103"
                        ],
                        "name": "J. C. BurgesChristopher",
                        "slug": "J.-C.-BurgesChristopher",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "BurgesChristopher",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. BurgesChristopher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 91
                            }
                        ],
                        "text": "If the working set is empty the method becomes the standard SVM approach to classification [20, 9, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 90
                            }
                        ],
                        "text": "Both approaches can be extended to handle nonlinear discrimination using kernel functions [8, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215966761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6716697767fc601efc7690f40820d9ea7a7bf57c",
            "isKey": false,
            "numCitedBy": 13527,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, w..."
            },
            "slug": "A-Tutorial-on-Support-Vector-Machines-for-Pattern-BurgesChristopher",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Support Vector Machines for Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This tutorial starts with an overview of the concepts of VC dimension and structural risk minimization and describes linear Support Vector Machines (SVMs) for separable and non-separable data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61480753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edb62d05f8eeaa7e1921c6c25c544935a2b6b131",
            "isKey": false,
            "numCitedBy": 415,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Theory-of-Pattern-Recognition-Amari",
            "title": {
                "fragments": [],
                "text": "A Theory of Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Using the mathematical programming modeling language AMPL [11], we were able to express the problem in thirty lines of code plus a data file and solve it using CPLEX."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Incline Village, Nevada. Using the CPLEX Callable Library"
            },
            "venue": {
                "fragments": [],
                "text": "CPLEX Optimization Incorporated"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Support vector machines: Training and applications. AI Memo 1602"
            },
            "venue": {
                "fragments": [],
                "text": "Support vector machines: Training and applications. AI Memo 1602"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "S3VM constructs a support vector machine using all the available data from both the training and working sets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2217This paper has been accepted for publication in Proceedings of Neural Information Processing Systems, Denver, 1998."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimation of dependencies based on empirical Data English translation, Russian version"
            },
            "venue": {
                "fragments": [],
                "text": "Estimation of dependencies based on empirical Data English translation, Russian version"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 102
                            }
                        ],
                        "text": "The capacity control provided by the margin maximization is imperative to achieve good generalization [21, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chervonenkis"
            },
            "venue": {
                "fragments": [],
                "text": "Theory of Pattern Recognition. Nauka, Moscow"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 89
                            }
                        ],
                        "text": "There are successful semi-supervised algorithms for k-means and fuzzy c-means clustering [4, 18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tumor volume measurements using supervised and semi-supervised mri segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Neural Networks in Engineering Conference, AN- NIE"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "solution to this problem can be found using CPLEX or other commercial mixed integer programming codes [10] provided computer resources are sufficient for the problem size."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Incline Village"
            },
            "venue": {
                "fragments": [],
                "text": "Nevada. Using the CPLEX Callable Library"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mangasarian . Parsimonious least norm approximation"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report Mathematical Programming Technical Report"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Harrison Fries . Linear programming support vector machines for pattern classification and regression estimation : and the sr algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vapnik . Support vector networks"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Harrison Fries . Linear programming support vector machines for pattern classification and regression estimation : and the sr algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mangasarian . Massive data discrimination via linear support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tumor volume measurements using supervised and semisupervised mri segmentation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 11,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Semi-Supervised-Support-Vector-Machines-Bennett-Demiriz/8198e70878c907e1bd05e7a3fa4280d8c338df60?sort=total-citations"
}