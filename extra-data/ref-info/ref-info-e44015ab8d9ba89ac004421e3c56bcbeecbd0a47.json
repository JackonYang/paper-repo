{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741916"
                        ],
                        "name": "M. Garris",
                        "slug": "M.-Garris",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Garris",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16555647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8087d6c784d46534bb796d32f2342a0c8e9d2fc7",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces scoring methods developed to automatically assess the performance of document recognition systems, specifically, to evaluate the spatial correspondence of zones produced by a document segmentor. Two different approaches are discussed. The first approach (based on zone overlap and nearest-neighbors) is better applied to merged zones, whereas the second approach (based on zone alignments) is better applied to nested zones (such as those found in tables and graphs). Definitions of coverage and efficiency error are presented, and scoring results on real system output is provided that validates the usefulness of these methods to compare different document recognition algorithms. Currently, no standard testing procedures exist for measuring and comparing algorithms within a complex document recognition system. Scoring methods, like the ones introduced in this paper, serve as design and validations tools, expediting the development and deployment of document analysis technology for system developers and end users."
            },
            "slug": "Evaluating-spatial-correspondence-of-zones-in-Garris",
            "title": {
                "fragments": [],
                "text": "Evaluating spatial correspondence of zones in document recognition systems"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper introduces scoring methods developed to automatically assess the performance of document recognition systems, specifically, to evaluate the spatial correspondence of zones produced by a document segmentor."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1896610"
                        ],
                        "name": "S. Randriamasy",
                        "slug": "S.-Randriamasy",
                        "structuredName": {
                            "firstName": "Sabine",
                            "lastName": "Randriamasy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Randriamasy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6941199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f05833210f2b2e2f495594aeb98ff66e30c8fa1",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for automatically evaluating the quality of document page segmentation algorithms is introduced. Many different zoning techniques are now available but there is no robust method available to benchmark and evaluate them reliably. Our proposed strategy is a region-based approach, in which segmentation results are compared with manually generated \"ground truth files\", describing all possible correct segmentations. A segmentation ground truthing scheme has been proposed. The evaluation of segmentation quality is achieved by testing the overlap between the two sets of regions. In fact, the regions are defined as the \"black\" pixels contained in the extracted polygons. An explicit specification of segmentation errors and a numerical evaluation are derived. The algorithm is simple and fast, and provides a multi-level output for each segmentation.<<ETX>>"
            },
            "slug": "Benchmarking-page-segmentation-algorithms-Randriamasy-Vincent",
            "title": {
                "fragments": [],
                "text": "Benchmarking page segmentation algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A method for automatically evaluating the quality of document page segmentation algorithms is introduced, in which segmentation results are compared with manually generated \"ground truth files\", describing all possible correct segmentations."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111237291"
                        ],
                        "name": "Su S. Chen",
                        "slug": "Su-S.-Chen",
                        "structuredName": {
                            "firstName": "Su",
                            "lastName": "Chen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su S. Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 54
                            }
                        ],
                        "text": "Each polygonal area A E A consists of an ordered pair (9,1), where 9 e 0 specifies the content type and I is the area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63629817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "068bc334298658330e9df2ceebeb5f4c76b60b90",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of this study is to apply solid statistical methods to systematically model and extract various layout structures on document images, such as words, text lines and text blocks. \nWe first establish the computation theory of the recursive morphological transforms, namely the recursive erosion transform, the recursive dilation transform, the recursive opening transform, and the recursive closing transform. The transforms serve as a set of powerful tools for the document image shape analysis. \nThen we describe our efforts to construct a series of carefully ground-truthed document image databases, such as the UW English document image database (I). The database offers a platform based on which we can develop, train and evaluate our document layout analysis system. \nWe present three sub-components of our document layout analysis system. They are the text skew estimation, the word segmentation, and the object spatial analysis: \nThe text skew estimation finds the text skew angle of a document image. We develop an automatic text skew estimation algorithm using the recursive opening and closing transforms. It computes the estimated text skew angles which are within 0.5$\\sp\\circ$ of the true text skew angles with a probability of 0.95 on real images. \nThe word segmentation detects all the words on a document image. We describe a word segmentation algorithm that utilizes the recursive closing transform. We derive the quantitative measures, such as the rates of miss, false, correct, splitting, merging and spurious detections, to evaluate its performance. The results show that the algorithm correctly detects the words on a document image at a rate of about 95%. \nThe object spatial analysis treats the detected words as atomic and employs a probabilistic linear displacement model (PLDM) and an augmented PLDM model to model and extract the text lines and text blocks in a document image. By gathering statistics from a large population of document images, we are able to validate our models and determine the proper model parameters. The correct text line and text block detection rates are about 92% and 81% respectively."
            },
            "slug": "Document-layout-analysis-using-recursive-transforms-Chen",
            "title": {
                "fragments": [],
                "text": "Document layout analysis using recursive morphological transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The aim of this study is to apply solid statistical methods to systematically model and extract various layout structures on document images, such as words, text lines and text blocks, through the computation theory of the recursive morphological transforms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6826352,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebbbb7c50c5a5bc6f402230c8c77b83c83db4b48",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation of document images can be performed by projecting image pixels. This pixel projection approach is one of widely used top-down segmentation methods and is based on the assumption that the document image has been correctly deskewed. Unfortunately, the pixel projection approach is computationally inefficient. It is because each symbol is not treated as a computational unit. In this paper, we explain a new technique which is highly tactical in the profiling analysis. Instead of projecting image pixels, we first compute the bounding box of each connected component in a document image and then we project those bounding boxes. Using the new technique, this paper describes how to extract words, text lines, and text blocks (e.g., paragraphs). This bounding box projection approach has many advantages over the pixel projection approach. It is less computationally involved. When applied to text zones, it is also possible to infer from the projection profiles how bounding boxes (and, therefore, primitive symbols) are aligned and/or where significant horizontal and vertical gaps are present. Since the new technique manipulates only bounding boxes, it can be applied to any noncursive language documents."
            },
            "slug": "Document-page-decomposition-using-bounding-boxes-of-Ha-Phillips",
            "title": {
                "fragments": [],
                "text": "Document page decomposition using bounding boxes of connected components of black pixels"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper describes how to extract words, text lines, and text blocks (e.g., paragraphs) using a new technique which is highly tactical in the profiling analysis and has many advantages over the pixel projection approach."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13615381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d91e0d202fa23b7a2e81c5b3b04eb4cc5327b0f9",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs. The physical reader of the paper document is the scanner just like the physical reader of the floppy is the floppy drive and the physical reader of the tape cartridge is the tape cartridge drive, and the physical reader of the CDROM is the CDROM drive. In the survey presented, we restrict ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences. Understanding such documents involves estimating the rotation skew of each document page, determining the geometric page layout, labeling blocks as text or non-text, determining the read order for text blocks, recognizing the text of text blocks through an OCR system, determining the logical page layout, and formatting the data and information of the document in a suitable way for use by a word processing system or by an information retrieval system.<<ETX>>"
            },
            "slug": "Document-image-understanding:-geometric-and-logical-Haralick",
            "title": {
                "fragments": [],
                "text": "Document image understanding: geometric and logical layout"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs and restricts ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499975"
                        ],
                        "name": "J. Kanai",
                        "slug": "J.-Kanai",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Kanai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kanai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688357"
                        ],
                        "name": "S. V. Rice",
                        "slug": "S.-V.-Rice",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Rice",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. V. Rice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688975"
                        ],
                        "name": "T. Nartker",
                        "slug": "T.-Nartker",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Nartker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nartker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30733052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bd99ebf0bbe9a8513350d9eae4f3570c99d559b",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Many current optical character recognition (OCR) systems attempt to decompose printed pages into a set of zones, each containing a single column of text, before converting the characters into coded form. The authors present a methodology for automatically assessing the accuracy of such decompositions, and demonstrate its use in evaluating six OCR systems. >"
            },
            "slug": "Automated-Evaluation-of-OCR-Zoning-Kanai-Rice",
            "title": {
                "fragments": [],
                "text": "Automated Evaluation of OCR Zoning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A methodology for automatically assessing the accuracy of optical character recognition decompositions is presented, and its use in evaluating six OCR systems is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User's Reference Manual for the UW English/Technical Document Image Database III. UW-Ill English/Technical Document Image"
            },
            "venue": {
                "fragments": [],
                "text": "Database Manual,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Illuminator User's Manual"
            },
            "venue": {
                "fragments": [],
                "text": "Illuminator User's Manual"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DAFS: Document Attribute Format Speciication"
            },
            "venue": {
                "fragments": [],
                "text": "DAFS: Document Attribute Format Speciication"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Prototype of a Complete Document Understanding System"
            },
            "venue": {
                "fragments": [],
                "text": "IAPR Workshop on Document Analysis Systems,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User's Reference Manual for the UW English/Technical Document Image Database III. UW-III  English/Technical Document Image"
            },
            "venue": {
                "fragments": [],
                "text": "Database Manual,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Prototype of a Complete Document Understanding System. IAPR Workshop on Document Analysis Systems"
            },
            "venue": {
                "fragments": [],
                "text": "The Prototype of a Complete Document Understanding System. IAPR Workshop on Document Analysis Systems"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User's Reference Manual for the UW English/Technical Document Image Database III. UW-III English/Technical Document Image Database Manual"
            },
            "venue": {
                "fragments": [],
                "text": "User's Reference Manual for the UW English/Technical Document Image Database III. UW-III English/Technical Document Image Database Manual"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 13,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Performance-evaluation-of-document-layout-analysis-Liang-Phillips/e44015ab8d9ba89ac004421e3c56bcbeecbd0a47?sort=total-citations"
}