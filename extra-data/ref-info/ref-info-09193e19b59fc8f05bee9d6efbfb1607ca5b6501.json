{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40401747"
                        ],
                        "name": "Aur\u00e9lien Lucchi",
                        "slug": "Aur\u00e9lien-Lucchi",
                        "structuredName": {
                            "firstName": "Aur\u00e9lien",
                            "lastName": "Lucchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lien Lucchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145548651"
                        ],
                        "name": "Kevin Smith",
                        "slug": "Kevin-Smith",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118589"
                        ],
                        "name": "R. Achanta",
                        "slug": "R.-Achanta",
                        "structuredName": {
                            "firstName": "Radhakrishna",
                            "lastName": "Achanta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Achanta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144237098"
                        ],
                        "name": "G. Knott",
                        "slug": "G.-Knott",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Knott",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Knott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "The former approach uses haar-like features and texture histograms computed on a small region around the pixel of interest, whereas the latter uses sophisticated rotational [17] and ray [34] features computed on superpixels [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17867317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "637772da5a954a884bc6e62fd41584dbfb9a5ae5",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "It is becoming increasingly clear that mitochondria play an important role in neural function. Recent studies show mitochondrial morphology to be crucial to cellular physiology and synaptic function and a link between mitochondrial defects and neuro-degenerative diseases is strongly suspected. Electron microscopy (EM), with its very high resolution in all three directions, is one of the key tools to look more closely into these issues but the huge amounts of data it produces make automated analysis necessary. State-of-the-art computer vision algorithms designed to operate on natural 2-D images tend to perform poorly when applied to EM data for a number of reasons. First, the sheer size of a typical EM volume renders most modern segmentation schemes intractable. Furthermore, most approaches ignore important shape cues, relying only on local statistics that easily become confused when confronted with noise and textures inherent in the data. Finally, the conventional assumption that strong image gradients always correspond to object boundaries is violated by the clutter of distracting membranes. In this work, we propose an automated graph partitioning scheme that addresses these issues. It reduces the computational complexity by operating on supervoxels instead of voxels, incorporates shape features capable of describing the 3-D shape of the target objects, and learns to recognize the distinctive appearance of true boundaries. Our experiments demonstrate that our approach is able to segment mitochondria at a performance level close to that of a human annotator, and outperforms a state-of-the-art 3-D segmentation technique."
            },
            "slug": "Supervoxel-Based-Segmentation-of-Mitochondria-in-EM-Lucchi-Smith",
            "title": {
                "fragments": [],
                "text": "Supervoxel-Based Segmentation of Mitochondria in EM Image Stacks With Learned Shape Features"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes an automated graph partitioning scheme that is able to segment mitochondria at a performance level close to that of a human annotator, and outperforms a state-of-the-art 3-D segmentation technique."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Medical Imaging"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2129065"
                        ],
                        "name": "V. Kaynig",
                        "slug": "V.-Kaynig",
                        "structuredName": {
                            "firstName": "Verena",
                            "lastName": "Kaynig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kaynig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34459632"
                        ],
                        "name": "Thomas J. Fuchs",
                        "slug": "Thomas-J.-Fuchs",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Fuchs",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas J. Fuchs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "We compute pixel probabilities only (point (a) above), and directly obtain a segmentation by mild smoothing and thresholding, without using graph cuts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15668169,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24f1765f3588ec70f56cec41714dfde60d74750f",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In the field of neuroanatomy, automatic segmentation of electron microscopy images is becoming one of the main limiting factors in getting new insights into the functional structure of the brain. We propose a novel framework for the segmentation of thin elongated structures like membranes in a neuroanatomy setting. The probability output of a random forest classifier is used in a regular cost function, which enforces gap completion via perceptual grouping constraints. The global solution is efficiently found by graph cut optimization. We demonstrate substantial qualitative and quantitative improvement over state-of the art segmentations on two considerably different stacks of ssTEM images as well as in segmentations of streets in satellite imagery. We demonstrate that the superior performance of our method yields fully automatic 3D reconstructions of dendrites from ssTEM data."
            },
            "slug": "Neuron-geometry-extraction-by-perceptual-grouping-Kaynig-Fuchs",
            "title": {
                "fragments": [],
                "text": "Neuron geometry extraction by perceptual grouping in ssTEM images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a novel framework for the segmentation of thin elongated structures like membranes in a neuroanatomy setting using the probability output of a random forest classifier in a regular cost function, which enforces gap completion via perceptual grouping constraints."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542296"
                        ],
                        "name": "L. Kamentsky",
                        "slug": "L.-Kamentsky",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Kamentsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kamentsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "Preliminary results in this direction are encouraging: the problem-specific postprocessing techniques in [20] and [24], operating on our segmentation, reduce the Rand error to measure to 36\u00b710\u22123 and 32\u00b710\u22123, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61573213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66fcdcefd643dff76cc34c1f1b07990fc0279942",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "CellProfiler is a flexible, open-source tool designed to analyze microscopy images. CellProfiler's primary focus is on analysis of fluorescently labeled cells, but it can be adapted to other uses. This poster describes the analysis of the ISBI 2012 EM challenge images using CellProfiler in conjunction with custom software written for the challenge. The images are first scored with a custom pixel-based classifier trained on the ground truth. This scoring is then used as the input for CellProfiler. I first identify potential centers within tissue surrounded by membrane, and then grow these using a seeded watershed. Finally, I use a module that was custom-designed for the challenge to clean up artifacts in the resulting segmentation. The CellProfiler EM Challenge entry demonstrates techniques for analyzing neuronal structures. It also demonstrates how CellProfiler can be used as an algorithm development platform. CellProfiler can run ImageJ and ImageJ 2.0 plugins written in Java as well as native modules written in Python. An analysis method can be distributed as a CellProfiler pipeline, contributing to the reproducibility and documentation of the method and allowing researchers to easily integrate both their algorithms and others to arrive at a production-quality and scale solution."
            },
            "slug": "Segmentation-of-EM-Images-of-Neuronal-Structures-Kamentsky",
            "title": {
                "fragments": [],
                "text": "Segmentation of EM Images of Neuronal Structures Using CellProfiler"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The analysis of the ISBI 2012 EM challenge images is described using CellProfiler in conjunction with custom software written for the challenge, and techniques for analyzing neuronal structures are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145844120"
                        ],
                        "name": "A. Cardona",
                        "slug": "A.-Cardona",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cardona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cardona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889009"
                        ],
                        "name": "S. Saalfeld",
                        "slug": "S.-Saalfeld",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Saalfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Saalfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8614408"
                        ],
                        "name": "S. Preibisch",
                        "slug": "S.-Preibisch",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Preibisch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Preibisch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10182247"
                        ],
                        "name": "Benjamin Schmid",
                        "slug": "Benjamin-Schmid",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145875167"
                        ],
                        "name": "A. Cheng",
                        "slug": "A.-Cheng",
                        "structuredName": {
                            "firstName": "Anchi",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2437532"
                        ],
                        "name": "J. Pulokas",
                        "slug": "J.-Pulokas",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Pulokas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pulokas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2931840"
                        ],
                        "name": "P. Toman\u00e7ak",
                        "slug": "P.-Toman\u00e7ak",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Toman\u00e7ak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Toman\u00e7ak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2204140"
                        ],
                        "name": "V. Hartenstein",
                        "slug": "V.-Hartenstein",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Hartenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hartenstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "We validate our approach on the publicly-available dataset [9] provided by the organizers of the ISBI 2012 EM Segmentation Challenge [1], which represents two portions of the ventral nerve cord of a Drosophila larva."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9086006,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3874df6410a20b1d7ba7091d596398f72bcb93cf",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "The analysis of microcircuitry (the connectivity at the level of individual neuronal processes and synapses), which is indispensable for our understanding of brain function, is based on serial transmission electron microscopy (TEM) or one of its modern variants. Due to technical limitations, most previous studies that used serial TEM recorded relatively small stacks of individual neurons. As a result, our knowledge of microcircuitry in any nervous system is very limited. We applied the software package TrakEM2 to reconstruct neuronal microcircuitry from TEM sections of a small brain, the early larval brain of Drosophila melanogaster. TrakEM2 enables us to embed the analysis of the TEM image volumes at the microcircuit level into a light microscopically derived neuro-anatomical framework, by registering confocal stacks containing sparsely labeled neural structures with the TEM image volume. We imaged two sets of serial TEM sections of the Drosophila first instar larval brain neuropile and one ventral nerve cord segment, and here report our first results pertaining to Drosophila brain microcircuitry. Terminal neurites fall into a small number of generic classes termed globular, varicose, axiform, and dendritiform. Globular and varicose neurites have large diameter segments that carry almost exclusively presynaptic sites. Dendritiform neurites are thin, highly branched processes that are almost exclusively postsynaptic. Due to the high branching density of dendritiform fibers and the fact that synapses are polyadic, neurites are highly interconnected even within small neuropile volumes. We describe the network motifs most frequently encountered in the Drosophila neuropile. Our study introduces an approach towards a comprehensive anatomical reconstruction of neuronal microcircuitry and delivers microcircuitry comparisons between vertebrate and insect neuropile."
            },
            "slug": "An-Integrated-Micro-and-Macroarchitectural-Analysis-Cardona-Saalfeld",
            "title": {
                "fragments": [],
                "text": "An Integrated Micro- and Macroarchitectural Analysis of the Drosophila Brain by Computer-Assisted Serial Section Electron Microscopy"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This study applies the software package TrakEM2 to reconstruct neuronal microcircuitry from TEM sections of a small brain, the early larval brain of Drosophila melanogaster, and describes the network motifs most frequently encountered in the Drosophile neuropile."
            },
            "venue": {
                "fragments": [],
                "text": "PLoS biology"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2129065"
                        ],
                        "name": "V. Kaynig",
                        "slug": "V.-Kaynig",
                        "structuredName": {
                            "firstName": "Verena",
                            "lastName": "Kaynig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kaynig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34459632"
                        ],
                        "name": "Thomas J. Fuchs",
                        "slug": "Thomas-J.-Fuchs",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Fuchs",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas J. Fuchs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "The former approach uses haar-like features and texture histograms computed on a small region around the pixel of interest, whereas the latter uses sophisticated rotational [17] and ray [34] features computed on superpixels [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32113183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecfc5d6f23d614f6789442519970db2c0d90363d",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In neuroanatomy, automatic geometry extraction of neurons from electron microscopy images is becoming one of the main limiting factors in getting new insights into the functional structure of the brain. We propose a novel framework for tracing neuronal processes over serial sections for 3d reconstructions. The automatic processing pipeline combines the probabilistic output of a random forest classifier with geometrical consistency constraints which take the geometry of whole sections into account. Our experiments demonstrate significant improvement over grouping by Euclidean distance, reducing the split and merge error per object by a factor of two."
            },
            "slug": "Geometrical-Consistent-3D-Tracing-of-Neuronal-in-Kaynig-Fuchs",
            "title": {
                "fragments": [],
                "text": "Geometrical Consistent 3D Tracing of Neuronal Processes in ssTEM Data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel framework for tracing neuronal processes over serial sections for 3d reconstructions is proposed which combines the probabilistic output of a random forest classifier with geometrical consistency constraints which take the geometry of whole sections into account."
            },
            "venue": {
                "fragments": [],
                "text": "MICCAI"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723587"
                        ],
                        "name": "Radim Burget",
                        "slug": "Radim-Burget",
                        "structuredName": {
                            "firstName": "Radim",
                            "lastName": "Burget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radim Burget"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1856510"
                        ],
                        "name": "V. Uher",
                        "slug": "V.-Uher",
                        "structuredName": {
                            "firstName": "V\u00e1clav",
                            "lastName": "Uher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Uher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35207995"
                        ],
                        "name": "J. Masek",
                        "slug": "J.-Masek",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Masek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Masek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29276976,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3f116cdf6f1a8441ec46df5c4a34d42d6749331",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with the segmentation of neuronal structures in electron microscope (EM) stacks, which is one of the challenges of the ISBI 2012 conference. The data for the challenge consists of a stack of 30 EM slices for training and 30 EM stacks for testing. The training data was labelled by an expert human neuroanatomist. In this paper a segmentation using local-level and segment-level features and machine learning algorithms was used. The results achieved on the ISBI 2012 challenge test set were: the Rand error: 0.139038440, warping error: 0.002641296 and pixel error: 0.102285508. The main criterion for segmentation evaluation was the Rand error."
            },
            "slug": "Trainable-Segmentation-Based-on-Local-level-and-Burget-Uher",
            "title": {
                "fragments": [],
                "text": "Trainable Segmentation Based on Local-level and Segment-level Feature Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A segmentation using local-level and segment-level features and machine learning algorithms was used for segmentation of neuronal structures in EM stacks, which is one of the challenges of the ISBI 2012 conference."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "DNN are inspired by convolutional neural networks introduced in 1980 [16], improved in the 1990s [25], refined and simplified in the 2000s [5, 33], and brought to their full potential by making them both large and deep [12, 13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Lately, DNN proved their efficiency on data sets extending from handwritten digits (MNIST) [10, 12], handwritten characters [11] to 3D toys (NORB) [13] and faces [35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our solution is based on a Deep Neural Network (DNN) [12, 13] used as a pixel classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A DNN [13] consists of a succession of convolutional, max-pooling and fully connected layers."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2161592,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "398c296d0cc7f9d180f84969f8937e6d3a413796",
            "isKey": false,
            "numCitedBy": 3369,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks."
            },
            "slug": "Multi-column-deep-neural-networks-for-image-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "Multi-column deep neural networks for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "On the very competitive MNIST handwriting benchmark, this method is the first to achieve near-human performance and improves the state-of-the-art on a plethora of common image classification benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35571193"
                        ],
                        "name": "D. Bock",
                        "slug": "D.-Bock",
                        "structuredName": {
                            "firstName": "Davi",
                            "lastName": "Bock",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004120"
                        ],
                        "name": "W. Lee",
                        "slug": "W.-Lee",
                        "structuredName": {
                            "firstName": "Wei-Chung",
                            "lastName": "Lee",
                            "middleNames": [
                                "Allen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3571452"
                        ],
                        "name": "A. Kerlin",
                        "slug": "A.-Kerlin",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Kerlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kerlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2344727"
                        ],
                        "name": "M. Andermann",
                        "slug": "M.-Andermann",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Andermann",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143810605"
                        ],
                        "name": "Greg Hood",
                        "slug": "Greg-Hood",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Hood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Hood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34657092"
                        ],
                        "name": "A. Wetzel",
                        "slug": "A.-Wetzel",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Wetzel",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wetzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145215627"
                        ],
                        "name": "S. Yurgenson",
                        "slug": "S.-Yurgenson",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Yurgenson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yurgenson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4210225"
                        ],
                        "name": "E. Soucy",
                        "slug": "E.-Soucy",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Soucy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Soucy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109023915"
                        ],
                        "name": "Hyon Suk Kim",
                        "slug": "Hyon-Suk-Kim",
                        "structuredName": {
                            "firstName": "Hyon",
                            "lastName": "Kim",
                            "middleNames": [
                                "Suk"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyon Suk Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46567235"
                        ],
                        "name": "R. Reid",
                        "slug": "R.-Reid",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Reid",
                            "middleNames": [
                                "Clay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Reid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "Our solution is based on a Deep Neural Network (DNN) [12, 13] used as a pixel classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4412010,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "124dabf0da002ec1aa44eabd3885cd80873d304c",
            "isKey": false,
            "numCitedBy": 803,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "In the cerebral cortex, local circuits consist of tens of thousands of neurons, each of which makes thousands of synaptic connections. Perhaps the biggest impediment to understanding these networks is that we have no wiring diagrams of their interconnections. Even if we had a partial or complete wiring diagram, however, understanding the network would also require information about each neuron's function. Here we show that the relationship between structure and function can be studied in the cortex with a combination of in vivo physiology and network anatomy. We used two-photon calcium imaging to characterize a functional property\u2014the preferred stimulus orientation\u2014of a group of neurons in the mouse primary visual cortex. Large-scale electron microscopy of serial thin sections was then used to trace a portion of these neurons\u2019 local network. Consistent with a prediction from recent physiological experiments, inhibitory interneurons received convergent anatomical input from nearby excitatory neurons with a broad range of preferred orientations, although weak biases could not be rejected."
            },
            "slug": "Network-anatomy-and-in-vivo-physiology-of-visual-Bock-Lee",
            "title": {
                "fragments": [],
                "text": "Network anatomy and in vivo physiology of visual cortical neurons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work used two-photon calcium imaging to characterize a functional property\u2014the preferred stimulus orientation\u2014of a group of neurons in the mouse primary visual cortex and large-scale electron microscopy of serial thin sections was used to trace a portion of these neurons\u2019 local network."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40401747"
                        ],
                        "name": "Aur\u00e9lien Lucchi",
                        "slug": "Aur\u00e9lien-Lucchi",
                        "structuredName": {
                            "firstName": "Aur\u00e9lien",
                            "lastName": "Lucchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lien Lucchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145548651"
                        ],
                        "name": "Kevin Smith",
                        "slug": "Kevin-Smith",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118589"
                        ],
                        "name": "R. Achanta",
                        "slug": "R.-Achanta",
                        "structuredName": {
                            "firstName": "Radhakrishna",
                            "lastName": "Achanta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Achanta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689738"
                        ],
                        "name": "V. Lepetit",
                        "slug": "V.-Lepetit",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Lepetit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lepetit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "The former approach uses haar-like features and texture histograms computed on a small region around the pixel of interest, whereas the latter uses sophisticated rotational [17] and ray [34] features computed on superpixels [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16766181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1faf917f4f7388a63957d065607cdc706a7d2879",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "While there has been substantial progress in segmenting natural images, state-of-the-art methods that perform well in such tasks unfortunately tend to underperform when confronted with the different challenges posed by electron microscope (EM) data. For example, in EM imagery of neural tissue, numerous cells and subcellular structures appear within a single image, they exhibit irregular shapes that cannot be easily modeled by standard techniques, and confusing textures clutter the background. We propose a fully automated approach that handles these challenges by using sophisticated cues that capture global shape and texture information, and by learning the specific appearance of object boundaries. We demonstrate that our approach significantly outperforms state-of-the-art techniques and closely matches the performance of human annotators."
            },
            "slug": "A-Fully-Automated-Approach-to-Segmentation-of-in-EM-Lucchi-Smith",
            "title": {
                "fragments": [],
                "text": "A Fully Automated Approach to Segmentation of Irregularly Shaped Cellular Structures in EM Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a fully automated approach that handles EM imagery of neural tissue challenges by using sophisticated cues that capture global shape and texture information, and by learning the specific appearance of object boundaries."
            },
            "venue": {
                "fragments": [],
                "text": "MICCAI"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206775608,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "69e68bfaadf2dccff800158749f5a50fe82d173b",
            "isKey": false,
            "numCitedBy": 3717,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname \u201cneocognitron\u201d. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of \u201cS-cells\u201d, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of \u201cC-cells\u201d similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any \u201cteacher\u201d during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern."
            },
            "slug": "Neocognitron:-A-self-organizing-neural-network-for-Fukushima",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A neural network model for a mechanism of visual pattern recognition that is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity of their shapes without affected by their positions."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2857272"
                        ],
                        "name": "Erhan Bas",
                        "slug": "Erhan-Bas",
                        "structuredName": {
                            "firstName": "Erhan",
                            "lastName": "Bas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erhan Bas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149919"
                        ],
                        "name": "M. G. Uzunbas",
                        "slug": "M.-G.-Uzunbas",
                        "structuredName": {
                            "firstName": "Mustafa",
                            "lastName": "Uzunbas",
                            "middleNames": [
                                "G\u00f6khan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. G. Uzunbas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082029696"
                        ],
                        "name": "Dimitris Metaxsas",
                        "slug": "Dimitris-Metaxsas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxsas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris Metaxsas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145910"
                        ],
                        "name": "E. Myers",
                        "slug": "E.-Myers",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Myers",
                            "middleNames": [
                                "Wimberly"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Myers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7909459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c939086c9f779417f7a60b8bdad397d4338b019",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to extract useful information from EM images, such as segmentation, it is compulsory to characterize regions structurally, as well as contextually. For that reason, we propose a multistage decision mechanism that utilizes underlying differential geometric properties of objects in a biologically inherited framework. Consequently, we start with an initial feature selection procedure to select most relevant features to characterize distinct regions, such as membrane, cytoplasm and outliers. Similar to a topographic map, a random-forest classifier is employed to highlight mountain ridge like structures, e.g. membranes as well as plateaus, e.g. cytoplasm. In order to extract the underlying geometry of structures on this topographic map, especially membrane like structures, principal surface analysis is utilized. This unsupervised technique returns highly sparse yet accurate low dimensional representation of the data and especially characterizes membrane like regions. A task specific, second stage decision mechanism is employed to distinguish contextually different mitochondria and cell boundary membranes. This second stage learning/decision mechanism is based on the appearance, the initial topographic map with its low dimensional reconstruction and expert supervision on different types of membranes. Initial results on individual EM slices indicate that the proposed approach can successfully segment objects with minimal expert supervision and can potentially form a basis for a larger scale volumetric data interpretation."
            },
            "slug": "Contextual-grouping-in-a-concept-:-a-multistage-for-Bas-Uzunbas",
            "title": {
                "fragments": [],
                "text": "Contextual grouping in a concept : a multistage decision strategy for EM segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Initial results on individual EM slices indicate that the proposed approach can successfully segment objects with minimal expert supervision and can potentially form a basis for a larger scale volumetric data interpretation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35086944"
                        ],
                        "name": "Viren Jain",
                        "slug": "Viren-Jain",
                        "structuredName": {
                            "firstName": "Viren",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Viren Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079916962"
                        ],
                        "name": "Benjamin Bollmann",
                        "slug": "Benjamin-Bollmann",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Bollmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Bollmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057490461"
                        ],
                        "name": "Mark Richardson",
                        "slug": "Mark-Richardson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Richardson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35725792"
                        ],
                        "name": "Daniel R. Berger",
                        "slug": "Daniel-R.-Berger",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Berger",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel R. Berger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2495450"
                        ],
                        "name": "M. Helmstaedter",
                        "slug": "M.-Helmstaedter",
                        "structuredName": {
                            "firstName": "Moritz",
                            "lastName": "Helmstaedter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Helmstaedter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997979"
                        ],
                        "name": "K. Briggman",
                        "slug": "K.-Briggman",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Briggman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Briggman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922222"
                        ],
                        "name": "W. Denk",
                        "slug": "W.-Denk",
                        "structuredName": {
                            "firstName": "Winfried",
                            "lastName": "Denk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Denk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33483716"
                        ],
                        "name": "Jared B. Bowden",
                        "slug": "Jared-B.-Bowden",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Bowden",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jared B. Bowden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10055492"
                        ],
                        "name": "J. Mendenhall",
                        "slug": "J.-Mendenhall",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Mendenhall",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mendenhall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37404109"
                        ],
                        "name": "W. Abraham",
                        "slug": "W.-Abraham",
                        "structuredName": {
                            "firstName": "Wickliffe",
                            "lastName": "Abraham",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Abraham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143943612"
                        ],
                        "name": "K. Harris",
                        "slug": "K.-Harris",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Harris",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48299334"
                        ],
                        "name": "N. Kasthuri",
                        "slug": "N.-Kasthuri",
                        "structuredName": {
                            "firstName": "Narayanan",
                            "lastName": "Kasthuri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kasthuri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2914957"
                        ],
                        "name": "K. Hayworth",
                        "slug": "K.-Hayworth",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Hayworth",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hayworth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2307736"
                        ],
                        "name": "R. Schalek",
                        "slug": "R.-Schalek",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schalek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schalek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144338628"
                        ],
                        "name": "J. Tapia",
                        "slug": "J.-Tapia",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Tapia",
                            "middleNames": [
                                "Carlos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tapia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27103730"
                        ],
                        "name": "J. Lichtman",
                        "slug": "J.-Lichtman",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Lichtman",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lichtman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "Warping error: a segmentation metric designed to account for topological disagreements [19]; it accounts for the number of neuron splits and mergers required to obtain the candidate segmentation from ground truth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14331637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8f6abd8794269194119f6e129012b8d4c94371d",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent studies have shown that machine learning can improve the accuracy of detecting object boundaries in images. In the standard approach, a boundary detector is trained by minimizing its pixel-level disagreement with human boundary tracings. This naive metric is problematic because it is overly sensitive to boundary locations. This problem is solved by metrics provided with the Berkeley Segmentation Dataset, but these can be insensitive to topo-logical differences, such as gaps in boundaries. Furthermore, the Berkeley metrics have not been useful as cost functions for supervised learning. Using concepts from digital topology, we propose a new metric called the warping error that tolerates disagreements over boundary location, penalizes topological disagreements, and can be used directly as a cost function for learning boundary detection, in a method that we call Boundary Learning by Optimization with Topological Constraints (BLOTC). We trained boundary detectors on electron microscopic images of neurons, using both BLOTC and standard training. BLOTC produced substantially better performance on a 1.2 million pixel test set, as measured by both the warping error and the Rand index evaluated on segmentations generated from the boundary labelings. We also find our approach yields significantly better segmentation performance than either gPb-OWT-UCM or multiscale normalized cut, as well as Boosted Edge Learning trained directly on our data."
            },
            "slug": "Boundary-Learning-by-Optimization-with-Topological-Jain-Bollmann",
            "title": {
                "fragments": [],
                "text": "Boundary Learning by Optimization with Topological Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a new metric called the warping error that tolerates disagreements over boundary location, penalizes topological disagreements, and can be used directly as a cost function for learning boundary detection, in a method that it is called Boundary Learning by Optimization with Topological Constraints (BLOTC)."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6803671"
                        ],
                        "name": "L. Gambardella",
                        "slug": "L.-Gambardella",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Gambardella",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our fast GPU implementation [10, 12] overcomes this problem, speeding up single-threaded CPU code by up to two orders of magnitude."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A GPU implementation [12] accelerates the forward propagation and back propagation routines by a factor of 50."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our solution is based on a Deep Neural Network (DNN) [12, 13] used as a pixel classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Lately, DNN proved their efficiency on data sets extending from handwritten digits (MNIST) [10, 12], handwritten characters [11] to 3D toys (NORB) [13] and faces [35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "DNN are inspired by convolutional neural networks introduced in 1980 [16], improved in the 1990s [25], refined and simplified in the 2000s [5, 33], and brought to their full potential by making them both large and deep [12, 13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 904144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a47ba057a858f8c024d2518cc3731fc7eb40de1",
            "isKey": false,
            "numCitedBy": 1169,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs, respectively."
            },
            "slug": "Flexible,-High-Performance-Convolutional-Neural-for-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "Flexible, High Performance Convolutional Neural Networks for Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A fast, fully parameterizable GPU implementation of Convolutional Neural Network variants and their feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765794"
                        ],
                        "name": "Germ\u00e1n Gonz\u00e1lez",
                        "slug": "Germ\u00e1n-Gonz\u00e1lez",
                        "structuredName": {
                            "firstName": "Germ\u00e1n",
                            "lastName": "Gonz\u00e1lez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Germ\u00e1n Gonz\u00e1lez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2721983"
                        ],
                        "name": "F. Fleuret",
                        "slug": "F.-Fleuret",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Fleuret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fleuret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Feature selection mirrors the researcher\u2019s expectation of which characteristics of the image are relevant for classification, and has a large impact on classification accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2456027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90b19d2807bfd9fcb2d752b54775d6de400d3105",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art approaches for detecting filament-like structures in noisy images rely on filters optimized for signals of a particular shape, such as an ideal edge or ridge. While these approaches are optimal when the image conforms to these ideal shapes, their performance quickly degrades on many types of real data where the image deviates from the ideal model, and when noise processes violate a Gaussian assumption. In this paper, we show that by learning rotational features, we can outperform state-of-the-art filament detection techniques on many different kinds of imagery. More specifically, we demonstrate superior performance for the detection of blood vessel in retinal scans, neurons in brightfield microscopy imagery, and streets in satellite imagery."
            },
            "slug": "Learning-rotational-features-for-filament-detection-Gonz\u00e1lez-Fleuret",
            "title": {
                "fragments": [],
                "text": "Learning rotational features for filament detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that by learning rotational features, this work can outperform state-of-the-art filament detection techniques on many different kinds of imagery."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996960"
                        ],
                        "name": "M. Riesenhuber",
                        "slug": "M.-Riesenhuber",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Riesenhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riesenhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 101
                            }
                        ],
                        "text": "The biggest architectural difference between the our DNN and earlier CNN [25] are max-pooling layers [30, 32, 31] instead of sub-sampling layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8920227,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "85abadb689897997f1e37baa7b5fc6f7d497518b",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function."
            },
            "slug": "Hierarchical-models-of-object-recognition-in-cortex-Riesenhuber-Poggio",
            "title": {
                "fragments": [],
                "text": "Hierarchical models of object recognition in cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions is described."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38767254"
                        ],
                        "name": "David Steinkraus",
                        "slug": "David-Steinkraus",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Steinkraus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Steinkraus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "Lately, DNN proved their efficiency on data sets extending from handwritten digits (MNIST) [10, 12], handwritten characters [11] to 3D toys (NORB) [13] and faces [35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4659176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5562a56da3a96dae82add7de705e2bd841eb00fc",
            "isKey": false,
            "numCitedBy": 2432,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are a powerful technology forclassification of visual inputs arising from documents.However, there is a confusing plethora of different neuralnetwork methods that are used in the literature and inindustry. This paper describes a set of concrete bestpractices that document analysis researchers can use toget good results with neural networks. The mostimportant practice is getting a training set as large aspossible: we expand the training set by adding a newform of distorted data. The next most important practiceis that convolutional neural networks are better suited forvisual document tasks than fully connected networks. Wepropose that a simple \"do-it-yourself\" implementation ofconvolution with a flexible architecture is suitable formany visual document problems. This simpleconvolutional neural network does not require complexmethods, such as momentum, weight decay, structure-dependentlearning rates, averaging layers, tangent prop,or even finely-tuning the architecture. The end result is avery simple yet general architecture which can yieldstate-of-the-art performance for document analysis. Weillustrate our claims on the MNIST set of English digitimages."
            },
            "slug": "Best-practices-for-convolutional-neural-networks-to-Simard-Steinkraus",
            "title": {
                "fragments": [],
                "text": "Best practices for convolutional neural networks applied to visual document analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A set of concrete bestpractices that document analysis researchers can use to get good results with neural networks, including a simple \"do-it-yourself\" implementation of convolution with a flexible architecture suitable for many visual document problems."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 224
                            }
                        ],
                        "text": "DNN are inspired by convolutional neural networks introduced in 1980 [16], improved in the 1990s [25], refined and simplified in the 2000s [5, 33], and brought to their full potential by making them both large and deep [12, 13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35260,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145548651"
                        ],
                        "name": "Kevin Smith",
                        "slug": "Kevin-Smith",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1946668"
                        ],
                        "name": "A. Carleton",
                        "slug": "A.-Carleton",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Carleton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Carleton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689738"
                        ],
                        "name": "V. Lepetit",
                        "slug": "V.-Lepetit",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Lepetit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lepetit"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Feature selection mirrors the researcher\u2019s expectation of which characteristics of the image are relevant for classification, and has a large impact on classification accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 943371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55327a1f45f27f34f58858b4a45a94cc01ced887",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new class of image features, the Ray feature set, that consider image characteristics at distant contour points, capturing information which is difficult to represent with standard feature sets. This property allows Ray features to efficiently and robustly recognize deformable or irregular shapes, such as cells in microscopic imagery. Experiments show Ray features clearly outperform other powerful features including Haar-like features and Histograms of Oriented Gradients when applied to detecting irregularly shaped neuron nuclei and mitochondria. Ray features can also provide important complementary information to Haar features for other tasks such as face detection, reducing the number of weak learners and computational cost. Ray features can be efficiently precomputed to reduce cost, just as precomputing integral images reduces the overall cost of Haar features. While Rays are slightly more expensive to precompute, their computational cost is less than that of Haar features for scanning an AdaBoost-based detector window across an image at run-time."
            },
            "slug": "Fast-Ray-features-for-learning-irregular-shapes-Smith-Carleton",
            "title": {
                "fragments": [],
                "text": "Fast Ray features for learning irregular shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A new class of image features, the Ray feature set, that consider image characteristics at distant contour points, capturing information which is difficult to represent with standard feature sets, allowing them to efficiently and robustly recognize deformable or irregular shapes."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230605"
                        ],
                        "name": "Daniel Strigl",
                        "slug": "Daniel-Strigl",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Strigl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Strigl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094229001"
                        ],
                        "name": "Klaus Kofler",
                        "slug": "Klaus-Kofler",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Kofler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus Kofler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828543"
                        ],
                        "name": "Stefan Podlipnig",
                        "slug": "Stefan-Podlipnig",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Podlipnig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Podlipnig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Training huge nets requires months or even years on CPUs, where high data transfer latency prevented multi-threading code from saving the situation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13377478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "687a0ce2ec2711ef206e2486cd56d192a88b3145",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present the implementation of a framework for accelerating training and classification of arbitrary Convolutional Neural Networks (CNNs) on the GPU. CNNs are a derivative of standard Multilayer Perceptron (MLP) neural networks optimized for two-dimensional pattern recognition problems such as Optical Character Recognition (OCR) or face detection. We describe the basic parts of a CNN and demonstrate the performance and scalability improvement that can be achieved by shifting the computation-intensive tasks of a CNN to the GPU. Depending on the network topology training and classification on the GPU performs 2 to 24 times faster than on the CPU. Furthermore, the GPU version scales much better than the CPU implementation with respect to the network size."
            },
            "slug": "Performance-and-Scalability-of-GPU-Based-Neural-Strigl-Kofler",
            "title": {
                "fragments": [],
                "text": "Performance and Scalability of GPU-Based Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents the implementation of a framework for accelerating training and classification of arbitrary Convolutional Neural Networks (CNNs) on the GPU and describes the basic parts of a CNN and demonstrates the performance and scalability improvement that can be achieved by shifting the computation-intensive tasks of aCNN to the GPU."
            },
            "venue": {
                "fragments": [],
                "text": "2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128145"
                        ],
                        "name": "Lior Wolf",
                        "slug": "Lior-Wolf",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lior Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 101
                            }
                        ],
                        "text": "The biggest architectural difference between the our DNN and earlier CNN [25] are max-pooling layers [30, 32, 31] instead of sub-sampling layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 260426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "040c23e5a409fbdedd5032263dfcb1a4d7dfd200",
            "isKey": false,
            "numCitedBy": 969,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex."
            },
            "slug": "Object-recognition-with-features-inspired-by-visual-Serre-Wolf",
            "title": {
                "fragments": [],
                "text": "Object recognition with features inspired by visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex and exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4477577"
                        ],
                        "name": "C. Curcio",
                        "slug": "C.-Curcio",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Curcio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Curcio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2752927"
                        ],
                        "name": "K. Sloan",
                        "slug": "K.-Sloan",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Sloan",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sloan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5262673"
                        ],
                        "name": "R. E. Kalina",
                        "slug": "R.-E.-Kalina",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Kalina",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. E. Kalina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87661583"
                        ],
                        "name": "A. Hendrickson",
                        "slug": "A.-Hendrickson",
                        "structuredName": {
                            "firstName": "Anita",
                            "lastName": "Hendrickson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hendrickson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "Foveation is inspired by the structure of human photoreceptor topography [14], and has recently been shown to be very effective for improving nonlocal-means denoising algorithms [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24649779,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "ee24543a48176deb824a64f0dd7bec2a35b0ff29",
            "isKey": false,
            "numCitedBy": 2329,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "We have measured the spatial density of cones and rods in eight wholemounted human retinas, obtained from seven individuals between 27 and 44 years of age, and constructed maps of photoreceptor density and between\u2010individual variability. The average human retina contains 4.6 million cones (4.08\u20135.29 million). Peak foveal cone density averages 199,000 cones/mm2 and is highly variable between individuals (100,000\u2013324,000 cones/mm2). The point of highest density may be found in an area as large as 0.032 deg2. Cone density falls steeply with increasing eccentricity and is an order of magnitude lower 1 mm away from the foveal center. Superimposed on this gradient is a streak of high cone density along the horizontal meridian. At equivalent eccentricities, cone density is 40\u201345% higher in nasal compared to temporal retina and slightly higher in midperipheral inferior compared to superior retina. Cone density also increases slightly in far nasal retina. The average human retina contains 92 million rods (77.9\u2013107.3 million). In the fovea, the average horizontal diameter of the rod\u2010free zone is 0.350 mm (1.25\u00b0). Foveal rod density increases most rapidly superiorly and least rapidly nasally. The highest rod densities are located along an elliptical ring at the eccentricity of the optic disk and extending into nasal retina with the point of highest density typically in superior retina (5/6 eyes). Rod densities decrease by 15\u201325% where the ring crosses the horizontal meridian. Rod density declines slowly from the rod ring to the far periphery and is highest in nasal and superior retina. Individual variability in photoreceptor density differs with retinal region and is similar for both cones and rods. Variability is highest near the fovea, reaches a minimum in the midperiphery, and then increases with eccentricity to the ora serrata. The total number of foveal cones is similar for eyes with widely varying peak cone density, consistent with the idea that the variability reflects differences in the lateral migration of photoreceptors during development. Two fellow eyes had cone and rod numbers within 8% and similar but not identical photoreceptor topography."
            },
            "slug": "Human-photoreceptor-topography-Curcio-Sloan",
            "title": {
                "fragments": [],
                "text": "Human photoreceptor topography"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The total number of foveal cones is similar for eyes with widely varying peak cone density, consistent with the idea that the variability reflects differences in the lateral migration of photoreceptors during development."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of comparative neurology"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118589"
                        ],
                        "name": "R. Achanta",
                        "slug": "R.-Achanta",
                        "structuredName": {
                            "firstName": "Radhakrishna",
                            "lastName": "Achanta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Achanta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2863792"
                        ],
                        "name": "Appu Shaji",
                        "slug": "Appu-Shaji",
                        "structuredName": {
                            "firstName": "Appu",
                            "lastName": "Shaji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Appu Shaji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145548651"
                        ],
                        "name": "Kevin Smith",
                        "slug": "Kevin-Smith",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40401747"
                        ],
                        "name": "Aur\u00e9lien Lucchi",
                        "slug": "Aur\u00e9lien-Lucchi",
                        "structuredName": {
                            "firstName": "Aur\u00e9lien",
                            "lastName": "Lucchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lien Lucchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735035"
                        ],
                        "name": "S. S\u00fcsstrunk",
                        "slug": "S.-S\u00fcsstrunk",
                        "structuredName": {
                            "firstName": "Sabine",
                            "lastName": "S\u00fcsstrunk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S\u00fcsstrunk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "Feature selection mirrors the researcher\u2019s expectation of which characteristics of the image are relevant for classification, and has a large impact on classification accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15415288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3913ef72439e5605251ced2a71f7df41072d5bf",
            "isKey": false,
            "numCitedBy": 646,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Superpixels are becoming increasingly popular for use in computer vision applications. However, there are few algorithms that output a desired number of regular, compact superpixels with a low computational overhead. We introduce a novel algorithm that clusters pixels in the combined five-dimensional color and image plane space to efficiently generate compact, nearly uniform superpixels. The simplicity of our approach makes it extremely easy to use \u2013 a lone parameter specifies the number of superpixels \u2013 and the efficiency of the algorithm makes it very practical. Experiments show that our approach produces superpixels at a lower computational cost while achieving a segmentation quality equal to or greater than four state-of-the-art methods, as measured by boundary recall and under-segmentation error. We also demonstrate the benefits of our superpixel approach in contrast to existing methods for two tasks in which superpixels have already been shown to increase performance over pixel-based methods."
            },
            "slug": "SLIC-Superpixels-Achanta-Shaji",
            "title": {
                "fragments": [],
                "text": "SLIC Superpixels ?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel algorithm is introduced that clusters pixels in the combined five-dimensional color and image plane space to efficiently generate compact, nearly uniform superpixels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Segmentation through graph cuts [7] uses (a) as the unary term, and (b) as the binary term."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2430892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3120324069ec20eed853d3f9bbbceb32e4173b93",
            "isKey": false,
            "numCitedBy": 3913,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of minimizing a large class of energy functions that occur in early vision. The major restriction is that the energy function's smoothness term must only involve pairs of pixels. We propose two algorithms that use graph cuts to compute a local minimum even when very large moves are allowed. The first move we consider is an /spl alpha/-/spl beta/-swap: for a pair of labels /spl alpha/,/spl beta/, this move exchanges the labels between an arbitrary set of pixels labeled a and another arbitrary set labeled /spl beta/. Our first algorithm generates a labeling such that there is no swap move that decreases the energy. The second move we consider is an /spl alpha/-expansion: for a label a, this move assigns an arbitrary set of pixels the label /spl alpha/. Our second algorithm, which requires the smoothness term to be a metric, generates a labeling such that there is no expansion move that decreases the energy. Moreover, this solution is within a known factor of the global minimum. We experimentally demonstrate the effectiveness of our approach on image restoration, stereo and motion."
            },
            "slug": "Fast-approximate-energy-minimization-via-graph-cuts-Boykov-Veksler",
            "title": {
                "fragments": [],
                "text": "Fast approximate energy minimization via graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes two algorithms that use graph cuts to compute a local minimum even when very large moves are allowed, and generates a labeling such that there is no expansion move that decreases the energy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070963479"
                        ],
                        "name": "Dominik Scherer",
                        "slug": "Dominik-Scherer",
                        "structuredName": {
                            "firstName": "Dominik",
                            "lastName": "Scherer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dominik Scherer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113785713"
                        ],
                        "name": "Andreas C. M\u00fcller",
                        "slug": "Andreas-C.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "M\u00fcller",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas C. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 101
                            }
                        ],
                        "text": "The biggest architectural difference between the our DNN and earlier CNN [25] are max-pooling layers [30, 32, 31] instead of sub-sampling layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18388506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d21006fa32ff69f6b0a646f26ce0db84f2f4d33",
            "isKey": false,
            "numCitedBy": 1285,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A common practice to gain invariant features in object recognition models is to aggregate multiple low-level features over a small neighborhood. However, the differences between those models makes a comparison of the properties of different aggregation functions hard. Our aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks. Empirical results show that a maximum pooling operation significantly outperforms subsampling operations. Despite their shift-invariant properties, overlapping pooling windows are no significant improvement over nonoverlapping pooling windows. By applying this knowledge, we achieve state-of-the-art error rates of 4.57% on the NORB normalized-uniform dataset and 5.6% on the NORB jittered-cluttered dataset."
            },
            "slug": "Evaluation-of-Pooling-Operations-in-Convolutional-Scherer-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks, and empirical results show that a maximum pooling operation significantly outperforms subsampling operations."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6803671"
                        ],
                        "name": "L. Gambardella",
                        "slug": "L.-Gambardella",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Gambardella",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Lately, DNN proved their efficiency on data sets extending from handwritten digits (MNIST) [9, 11], handwritten characters [10] to 3D toys (NORB) [12] and faces [34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10122297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "260a7615bbffec052d67dffde5bcf9b4687b50ee",
            "isKey": false,
            "numCitedBy": 448,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In 2010, after many years of stagnation, the MNIST handwriting recognition benchmark record dropped from 0.40% error rate to 0.35%. Here we report 0.27% for a committee of seven deep CNNs trained on graphics cards, narrowing the gap to human performance. We also apply the same architecture to NIST SD 19, a more challenging dataset including lower and upper case letters. A committee of seven CNNs obtains the best results published so far for both NIST digits and NIST letters. The robustness of our method is verified by analyzing 78125 different 7-net committees."
            },
            "slug": "Convolutional-Neural-Network-Committees-for-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "Convolutional Neural Network Committees for Handwritten Character Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This work applies the same architecture to NIST SD 19, a more challenging dataset including lower and upper case letters, and obtains the best results published so far for both NIST digits and NIST letters."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 139
                            }
                        ],
                        "text": "DNN are inspired by convolutional neural networks introduced in 1980 [15], improved in the 1990s [24], refined and simplified in the 2000s [5, 32], and brought to their full potential by making them both large and deep [11, 12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1304548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43b87f5f4da973a513eaddb779032f0ceacfa394",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 267,
            "paperAbstract": {
                "fragments": [],
                "text": "I. Theory.- Neurobiological Background.- Related Work.- Neural Abstraction Pyramid Architecture.- Unsupervised Learning.- Supervised Learning.- II. Applications.- Recognition of Meter Values.- Binarization of Matrix Codes.- Learning Iterative Image Reconstruction.- Face Localization.- Summary and Conclusions."
            },
            "slug": "Hierarchical-Neural-Networks-for-Image-Behnke",
            "title": {
                "fragments": [],
                "text": "Hierarchical Neural Networks for Image Interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The results show clear trends in the direction of improvement in the level of supervised learning in relation to the recognition of meter values and in the application of Matrix Codes."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49390793"
                        ],
                        "name": "A. Foi",
                        "slug": "A.-Foi",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Foi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Foi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2772474"
                        ],
                        "name": "G. Boracchi",
                        "slug": "G.-Boracchi",
                        "structuredName": {
                            "firstName": "Giacomo",
                            "lastName": "Boracchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Boracchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "Foveation is inspired by the structure of human photoreceptor topography [14], and has recently been shown to be very effective for improving nonlocal-means denoising algorithms [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10273396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7a2c98e9a64fcf6cc7b0410b23ae8007ef1c70c",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Nonlocal image filters suppress noise and other distortions by searching for similar patches at different locations within the image, thus exploiting the self-similarity present in natural images. This similarity is typically assessed by a windowed distance of the patches pixels. Inspired by the human visual system, we introduce a patch foveation operator and measure patch similarity through a foveated distance, where each patch is blurred with spatially variant point-spread functions having standard deviation increasing with the spatial distance from the patch center. In this way, we install a different form of self-similarity in images: the foveated self-similarity. We consider the Nonlocal Means algorithm (NL-means) for the removal of additive white Gaussian noise as a simple prototype of nonlocal image filtering and derive an explicit construction of its corresponding foveation operator, thus yielding the Foveated NL-means algorithm. Our analysis and experimental study show that, to the purpose of image denoising, the foveated self-similarity can be a far more effective regularity assumption than the conventional windowed self-similarity. In the comparison with NL-means, the proposed foveated algorithm achieves a substantial improvement in denoising quality, according to both objective criteria and visual appearance, particularly due to better contrast and sharpness. Moreover, foveation is introduced at a negligible cost in terms of computational complexity."
            },
            "slug": "Foveated-self-similarity-in-nonlocal-image-Foi-Boracchi",
            "title": {
                "fragments": [],
                "text": "Foveated self-similarity in nonlocal image filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work considers the Nonlocal Means algorithm for the removal of additive white Gaussian noise as a simple prototype of nonlocal image filtering and derives an explicit construction of its corresponding foveation operator, thus yielding the Foveated NL-means algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4688037"
                        ],
                        "name": "L. Arranz",
                        "slug": "L.-Arranz",
                        "structuredName": {
                            "firstName": "Lorena",
                            "lastName": "Arranz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Arranz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114372875"
                        ],
                        "name": "M\u00e9ndez-Ferrer Sim\u00f3n",
                        "slug": "M\u00e9ndez-Ferrer-Sim\u00f3n",
                        "structuredName": {
                            "firstName": "M\u00e9ndez-Ferrer",
                            "lastName": "Sim\u00f3n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00e9ndez-Ferrer Sim\u00f3n"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 58
                            }
                        ],
                        "text": "ingly urgent, as they enable acquisition of huge datasets [6, 20], whose manual analysis is simply unfeasible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 174
                            }
                        ],
                        "text": "Such implementation is currently being further optimized (with foreseen speedups of one order of magnitude at least) in view of application to huge, terapixel-class datasets [6, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18826516,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "id": "b9f48938447efdfb3c740c210ab7de5c17db6014",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the last few years, the mesenchymal stromal compartment of the bone marrow has regained interest. The main reason for this resurgence is the recognition of their immunomodulatory properties and their prominent role in the maintenance and regulation of hematopoiesis. This has simultaneously prompted preclinical and clinical studies trying to take advantage of these properties and, at the same time, basic studies that have tried to dissect the bone marrow stromal compartment and the specific functions that different stromal cells have in the regulation of hematopoiesis and immunity. In this minireview we will summarize our contributions to the functions of mesenchymal stem cells in regulating hematopoietic stem cells. By putting them in a broader context, we will discuss the emerging role of mesenchymal stem cells as key integrators of neuro-endocrine signals, able to couple whole-organism demands to fine-tuned responses in remote stem cell niches. Rec.12/4/2012, Acc.12/10/2012, pp38-47"
            },
            "slug": "Network-anatomy-and-in-vivo-physiology-of-stem-and-Arranz-Sim\u00f3n",
            "title": {
                "fragments": [],
                "text": "Network anatomy and in vivo physiology of mesenchymal stem and stromal cells"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The emerging role of mesenchymal stem cells as key integrators of neuro-endocrine signals, able to couple whole-organism demands to fine-tuned responses in remote stem cell niches, is discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6803671"
                        ],
                        "name": "L. Gambardella",
                        "slug": "L.-Gambardella",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Gambardella",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our fast GPU implementation [9, 11] overcomes this problem, speeding up single-threaded CPU code by up to two orders of magnitude."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Lately, DNN proved their efficiency on data sets extending from handwritten digits (MNIST) [9, 11], handwritten characters [10] to 3D toys (NORB) [12] and faces [34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1918673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b98cd08b75ebf2bd1d1ec47c51ef75777a7e64bd",
            "isKey": false,
            "numCitedBy": 875,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35 error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning."
            },
            "slug": "Deep,-Big,-Simple-Neural-Nets-for-Handwritten-Digit-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "Deep, Big, Simple Neural Nets for Handwritten Digit Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35 error rate on the MNIST handwritten digits benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143980357"
                        ],
                        "name": "W. Rand",
                        "slug": "W.-Rand",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Rand",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "Rand error: defined as 1\u2212Frand, where Frand represents the F1 score of the Rand index [29], which measures the accuracy with which pixels are associated to their respective neurons."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 197457299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "954937ece00fd465f6a639fa739a04af8d5d7efb",
            "isKey": false,
            "numCitedBy": 5534,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Many intuitively appealing methods have been suggested for clustering data, however, interpretation of their results has been hindered by the lack of objective criteria. This article proposes several criteria which isolate specific aspects of the performance of a method, such as its retrieval of inherent structure, its sensitivity to resampling and the stability of its results in the light of new data. These criteria depend on a measure of similarity between two different clusterings of the same set of data; the measure essentially considers how each pair of data points is assigned in each clustering."
            },
            "slug": "Objective-Criteria-for-the-Evaluation-of-Clustering-Rand",
            "title": {
                "fragments": [],
                "text": "Objective Criteria for the Evaluation of Clustering Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This article proposes several criteria which isolate specific aspects of the performance of a method, such as its retrieval of inherent structure, its sensitivity to resampling and the stability of its results in the light of new data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784694"
                        ],
                        "name": "Saadia Iftikhar",
                        "slug": "Saadia-Iftikhar",
                        "structuredName": {
                            "firstName": "Saadia",
                            "lastName": "Iftikhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saadia Iftikhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781968"
                        ],
                        "name": "A. Godil",
                        "slug": "A.-Godil",
                        "structuredName": {
                            "firstName": "Afzal",
                            "lastName": "Godil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Godil"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 70341778,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4aa704280de8d34114bf894696c6b4a724d52d2",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Detection-of-Neuronal-Structures-using-a-and-Iftikhar-Godil",
            "title": {
                "fragments": [],
                "text": "The Detection of Neuronal Structures using a Patch-based Multi-features and Support Vector Machines Learning Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "ISBI 2013"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59703313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46d2216289fa276811c09234ac09215c450bc820",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hierarchical-Neural-Networks-for-Image-(Lecture-in-Behnke",
            "title": {
                "fragments": [],
                "text": "Hierarchical Neural Networks for Image Interpretation (Lecture Notes in Computer Science)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Segmentation through graph cuts [7] uses (a) as the unary term, and (b) as the binary term."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45232003,
            "fieldsOfStudy": [],
            "id": "a57520b68e73b5e1fc3668b443daf74ebe957cc7",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast Approximate Energy Minimization via Graph Cuts"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Segmentation of neuronal structures in EM stacks challenge -ISBI 2012"
            },
            "venue": {
                "fragments": [],
                "text": "Segmentation of neuronal structures in EM stacks challenge -ISBI 2012"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Membrane extraction using two-step classification and post-processing"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of ISBI 2012 EM Segmentation Challenge"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neuron Segmentation in EM Images using Series of Classifiers and Watershed Tree"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of ISBI 2012 EM Segmentation Challenge"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "The recent field of connectomics [2] is developing high-throughput techniques for mapping connections in nervous systems, one of the most important and ambitious goals of neuroanatomy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Open Connectome Project"
            },
            "venue": {
                "fragments": [],
                "text": "The Open Connectome Project"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Preliminary results in this direction are encouraging: the problem-specific postprocessing techniques in [20] and [24], operating on our segmentation, reduce the Rand error to measure to 36\u00b710\u22123 and 32\u00b710\u22123, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Segmentation of Neuronal Structures in EM stacks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of ISBI 2012 EM Segmentation Challenge"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Our solution is based on a Deep Neural Network (DNN) [12, 13] used as a pixel classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mouse Visual Cortex Dataset in the Open Connectome Project"
            },
            "venue": {
                "fragments": [],
                "text": "Mouse Visual Cortex Dataset in the Open Connectome Project"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "The network computes the probability of a pixel being a membrane, using as input the image intensities in a square window centered on the pixel itself."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Lately, DNN proved their efficiency on data sets extending from handwritten digits (MNIST) [10, 12], handwritten characters [11] to 3D toys (NORB) [13] and faces [35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Luca Maria Gambardella, and J\u00fcrgen Schmidhuber. Flexible, high performance convolutional neural networks for image classification"
            },
            "venue": {
                "fragments": [],
                "text": "International Joint Conference on Artificial Intelligence"
            },
            "year": 2011
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 21,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 40,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Deep-Neural-Networks-Segment-Neuronal-Membranes-in-Ciresan-Giusti/09193e19b59fc8f05bee9d6efbfb1607ca5b6501?sort=total-citations"
}