{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123937952"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111931"
                        ],
                        "name": "J. Guinness",
                        "slug": "J.-Guinness",
                        "structuredName": {
                            "firstName": "Jethran",
                            "lastName": "Guinness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Guinness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885046"
                        ],
                        "name": "Alex Zamanian",
                        "slug": "Alex-Zamanian",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Zamanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Zamanian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15548439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad269ba941949a1d66b6649a71d752784c576dc3",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for augmenting annotated training data with hierarchical word clusters that are automatically derived from a large unannotated corpus. Cluster membership is encoded in features that are incorporated in a discriminatively trained tagging model. Active learning is used to select training examples. We evaluate the technique for named-entity tagging. Compared with a state-of-the-art HMM-based name finder, the presented technique requires only 13% as much annotated data to achieve the same level of performance. Given a large annotated training set of 1,000,000 words, the technique achieves a 25% reduction in error over the state-of-the-art HMM trained on the same material."
            },
            "slug": "Name-Tagging-with-Word-Clusters-and-Discriminative-Miller-Guinness",
            "title": {
                "fragments": [],
                "text": "Name Tagging with Word Clusters and Discriminative Training"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A technique for augmenting annotated training data with hierarchical word clusters that are automatically derived from a large unannotated corpus that achieves a 25% reduction in error over the state-of-the-art HMM trained on the same material."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3024630"
                        ],
                        "name": "Hai Leong Chieu",
                        "slug": "Hai-Leong-Chieu",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Chieu",
                            "middleNames": [
                                "Leong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Leong Chieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(Chieu and Ng, 2003) 88."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 80
                            }
                        ],
                        "text": "NER systems often have global features to capture discourse-level regularities (Chieu and Ng 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16619357,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03c03dec975554cb02aca1e076106178dbe0a8a0",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The named entity recognition (NER) task involves identifying noun phrases that are names, and assigning a class to each name. This task has its origin from the Message Understanding Conferences (MUC) in the 1990s, a series of conferences aimed at evaluating systems that extract information from natural language texts. It became evident that in order to achieve good performance in information extraction, a system needs to be able to recognize names. A separate subtask on NER was created in MUC-6 and MUC-7 (Chinchor, 1998)."
            },
            "slug": "Named-Entity-Recognition-with-a-Maximum-Entropy-Chieu-Ng",
            "title": {
                "fragments": [],
                "text": "Named Entity Recognition with a Maximum Entropy Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The named entity recognition (NER) task involves identifying noun phrases that are names, and assigning a class to each name."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100902063"
                        ],
                        "name": "Y. Wong",
                        "slug": "Y.-Wong",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Wong",
                            "middleNames": [
                                "Fu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 14
                            }
                        ],
                        "text": "Uszkoreit and Brants (2008) proposed a\n1030\ndistributed clustering algorithm with a similar objective function as the Brown algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9207265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47bb53c0ee0b7f2a56422ee3f493dc155af4a066",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a simple yet novel method of exploiting unlabeled text to further improve the accuracy of a high-performance state-of-the art named entity recognition (NER) system. The method utilizes the empirical property that many named entities occur in one name class only. Using only unlabeled text as the additional resource, our improved NER system achieves an F1 score of 87.13%, an improvement of 1.17% in F1 score and a 8.3% error reduction on the CoNLL 2003 English NER official test set. This accuracy places our NER system among the top 3 systems in the CoNLL 2003 English shared task."
            },
            "slug": "One-Class-per-Named-Entity:-Exploiting-Unlabeled-Wong-Ng",
            "title": {
                "fragments": [],
                "text": "One Class per Named Entity: Exploiting Unlabeled Text for Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A simple yet novel method of exploiting unlabeled text to further improve the accuracy of a high-performance state-of-the art named entity recognition (NER) system using the empirical property that many named entities occur in one name class only."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144042991"
                        ],
                        "name": "Jun Suzuki",
                        "slug": "Jun-Suzuki",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Suzuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Suzuki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789234"
                        ],
                        "name": "Hideki Isozaki",
                        "slug": "Hideki-Isozaki",
                        "structuredName": {
                            "firstName": "Hideki",
                            "lastName": "Isozaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hideki Isozaki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Suzuki and Isozaki (2008), on the other hand, used the automatically labeled corpus to train HMMs.\nAndo and Zhang (2005) defined an objective function that combines the original problem on the labeled data with a set of auxiliary problems on unlabeled data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 23
                            }
                        ],
                        "text": "Wong and Ng (2007) and Suzuki and Isozaki (2008) are similar in that they run a baseline discriminative classifier on unlabeled data to generate pseudo examples, which are then used to train a different type of classifier for the same problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 28
                            }
                        ],
                        "text": "2004), (Wong and Ng 2007), (Suzuki and Isozaki 2008), and (Koo et. al., 2008), as well as this paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 151
                            }
                        ],
                        "text": "Part-of-speech tags were used in the topranked systems in CoNLL 2003, as well as in many follow up studies that used the data set (Ando and Zhang 205; Suzuki and Isozaki 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 24
                            }
                        ],
                        "text": "Although the method in (Suzuki and Isozaki 2008) is quite general, it is hard to see how it can be applied to the query classification problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 647664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ece4e8d31f872d928369ac2cf58a616a7182112",
            "isKey": true,
            "numCitedBy": 155,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides evidence that the use of more unlabeled data in semi-supervised learning can improve the performance of Natural Language Processing (NLP) tasks, such as part-of-speech tagging, syntactic chunking, and named entity recognition. We first propose a simple yet powerful semi-supervised discriminative model appropriate for handling large scale unlabeled data. Then, we describe experiments performed on widely used test collections, namely, PTB III data, CoNLL\u201900 and \u201903 shared task data for the above three NLP tasks, respectively. We incorporate up to 1G-words (one billion tokens) of unlabeled data, which is the largest amount of unlabeled data ever used for these tasks, to investigate the performance improvement. In addition, our results are superior to the best reported results for all of the above test collections."
            },
            "slug": "Semi-Supervised-Sequential-Labeling-and-Using-Scale-Suzuki-Isozaki",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Sequential Labeling and Segmentation Using Giga-Word Scale Unlabeled Data"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "Evidence that the use of more unlabeled data in semi-supervised learning can improve the performance of Natural Language Processing tasks, such as part-of-speech tagging, syntactic chunking, and named entity recognition is provided."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3853032"
                        ],
                        "name": "J. Lai",
                        "slug": "J.-Lai",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Lai",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10986188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3de5d40b60742e3dfa86b19e7f660962298492af",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics."
            },
            "slug": "Class-Based-n-gram-Models-of-Natural-Language-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "Class-Based n-gram Models of Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work addresses the problem of predicting a word from previous words in a sample of text and discusses n-gram models based on classes of words, finding that these models are able to extract classes that have the flavor of either syntactically based groupings or semanticallybased groupings, depending on the nature of the underlying statistics."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060101052"
                        ],
                        "name": "Terry Koo",
                        "slug": "Terry-Koo",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Koo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terry Koo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701734"
                        ],
                        "name": "X. Carreras",
                        "slug": "X.-Carreras",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Carreras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Carreras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1916754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "790ecefeaf2b471b439743a772ccce026131bef5",
            "isKey": false,
            "numCitedBy": 494,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple and effective semisupervised method for training dependency parsers. We focus on the problem of lexical representation, introducing features that incorporate word clusters derived from a large unannotated corpus. We demonstrate the effectiveness of the approach in a series of dependency parsing experiments on the Penn Treebank and Prague Dependency Treebank, and we show that the cluster-based features yield substantial gains in performance across a wide range of conditions. For example, in the case of English unlabeled second-order parsing, we improve from a baseline accuracy of 92.02% to 93.16%, and in the case of Czech unlabeled second-order parsing, we improve from a baseline accuracy of 86.13% to 87.13%. In addition, we demonstrate that our method also improves performance when small amounts of training data are available, and can roughly halve the amount of supervised data required to reach a desired level of performance."
            },
            "slug": "Simple-Semi-supervised-Dependency-Parsing-Koo-Carreras",
            "title": {
                "fragments": [],
                "text": "Simple Semi-supervised Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work focuses on the problem of lexical representation, introducing features that incorporate word clusters derived from a large unannotated corpus, and shows that the cluster-based features yield substantial gains in performance across a wide range of conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1855302"
                        ],
                        "name": "Joseph Smarr",
                        "slug": "Joseph-Smarr",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Smarr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Smarr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122619312"
                        ],
                        "name": "Huy Nguyen",
                        "slug": "Huy-Nguyen",
                        "structuredName": {
                            "firstName": "Huy",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huy Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(Klein et al., 2003) 86."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1080545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e958d809a45ba3ae9eef8c5381e8cad8f11de10",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss two named-entity recognition models which use characters and character n-grams either exclusively or as an important part of their data representation. The first model is a character-level HMM with minimal context information, and the second model is a maximum-entropy conditional markov model with substantially richer context features. Our best model achieves an overall F1 of 86.07% on the English test data (92.31% on the development data). This number represents a 25% error reduction over the same model without word-internal (substring) features."
            },
            "slug": "Named-Entity-Recognition-with-Character-Level-Klein-Smarr",
            "title": {
                "fragments": [],
                "text": "Named Entity Recognition with Character-Level Models"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "Two named-entity recognition models which use characters and character n-grams either exclusively or as an important part of their data representation are discussed, both of which are a character-level HMM with minimal context information and a maximum-entropy conditional markov model with substantially richer context features."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707117"
                        ],
                        "name": "Radu Florian",
                        "slug": "Radu-Florian",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Florian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radu Florian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683685"
                        ],
                        "name": "Abraham Ittycheriah",
                        "slug": "Abraham-Ittycheriah",
                        "structuredName": {
                            "firstName": "Abraham",
                            "lastName": "Ittycheriah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abraham Ittycheriah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40544823"
                        ],
                        "name": "Hongyan Jing",
                        "slug": "Hongyan-Jing",
                        "structuredName": {
                            "firstName": "Hongyan",
                            "lastName": "Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongyan Jing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10606201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1ba322f795adbdc706651dbc76ad53b9c5f9468",
            "isKey": false,
            "numCitedBy": 477,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a classifier-combination experimental framework for named entity recognition in which four diverse classifiers (robust linear classifier, maximum entropy, transformation-based learning, and hidden Markov model) are combined under different conditions. When no gazetteer or other additional training resources are used, the combined system attains a performance of 91.6F on the English development data; integrating name, location and person gazetteers, and named entity systems trained on additional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data."
            },
            "slug": "Named-Entity-Recognition-through-Classifier-Florian-Ittycheriah",
            "title": {
                "fragments": [],
                "text": "Named Entity Recognition through Classifier Combination"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A classifier-combination experimental framework for named entity recognition in which four diverse classifiers (robust linear classifier, maximum entropy, transformation-based learning, and hidden Markov model) are combined under different conditions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4158998"
                        ],
                        "name": "David S. Vogel",
                        "slug": "David-S.-Vogel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Vogel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2704747"
                        ],
                        "name": "S. Bickel",
                        "slug": "S.-Bickel",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Bickel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145053730"
                        ],
                        "name": "P. Haider",
                        "slug": "P.-Haider",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Haider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2351716"
                        ],
                        "name": "R. Schimpfky",
                        "slug": "R.-Schimpfky",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Schimpfky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schimpfky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101989147"
                        ],
                        "name": "Peter Siemen",
                        "slug": "Peter-Siemen",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Siemen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Siemen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066036540"
                        ],
                        "name": "S. Bridges",
                        "slug": "S.-Bridges",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Bridges",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bridges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751348"
                        ],
                        "name": "T. Scheffer",
                        "slug": "T.-Scheffer",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Scheffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Scheffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 65
                            }
                        ],
                        "text": "The best two systems in the competition (Shen et al., 2005) and (Vogel et al., 2005) resorted to knowledge engineering techniques to bridge the gap between\nthe small set of examples and the new queries."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4471502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31462c9d3848d593e57eff18ce6d6d384a717f92",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of search engines crucially depends on their ability to capture the meaning of a query most likely intended by the user. We study the problem of mapping a search engine query to those nodes of a given subject taxonomy that characterize its most likely meanings. We describe the architecture of a classification system that uses a web directory to identify the subject context that the query terms are frequently used in. Based on its performance on the classification of 800,000 example queries recorded from MSN search, the system received the Runner-Up Award for Query Categorization Performance of the KDD Cup 2005."
            },
            "slug": "Classifying-search-engine-queries-using-the-web-as-Vogel-Bickel",
            "title": {
                "fragments": [],
                "text": "Classifying search engine queries using the web as background knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The architecture of a classification system that uses a web directory to identify the subject context that the query terms are frequently used in is described, which received the Runner-Up Award for Query Categorization Performance of the KDD Cup 2005."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37643602"
                        ],
                        "name": "Dou Shen",
                        "slug": "Dou-Shen",
                        "structuredName": {
                            "firstName": "Dou",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dou Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066007146"
                        ],
                        "name": "Rong Pan",
                        "slug": "Rong-Pan",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian-Tao Sun",
                        "slug": "Jian-Tao-Sun",
                        "structuredName": {
                            "firstName": "Jian-Tao",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian-Tao Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730133"
                        ],
                        "name": "J. J. Pan",
                        "slug": "J.-J.-Pan",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pan",
                            "middleNames": [
                                "Junfeng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. J. Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115598322"
                        ],
                        "name": "Kangheng Wu",
                        "slug": "Kangheng-Wu",
                        "structuredName": {
                            "firstName": "Kangheng",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kangheng Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111609861"
                        ],
                        "name": "Jie Yin",
                        "slug": "Jie-Yin",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 41
                            }
                        ],
                        "text": "The best two systems in the competition (Shen et al., 2005) and (Vogel et al., 2005) resorted to knowledge engineering techniques to bridge the gap between\nthe small set of examples and the new queries."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 431999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d879eba4996654832237da054f78f78fcda77687",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe our ensemble-search based approach, Q2C@UST (http://webprojectl.cs.ust.hk/q2c/), for the query classification task for the KDDCUP 2005. There are two aspects to the key difficulties of this problem: one is that the meaning of the queries and the semantics of the predefined categories are hard to determine. The other is that there are no training data for this classification problem. We apply a two-phase framework to tackle the above difficulties. Phase I corresponds to the training phase of machine learning research and phase II corresponds to testing phase. In phase I, two kinds of classifiers are developed as the base classifiers. One is synonym-based and the other is statistics based. Phase II consists of two stages. In the first stage, the queries are enriched such that for each query, its related Web pages together with their category information are collected through the use of search engines. In the second stage, the enriched queries are classified through the base classifiers trained in phase I. Based on the classification results obtained by the base classifiers, two ensemble classifiers based on two different strategies are proposed. The experimental results on the validation dataset help confirm our conjectures on the performance of the Q2C@UST system. In addition, the evaluation results given by the KDDCUP 2005 organizer confirm the effectiveness of our proposed approaches. The best F1 value of our two solutions is 9.6% higher than the best of all other participants' solutions. The average F1 value of our two submitted solutions is 94.4% higher than the average F1 value from all other submitted solutions."
            },
            "slug": "Q2C@UST:-our-winning-solution-to-query-in-KDDCUP-Shen-Pan",
            "title": {
                "fragments": [],
                "text": "Q2C@UST: our winning solution to query classification in KDDCUP 2005"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper describes the ensemble-search based approach, Q2C@UST, for the query classification task for the KDDCUP 2005, and proposes two ensemble classifiers based on two different strategies to tackle the key difficulties."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784037"
                        ],
                        "name": "T. Brants",
                        "slug": "T.-Brants",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Brants",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brants"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 65
                            }
                        ],
                        "text": "For each query class, we train a logistic regression classifier (Vapnik 1999) with L2 regularization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11623716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00ae51ba9340abc30d36804f9b51ab83b81cec23",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In statistical language modeling, one technique to reduce the problematic eects of data sparsity is to partition the vocabulary into equivalence classes. In this paper we investigate the eects of applying such a technique to higherorder n-gram models trained on large corpora. We introduce a modification of the exchange clustering algorithm with improved eciency for certain partially class-based models and a distributed version of this algorithm to eciently obtain automatic word classifications for large vocabularies (>1 million words) using such large training corpora (>30 billion tokens). The resulting clusterings are then used in training partially class-based language models. We show that combining them with wordbased n-gram models in the log-linear model of a state-of-the-art statistical machine translation system leads to improvements in translation quality as indicated by the BLEU score."
            },
            "slug": "Distributed-Word-Clustering-for-Large-Scale-in-Uszkoreit-Brants",
            "title": {
                "fragments": [],
                "text": "Distributed Word Clustering for Large Scale Class-Based Language Modeling in Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper introduces a modification of the exchange clustering algorithm with improved eciency for certain partially class-based models and a distributed version of this algorithm to eciently obtain automatic word classifications for large vocabularies using such large training corpora."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365155"
                        ],
                        "name": "S. Deerwester",
                        "slug": "S.-Deerwester",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Deerwester",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Deerwester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737579"
                        ],
                        "name": "G. Furnas",
                        "slug": "G.-Furnas",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Furnas",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Furnas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154682"
                        ],
                        "name": "R. Harshman",
                        "slug": "R.-Harshman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Harshman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Harshman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3252915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20a80a7356859daa4170fb4da6b87b84adbb547f",
            "isKey": false,
            "numCitedBy": 7019,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising."
            },
            "slug": "Indexing-by-Latent-Semantic-Analysis-Deerwester-Dumais",
            "title": {
                "fragments": [],
                "text": "Indexing by Latent Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new method for automatic indexing and retrieval to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105414"
                        ],
                        "name": "F. D. Meulder",
                        "slug": "F.-D.-Meulder",
                        "structuredName": {
                            "firstName": "Fien",
                            "lastName": "Meulder",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Meulder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2470716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb",
            "isKey": false,
            "numCitedBy": 2960,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance."
            },
            "slug": "Introduction-to-the-CoNLL-2003-Shared-Task:-Named-Sang-Meulder",
            "title": {
                "fragments": [],
                "text": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The CoNLL-2003 shared task: language-independent named entity recognition is described and a general overview of the systems that have taken part in the task and discuss their performance is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8884845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4b828609b60b06e61bea7a4029cc9e1cad5df87",
            "isKey": false,
            "numCitedBy": 3754,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several, previously proposed phrase-based translation models. Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models out-perform word-based models. Our empirical results, which hold for all examined language pairs, suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations. Surprisingly, learning phrases longer than three words and learning phrases from high-accuracy word-level alignment models does not have a strong impact on performance. Learning only syntactically motivated phrases degrades the performance of our systems."
            },
            "slug": "Statistical-Phrase-Based-Translation-Koehn-Och",
            "title": {
                "fragments": [],
                "text": "Statistical Phrase-Based Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The empirical results suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translation."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690967"
                        ],
                        "name": "A. Blum",
                        "slug": "A.-Blum",
                        "structuredName": {
                            "firstName": "Avrim",
                            "lastName": "Blum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144135485"
                        ],
                        "name": "Tom. Mitchell",
                        "slug": "Tom.-Mitchell",
                        "structuredName": {
                            "firstName": "Tom.",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom. Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207228399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278841ab0cb24c1abcb75e363aeed1fa741c8cc4",
            "isKey": false,
            "numCitedBy": 5471,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of using a large unlabeled sample to boost performance of a learning algorit,hrn when only a small set of labeled examples is available. In particular, we consider a problem setting motivated by the task of learning to classify web pages, in which the description of each example can be partitioned into two distinct views. For example, the description of a web page can be partitioned into the words occurring on that page, and the words occurring in hyperlinks t,hat point to that page. We assume that either view of the example would be sufficient for learning if we had enough labeled data, but our goal is to use both views together to allow inexpensive unlabeled data to augment, a much smaller set of labeled examples. Specifically, the presence of two distinct views of each example suggests strategies in which two learning algorithms are trained separately on each view, and then each algorithm\u2019s predictions on new unlabeled examples are used to enlarge the training set of the other. Our goal in this paper is to provide a PAC-style analysis for this setting, and, more broadly, a PAC-style framework for the general problem of learning from both labeled and unlabeled data. We also provide empirical results on real web-page data indicating that this use of unlabeled examples can lead to significant improvement of hypotheses in practice. *This research was supported in part by the DARPA HPKB program under contract F30602-97-1-0215 and by NSF National Young investigator grant CCR-9357793. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. TO copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. COLT 98 Madison WI USA Copyright ACM 1998 l-58113-057--0/98/ 7...%5.00 92 Tom Mitchell School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213-3891 mitchell+@cs.cmu.edu"
            },
            "slug": "Combining-labeled-and-unlabeled-data-with-Blum-Mitchell",
            "title": {
                "fragments": [],
                "text": "Combining labeled and unlabeled data with co-training"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A PAC-style analysis is provided for a problem setting motivated by the task of learning to classify web pages, in which the description of each example can be partitioned into two distinct views, to allow inexpensive unlabeled data to augment, a much smaller set of labeled examples."
            },
            "venue": {
                "fragments": [],
                "text": "COLT' 98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70217511"
                        ],
                        "name": "Tim Heilman",
                        "slug": "Tim-Heilman",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Heilman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Heilman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1775037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f755b0333440f1346a8ba889e404c024cfb21e0",
            "isKey": false,
            "numCitedBy": 812,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Determining the similarity of short text snippets, such as search queries, works poorly with traditional document similarity measures (e.g., cosine), since there are often few, if any, terms in common between two short text snippets. We address this problem by introducing a novel method for measuring the similarity between short text snippets (even those without any overlapping terms) by leveraging web search results to provide greater context for the short texts. In this paper, we define such a similarity kernel function, mathematically analyze some of its properties, and provide examples of its efficacy. We also show the use of this kernel function in a large-scale system for suggesting related queries to search engine users."
            },
            "slug": "A-web-based-kernel-function-for-measuring-the-of-Sahami-Heilman",
            "title": {
                "fragments": [],
                "text": "A web-based kernel function for measuring the similarity of short text snippets"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper defines a similarity kernel function, mathematically analyze some of its properties, and provides examples of its efficacy, and shows the use of this kernel function in a large-scale system for suggesting related queries to search engine users."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145580839"
                        ],
                        "name": "Jimmy J. Lin",
                        "slug": "Jimmy-J.-Lin",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Lin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy J. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 219829,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eec9a50881bbefc3b72064e9e6852558f000cf04",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the challenge of scaling up language processing algorithms to increasingly large datasets. While cluster computing has been available in commercial environments for several years, academic researchers have fallen behind in their ability to work on large datasets. I discuss two barriers contributing to this problem: lack of a suitable programming model for managing concurrency and difficulty in obtaining access to hardware. Hadoop, an open-source implementation of Google's MapReduce framework, provides a compelling solution to both issues. Its simple programming model hides system-level details from the developer, and its ability to run on commodity hardware puts cluster computing within the reach of many academic research groups. This paper illustrates these points with a case study in building word cooccurrence matrices from large corpora. I conclude with an analysis of an alternative computing model based on renting instead of buying computer clusters."
            },
            "slug": "Scalable-Language-Processing-Algorithms-for-the-A-Lin",
            "title": {
                "fragments": [],
                "text": "Scalable Language Processing Algorithms for the Masses: A Case Study in Computing Word Co-occurrence Matrices with MapReduce"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This paper illustrates the challenge of scaling up language processing algorithms to increasingly large datasets with a case study in building word cooccurrence matrices from large corpora and an analysis of an alternative computing model based on renting instead of buying computer clusters."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143623693"
                        ],
                        "name": "Y. Li",
                        "slug": "Y.-Li",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49774164"
                        ],
                        "name": "Zijian Zheng",
                        "slug": "Zijian-Zheng",
                        "structuredName": {
                            "firstName": "Zijian",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zijian Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2732405"
                        ],
                        "name": "H. Dai",
                        "slug": "H.-Dai",
                        "structuredName": {
                            "firstName": "Honghua",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Dai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4471884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40b1f9165661cd45a654b57c36ad69e0f93a6dcb",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The KDD-Cup 2005 Competition was held in conjunction with the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. The task of the KDD-Cup 2005 competition was to classify 800,000 internet user search queries into 67 predefined categories. This task is easy to understand, but the lack of straightforward training set, subjective user intents of queries, poor information in short queries, and high noise level make the task very challenge.In this paper, we summarize the competition task, the evaluation method, and the results of the competition. Here we only highlight some key techniques used in submitted solutions. The technical details of the solutions from the three award winning teams are available in their papers separately in this issue of SIGKDD Explorations. At the end, we also share the results of a survey conducted with this year's Cup participants. To facilitate research in this area, the task description, data, answer set, and related information of this KDD-Cup are published at the KDD-Cup 2005 web site: http://www.acm.org/sigs/sigkdd/kdd2005/kddcup.html."
            },
            "slug": "KDD-CUP-2005-report:-facing-a-great-challenge-Li-Zheng",
            "title": {
                "fragments": [],
                "text": "KDD CUP-2005 report: facing a great challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The KDD-Cup 2005 competition was to classify 800,000 internet user search queries into 67 predefined categories, but the lack of straightforward training set, subjective user intents of queries, poor information in short queries, and high noise level make the task very challenge."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40435330"
                        ],
                        "name": "Shaojun Zhao",
                        "slug": "Shaojun-Zhao",
                        "structuredName": {
                            "firstName": "Shaojun",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaojun Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7536576"
                        ],
                        "name": "Benjamin Van Durme",
                        "slug": "Benjamin-Van-Durme",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Durme",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Durme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724629"
                        ],
                        "name": "Marius Pasca",
                        "slug": "Marius-Pasca",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Pasca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marius Pasca"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 74
                            }
                        ],
                        "text": "To obtain a list of phrases to be clustered, we followed the approach in (Lin et al., 2008) by collecting 20 million unique queries from an anonymized query log that are found in a 700 billion token web corpus with a minimum frequency count of 100."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 74
                            }
                        ],
                        "text": "K-Means clustering (MacQueen 1967) is one of the simplest and most well-known clustering algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7710382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fdebb7a2082eabc42dbad8b34b80cf43d0c1755",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Documents in languages such as Chinese, Japanese and Korean sometimes annotate terms with their translations in English inside a pair of parentheses. We present a method to extract such translations from a large collection of web documents by building a partially parallel corpus and use a word alignment algorithm to identify the terms being translated. The method is able to generalize across the translations for different terms and can reliably extract translations that occurred only once in the entire web. Our experiment on Chinese web pages produced more than 26 million pairs of translations, which is over two orders of magnitude more than previous results. We show that the addition of the extracted translation pairs as training data provides significant increase in the BLEU score for a statistical machine translation system."
            },
            "slug": "Mining-Parenthetical-Translations-from-the-Web-by-Lin-Zhao",
            "title": {
                "fragments": [],
                "text": "Mining Parenthetical Translations from the Web by Word Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a method to extract translations from a large collection of web documents by building a partially parallel corpus and use a word alignment algorithm to identify the terms being translated."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13410,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38070424"
                        ],
                        "name": "R. Ando",
                        "slug": "R.-Ando",
                        "structuredName": {
                            "firstName": "Rie",
                            "lastName": "Ando",
                            "middleNames": [
                                "Kubota"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ando"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 99
                            }
                        ],
                        "text": "Suzuki and Isozaki (2008), on the other hand, used the automatically labeled corpus to train HMMs.\nAndo and Zhang (2005) defined an objective function that combines the original problem on the labeled data with a set of auxiliary problems on unlabeled data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 643,
                                "start": 3
                            }
                        ],
                        "text": ", (Blum and Mitchell 1998), the classifiers learned from unlabel ed data wer e used directly. Recent research shows that it i s better to use whatever is learned from the unlabeled data as fea tures in a discriminative clasifier. This approach is taken by (Miller et. al. 2004), ( Wong and Ng 2007) , (Suzuki and Isozaki 2008), and (Koo et. al., 2008), as well as this paper. Wong and Ng (2007) and Suzuki and Isozaki (2008) are si milar in that they run a baseline discriminative classifi er on unlabeled data to generate pseudo exam ples, which are then used to train a different type of classifier for the sa me problem. Wong and Ng (2007) made the assumption that each pro per named belongs to one class (th ey observed that this is true about 85% of the time for English)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Ando and Zhang (2005) defined an obj ective function that combines the original pr oblem on the labeled data with a set of auxiliary problems"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 395,
                                "start": 3
                            }
                        ],
                        "text": ", (Blum and Mitchell 1998), the classifiers learned from unlabel ed data wer e used directly. Recent research shows that it i s better to use whatever is learned from the unlabeled data as fea tures in a discriminative clasifier. This approach is taken by (Miller et. al. 2004), ( Wong and Ng 2007) , (Suzuki and Isozaki 2008), and (Koo et. al., 2008), as well as this paper. Wong and Ng (2007) and Suzuki and Isozaki (2008) are si milar in that they run a baseline discriminative classifi er on unlabeled data to generate pseudo exam ples, which are then used to train a different type of classifier for the sa me problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 804,
                                "start": 3
                            }
                        ],
                        "text": ", (Blum and Mitchell 1998), the classifiers learned from unlabel ed data wer e used directly. Recent research shows that it i s better to use whatever is learned from the unlabeled data as fea tures in a discriminative clasifier. This approach is taken by (Miller et. al. 2004), ( Wong and Ng 2007) , (Suzuki and Isozaki 2008), and (Koo et. al., 2008), as well as this paper. Wong and Ng (2007) and Suzuki and Isozaki (2008) are si milar in that they run a baseline discriminative classifi er on unlabeled data to generate pseudo exam ples, which are then used to train a different type of classifier for the sa me problem. Wong and Ng (2007) made the assumption that each pro per named belongs to one class (th ey observed that this is true about 85% of the time for English). Suzuki and Isozaki (2008), on the other hand, used the automatically labeled corpus to train HMMs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13650160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "944e1a7b2c5c62e952418d7684e3cade89c76f87",
            "isKey": true,
            "numCitedBy": 1414,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most important issues in machine learning is whether one can improve the performance of a supervised learning algorithm by including unlabeled data. Methods that use both labeled and unlabeled data are generally referred to as semi-supervised learning. Although a number of such methods are proposed, at the current stage, we still don't have a complete understanding of their effectiveness. This paper investigates a closely related problem, which leads to a novel approach to semi-supervised learning. Specifically we consider learning predictive structures on hypothesis spaces (that is, what kind of classifiers have good predictive power) from multiple learning tasks. We present a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data. Under this framework, algorithms for structural learning will be proposed, and computational issues will be investigated. Experiments will be given to demonstrate the effectiveness of the proposed algorithms in the semi-supervised learning setting."
            },
            "slug": "A-Framework-for-Learning-Predictive-Structures-from-Ando-Zhang",
            "title": {
                "fragments": [],
                "text": "A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data, and algorithms for structural learning will be proposed, and computational issues will be investigated."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71084179"
                        ],
                        "name": "Muthu Dayalan",
                        "slug": "Muthu-Dayalan",
                        "structuredName": {
                            "firstName": "Muthu",
                            "lastName": "Dayalan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Muthu Dayalan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 67055872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "963a865539ecaf97acaabb236f106d33656cfcca",
            "isKey": false,
            "numCitedBy": 7853,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day."
            },
            "slug": "MapReduce:-simplified-data-processing-on-large-Dayalan",
            "title": {
                "fragments": [],
                "text": "MapReduce: Simplified Data Processing on Large Clusters"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This presentation explains how the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks."
            },
            "venue": {
                "fragments": [],
                "text": "OSDI"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104537710"
                        ],
                        "name": "J. MacQueen",
                        "slug": "J.-MacQueen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "MacQueen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacQueen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 20
                            }
                        ],
                        "text": "Over the past decade, supervised learning algorithms have gained widespread acceptance in natural language processing (NLP)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 20
                            }
                        ],
                        "text": "K-Means clustering (MacQueen 1967) is one of the simplest and most well-known clustering algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6278891,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ac8ab51a86f1a9ae74dd0e4576d1a019f5e654ed",
            "isKey": false,
            "numCitedBy": 24210,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to describe a process for partitioning an N-dimensional population into k sets on the basis of a sample. The process, which is called 'k-means,' appears to give partitions which are reasonably efficient in the sense of within-class variance. That is, if p is the probability mass function for the population, S = {S1, S2, * *, Sk} is a partition of EN, and ui, i = 1, 2, * , k, is the conditional mean of p over the set Si, then W2(S) = ff=ISi f z u42 dp(z) tends to be low for the partitions S generated by the method. We say 'tends to be low,' primarily because of intuitive considerations, corroborated to some extent by mathematical analysis and practical computational experience. Also, the k-means procedure is easily programmed and is computationally economical, so that it is feasible to process very large samples on a digital computer. Possible applications include methods for similarity grouping, nonlinear prediction, approximating multivariate distributions, and nonparametric tests for independence among several variables. In addition to suggesting practical classification methods, the study of k-means has proved to be theoretically interesting. The k-means concept represents a generalization of the ordinary sample mean, and one is naturally led to study the pertinent asymptotic behavior, the object being to establish some sort of law of large numbers for the k-means. This problem is sufficiently interesting, in fact, for us to devote a good portion of this paper to it. The k-means are defined in section 2.1, and the main results which have been obtained on the asymptotic behavior are given there. The rest of section 2 is devoted to the proofs of these results. Section 3 describes several specific possible applications, and reports some preliminary results from computer experiments conducted to explore the possibilities inherent in the k-means idea. The extension to general metric spaces is indicated briefly in section 4. The original point of departure for the work described here was a series of problems in optimal classification (MacQueen [9]) which represented special"
            },
            "slug": "Some-methods-for-classification-and-analysis-of-MacQueen",
            "title": {
                "fragments": [],
                "text": "Some methods for classification and analysis of multivariate observations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31718631"
                        ],
                        "name": "B. Bloom",
                        "slug": "B.-Bloom",
                        "structuredName": {
                            "firstName": "Burton",
                            "lastName": "Bloom",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bloom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 93
                            }
                        ],
                        "text": "To reduce the memory requirement for storing a large number of phrases, we used Blom Filter (Bloom 1970) to decide whether a sequence of tokens is a phrase."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7931252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f39a2c11983b21fd5054d5393614959bfbc4e50f",
            "isKey": false,
            "numCitedBy": 7101,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper trade-offs among certain computational factors in hash coding are analyzed. The paradigm problem considered is that of testing a series of messages one-by-one for membership in a given set of messages. Two new hash-coding methods are examined and compared with a particular conventional hash-coding method. The computational factors considered are the size of the hash area (space), the time required to identify a message as a nonmember of the given set (reject time), and an allowable error frequency.\nThe new methods are intended to reduce the amount of space required to contain the hash-coded information from that associated with conventional methods. The reduction in space is accomplished by exploiting the possibility that a small fraction of errors of commission may be tolerable in some applications, in particular, applications in which a large amount of data is involved and a core resident hash area is consequently not feasible using conventional methods.\nIn such applications, it is envisaged that overall performance could be improved by using a smaller core resident hash area in conjunction with the new methods and, when necessary, by using some secondary and perhaps time-consuming test to \u201ccatch\u201d the small fraction of errors associated with the new methods. An example is discussed which illustrates possible areas of application for the new methods.\nAnalysis of the paradigm problem demonstrates that allowing a small number of test messages to be falsely identified as members of the given set will permit a much smaller hash area to be used without increasing reject time."
            },
            "slug": "Space/time-trade-offs-in-hash-coding-with-allowable-Bloom",
            "title": {
                "fragments": [],
                "text": "Space/time trade-offs in hash coding with allowable errors"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Analysis of the paradigm problem demonstrates that allowing a small number of test messages to be falsely identified as members of the given set will permit a much smaller hash area to be used without increasing reject time."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 53
                            }
                        ],
                        "text": "Previous approaches, e.g., (Miller et al. 2004) and (Koo et al. 2008), have all used the Brown algorithm for clustering (Brown et al. 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our query classifier is on par with the best system in KDDCUP 2005 without resorting to labor intensive knowledge engineering efforts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 123
                            }
                        ],
                        "text": "This method has been shown to be quite successful in named entity recognition (Miller et al. 2004) and dependency parsing (Koo et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simple Semisupervised Dependency Parsing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 65
                            }
                        ],
                        "text": "For each query class, we train a logistic regression classifier (Vapnik 1999) with L2 regularization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 198120202,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "15cbb7b85622db0d17ade1d24fa7cfa321d16bd6",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory,-Second-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory, Second Edition"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 52
                            }
                        ],
                        "text": "In earlier work on semi-supervised learning, e.g., (Blum and Mitchell 1998), the classifiers learned from unlabeled data were used directly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "e-offs in hash coding with allowable errors, Communications of the ACM"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Report : Facing a Great Challenge"
            },
            "venue": {
                "fragments": [],
                "text": "SIGKDD Explorations"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 73
                            }
                        ],
                        "text": "To obtain a list of phrases to be clustered, we followed the approach in (Lin et al., 2008) by collecting 20 million unique queries from an anonymized query log that are found in a 700 billion token web corp us with a minimum frequency count of 100."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 74
                            }
                        ],
                        "text": "To obtain a list of phrases to be clustered, we followed the approach in (Lin et al., 2008) by collecting 20 million unique queries from an anonymized query log that are found in a 700 billion token web corpus with a minimum frequency count of 100."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mining Parenthetical Translations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "-2005 Report: Facing a Great Challenge. SIGKDD Explorations"
            },
            "venue": {
                "fragments": [],
                "text": "-2005 Report: Facing a Great Challenge. SIGKDD Explorations"
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Phrase-Clustering-for-Discriminative-Learning-Lin-Wu/b5e12de7d3f2a66bfcf10a510f9ac80afb3541c1?sort=total-citations"
}