{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145660147"
                        ],
                        "name": "H. Franco",
                        "slug": "H.-Franco",
                        "structuredName": {
                            "firstName": "Horacio",
                            "lastName": "Franco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Franco"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 859773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d96910d3ac99d939563b484d6180efbcbb5b4a0",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors have previously demonstrated that feedforward networks can be used to estimate local output probabilities in hidden Markov model (HMM) speech recognition systems (Renals et al., 1991). These connectionist techniques are integrated into the DECIPHER system, with experiments being performed using the speaker-independent DARPA RM database. The results indicate that: connectionist probability estimation can improve performance of a context-independent maximum-likelihood-trained HMM system; performance of the connectionist system is close to what can be achieved using (context-dependent) HMM systems of much higher complexity; and mixing connectionist and maximum-likelihood estimates can improve the performance of the state-of-the-art context-independent HMM system.<<ETX>>"
            },
            "slug": "Connectionist-probability-estimation-in-the-speech-Renals-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist probability estimation in the DECIPHER speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Results indicate that connectionist probability estimation can improve performance of a context-independent maximum-likelihood-trained HMM system; performance of the connectionist system is close to what can be achieved using (context-dependent) HMM systems of much higher complexity."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(For a proof of this, see [ 58 ].) The local probabilities may be estimated by a MLP, with the addition of binary input units, representing the pr evious state (one for each possible previous state)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61058350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d82e058a5c40954b8f5db170a298a889a254c37",
            "isKey": false,
            "numCitedBy": 1409,
            "numCiting": 190,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nConnectionist Speech Recognition: A Hybrid Approach describes the theory and implementation of a method to incorporate neural network approaches into state-of-the-art continuous speech recognition systems based on Hidden Markov Models (HMMs) to improve their performance. In this framework, neural networks (and in particular, multilayer perceptrons or MLPs) have been restricted to well-defined subtasks of the whole system, i.e., HMM emission probability estimation and feature extraction. The book describes a successful five year international collaboration between the authors. The lessons learned form a case study that demonstrates how hybrid systems can be developed to combine neural networks with more traditional statistical approaches. The book illustrates both the advantages and limitations of neural networks in the framework of a statistical system. Using standard databases and comparing with some conventional approaches, it is shown that MLP probability estimation can improve recognition performance. Other approaches are discussed, though there is no such unequivocal experimental result for these methods. Connectionist Speech Recognition: A Hybrid Approach is of use to anyone intending to use neural networks for speech recognition or within the framework provided by an existing successful statistical approach. This includes research and development groups working in the field of speech recognition, both with standard and neural network approaches, as well as other pattern recognition and/or neural network researchers. This book is also suitable as a text for advanced courses on neural networks or speech processing."
            },
            "slug": "Connectionist-Speech-Recognition:-A-Hybrid-Approach-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist Speech Recognition: A Hybrid Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705919"
                        ],
                        "name": "Chuck Wooters",
                        "slug": "Chuck-Wooters",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Wooters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chuck Wooters"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "the global conditional likelihood p( Np+1, QNp+1| p 1, Q p 1) [ 57 ,58]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14326530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c40c29770bcb3d0d8bae48ad94fd37673d1cb2e3",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work has shown the ability of Multilayer Perceptrons (MLPs) to estimate emission probabilities for Hidden Markov Models (HMMs). The advantages of a speech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. This paper presents results on the speaker-dependent portion of DARPA's English language Resource Management database. Results support the previously reported utility of MLP probability estimation for continuous speech recognition. An additional approach we are pursuing is to use MLPs as nonlinear predictors for autoregressive HMMs. While this is shown to be more compatible with the HMM formalism, it still suffers from several limitations. This approach is generalized to take account of time correlation between successive observations, without any restrictive assumptions about the driving noise."
            },
            "slug": "Connectionist-Approaches-to-the-Use-of-Markov-for-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist Approaches to the Use of Markov Models for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Results support the previously reported utility of MLP probability estimation for continuous speech recognition and are generalized to take account of time correlation between successive observations, without any restrictive assumptions about the driving noise."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145660147"
                        ],
                        "name": "H. Franco",
                        "slug": "H.-Franco",
                        "structuredName": {
                            "firstName": "Horacio",
                            "lastName": "Franco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Franco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2242830"
                        ],
                        "name": "Victor Abrash",
                        "slug": "Victor-Abrash",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Abrash",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Abrash"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 33
                            }
                        ],
                        "text": "A variant of the second approach [70,71] uses an equivalent decomposition: p(ci, dj|x) = p(di|x)p(cj |di,x) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5049191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4d53c75cabc89ad9f3926976430cdffb213ad16",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "n M In this paper we present a hybrid multilayer perceptron (MLP)/hidde arkov model (HMM) speaker-independent continuous-speech recogni-b tion system, in which the advantages of both approaches are combined y using MLPs to estimate the state-dependent observation probabilities p of an HMM. New MLP architectures and training procedures are resented which allow the modeling of multiple distributions for phonetic a p classes and context-dependent phonetic classes. Comparisons with ure HMM system illustrate advantages of the hybrid approach both in terms of recognition accuracy and number of parameters required."
            },
            "slug": "Hybrid-neural-network/hidden-Markov-model-Cohen-Franco",
            "title": {
                "fragments": [],
                "text": "Hybrid neural network/hidden Markov model continuous-speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A hybrid multilayer perceptron (MLP)/hidde arkov model (HMM) speaker-independent continuous-speech recogni-b tion system, in which the advantages of both approaches are combined using MLPs to estimate the state-dependent observation probabilities of an HMM."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8911025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4914df5c8b886e85502bba35a35741d05639bd8",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the period of 1987-1991, a series of theoretical and experimental results have suggested that multilayer perceptrons (MLP) are an effective family of algorithms for the smooth estimation of high-dimension probability density functions that are useful in continuous speech recognition. The early form of this work has focused on hidden Markov models (HMM) that are independent of phonetic context. More recently, the theory has been extended to context-dependent models. The authors review the basic principles of their hybrid HMM/MLP approach and describe a series of improvements that are analogous to the system modifications instituted for the leading conventional HMM systems over the last few years. Some of these methods directly trade off computational complexity for reduced requirements of memory and memory bandwidth. Results are presented on the widely used Resource Management speech database that has been distributed by the US National Institute of Standards and Technology."
            },
            "slug": "Continuous-speech-recognition-by-connectionist-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition by connectionist statistical methods"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The authors review the basic principles of their hybrid HMM/MLP approach and describe a series of improvements that are analogous to the system modifications instituted for the leading conventional HMM systems over the last few years."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065228513"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14700006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee50abb5aff3e5c43a38f24396b9552d593a9ae0",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The statistical use of a particular classic form of a connectionist system, the multilayer perceptron (MLP), is described in the context of the recognition of continuous speech. A discriminant hidden Markov model (HMM) is defined, and it is shown how a particular MLP with contextual and extra feedback input units can be considered as a general form of such a Markov model. A link between these discriminant HMMs, trained along the Viterbi algorithm, and any other approach based on least mean square minimization of an error function (LMSE) is established. It is shown theoretically and experimentally that the outputs of the MLP (when trained along the LMSE or the entropy criterion) approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities. Results of a series of speech recognition experiments are reported. The possibility of embedding MLP into HMM is described. Relations with other recurrent networks are also explained. >"
            },
            "slug": "Links-Between-Markov-Models-and-Multilayer-Bourlard-Wellekens",
            "title": {
                "fragments": [],
                "text": "Links Between Markov Models and Multilayer Perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown theoretically and experimentally that the outputs of the MLP approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17831368,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5001470e8808afe9887afbe48e2eaaf1a0395d10",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We are developing a phoneme based, speaker-dependent continuous speech recognition system embedding a Multilayer Perceptron (MLP) (i.e., a feedforward Artificial Neural Network), into a Hidden Markov Model (HMM) approach. In [Bourlard & Wellekens], it was shown that MLPs were approximating Maximum a Posteriori (MAP) probabilities and could thus be embedded as an emission probability estimator in HMMs. By using contextual information from a sliding window on the input frames, we have been able to improve frame or phoneme classification performance over the corresponding performance for Simple Maximum Likelihood (ML) or even MAP probabilities that are estimated without the benefit of context. However, recognition of words in continuous speech was not so simply improved by the use of an MLP, and several modifications of the original scheme were necessary for getting acceptable performance. It is shown here that word recognition performance for a simple discrete density HMM system appears to be somewhat better when MLP methods are used to estimate the emission probabilities."
            },
            "slug": "A-Continuous-Speech-Recognition-System-Embedding-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "A Continuous Speech Recognition System Embedding MLP into HMM"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown here that word recognition performance for a simple discrete density HMM system appears to be somewhat better when MLP methods are used to estimate the emission probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "One way of achieving this is by adopting a normalizing output transfer function such as the normalized exponential or \u2018softmax\u2019 [34],"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18865663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "830ccb44084d9d6cdcb70d623df5012ae4835142",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the attractions of neural network approaches to pattern recognition is the use of a discrimination-based training method. We show that once we have modified the output layer of a multilayer perceptron to provide mathematically correct probability distributions, and replaced the usual squared error criterion with a probability-based score, the result is equivalent to Maximum Mutual Information training, which has been used successfully to improve the performance of hidden Markov models for speech recognition. If the network is specially constructed to perform the recognition computations of a given kind of stochastic model based classifier then we obtain a method for discrimination-based training of the parameters of the models. Examples include an HMM-based word discriminator, which we call an 'Alphanet'."
            },
            "slug": "Training-Stochastic-Model-Recognition-Algorithms-as-Bridle",
            "title": {
                "fragments": [],
                "text": "Training Stochastic Model Recognition Algorithms as Networks can Lead to Maximum Mutual Information Estimation of Parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "It is shown that once the output layer of a multilayer perceptron is modified to provide mathematically correct probability distributions, and the usual squared error criterion is replaced with a probability-based score, the result is equivalent to Maximum Mutual Information training."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47963084"
                        ],
                        "name": "E. Singer",
                        "slug": "E.-Singer",
                        "structuredName": {
                            "firstName": "Elliot",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50471368"
                        ],
                        "name": "R. Lippman",
                        "slug": "R.-Lippman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lippman",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lippman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62570049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2839e339237dcf2dd09a3159c82215a5d62df19",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A high performance speaker-independent isolated-word speech recognizer was developed which combines hidden Markov models (HMMs) and radial basis function (RBF) neural networks. RBF networks in this recognizer use discriminant training techniques to estimate Bayesian probabilities for each speech frame while HMM decoders estimate overall word likelihood scores for network outputs. RBF training is performed after the HMM recognizer has automatically segmented training tokens using forced Viterbi alignment. In recognition experiments using a speaker-independent E-set database, the hybrid recognizer had an error rate of 11.5% compared to 15.7% for the robust unimodal Gaussian HMM recognizer upon which the hybrid system was based. The error rate was also lower than that of a tied-mixture HMM recognizer with the same number of centers. These results demonstrate that RBF networks can be successfully incorporated in hybrid recognizers and suggest that they may be capable of good performance with fewer parameters than required by Gaussian mixture classifiers.<<ETX>>"
            },
            "slug": "A-speech-recognizer-using-radial-basis-function-in-Singer-Lippman",
            "title": {
                "fragments": [],
                "text": "A speech recognizer using radial basis function neural networks in an HMM framework"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The results demonstrate that RBF networks can be successfully incorporated in hybrid recognizers and suggest that they may be capable of good performance with fewer parameters than required by Gaussian mixture classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861227"
                        ],
                        "name": "K. Iso",
                        "slug": "K.-Iso",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Iso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Iso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110691850"
                        ],
                        "name": "Takao Watanabe",
                        "slug": "Takao-Watanabe",
                        "structuredName": {
                            "firstName": "Takao",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takao Watanabe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57863167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2898aabdf8a0eef517c87bf82fdd113c2b3ebd40",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A speech recognition model called the neural prediction model (NPM) is proposed. The model uses a sequence of multilayer perceptrons (MLPs) as a separate nonlinear predictor for each class. It is designed to represent temporal structures of speech patterns as recognition cues. In particular, temporal correlation in successive feature vectors of a speech pattern is represented in the mappings formed as MLP input-output relations. Temporal distortion of speech is efficiently normalized by a dynamic-programming technique. Recognition and training algorithms are presented based on the combination of dynamic-programming and back-propagation techniques. Evaluation experiments were conducted using ten-digit vocabulary samples uttered by 107 speakers. A 99.8% recognition accuracy was obtained. This suggests that the model is effective for speaker-independent speech recognition.<<ETX>>"
            },
            "slug": "Speaker-independent-word-recognition-using-a-neural-Iso-Watanabe",
            "title": {
                "fragments": [],
                "text": "Speaker-independent word recognition using a neural prediction model"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A speech recognition model called the neural prediction model (NPM) is proposed, which uses a sequence of multilayer perceptrons (MLPs) as a separate nonlinear predictor for each class to represent temporal structures of speech patterns as recognition cues."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143811539"
                        ],
                        "name": "S. Austin",
                        "slug": "S.-Austin",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Austin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Austin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2354787"
                        ],
                        "name": "G. Zavaliagkos",
                        "slug": "G.-Zavaliagkos",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Zavaliagkos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zavaliagkos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152901373"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "Evan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62030667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6dd2cbed82ac119349336a3d711e631913abb09",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present the concept of a segmental neural net (SNN) for phonetic modeling in continuous speech recognition (CSR) and demonstrate how this can be used with a multiple hypothesis (or N-Best) paradigm to combine different CSR systems. In particular, the authors developed a system that combines the SNN with a hidden Markov model (HMM) system. In a speaker-independent, 1000-word CSR test using a word-pair grammar, the error rate for the hybrid system dropped 25% from that of a state-of-the-art HMM system alone. By taking into account all the frames of a phonetic segment simultaneously, the SNN overcomes the well-known conditional-independence limitation of HMMs. The hybrid SNN/HMM system generates likely phonetic segmentations from the HMM N-best list, which are scored by the SNN. The HMM and SNN scores are then combined to optimize performance.<<ETX>>"
            },
            "slug": "Speech-recognition-using-segmental-neural-nets-Austin-Zavaliagkos",
            "title": {
                "fragments": [],
                "text": "Speech recognition using segmental neural nets"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A system that combines the SNN with a hidden Markov model (HMM) system for phonetic modeling in continuous speech recognition (CSR) and demonstrates how this can be used with a multiple hypothesis (or N-Best) paradigm to combine different CSR systems."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2376916"
                        ],
                        "name": "G. Flammia",
                        "slug": "G.-Flammia",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Flammia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Flammia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688499"
                        ],
                        "name": "R. Kompe",
                        "slug": "R.-Kompe",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Kompe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kompe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Initial work in using global optimization methods for conti nuous speech recognition has been performed by Bridle [61], Niles [62] and Bengio [ 63 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 894840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffbe67c217967b6bfb0a5ecc0dc4cdd5cda65776",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) is proposed. ANNs are suitable for performing phonetic classification, whereas HMMs have been proven successful at modeling the temporal structure of the speech signal. In the approach described, the ANN outputs constitute the sequence of observation vectors for the HMM. An algorithm is proposed for global optimization of all the parameters. Results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported.<<ETX>>"
            },
            "slug": "Global-optimization-of-a-neural-network-hidden-Bengio-Mori",
            "title": {
                "fragments": [],
                "text": "Global optimization of a neural network-hidden Markov model hybrid"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) with results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705919"
                        ],
                        "name": "Chuck Wooters",
                        "slug": "Chuck-Wooters",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Wooters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chuck Wooters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 44
                            }
                        ],
                        "text": "The first approach has been investigated in [46,69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61017150,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1116b32168ca91607d81e8aa6be64ee7b539449",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A series of theoretical and experimental results have suggested that multilayer perceptrons (MLPs) are an effective family of algorithms for the smooth estimate of highly dimensioned probability density functions that are useful in continuous speech recognition. All of these systems have exclusively used context-independent phonetic models, in the sense that the probabilities or costs are estimated for simple speech units such as phonemes or words, rather than biphones or triphones. Numerous conventional systems based on hidden Markov models (HMMs) have been reported that use triphone or triphone like context-dependent models. In one case the outputs of many context-dependent MLPs (one per context class) were used to help choose the best sentence from the N best sentences as determined by a context-dependent HMM system. It is shown how, without any simplifying assumptions, one can estimate likelihoods for context-dependent phonetic models with nets that are not substantially larger than context-independent MLPs.<<ETX>>"
            },
            "slug": "CDNN:-a-context-dependent-neural-network-for-speech-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "CDNN: a context dependent neural network for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown how, without any simplifying assumptions, one can estimate likelihoods for context-dependent phonetic models with nets that are not substantially larger than context-independent MLPs."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40268570"
                        ],
                        "name": "A. J. Robinson",
                        "slug": "A.-J.-Robinson",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Robinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Robinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14787570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6629770cb6a00ad585918e71fe6dbad829ad0d1",
            "isKey": false,
            "numCitedBy": 543,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an application of recurrent networks for phone probability estimation in large vocabulary speech recognition. The need for efficient exploitation of context information is discussed; a role for which the recurrent net appears suitable. An overview of early developments of recurrent nets for phone recognition is given along with the more recent improvements that include their integration with Markov models. Recognition results are presented for the DARPA TIMIT and Resource Management tasks, and it is concluded that recurrent nets are competitive with traditional means for performing phone probability estimation."
            },
            "slug": "An-application-of-recurrent-nets-to-phone-Robinson",
            "title": {
                "fragments": [],
                "text": "An application of recurrent nets to phone probability estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Recognition results are presented for the DARPA TIMIT and Resource Management tasks, and it is concluded that recurrent nets are competitive with traditional means for performing phone probability estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144887151"
                        ],
                        "name": "D. McKelvie",
                        "slug": "D.-McKelvie",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McKelvie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McKelvie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895502"
                        ],
                        "name": "F. McInnes",
                        "slug": "F.-McInnes",
                        "structuredName": {
                            "firstName": "Fergus",
                            "lastName": "McInnes",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. McInnes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57183426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91c0cc34d9a8aa872e61cb74ddc9bd750929436b",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognition performances of two front ends are compared for two continuous speech recognition tasks. First, a neural network model (NNM) front end was used, with frame labeling performed by a radial basis function network and segmentation by a Viterbi algorithm. The second front end was a discrete hidden Markov model (HMM), featuring explicit state duration probability distributions. Two experiments were performed. The first used a speaker-dependent database, with a lexicon of 571 words. Using a low-perplexity grammar, the NNM front end produced a word accuracy of 94% and a sentence accuracy of 86%. This was slightly inferior to the HMM front end, which produced word accuracies of 96% and sentence accuracies of 88%. Without a grammar, word accuracies of 58% (NNM) and 49% (HMM) were recorded. The second set of experiments used the MIT portion of the TIMIT database (415 speakers and 2072 sentences in total). Results were poor for both front ends, with the NNM producing marginally better results.<<ETX>>"
            },
            "slug": "A-comparative-study-of-continuous-speech-using-and-Renals-McKelvie",
            "title": {
                "fragments": [],
                "text": "A comparative study of continuous speech recognition using neural networks and hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "The recognition performances of two front ends are compared for two continuous speech recognition tasks, with the NNM producing marginally better results than the HMM."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144711425"
                        ],
                        "name": "T. Robinson",
                        "slug": "T.-Robinson",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Robinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Robinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1998157"
                        ],
                        "name": "F. Fallside",
                        "slug": "F.-Fallside",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Fallside",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fallside"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61818881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "758eae04fc9f4331b0ceab797387c8fc9f00db58",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-recurrent-error-propagation-network-speech-system-Robinson-Fallside",
            "title": {
                "fragments": [],
                "text": "A recurrent error propagation network speech recognition system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152901373"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "Evan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2727234"
                        ],
                        "name": "Y. Chow",
                        "slug": "Y.-Chow",
                        "structuredName": {
                            "firstName": "Yen-lu",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353221"
                        ],
                        "name": "O. Kimball",
                        "slug": "O.-Kimball",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Kimball",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kimball"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4953636"
                        ],
                        "name": "M. Krasner",
                        "slug": "M.-Krasner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Krasner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krasner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, traditional HMM systems have experienced a much improved performance by modeling phones in context [ 67 ,6,7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60579533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df53e0dc66eb13bb51c6e4803ceae56d3ebe6f23",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the results of our work in designing a system for phonetic recognition of unrestricted continuous speech. We describe several algorithms used to recognize phonemes using context-dependent Hidden Markov Models of the phonemes. We present results for several variations of the parameters of the algorithms. In addition, we propose a technique that makes it possible to integrate traditional acoustic-phonetic features into a hidden Markov process. The categorical decisions usually associated with heuristic acoustic-phonetic algorithms are replaced by automated training techniques and global search strategies. The combination of general spectral information and specific acoustic-phonetic features is shown to result in more accurate phonetic recognition than either representation by itself."
            },
            "slug": "Context-dependent-modeling-for-acoustic-phonetic-of-Schwartz-Chow",
            "title": {
                "fragments": [],
                "text": "Context-dependent modeling for acoustic-phonetic recognition of continuous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The combination of general spectral information and specific acoustic-phonetic features is shown to result in more accurate phonetic recognition than either representation by itself."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '85. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47749181"
                        ],
                        "name": "M. Franzini",
                        "slug": "M.-Franzini",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Franzini",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Franzini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110051082"
                        ],
                        "name": "K. Lee",
                        "slug": "K.-Lee",
                        "structuredName": {
                            "firstName": "K.-F.",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "The Viterbi approximation to this is analogous to segmental k-means training and has been referred to as embedded training [64] or connectionist Viterbi training [65]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12292955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f866ac085771f5676800db2d9b102975b2a1b2d7",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A hybrid method for continuous-speech recognition which combines hidden Markov models (HMMs) and a connectionist technique called connectionist Viterbi training (CVT) is presented. CVT can be run iteratively and can be applied to large-vocabulary recognition tasks. Successful completion of training the connectionist component of the system, despite the large network size and volume of training data, depends largely on several measures taken to reduce learning time. The system is trained and tested on the TI/NBS speaker-independent continuous-digits database. Performance on test data for unknown-length strings is 98.5% word accuracy and 95.0% string accuracy. Several improvements to the current system are expected to increase these accuracies significantly.<<ETX>>"
            },
            "slug": "Connectionist-Viterbi-training:-a-new-hybrid-method-Franzini-Lee",
            "title": {
                "fragments": [],
                "text": "Connectionist Viterbi training: a new hybrid method for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A hybrid method for continuous-speech recognition which combines hidden Markov models (HMMs) and a connectionist technique called connectionist Viterbi training (CVT) is presented and can be run iteratively and applied to large-vocabulary recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112105858"
                        ],
                        "name": "William Y. Huang",
                        "slug": "William-Y.-Huang",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Huang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Y. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990248"
                        ],
                        "name": "R. Lippmann",
                        "slug": "R.-Lippmann",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lippmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lippmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39981709"
                        ],
                        "name": "B. Gold",
                        "slug": "B.-Gold",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Gold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58806076,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31976fe5c1c2cf0fe151ac2698ad329b4c63c3f6",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Artificial neural networks are of interest because algorithms used in many speech recognizers can be implemented using highly parallel neural net architectures and because new parallel algorithms are being development that are inspired by biological nervous systems. Some neural net approaches are resented for the problem of static pattern classification and time alignment. For static pattern classification, multi-layer perceptron classifiers trained with back propagation can form arbitrary decision regions, are robust, and train rapidly for convex decision regions. For time alignment, the Viterbi net is a neural net implementation of the Viterbi decoder used very effectively in recognition systems based on hidden Markov models (HMMs).<<ETX>>"
            },
            "slug": "A-neural-net-approach-to-speech-recognition-Huang-Lippmann",
            "title": {
                "fragments": [],
                "text": "A neural net approach to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work has shown that for static pattern classification, multi-layer perceptron classifiers trained with back propagation can form arbitrary decision regions, are robust, and train rapidly for convex decision regions."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9563026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd62c9976534a6a2096a38244f6cbb03635a127e",
            "isKey": false,
            "numCitedBy": 2787,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: (1) using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation; and (2) the time-delay arrangement enables the network to discover acoustic-phonetic features and the temporal relationships between them independently of position in time and therefore not blurred by temporal shifts in the input. As a recognition task, the speaker-dependent recognition of the phonemes B, D, and G in varying phonetic contexts was chosen. For comparison, several discrete hidden Markov models (HMM) were trained to perform the same task. Performance evaluation over 1946 testing tokens from three speakers showed that the TDNN achieves a recognition rate of 98.5% correct while the rate obtained by the best of the HMMs was only 93.7%. >"
            },
            "slug": "Phoneme-recognition-using-time-delay-neural-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition using time-delay neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61370836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f613e5481d8d567573b0ffa7b8e1c5b07d33a04",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors focus on a tutorial description of the hybrid HMM/ANN method. The approach has been applied to large vocabulary continuous speech recognition, and variants are in use by many researchers, The method provides a mechanism for incorporating a range of sources of evidence without strong assumptions about their joint statistics, and may have applicability to much more complex systems that can incorporate deep acoustic and linguistic context. The method is inherently discriminant and conservative of parameters. Despite these potential advantages, the hybrid method has focused on implementing fairly simple systems, which do surprisingly well on large continuous speech recognition tasks, Researchers are only beginning to explore the use of more complex structures with this paradigm. In particular, they are just beginning to look at the connectionist inference of language models (including phonology) from data, which may be required in order to take advantage of locally discriminant probabilities rather than simply translating to likelihoods. Finally, the authors' current intuition is that more advanced versions of the hybrid method can greatly benefit from a perceptual perspective. >"
            },
            "slug": "Continuous-speech-recognition-Morgan-Bourlard",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The authors focus on a tutorial description of the hybrid HMM/ANN method, which provides a mechanism for incorporating a range of sources of evidence without strong assumptions about their joint statistics, and may have applicability to much more complex systems that can incorporate deep acoustic and linguistic context."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Process. Mag."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15553242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "436f38dc28ca25af965b202ebe0e27c747888da6",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a signal modeling technique based upon finite mixture autoregressive probabilistic functions of Markov chains is developed and applied to the problem of speech recognition, particularly speaker-independent recognition of isolated digits. Two types of mixture probability densities are investigated: finite mixtures of Gaussian autoregressive densities (GAM) and nearest-neighbor partitioned finite mixtures of Gaussian autoregressive densities (PGAM). In the former (GAM), the observation density in each Markov state is simply a (stochastically constrained) weighted sum of Gaussian autoregressive densities, while in the latter (PGAM) it involves nearest-neighbor decoding which in effect, defines a set of partitions on the observation space. In this paper we discuss the signal modeling methodology and give experimental results on speaker independent recognition of isolated digits. We also discuss the potential use of the modeling technique for other applications."
            },
            "slug": "Mixture-autoregressive-hidden-Markov-models-for-Juang-Rabiner",
            "title": {
                "fragments": [],
                "text": "Mixture autoregressive hidden Markov models for speech signals"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The signal modeling methodology is discussed and experimental results on speaker independent recognition of isolated digits are given and the potential use of the modeling technique for other applications are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47944231"
                        ],
                        "name": "L. Dodd",
                        "slug": "L.-Dodd",
                        "structuredName": {
                            "firstName": "L",
                            "lastName": "Dodd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Dodd"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Bridle and Bengio used this approach to optimize the input parameters via some (linear or nonlinear) transform, training the parameters of the HMM by a maximum likelihood process."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "Initial work in using global optimization methods for continuous speech recognition has been performed by Bridle [61], Niles [62] and Bengio [63]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 15
                            }
                        ],
                        "text": "More recently, Bridle introduced the \u201calphanet\u201d representation [60] of HMMs, in which the computation of the HMM \u201cforward\u201d probabilities \u03b1jt = P(Xt1, q(t) = j) is performed by the forward dynamics of a recurrent network."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62649110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6c94cc324f585bd6c004f2b99b5589568643e45",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors extend to continuous speech recognition (CSR) the Alphanet approach to integrating backprop networks and HMM (hidden Markov model)-based isolated word recognition. They present the theory of a method for discriminative training of components of a CSR system, using training data in the form of complete sentences. The derivatives of the discriminative score with respect to the parameters are expressed in terms of the posterior probabilities of state occupancies (gammas) under two conditions called 'clamped' and 'free' because they correspond to the two conditions in Boltzmann machine training. The authors compute these clamped and free gammas using the forward-backward algorithm twice, and use the differences to drive the adaptation of a preprocessing data transformation, which can be thought of as replacing the linear transformation which yields MFCCs, or which normalizes a grand covariance matrix.<<ETX>>"
            },
            "slug": "An-Alphanet-approach-to-optimising-input-for-speech-Bridle-Dodd",
            "title": {
                "fragments": [],
                "text": "An Alphanet approach to optimising input transformations for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The authors extend to continuous speech recognition (CSR) the Alphanet approach to integrating backprop networks and HMM (hidden Markov model)-based isolated word recognition and present the theory of a method for discriminative training of components of a CSR system, using training data in the form of complete sentences."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14789841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4775e2f0d27e8be4aae7b5b5c2560b96ce2eb58",
            "isKey": false,
            "numCitedBy": 1403,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them."
            },
            "slug": "A-Maximum-Likelihood-Approach-to-Continuous-Speech-Bahl-Jelinek",
            "title": {
                "fragments": [],
                "text": "A Maximum Likelihood Approach to Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a number of statistical models for use in speech recognition, with special attention to determining the parameters for such models from sparse data, and describes two decoding methods appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121831295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7c3f98c68b6609599771b1161c0d94200eae03dc",
            "isKey": false,
            "numCitedBy": 501,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Continuously-variable-duration-hidden-Markov-models-Levinson",
            "title": {
                "fragments": [],
                "text": "Continuously variable duration hidden Markov models for automatic speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "More recently, Bridle introduced the \u201calphanet\u201d representation [60] of HMMs, in which the computation of the HMM \u201cforward\u201d probabilities \u03b1jt = P(Xt1, q(t) = j) is performed by the forward dynamics of a recurrent network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41994273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c91c2ac02e33caff601b2e4d62a6841b33ca3929",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Alpha-nets:-A-recurrent-'neural'-network-with-a-Bridle",
            "title": {
                "fragments": [],
                "text": "Alpha-nets: A recurrent 'neural' network architecture with a hidden Markov model interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56128297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f09ce0dd760857e0d0e4879f6e2543f04c5d33",
            "isKey": false,
            "numCitedBy": 926,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for estimating the parameters of hidden Markov models of speech is described. Parameter values are chosen to maximize the mutual information between an acoustic observation sequence and the corresponding word sequence. Recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "slug": "Maximum-mutual-information-estimation-of-hidden-for-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "Maximum mutual information estimation of hidden Markov model parameters for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method for estimating the parameters of hidden Markov models of speech is described and recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699205"
                        ],
                        "name": "S. Furui",
                        "slug": "S.-Furui",
                        "structuredName": {
                            "firstName": "Sadaoki",
                            "lastName": "Furui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Furui"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "In addition to these 13 coefficients, we estimate their temporal derivatives [72], giving 26 coefficients per frame."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40519557,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "f64038de5e388bce2f0575cfb4a291a41e3bab57",
            "isKey": false,
            "numCitedBy": 899,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new isolated word recognition technique based on a combination of instantaneous and dynamic features of the speech spectrum. This technique is shown to be highly effective in speaker-independent speech recognition. Spoken utterances are represented by time sequences of cepstrum coefficients and energy. Regression coefficients for these time functions are extracted for every frame over an approximately 50 ms period. Time functions of regression coefficients extracted for cepstrum and energy are combined with time functions of the original cepstrum coefficients, and used with a staggered array DP matching algorithm to compare multiple templates and input speech. Speaker-independent isolated word recognition experiments using a vocabulary of 100 Japanese city names indicate that a recognition error rate of 2.4 percent can be obtained with this method. Using only the original cepstrum coefficients the error rate is 6.2 percent."
            },
            "slug": "Speaker-independent-isolated-word-recognition-using-Furui",
            "title": {
                "fragments": [],
                "text": "Speaker-independent isolated word recognition using dynamic features of speech spectrum"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper proposes a new isolated word recognition technique based on a combination of instantaneous and dynamic features of the speech spectrum that is shown to be highly effective in speaker-independent speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3175118"
                        ],
                        "name": "S. Soudoplatoff",
                        "slug": "S.-Soudoplatoff",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Soudoplatoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soudoplatoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This has been used in HMM speech recognition by  Soudoplatoff (1986) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61722643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "164ec58ac12392682bed2c43247a7d36ed0a6989",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents how to avoid the labelling part of a speech recognition strategy based on hidden Markov models, while keeping a stochastic formulation. After a brief recall of how a Markov model can be used for speech recognition, we propose another formulation, in which the labels are suppressed, dealing only with continuous parameters. The notion of speech generator is then introduced, and the formulas for speech training as well as decoding are rewritten. This new formulation leads to the fact that the probability densitiesp(x | G), whereGis a generator, andxan acoustic vector, must be estimated. We explain our choice of non-parametric methods, using Parzen estimators. Those estimators require a kernel function, which we choose in a simple manner, and the value for the radius of the kernel, which is the key problem. Successively statistical solution, information theory solution, and an original topological solution are presented, the last being retained. We finally present the results of an application of this model to a 5000 words speech recognition system. The results showed that one can decrease the error-rate, by switching from a simple labelling scheme to this continuous parameter model."
            },
            "slug": "Markov-modeling-of-continuous-parameters-in-speech-Soudoplatoff",
            "title": {
                "fragments": [],
                "text": "Markov modeling of continuous parameters in speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results showed that one can decrease the error-rate, by switching from a simple labelling scheme to this continuous parameter model, and the results of an application of this model to a 5000 words speech recognition system were presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102981024"
                        ],
                        "name": "A. Poritz",
                        "slug": "A.-Poritz",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Poritz",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Poritz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32413326,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1e6f96bee0a7b78402866e1461d00a72612dcc69",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for modelling time series is presented and then applied to the analysis of the speech signal. A time series is represented as a sample sequence generated by a finite state hidden Markov model with output densities parameterized by linear prediction polynomials and error variances. These objects are defined and their properties developed. The theory culminates in a theorem that provides a computationally efficient iterative scheme to improve the model. The theorem has been used to create models from speech signals of considerable length. One such model is examined with emphasis on the relationship between states of the model and traditional classes of speech events. A use of the method is illustrated by an application to the talker verification problem."
            },
            "slug": "Linear-predictive-hidden-Markov-models-and-the-Poritz",
            "title": {
                "fragments": [],
                "text": "Linear predictive hidden Markov models and the speech signal"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method for modelling time series is presented and then applied to the analysis of the speech signal, resulting in a theorem that provides a computationally efficient iterative scheme to improve the model."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60769407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1aa31d5deb45f477a6de45b3b75b62c7f4a213e7",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This thesis examines the acoustic-modeling problem in automatic speech recognition from an information-theoretic point of view. This problem is to design a speech-recognition system which can extract from the speech waveform as much information as possible about the corresponding word sequence. The information extraction process is broken down into two steps: a signal processing step which converts a speech waveform into a sequence of information bearing acoustic feature vectors, and a step which models such a sequence. This thesis is primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space such as R sub N. It explores the trade-off between packing a lot of information into such sequences and being able to model them accurately. The difficulty of developing accurate models of continuous parameter sequences is addressed by investigating a method of parameter estimation which is specifically designed to cope with inaccurate modeling assumptions."
            },
            "slug": "The-acoustic-modeling-problem-in-automatic-speech-Brown",
            "title": {
                "fragments": [],
                "text": "The acoustic-modeling problem in automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis is primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space such as R sub N and explores the trade-off between packing a lot of information into such sequences and being able to model them accurately."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781290"
                        ],
                        "name": "H. Murveit",
                        "slug": "H.-Murveit",
                        "structuredName": {
                            "firstName": "Hy",
                            "lastName": "Murveit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murveit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35577831"
                        ],
                        "name": "J. Bernstein",
                        "slug": "J.-Bernstein",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Bernstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744182"
                        ],
                        "name": "M. Weintraub",
                        "slug": "M.-Weintraub",
                        "structuredName": {
                            "firstName": "Mitch",
                            "lastName": "Weintraub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Weintraub"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60554400,
            "fieldsOfStudy": [
                "Physics",
                "Linguistics"
            ],
            "id": "573a1bb7a78c49c5ec23b1d2e36693db3dfe0f81",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A large-vocabulary, continuous-speech system, called DECIPHER, which is based on a hidden Markov model (HMM) approach and is designed to achieve high word accuracy in a speaker-independent mode is described. The results of a series of experiments that test acoustic and phonological adaptation of the DECIPHER system to the pronunciations of a single speaker in a speaker-dependent task are presented. Estimating the probabilities of alternative pronunciations and speaker-dependent phonology are discussed.<<ETX>>"
            },
            "slug": "The-decipher-speech-recognition-system-Cohen-Murveit",
            "title": {
                "fragments": [],
                "text": "The decipher speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A large-vocabulary, continuous-speech system, called DECIPHER, which is based on a hidden Markov model (HMM) approach and is designed to achieve high word accuracy in a speaker-independent mode is described and the probabilities of alternative pronunciations and speaker-dependent phonology are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144982775"
                        ],
                        "name": "W. Fisher",
                        "slug": "W.-Fisher",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Fisher",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35577831"
                        ],
                        "name": "J. Bernstein",
                        "slug": "J.-Bernstein",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Bernstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786370"
                        ],
                        "name": "D. Pallett",
                        "slug": "D.-Pallett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pallett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pallett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Resource Management (RM) speaker-independent continuous speech database [ 11 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We shall discuss the performance of this system evaluated on the DARPA Resource Management database, a 991 word speaker-independent continuous speech recognition task [ 11 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60461029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2a4080f0587dea4c4ff98d18fb1e22273a71665",
            "isKey": false,
            "numCitedBy": 394,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "A database of continuous read speech has been designed and recorded within the DARPA strategic computing speech recognition program. The data is intended for use in designing and evaluating algorithms for speaker-independent, speaker-adaptive and speaker-dependent speech recognition. The data consists of read sentences appropriate to a naval resource management task built around existing interactive database and graphics programs. The 1000-word task vocabulary is intended to be logically complete and habitable. The database, which represents over 21000 recorded utterances from 160 talkers with a variety of dialects, includes a partition of sentences and talkers for training and for testing purposes.<<ETX>>"
            },
            "slug": "The-DARPA-1000-word-resource-management-database-Price-Fisher",
            "title": {
                "fragments": [],
                "text": "The DARPA 1000-word resource management database for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A database of continuous read speech has been designed and recorded within the DARPA strategic computing speech recognition program for use in designing and evaluating algorithms for speaker-independent, speaker-adaptive and speaker-dependent speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144001744"
                        ],
                        "name": "J. Tebelskis",
                        "slug": "J.-Tebelskis",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Tebelskis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tebelskis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21676552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d01fcd90db72ad9900b5e8462745dc5f38aaa767",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A large-vocabulary isolated word recognition system based on linked predictive neural networks (LPNNs) is presented. In this system, neural networks are used as predictors of speech frames, enabling a pool of such networks to serve as phoneme models. Higher-level algorithms are used to organize these networks, linking them into sequences corresponding to the phonetic spellings of words, and to train and evaluate the networks for word recognition. By virtue of linking phonemic networks, the LPNN is vocabulary independent and can be applied to large-vocabulary recognition. Recognition rates of 94% for a 234-word Japanese vocabulary of acoustically similar words and 90% for a larger vocabulary of 924 words are obtained.<<ETX>>"
            },
            "slug": "Large-vocabulary-recognition-using-linked-neural-Tebelskis-Waibel",
            "title": {
                "fragments": [],
                "text": "Large vocabulary recognition using linked predictive neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "In this system, neural networks are used as predictors of speech frames, enabling a pool of such networks to serve as phoneme models, and the LPNN is vocabulary independent and can be applied to large-vocabulary recognition."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 113
                            }
                        ],
                        "text": "Thus, we could embed predictive MLPs in a Markov process to give a piecewise stationary model of speech dynamics [51,52,53,54]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 126
                            }
                        ],
                        "text": "The usual HMM training approach is to construct a density estimator that maximizes the likelihood P(X|M) (or P(X|QN1 ) if the Viterbi criterion is used)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The Viterbi approximation to this is analogous to segmental k-means training and has been referred to as embedded training [64] or connectionist Viterbi training [65]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 92
                            }
                        ],
                        "text": "The predictive MLPs are trained by the usual gradient descent process embedded in a Viterbi [51,52,53] or forward-backward [54] HMM training algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 19
                            }
                        ],
                        "text": "Training using the Viterbi criterion is sometimes known as the segmental k-means algorithm [16]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 64
                            }
                        ],
                        "text": "In this method a frame level optimization is interleaved with a Viterbi re-alignment."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "We may translate this concern to a local level, if we assume the Viterbi criterion."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 27
                            }
                        ],
                        "text": "The usual time-synchronous Viterbi decoding algorithm is used for recognition."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 39
                            }
                        ],
                        "text": "Recognition may be performed using the Viterbi criterion, by computing the state sequence, QN1 , that maximizes the posterior P(QN1 |X)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 8
                            }
                        ],
                        "text": "In this Viterbi training scheme, the temporal and static parts of the training problem are separated, in contrast to the forward-backward algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The Viterbi algorithm essentially traces the minimum cost (or maximum probability) path through a time-state lattice [19] subject to the constraints imposed by the acoustic and language models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 35
                            }
                        ],
                        "text": "It may be proved that performing a Viterbi segmentation using posterior local probabilities will also result in a global optimization [29]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 117
                            }
                        ],
                        "text": "One involves a direct computation of the posterior probability of a model given the acoustic data; the second is the Viterbi approximation to this."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 113
                            }
                        ],
                        "text": "It should be noted that the transitionprobabilities are still optimized by a maximum likelihoodcriterion (or the Viterbi approximation\nto it)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "Another criterion, usually referred to as the Viterbi criterion, only considers the best path throughM, leading to simplifications of the algorithms involved."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 39
                            }
                        ],
                        "text": "We initialize the models and perform a Viterbi alignment (using a bootstrap recognizer), producing a time-aligned state segmentation, subject to the language model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 79
                            }
                        ],
                        "text": "7This substitution is not forced upon us; there is no theoretical reason why a Viterbi search cannot be carried out using posterior probabilities [29] (but, see section II."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "In combination with the transition probabilities, we may use the Viterbi algorithm to compute the HMM state sequence most likely to have produced the speech signal, given the lexical and language model constraints."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Levin [51] used a single predictive MLP, rather than a MLP for each HMM state; however this MLP had an extra set of \u201ccontrol\u201d inputs, representing HMM state."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62309127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db6d47ce162007c055df7cfbf9d897824c0d1c90",
            "isKey": true,
            "numCitedBy": 112,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are used to model nonlinear and time-varying systems. The proposed model attempts to cope with the time variability systems by adding an undetermined control input which modulates the mapping implemented by the network. The network architecture proposed, the hidden control neural network (HCNN), combines nonlinear prediction of conventional neural networks with hidden Markov modeling. This network is trained using an algorithm that is based on back-propagation and segmentation algorithms for estimating the unknown control together with the network's parameters. The HCNN approach is evaluated on multispeaker recognition of connected digits, yielding a word accuracy of 99.3%.<<ETX>>"
            },
            "slug": "Word-recognition-using-hidden-control-neural-Levin",
            "title": {
                "fragments": [],
                "text": "Word recognition using hidden control neural architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The network architecture proposed, the hidden control neural network (HCNN), combines nonlinear prediction of conventional neural networks with hidden Markov modeling and is trained using an algorithm that is based on back-propagation and segmentation algorithms for estimating the unknown control together with the network's parameters."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154317"
                        ],
                        "name": "J. Wilpon",
                        "slug": "J.-Wilpon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Wilpon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilpon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705574"
                        ],
                        "name": "F. Soong",
                        "slug": "F.-Soong",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Soong",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Soong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43507125,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "5815d252012f952bd5b654441ee84289ce676bb6",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors use an enhanced analysis feature set consisting of both instantaneous and transitional spectral information and test the hidden-Markov-model (HMM)-based connected-digit recognizer in speaker-trained, multispeaker, and speaker-independent modes. For the evaluation, both a 50-talker connected-digit database recorded over local, dialed-up telephone lines, and the Texas Instruments, 225-adult-talker, connected-digits database are used. Using these databases, the performance achieved was 0.35, 1.65, and 1.75% string error rates for known-length strings, for speaker-trained, multispeaker, and speaker-independent modes, respectively, and 0.78, 2.85, and 2.94% string error rates for unknown-length strings of up to seven digits in length for the three modes. Several experiments were carried out to determine the best set of conditions (e.g., training, recognition, parameters, etc.) for recognition of digits. The results and the interpretation of these experiments are described. >"
            },
            "slug": "High-performance-connected-digit-recognition-using-Rabiner-Wilpon",
            "title": {
                "fragments": [],
                "text": "High performance connected digit recognition using hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An enhanced analysis feature set consisting of both instantaneous and transitional spectral information is used and the hidden-Markov-model (HMM)-based connected-digit recognizer in speaker-trained, multispeaker, and speaker-independent modes is tested."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615027"
                        ],
                        "name": "Krist Roginski",
                        "slug": "Krist-Roginski",
                        "structuredName": {
                            "firstName": "Krist",
                            "lastName": "Roginski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Krist Roginski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681269"
                        ],
                        "name": "M. Fanty",
                        "slug": "M.-Fanty",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Fanty",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fanty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": ", [4]), architectures and associated training algorithms have not yet been developed that can adequately model the temporal structure of speech."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2502381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e41a355e3d9956e36037c81cf05e0d991cf2fa7b",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A recognition system is reported which recognizes names spelled over the telephone with brief pauses between letters. The system uses separate neural networks to locate segment boundaries and classify letters. The letter scores are then used to search a database of names to find the best scoring name. The speaker-independent classification rate for spoken letters is 89%. The system retrieves the correct name, spelled with pauses between letters, 91% of the time from a database of 50,000 names."
            },
            "slug": "English-alphabet-recognition-with-telephone-speech-Cole-Roginski",
            "title": {
                "fragments": [],
                "text": "English alphabet recognition with telephone speech"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A recognition system is reported which recognizes names spelled over the telephone with brief pauses between letters, and retrieves the correct name 91% of the time from a database of 50,000 names."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154317"
                        ],
                        "name": "J. Wilpon",
                        "slug": "J.-Wilpon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Wilpon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilpon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705574"
                        ],
                        "name": "F. Soong",
                        "slug": "F.-Soong",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Soong",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Soong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Training using the Viterbi criterion is sometimes known as the segmental k-means algorithm [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 182480046,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "df9920c18f8bd5020971392280a15e0b3b2ff11c",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for connected-word recognition based on whole-word reference patterns have become increasingly sophisticated and have been shown capable of achieving high recognition performance for small or syntax-constrained moderate-size vocabularies in a speaker-trained mode. An enhanced analysis feature set consisting of both instantaneous and transitional spectral information is used and the hidden-Markov-model-based connected digit recognizer is tested in speaker-trained, multispeaker, and speaker-independent modes. The performance achieved was 0.35, 1.65 and 1.75% string error rates, respectively, for known length strings and 0.78, 2.85 and 2.94% string error rates, respectively, for unknown length strings.<<ETX>>"
            },
            "slug": "High-performance-connected-digit-recognition,-using-Rabiner-Wilpon",
            "title": {
                "fragments": [],
                "text": "High performance connected digit recognition, using hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An enhanced analysis feature set consisting of both instantaneous and transitional spectral information is used and the hidden-Markov-model-based connected digit recognizer is tested in speaker-trained, multispeaker, and speaker-independent modes."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793645"
                        ],
                        "name": "H. Gish",
                        "slug": "H.-Gish",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Gish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Gish"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "This result was expanded by Gish [30], Hampshire and Pearlmutter [31] and Richard and Lippmann [32], among others."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "In practice, this is not attainable: indeed, using a cross-validation training schedule a local\n6This result was expanded by Gish [30], Hampshire and Pearlmutter [31] and Richard and Lippmann [32], among others.\nminimum is not reached as training is stopped early to avoid overfitting (see section VI)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 123202935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c6be95e99e6d5538dfa362d18ac9b7e3ecce92a",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that training a neural network using a mean-square-error criterion gives network outputs that approximate posterior class probabilities. Based on this probabilistic interpretation of the network operation, information-theoretic training criteria such as maximum mutual information and the Kullback-Liebler measure are investigated. It is shown that both of these criteria are equivalent to the maximum-likelihood estimation (MLE) of the network parameters. MLE of a network allows for the comparison of network models using the Akaike information criterion and the minimum-description length criterion.<<ETX>>"
            },
            "slug": "A-probabilistic-approach-to-the-understanding-and-Gish",
            "title": {
                "fragments": [],
                "text": "A probabilistic approach to the understanding and training of neural network classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "It is shown that training a neural network using a mean-square-error criterion gives network outputs that approximate posterior class probabilities and information-theoretic training criteria such as maximum mutual information and the Kullback-Liebler measure are investigated."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34915378"
                        ],
                        "name": "R. Rohwer",
                        "slug": "R.-Rohwer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rohwer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rohwer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 149
                            }
                        ],
                        "text": "\u2022 If linear output units are used, then the discriminative training of the output layer may be accomplished non-iteratively using a matrix inversion [39,40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1709501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33fcc09d5b8fe77f7abe926ffb39e9687f361326",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of a radial basis functions network to a static speech pattern classification problem is described. The radial basis functions network offers training times two to three orders of magnitude faster than backpropagation, when training networks of similar power and generality. Recognition results compare well with those obtained using backpropagation and a vector-quantized hidden Markov model on the same problem. A computationally efficient method of exactly solving linear networks in a noniterative fashion is also described. The method was applied to classification of vowels into 20 classes using three different types of input analysis and varying numbers of radial basis functions. The three types of input vectors consisted of linear-prediction-coding cepstral coefficient; formant tracks with frequency, amplitude, and bandwidth information; and bark-scaled formant tracks. All input analyses were supplemented with duration information. The best test results were obtained using the cepstral coefficients and 170 or more radial basis functions.<<ETX>>"
            },
            "slug": "Phoneme-classification-experiments-using-radial-Renals-Rohwer",
            "title": {
                "fragments": [],
                "text": "Phoneme classification experiments using radial basis functions"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The application of a radial basis functions network to a static speech pattern classification problem is described and recognition results compare well with those obtained using backpropagation and a vector-quantized hidden Markov model on the same problem."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145660147"
                        ],
                        "name": "H. Franco",
                        "slug": "H.-Franco",
                        "structuredName": {
                            "firstName": "Horacio",
                            "lastName": "Franco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Franco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 269
                            }
                        ],
                        "text": "RBF networks with a prior-weighted softmax (or prior-weighted linear normalizing) output transfer function are also potentially attractive, since in this case there is a relationship between the RBF network weights and the coefficients of a tied mixture density system [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "\u2022 RBF networks have a structural isomorphism to tied mixture density models, although the training criterion is often different [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 230
                            }
                        ],
                        "text": "Experiments have also been performed in which the coefficients of a tied mixture density HMM (SRI\u2019s DECIPHER system [7]) were used to initialize a RBF network, which was then discriminatively trained using the scheme described in [41]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15964330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2130cf77ccd9223b6778c1c67ed915e1d2a3f74d",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Issues relating to the estimation of hidden Markov model (HMM) local probabilities are discussed. In particular we note the isomorphism of radial basis functions (RBF) networks to tied mixture density modelling; additionally we highlight the differences between these methods arising from the different training criteria employed. We present a method in which connectionist training can be modified to resolve these differences and discuss some preliminary experiments. Finally, we discuss some outstanding problems with discriminative training."
            },
            "slug": "Connectionist-Optimisation-of-Tied-Mixture-Hidden-Renals-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist Optimisation of Tied Mixture Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Issues relating to the estimation of hidden Markov model (HMM) local probabilities are discussed and a method in which connectionist training can be modified to resolve differences is presented."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30991537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e342aa20d7be3560b8ff6cbf85f98e8631f63328",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This group works towards automatic transcription of continuous speech with a vocabulary and syntax as unrestricted as possible. It is a long-term effort; however, an experimental system is operational. The acoustic processor contains a spectrum analyzer based on the Fast Fourier Transform and a phone segmenter/recognizer which makes use of transitional and steady-state information in its classification. The linguistic processor accepts an imperfect string of phones and produces an estimated transcription of the speech input."
            },
            "slug": "Continuous-speech-recognition-Jelinek",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "This group works towards automatic transcription of continuous speech with a vocabulary and syntax as unrestricted as possible and an experimental system is operational."
            },
            "venue": {
                "fragments": [],
                "text": "SGAR"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20265401"
                        ],
                        "name": "P. B. Scott",
                        "slug": "P.-B.-Scott",
                        "structuredName": {
                            "firstName": "Phillips",
                            "lastName": "Scott",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. B. Scott"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40547833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75fe012fa1789965542a7a28b800a4a7ecd9d9c1",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This report describes the development, operation, and performance characteristics of an Advanced Development Model of a Voice Input Code Identifier (VICI). The VICI is an isolated word recognition system capable of recognizing the English digits and four control words, CANCEL, ERASE, VERIFY and TERMINATE independently of speaker for a large population of General American males. A visual feedback system has been incorporated to allow the speaker to verify the correctness of each digit entry and if necessary to correct a faulty entry by the use of the control word, ERASE, and then enter a new digit. A complete code group of four digits can be accepted by the use of the control word VERIFY or rejected by the word CANCEL. The speaker can view on an alphanumeric display each recognized digit within .1 to .2 seconds after it is pronounced in order to verify the correctness of each digit entry. Live tests involving a total of 30 speakers showed that a four digit group could be entered into the VICI system with verification in as short an interval as 2.8 seconds. Four to seven seconds were typically required for most speakers for a digit group if no errors were made either by the speaker or the system. Ten to 12 seconds were required by most speakers to detect and correct an error and complete the entry of a proper code. It was necessary to employ correction for an average of 7.5% of the 75 digit groups spoken by the 29 participants in the live tests. In every case the errors were correctable and every code was entered properly."
            },
            "slug": "VICI-A-speaker-independent-word-recognition-system-Scott",
            "title": {
                "fragments": [],
                "text": "VICI - A speaker independent word recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The VICI is an isolated word recognition system capable of recognizing the English digits and four control words, CANCEL, ERASE, VERIFY and TERMINATE independently of speaker for a large population of General American males."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5768521"
                        ],
                        "name": "G. Barna",
                        "slug": "G.-Barna",
                        "structuredName": {
                            "firstName": "Gy\u00f6rgy",
                            "lastName": "Barna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693259"
                        ],
                        "name": "Ron Chrisley",
                        "slug": "Ron-Chrisley",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Chrisley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Chrisley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17154105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6666e8358eed45caf93ada4272f8d63bb1b6b705",
            "isKey": false,
            "numCitedBy": 512,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Three basic types of neural-like networks (backpropagation network, Boltzmann machine, and learning vector quantization), were applied to two representative artificial statistical pattern recognition tasks, each with varying dimensionality. The performance of each network's approach to solving the tasks was evaluated and compared, both to the performance of the other two networks and to the theoretical limit. The learning vector quantization was further benchmarked against the parametric Bayes classifier and the k-nearest-neighbor classifier using natural speech data. A novel learning vector quantization classifier called LVQ2 is introduced.<<ETX>>"
            },
            "slug": "Statistical-pattern-recognition-with-neural-studies-Kohonen-Barna",
            "title": {
                "fragments": [],
                "text": "Statistical pattern recognition with neural networks: benchmarking studies"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Three basic types of neural-like networks, backpropagation network, Boltzmann machine, and learning vector quantization, were applied to two representative artificial statistical pattern recognition tasks, each with varying dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE 1988 International Conference on Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49819964"
                        ],
                        "name": "M. Richard",
                        "slug": "M.-Richard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Richard",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Richard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990248"
                        ],
                        "name": "R. Lippmann",
                        "slug": "R.-Lippmann",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lippmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lippmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37584437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a6d820385527df2183a36ae1615f426ba894c5d",
            "isKey": false,
            "numCitedBy": 1166,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Many neural network classifiers provide outputs which estimate Bayesian a posteriori probabilities. When the estimation is accurate, network outputs can be treated as probabilities and sum to one. Simple proofs show that Bayesian probabilities are estimated when desired network outputs are 1 of M (one output unity, all others zero) and a squared-error or cross-entropy cost function is used. Results of Monte Carlo simulations performed using multilayer perceptron (MLP) networks trained with backpropagation, radial basis function (RBF) networks, and high-order polynomial networks graphically demonstrate that network outputs provide good estimates of Bayesian probabilities. Estimation accuracy depends on network complexity, the amount of training data, and the degree to which training data reflect true likelihood distributions and a priori class probabilities. Interpretation of network outputs as Bayesian probabilities allows outputs from multiple networks to be combined for higher level decision making, simplifies creation of rejection thresholds, makes it possible to compensate for differences between pattern class probabilities in training and test data, allows outputs to be used to minimize alternative risk functions, and suggests alternative measures of network performance."
            },
            "slug": "Neural-Network-Classifiers-Estimate-Bayesian-a-Richard-Lippmann",
            "title": {
                "fragments": [],
                "text": "Neural Network Classifiers Estimate Bayesian a posteriori Probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Results of Monte Carlo simulations performed using multilayer perceptron (MLP) networks trained with backpropagation, radial basis function (RBF) networks, and high-order polynomial networks graphically demonstrate that network outputs provide good estimates of Bayesian probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "Using single frame perceptual linear prediction (PLP) coefficient inputs [47], a 512 hidden unit MLP produced a phone classification rate of 59%, at the frame level."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15052804,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b578f4faeb00b808e8786d897447f2493b12b4e9",
            "isKey": false,
            "numCitedBy": 2939,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "A new technique for the analysis of speech, the perceptual linear predictive (PLP) technique, is presented and examined. This technique uses three concepts from the psychophysics of hearing to derive an estimate of the auditory spectrum: (1) the critical-band spectral resolution, (2) the equal-loudness curve, and (3) the intensity-loudness power law. The auditory spectrum is then approximated by an autoregressive all-pole model. A 5th-order all-pole model is effective in suppressing speaker-dependent details of the auditory spectrum. In comparison with conventional linear predictive (LP) analysis, PLP analysis is more consistent with human hearing. The effective second formant F2' and the 3.5-Bark spectral-peak integration theories of vowel perception are well accounted for. PLP analysis is computationally efficient and yields a low-dimensional representation of speech. These properties are found to be useful in speaker-independent automatic-speech recognition."
            },
            "slug": "Perceptual-linear-predictive-(PLP)-analysis-of-Hermansky",
            "title": {
                "fragments": [],
                "text": "Perceptual linear predictive (PLP) analysis of speech."
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A new technique for the analysis of speech, the perceptual linear predictive (PLP) technique, which uses three concepts from the psychophysics of hearing to derive an estimate of the auditory spectrum, and yields a low-dimensional representation of speech."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1474583163"
                        ],
                        "name": "S. Das",
                        "slug": "S.-Das",
                        "structuredName": {
                            "firstName": "Subrata",
                            "lastName": "Das",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5842352"
                        ],
                        "name": "P. DeSouza",
                        "slug": "P.-DeSouza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "DeSouza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. DeSouza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052717227"
                        ],
                        "name": "M. Epstein",
                        "slug": "M.-Epstein",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Epstein",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Epstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686820"
                        ],
                        "name": "B. M\u00e9rialdo",
                        "slug": "B.-M\u00e9rialdo",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "M\u00e9rialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M\u00e9rialdo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713978"
                        ],
                        "name": "D. Nahamoo",
                        "slug": "D.-Nahamoo",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nahamoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nahamoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774515"
                        ],
                        "name": "M. Picheny",
                        "slug": "M.-Picheny",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Picheny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Picheny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069585498"
                        ],
                        "name": "J. Powell",
                        "slug": "J.-Powell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Powell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Powell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 383,
                                "start": 379
                            }
                        ],
                        "text": "\u2022 Piecewise stationarity\u2014we can model speech using a Markov chain; \u2022 The prior probability of a model can be separately estimated\u2014 a language model including syntactic constraints about word sequences and phonological rules about sub-word unit sequences, P(M), may be derived without reference to the acoustic data (although some attempts have been made to relax this assumption [20]); \u2022 Observation independence\u2014the current data vector, x(t), is conditionally independent of previously emitted data vectorsXt 1 1 = fx(1), ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6696141,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "523ab3a5ca8507cff18252463785a97637766d4c",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a series of experiments in which the phonetic baseform is deduced automatically for new words by utilizing actual utterances of the new word in conjunction with a set of automatically derived spelling-to-sound rules. Recognition performance was evaluated on new words spoken by two different speakers when the phonetic baseforms were extracted via the above approach. The error rates on these new words were found to be comparable to or better than when the phonetic baseforms were derived by hand, thus validating the basic approach.<<ETX>>"
            },
            "slug": "Automatic-Phonetic-Baseform-Determination-Bahl-Das",
            "title": {
                "fragments": [],
                "text": "Automatic Phonetic Baseform Determination"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors describe a series of experiments in which the phonetic baseform is deduced automatically for new words by utilizing actual utterances of the new word in conjunction with a set of automatically derived spelling-to-sound rules."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18821787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f3175b3930d0c71495a52a7bccb3889e5f33520",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We have done an empirical study of the relation of the number of parameters (weights) in a feedforward net to generalization performance. Two experiments are reported. In one, we use simulated data sets with well-controlled parameters, such as the signal-to-noise ratio of continuous-valued data. In the second, we train the network on vector-quantized mel cepstra from real speech samples. In each case, we use back-propagation to train the feedforward net to discriminate in a multiple class pattern classification problem. We report the results of these studies, and show the application of cross-validation techniques to prevent overfitting."
            },
            "slug": "Generalization-and-Parameter-Estimation-in-Netws:-Morgan-Bourlard",
            "title": {
                "fragments": [],
                "text": "Generalization and Parameter Estimation in Feedforward Netws: Some Experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An empirical study of the relation of the number of parameters (weights) in a feedforward net to generalization performance and the application of cross-validation techniques to prevent overfitting is done."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191677"
                        ],
                        "name": "J. Hampshire",
                        "slug": "J.-Hampshire",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hampshire",
                            "middleNames": [
                                "B."
                            ],
                            "suffix": "II"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hampshire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700974"
                        ],
                        "name": "Barak A. Pearlmutter",
                        "slug": "Barak-A.-Pearlmutter",
                        "structuredName": {
                            "firstName": "Barak",
                            "lastName": "Pearlmutter",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barak A. Pearlmutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14038203,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "85241210389fbce403f5d12597b9bf32a5633dc2",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Equivalence-Proofs-for-Multi-Layer-Perceptron-and-Hampshire-Pearlmutter",
            "title": {
                "fragments": [],
                "text": "Equivalence Proofs for Multi-Layer Perceptron Classifiers and the Bayesian Discriminant Function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40268570"
                        ],
                        "name": "A. J. Robinson",
                        "slug": "A.-J.-Robinson",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Robinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Robinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086268"
                        ],
                        "name": "F. Failside",
                        "slug": "F.-Failside",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Failside",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Failside"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 128
                            }
                        ],
                        "text": "This unfolding enables training using a variant of the back propagation algorithm, referred to as back propagation through time [26,49,50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10802530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b247fe6efc9e1011555428647f390dd98bdd3446",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Error propagation nets have been shown to be able to learn a variety of tasks in which a static input pattern is mapped onto a static output pattern. This paper presents a generalisation of these nets to deal with time varying, or dynamic patterns, and three possible architectures are explored. As an example, dynamic nets are applied to the problem of speech coding, in which a time sequence of speech data are coded by one net and decoded by another. The use of dynamic nets gives a better signal to noise ratio than that achieved using static nets."
            },
            "slug": "Static-and-Dynamic-Error-Propagation-Networks-with-Robinson-Failside",
            "title": {
                "fragments": [],
                "text": "Static and Dynamic Error Propagation Networks with Application to Speech Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents a generalisation of error propagation nets to deal with time varying, or dynamic patterns, and three possible architectures are explored."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706196"
                        ],
                        "name": "S. Makino",
                        "slug": "S.-Makino",
                        "structuredName": {
                            "firstName": "Shozo",
                            "lastName": "Makino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Makino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798454"
                        ],
                        "name": "T. Kawabata",
                        "slug": "T.-Kawabata",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Kawabata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kawabata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2241277"
                        ],
                        "name": "K. Kido",
                        "slug": "K.-Kido",
                        "structuredName": {
                            "firstName": "Ken'iti",
                            "lastName": "Kido",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kido"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Over the past few years, connectionist models have been widely proposed as a potentially powerful approach to speech recognition (e.g., [ 1 ,2,3])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37752577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f93ee2e335d83ee32787693861f4d48e78e6786",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new method for the recognition of consonant based on the Perceptron model. The recognition model is composed of the sensory, feature extraction, response and lateral inhibition layers. The recognition scores of 90.4% to 98.4% are obtained for unvoiced affricates, unvoiced plosives, unvoiced and voiced fricatives."
            },
            "slug": "Recognition-of-consonant-based-on-the-perceptron-Makino-Kawabata",
            "title": {
                "fragments": [],
                "text": "Recognition of consonant based on the perceptron model"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This paper proposes a new method for the recognition of consonant based on the Perceptron model, which is composed of the sensory, feature extraction, response and lateral inhibition layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31129825"
                        ],
                        "name": "A. Webb",
                        "slug": "A.-Webb",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Webb",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Webb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159852"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205119390,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "f7c73870b2ca0f775f996df2d0f3fd0588ea1930",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-optimised-internal-representation-of-multilayer-Webb-Lowe",
            "title": {
                "fragments": [],
                "text": "The optimised internal representation of multilayer classifier networks performs nonlinear discriminant analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423281"
                        ],
                        "name": "L. A. Liporace",
                        "slug": "L.-A.-Liporace",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Liporace",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. A. Liporace"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30026295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "664eb4fb59f2ce8f2e019a77653f9ed2cc5df591",
            "isKey": false,
            "numCitedBy": 430,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Parameter estimation for multivariate functions of Markov chains, a class of versatile statistical models for vector random processes, is discussed. The model regards an ordered sequence of vectors as noisy multivariate observations of a Markov chain. Mixture distributions are a special case. The foundations of the theory presented here were established by Baum, Petrie, Soules, and Weiss. A powerful representation theorem by Fan is employed to generalize the analysis of Baum, {\\em et al.} to a larger class of distributions."
            },
            "slug": "Maximum-likelihood-estimation-for-multivariate-of-Liporace",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation for multivariate observations of Markov sources"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "Parameter estimation for multivariate functions of Markov chains, a class of versatile statistical models for vector random processes, is discussed, and a powerful representation theorem by Fan is employed to generalize the analysis of Baum, et al. to a larger class of distributions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16642315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e4193d03eb3c5a695a3d8b3506f80704f9dfc19",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is of tutorial nature and describes a one-stage dynamic programming algorithm for file problem of connected word recognition. The algorithm to be developed is essentially identical to one presented by Vintsyuk [1] and later by Bridle and Brown [2] ; but the notation and the presentation have been clarified. The derivation used for optimally time synchronizing a test pattern, consisting of a sequence of connected words, is straightforward and simple in comparison with other approaches decomposing the pattern matching problem into several levels. The approach presented relies basically on parameterizing the time warping path by a single index and on exploiting certain path constraints both in the word interior and at the word boundaries. The resulting algorithm turns out to be significantly more efficient than those proposed by Sakoe [3] as well as Myers and Rabiner [4], while providing the same accuracy in estimating the best possible matching string. Its most important feature is that the computational expenditure per word is independent of the number of words in the input string. Thus, it is well suited for recognizing comparatively long word sequences and for real-time operation. Furthermore, there is no need to specify the maximum number of words in the input string. The practical implementation of the algorithm is discussed; it requires no heuristic rules and no overhead. The algorithm can be modified to deal with syntactic constraints in terms of a finite state syntax."
            },
            "slug": "The-use-of-a-one-stage-dynamic-programming-for-word-Ney",
            "title": {
                "fragments": [],
                "text": "The use of a one-stage dynamic programming algorithm for connected word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The algorithm to be developed is essentially identical to one presented by Vintsyuk and later by Bridle and Brown, but the notation and the presentation have been clarified and the computational expenditure per word is independent of the number of words in the input string."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19920501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c8293e7054230cc6cc6e3172f761d89d267f7a7",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning algorithms have been used both on feed-forward deterministic networks and on feed-back statistical networks to capture input-output relations and do pattern classification. These learning algorithms are examined for a class of problems characterized by noisy or statistical data, in which the networks learn the relation between input data and probability distributions of answers. In simple but nontrivial networks the two learning rules are closely related. Under some circumstances the learning problem for the statistical networks can be solved without Monte Carlo procedures. The usual arbitrary learning goals of feed-forward networks can be given useful probabilistic meaning."
            },
            "slug": "Learning-algorithms-and-probability-distributions-Hopfield",
            "title": {
                "fragments": [],
                "text": "Learning algorithms and probability distributions in feed-forward and feed-back networks."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "These learning algorithms are examined for a class of problems characterized by noisy or statistical data, in which the networks learn the relation between input data and probability distributions of answers, in simple but nontrivial networks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47055692"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 128
                            }
                        ],
                        "text": "This unfolding enables training using a variant of the back propagation algorithm, referred to as back propagation through time [26,49,50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18470994,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1a3d22599028a05669e884f3eaf19a342e190a87",
            "isKey": false,
            "numCitedBy": 4036,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Backpropagation is now the most widely used tool in the field of artificial neural networks. At the core of backpropagation is a method for calculating derivatives exactly and efficiently in any large system made up of elementary subsystems or calculations which are represented by known, differentiable functions; thus, backpropagation has many applications which do not involve neural networks as such. This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis. Next, it presents the basic equations for backpropagation through time, and discusses applications to areas like pattern recognition involving dynamic systems, systems identification, and control. Finally, i t describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method. Pseudocode is provided to clarify the algorithms. The chain rule for ordered derivatives-the theorem which underlies backpropagation-is briefly discussed."
            },
            "slug": "Backpropagation-Through-Time:-What-It-Does-and-How-Werbos",
            "title": {
                "fragments": [],
                "text": "Backpropagation Through Time: What It Does and How to Do It"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis, and describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145145320"
                        ],
                        "name": "J. Beck",
                        "slug": "J.-Beck",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Beck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143869759"
                        ],
                        "name": "P. Kohn",
                        "slug": "P.-Kohn",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Kohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748118"
                        ],
                        "name": "J. Bilmes",
                        "slug": "J.-Bilmes",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Bilmes",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bilmes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143657504"
                        ],
                        "name": "E. Allman",
                        "slug": "E.-Allman",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Allman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Allman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153308817"
                        ],
                        "name": "J. Beer",
                        "slug": "J.-Beer",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Beer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30380934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f4d66aca349516cf38c4cdc87559f04134110d4",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Ring-Array-Processor:-A-Multiprocessing-for-Morgan-Beck",
            "title": {
                "fragments": [],
                "text": "The Ring Array Processor: A Multiprocessing Peripheral for Connection Applications"
            },
            "venue": {
                "fragments": [],
                "text": "J. Parallel Distributed Comput."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2363971"
                        ],
                        "name": "J. Hertz",
                        "slug": "J.-Hertz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hertz",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hertz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46486898"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50760571"
                        ],
                        "name": "R. Palmer",
                        "slug": "R.-Palmer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Palmer",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Palmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38623065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c0cbbd275bb43e09f0527a31ddd61824eca295b",
            "isKey": false,
            "numCitedBy": 6517,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book is a comprehensive introduction to the neural network models currently under intensive study for computational applications. It is a detailed, logically-developed treatment that covers the theory and uses of collective computational networks, including associative memory, feed forward networks, and unsupervised learning. It also provides coverage of neural network applications in a variety of problems of both theoretical and practical interest."
            },
            "slug": "Introduction-to-the-theory-of-neural-computation-Hertz-Krogh",
            "title": {
                "fragments": [],
                "text": "Introduction to the theory of neural computation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book is a detailed, logically-developed treatment that covers the theory and uses of collective computational networks, including associative memory, feed forward networks, and unsupervised learning."
            },
            "venue": {
                "fragments": [],
                "text": "The advanced book program"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7305058,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "ede664196e056b81cc3f9a208d9f207c7fba40e7",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that it is possible to factor a multilayered classification network with a large output layer into a number of smaller networks, where the product of the sizes of the output layers equals the size of the original output layer. No assumptions of statistical independence are required."
            },
            "slug": "Factoring-Networks-by-a-Statistical-Method-Morgan-Bourlard",
            "title": {
                "fragments": [],
                "text": "Factoring Networks by a Statistical Method"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is shown that it is possible to factor a multilayered classification network with a large output layer into a number of smaller networks, where the product of the sizes of the output layers equals the size of the original output layer."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16926,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62562997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae9443b39a5abfbf3cc9776173c1ae4f94732408",
            "isKey": false,
            "numCitedBy": 593,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a new sequential decoding algorithm is introduced that uses stack storage at the receiver. It is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp the rate below which the average number of decoding steps is bounded by a constant. Practical problems connected with implementing the stack algorithm are discussed and a scheme is described that facilitates satisfactory performance even with limited stack storage capacity. Preliminary simulation results estimating the decoding effort and the needed stack siazree presented."
            },
            "slug": "Fast-sequential-decoding-algorithm-using-a-stack-Jelinek",
            "title": {
                "fragments": [],
                "text": "Fast sequential decoding algorithm using a stack"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new sequential decoding algorithm is introduced that uses stack storage at the receiver that is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145768864"
                        ],
                        "name": "D. Broomhead",
                        "slug": "D.-Broomhead",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Broomhead",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Broomhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159852"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117200472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5558a34dfd1dbb572895664d38fca04029a99cb",
            "isKey": false,
            "numCitedBy": 2933,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The relationship between 'learning' in adaptive layered networks and the fitting of data with high dimensional surfaces is discussed. This leads naturally to a picture of 'generalization in terms of interpolation between known data points and suggests a rational approach to the theory of such networks. A class of adaptive networks is identified which makes the interpolation scheme explicit. This class has the property that learning is equivalent to the solution of a set of linear equations. These networks thus represent nonlinear relationships while having a guaranteed learning rule. Great Britain."
            },
            "slug": "Radial-Basis-Functions,-Multi-Variable-Functional-Broomhead-Lowe",
            "title": {
                "fragments": [],
                "text": "Radial Basis Functions, Multi-Variable Functional Interpolation and Adaptive Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The relationship between 'learning' in adaptive layered networks and the fitting of data with high dimensional surfaces is discussed, leading naturally to a picture of 'generalization in terms of interpolation between known data points and suggests a rational approach to the theory of such networks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2856152"
                        ],
                        "name": "E. Parzen",
                        "slug": "E.-Parzen",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Parzen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Parzen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 39
                            }
                        ],
                        "text": "An example is Parzen window estimation (Parzen, 1962), a kernel-based method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122932724,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "de28c165623adabcdba0fdb18b65eba685aaf31d",
            "isKey": false,
            "numCitedBy": 9493,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Given a sequence of independent identically distributed random variables with a common probability density function, the problem of the estimation of a probability density function and of determining the mode of a probability function are discussed. Only estimates which are consistent and asymptotically normal are constructed. (Author)"
            },
            "slug": "On-Estimation-of-a-Probability-Density-Function-and-Parzen",
            "title": {
                "fragments": [],
                "text": "On Estimation of a Probability Density Function and Mode"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "Using the maximum likelihood criterion, recognition can be carried out using a best-first search strategy via the stack decoding algorithm [17] or, equivalently, by an A* search [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 34428834,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "b49bb7ecd2afd6461c78ff29536839b5ee45cd15",
            "isKey": false,
            "numCitedBy": 1501,
            "numCiting": 177,
            "paperAbstract": {
                "fragments": [],
                "text": "Feel lonely? What about reading books? Book is one of the greatest friends to accompany while in your lonely time. When you have no friends and activities somewhere and sometimes, reading book can be a great choice. This is not only for spending the time, it will increase the knowledge. Of course the b=benefits to take will relate to what kind of book that you are reading. And now, we will concern you to try reading problem solving methods in artificial intelligence as one of the reading material to finish quickly."
            },
            "slug": "Problem-solving-methods-in-artificial-intelligence-Nilsson",
            "title": {
                "fragments": [],
                "text": "Problem-solving methods in artificial intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper will concern you to try reading problem solving methods in artificial intelligence as one of the reading material to finish quickly."
            },
            "venue": {
                "fragments": [],
                "text": "McGraw-Hill computer science series"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 90
                            }
                        ],
                        "text": "In this case, training may be performed by the Baum-Welch (or forward-backward) algorithm [13,14,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48403,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19356,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545803"
                        ],
                        "name": "M. Aizerman",
                        "slug": "M.-Aizerman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Aizerman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Aizerman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60493317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3caf34c1c86633b6e80dca29e3cb2b6367a0f93",
            "isKey": false,
            "numCitedBy": 1692,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theoretical-Foundations-of-the-Potential-Function-Aizerman",
            "title": {
                "fragments": [],
                "text": "Theoretical Foundations of the Potential Function Method in Pattern Recognition Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 23
                            }
                        ],
                        "text": "Bourlard and Wellekens [28,29] proved that a MLP trained to perform classification is a class-conditional posterior probability estimator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "This substitution is not forced upon us; there is no theoretical reason why a Viterbi search cannot be carried out using posterior probabilities [29] (but, see section II."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "An alternative approach was the discriminative HMM, originally defined by Bourlard and Wellekens [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "It may be proved that performing a Viterbi segmentation using posterior local probabilities will also result in a global optimization [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Bourlard and Wellekens [28,29] proved that a MLP trained to perform classification is a class-conditional posterior probability estimator.6 That is, after a \u20181-from-N\u2019 training, a MLP output value, given an input x, will be an estimate of the posterior probability, P(ci|x), of the corresponding class ci given the input."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Links between Markovmodels andmultilayer perceptrons"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. PAMI-12, pp. 1167\u20131178, 1990."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "RBF networks have been used successfully as probability estimators in HMM continuous speech recognition systems [43] and isolated word recognition systems [44]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 2
                            }
                        ],
                        "text": ", [43,44]), outputs less than zero or greater than one are not common."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 93
                            }
                        ],
                        "text": "Linear output RBF networks are an attractive probability estimator for computational reasons [43,44]; large RBF networks may be trained on a substantial speech database using standard workstations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A comparativestudy of continuous speech recognition using neural networks and hiddenMarkov models"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing, (Toronto), pp. 369\u2013372, 1991."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102329511"
                        ],
                        "name": "George W. Soules",
                        "slug": "George-W.-Soules",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Soules",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George W. Soules"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063108982"
                        ],
                        "name": "Norman Weiss",
                        "slug": "Norman-Weiss",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norman Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122568650,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3092a4929bdb3d6a8fe53f162586b7431b5ff8a4",
            "isKey": false,
            "numCitedBy": 4551,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Maximization-Technique-Occurring-in-the-Analysis-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2294095"
                        ],
                        "name": "M. Powell",
                        "slug": "M.-Powell",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Powell",
                            "middleNames": [
                                "J.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Powell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118224933,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c71ca26b183025b9f39f940f5e730f2c9a64e414",
            "isKey": false,
            "numCitedBy": 1425,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Radial-basis-functions-for-multivariable-a-review-Powell",
            "title": {
                "fragments": [],
                "text": "Radial basis functions for multivariable interpolation: a review"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145502114"
                        ],
                        "name": "R. Reddy",
                        "slug": "R.-Reddy",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Reddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Reddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54110621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0afb2945389d55df4dc09d03c2a70e752458d1e",
            "isKey": false,
            "numCitedBy": 346,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Large-vocabulary-speaker-independent-continuous-the-Reddy-Lee",
            "title": {
                "fragments": [],
                "text": "Large-vocabulary speaker-independent continuous speech recognition: the sphinx system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114788213"
                        ],
                        "name": "D. Signorini",
                        "slug": "D.-Signorini",
                        "structuredName": {
                            "firstName": "DavidF.",
                            "lastName": "Signorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Signorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4137433"
                        ],
                        "name": "J. Slattery",
                        "slug": "J.-Slattery",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Slattery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Slattery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058057862"
                        ],
                        "name": "S. Dodds",
                        "slug": "S.-Dodds",
                        "structuredName": {
                            "firstName": "Sally",
                            "lastName": "Dodds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dodds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51934565"
                        ],
                        "name": "V. Lane",
                        "slug": "V.-Lane",
                        "structuredName": {
                            "firstName": "V",
                            "lastName": "Lane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095059657"
                        ],
                        "name": "P. Littlejohns",
                        "slug": "P.-Littlejohns",
                        "structuredName": {
                            "firstName": "P",
                            "lastName": "Littlejohns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Littlejohns"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2878979,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "20b844e395355b40fa5940c61362ec40e56027aa",
            "isKey": false,
            "numCitedBy": 4706,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-networks-Signorini-Slattery",
            "title": {
                "fragments": [],
                "text": "Neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "The Lancet"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859441"
                        ],
                        "name": "Eiichi Tsuboka",
                        "slug": "Eiichi-Tsuboka",
                        "structuredName": {
                            "firstName": "Eiichi",
                            "lastName": "Tsuboka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eiichi Tsuboka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10266228"
                        ],
                        "name": "Y. Takada",
                        "slug": "Y.-Takada",
                        "structuredName": {
                            "firstName": "Yoshihiro",
                            "lastName": "Takada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Takada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778603"
                        ],
                        "name": "H. Wakita",
                        "slug": "H.-Wakita",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Wakita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wakita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "The predictive MLPs are trained by the usual gradient descent process embedded in a Viterbi [51,52,53] or forward-backward [54] HMM training algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 113
                            }
                        ],
                        "text": "Thus, we could embed predictive MLPs in a Markov process to give a piecewise stationary model of speech dynamics [51,52,53,54]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29586588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b44c147caf1719397d4e9b9a8be2fd0263f534c5",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-predictive-hidden-Markov-model-Tsuboka-Takada",
            "title": {
                "fragments": [],
                "text": "Neural predictive hidden Markov model"
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705919"
                        ],
                        "name": "Chuck Wooters",
                        "slug": "Chuck-Wooters",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Wooters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chuck Wooters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42369035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ffc709e6cc315227f90f1b621085d2185ea85ff",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Continuous-speech-recognition-on-the-resource-using-Morgan-Wooters",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition on the resource management database using connectionist probability estimation"
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120460"
                        ],
                        "name": "L. Niles",
                        "slug": "L.-Niles",
                        "structuredName": {
                            "firstName": "Les",
                            "lastName": "Niles",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Niles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45134430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "504de71b77a2967765b635d0afaca4b78b638a3b",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "TIMIT-phoneme-recognition-using-an-HMM-derived-Niles",
            "title": {
                "fragments": [],
                "text": "TIMIT phoneme recognition using an HMM-derived recurrent neural network"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145768864"
                        ],
                        "name": "D. Broomhead",
                        "slug": "D.-Broomhead",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Broomhead",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Broomhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159852"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 80
                            }
                        ],
                        "text": "The RBF network was originally introduced as a method of function approximation [38,39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 149
                            }
                        ],
                        "text": "\u2022 If linear output units are used, then the discriminative training of the output layer may be accomplished non-iteratively using a matrix inversion [39,40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3686496,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b08ba914037af6d88d16e2657a65cd9dc5cf5da1",
            "isKey": false,
            "numCitedBy": 2307,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multivariable-Functional-Interpolation-and-Adaptive-Broomhead-Lowe",
            "title": {
                "fragments": [],
                "text": "Multivariable Functional Interpolation and Adaptive Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "This is a result of the observation independenceassumption, causing an under-estimate of the joint observation density [66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Acoustic-ModellingProblemin Automatic SpeechRecognition"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Links between Markovmodels andmultilayer perceptrons"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 198
                            }
                        ],
                        "text": "However, computational experiments have shown that the sum of estimated posteriors is usually extremely close to one, for test vectors drawn from a region of space well-sampled by the training data [32,33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Merging multilayer perceptrons and hidden Markov models: some experiments in continuous speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks: Advances and Applications (E. Gelenbe, ed.), pp. 215\u2013 239, North-Holland, 1991."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 9
                            }
                        ],
                        "text": "Robinson [48,10] has used such networks to great effect in phone recognition and continuous speech systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A recurrenterror propagationnetworkspeech recognition system,\u201dComputer"
            },
            "venue": {
                "fragments": [],
                "text": "Speechand Language,vol"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist SpeechRecognition\u2014A Hybrid Approach. Kluwer Academic"
            },
            "venue": {
                "fragments": [],
                "text": "Connectionist SpeechRecognition\u2014A Hybrid Approach. Kluwer Academic"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Merging multilayer perceptrons and hidden Markov models : Some experiments in continuous speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks : Advances and Applications ("
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition of consonants based on the perceptron"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory,"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Acoustic-Modelling Problem in Automatic SpeechRecognition"
            },
            "venue": {
                "fragments": [],
                "text": "The Acoustic-Modelling Problem in Automatic SpeechRecognition"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IT-28"
            },
            "venue": {
                "fragments": [],
                "text": "IT-28"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 90
                            }
                        ],
                        "text": "In this case, training may be performed by the Baum-Welch (or forward-backward) algorithm [13,14,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihoodfrom incomplete data via the EM algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Royal Statistical Society Series B, vol. 39, pp. 1\u201338, 1977."
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 121
                            }
                        ],
                        "text": "Within this statistical framework, connectionist methods have been used to improve continuous speech recognition systems (Renals et al., 1992; Austin et al., 1992; Robinson, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recurrent nets for phone probability estimation"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings DARPA Workshop on Continuous Speech Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PART 11, JANUARY 1994 Observation independence-The acoustic Context was increased by presenting a multiframe input to the network"
            },
            "venue": {
                "fragments": [],
                "text": "PART 11, JANUARY 1994 Observation independence-The acoustic Context was increased by presenting a multiframe input to the network"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist optimization of tied mixture hidden Markov models"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The DARPA IOOO-word Resource Management database for continuous speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Int. Conf. Acoustics Speech Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Poritz, \u201cLinear predictive hidden Markov models and the speech"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 220
                            }
                        ],
                        "text": "Rather than estimating posterior probabilities, of the form P(qi|x(t)), they estimate a conditional likelihood,p(x(t)|qi,Xt 1 t p), which may be used to estimate the global conditional likelihood p(XNp+1, Qp+1 |Xp1, Q1) [57,58]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conectionist approaches to the use of Markov models for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems (R. P. Lippmann, J. E. Moody, and D. S. Touretzky, eds.), vol. 3, pp. 213\u2013219, San Mateo CA: Morgan Kaufmann, 1991."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "Using the maximum likelihood criterion, recognition can be carried out using a best-first search strategy via the stack decoding algorithm [17] or, equivalently, by an A* search [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast sequential decoding algorithm usinga stack,\u201dIBM"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Research and Development,"
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hybrid neural networkhidden Markov model continuous-speech recognition Context-dependent multiple distribution phone modeling using MLP's"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Conf. Spoken Language Processing Advances in Neural Information Processing Systems"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conf. Acoust. Speech Signal Processing (Toronto)"
            },
            "venue": {
                "fragments": [],
                "text": "Conf. Acoust. Speech Signal Processing (Toronto)"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning algorithms and probability distributions in feedforward networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences  USA, vol. 84, pp. 8429\u20138433, 1987."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Technol"
            },
            "venue": {
                "fragments": [],
                "text": "Technol"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 119
                            }
                        ],
                        "text": "This is a result of the observation independenceassumption, causing an under-estimate of the joint observation density (Brown, 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Acoustic-Modelling Problem in Automatic Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. thesis,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist probability estimation in HMM speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speaker-independent word recognition"
            },
            "venue": {
                "fragments": [],
                "text": "querque),"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Context-dependent modeling for acoustic-phonetic 259-274"
            },
            "venue": {
                "fragments": [],
                "text": "Context-dependent modeling for acoustic-phonetic 259-274"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 121
                            }
                        ],
                        "text": "Within this statistical framework, connectionist methods have been used to improve continuous speech recognition systems (Renals et al., 1992; Austin et al., 1992; Robinson, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speech recognition using segemental neural nets"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "Of course, hidden unit outputs resulting from speech input are not random and, as reported in [37], the network biases were not good replacements for the priors at recognition time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist probability estimation in HMM speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Rep. TR-92-081, International Computer Science Institute, Berkeley CA, USA, 1992."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist Speech R e c o g n i r i o d Hybrid Approach"
            },
            "venue": {
                "fragments": [],
                "text": "Connectionist Speech R e c o g n i r i o d Hybrid Approach"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "received the Ph.D. degree in computer science from the University of California at Berkeley"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hybrid neural networkhidden Markov model continuous-speech recognition,"
            },
            "venue": {
                "fragments": [],
                "text": "in Proc. Int. Conf. Spoken Language Processing (Banff),"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robinson, and an anonymous referee for a critical reading of the manuscript"
            },
            "venue": {
                "fragments": [],
                "text": "REFERENCES"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The optimized intemal representation of multilayer classifier networks performs nonlinear discriminant analy"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. IEEE Int. Conf. Acoustics Speech Signal Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Int. Conf. Acoustics Speech Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 9
                            }
                        ],
                        "text": "Robinson [48,10] has used such networks to great effect in phone recognition and continuous speech systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A recurrenterror propagationnetwork speech recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Speech and Language,vol. 5, pp. 259\u2013274, 1991."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acoustics Speech Signal Processing (Albuquerque)"
            },
            "venue": {
                "fragments": [],
                "text": "Acoustics Speech Signal Processing (Albuquerque)"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speech Signal Processing (Tampa FL)"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Signal Processing (Tampa FL)"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "M\u201991) received the B.Sc. degree in chemistry from the University of Sheffield in 1986, the M.Sc. degree in artificial intelligence in 1987, and the Ph.D"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A recurrent error propagationnetwork speech recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Speech and Language"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acoustics Speech Signal Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Acoustics Speech Signal Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The acousticmodeling problem in automatic speech recognition \u201d , Ph . D . thesis , School of Comput"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 108
                            }
                        ],
                        "text": "However, traditional HMM systems have experienced a much improved performance by modeling phones in context [67,6,7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Context-dependentmodelling for acoustic-phoneticrecognition of continuousspeech"
            },
            "venue": {
                "fragments": [],
                "text": "ProceedingsIEEE InternationalConference on Acoustics, Speech and Signal Processing, (Tampa FL), pp. 1205\u20131208, 1985."
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum likelihood approach to continuousspeech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactionson Pattern Analysis and Machine Intelligence, vol. PAMI-5, pp. 179\u2013190, 1983."
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The DARPA IOOOword Resource Management database for continuous speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . IEEE Int . Conf . Acoustics Speech Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 33
                            }
                        ],
                        "text": "A variant of the second approach [70,71] uses an equivalent decomposition: p(ci, dj|x) = p(di|x)p(cj |di,x) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextdependent multiple distribution phone modelling using MLPs"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems (S. J. Hanson, J. D. Cowan, and C. L. Giles, eds.), vol. 5, San Mateo CA: Morgan Kaufmann,  1993."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "This is a result of the observation independenceassumption, causing an under-estimate of the joint observation density [66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Acoustic-Modelling Problemin Automatic SpeechRecognition"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conectionist approaches to the use of Markov models for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Training using the Viterbi criterion is sometimes known as the segmental k-means algorithm [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "High performance connecteddigit recognitionusing hiddenMarkovmodels"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Acoustics, Speech andSignal Processing,vol. 37, pp. 1214\u20131225,1989."
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From 1984 to 1988, he worked at the EEG Systems Lab in San Francisco on the analysis of brain waves collected in controlled"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "Most of our experiments have been performed using the DARPA Resource Management (RM) speaker-independent continuous speech database [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "We shall discuss the performance of this system evaluated on the DARPA Resource Management database, a 991 word speaker-independent continuous speech recognition task [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The DARPA 1000word Resource Managementdatabase for continuousspeech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 651\u2013654, 1988."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Leaming algorithms and probability distributions in feed - forward networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Nut . Acad . Sci ."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 80
                            }
                        ],
                        "text": "The RBF network was originally introduced as a method of function approximation [38,39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Radial basis functions for multi-variable interpolation: a review"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Rep. DAMPT/NA12, Dept. of Applied Mathematics and Theoretical Physics, University of Cambridge, 1985."
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Con - nectionist optimization of tied mixture hidden Markov models"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A recurrenterror propagationnetworkspeech recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Speechand Language"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conf Acoustics Speech Signal Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Conf Acoustics Speech Signal Processing"
            },
            "year": 1992
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 19,
            "methodology": 31,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 131,
        "totalPages": 14
    },
    "page_url": "https://www.semanticscholar.org/paper/Connectionist-probability-estimators-in-HMM-speech-Renals-Morgan/a08c99425ad94eed67d059813511fe9ca55e73eb?sort=total-citations"
}