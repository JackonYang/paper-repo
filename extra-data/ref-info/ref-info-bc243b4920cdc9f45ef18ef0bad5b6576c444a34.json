{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500336"
                        ],
                        "name": "Alex Kulesza",
                        "slug": "Alex-Kulesza",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Kulesza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Kulesza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "The closest work to ours is a theoretical analysis of MRF structural learning with \nLBP and LP-relaxation approximations (Kulesza &#38; Pereira, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 208
                            }
                        ],
                        "text": "LBP s tendency to fall into horrible local maxima (as \nseen in Section 4) misled Algorithm 1 to believe its most violated constraint was not violated, leading \nit to early termination, mirroring the result in (Kulesza &#38; Pereira, 2007)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 10876177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "325ea1f2022ee3886a5810df76dcfbe4010ad439",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In many structured prediction problems, the highest-scoring labeling is hard to compute exactly, leading to the use of approximate inference methods. However, when inference is used in a learning algorithm, a good approximation of the score may not be sufficient. We show in particular that learning can fail even with an approximate inference method with rigorous approximation guarantees. There are two reasons for this. First, approximate methods can effectively reduce the expressivity of an underlying model by making it impossible to choose parameters that reliably give good predictions. Second, approximations can respond to parameter changes in such a way that standard learning algorithms are misled. In contrast, we give two positive results in the form of learning bounds for the use of LP-relaxed inference in structured perceptron and empirical risk minimization settings. We argue that without understanding combinations of inference and learning, such as these, that are appropriately compatible, learning performance under approximate inference cannot be guaranteed."
            },
            "slug": "Structured-Learning-with-Approximate-Inference-Kulesza-Pereira",
            "title": {
                "fragments": [],
                "text": "Structured Learning with Approximate Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown in particular that learning can fail even with an approximate inference method with rigorous approximation guarantees, and argued that without understanding combinations of inference and learning, such as these that are appropriately compatible, learning performance under approximate inference cannot be guaranteed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37210858"
                        ],
                        "name": "Charles Sutton",
                        "slug": "Charles-Sutton",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Sutton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 158
                            }
                        ],
                        "text": "\u2026(Culotta et al., 2007; He et al., 2004; Kumar &#38; \nHebert, 2003; Vishwanathan et al., 2006), or the model is simpli.ed to make the par\u00adtition function tractable \n(Sutton &#38; McCallum, 2005), or CRF max-likelihood training is replaced with Per\u00adceptron training (Roth \n&#38; Yih, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7663738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8e9a234aee3fe570358d61068db175459227dac",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminitive models for sequences and trees\u2014such as linear-chain conditional random fields (CRFs) and max-margin parsing\u2014have shown great promise because they combine the ability to incorporate arbitrary input features and the benefits of principled global inference over their structured outputs. However, since parameter estimation in these models involves repeatedly performing this global inference, training can be very slow. We present piecewise training, a new training method that combines the speed of local training with the accuracy of global training by incorporating a limited amount of global information derived from previous errors of the model. On namedentity and part-of-speech data, we show that our new method not only trains in less than one-fifth the time of a CRF and yields improved accuracy over the MEMM, but surprisingly also provides a statistically-significant gain in accuracy over the CRF. Also, we present preliminary results showing a potential application to efficient training of discriminative parsers."
            },
            "slug": "Fast,-Piecewise-Training-for-Discriminative-and-Sutton-McCallum",
            "title": {
                "fragments": [],
                "text": "Fast, Piecewise Training for Discriminative Finite-state and Parsing Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730156"
                        ],
                        "name": "Carlos Guestrin",
                        "slug": "Carlos-Guestrin",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guestrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos Guestrin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 114
                            }
                        ],
                        "text": "Markov Random Fields in SSVMs A special case of structural SVM that we will examine throughout \nthis paper is M3N (Taskar et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "For M3Ns, Anguelov et al. (Anguelov et al., 2005) pro\u00adposed to directly fold a linear \nrelaxation into OP 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 209
                            }
                        ],
                        "text": "\u2026\nSeveral discriminative structural learners were pro\u00adposed in recent years, including conditional ran\u00addom \n.elds (CRFs) (La.erty et al., 2001), Perceptron HMMs (Collins, 2002), max-margin Markov networks (M3Ns) \n(Taskar et al., 2003), and structural SVMs (SSVMs) (Tsochantaridis et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 131
                            }
                        ],
                        "text": "Introduction \nDiscriminative training methods like conditional ran\u00addom .elds (La.erty et al., 2001), maximum-margin \nMarkov networks (Taskar et al., 2003), and struc\u00adtural SVMs (Tsochantaridis et al., 2005) have substan\u00adtially \nimproved prediction performance on a variety of structured prediction\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 230
                            }
                        ],
                        "text": "Structured Output Prediction \nSeveral discriminative structural learners were pro\u00adposed in recent years, including conditional ran\u00addom \n.elds (CRFs) (La.erty et al., 2001), Perceptron HMMs (Collins, 2002), max-margin Markov networks (M3Ns) \n(Taskar et al., 2003), and structural SVMs (SSVMs) (Tsochantaridis et al., 2005)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 201720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c450531e1121cfb657be5195e310217a4675397",
            "isKey": true,
            "numCitedBy": 1477,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In typical classification tasks, we seek a function which assigns a label to a single object. Kernel-based approaches, such as support vector machines (SVMs), which maximize the margin of confidence of the classifier, are the method of choice for many such tasks. Their popularity stems both from the ability to use high-dimensional feature spaces, and from their strong theoretical guarantees. However, many real-world tasks involve sequential, spatial, or structured data, where multiple labels must be assigned. Existing kernel-based methods ignore structure in the problem, assigning labels independently to each object, losing much useful information. Conversely, probabilistic graphical models, such as Markov networks, can represent correlations between labels, by exploiting problem structure, but cannot handle high-dimensional feature spaces, and lack strong theoretical generalization guarantees. In this paper, we present a new framework that combines the advantages of both approaches: Maximum margin Markov (M3) networks incorporate both kernels, which efficiently deal with high-dimensional features, and the ability to capture correlations in structured data. We present an efficient algorithm for learning M3 networks based on a compact quadratic program formulation. We provide a new theoretical bound for generalization in structured domains. Experiments on the task of handwritten character recognition and collective hypertext classification demonstrate very significant gains over previous approaches."
            },
            "slug": "Max-Margin-Markov-Networks-Taskar-Guestrin",
            "title": {
                "fragments": [],
                "text": "Max-Margin Markov Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Maximum margin Markov (M3) networks incorporate both kernels, which efficiently deal with high-dimensional features, and the ability to capture correlations in structured data, and a new theoretical bound for generalization in structured domains is provided."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765700"
                        ],
                        "name": "Ioannis Tsochantaridis",
                        "slug": "Ioannis-Tsochantaridis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Tsochantaridis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Tsochantaridis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783941"
                        ],
                        "name": "Y. Altun",
                        "slug": "Y.-Altun",
                        "structuredName": {
                            "firstName": "Yasemin",
                            "lastName": "Altun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Altun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 102
                            }
                        ],
                        "text": "Ifa polynomial time separation \noracle exists, OP 1 and Al\u00adgorithm 1 have three theoretical guarantees (Tsochan\u00adtaridis et al., 2005): \nPolynomial Time Termination: Algorithm 1 ter\u00ad minates in a polynomial number of iterations, and thus \noverall polynomial time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 130
                            }
                        ],
                        "text": "If such a separation oracle exists and can be computed in polynomial time, OP 1 and Algorithm 1 have three theoretical guarantees (Tsochantaridis et al., 2005):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 34
                            }
                        ],
                        "text": ", 2003), natural language parsing (Tsochantaridis et al., 2005), sequence alignment (Yu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 146
                            }
                        ],
                        "text": "\u2026training methods like conditional ran\u00addom .elds (La.erty et al., 2001), maximum-margin \nMarkov networks (Taskar et al., 2003), and struc\u00adtural SVMs (Tsochantaridis et al., 2005) have substan\u00adtially \nimproved prediction performance on a variety of structured prediction problems, including\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 260
                            }
                        ],
                        "text": "\u2026\nSeveral discriminative structural learners were pro\u00adposed in recent years, including conditional ran\u00addom \n.elds (CRFs) (La.erty et al., 2001), Perceptron HMMs (Collins, 2002), max-margin Markov networks (M3Ns) \n(Taskar et al., 2003), and structural SVMs (SSVMs) (Tsochantaridis et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 60
                            }
                        ],
                        "text": "(yi,h(xi)), S \nni=1 SSVMs solve this quadratic program (QP) (Tsochan\u00adtaridis et al., 2005): Optimization Problem 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 146
                            }
                        ],
                        "text": "\u2026prediction performance on a variety of structured prediction problems, including part-of\u00adspeech \ntagging (Altun et al., 2003), natural language parsing (Tsochantaridis et al., 2005), sequence align\u00adment \n(Yu et al., 2007), and classi.cation under multi\u00advariate loss functions (Joachims, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17671150,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc97e7dbb821a4edfb5151bff4352655eedca9ee",
            "isKey": false,
            "numCitedBy": 2247,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning general functional dependencies between arbitrary input and output spaces is one of the key challenges in computational intelligence. While recent progress in machine learning has mainly focused on designing flexible and powerful input representations, this paper addresses the complementary issue of designing classification algorithms that can deal with more complex outputs, such as trees, sequences, or sets. More generally, we consider problems involving multiple dependent output variables, structured output spaces, and classification problems with class attributes. In order to accomplish this, we propose to appropriately generalize the well-known notion of a separation margin and derive a corresponding maximum-margin formulation. While this leads to a quadratic program with a potentially prohibitive, i.e. exponential, number of constraints, we present a cutting plane algorithm that solves the optimization problem in polynomial time for a large class of problems. The proposed method has important applications in areas such as computational biology, natural language processing, information retrieval/extraction, and optical character recognition. Experiments from various domains involving different types of output spaces emphasize the breadth and generality of our approach."
            },
            "slug": "Large-Margin-Methods-for-Structured-and-Output-Tsochantaridis-Joachims",
            "title": {
                "fragments": [],
                "text": "Large Margin Methods for Structured and Interdependent Output Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes to appropriately generalize the well-known notion of a separation margin and derive a corresponding maximum-margin formulation and presents a cutting plane algorithm that solves the optimization problem in polynomial time for a large class of problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3166569"
                        ],
                        "name": "C. Yu",
                        "slug": "C.-Yu",
                        "structuredName": {
                            "firstName": "Chun-Nam",
                            "lastName": "Yu",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346672"
                        ],
                        "name": "R. Elber",
                        "slug": "R.-Elber",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Elber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Elber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786404"
                        ],
                        "name": "J. Pillardy",
                        "slug": "J.-Pillardy",
                        "structuredName": {
                            "firstName": "Jaroslaw",
                            "lastName": "Pillardy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pillardy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 196
                            }
                        ],
                        "text": "\u2026prediction performance on a variety of structured prediction problems, including part-of\u00adspeech \ntagging (Altun et al., 2003), natural language parsing (Tsochantaridis et al., 2005), sequence align\u00adment \n(Yu et al., 2007), and classi.cation under multi\u00advariate loss functions (Joachims, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 28
                            }
                        ],
                        "text": ", 2005), sequence alignment (Yu et al., 2007), and classification under multivariate loss functions (Joachims, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1866901,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "a6a03fab612d2b490c8460d07f97c30178acd5a2",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequence to structure alignment is an important step in homology modeling of protein structures. Incorporation of features such as secondary structure, solvent accessibility, or evolutionary information improve sequence to structure alignment accuracy, but conventional generative estimation techniques for alignment models impose independence assumptions that make these features difficult to include in a principled way. In this paper, we overcome this problem using a Support Vector Machine (SVM) method that provides a well-founded way of estimating complex alignment models with hundred of thousands of parameters. Furthermore, we show that the method can be trained using a variety of loss functions. In a rigorous empirical evaluation, the SVM algorithm outperforms the generative alignment method SSALN, a highly accurate generative alignment model that incorporates structural information. The alignment model learned by the SVM aligns 50% of the residues correctly and aligns over 70% of the residues within a shift of four positions."
            },
            "slug": "Support-Vector-Training-of-Protein-Alignment-Models-Yu-Joachims",
            "title": {
                "fragments": [],
                "text": "Support Vector Training of Protein Alignment Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A Support Vector Machine (SVM) method is used that provides a well-founded way of estimating complex alignment models with hundred of thousands of parameters and outperforms the Generative alignment method SSALN, a highly accurate generative alignment model that incorporates structural information."
            },
            "venue": {
                "fragments": [],
                "text": "RECOMB"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145349582"
                        ],
                        "name": "Sanjiv Kumar",
                        "slug": "Sanjiv-Kumar",
                        "structuredName": {
                            "firstName": "Sanjiv",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjiv Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 90
                            }
                        ],
                        "text": "Therefore, the par\u00adtition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar &#38; \nHebert, 2003; Vishwanathan et al., 2006), or the model is simpli.ed to make the par\u00adtition function tractable \n(Sutton &#38; McCallum, 2005), or CRF max-likelihood training is replaced with\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1282113,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "015293bf7c4cf7ce50a01ce1ceb11f584d123d25",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present Discriminative Random Fields (DRF), a discriminative framework for the classification of natural image regions by incorporating neighborhood spatial dependencies in the labels as well as the observed data. The proposed model exploits local discriminative models and allows to relax the assumption of conditional independence of the observed data given the labels, commonly used in the Markov Random Field (MRF) framework. The parameters of the DRF model are learned using penalized maximum pseudo-likelihood method. Furthermore, the form of the DRF model allows the MAP inference for binary classification problems using the graph min-cut algorithms. The performance of the model was verified on the synthetic as well as the real-world images. The DRF model outperforms the MRF model in the experiments."
            },
            "slug": "Discriminative-Fields-for-Modeling-Spatial-in-Kumar-Hebert",
            "title": {
                "fragments": [],
                "text": "Discriminative Fields for Modeling Spatial Dependencies in Natural Images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed DRF model exploits local discriminative models and allows to relax the assumption of conditional independence of the observed data given the labels, commonly used in the Markov Random Field (MRF) framework."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144105277"
                        ],
                        "name": "Wen-tau Yih",
                        "slug": "Wen-tau-Yih",
                        "structuredName": {
                            "firstName": "Wen-tau",
                            "lastName": "Yih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-tau Yih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 282
                            }
                        ],
                        "text": "Therefore, the par\u00adtition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar &#38; \nHebert, 2003; Vishwanathan et al., 2006), or the model is simpli.ed to make the par\u00adtition function tractable \n(Sutton &#38; McCallum, 2005), or CRF max-likelihood training is replaced with Per\u00adceptron training (Roth \n&#38; Yih, 2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 169
                            }
                        ],
                        "text": "Structured Output Prediction \nSeveral discriminative structural learners were pro\u00adposed in recent years, including conditional ran\u00addom \n.elds (CRFs) (La.erty et al., 2001), Perceptron HMMs (Collins, 2002), max-margin Markov networks (M3Ns) \n(Taskar et al., 2003), and structural SVMs (SSVMs) (Tsochantaridis et al., 2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 253
                            }
                        ],
                        "text": "\u2026(Culotta et al., 2007; He et al., 2004; Kumar &#38; \nHebert, 2003; Vishwanathan et al., 2006), or the model is simpli.ed to make the par\u00adtition function tractable \n(Sutton &#38; McCallum, 2005), or CRF max-likelihood training is replaced with Per\u00adceptron training (Roth \n&#38; Yih, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14624915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5239ff7191927cb798ddff876cfd22ffa31d80ab",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Inference in Conditional Random Fields and Hidden Markov Models is done using the Viterbi algorithm, an efficient dynamic programming algorithm. In many cases, general (non-local and non-sequential) constraints may exist over the output sequence, but cannot be incorporated and exploited in a natural way by this inference procedure. This paper proposes a novel inference procedure based on integer linear programming (ILP) and extends CRF models to naturally and efficiently support general constraint structures. For sequential constraints, this procedure reduces to simple linear programming as the inference process. Experimental evidence is supplied in the context of an important NLP problem, semantic role labeling."
            },
            "slug": "Integer-linear-programming-inference-for-random-Roth-Yih",
            "title": {
                "fragments": [],
                "text": "Integer linear programming inference for conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel inference procedure based on integer linear programming (ILP) and extends CRF models to naturally and efficiently support general constraint structures is proposed and Experimental evidence is supplied in the context of an important NLP problem, semantic role labeling."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895207"
                        ],
                        "name": "C. Gentile",
                        "slug": "C.-Gentile",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Gentile",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gentile"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49085139"
                        ],
                        "name": "L. Zaniboni",
                        "slug": "L.-Zaniboni",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Zaniboni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zaniboni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 86
                            }
                        ],
                        "text": "Often, incorporating \ninter-label dependen\u00adcies into the model can improve performance (Cesa-Bianchi et al., 2006; Elissee."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1108504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea0eb78042d22cb4c57c6d315e37e811c4e44e8f",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We study hierarchical classification in the general case when an instance could belong to more than one class node in the underlying taxonomy. Experiments done in previous work showed that a simple hierarchy of Support Vectors Machines (SVM) with a top-down evaluation scheme has a surprisingly good performance on this kind of task. In this paper, we introduce a refined evaluation scheme which turns the hierarchical SVM classifier into an approximator of the Bayes optimal classifier with respect to a simple stochastic model for the labels. Experiments on synthetic datasets, generated according to this stochastic model, show that our refined algorithm outperforms the simple hierarchical SVM. On real-world data, however, the advantage brought by our approach is a bit less clear. We conjecture this is due to a higher noise rate for the training labels in the low levels of the taxonomy."
            },
            "slug": "Hierarchical-classification:-combining-Bayes-with-Cesa-Bianchi-Gentile",
            "title": {
                "fragments": [],
                "text": "Hierarchical classification: combining Bayes with SVM"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A refined evaluation scheme is introduced which turns the hierarchical SVM classifier into an approximator of the Bayes optimal classifier with respect to a simple stochastic model for the labels."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 158
                            }
                        ],
                        "text": "\u2026\nSeveral discriminative structural learners were pro\u00adposed in recent years, including conditional ran\u00addom \n.elds (CRFs) (La.erty et al., 2001), Perceptron HMMs (Collins, 2002), max-margin Markov networks (M3Ns) \n(Taskar et al., 2003), and structural SVMs (SSVMs) (Tsochantaridis et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10888973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a7958b418bceb48a315384568091ab1898b1640",
            "isKey": false,
            "numCitedBy": 2272,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe new algorithms for training tagging models, as an alternative to maximum-entropy models or conditional random fields (CRFs). The algorithms rely on Viterbi decoding of training examples, combined with simple additive updates. We describe theory justifying the algorithms through a modification of the proof of convergence of the perceptron algorithm for classification problems. We give experimental results on part-of-speech tagging and base noun phrase chunking, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "slug": "Discriminative-Training-Methods-for-Hidden-Markov-Collins",
            "title": {
                "fragments": [],
                "text": "Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results on part-of-speech tagging and base noun phrase chunking are given, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783941"
                        ],
                        "name": "Y. Altun",
                        "slug": "Y.-Altun",
                        "structuredName": {
                            "firstName": "Yasemin",
                            "lastName": "Altun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Altun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765700"
                        ],
                        "name": "Ioannis Tsochantaridis",
                        "slug": "Ioannis-Tsochantaridis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Tsochantaridis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Tsochantaridis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 139
                            }
                        ],
                        "text": ", 2004) have substantially improved prediction performance on a variety of structured prediction problems, including part-ofspeech tagging (Altun et al., 2003), natural language parsing (Tsochantaridis et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "\u2026et al., 2005) have substan\u00adtially \nimproved prediction performance on a variety of structured prediction problems, including part-of\u00adspeech \ntagging (Altun et al., 2003), natural language parsing (Tsochantaridis et al., 2005), sequence align\u00adment \n(Yu et al., 2007), and classi.cation under\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9699301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fe5ed2a3b50becdbbcd17e7733653d5ef6ac398",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel discriminative learning technique for label sequences based on a combination of the two most successful learning algorithms, Support Vector Machines and Hidden Markov Models which we call Hidden Markov Support Vector Machine. The proposed architecture handles dependencies between neighboring labels using Viterbi decoding. In contrast to standard HMM training, the learning procedure is discriminative and is based on a maximum/soft margin criterion. Compared to previous methods like Conditional Random Fields, Maximum Entropy Markov Models and label sequence boosting, HM-SVMs have a number of advantages. Most notably, it is possible to learn non-linear discriminant functions via kernel functions. At the same time, HM-SVMs share the key advantages with other discriminative methods, in particular the capability to deal with overlapping features. We report experimental evaluations on two tasks, named entity recognition and part-of-speech tagging, that demonstrate the competitiveness of the proposed approach."
            },
            "slug": "Hidden-Markov-Support-Vector-Machines-Altun-Tsochantaridis",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper presents a novel discriminative learning technique for label sequences based on a combination of the two most successful learning algorithms, Support Vector Machines and Hidden Markov Models which it is called HM-SVMs and handles dependencies between neighboring labels using Viterbi decoding."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765700"
                        ],
                        "name": "Ioannis Tsochantaridis",
                        "slug": "Ioannis-Tsochantaridis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Tsochantaridis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Tsochantaridis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783941"
                        ],
                        "name": "Y. Altun",
                        "slug": "Y.-Altun",
                        "structuredName": {
                            "firstName": "Yasemin",
                            "lastName": "Altun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Altun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 29
                            }
                        ],
                        "text": ", 2003), and structural SVMs (Tsochantaridis et al., 2004) have substantially improved prediction performance on a variety of structured prediction problems, including part-ofspeech tagging (Altun et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 188
                            }
                        ],
                        "text": "To find w balancing model complexity and empirical risk R S (h) = 1 n \u2211n i=1 \u2206(yi, h(xi)), SSVMs solve the following quadratic program (QP) for the case of the margin-rescaling hinge loss (Tsochantaridis et al., 2004):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 37
                            }
                        ],
                        "text": ", 2003), and structural SVMs (SSVMs) (Tsochantaridis et al., 2004)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 564746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93aa298b40bb3ec23c25239089284fdf61ded917",
            "isKey": false,
            "numCitedBy": 1455,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning general functional dependencies is one of the main goals in machine learning. Recent progress in kernel-based methods has focused on designing flexible and powerful input representations. This paper addresses the complementary issue of problems involving complex outputs such as multiple dependent output variables and structured output spaces. We propose to generalize multiclass Support Vector Machine learning in a formulation that involves features extracted jointly from inputs and outputs. The resulting optimization problem is solved efficiently by a cutting plane algorithm that exploits the sparseness and structural decomposition of the problem. We demonstrate the versatility and effectiveness of our method on problems ranging from supervised grammar learning and named-entity recognition, to taxonomic text classification and sequence alignment."
            },
            "slug": "Support-vector-machine-learning-for-interdependent-Tsochantaridis-Hofmann",
            "title": {
                "fragments": [],
                "text": "Support vector machine learning for interdependent and structured output spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes to generalize multiclass Support Vector Machine learning in a formulation that involves features extracted jointly from inputs and outputs, and demonstrates the versatility and effectiveness of the method on problems ranging from supervised grammar learning and named-entity recognition, to taxonomic text classification and sequence alignment."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 117
                            }
                        ],
                        "text": "Several discriminative structural learners were proposed in recent years, including conditional random fields (CRFs) (Lafferty et al., 2001), Perceptron HMMs (Collins, 2002), max-margin Markov networks (M(3)Ns) (Taskar et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 63
                            }
                        ],
                        "text": "Discriminative training methods like conditional random fields (Lafferty et al., 2001), maximum-margin Markov networks (Taskar et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13411,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33913193"
                        ],
                        "name": "Xuming He",
                        "slug": "Xuming-He",
                        "structuredName": {
                            "firstName": "Xuming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400347470"
                        ],
                        "name": "M. A. Carreira-Perpi\u00f1\u00e1n",
                        "slug": "M.-A.-Carreira-Perpi\u00f1\u00e1n",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Carreira-Perpi\u00f1\u00e1n",
                            "middleNames": [
                                "\u00c1."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Carreira-Perpi\u00f1\u00e1n"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 50
                            }
                        ],
                        "text": "Therefore, the partition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar & Hebert, 2003; Vishwanathan et al., 2006), or the model is simplified to make the partition function tractable (Sutton & McCallum, 2005), or CRF max-likelihood training is replaced with Perceptron training (Roth & Yih, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 73
                            }
                        ],
                        "text": "Therefore, the par\u00adtition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar &#38; \nHebert, 2003; Vishwanathan et al., 2006), or the model is simpli.ed to make the par\u00adtition function tractable \n(Sutton &#38; McCallum, 2005), or CRF max-likelihood training is replaced with\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11859305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "363b56f85e12389017ba8894056a1b309e46a5f7",
            "isKey": false,
            "numCitedBy": 933,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to include contextual features for labeling images, in which each pixel is assigned to one of a finite set of labels. The features are incorporated into a probabilistic framework, which combines the outputs of several components. Components differ in the information they encode. Some focus on the image-label mapping, while others focus solely on patterns within the label field. Components also differ in their scale, as some focus on fine-resolution patterns while others on coarser, more global structure. A supervised version of the contrastive divergence algorithm is applied to learn these features from labeled image data. We demonstrate performance on two real-world image databases and compare it to a classifier and a Markov random field."
            },
            "slug": "Multiscale-conditional-random-fields-for-image-He-Zemel",
            "title": {
                "fragments": [],
                "text": "Multiscale conditional random fields for image labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An approach to include contextual features for labeling images, in which each pixel is assigned to one of a finite set of labels, are incorporated into a probabilistic framework, which combines the outputs of several components."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713874"
                        ],
                        "name": "S. Vishwanathan",
                        "slug": "S.-Vishwanathan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vishwanathan",
                            "middleNames": [
                                "V.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vishwanathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145610994"
                        ],
                        "name": "Mark W. Schmidt",
                        "slug": "Mark-W.-Schmidt",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Schmidt",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark W. Schmidt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 98
                            }
                        ],
                        "text": "Therefore, the par\u00adtition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar &#38; \nHebert, 2003; Vishwanathan et al., 2006), or the model is simpli.ed to make the par\u00adtition function tractable \n(Sutton &#38; McCallum, 2005), or CRF max-likelihood training is replaced with Per\u00adceptron training (Roth \n&#38; Yih, 2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 50
                            }
                        ],
                        "text": "Therefore, the partition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar & Hebert, 2003; Vishwanathan et al., 2006), or the model is simplified to make the partition function tractable (Sutton & McCallum, 2005), or CRF max-likelihood training is replaced with Perceptron training (Roth & Yih, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "Kumar, S., &#38; Hebert, M. (2003)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 112
                            }
                        ],
                        "text": "Therefore, the par\u00adtition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar &#38; \nHebert, 2003; Vishwanathan et al., 2006), or the model is simpli.ed to make the par\u00adtition function tractable \n(Sutton &#38; McCallum, 2005), or CRF max-likelihood training is replaced with\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1978101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "950e8d556e30d2a873172bfa90f4f36da5286c07",
            "isKey": true,
            "numCitedBy": 358,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply Stochastic Meta-Descent (SMD), a stochastic gradient optimization method with gain vector adaptation, to the training of Conditional Random Fields (CRFs). On several large data sets, the resulting optimizer converges to the same quality of solution over an order of magnitude faster than limited-memory BFGS, the leading method reported to date. We report results for both exact and inexact inference techniques."
            },
            "slug": "Accelerated-training-of-conditional-random-fields-Vishwanathan-Schraudolph",
            "title": {
                "fragments": [],
                "text": "Accelerated training of conditional random fields with stochastic gradient methods"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Stochastic Meta-Descent (SMD), a stochastic gradient optimization method with gain vector adaptation, is applied to the training of Conditional Random Fields (CRFs) and the resulting optimizer converges to the same quality of solution over an order of magnitude faster than limited-memory BFGS."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838674"
                        ],
                        "name": "Dragomir Anguelov",
                        "slug": "Dragomir-Anguelov",
                        "structuredName": {
                            "firstName": "Dragomir",
                            "lastName": "Anguelov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dragomir Anguelov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482074"
                        ],
                        "name": "Vassil Chatalbashev",
                        "slug": "Vassil-Chatalbashev",
                        "structuredName": {
                            "firstName": "Vassil",
                            "lastName": "Chatalbashev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vassil Chatalbashev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35195064"
                        ],
                        "name": "D. Gupta",
                        "slug": "D.-Gupta",
                        "structuredName": {
                            "firstName": "Dinkar",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728179"
                        ],
                        "name": "G. Heitz",
                        "slug": "G.-Heitz",
                        "structuredName": {
                            "firstName": "Geremy",
                            "lastName": "Heitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Heitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "(Anguelov et al., 2005) proposed to directly fold a linear relaxation into OP 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 27
                            }
                        ],
                        "text": "For M3Ns, Anguelov et al. (Anguelov et al., 2005) pro\u00adposed to directly fold a linear \nrelaxation into OP 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8396595,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55a5e1a4e0068a4f2a8a8bdfbd777c249110ccfe",
            "isKey": false,
            "numCitedBy": 419,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of segmenting 3D scan data into objects or object classes. Our segmentation framework is based on a subclass of Markov random fields (MRFs) which support efficient graph-cut inference. The MRF models incorporate a large set of diverse features and enforce the preference that adjacent scan points have the same classification label. We use a recently proposed maximum-margin framework to discriminatively train the model from a set of labeled scans; as a result we automatically learn the relative importance of the features for the segmentation task. Performing graph-cut inference in the trained MRF can then be used to segment new scenes very efficiently. We test our approach on three large-scale datasets produced by different kinds of 3D sensors, showing its applicability to both outdoor and indoor environments containing diverse objects."
            },
            "slug": "Discriminative-learning-of-Markov-random-fields-for-Anguelov-Taskar",
            "title": {
                "fragments": [],
                "text": "Discriminative learning of Markov random fields for segmentation of 3D scan data"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This work addresses the problem of segmenting 3D scan data into objects or object classes by using a recently proposed maximum-margin framework to discriminatively train the model from a set of labeled scans and automatically learn the relative importance of the features for the segmentation task."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1840551"
                        ],
                        "name": "M. Boutell",
                        "slug": "M.-Boutell",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Boutell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Boutell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111112811"
                        ],
                        "name": "Xipeng Shen",
                        "slug": "Xipeng-Shen",
                        "structuredName": {
                            "firstName": "Xipeng",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xipeng Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48726084"
                        ],
                        "name": "Christopher M. Brown",
                        "slug": "Christopher-M.-Brown",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher M. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 26
                            }
                        ],
                        "text": "Four real datasets, Scene (Boutell et al., 2004), Yeast (Elisseeff & Weston, 2002), Reuters (the RCV1 subset 1 data set) (Lewis et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Scene Yeast Reuters Mediamill Synth1 Synth2 \n 6 471 5045 6000 36015 8.99\u00b1.08 16.34 Greedy 0.43% 17.02% 31.28% 20.81% 0.00% 31.17% LBP 0.31% 0.00% \n0.00% 0.00% 0.00% 0.00% Combine 2.90% 91.42% 0.44% 4.27% 0.00% 29.11% Exact 0.95% 84.30% 0.67% 65.58% \n0.00% 27.92% LProg 0.00% 0.43% 0.32% 1.30% 0.00% 1.48% the same results, excepting Cut s superior speed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 215
                            }
                        ],
                        "text": "Yeast 14 1500 917 103 1533 20.91\u00b1.55 25.09 Reuters 10 \n2916 2914 47236 472405 4.96\u00b1.09 15.80 Mediamill 10 29415 12168 120 1245 18.60\u00b1.14 25.37 Synth1 Synth2 \n10 1000 10000 40 445 9.80\u00b1.09 10.00 Four real datasets, Scene (Boutell et al., 2004), Yeast (Elissee."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 62
                            }
                        ],
                        "text": "Greedy LBP Combine Exact LProg Greedy LBP Combine \nExact LProg Scene Dataset Mediamill Dataset Greedy 10.67\u00b1.28 10.74\u00b1.28 10.67\u00b1.28 10.67\u00b1.28 10.67\u00b1.28 \n23.39\u00b1.16 25.66\u00b1.17 24.32\u00b1.17 24.92\u00b1.17 27.05\u00b1.18 LBP 10.45\u00b1.27 10.54\u00b1.27 10.45\u00b1.27 10.42\u00b1.27 10.49\u00b1.27 \n22.83\u00b1.16 22.83\u00b1.16 22.83\u00b1.16 22.83\u00b1.16 22.83\u00b1.16 Combine 10.72\u00b1.28 11.78\u00b1.30 10.72\u00b1.28 10.77\u00b1.28 11.20\u00b1.29 \n19.56\u00b1.14 20.12\u00b1.15 19.72\u00b1.14 19.82\u00b1.14 20.23\u00b1.15 Exact 10.08\u00b1.26 10.33\u00b1.27 10.08\u00b1.26 10.06\u00b1.26 10.20\u00b1.26 \n19.07\u00b1.14 27.23\u00b1.18 19.08\u00b1.14 18.75\u00b1.14 36.83\u00b1.21 LProg 10.55\u00b1.27 10.49\u00b1.27 10.49\u00b1.27 10.49\u00b1.27 10.49\u00b1.27 \n18.50\u00b1.14 18.26\u00b1.14 18.26\u00b1.14 18.21\u00b1.14 18.29\u00b1.14 Yeast Dataset Synth1 Dataset Greedy 21.62\u00b1.56 21.77\u00b1.56 \n21.58\u00b1.56 21.62\u00b1.56 24.42\u00b1.61 8.86\u00b1.08 8.86\u00b1.08 8.86\u00b1.08 8.86\u00b1.08 8.86\u00b1.08 LBP 24.32\u00b1.61 24.32\u00b1.61 24.32\u00b1.61 \n24.32\u00b1.61 24.32\u00b1.61 13.94\u00b1.12 13.94\u00b1.12 13.94\u00b1.12 13.94\u00b1.12 13.94\u00b1.12 Combine 22.33\u00b1.57 37.24\u00b1.77 22.32\u00b1.57 \n21.82\u00b1.56 42.72\u00b1.81 8.86\u00b1.08 8.86\u00b1.08 8.86\u00b1.08 8.86\u00b1.08 8.86\u00b1.08 Exact 23.38\u00b1.59 21.99\u00b1.57 21.06\u00b1.55 \n20.23\u00b1.53 45.90\u00b1.82 6.89\u00b1.06 6.86\u00b1.06 6.86\u00b1.06 6.86\u00b1.06 6.86\u00b1.06 LProg 20.47\u00b1.54 20.45\u00b1.54 20.47\u00b1.54 \n20.48\u00b1.54 20.49\u00b1.54 8.94\u00b1.08 8.94\u00b1.08 8.94\u00b1.08 8.94\u00b1.08 8.94\u00b1.08 Reuters Dataset Synth2 Dataset Greedy \n5.32\u00b1.09 13.38\u00b1.21 5.06\u00b1.09 5.42\u00b1.09 16.98\u00b1.26 7.27\u00b1.07 27.92\u00b1.20 7.27\u00b1.07 7.28\u00b1.07 19.03\u00b1.15 LBP 15.80\u00b1.25 \n15.80\u00b1.25 15.80\u00b1.25 15.80\u00b1.25 15.80\u00b1.25 10.00\u00b1.09 10.00\u00b1.09 10.00\u00b1.09 10.00\u00b1.09 10.00\u00b1.09 Combine 4.90\u00b1.09 \n4.57\u00b1.08 4.53\u00b1.08 4.49\u00b1.08 4.55\u00b1.08 7.90\u00b1.07 26.39\u00b1.19 7.90\u00b1.07 7.90\u00b1.07 18.11\u00b1.15 Exact 6.36\u00b1.11 5.54\u00b1.10 \n5.67\u00b1.10 5.59\u00b1.10 5.62\u00b1.10 7.04\u00b1.07 25.71\u00b1.19 7.04\u00b1.07 7.04\u00b1.07 17.80\u00b1.15 LProg 6.73\u00b1.12 6.41\u00b1.11 6.38\u00b1.11 \n6.38\u00b1.11 6.38\u00b1.11 5.83\u00b1.05 6.63\u00b1.06 5.83\u00b1.05 5.83\u00b1.05 6.29\u00b1.06 Undergenerating and exact training do \nnot control for this, leading to relaxed inference yielding many am\u00adbiguous labelings."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9404152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "896b9c1551b7ffa347baed144582ec3b5d88f703",
            "isKey": true,
            "numCitedBy": 1923,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-multi-label-scene-classification-Boutell-Luo",
            "title": {
                "fragments": [],
                "text": "Learning multi-label scene classification"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 64
                            }
                        ],
                        "text": "Cut is quadratic pseudo-Boolean optimization using a graph-cut \n(Kolmogorov &#38; Rother, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15319364,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41dd3da0216e5f47511c2e7413089043c11295f6",
            "isKey": false,
            "numCitedBy": 415,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Optimization techniques based on graph cuts have become a standard tool for many vision applications. These techniques allow to minimize efficiently certain energy functions corresponding to pairwise Markov random fields (MRFs). Currently, there is an accepted view within the computer vision community that graph cuts can only be used for optimizing a limited class of MRF energies (e.g., submodular functions). In this survey, we review some results that show that graph cuts can be applied to a much larger class of energy functions (in particular, nonsubmodular functions). While these results are well-known in the optimization community, to our knowledge they were not used in the context of computer vision and MRF optimization. We demonstrate the relevance of these results to vision on the problem of binary texture restoration."
            },
            "slug": "Minimizing-Nonsubmodular-Functions-with-Graph-Kolmogorov-Rother",
            "title": {
                "fragments": [],
                "text": "Minimizing Nonsubmodular Functions with Graph Cuts-A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This survey reviews some results that show that graph cuts can be applied to a much larger class of energy functions (in particular, nonsubmodular functions) and demonstrates the relevance of these results to vision on the problem of binary texture restoration."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 42
                            }
                        ],
                        "text": "Cut was implemented \nwith Max.ow software (Boykov &#38; Kolmogorov, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5324521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c62fdf1e6a520d9fee8ca9981fb588d07f2c6fa",
            "isKey": false,
            "numCitedBy": 3563,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Minimum cut/maximum flow algorithms on graphs have emerged as an increasingly useful tool for exactor approximate energy minimization in low-level vision. The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity. Their practical efficiency, however, has to date been studied mainly outside the scope of computer vision. The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision. We compare the running times of several standard algorithms, as well as a new algorithm that we have recently developed. The algorithms we study include both Goldberg-Tarjan style \"push -relabel\" methods and algorithms based on Ford-Fulkerson style \"augmenting paths.\" We benchmark these algorithms on a number of typical graphs in the contexts of image restoration, stereo, and segmentation. In many cases, our new algorithm works several times faster than any of the other methods, making near real-time performance possible. An implementation of our max-flow/min-cut algorithm is available upon request for research purposes."
            },
            "slug": "An-experimental-comparison-of-min-cut/max-flow-for-Boykov-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "An experimental comparison of min-cut/max- flow algorithms for energy minimization in vision"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision, comparing the running times of several standard algorithms, as well as a new algorithm that is recently developed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32440409"
                        ],
                        "name": "T. Rose",
                        "slug": "T.-Rose",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Rose",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146329150"
                        ],
                        "name": "Fan Li",
                        "slug": "Fan-Li",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fan Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 53
                            }
                        ],
                        "text": "Weston, 2002), Reuters (the RCV1 subset 1 data set) (Lewis et al., 2004), and Me\u00addiamill (Snoek \net al., 2006), came from the LIBSVM multi-label dataset collection (Chang &#38; Lin, 2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 80
                            }
                        ],
                        "text": ", 2004), Yeast (Elisseeff & Weston, 2002), Reuters (the RCV1 subset 1 data set) (Lewis et al., 2004), and Me-"
                    },
                    "intents": []
                }
            ],
            "corpusId": 11027141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2abe6b9ea1b13653b7384e9c8ef14b0d87e20cfc",
            "isKey": false,
            "numCitedBy": 2683,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters documentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illustrating the collection's properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices."
            },
            "slug": "RCV1:-A-New-Benchmark-Collection-for-Text-Research-Lewis-Yang",
            "title": {
                "fragments": [],
                "text": "RCV1: A New Benchmark Collection for Text Categorization Research"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50256971"
                        ],
                        "name": "Thomas Finley",
                        "slug": "Thomas-Finley",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Finley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Finley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 200
                            }
                        ],
                        "text": "Related \nWork In prior work on discriminative training using approx\u00adimate inference, structural SVMs have learned \nmod\u00adels for correlation clustering, utilizing both greedy and LP relaxed approximations (Finley &#38; \nJoachims, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 77
                            }
                        ],
                        "text": "However, in many important problems (e.g., cluster\u00ading (Culotta et \nal., 2007; Finley &#38; Joachims, 2005), multi-label classi.cation, image segmentation, ma\u00adchine translation) \nexact inference and the separation oracle are computationally intractable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8292657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9616433b227763c28f31820ec05b174fcd577af",
            "isKey": false,
            "numCitedBy": 238,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Supervised clustering is the problem of training a clustering algorithm to produce desirable clusterings: given sets of items and complete clusterings over these sets, we learn how to cluster future sets of items. Example applications include noun-phrase coreference clustering, and clustering news articles by whether they refer to the same topic. In this paper we present an SVM algorithm that trains a clustering algorithm by adapting the item-pair similarity measure. The algorithm may optimize a variety of different clustering functions to a variety of clustering performance measures. We empirically evaluate the algorithm for noun-phrase and news article clustering."
            },
            "slug": "Supervised-clustering-with-support-vector-machines-Finley-Joachims",
            "title": {
                "fragments": [],
                "text": "Supervised clustering with support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper presents an SVM algorithm that trains a clustering algorithm by adapting the item-pair similarity measure, and empirically evaluates the algorithm for noun-phrase and news article clustering."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145404204"
                        ],
                        "name": "Cees G. M. Snoek",
                        "slug": "Cees-G.-M.-Snoek",
                        "structuredName": {
                            "firstName": "Cees",
                            "lastName": "Snoek",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cees G. M. Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738975"
                        ],
                        "name": "J. V. Gemert",
                        "slug": "J.-V.-Gemert",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Gemert",
                            "middleNames": [
                                "C.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Gemert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720149"
                        ],
                        "name": "J. Geusebroek",
                        "slug": "J.-Geusebroek",
                        "structuredName": {
                            "firstName": "Jan-Mark",
                            "lastName": "Geusebroek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Geusebroek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15379808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ab5acb5f32ef2d28f91109d40e5e859a9c101bf",
            "isKey": false,
            "numCitedBy": 646,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the challenge problem for generic video indexing to gain insight in intermediate steps that affect performance of multimedia analysis methods, while at the same time fostering repeatability of experiments. To arrive at a challenge problem, we provide a general scheme for the systematic examination of automated concept detection methods, by decomposing the generic video indexing problem into 2 unimodal analysis experiments, 2 multimodal analysis experiments, and 1 combined analysis experiment. For each experiment, we evaluate generic video indexing performance on 85 hours of international broadcast news data, from the TRECVID 2005/2006 benchmark, using a lexicon of 101 semantic concepts. By establishing a minimum performance on each experiment, the challenge problem allows for component-based optimization of the generic indexing issue, while simultaneously offering other researchers a reference for comparison during indexing methodology development. To stimulate further investigations in intermediate analysis steps that inuence video indexing performance, the challenge offers to the research community a manually annotated concept lexicon, pre-computed low-level multimedia features, trained classifier models, and five experiments together with baseline performance, which are all available at http://www.mediamill.nl/challenge/."
            },
            "slug": "The-challenge-problem-for-automated-detection-of-in-Snoek-Worring",
            "title": {
                "fragments": [],
                "text": "The challenge problem for automated detection of 101 semantic concepts in multimedia"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The challenge problem for generic video indexing is introduced to gain insight in intermediate steps that affect performance of multimedia analysis methods, while at the same time fostering repeatability of experiments."
            },
            "venue": {
                "fragments": [],
                "text": "MM '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692448"
                        ],
                        "name": "P. Hammer",
                        "slug": "P.-Hammer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hammer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144250254"
                        ],
                        "name": "P. Hansen",
                        "slug": "P.-Hansen",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Hansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744574"
                        ],
                        "name": "B. Simeone",
                        "slug": "B.-Simeone",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Simeone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Simeone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "Boros, E., &#38; Hammer, P. L. (2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 143
                            }
                        ],
                        "text": "We consider the following overgenerating methods: LProg \nis an expression of the inference problem as a relaxed integer linear program (Boros &#38; Hammer, 2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 12
                            }
                        ],
                        "text": "{0, 2 , 1} (Hammer et al., 1984)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Hammer, P. L., Hansen, P., &#38; Simeone, B. (1984)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 87
                            }
                        ],
                        "text": "The LProg and Cut approximations share two im\u00adportant properties (Boros &#38; Hammer, \n2002; Hammer et al., 1984): Equivalence says that maximizing so\u00adlutions of the Cut and LProg formulations \nare trans\u00admutable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 156
                            }
                        ],
                        "text": "One proof de.nes this transmutation proce\u00ad 1 dure, where \u00d8 (in cuts optimization) \nand (in LP 2 optimization) variable assignments are interchange\u00adable (Boros &#38; Hammer, 2002)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23630537,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7c6da6017d0325a37787d78f5015700c45eaa765",
            "isKey": true,
            "numCitedBy": 333,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper is concerned with the \u2018primal\u2019 problem of maximizing a given quadratic pseudo-boolean function. Four equivalent problems are discussed\u2014the primal, the \u2018complementation\u2019, the \u2018discrete Rhys LP\u2019 and the \u2018weighted stability problem of a SAM graph\u2019. Each of them has a relaxation\u2014the \u2018roof dual\u2019, the \u2018quadratic complementation,\u2019 the \u2018continuous Rhys LP\u2019 and the \u2018fractional weighted stability problem of a SAM graph\u2019. The main result is that the four gaps associated with the four relaxations are equal. Furthermore, a solution to any of these problems leads at once to solutions of the other three equivalent ones. The four relaxations can be solved in polynomial time by transforming them to a bipartite maximum flow problem. The optimal solutions of the \u2018roof-dual\u2019 define \u2018best\u2019 linear majorantsp(x) off, having the following persistency property: if theith coefficient inp is positive (negative) thenxi=1 (0) in every optimum of the primal problem. Several characterizations are given for the case where these persistency results cannot be used to fix any variable of the primal. On the other hand, a class of gap-free functions (properly including the supermodular ones) is exhibited."
            },
            "slug": "Roof-duality,-complementation-and-persistency-in-Hammer-Hansen",
            "title": {
                "fragments": [],
                "text": "Roof duality, complementation and persistency in quadratic 0\u20131 optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main result is that the four gaps associated with the four relaxations are equal, and a class of gap-free functions (properly including the supermodular ones) is exhibited."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741453"
                        ],
                        "name": "A. Culotta",
                        "slug": "A.-Culotta",
                        "structuredName": {
                            "firstName": "Aron",
                            "lastName": "Culotta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Culotta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987641"
                        ],
                        "name": "Michael L. Wick",
                        "slug": "Michael-L.-Wick",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wick",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael L. Wick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 50
                            }
                        ],
                        "text": "Therefore, the partition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar & Hebert, 2003; Vishwanathan et al., 2006), or the model is simplified to make the partition function tractable (Sutton & McCallum, 2005), or CRF max-likelihood training is replaced with Perceptron training (Roth & Yih, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 13
                            }
                        ],
                        "text": ", clustering (Culotta et al., 2007; Finley & Joachims, 2005), multi-label classification, image segmentation, machine translation) exact inference and the separation oracle are computationally intractable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 51
                            }
                        ],
                        "text": "Therefore, the par\u00adtition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar &#38; \nHebert, 2003; Vishwanathan et al., 2006), or the model is simpli.ed to make the par\u00adtition function tractable \n(Sutton &#38; McCallum, 2005), or CRF max-likelihood training is replaced with\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 55
                            }
                        ],
                        "text": "However, in many important problems (e.g., cluster\u00ading (Culotta et \nal., 2007; Finley &#38; Joachims, 2005), multi-label classi.cation, image segmentation, ma\u00adchine translation) \nexact inference and the separation oracle are computationally intractable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6618210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a957e6cbc55f004f94b468f23c5149f1b0fd3389",
            "isKey": true,
            "numCitedBy": 192,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional noun phrase coreference resolution systems represent features only of pairs of noun phrases. In this paper, we propose a machine learning method that enables features over sets of noun phrases, resulting in a first-order probabilistic model for coreference. We outline a set of approximations that make this approach practical, and apply our method to the ACE coreference dataset, achieving a 45% error reduction over a comparable method that only considers features of pairs of noun phrases. This result demonstrates an example of how a firstorder logic representation can be incorporated into a probabilistic model and scaled efficiently."
            },
            "slug": "First-Order-Probabilistic-Models-for-Coreference-Culotta-Wick",
            "title": {
                "fragments": [],
                "text": "First-Order Probabilistic Models for Coreference Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A machine learning method is proposed that enables features over sets of noun phrases, resulting in a first-order probabilistic model for coreference, and it is applied to the ACE coreference dataset, achieving a 45% error reduction over a comparable method."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766703"
                        ],
                        "name": "A. Elisseeff",
                        "slug": "A.-Elisseeff",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Elisseeff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Elisseeff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1976599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30b2a3422332a76663110beae4bfc4d74763f4a0",
            "isKey": false,
            "numCitedBy": 1246,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a Support Vector Machine (SVM) like learning system to handle multi-label problems. Such problems are usually decomposed into many two-class problems but the expressive power of such a system can be weak [5, 7]. We explore a new direct approach. It is based on a large margin ranking system that shares a lot of common properties with SVMs. We tested it on a Yeast gene functional classification problem with positive results."
            },
            "slug": "A-kernel-method-for-multi-labelled-classification-Elisseeff-Weston",
            "title": {
                "fragments": [],
                "text": "A kernel method for multi-labelled classification"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This article presents a Support Vector Machine like learning system to handle multi-label problems, based on a large margin ranking system that shares a lot of common properties with SVMs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 33
                            }
                        ],
                        "text": "LBP is loopy belief propagation (Pearl, 1988)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18218,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 68
                            }
                        ],
                        "text": "Training Structural SVMs when Exact Inference is Intractable Thomas Finley tomf@cs.cornell.edu Thorsten \nJoachims tj@cs.cornell.edu Cornell University, Department of Computer Science, Upson Hall, Ithaca, NY \n14853 USA Abstract While discriminative training (e.g., CRF, structural SVM) holds much promise for ma\u00adchine \ntranslation, image segmentation, and clustering, the complex inference these ap\u00adplications require make \nexact training in\u00adtractable."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 209
                            }
                        ],
                        "text": "Related \nWork In prior work on discriminative training using approx\u00adimate inference, structural SVMs have learned \nmod\u00adels for correlation clustering, utilizing both greedy and LP relaxed approximations (Finley &#38; \nJoachims, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Finley, T., &#38; Joachims, T. (2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 86
                            }
                        ],
                        "text": "However, in many important problems (e.g., cluster\u00ading (Culotta et \nal., 2007; Finley &#38; Joachims, 2005), multi-label classi.cation, image segmentation, ma\u00adchine translation) \nexact inference and the separation oracle are computationally intractable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 62
                            }
                        ],
                        "text": ", 2007), and classification under multivariate loss functions (Joachims, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 281,
                                "start": 267
                            }
                        ],
                        "text": "\u2026prediction performance on a variety of structured prediction problems, including part-of\u00adspeech \ntagging (Altun et al., 2003), natural language parsing (Tsochantaridis et al., 2005), sequence align\u00adment \n(Yu et al., 2007), and classi.cation under multi\u00advariate loss functions (Joachims, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1115550,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "175c1bb60ee46dac56d942ef8c7339977b4ebb0e",
            "isKey": false,
            "numCitedBy": 845,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a Support Vector Method for optimizing multivariate nonlinear performance measures like the F1-score. Taking a multivariate prediction approach, we give an algorithm with which such multivariate SVMs can be trained in polynomial time for large classes of potentially non-linear performance measures, in particular ROCArea and all measures that can be computed from the contingency table. The conventional classification SVM arises as a special case of our method."
            },
            "slug": "A-support-vector-method-for-multivariate-measures-Joachims",
            "title": {
                "fragments": [],
                "text": "A support vector method for multivariate performance measures"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An algorithm with which such multivariate SVMs can be trained in polynomial time for large classes of potentially non-linear performance measures, in particular ROCArea and all measures that can be computed from the contingency table are given."
            },
            "venue": {
                "fragments": [],
                "text": "K\u00fcnstliche Intell."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708061"
                        ],
                        "name": "E. Boros",
                        "slug": "E.-Boros",
                        "structuredName": {
                            "firstName": "Endre",
                            "lastName": "Boros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Boros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692448"
                        ],
                        "name": "P. Hammer",
                        "slug": "P.-Hammer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hammer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hammer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "One proof de.nes this transmutation proce\u00ad 1 dure, where \u00d8 (in cuts optimization) \nand (in LP 2 optimization) variable assignments are interchange\u00adable (Boros &#38; Hammer, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 65
                            }
                        ],
                        "text": "The LProg and Cut approximations share two im\u00adportant properties (Boros &#38; Hammer, \n2002; Hammer et al., 1984): Equivalence says that maximizing so\u00adlutions of the Cut and LProg formulations \nare trans\u00admutable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 135
                            }
                        ],
                        "text": "We consider the following overgenerating methods: LProg \nis an expression of the inference problem as a relaxed integer linear program (Boros &#38; Hammer, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11157651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b57d8ca6b0eadcb2689c4963e698bb4db1f23a7",
            "isKey": false,
            "numCitedBy": 804,
            "numCiting": 214,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pseudo-Boolean-optimization-Boros-Hammer",
            "title": {
                "fragments": [],
                "text": "Pseudo-Boolean optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Appl. Math."
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "Boros, E., &#38; Hammer, P. L. (2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 83
                            }
                        ],
                        "text": "Importantly, there is always some optimal solution where all yu, yuv \u2208 {0, 12 , 1} (Hammer et al., 1984)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 64
                            }
                        ],
                        "text": "The LProg and Cut approximations share two important properties (Boros & Hammer, 2002; Hammer et al., 1984): Equivalence says that maximizing solutions of the Cut and LProg formulations are transmutable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 143
                            }
                        ],
                        "text": "We consider the following overgenerating methods: LProg \nis an expression of the inference problem as a relaxed integer linear program (Boros &#38; Hammer, 2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 12
                            }
                        ],
                        "text": "{0, 2 , 1} (Hammer et al., 1984)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Hammer, P. L., Hansen, P., &#38; Simeone, B. (1984)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 87
                            }
                        ],
                        "text": "The LProg and Cut approximations share two im\u00adportant properties (Boros &#38; Hammer, \n2002; Hammer et al., 1984): Equivalence says that maximizing so\u00adlutions of the Cut and LProg formulations \nare trans\u00admutable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 156
                            }
                        ],
                        "text": "One proof de.nes this transmutation proce\u00ad 1 dure, where \u00d8 (in cuts optimization) \nand (in LP 2 optimization) variable assignments are interchange\u00adable (Boros &#38; Hammer, 2002)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Roofduality, complementation, and persistency in quadratic 0\u20131"
            },
            "venue": {
                "fragments": [],
                "text": "optimization. Math. Program.,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "\u2026et al., 2005) have substan\u00adtially \nimproved prediction performance on a variety of structured prediction problems, including part-of\u00adspeech \ntagging (Altun et al., 2003), natural language parsing (Tsochantaridis et al., 2005), sequence align\u00adment \n(Yu et al., 2007), and classi.cation under\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hid - den Markov support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Max-margin Markov networks. In NIPS 16"
            },
            "venue": {
                "fragments": [],
                "text": "Max-margin Markov networks. In NIPS 16"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Searn in practice"
            },
            "venue": {
                "fragments": [],
                "text": "Searn in practice"
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 14,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Training-structural-SVMs-when-exact-inference-is-Finley-Joachims/bc243b4920cdc9f45ef18ef0bad5b6576c444a34?sort=total-citations"
}