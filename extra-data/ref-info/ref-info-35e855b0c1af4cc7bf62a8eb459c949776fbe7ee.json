{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891864"
                        ],
                        "name": "Gyuri Dork\u00f3",
                        "slug": "Gyuri-Dork\u00f3",
                        "structuredName": {
                            "firstName": "Gyuri",
                            "lastName": "Dork\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyuri Dork\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "One way to overcome this potential weakness is to use feature selection [11] or boosting [41] to retain only the most discriminative features for recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7423140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edfc506e67681bf7baa4362ca60cda39744383f5",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we introduce a scale-invariant feature selection method that learns to recognize and detect object classes from images of natural scenes. The first step of our method consists of clustering local scale-invariant descriptors to characterize object class appearance. Next, we train on the groups, and perform feature selection to determine the most discriminative parts. We use local regions to realize robust and sparse part and texture selection invariant to changes in scale, orientation and affine deformation and, as a result, we avoid image normalization in both training and prediction phases. We train our object models without requiring image parts to be labeled or objects to be separated from the background. Moreover, our method continues to work well when images have cluttered background and occluded objects. We evaluate our method on seven recently proposed datasets, and quantitatively compare the effect of different types of local regions and feature selection criteria on object recognition. Our experiments show that local invariant descriptors are an appropriate representation for many different object classes. Our results also confirm the importance of appearance-based discriminative feature selection."
            },
            "slug": "Object-Class-Recognition-Using-Discriminative-Local-Dork\u00f3-Schmid",
            "title": {
                "fragments": [],
                "text": "Object Class Recognition Using Discriminative Local Features"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A scale-invariant feature selection method that learns to recognize and detect object classes from images of natural scenes that uses local regions to realize robust and sparse part and texture selection invariant to changes in scale, orientation and affine deformation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Additional research directions include designing kernels that incorporate geometrical relations between local features (see [17] for preliminary work along these lines) and feature selection methods that can separate foreground from background."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2363818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d582df7250124b0523e07f61766cfa422eb5cde2",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Sets of local features that are invariant to common image transformations are an effective representation to use when comparing images; current methods typically judge feature sets' similarity via a voting scheme (which ignores co-occurrence statistics) or by comparing histograms over a set of prototypes (which must be found by clustering). We present a method for efficiently comparing images based on their discrete distributions (bags) of distinctive local invariant features, without clustering descriptors. Similarity between images is measured with an approximation of the Earth Mover's Distance (EMD), which quickly computes minimal-cost correspondences between two bags of features. Each image's feature distribution is mapped into a normed space with a low-distortion embedding of EMD. Examples most similar to a novel query image are retrieved in time sublinear in the number of examples via approximate nearest neighbor search in the embedded space. We evaluate our method with scene, object, and texture recognition tasks."
            },
            "slug": "Efficient-image-matching-with-distributions-of-Grauman-Darrell",
            "title": {
                "fragments": [],
                "text": "Efficient image matching with distributions of local invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a method for efficiently comparing images based on their discrete distributions of distinctive local invariant features, without clustering descriptors, and evaluates the method with scene, object, and texture recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793750"
                        ],
                        "name": "C. Wallraven",
                        "slug": "C.-Wallraven",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wallraven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wallraven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2646632"
                        ],
                        "name": "M. Nilsback",
                        "slug": "M.-Nilsback",
                        "structuredName": {
                            "firstName": "Maria-Elena",
                            "lastName": "Nilsback",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nilsback"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 144648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76dfa58f92d79f004297588e33f192c619085d39",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers the problem of multi-object categorization. We present an algorithm that combines support vector machines with local features via a new class of Mercer kernels. This class of kernels allows us to perform scalar products on feature vectors consisting of local descriptors, computed around interest points (like corners); these feature vectors are generally of different lengths for different images. The resulting framework is able to recognize multi-object categories in different settings, from lab-controlled to real-world scenes. We present several experiments, on different databases, and we benchmark our results with state-of-the-art algorithms for categorization, achieving excellent results."
            },
            "slug": "Object-categorization-via-local-kernels-Caputo-Wallraven",
            "title": {
                "fragments": [],
                "text": "Object categorization via local kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "An algorithm that combines support vector machines with local features via a new class of Mercer kernels allows us to perform scalar products on feature vectors consisting of local descriptors, computed around interest points (like corners), able to recognize multi-object categories in different settings."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7549619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc3098cff5469c55c3e81dc127563afe6dbadf22",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative learning is challenging when examples are sets of features, and the sets vary in cardinality and lack any sort of meaningful ordering. Kernel-based classification methods can learn complex decision boundaries, but a kernel over unordered set inputs must somehow solve for correspondences \u2013 generally a computationally expensive task that becomes impractical for large set sizes. We present a new fast kernel function which maps unordered feature sets to multi-resolution histograms and computes a weighted histogram intersection in this space. This \u201cpyramid match\u201d computation is linear in the number of features, and it implicitly finds correspondences based on the finest resolution histogram cell where a matched pair first appears. Since the kernel does not penalize the presence of extra features, it is robust to clutter. We show the kernel function is positive-definite, making it valid for use in learning algorithms whose optimal solutions are guaranteed only for Mercer kernels. We demonstrate our algorithm on object recognition tasks and show it to be accurate and dramatically faster than current approaches."
            },
            "slug": "Pyramid-Match-Kernels:-Discriminative-with-Sets-of-Grauman-Darrell",
            "title": {
                "fragments": [],
                "text": "Pyramid Match Kernels: Discriminative Classification with Sets of Image Features (version 2)"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new fast kernel function is presented which maps unordered feature sets to multi-resolution histograms and computes a weighted histogram intersection in this space and is shown to be positive-definite, making it valid for use in learning algorithms whose optimal solutions are guaranteed only for Mercer kernels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3188179"
                        ],
                        "name": "A. Opelt",
                        "slug": "A.-Opelt",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Opelt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Opelt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40446025"
                        ],
                        "name": "M. Fussenegger",
                        "slug": "M.-Fussenegger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fussenegger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fussenegger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718587"
                        ],
                        "name": "A. Pinz",
                        "slug": "A.-Pinz",
                        "structuredName": {
                            "firstName": "Axel",
                            "lastName": "Pinz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pinz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 158
                            }
                        ],
                        "text": "\u2026satisfying way of representing many real-world objects, learning and inference problems for spatial relations remain extremely complex and computationally intensive, especially in a weakly supervised setting where the location of the object in a training image has not been marked by hand."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16562909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c91808994a250d7be332400a534a9291ca3b60e",
            "isKey": false,
            "numCitedBy": 333,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe the first stage of a new learning system for object detection and recognition. For our system we propose Boosting (5) as the underlying learning technique. This allows the use of very diverse sets of visual features in the learning process within a com- mon framework: Boosting \u2014 together with a weak hypotheses finder \u2014 may choose very inhomogeneous features as most relevant for combina- tion into a final hypothesis. As another advantage the weak hypotheses finder may search the weak hypotheses space without explicit calculation of all available hypotheses, reducing computation time. This contrasts the related work of Agarwal and Roth (1) where Winnow was used as learning algorithm and all weak hypotheses were calculated explicitly. In our first empirical evaluation we use four types of local descriptors: two basic ones consisting of a set of grayvalues and intensity moments and two high level descriptors: moment invariants (8) and SIFTs (12). The descriptors are calculated from local patches detected by an inter- est point operator. The weak hypotheses finder selects one of the local patches and one type of local descriptor and efficiently searches for the most discriminative similarity threshold. This differs from other work on Boosting for object recognition where simple rectangular hypotheses (22) or complex classifiers (20) have been used. In relatively simple images, where the objects are prominent, our approach yields results comparable to the state-of-the-art (3). But we also obtain very good results on more complex images, where the objects are located in arbitrary positions, poses, and scales in the images. These results indicate that our flexible approach, which also allows the inclusion of features from segmented re- gions and even spatial relationships, leads us a significant step towards generic object recognition."
            },
            "slug": "Weak-Hypotheses-and-Boosting-for-Generic-Object-and-Opelt-Fussenegger",
            "title": {
                "fragments": [],
                "text": "Weak Hypotheses and Boosting for Generic Object Detection and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The first stage of a new learning system for object detection and recognition using Boosting as the underlying learning technique and the inclusion of features from segmented re- gions and even spatial relationships leads us a significant step towards generic object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another approach is to design novel kernels that can yield high discriminative power despite the noise and irrelevant information that may be present in local feature sets [32,  18 , 50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "At the same time, Support Vector Machine (SVM) classiers [46] have shown their promise for visual classication tasks (see [43] for an early example), and the development of specialized kernels suitable for use with local features has emerged as a fruitful line of research [5, 12,  18 , 32, 40, 50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our approach outperforms Grauman et al. [ 18 ] for the same setup."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our own approach is related to that of Grauman and Darrell [ 18 ], who have developed a kernel that approximates the optimal partial matching between two feature sets."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13036203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "625bce34ec80d29242340400d916e799d2975430",
            "isKey": true,
            "numCitedBy": 1593,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative learning is challenging when examples are sets of features, and the sets vary in cardinality and lack any sort of meaningful ordering. Kernel-based classification methods can learn complex decision boundaries, but a kernel over unordered set inputs must somehow solve for correspondences epsivnerally a computationally expensive task that becomes impractical for large set sizes. We present a new fast kernel function which maps unordered feature sets to multi-resolution histograms and computes a weighted histogram intersection in this space. This \"pyramid match\" computation is linear in the number of features, and it implicitly finds correspondences based on the finest resolution histogram cell where a matched pair first appears. Since the kernel does not penalize the presence of extra features, it is robust to clutter. We show the kernel function is positive-definite, making it valid for use in learning algorithms whose optimal solutions are guaranteed only for Mercer kernels. We demonstrate our algorithm on object recognition tasks and show it to be accurate and dramatically faster than current approaches"
            },
            "slug": "The-pyramid-match-kernel:-discriminative-with-sets-Grauman-Darrell",
            "title": {
                "fragments": [],
                "text": "The pyramid match kernel: discriminative classification with sets of image features"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new fast kernel function is presented which maps unordered feature sets to multi-resolution histograms and computes a weighted histogram intersection in this space and is shown to be positive-definite, making it valid for use in learning algorithms whose optimal solutions are guaranteed only for Mercer kernels."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 241
                            }
                        ],
                        "text": "To achieve rotation invariance, we can either use rotationally invariant descriptors\u2014for example, SPIN and RIFT [27], as presented in the following section\u2014or rotate the circular regions in the direction of the dominant gradient orientation [31, 37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "The SIFT descriptor [31] has been shown to outperform a set of existing descriptors [35], while SPIN and RIFT, introduced by [27], have achieved good performance in the context of texture classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "For SIFT descriptors the norm of each descriptor is scaled to one [31]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 221242327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c04f169203f9e55056a6f7f956695babe622a38",
            "isKey": false,
            "numCitedBy": 12997,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene and can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "For example, the recent successes of the novel feature extraction schemes of [24, 10] suggest that increasing the density and redundancy of local feature sets may be beneficial for recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11117513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d32093cd04d6beffb6d757f58b5ac950543ff7d",
            "isKey": false,
            "numCitedBy": 896,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual codebook based quantization of robust appearance descriptors extracted from local image patches is an effective means of capturing image statistics for texture analysis and scene classification. Codebooks are usually constructed by using a method such as k-means to cluster the descriptor vectors of patches sampled either densely ('textons') or sparsely ('bags of features' based on key-points or salience measures) from a set of training images. This works well for texture analysis in homogeneous images, but the images that arise in natural object recognition tasks have far less uniform statistics. We show that for dense sampling, k-means over-adapts to this, clustering centres almost exclusively around the densest few regions in descriptor space and thus failing to code other informative regions. This gives suboptimal codes that are no better than using randomly selected centres. We describe a scalable acceptance-radius based clusterer that generates better codebooks and study its performance on several image classification tasks. We also show that dense representations outperform equivalent keypoint based ones on these tasks and that SVM or mutual information based feature selection starting from a dense codebook further improves the performance."
            },
            "slug": "Creating-efficient-codebooks-for-visual-recognition-Jurie-Triggs",
            "title": {
                "fragments": [],
                "text": "Creating efficient codebooks for visual recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that dense representations outperform equivalent keypoint based ones on these tasks and that SVM or mutual information based feature selection starting from a dense codebook further improves the performance."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 93
                            }
                        ],
                        "text": "To incorporate EMD or \u03c7(2) distance into the SVM framework, we use extended Gaussian kernels [6, 22]: K(Si, Sj) = exp ( \u2212 1 A D(Si, Sj) ) , (2) where D(Si, Sj) is EMD (resp."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "In addition, it must be noted that even non-Mercer kernels often work well in real applications [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 23544307,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d09deeb2eb6b1175d13817284d967189a83dbdde",
            "isKey": false,
            "numCitedBy": 1463,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that support vector machines (SVM's) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x, y) = e(-rho)Sigma(i)/xia-yia/b with a < or = 1 and b < or = 2 are evaluated on the classification of images extracted from the Corel stock photo collection and shown to far outperform traditional polynomial or Gaussian radial basis function (RBF) kernels. Moreover, we observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels."
            },
            "slug": "Support-vector-machines-for-histogram-based-image-Chapelle-Haffner",
            "title": {
                "fragments": [],
                "text": "Support vector machines for histogram-based image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2990188"
                        ],
                        "name": "J. Willamowski",
                        "slug": "J.-Willamowski",
                        "structuredName": {
                            "firstName": "Jutta",
                            "lastName": "Willamowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Willamowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3168148"
                        ],
                        "name": "Dami\u00e1n Arregui",
                        "slug": "Dami\u00e1n-Arregui",
                        "structuredName": {
                            "firstName": "Dami\u00e1n",
                            "lastName": "Arregui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dami\u00e1n Arregui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69931662"
                        ],
                        "name": "Gabriella Csurka",
                        "slug": "Gabriella-Csurka",
                        "structuredName": {
                            "firstName": "Gabriella",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriella Csurka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3344005"
                        ],
                        "name": "C. Dance",
                        "slug": "C.-Dance",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Dance",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dance"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2034793"
                        ],
                        "name": "Lixin Fan",
                        "slug": "Lixin-Fan",
                        "structuredName": {
                            "firstName": "Lixin",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lixin Fan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10582358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee3391a1c0288ccf150b7d4c883918cfedb655bc",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naive Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for classifying nine semantic visual categories and comment on results obtained by Fergus et al using a different method on the same data set. We obtain excellent results as well for multi class categorization as for object detection. A thorough evaluation clearly demonstrates that our method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information."
            },
            "slug": "Categorizing-Nine-Visual-Classes-using-Local-Willamowski-Arregui",
            "title": {
                "fragments": [],
                "text": "Categorizing Nine Visual Classes using Local Appearance Descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A thorough evaluation clearly demonstrates that the bag of keypoints method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "Many different descriptors have been presented in the literature (see [35] for an overview)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "The SIFT descriptor [31] has been shown to outperform a set of existing descriptors [35], while SPIN and RIFT, introduced by [27], have achieved good performance in the context of texture classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2572455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69401bfdafab7cde00bb8e5b2f6c28e9d72d8cfb",
            "isKey": false,
            "numCitedBy": 3665,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "slug": "A-performance-evaluation-of-local-descriptors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "A performance evaluation of local descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is observed that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best and Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797063"
                        ],
                        "name": "S. Agarwal",
                        "slug": "S.-Agarwal",
                        "structuredName": {
                            "firstName": "Shivani",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "1The car (side) images are from the UIUC car dataset [2], http://l2r."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 114
                            }
                        ],
                        "text": "Initially, part-based methods relied on simple Harris interest points, which only provided translation invariance [2, 51]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 262977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d081b80b1850df9b1e382f97a7a244890d6485e",
            "isKey": false,
            "numCitedBy": 638,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects. A vocabulary of information-rich object parts is automatically constructed from a set of sample images of the object class of interest. Images are then represented using parts from this vocabulary, along with spatial relations observed among them. Based on this representation, a feature-efficient learning algorithm is used to learn to detect instances of the object class. The framework developed can be applied to any object with distinguishable parts in a relatively fixed spatial configuration. We report experiments on images of side views of cars. Our experiments show that the method achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation.In addition, we discuss and offer solutions to several methodological issues that are significant for the research community to be able to evaluate object detection approaches."
            },
            "slug": "Learning-a-Sparse-Representation-for-Object-Agarwal-Roth",
            "title": {
                "fragments": [],
                "text": "Learning a Sparse Representation for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects, that achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793750"
                        ],
                        "name": "C. Wallraven",
                        "slug": "C.-Wallraven",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wallraven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wallraven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144813423"
                        ],
                        "name": "Arnulf B. A. Graf",
                        "slug": "Arnulf-B.-A.-Graf",
                        "structuredName": {
                            "firstName": "Arnulf",
                            "lastName": "Graf",
                            "middleNames": [
                                "B.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnulf B. A. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4573035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c393b31ca71e8c4dd7c8c5a11653b18447c90466",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in computer vision have shown that local features can provide efficient representations suitable for robust object recognition. Support vector machines have been established as powerful learning algorithms with good generalization capabilities. We combine these two approaches and propose a general kernel method for recognition with local features. We show that the proposed kernel satisfies the Mercer condition and that it is, suitable for many established local feature frameworks. Large-scale recognition results are presented on three different databases, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features. In addition, experiments on noisy and occluded images show that local feature representations significantly outperform global approaches."
            },
            "slug": "Recognition-with-local-features:-the-kernel-recipe-Wallraven-Caputo",
            "title": {
                "fragments": [],
                "text": "Recognition with local features: the kernel recipe"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Large-scale recognition results are presented, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features and that local feature representations significantly outperform global approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672681"
                        ],
                        "name": "G. O. Cula",
                        "slug": "G.-O.-Cula",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Cula",
                            "middleNames": [
                                "Oana"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. O. Cula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 270
                            }
                        ],
                        "text": "\u2026repre\u0301sentation d\u2019image par une distribution (signature, histogramme) de descripteurs calcule\u0301s en des points d\u2019inte\u0301re\u0302t, et d\u2019une classification par Machine a\u0300 Vecteur Support dont les noyaux utilisent des mesures adapte\u0301es a\u0300 la comparaison de distributions (Earth Mover Distance, chi-square)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7356365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b45dc2f11ed201f192d9bec153fcca1ca95e460",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A bidirectional texture function (BTF) describes image texture as it varies with viewing and illumination direction. Many real world surfaces such as skin, fur, gravel, etc. exhibit fine-scale geometric surface detail. Accordingly, variations in appearance with viewing and illumination direction may be quite complex due to local foreshortening, masking and shadowing. Representations of surface texture that support robust recognition must account for these effects. We construct a representation which captures the underlying statistical distribution of features in the image texture as well as the variations in this distribution with viewing and illumination direction. The representation combines clustering to learn characteristic image features and principle components analysis to reduce the space of feature histograms. This representation is based on a core image set as determined by a quantitative evaluation of importance of individual images in the overall representation. The result is a compact representation and a recognition method where a single novel image of unknown viewing and illumination direction can be classified efficiently. The CUReT (Columbia-Utrecht reflectance and texture) database is used as a test set for evaluation of these methods."
            },
            "slug": "Compact-representation-of-bidirectional-texture-Cula-Dana",
            "title": {
                "fragments": [],
                "text": "Compact representation of bidirectional texture functions"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A representation is constructed which captures the underlying statistical distribution of features in the image texture as well as the variations in this distribution with viewing and illumination direction and is a compact representation and a recognition method where a single novel image of unknown viewing and illuminated direction can be classified efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Mots-cle\u0301s : reconnaissance de textures, reconnaissance d\u2019objets, de\u0301tecteurs de points d\u2019inte\u0301re\u0302t invariants aux transformations affines et a\u0300 l\u2019e\u0301chelle, machines a\u0300 vecteurs support, me\u0301thodes par noyaux"
                    },
                    "intents": []
                }
            ],
            "corpusId": 206763997,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "72bf4b2ce534b95bc24118491dbc4f8d550734a2",
            "isKey": false,
            "numCitedBy": 1158,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine Harris and Laplacian regions is found in the image. Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern. This pattern is captured in an affine-invariant fashion via a process of shape normalization followed by the computation of two novel descriptors, the spin image and the RIFT descriptor. When affine invariance is not required, the original elliptical shape serves as an additional discriminative feature for texture recognition. The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
            },
            "slug": "A-sparse-texture-representation-using-local-affine-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "A sparse texture representation using local affine regions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The proposed texture representation is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745185"
                        ],
                        "name": "Feng Jing",
                        "slug": "Feng-Jing",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Jing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49846744"
                        ],
                        "name": "Bo Zhang",
                        "slug": "Bo-Zhang",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 93
                            }
                        ],
                        "text": "To incorporate EMD or \u03c7(2) distance into the SVM framework, we use extended Gaussian kernels [6, 22]: K(Si, Sj) = exp ( \u2212 1 A D(Si, Sj) ) , (2) where D(Si, Sj) is EMD (resp."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8267805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03a745fc9052ba440d15ef753bd145a0695a5d09",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, the application of support vector machines (SVM) in relevance feedback for region-based image retrieval is investigated. Both the one class SVM as a class distribution estimator and two classes SVM as a classifier are taken into account. For the latter, two representative display strategies are studied. Since the common kernels often rely on inner product or L/sub p/ norm in the input space, they are infeasible in the region-based image retrieval systems that use variable-length representations. To resolve the issue, a new kind of kernel that is a generalization of Gaussian kernel is proposed. Experimental results on a database of 10,000 general-purpose images demonstrate the effectiveness and robustness of the proposed approach."
            },
            "slug": "Support-vector-machines-for-region-based-image-Jing-Li",
            "title": {
                "fragments": [],
                "text": "Support vector machines for region-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new kind of kernel that is a generalization of Gaussian kernel is proposed to resolve the issue of infeasible kernels in region-based image retrieval systems that use variable-length representations."
            },
            "venue": {
                "fragments": [],
                "text": "2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794837"
                        ],
                        "name": "Siwei Lyu",
                        "slug": "Siwei-Lyu",
                        "structuredName": {
                            "firstName": "Siwei",
                            "lastName": "Lyu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siwei Lyu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2262078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cba5ad0b755434eda25c0147633a843e5b9cbd24",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A new class of kernels for object recognition based on local image feature representations are introduced in this paper. These kernels satisfy the Mercer condition and incorporate multiple types of local features and semilocal constraints between them. Experimental results of SVM classifiers coupled with the proposed kernels are reported on recognition tasks with the COIL-100 database and compared with existing methods. The proposed kernels achieved competitive performance and were robust to changes in object configurations and image degradations."
            },
            "slug": "Mercer-kernels-for-object-recognition-with-local-Lyu",
            "title": {
                "fragments": [],
                "text": "Mercer kernels for object recognition with local features"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A new class of kernels for object recognition based on local image feature representations that satisfy the Mercer condition and incorporate multiple types of local features and semilocal constraints between them are introduced."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206769491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a737c107623bcffefa0bac20f1b64677f6a1255a",
            "isKey": false,
            "numCitedBy": 1142,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We seek to discover the object categories depicted in a set of unlabelled images. We achieve this using a model developed in the statistical text literature: probabilistic latent semantic analysis (pLSA). In text analysis, this is used to discover topics in a corpus using the bag-of-words document representation. Here we treat object categories as topics, so that an image containing instances of several categories is modeled as a mixture of topics. The model is applied to images by using a visual analogue of a word, formed by vector quantizing SIFT-like region descriptors. The topic discovery approach successfully translates to the visual domain: for a small set of objects, we show that both the object categories and their approximate spatial layout are found without supervision. Performance of this unsupervised method is compared to the supervised approach of Fergus et al. (2003) on a set of unseen images containing only one object per image. We also extend the bag-of-words vocabulary to include 'doublets' which encode spatially local co-occurring regions. It is demonstrated that this extended vocabulary gives a cleaner image segmentation. Finally, the classification and segmentation methods are applied to a set of images containing multiple objects per image. These results demonstrate that we can successfully build object class models from an unsupervised analysis of images."
            },
            "slug": "Discovering-objects-and-their-location-in-images-Sivic-Russell",
            "title": {
                "fragments": [],
                "text": "Discovering objects and their location in images"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work treats object categories as topics, so that an image containing instances of several categories is modeled as a mixture of topics, and develops a model developed in the statistical text literature: probabilistic latent semantic analysis (pLSA)."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716824"
                        ],
                        "name": "A. Verri",
                        "slug": "A.-Verri",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Verri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Verri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1375403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fda96d554f4e5a21e35bf33b9720141da47664b",
            "isKey": false,
            "numCitedBy": 865,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines (SVMs) have been recently proposed as a new technique for pattern recognition. Intuitively, given a set of points which belong to either of two classes, a linear SVM finds the hyperplane leaving the largest possible fraction of points of the same class on the same side, while maximizing the distance of either class from the hyperplane. The hyperplane is determined by a subset of the points of the two classes, named support vectors, and has a number of interesting theoretical properties. In this paper, we use linear SVMs for 3D object recognition. We illustrate the potential of SVMs on a database of 7200 images of 100 different objects. The proposed system does not require feature extraction and performs recognition on images regarded as points of a space of high dimension without estimating pose. The excellent recognition rates achieved in all the performed experiments indicate that SVMs are well-suited for aspect-based recognition."
            },
            "slug": "Support-Vector-Machines-for-3D-Object-Recognition-Pontil-Verri",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines for 3D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed system does not require feature extraction and performs recognition on images regarded as points of a space of high dimension without estimating pose, indicating that SVMs are well-suited for aspect-based recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 114
                            }
                        ],
                        "text": "Initially, part-based methods relied on simple Harris interest points, which only provided translation invariance [2, 51]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1061324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "472ff211d18aa2ca2b65b69d86499430ad287499",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method to learn heterogeneous models of object classes for visual recognition. The training images contain a preponderance of clutter and learning is unsupervised. Our models represent objects as probabilistic constellations of rigid parts (features). The variability within a class is represented by a join probability density function on the shape of the constellation and the appearance of the parts. Our method automatically identifies distinctive features in the training set. The set of model parameters is then learned using expectation maximization. When trained on different, unlabeled and unsegmented views of a class of objects, each component of the mixture model can adapt to represent a subset of the views. Similarly, different component models can also \"specialize\" on sub-classes of an object class. Experiments on images of human heads, leaves from different species of trees, and motor-cars demonstrate that the method works well over a wide variety of objects."
            },
            "slug": "Towards-automatic-discovery-of-object-categories-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Towards automatic discovery of object categories"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A method to learn heterogeneous models of object classes for visual recognition that automatically identifies distinctive features in the training set and learns the set of model parameters using expectation maximization."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3214795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7417d7dcf6152736612e3f04ccc72731dc8d9505",
            "isKey": false,
            "numCitedBy": 418,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new approach to material classification under unknown viewpoint and illumination. Our texture model is based on the statistical distribution of clustered filter responses. However, unlike previous 3D texton representations, we use rotationally invariant filters and cluster in an extremely low dimensional space. Having built a texton dictionary, we present a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed. We argue that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance and demonstrate this claim with results on all 61 textures in the Columbia-Utrecht database. We then proceed to show how texture models can be further extended by compensating for viewpoint changes using weak isotropy.The new clustering and classification methods are compared to those of Leung and Malik (ICCV 1999), Schmid (CVPR 2001) and Cula and Dana (CVPR 2001), which are the current state-of-the-art approaches."
            },
            "slug": "Classifying-Images-of-Materials:-Achieving-and-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Classifying Images of Materials: Achieving Viewpoint and Illumination Independence"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed, and argues that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 293
                            }
                        ],
                        "text": "\u2026repre\u0301sentation d\u2019image par une distribution (signature, histogramme) de descripteurs calcule\u0301s en des points d\u2019inte\u0301re\u0302t, et d\u2019une classification par Machine a\u0300 Vecteur Support dont les noyaux utilisent des mesures adapte\u0301es a\u0300 la comparaison de distributions (Earth Mover Distance, chi-square)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 456211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70284b4fe852f472d4576c30f97a6fddbfef2aee",
            "isKey": false,
            "numCitedBy": 532,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We question the role that large scale filter banks have traditionally played in texture classification. It is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods (starting from as small as 3 /spl times/ 3 pixels square), and that this outperforms classification using filter banks with large support. We develop a novel texton based representation, which is suited to modeling this joint neighborhood distribution for MRFs. The representation is learnt from training images, and then used to classify novel images (with unknown viewpoint and lighting) into texture classes. The power of the method is demonstrated by classifying over 2800 images of all 61 textures present in the Columbia-Utrecht database. The classification performance surpasses that of recent state-of-the-art filter bank based classifiers such as Leung & Malik, Cula & Dana, and Varma & Zisserman."
            },
            "slug": "Texture-classification:-are-filter-banks-necessary-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Texture classification: are filter banks necessary?"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel texton based representation is developed, which is suited to modeling this joint neighborhood distribution for MRFs, and it is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 154
                            }
                        ],
                        "text": "2 Object recognition The earliest work on appearance-based object recognition has mainly utilized global descriptions such as color or texture histograms [39, 43, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2551159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd232cf2ab28cc0ba06942875f14206f04ebbae0",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 109,
            "paperAbstract": {
                "fragments": [],
                "text": "The appearance of an object is composed of local structure. This local structure can be described and characterized by a vector of local features measured by local operators such as Gaussian derivatives or Gabor filters. This article presents a technique where appearances of objects are represented by the joint statistics of such local neighborhood operators. As such, this represents a new class of appearance based techniques for computer vision. Based on joint statistics, the paper develops techniques for the identification of multiple objects at arbitrary positions and orientations in a cluttered scene. Experiments show that these techniques can identify over 100 objects in the presence of major occlusions. Most remarkably, the techniques have low complexity and therefore run in real-time."
            },
            "slug": "Recognition-without-Correspondence-using-Receptive-Schiele-Crowley",
            "title": {
                "fragments": [],
                "text": "Recognition without Correspondence using Multidimensional Receptive Field Histograms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article presents a technique where appearances of objects are represented by the joint statistics of such local neighborhood operators, which represents a new class of appearance based techniques for computer vision."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "ours: Berg [3] Grauman [18] (HS+LS)(SIFT+SPIN) overall rate 53."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6055435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c7fc38debaf3589e712973642246bd54fe63b3",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points. This algorithm sets up correspondence as an integer quadratic programming problem, where the cost function has terms based on similarity of corresponding geometric blur point descriptors as well as the geometric distortion between pairs of corresponding feature points. The algorithm handles outliers, and thus enables matching of exemplars to query images in the presence of occlusion and clutter. Given the correspondences, we estimate an aligning transform, typically a regularized thin plate spline, resulting in a dense correspondence between the two shapes. Object recognition is then handled in a nearest neighbor framework where the distance between exemplar and query is the matching cost between corresponding points. We show results on two datasets. One is the Caltech 101 dataset (Fei-Fei, Fergus and Perona), an extremely challenging dataset with large intraclass variation. Our approach yields a 48% correct classification rate, compared to Fei-Fei et al 's 16%. We also show results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "slug": "Shape-matching-and-object-recognition-using-low-Berg-Berg",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using low distortion correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work approaches recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points, and shows results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829696"
                        ],
                        "name": "Y. Rubner",
                        "slug": "Y.-Rubner",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Note that EMD is a cross-bin dissimilarity measure and can handle variable-length representation of distributions, i.e., m and n do not have to be the same."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "We do not have a proof of the positive definiteness for the EMD-kernel; however, in our experiments, this kernel has always yielded positive definite Gram matrices."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "In contrast with some alternative kernels, such as the ones based on the Kullback-Leibler divergence [38], the \u03c72 and EMD kernels are parameter-free, and they do not require the estimation of distribution parameters using a time-consuming EM/MCMC algorithm as in [38]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "The resulting kernel is the EMD kernel (or \u03c72 kernel)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "To incorporate EMD or \u03c72 distance into the SVM framework, we use extended Gaussian kernels [6, 22]:\nK(Si, Sj) = exp ( \u2212 1 A D(Si, Sj) ) , (2)\nwhere D(Si, Sj) is EMD (resp. \u03c7 2 distance) if Si and Sj are image signatures (resp. vocabulary-histograms)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Earth Mover\u2019s Distance (EMD) [44] has shown to be very suitable for measuring the similarity between image signatures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The EMD between two signatures S1 = {(p1, u1), . . . , (pm, um)} and S2 = {(q1, w1), . . . , (qn, wn)} is defined as follows:\nD(S1, S2) =\n\u2211m i=1 \u2211n j=1 fij d(pi, qj)\u2211m\ni=1 \u2211n j=1 fij\nwhere fij is a flow value that can be determined by solving a linear programming problem, and d(pi, qj) is the ground distance between cluster centers pi and qj ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "The parameter A of the EMD (resp. \u03c72) kernel is the mean value of the EMD (resp. \u03c72) distances between all training images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "Specifically, we use a kernel based on the Earth Mover\u2019s Distance [44], which solves the partial matching problem exactly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14106275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d13a04844e4a781e5180987118f732d93aa9f398",
            "isKey": true,
            "numCitedBy": 4139,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the properties of a metric between two distributions, the Earth Mover's Distance (EMD), for content-based image retrieval. The EMD is based on the minimal cost that must be paid to transform one distribution into the other, in a precise sense, and was first proposed for certain vision problems by Peleg, Werman, and Rom. For image retrieval, we combine this idea with a representation scheme for distributions that is based on vector quantization. This combination leads to an image comparison framework that often accounts for perceptual similarity better than other previously proposed methods. The EMD is based on a solution to the transportation problem from linear optimization, for which efficient algorithms are available, and also allows naturally for partial matching. It is more robust than histogram matching techniques, in that it can operate on variable-length representations of the distributions that avoid quantization and other binning problems typical of histograms. When used to compare distributions with the same overall mass, the EMD is a true metric. In this paper we focus on applications to color and texture, and we compare the retrieval performance of the EMD with that of other distances."
            },
            "slug": "The-Earth-Mover's-Distance-as-a-Metric-for-Image-Rubner-Tomasi",
            "title": {
                "fragments": [],
                "text": "The Earth Mover's Distance as a Metric for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper investigates the properties of a metric between two distributions, the Earth Mover's Distance (EMD), for content-based image retrieval, and compares the retrieval performance of the EMD with that of other distances."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879646"
                        ],
                        "name": "Thomas Deselaers",
                        "slug": "Thomas-Deselaers",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Deselaers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Deselaers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51027911"
                        ],
                        "name": "Daniel Keysers",
                        "slug": "Daniel-Keysers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keysers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Keysers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "For example, the recent successes of the novel feature extraction schemes of [24, 10] suggest that increasing the density and redundancy of local feature sets may be beneficial for recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "test set 1 test set 2 HS LS HS+LS Larlus [25] HS LS HS+LS Deselaers [10] bikes 87."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1718345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4007ea25ce06841055b690f05d3bd9070036ac2",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for automatically learning discriminative image patches for the recognition of given object classes. The approach applies discriminative training of log-linear models to image patch histograms. We show that it works well on three tasks and performs significantly better than other methods using the same features. For example, the method decides that patches containing an eye are most important for distinguishing face from background images. The recognition performance is very competitive with error rates presented in other publications. In particular, a new best error rate for the Caltech motorbikes data of 1.5% is achieved."
            },
            "slug": "Discriminative-training-for-object-recognition-Deselaers-Keysers",
            "title": {
                "fragments": [],
                "text": "Discriminative training for object recognition using image patches"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A method for automatically learning discriminative image patches for the recognition of given object classes is presented and decides that patches containing an eye are most important for distinguishing face from background images."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059148801"
                        ],
                        "name": "J. Eichhorn",
                        "slug": "J.-Eichhorn",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Eichhorn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eichhorn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15106596,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b053b5cff065b1ae74dca7dfcc6c1ea634fb9d86",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose to combine an efficient image representation based on local descriptors with a Support Vector Machine classifier in order to perform object categorization. For this purpose, we apply kernels defined on sets of vectors. After testing different combinations of kernel / local descriptors, we have been able to identify a very performant one."
            },
            "slug": "Object-categorization-with-SVM:-kernels-for-local-Eichhorn-Chapelle",
            "title": {
                "fragments": [],
                "text": "Object categorization with SVM: kernels for local features"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An efficient image representation based on local descriptors based on kernels defined on sets of vectors with a Support Vector Machine classifier in order to perform object categorization is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 296
                            }
                        ],
                        "text": "Cet article e\u0301value la pertinence d\u2019une repre\u0301sentation d\u2019image par une distribution (signature, histogramme) de descripteurs calcule\u0301s en des points d\u2019inte\u0301re\u0302t, et d\u2019une classification par Machine a\u0300 Vecteur Support dont les noyaux utilisent des mesures adapte\u0301es a\u0300 la comparaison de distributions (Earth Mover Distance, chi-square)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 278
                            }
                        ],
                        "text": "\u2026repre\u0301sentation d\u2019image par une distribution (signature, histogramme) de descripteurs calcule\u0301s en des points d\u2019inte\u0301re\u0302t, et d\u2019une classification par Machine a\u0300 Vecteur Support dont les noyaux utilisent des mesures adapte\u0301es a\u0300 la comparaison de distributions (Earth Mover Distance, chi-square)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2166325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "191c3c15cc4c957ee3437fc27ba3178bae292e7f",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions. Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions."
            },
            "slug": "Recognizing-surfaces-using-three-dimensional-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Recognizing surfaces using three-dimensional textons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A unified model to address both the reflectance and surface normal aspects of natural texture and to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties is provided."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120763852"
                        ],
                        "name": "F. Cohen",
                        "slug": "F.-Cohen",
                        "structuredName": {
                            "firstName": "Fredric",
                            "lastName": "Cohen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47774603"
                        ],
                        "name": "Z. Fan",
                        "slug": "Z.-Fan",
                        "structuredName": {
                            "firstName": "Zhigang",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107308659"
                        ],
                        "name": "M. A. Patel",
                        "slug": "M.-A.-Patel",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Patel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Patel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 112
                            }
                        ],
                        "text": "Early research in this domain has concentrated on global 2D image transformations, such as rotation and scaling [7, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206418967,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "92a552175e992afd0b9fe943a02ec5580b4aa6df",
            "isKey": false,
            "numCitedBy": 335,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Consideration is given to the problem of classifying a test textured image that is obtained from one of C possible parent texture classes, after possibly applying unknown rotation and scale changes to the parent texture. The training texture images (parent classes) are modeled by Gaussian Markov random fields (GMRFs). To classify a rotated and scaled test texture, the rotation and scale changes are incorporated in the texture model through an appropriate transformation of the power spectral density of the GMRF. For the rotated and scaled image, a bona fide likelihood function that shows the explicit dependence of the likelihood function on the GMRF parameters, as well as on the rotation and scale parameters, is derived. Although, in general, the scaled and/or rotated texture does not correspond to a finite-order GMRF, it is possible nonetheless to write down a likelihood function for the image data. The likelihood function of the discrete Fourier transform of the image data corresponds to that of a white nonstationary Gaussian random field, with the variance at each pixel (i,j) being a known function of the rotation, the scale, the GMRF model parameters, and (i,j). The variance is an explicit function of the appropriately sampled power spectral density of the GMRF. The estimation of the rotation and scale parameters is performed in the frequency domain by maximizing the likelihood function associated with the discrete Fourier transform of the image data. Cramer-Rao error bounds on the scale and rotation estimates are easily computed. A modified Bayes decision rule is used to classify a given test image into one of C possible texture classes. The classification power of the method is demonstrated through experimental results on natural textures from the Brodatz album. >"
            },
            "slug": "Classification-of-Rotated-and-Scaled-Textured-Using-Cohen-Fan",
            "title": {
                "fragments": [],
                "text": "Classification of Rotated and Scaled Textured Images Using Gaussian Markov Random Field Models"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A modified Bayes decision rule is used to classify a given test image into one of C possible texture classes and the classification power of the method is demonstrated through experimental results on natural textures from the Brodatz album."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47690405"
                        ],
                        "name": "P. Moreno",
                        "slug": "P.-Moreno",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Moreno",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Moreno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35541734"
                        ],
                        "name": "Purdy Ho",
                        "slug": "Purdy-Ho",
                        "structuredName": {
                            "firstName": "Purdy",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Purdy Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "In contrast with some alternative kernels, such as the ones based on the Kullback-Leibler divergence [38], the \u03c7(2) and EMD kernels are parameter-free, and they do not require the estimation of distribution parameters using a time-consuming EM/MCMC algorithm as in [38]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6831693,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f73f60fb07a979e53beac26c92eaaafb644a648",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the last years significant efforts have been made to develop kernels that can be applied to sequence data such as DNA, text, speech, video and images. The Fisher Kernel and similar variants have been suggested as good ways to combine an underlying generative model in the feature space and discriminant classifiers such as SVM's. In this paper we suggest an alternative procedure to the Fisher kernel for systematically finding kernel functions that naturally handle variable length sequence data in multimedia domains. In particular for domains such as speech and images we explore the use of kernel functions that take full advantage of well known probabilistic models such as Gaussian Mixtures and single full covariance Gaussian models. We derive a kernel distance based on the Kullback-Leibler (KL) divergence between generative models. In effect our approach combines the best of both generative and discriminative methods and replaces the standard SVM kernels. We perform experiments on speaker identification/verification and image classification tasks and show that these new kernels have the best performance in speaker verification and mostly outperform the Fisher kernel based SVM's and the generative classifiers in speaker identification and image classification."
            },
            "slug": "A-Kullback-Leibler-Divergence-Based-Kernel-for-SVM-Moreno-Ho",
            "title": {
                "fragments": [],
                "text": "A Kullback-Leibler Divergence Based Kernel for SVM Classification in Multimedia Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper suggests an alternative procedure to the Fisher kernel for systematically finding kernel functions that naturally handle variable length sequence data in multimedia domains and derives a kernel distance based on the Kullback-Leibler (KL) divergence between generative models."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The object category datasets are Xerox7 [52], Graz [41], CalTech6 [ 14 ], CalTech101 [13] and Pascal [1]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For object category classication, our approach outperforms existing methods on the Xerox7 [52], Graz [41], CalTech6 [ 14 ], CalTech101 [13] and the more dicult test set of the PASCAL challenge [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent achievements in both texture and object recognition have demonstrated that using local features, or descriptors computed at a sparse set of scale- or aneinvariant keypoints, tends to be an eectiv e approach [ 14 , 27, 47, 52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Subsequently, local features with higher degrees of invariance were used to obtain robustness against scaling changes [ 14 ] and ane deformations [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": true,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726178"
                        ],
                        "name": "X. Llad\u00f3",
                        "slug": "X.-Llad\u00f3",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Llad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Llad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153913367"
                        ],
                        "name": "J. Mart\u00ed",
                        "slug": "J.-Mart\u00ed",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Mart\u00ed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mart\u00ed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144877016"
                        ],
                        "name": "M. Petrou",
                        "slug": "M.-Petrou",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Petrou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Petrou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 296
                            }
                        ],
                        "text": "Cet article e\u0301value la pertinence d\u2019une repre\u0301sentation d\u2019image par une distribution (signature, histogramme) de descripteurs calcule\u0301s en des points d\u2019inte\u0301re\u0302t, et d\u2019une classification par Machine a\u0300 Vecteur Support dont les noyaux utilisent des mesures adapte\u0301es a\u0300 la comparaison de distributions (Earth Mover Distance, chi-square)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 283
                            }
                        ],
                        "text": "\u2026repre\u0301sentation d\u2019image par une distribution (signature, histogramme) de descripteurs calcule\u0301s en des points d\u2019inte\u0301re\u0302t, et d\u2019une classification par Machine a\u0300 Vecteur Support dont les noyaux utilisent des mesures adapte\u0301es a\u0300 la comparaison de distributions (Earth Mover Distance, chi-square)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145656,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "249e5937b44f9e1c6b8a61d27ca361c43ca23f1a",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Changes in the angle of illumination incident upon a 3D surface texture can significantly alter its appearance, implying variations in the image texture. These texture variations produce displacements of class members in the feature space, increasing the failure rates of texture classifiers. To avoid this problem, a model-based texture recognition system which classifies textures seen from different distances and under different illumination directions is presented in this paper. The system works on the basis of a surface model obtained by means of 4-source colour photometric stereo, used to generate 2D image textures under different illumination directions. The recognition system combines coocurrence matrices for feature extraction with a Nearest Neighbour classifier. Moreover, the recognition allows one to guess the approximate direction of the illumination used to capture the test image."
            },
            "slug": "Classification-of-textures-seen-from-different-and-Llad\u00f3-Mart\u00ed",
            "title": {
                "fragments": [],
                "text": "Classification of textures seen from different distances and under varying illumination direction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A model-based texture recognition system which classifies textures seen from different distances and under different illumination directions is presented, working on the basis of a surface model obtained by means of 4-source colour photometric stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46365515"
                        ],
                        "name": "Jiahua Wu",
                        "slug": "Jiahua-Wu",
                        "structuredName": {
                            "firstName": "Jiahua",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiahua Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712844"
                        ],
                        "name": "M. Chantler",
                        "slug": "M.-Chantler",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Chantler",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chantler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "Dans un premier temps nous e\u0301valuons la performance de notre approche avec diffe\u0301rentes combinaisons de de\u0301tecteurs de points d\u2019inte\u0301re\u0302t, de descripteurs, de noyaux et de classifieurs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10190315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d10d57b032aa3e57f45283454b7a5a50faa5a3f",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new texture classification scheme which is invariant to surface-rotation. Many texture classification approaches have been presented in the past that are image-rotation invariant. However, image rotation is not necessarily the same as surface rotation. We have therefore developed a classifier that uses invariants that are derived from surface properties rather than image properties. Previously we developed a scheme that used surface gradient (normal) fields estimated using photometric stereo. In this paper we augment these data with albedo information and also employ an additional feature set: the radial spectrum. We used 30 real textures to test the new classifier. A classification accuracy of 91% was achieved when albedo and gradient 1D polar and radial features were combined. The best performance was also achieved by using 2D albedo and gradient spectra. The classification accuracy is 99%."
            },
            "slug": "Combining-gradient-and-albedo-data-for-rotation-of-Wu-Chantler",
            "title": {
                "fragments": [],
                "text": "Combining gradient and albedo data for rotation invariant classification of 3D surface texture"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper presents a new texture classification scheme which is invariant to surface-rotation, and uses invariants that are derived from surface properties rather than image properties, and employs the radial spectrum."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260234"
                        ],
                        "name": "J. G\u00e5rding",
                        "slug": "J.-G\u00e5rding",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "G\u00e5rding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G\u00e5rding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 141
                            }
                        ],
                        "text": "Finally, we obtain affine-invariant versions of the Harris-Laplace and Laplacian detectors through the use of an affine adaptation procedure [16, 36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15548916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9e58a5b063d4252a15fd94c0613f83a4fdb780e",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of computing cues to the three-dimensional structure of surfaces in the world directly from the local structure of the brightness pattern of either a single monocular image or a binocular image pair.It is shown that starting from Gaussian derivatives of order up to two at a range of scales in scale-space, local estimates of (i) surface orientation from monocular texture foreshortening, (ii) surface orientation from monocular texture gradients, and (iii) surface orientation from the binocular disparity gradient can be computed without iteration or search, and by using essentially the same basic mechanism.The methodology is based on a multi-scale descriptor of image structure called the windowed second moment matrix, which is computed with adaptive selection of both scale levels and spatial positions. Notably, this descriptor comprises two scale parameters; a local scale parameter describing the amount of smoothing used in derivative computations, and an integration scale parameter determining over how large a region in space the statistics of regional descriptors is accumulated.Experimental results for both synthetic and natural images are presented, and the relation with models of biological vision is briefly discussed."
            },
            "slug": "Direct-computation-of-shape-cues-using-spatial-G\u00e5rding-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Direct computation of shape cues using scale-adapted spatial derivative operators"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of computing cues to the three-dimensional structure of surfaces in the world directly from the local structure of the brightness pattern of either a single monocular image or a binocular image pair using a multi-scale descriptor of image structure called the windowed second moment matrix."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2646632"
                        ],
                        "name": "M. Nilsback",
                        "slug": "M.-Nilsback",
                        "structuredName": {
                            "firstName": "Maria-Elena",
                            "lastName": "Nilsback",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nilsback"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 174299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c58147952c3e2b775ed1ba5dfa2c4bc6f01566a",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition systems aiming to work in real world settings should use multiple cues in order to achieve robustness. We present a new cue integration scheme, which extends the idea of cue accumulation to discriminative classifiers. We derive and test the scheme for support vector machines (SVMs), but we also show that it is easily extendible to any large margin classifier. In the case of one-class SVMs the scheme can be interpreted as a new class of Mercer kernels for multiple cues. Experimental comparison with a probabilistic accumulation scheme is favorable to our method. Comparison with voting scheme shows that our method may suffer as the number of object classes increases. Based on these results, we propose a recognition algorithm consisting of a decision tree where decisions at each node are taken using our accumulation scheme. Results obtained using this new algorithm compare very favorably to accumulation (both probabilistic and discriminative) and voting scheme."
            },
            "slug": "Cue-integration-through-discriminative-accumulation-Nilsback-Caputo",
            "title": {
                "fragments": [],
                "text": "Cue integration through discriminative accumulation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new cue integration scheme is presented, which extends the idea of cue accumulation to discriminative classifiers and it is shown that it is easily extendible to any large margin classifier."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "We use the same Gabor filters as in [33], i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 238
                            }
                        ],
                        "text": "3 Texture classification In this section, we present a comparative evaluation of our approach with four state-ofthe-art texture classification methods: Lazebnik\u2019s method [27], VZ-joint [49], Hayman\u2019s method [19], and global Gabor filters [33]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Finally, Global Gabor filters [33] is a \u201ctraditional\u201d texture analysis method using global mean and standard deviation of the responses of Gabor filters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15171942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2989b07819dfd279222a3755d3b7862f1a1a7f53",
            "isKey": true,
            "numCitedBy": 4175,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Image content based retrieval is emerging as an important research area with application to digital libraries and multimedia databases. The focus of this paper is on the image processing aspects and in particular using texture information for browsing and retrieval of large image data. We propose the use of Gabor wavelet features for texture analysis and provide a comprehensive experimental evaluation. Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy. An application to browsing large air photos is illustrated."
            },
            "slug": "Texture-Features-for-Browsing-and-Retrieval-of-Data-Manjunath-Ma",
            "title": {
                "fragments": [],
                "text": "Texture Features for Browsing and Retrieval of Image Data"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 247
                            }
                        ],
                        "text": "1 Scale- and affine-invariant region detectors In this paper, we use two complementary local region detector types to extract salient image structures: The Harris-Laplace detector [37] responds to corner-like regions, while the Laplacian detector [29] extracts blob-like regions (Figure 1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 723210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02f474196fb9bd61fa3d418a7ba8ac500e8d422",
            "isKey": false,
            "numCitedBy": 2940,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure.Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation.In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments."
            },
            "slug": "Feature-Detection-with-Automatic-Scale-Selection-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation and how it can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8038506"
                        ],
                        "name": "B. Ginneken",
                        "slug": "B.-Ginneken",
                        "structuredName": {
                            "firstName": "Bram",
                            "lastName": "Ginneken",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ginneken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "For the CUReT texture database [9] we use the same subset of images as [48, 49]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 188
                            }
                        ],
                        "text": "Varma and Zisserman [48, 49] have further improved 2D texton-based representations, achieving very high levels of accuracy on the Columbia-Utrecht reflectance and texture (CUReT) database [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 179
                            }
                        ],
                        "text": "For texture classification, our approach outperforms existing methods on Brodatz [4], KTH-TIPS [19] and UIUCTex [27] datasets, and obtains comparable results on the CUReT dataset [9]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 142
                            }
                        ],
                        "text": "More recently, there has been a great deal of interest in recognizing images of textured surfaces subjected to lighting and viewpoint changes [8, 9, 28, 30, 48, 49, 53]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "The texture datasets are UIUCTex [27], KTH-TIPS [19], Brodatz [4], and CUReT [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 622815,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "16ba88cb3c3a0438bd9e5ace9096f9655ddc63df",
            "isKey": true,
            "numCitedBy": 1074,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we investigate the visual appearance of real-world surfaces and the dependence of appearance on imaging conditions. We present a BRDF (bidirectional reflectance distribution function) database with reflectance measurements for over 60 different samples, each observed with over 200 different combinations of viewing and source directions. We fit the BRDF measurements to two recent models to obtain a BRDF parameter database. These BRDF parameters can be directly used for both image analysis and image synthesis. Finally, we present a BTF (bidirectional texture function) database with image textures from over 60 different samples, each observed with over 200 different combinations of viewing and source directions. Each of these unique databases has important implications for a variety of vision algorithms and each is made publicly available."
            },
            "slug": "Reflectance-and-texture-of-real-world-surfaces-Dana-Ginneken",
            "title": {
                "fragments": [],
                "text": "Reflectance and texture of real-world surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The visual appearance of real-world surfaces and the dependence of appearance on imaging conditions is investigated and a BRDF (bidirectional reflectance distribution function) database with reflectance measurements for over 60 different samples, each observed with over 200 different combinations of viewing and source directions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "TOGS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "Note that the publicly available dataset contains two classes for face\u2014called face and faces easy\u2014and that the zebra category cited in [13] is"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "The CalTech101 dataset [13] contains 101 object categories with 40 to 800 images per category."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "For object category classification, our approach outperforms existing methods on the Xerox7 [52], Graz [41], CalTech6 [14], CalTech101 [13] and the more difficult test set of the PASCAL challenge [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "The object category datasets are Xerox7 [52], Graz [41], CalTech6 [14], CalTech101 [13] and Pascal [1]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2156851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aedb8df8f953429ec5a6df99fda5c5d71dbee4ff",
            "isKey": true,
            "numCitedBy": 2325,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Generative-Visual-Models-from-Few-Training-Fei-Fei-Fergus",
            "title": {
                "fragments": [],
                "text": "Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories"
            },
            "venue": {
                "fragments": [],
                "text": "2004 Conference on Computer Vision and Pattern Recognition Workshop"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "Subsequently, local features with higher degrees of invariance were used to obtain robustness against scaling changes [14] and affine deformations [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6253094,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "71c63a2c994e08212ab48a458d6efe6291786b82",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new approach for finding expressive and geometrically invariant parts for modeling 3D objects. The approach relies on identifying groups of local affine regions (image features having a characteristic appearance and elliptical shape) that remain approximately affinely rigid across a range of views of an object, and across multiple instances of the same object class. These groups, termed semi-local affine parts, are learned using correspondence search between pairs of unsegmented and cluttered input images, followed by validation against additional training images. The proposed approach is applied to the recognition of butterflies in natural imagery."
            },
            "slug": "Semi-Local-Affine-Parts-for-Object-Recognition-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Semi-Local Affine Parts for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper proposes a new approach for finding expressive and geometrically invariant parts for modeling 3D objects that remain approximately affinely rigid across a range of views of an object, and across multiple instances of the same object class."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141915"
                        ],
                        "name": "W. Niblack",
                        "slug": "W.-Niblack",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Niblack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niblack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50281905"
                        ],
                        "name": "R. Barber",
                        "slug": "R.-Barber",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Barber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712308"
                        ],
                        "name": "W. Equitz",
                        "slug": "W.-Equitz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Equitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Equitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123856769"
                        ],
                        "name": "E. Glasman",
                        "slug": "E.-Glasman",
                        "structuredName": {
                            "firstName": "Eduardo",
                            "lastName": "Glasman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Glasman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867341"
                        ],
                        "name": "D. Petkovic",
                        "slug": "D.-Petkovic",
                        "structuredName": {
                            "firstName": "Dragutin",
                            "lastName": "Petkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Petkovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70341848"
                        ],
                        "name": "P. Yanker",
                        "slug": "P.-Yanker",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yanker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yanker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690237"
                        ],
                        "name": "G. Taubin",
                        "slug": "G.-Taubin",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Taubin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Taubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The earliest work on appearance-based object recognition has mainly utilized global descriptions such as color or texture histograms [ 39 , 43, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14145220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "824aac4970a4d149b35c19a9d2d2dec4c994688e",
            "isKey": false,
            "numCitedBy": 2235,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In the query by image content (QBIC) project we are studying methods to query large on-line image databases using the images' content as the basis of the queries. Examples of the content we use include color, texture, and shape of image objects and regions. Potential applications include medical (`Give me other images that contain a tumor with a texture like this one'), photo-journalism (`Give me images that have blue at the top and red at the bottom'), and many others in art, fashion, cataloging, retailing, and industry. Key issues include derivation and computation of attributes of images and objects that provide useful query functionality, retrieval methods based on similarity as opposed to exact match, query by image example or user drawn image, the user interfaces, query refinement and navigation, high dimensional database indexing, and automatic and semi-automatic database population. We currently have a prototype system written in X/Motif and C running on an RS/6000 that allows a variety of queries, and a test database of over 1000 images and 1000 objects populated from commercially available photo clip art images. In this paper we present the main algorithms for color texture, shape and sketch query that we use, show example query results, and discuss future directions."
            },
            "slug": "QBIC-project:-querying-images-by-content,-using-and-Niblack-Barber",
            "title": {
                "fragments": [],
                "text": "QBIC project: querying images by content, using color, texture, and shape"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The main algorithms for color texture, shape and sketch query that are presented, show example query results, and discuss future directions are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4723637"
                        ],
                        "name": "J. Mao",
                        "slug": "J.-Mao",
                        "structuredName": {
                            "firstName": "Jianchang",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Cet article e\u0301value la pertinence d\u2019une repre\u0301sentation d\u2019image par une distribution (signature, histogramme) de descripteurs calcule\u0301s en des points d\u2019inte\u0301re\u0302t, et d\u2019une classification par Machine a\u0300 Vecteur Support dont les noyaux utilisent des mesures adapte\u0301es a\u0300 la comparaison de\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11686184,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science",
                "Computer Science"
            ],
            "id": "0b1c14ccf1aad87f215bfa5c6678d975d44ffb3a",
            "isKey": false,
            "numCitedBy": 795,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Texture-classification-and-segmentation-using-Mao-Jain",
            "title": {
                "fragments": [],
                "text": "Texture classification and segmentation using multiresolution simultaneous autoregressive models"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3037691"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Edie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "The SPIN descriptor, based on spin images used for matching range data [23], is a rotation-invariant two-dimensional histogram of intensities within an image region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1377132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df6c0c55864252090b4099237aa821a6c75b52c2",
            "isKey": false,
            "numCitedBy": 2634,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a 3D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion. Recognition is based on matching surfaces by matching points using the spin image representation. The spin image is a data level shape descriptor that is used to match surfaces represented as surface meshes. We present a compression scheme for spin images that results in efficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models. Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes."
            },
            "slug": "Using-Spin-Images-for-Efficient-Object-Recognition-Johnson-Hebert",
            "title": {
                "fragments": [],
                "text": "Using Spin Images for Efficient Object Recognition in Cluttered 3D Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A compression scheme for spin images that results in efficient multiple object recognition which is verified with results showing the simultaneous recognition of multiple objects from a library of 20 models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901127"
                        ],
                        "name": "E. Hayman",
                        "slug": "E.-Hayman",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Hayman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hayman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739548"
                        ],
                        "name": "Mario Fritz",
                        "slug": "Mario-Fritz",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Fritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mario Fritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270435"
                        ],
                        "name": "J. Eklundh",
                        "slug": "J.-Eklundh",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Eklundh",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eklundh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11307683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91e4c8003c492f9efc22be0d5c403d7b8275199a",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Classifying materials from their appearance is a challenging problem, especially if illumination and pose conditions are permitted to change: highlights and shadows caused by 3D structure can radically alter a sample\u2019s visual texture. Despite these difficulties, researchers have demonstrated impressive results on the CUReT database which contains many images of 61 materials under different conditions. A first contribution of this paper is to further advance the state-of-the-art by applying Support Vector Machines to this problem. To our knowledge, we record the best results to date on the CUReT database."
            },
            "slug": "On-the-Significance-of-Real-World-Conditions-for-Hayman-Caputo",
            "title": {
                "fragments": [],
                "text": "On the Significance of Real-World Conditions for Material Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A first contribution of this paper is to further advance the state-of-the-art by applying Support Vector Machines to this problem and record the best results to date on the CUReT database."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 141
                            }
                        ],
                        "text": "Finally, we obtain affine-invariant versions of the Harris-Laplace and Laplacian detectors through the use of an affine adaptation procedure [16, 36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": false,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 241
                            }
                        ],
                        "text": "To achieve rotation invariance, we can either use rotationally invariant descriptors\u2014for example, SPIN and RIFT [27], as presented in the following section\u2014or rotate the circular regions in the direction of the dominant gradient orientation [31, 37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "1 Scale- and affine-invariant region detectors In this paper, we use two complementary local region detector types to extract salient image structures: The Harris-Laplace detector [37] responds to corner-like regions, while the Laplacian detector [29] extracts blob-like regions (Figure 1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1704741,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8b440596b28dc6683caa2b5f6fbca70963e5909e",
            "isKey": false,
            "numCitedBy": 4161,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching results; the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points."
            },
            "slug": "Scale-&-Affine-Invariant-Interest-Point-Detectors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Scale & Affine Invariant Interest Point Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A comparative evaluation of different detectors is presented and it is shown that the proposed approach for detecting interest points invariant to scale and affine transformations provides better results than existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748264"
                        ],
                        "name": "D. Pelleg",
                        "slug": "D.-Pelleg",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Pelleg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pelleg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760402"
                        ],
                        "name": "A. Moore",
                        "slug": "A.-Moore",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Moore",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Moore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "In the future, we plan to experiment with efficient clustering methods, such as x-means with kd-trees [42], to improve the speed of vocabulary construction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11243672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7d385f45c096082812deb1623e5af2c2915b4a9",
            "isKey": false,
            "numCitedBy": 2490,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite its popularity for general clustering, K-means suuers three major shortcomings; it scales poorly computationally, the number of clusters K has to be supplied by the user, and the search is prone to local minima. We propose solutions for the rst two problems, and a partial remedy for the third. Building on prior work for algorithmic acceleration that is not based on approximation, we introduce a new algorithm that eeciently, searches the space of cluster locations and number of clusters to optimize the Bayesian Information Criterion (BIC) or the Akaike Information Criterion (AIC) measure. The innovations include two new ways of exploiting cached suucient statistics and a new very eecient test that in one K-means sweep selects the most promising subset of classes for reenement. This gives rise to a fast, statistically founded algorithm that outputs both the number of classes and their parameters. Experiments show this technique reveals the true number of classes in the underlying distribution , and that it is much faster than repeatedly using accelerated K-means for different values of K."
            },
            "slug": "X-means:-Extending-K-means-with-Efficient-of-the-of-Pelleg-Moore",
            "title": {
                "fragments": [],
                "text": "X-means: Extending K-means with Efficient Estimation of the Number of Clusters"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new algorithm is introduced that eeciently, searches the space of cluster locations and number of clusters to optimize the Bayesian Information Criterion (BIC) or the Akaike Information Criteria (AIC) measure."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686506"
                        ],
                        "name": "A. Atiya",
                        "slug": "A.-Atiya",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Atiya",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Atiya"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7406938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ff61b8e097ccdb784a35b466ba9e130c2502513",
            "isKey": false,
            "numCitedBy": 5530,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Chapters 2\u20137 make up Part II of the book: artificial neural networks. After introducing the basic concepts of neurons and artificial neuron learning rules in Chapter 2, Chapter 3 describes a particular formalism, based on signal-plus-noise, for the learning problem in general. After presenting the basic neural network types this chapter reviews the principal algorithms for error function minimization/optimization and shows how these learning issues are addressed in various supervised models. Chapter 4 deals with issues in unsupervised learning networks, such as the Hebbian learning rule, principal component learning, and learning vector quantization. Various techniques and learning paradigms are covered in Chapters 3\u20136, and especially the properties and relative merits of the multilayer perceptron networks, radial basis function networks, self-organizing feature maps and reinforcement learning are discussed in the respective four chapters. Chapter 7 presents an in-depth examination of performance issues in supervised learning, such as accuracy, complexity, convergence, weight initialization, architecture selection, and active learning. Par III (Chapters 8\u201315) offers an extensive presentation of techniques and issues in evolutionary computing. Besides the introduction to the basic concepts in evolutionary computing, it elaborates on the more important and most frequently used techniques on evolutionary computing paradigm, such as genetic algorithms, genetic programming, evolutionary programming, evolutionary strategies, differential evolution, cultural evolution, and co-evolution, including design aspects, representation, operators and performance issues of each paradigm. The differences between evolutionary computing and classical optimization are also explained. Part IV (Chapters 16 and 17) introduces swarm intelligence. It provides a representative selection of recent literature on swarm intelligence in a coherent and readable form. It illustrates the similarities and differences between swarm optimization and evolutionary computing. Both particle swarm optimization and ant colonies optimization are discussed in the two chapters, which serve as a guide to bringing together existing work to enlighten the readers, and to lay a foundation for any further studies. Part V (Chapters 18\u201321) presents fuzzy systems, with topics ranging from fuzzy sets, fuzzy inference systems, fuzzy controllers, to rough sets. The basic terminology, underlying motivation and key mathematical models used in the field are covered to illustrate how these mathematical tools can be used to handle vagueness and uncertainty. This book is clearly written and it brings together the latest concepts in computational intelligence in a friendly and complete format for undergraduate/postgraduate students as well as professionals new to the field. With about 250 pages covering such a wide variety of topics, it would be impossible to handle everything at a great length. Nonetheless, this book is an excellent choice for readers who wish to familiarize themselves with computational intelligence techniques or for an overview/introductory course in the field of computational intelligence. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond\u2014Bernhard Sch\u00f6lkopf and Alexander Smola, (MIT Press, Cambridge, MA, 2002, ISBN 0-262-19475-9). Reviewed by Amir F. Atiya."
            },
            "slug": "Learning-with-Kernels:-Support-Vector-Machines,-and-Atiya",
            "title": {
                "fragments": [],
                "text": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This book is an excellent choice for readers who wish to familiarize themselves with computational intelligence techniques or for an overview/introductory course in the field of computational intelligence."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3841331"
                        ],
                        "name": "Moray Allan",
                        "slug": "Moray-Allan",
                        "structuredName": {
                            "firstName": "Moray",
                            "lastName": "Allan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Moray Allan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879646"
                        ],
                        "name": "Thomas Deselaers",
                        "slug": "Thomas-Deselaers",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Deselaers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Deselaers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891864"
                        ],
                        "name": "Gyuri Dork\u00f3",
                        "slug": "Gyuri-Dork\u00f3",
                        "structuredName": {
                            "firstName": "Gyuri",
                            "lastName": "Dork\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyuri Dork\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762557"
                        ],
                        "name": "S. Duffner",
                        "slug": "S.-Duffner",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Duffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Duffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059148801"
                        ],
                        "name": "J. Eichhorn",
                        "slug": "J.-Eichhorn",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Eichhorn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eichhorn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48173155"
                        ],
                        "name": "Jason D. R. Farquhar",
                        "slug": "Jason-D.-R.-Farquhar",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Farquhar",
                            "middleNames": [
                                "D.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason D. R. Farquhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739548"
                        ],
                        "name": "Mario Fritz",
                        "slug": "Mario-Fritz",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Fritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mario Fritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144723337"
                        ],
                        "name": "Christophe Garcia",
                        "slug": "Christophe-Garcia",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51027911"
                        ],
                        "name": "Daniel Keysers",
                        "slug": "Daniel-Keysers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keysers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Keysers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758971"
                        ],
                        "name": "M. Koskela",
                        "slug": "M.-Koskela",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Koskela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Koskela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708642"
                        ],
                        "name": "Jorma T. Laaksonen",
                        "slug": "Jorma-T.-Laaksonen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Laaksonen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorma T. Laaksonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295553"
                        ],
                        "name": "Diane Larlus",
                        "slug": "Diane-Larlus",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Larlus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diane Larlus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37192632"
                        ],
                        "name": "H. Meng",
                        "slug": "H.-Meng",
                        "structuredName": {
                            "firstName": "Hongying",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Meng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083209039"
                        ],
                        "name": "Edgar Seemann",
                        "slug": "Edgar-Seemann",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Seemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edgar Seemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728216"
                        ],
                        "name": "A. Storkey",
                        "slug": "A.-Storkey",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Storkey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Storkey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540580"
                        ],
                        "name": "S. Szedm\u00e1k",
                        "slug": "S.-Szedm\u00e1k",
                        "structuredName": {
                            "firstName": "S\u00e1ndor",
                            "lastName": "Szedm\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Szedm\u00e1k"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145150531"
                        ],
                        "name": "ilkay Ulusoy",
                        "slug": "ilkay-Ulusoy",
                        "structuredName": {
                            "firstName": "ilkay",
                            "lastName": "Ulusoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ilkay Ulusoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2279074"
                        ],
                        "name": "Ville Viitaniemi",
                        "slug": "Ville-Viitaniemi",
                        "structuredName": {
                            "firstName": "Ville",
                            "lastName": "Viitaniemi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ville Viitaniemi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2875887"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "On the other hand, orderless bag-of-keypoints methods [47, 52] have the advantage of simplicity and computational efficiency, though they fail to represent the geometric structure of the object class or to distinguish between foreground and background features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2078231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb0ab2ee44ebf9c08bd2bf478c7444adfdcb2bd7",
            "isKey": false,
            "numCitedBy": 417,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge ran from February to March 2005. The goal of the challenge was to recognize objects from a number of visual object classes in realistic scenes (i.e. not pre-segmented objects). Four object classes were selected: motorbikes, bicycles, cars and people. Twelve teams entered the challenge. In this chapter we provide details of the datasets, algorithms used by the teams, evaluation criteria, and results achieved."
            },
            "slug": "The-2005-PASCAL-Visual-Object-Classes-Challenge-Everingham-Zisserman",
            "title": {
                "fragments": [],
                "text": "The 2005 PASCAL Visual Object Classes Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This chapter provides details of the datasets, algorithms used by the teams, evaluation criteria, and results achieved in the PASCAL Visual Object Classes Challenge."
            },
            "venue": {
                "fragments": [],
                "text": "MLCW"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718206"
                        ],
                        "name": "F. Graham",
                        "slug": "F.-Graham",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Graham",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "The \u03c7(2) kernel is a Mercer kernel [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2384316,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "13c82489c1568b67265d17a15720001a5737171e",
            "isKey": false,
            "numCitedBy": 1341,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Spectral graph theoretic methods have recently shown great promise for the problem of image segmentation. However, due to the computational demands of these approaches, applications to large problems such as spatiotemporal data and high resolution imagery have been slow to appear. The contribution of this paper is a method that substantially reduces the computational requirements of grouping algorithms based on spectral partitioning making it feasible to apply them to very large grouping problems. Our approach is based on a technique for the numerical solution of eigenfunction problems known as the Nystrom method. This method allows one to extrapolate the complete grouping solution using only a small number of samples. In doing so, we leverage the fact that there are far fewer coherent groups in a scene than pixels."
            },
            "slug": "Spectral-grouping-using-the-Nystrom-method-Fowlkes-Belongie",
            "title": {
                "fragments": [],
                "text": "Spectral grouping using the Nystrom method"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The contribution of this paper is a method that substantially reduces the computational requirements of grouping algorithms based on spectral partitioning making it feasible to apply them to very large grouping problems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064561619"
                        ],
                        "name": "Diane Larlus",
                        "slug": "Diane-Larlus",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Larlus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diane Larlus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134001996"
                        ],
                        "name": "Gyorgy Dorko",
                        "slug": "Gyorgy-Dorko",
                        "structuredName": {
                            "firstName": "Gyorgy",
                            "lastName": "Dorko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyorgy Dorko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801809"
                        ],
                        "name": "Fr\u00e9d\u00e9ric Jurie",
                        "slug": "Fr\u00e9d\u00e9ric-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fr\u00e9d\u00e9ric Jurie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "Slightly better results on PASCAL test set 1 were achieved using a dense method [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "test set 1 test set 2 HS LS HS+LS Larlus [25] HS LS HS+LS Deselaers [10] bikes 87."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "For test set 1 the best results, slightly better than ours, were obtained by Larlus [25]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 15433302,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "b11aff9845d3deeed6c96ed1e62e3425a73a9de1",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Nous proposons dans cet article une methode de construction automatique de vocabulaires visuels. Le vocabulaire visuel est obtenu par quantification de descripteurs locaux des images. Les vocabulaires visuels produits sont utilises pour construire automatiquement des representations discriminantes des objets presents dans les images. Nous decrivons une application de ces techniques a la categorisation d'images par sacs de primitives (bags of features) et montrons que les resultats obtenus sont tres superieurs a ceux obtenus par les methodes concurrentes."
            },
            "slug": "Cr\u00e9ation-de-Vocabulaires-Visuels-Efficaces-pour-la-Larlus-Dorko",
            "title": {
                "fragments": [],
                "text": "Cr\u00e9ation de Vocabulaires Visuels Efficaces pour la Cat\u00e9gorisation d'Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "http://www.vision.ethz.ch/projects/cogvis/CogVis-images/image-samples.html"
            },
            "venue": {
                "fragments": [],
                "text": "http://www.vision.ethz.ch/projects/cogvis/CogVis-images/image-samples.html"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 300,
                                "start": 277
                            }
                        ],
                        "text": "At the same time, Support Vector Machine (SVM) classifiers [46] have shown their promise for visual classification tasks (see [43] for an early example), and the development of specialized kernels suitable for use with local features has emerged as a fruitful line of research [5, 12, 18, 32, 40, 50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nilsback. Object categorization via local kernels"
            },
            "venue": {
                "fragments": [],
                "text": "In International Conference on Pattern Recognition,"
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 23,
            "methodology": 22,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 53,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Local-Features-and-Kernels-for-Classification-of-An-Zhang-Marszalek/35e855b0c1af4cc7bf62a8eb459c949776fbe7ee?sort=total-citations"
}