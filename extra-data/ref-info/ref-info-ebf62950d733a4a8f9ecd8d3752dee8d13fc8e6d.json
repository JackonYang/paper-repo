{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70034493"
                        ],
                        "name": "Arun Maskara",
                        "slug": "Arun-Maskara",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Maskara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arun Maskara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144664041"
                        ],
                        "name": "A. Noetzel",
                        "slug": "A.-Noetzel",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Noetzel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Noetzel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17428380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08e5738b13cdba5eb956015988df85c702616ef6",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The Simple Recurrent Network (SRN) is a neural network model that has been designed for the recognition of symbol sequences. It is a back-propagation network with a single hidden layer of units. The symbols of a sequence are presented one at a time at the input layer. But the activation pattern in the hidden units during the previous input symbol is also presented as an auxiliary input. In previous research, it has been shown that the SRN can be trained to behave as a nite state automaton (FSA) which accepts the valid strings corresponding to a particular grammar and rejects the invalid strings. It does this by predicting each successive symbol in the input string. However, the SRN architecture sometime fails to encode the context necessary to predict the next input symbol. This happens when two di erent states in the FSA generating the strings have the same output, and the SRN develops similar hidden layer encodings for these states. The failure happens more often when number of units in the hidden layer is limited. We have developed a new architecture, called the Forced Simple Recurrent Network (FSRN), that solves this problem. This architecture contains additional output units, which are trained to show the current input and the previous context. Simulation results show that for certain classes of FSA with u states, the SRN with dlog 2 ue units in the hidden layers fails, where as the FSRN with the same number of hidden layer units succeeds. 1 To appear In the Proceedings of the 1992 Long Island Conference on Arti cial Intelligence and Computer Graphics"
            },
            "slug": "Forcing-Simple-Recurrent-Neural-Networks-to-Encode-Maskara-Noetzel",
            "title": {
                "fragments": [],
                "text": "Forcing Simple Recurrent Neural Networks to Encode Context"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new architecture, called the Forced Simple Recurrent Network (FSRN), is developed, which contains additional output units, which are trained to show the current input and the previous context, that solves the problem of failing to encode the context necessary to predict the next input symbol."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13003683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "040800e88fbdff598fb85ea82c12f94c3939989f",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The backpropagation algorithm can be used for both recognition and generation of time trajectories. When used as a recognizer, it has been shown that the performance of a network can be greatly improved by adding structure to the architecture. The same is true in trajectory generation. In particular a new architecture corresponding to a \"reversed\" TDNN is proposed. Results show dramatic improvement of performance in the generation of hand-written characters. A combination of TDNN and reversed TDNN for compact encoding is also suggested."
            },
            "slug": "Reverse-TDNN:-An-Architecture-For-Trajectory-Simard-LeCun",
            "title": {
                "fragments": [],
                "text": "Reverse TDNN: An Architecture For Trajectory Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "The backpropagation algorithm can be used for both recognition and generation of time trajectories and results show dramatic improvement of performance in the generation of hand-written characters."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859277"
                        ],
                        "name": "T. Plate",
                        "slug": "T.-Plate",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Plate",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Plate"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1197280,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a7a9eeb64ec4511ed1415baa4716da15e2897641",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A solution to the problem of representing compo-sitional structure using distributed representations is described. The method uses circular convolution to associate items, which are represented by v ec-tors. Arbitrary variable bindings, short sequences of various lengths, frames, and reduced representations can be compressed into a xed width vector. These representations are items in their own right, and can be used in constructing compositional structures. The noisy reconstructions given by convolution memories can be cleaned up by using a separate associative memory that has good recon-structive properties."
            },
            "slug": "Holographic-Reduced-Representations:-Convolution-Plate",
            "title": {
                "fragments": [],
                "text": "Holographic Reduced Representations: Convolution Algebra for Compositional Distributed Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A solution to the problem of representing compo-sitional structure using distributed representations is described, which uses circular convolution to associate items, which are represented by v ec-tors."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140752"
                        ],
                        "name": "Charles R. Rosenberg",
                        "slug": "Charles-R.-Rosenberg",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Rosenberg",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles R. Rosenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 82
                            }
                        ],
                        "text": "One approach has been to use a fixed window on the sequence, e.g., as in NETtalk [Sejnowski and Rosenberg, 1986]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13921532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "406033f22b6a671b94bcbdfaf63070b7ce6f3e48",
            "isKey": false,
            "numCitedBy": 761,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Unrestricted English text can be converted to speech by applying phonological rules and handling exceptions with a look-up table. However, this approach is highly labor intensive since each entry and rule must be hand-crafted. NETtalk is an alternative approach that is based on an automated learning procedure for a parallel network of deterministic processing units. ~ f t e r ' training on a corpus of informal continuous speech, it achieves good performance and generalizes to novel words. The distributed internal representations of the phonological regularities discovered by the network are damage resistant."
            },
            "slug": "NETtalk:-a-parallel-network-that-learns-to-read-Sejnowski-Rosenberg",
            "title": {
                "fragments": [],
                "text": "NETtalk: a parallel network that learns to read aloud"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "NETtalk is an alternative approach that is based on an automated learning procedure for a parallel network of deterministic processing units that achieves good performance and generalizes to novel words."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19355,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 176
                            }
                        ],
                        "text": "The recurrent component of these networks uses convolution operations rather than the logistic-of-matrix-vector-product traditionally used in simple recurrent networks (SRNs) [Elman, 1991, Servan-Schreiber et al., 1991]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "HRNs are very similar to SRNs, such as those used by [Elman, 1991] and [Servan-Schreiber et al., 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 95
                            }
                        ],
                        "text": "SRNs have been used successfully to process sequential input and induce finite state grammars [Elman, 1991, Servan-Schreiber et al., 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 53
                            }
                        ],
                        "text": "HRNs are very similar to SRNs, sueh as those used by [Elman, 1991] and [Cleeremans et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 189900099,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "df2f25f585a9a046c3a193c716d94d5affd76f38",
            "isKey": true,
            "numCitedBy": 341,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper three problems for a connectionist account of language are considered:1. What is the nature of linguistic representations?2. How can complex structural relationships such as constituent structure be represented?3. How can the apparently open-ended nature of language be accommodated by a fixed-resource system?Using a prediction task, a simple recurrent network (SRN) is trained on multiclausal sentences which contain multiply-embedded relative clauses. Principal component analysis of the hidden unit activation patterns reveals that the network solves the task by developing complex distributed representations which encode the relevant grammatical relations and hierarchical constituent structure. Differences between the SRN state representations and the more traditional pushdown store are discussed in the final section."
            },
            "slug": "Distributed-Representations,-Simple-Recurrent-And-Elman",
            "title": {
                "fragments": [],
                "text": "Distributed Representations, Simple Recurrent Networks, And Grammatical Structure"
            },
            "venue": {
                "fragments": [],
                "text": "Mach. Learn."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "McClel - land . Graded state machines : The representation of temporal contingencies insimple recurrent networks"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reverse TDNN: an architec"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Arun Maskara and Andrew Noetzel. Forcing simple recurrent neural networks to encode contextPlate, 1991a] Tony A. Plate. Holographic Reduced Representations"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1992 Long Island Conference on Artificial Intelligence and Computer Graphics"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 3
                            }
                        ],
                        "text": "In [Plate, 1991a] the capacity of circular-convolution based associative memory was calculated."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Technical Report CRG-TR-91-1"
            },
            "venue": {
                "fragments": [],
                "text": "Department of Computer Science, University of Toronto,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Williams R"
            },
            "venue": {
                "fragments": [],
                "text": "J. Learning internal representations by error propagation. In Parallel distributed processing: Explorations in the microstructure of cognition, volume 1, chapter 8, pages 318-362. Bradford Books, Cambridge, MA"
            },
            "year": 1986
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 11,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Holographic-Recurrent-Networks-Plate/ebf62950d733a4a8f9ecd8d3752dee8d13fc8e6d?sort=total-citations"
}