{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356107"
                        ],
                        "name": "Orkut Buyukkokten",
                        "slug": "Orkut-Buyukkokten",
                        "structuredName": {
                            "firstName": "Orkut",
                            "lastName": "Buyukkokten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Orkut Buyukkokten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398574232"
                        ],
                        "name": "H. Garcia-Molina",
                        "slug": "H.-Garcia-Molina",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Garcia-Molina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Garcia-Molina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750481"
                        ],
                        "name": "A. Paepcke",
                        "slug": "A.-Paepcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Paepcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Paepcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699245"
                        ],
                        "name": "T. Winograd",
                        "slug": "T.-Winograd",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Winograd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Winograd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 28
                            }
                        ],
                        "text": ", the Power Browser project [5, 4], have focussed on a range of problems connected to web-surfing with PDAs such as bandwidth, power consumption, pen-based query input, etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1850263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58642dc60e5e8d5762f903483ad459c82285837e",
            "isKey": false,
            "numCitedBy": 310,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We have designed and implemented new Web browsing facilities to support effective navigation on Personal Digital Assistants (PDAs) with limited capabilities: low bandwidth, small display, and slow CPU. The implementation supports wireless browsing from 3Com's Palm Pilot. An HTTP proxy fetches web pages on the client's behalf and dynamically generates summary views to be transmitted to the client. These summaries represent both the link structure and contents of a set of web pages, using information about link importance. We discuss the architecture, user interface facilities, and the results of comparative performance evaluations. We measured a 45% gain in browsing speed, and a 42% reduction in required pen movements."
            },
            "slug": "Power-browser:-efficient-Web-browsing-for-PDAs-Buyukkokten-Garcia-Molina",
            "title": {
                "fragments": [],
                "text": "Power browser: efficient Web browsing for PDAs"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This work designed and implemented new Web browsing facilities to support effective navigation on Personal Digital Assistants (PDAs) with limited capabilities: low bandwidth, small display, and slow CPU."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356107"
                        ],
                        "name": "Orkut Buyukkokten",
                        "slug": "Orkut-Buyukkokten",
                        "structuredName": {
                            "firstName": "Orkut",
                            "lastName": "Buyukkokten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Orkut Buyukkokten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398574232"
                        ],
                        "name": "H. Garcia-Molina",
                        "slug": "H.-Garcia-Molina",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Garcia-Molina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Garcia-Molina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750481"
                        ],
                        "name": "A. Paepcke",
                        "slug": "A.-Paepcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Paepcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Paepcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 28
                            }
                        ],
                        "text": ", the Power Browser project [5, 4], have focussed on a range of problems connected to web-surfing with PDAs such as bandwidth, power consumption, pen-based query input, etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11412080,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "a2dfe79fe5aa55866f78e8fd5df998e51c2b0147",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Focused-Web-searching-with-PDAs-Buyukkokten-Garcia-Molina",
            "title": {
                "fragments": [],
                "text": "Focused Web searching with PDAs"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Networks"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113533823"
                        ],
                        "name": "Wei Fan",
                        "slug": "Wei-Fan",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Fan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "The heuristics provided in this paper operate without any training, either on HTML source (as in [6]) or on a language model; finding a statistical model with which to enhance these heuristics remains the most important future extension of this work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "Cohen and Fan [6] use the automated rule-learning system, RIPPER, to detect simple lists of strings and lists of associations of strings and URLs in noisy HTML source based on a collection of nineteen features pertaining to the structure of the HTML parse tree."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15679108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e7cfed8815cce163efac9d17b1109849c050c6b",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Page-Independent-Heuristics-for-Extracting-Cohen-Fan",
            "title": {
                "fragments": [],
                "text": "Learning Page-Independent Heuristics for Extracting Data from Web Pages"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 134
                            }
                        ],
                        "text": "It has been explored before with limited success in the context of detecting tables from plain ASCII text and scanned document images [9, 8, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41490827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e9383c894019f34e8cd77b68b89af5c1d42c7e9",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are an important means for communicating information in written media, and understanding such tables is a challenging problem in document layout analysis. In this paper we describe a general solution to the problem of recognizing the structure of a detected table region. First hierarchial clustering is used to identify columns and then spatial and lexical criteria to classify headers. We also address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, 'random graph probing,' for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "slug": "Table-structure-recognition-and-its-evaluation-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Table structure recognition and its evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new paradigm, 'random graph probing,' is described for comparing the results returned by the recognition system and the representation created during ground-truthing, which could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741158"
                        ],
                        "name": "P. Atzeni",
                        "slug": "P.-Atzeni",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Atzeni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Atzeni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682406"
                        ],
                        "name": "A. Mendelzon",
                        "slug": "A.-Mendelzon",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Mendelzon",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mendelzon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785690"
                        ],
                        "name": "G. Mecca",
                        "slug": "G.-Mecca",
                        "structuredName": {
                            "firstName": "Giansalvatore",
                            "lastName": "Mecca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mecca"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29101594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e0ba3628e81a6c501fe02f71376c748b3c66ccc",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Caching of Web documents improves the response time perceived by the clients. Cache replacement algorithms play a central role in the response time reduction by selecting a subset of documents for caching so that an appropriate performance metric is maximized. At the same time, the cache must take extra steps to guarantee some form of consistency of the cached data. Cache consistency algorithms enforce appropriate guarantees about the staleness of documents it stores. Most of the published work on Web cache design either considers cache consistency algorithms separately from cache replacement algorithms or concentrates only on studying one of the two. We argue that cache performance can be improved by integrating cache replacement and consistency algorithms. We present an unified algorithm LNC-R-W3-U. Using trace-based experiments, we demonstrate that LNC-R-W3-U achieves performance comparable (and often superior) to most of the published cache replacement algorithms and at the same time significantly reduces the staleness of the cached documents."
            },
            "slug": "The-World-Wide-Web-and-Databases-Atzeni-Mendelzon",
            "title": {
                "fragments": [],
                "text": "The World Wide Web and Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work argues that cache performance can be improved by integrating cache replacement and consistency algorithms, and presents an unified algorithm LNC-R-W3-U, which achieves performance comparable (and often superior) to most of the published cache replacement algorithms and at the same time significantly reduces the staleness of the cached documents."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741158"
                        ],
                        "name": "P. Atzeni",
                        "slug": "P.-Atzeni",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Atzeni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Atzeni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682406"
                        ],
                        "name": "A. Mendelzon",
                        "slug": "A.-Mendelzon",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Mendelzon",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mendelzon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785690"
                        ],
                        "name": "G. Mecca",
                        "slug": "G.-Mecca",
                        "structuredName": {
                            "firstName": "Giansalvatore",
                            "lastName": "Mecca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mecca"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60725124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c917ec967be8ce6545356ef428fc4157d947a7ae",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Internet Programming: Tools and Applications.- A Unified Algorithm for Cache Replacement and Consistency in Web Proxy Servers.- Transactional Services for the Internet.- On the Unification of Persistent Programming and the World-Wide Web.- Integration and Access to Web Data.- Interactive Query and Search in Semistructured Databases.- Bringing Database Functionality to the WWW.- Fixpoint Calculus for Querying Semistructured Data.- Hypertext Views on Databases.- Incremental Maintenance of Hypertext Views.- Using YAT to Build a Web Server.- Languages and Tools to Specify Hypertext Views on Databases.- Searching and Mining the Web.- WebSuite-A Tool Suite for Harnessing Web Data.- Extracting Patterns and Relations from the World Wide Web.- WUM: A Tool for Web Utilization Analysis.- Finding Near-Replicas of Documents on the Web."
            },
            "slug": "The-World-Wide-Web-and-databases-:-International-:-Atzeni-Mendelzon",
            "title": {
                "fragments": [],
                "text": "The World Wide Web and databases : International Workshop WebDB'98 : Valencia, Spain, March 27-28, 1998 : selected papers"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A Unified Algorithm for Cache Replacement and Consistency in Web Proxy Servers and a Tool Suite for Harnessing Web Data for Extracting Patterns and Relations from the World Wide Web."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118066054"
                        ],
                        "name": "Eric Ladd",
                        "slug": "Eric-Ladd",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Ladd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Ladd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401695641"
                        ],
                        "name": "J. O'Donnell",
                        "slug": "J.-O'Donnell",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "O'Donnell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Donnell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "do not contain any tags except formatting, list, hyperlink, and image tags [10], and"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "There is also a class of HTML tags called text-level formatting tags [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60054735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68d2d3a443f4d8ed6277c41d8dfab5c2b0b50dfb",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nQue's Platinum Edition Using HTML 4, XML, and Java 1.2 is the most complete tutorial and reference for experienced Webmasters who want to create Web sites using the latest technologies.. \"This guide delivers all the time-saving tips and expert advice you need to enhance your Web programming skills and expand your knowledge of HTML, XML, and Java. With insight, real-world examples, and a practical, hands-on approach, you'll move quickly to the more advanced issues and concepts. You'll master the HTML-related technologies and features, as well as build a solid understanding of high-end topics."
            },
            "slug": "Using-HTML-4,-XML,-and-Java-1.2-Ladd-O'Donnell",
            "title": {
                "fragments": [],
                "text": "Using HTML 4, XML, and Java 1.2"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "From the Publisher:  Que's Platinum Edition Using HTML 4, XML, and Java 1.2 is the most complete tutorial and reference for experienced Webmasters who want to create Web sites using the latest technologies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405796477"
                        ],
                        "name": "Jordi Ortiz-Lopez",
                        "slug": "Jordi-Ortiz-Lopez",
                        "structuredName": {
                            "firstName": "Jordi",
                            "lastName": "Ortiz-Lopez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordi Ortiz-Lopez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 61
                            }
                        ],
                        "text": "Incorporating a means of recognising text from images (as in [11, 1]) as well as better text summarisation methods for news summaries are also natural areas for further development."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 73
                            }
                        ],
                        "text": "Extending this implementation with a means of recognising text in images [11, 1] remains an area of further research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58126878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "578885300701343a5467a1565a6946e8bc307250",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Indexing and searching for WWW pages is relying on analyzing text. Current technology cannot process the text embedded in images on WWW pages. This paper argues that this is a significant problem as text in image form is usually semantically important (e.g. headers, titles). The results of a recent study are presented to show that the majority (76%) of words embedded in images do not appear elsewhere in the main text and that the majority (56%) of ALT tag descriptions of images are incorrect of do not exist at all. Research under way to devise tools to extracted text from images based on the way humans perceive color differences is outlined and results are presented."
            },
            "slug": "Accessing-textual-information-embedded-in-Internet-Antonacopoulos-Karatzas",
            "title": {
                "fragments": [],
                "text": "Accessing textual information embedded in Internet images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Research under way to devise tools to extracted text from images based on the way humans perceive color differences is outlined and results are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786259"
                        ],
                        "name": "S. Brin",
                        "slug": "S.-Brin",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Brin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Others, e.g., Brin [3] and other work at Google, have used a bootstrapping technique to extract particular kinds of relations from on-line text, such as author-title relations for books."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": ", Brin [3] and other work at Google, have used a bootstrapping technique to extract particular kinds of relations from on-line text, such as author-title relations for books."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6075461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92575a3c554353a27b2c0263ad7f8487d9102301",
            "isKey": false,
            "numCitedBy": 1235,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web is a vast resource for information. At the same time it is extremely distributed. A particular type of data such as restaurant lists may be scattered across thousands of independent information sources in many different formats. In this paper, we consider the problem of extracting a relation for such a data type from all of these sources automatically. We present a technique which exploits the duality between sets of patterns and relations to grow the target relation starting from a small sample. To test our technique we use it to extract a relation of (author,title) pairs from the World Wide Web."
            },
            "slug": "Extracting-Patterns-and-Relations-from-the-World-Brin",
            "title": {
                "fragments": [],
                "text": "Extracting Patterns and Relations from the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a technique which exploits the duality between sets of patterns and relations to grow the target relation starting from a small sample and uses it to extract a relation of (author,title) pairs from the World Wide Web."
            },
            "venue": {
                "fragments": [],
                "text": "WebDB"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118066054"
                        ],
                        "name": "Eric Ladd",
                        "slug": "Eric-Ladd",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Ladd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Ladd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401695641"
                        ],
                        "name": "J. O'Donnell",
                        "slug": "J.-O'Donnell",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "O'Donnell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Donnell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 67183356,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b38ecbdaf5aed0019307930be56f563affe55805",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nPlatinum Edition Using books are high-end tutorial references that teach experienced readers how to use cutting-edge technologies. Recent changes in Web technologies demand that HTML programmers learn a vast array of new Web programming skills this book teaches those skills in a practical, hands-on manner. Covers advanced-level topics that Webmasters need the most, like building Web databases, interactive forms, and Webcasting. This second edition includes updates for Java 1.2, a major new JavaScript section, Webcasting, XML, Dynamic HTML, and more on ActiveX. \nCovers advanced-level topics that Webmasters need the most, like building Web databases, interactive forms, and Webcasting \nIncludes updates for Java 1.2, a major new JavaScript section, Webcasting, XML, Dynamic HTML, and more on ActiveX \nFeatures updated HTML coverage: new tags for Internet Explorer 4 and Netscape Communicator"
            },
            "slug": "Using-HTML-4-Java-1.1-and-JavaScript-1.2:-Platinum-Ladd-O'Donnell",
            "title": {
                "fragments": [],
                "text": "Using HTML 4 Java 1.1 and JavaScript 1.2: Platinum Edition"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This book teaches a vast array of new Web programming skills in a practical, hands-on manner and includes updates for Java 1.2, a major new JavaScript section, Webcasting, XML, Dynamic HTML, and more on ActiveX."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901883"
                        ],
                        "name": "Shona Douglas",
                        "slug": "Shona-Douglas",
                        "structuredName": {
                            "firstName": "Shona",
                            "lastName": "Douglas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shona Douglas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 134
                            }
                        ],
                        "text": "It has been explored before with limited success in the context of detecting tables from plain ASCII text and scanned document images [9, 8, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14091058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "971af881cefc0bccb7f47046095d0a92f0de3152",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a prototype system for assigning table cells to their proper place in the logical structure of the table, based on a simple model of table structure combined with a number of measures of cohesion between cells. A framework is presented for examining the effect of particular variables on the performance of the system, and preliminary results are presented showing the effect of cohesion measures based on the simplest domain-independent analyses, with the aim allowing future comparison with more knowledge-intensive analyses based on natural language processing. These baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as we require. Future work will pursue the aim of more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells."
            },
            "slug": "Layout-and-language:-preliminary-investigations-in-Hurst-Douglas",
            "title": {
                "fragments": [],
                "text": "Layout and language: preliminary investigations in recognizing the structure of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "B baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as it is suggested that more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells are needed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2178614"
                        ],
                        "name": "N. Ashish",
                        "slug": "N.-Ashish",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Ashish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ashish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Ashish and Knoblock [2] describe a semi-automated method for \u201cwrapper\u201d generation that uses regular expressions for locating\n1Among the ten corporate sites, one TABLE container was wrongly identified as genuine, and there was one genuine table, which was not identified.\nkeywords combined with information about font size and indentation to identify structural units of interest within HTML documents."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Ashish and Knoblock [2] describe a semi-automated method for \u201cwrapper\u201d generation that uses regular expressions for locating"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10413529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a60a737b40ceb1a50bc8616ae6155bf50e07c07",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "With the current explosion of information on the World Wide Web (WWW) a wealth of information on many different subjects has become available on-line. Numerous sources contain information that can be classified as semi-structured. At present, however, the only way to access the information is by browsing individual pages. We cannot query web documents in a database-like fashion based on their underlying structure. However, we can provide database-like querying for semi-structured WWW sources by building wrappers around these sources. We present an approach for semi-automatically generating such wrappers. The key idea is to exploit the formatting information in pages from the source to hypothesize the underlying structure of a page. From this structure the system generates a wrapper that facilitates querying of a source and possibly integrating it with other sources. We demonstrate the ease with which we are able to build wrappers for a number of internet sources in different domains using our implemented wrapper generation toolkit."
            },
            "slug": "Wrapper-generation-for-semi-structured-Internet-Ashish-Knoblock",
            "title": {
                "fragments": [],
                "text": "Wrapper generation for semi-structured Internet sources"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The key idea is to exploit the formatting information in pages from the source to hypothesize the underlying structure of a page and generate a wrapper that facilitates querying of a source and possibly integrating it with other sources."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 61
                            }
                        ],
                        "text": "Incorporating a means of recognising text from images (as in [11, 1]) as well as better text summarisation methods for news summaries are also natural areas for further development."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 73
                            }
                        ],
                        "text": "Extending this implementation with a means of recognising text in images [11, 1] remains an area of further research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Locating and recognizing text i  n www images.Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "The heuristics provided in this paper operate without any training, either on HTML source (as in [6]) or on a language model; finding a statistical model with which to enhance these heuristics remains the most important future extension of this work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Cohen and Fan [6] use the automated rule-learning system, RIPPER, to detect simple lists of strings and lists of associations of strings and URLs in noisy HTML source based on a collection of nineteen features pertaining to the structure of the HTML parse tree."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "Cohen and Fan [6] use the automated rule-learning system, RIPPER, to detect simple lists of strings and lists of associations of strings and URLs in nois y HTML source based on a collection of nineteen features pertaining to the structure of the HTML parse tree."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning page-independent heuristi  cs for extracting data from web"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A system for understanding and reformulating tables"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth IAPR International Workshop on Document Analysis Systems"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "We then heuristically identify news links as those substrings of a news item that are:\n1. the text contents of hyperlinked containers, and\n2. whose lengths (in whitespace-delimited words) are less than a threshold, 4 ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "It then locates all text regions (ignoring genuine tables), discarding those that have three or more key phrases from a pre-defined list of terms likely to appear in disclaimers and legal information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Platinum Edition Using HTML 4, XML, and Java 1.2. Que Books"
            },
            "venue": {
                "fragments": [],
                "text": "Platinum Edition Using HTML 4, XML, and Java 1.2. Que Books"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "do not contain any tags except formatting, list, hyperlink, and image tags [10], and"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "There is also a class of HTML tags called text-level formatting tags[10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Platinum Edition Using HTML 4, XML, and Java"
            },
            "venue": {
                "fragments": [],
                "text": "Que Books,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 134
                            }
                        ],
                        "text": "It has been explored before with limited success in the context of detecting tables from plain ASCII text and scanned document images [9, 8, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A system for understanding and reformulating tables"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the Fourth IAPR International Workshop on Document Analysis Systems,"
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Flexible-Web-document-analysis-for-delivery-to-Penn-Hu/eb72ee8307eeeafeb93031d8625440b9e6415159?sort=total-citations"
}