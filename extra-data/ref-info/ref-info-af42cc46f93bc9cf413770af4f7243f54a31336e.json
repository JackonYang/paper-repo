{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We begin by briefly reviewing an algorithm we have developed for locating tables in ASCII and scanned documents [ 3 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Let meritpre (i, [i +1 ,j ]) be the merit of prepending line i to the table extending from line i + 1 to line j, and meritapp([i, j \u2212 1] ,j ) be the merit of appending line j to the table extending from line i to line j \u2212 1. We have chosen white space correlation and vertical connected component analysis to model specific functions for meritpre and meritapp [ 3 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section we describe a method for evaluating the performance of table detection algorithms building on the well-known concept of edit distance [ 3 ,4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37293831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edbd577d793a083de4f337acac992ec7837609e0",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An important step towards the goal of table understanding is a method for reliable table detection. This paper describes a general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables. A dynamic programming algorithm is given to solve the resulting optimization problem. This high-level framework is independent of any particular table quality measure and independent of the document medium. Moreover, it does not rely on the presence of ruling lines or other table delimiters. We also present table quality measures based on white space correlation and vertical connected component analysis. These measures can be applied equally well to ASCII text and scanned images. We report on some preliminary experiments using this method to detect tables in both ASCII text and scanned images, yielding promising results. We present detailed evaluation of these results using three different criteria which by themselves pose interesting research questions."
            },
            "slug": "Medium-independent-table-detection-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Medium-independent table detection"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables is described and a dynamic programming algorithm is given to solve the resulting optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "We begin by briefly describing an algorithm we have developed for parsing tables [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41490827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e9383c894019f34e8cd77b68b89af5c1d42c7e9",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are an important means for communicating information in written media, and understanding such tables is a challenging problem in document layout analysis. In this paper we describe a general solution to the problem of recognizing the structure of a detected table region. First hierarchial clustering is used to identify columns and then spatial and lexical criteria to classify headers. We also address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, 'random graph probing,' for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "slug": "Table-structure-recognition-and-its-evaluation-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Table structure recognition and its evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new paradigm, 'random graph probing,' is described for comparing the results returned by the recognition system and the representation created during ground-truthing, which could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2456613"
                        ],
                        "name": "J. H. Shamilian",
                        "slug": "J.-H.-Shamilian",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shamilian",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Shamilian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1394247998"
                        ],
                        "name": "T. Wood",
                        "slug": "T.-Wood",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Wood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wood"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "Another possibility would be to evaluate table recognition by measuring the overall performance of an application in which it is embedded [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206775234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ad7b7fe1c5e346b1cb9034af4fa18b5afe4d45e",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles. In these tables, textual data are presented in record lines made up of fixed-width fields. Tables often do not rely on line-art (ruled lines) to delimit fields, and in this way differ crucially from fixed forms. Our system performs these steps: copes with multiple tables per page; identifies records within tables; segments records into fields; and recognizes characters within fields, constrained by field-specific contextual knowledge. Obstacles to good performance on tables include small print, tight line-spacing, poor-quality text (such as photocopies), and line-art or background patterns that touch the text. Precise skew-correction and pitch-estimation, and high-performance OCR using neural nets proved crucial in overcoming these obstacles. The most significant technical advances in this work appear to be algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts. This GUI has been ergonomically designed to make efficient and intuitive use of exemplary images, so that the skill and manual effort required to retarget the system to new table layouts are held to a minimum. The system has been applied in this way to more than 400 distinct tabular layouts. During the last three years the system has read over fifty million records with high accuracy."
            },
            "slug": "A-retargetable-table-reader-Shamilian-Baird",
            "title": {
                "fragments": [],
                "text": "A retargetable table reader"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles, and algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "Another line of future work is concerned with the problem of determining the ground-truth used for performance evaluation [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9399933,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d5f9a51f9b21f267026d723219ab158b1598197",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine the nature of ground-truth: whether it is always well-defined fora given task, oron ly relative and approximate. In the conventional scenario, reference data is produced by recording the interpretation of each test document using a chosen data-entry platform. Looking a little more closely at this process, we study its constituents and their interrelations. We provide examples from the literature and from our own experiments where non-trivial problems with each of the components appear to preclude the possibility of real progress in evaluating automated graphics recognition systems, and propose possible solutions. More specifically, for documents with complex structure we recommend multi-valued, layered, weighted, functional ground-truth supported by model-guided reference data-entry systems and protocols. Mostly, however, we raise far more questions than we currently have answers for."
            },
            "slug": "Issues-in-Ground-Truthing-Graphic-Documents-Lopresti-Nagy",
            "title": {
                "fragments": [],
                "text": "Issues in Ground-Truthing Graphic Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "For documents with complex structure, this work recommends multi-valued, layered, weighted, functional ground-truth supported by model-guided reference data-entry systems and protocols, and raises far more questions than currently have answers."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582412"
                        ],
                        "name": "S. Agne",
                        "slug": "S.-Agne",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Agne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24940798"
                        ],
                        "name": "Markus Rogger",
                        "slug": "Markus-Rogger",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Rogger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Rogger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403736905"
                        ],
                        "name": "J. Rohrschneider",
                        "slug": "J.-Rohrschneider",
                        "structuredName": {
                            "firstName": "Joerg",
                            "lastName": "Rohrschneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rohrschneider"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 253
                            }
                        ],
                        "text": "Unlike existing approaches for the seemingly similar problem of page segmentation that also employ distance-type measures, our approach is based on logical structure, not on pixel-level comparisons [8,21] or matching the text characters output from OCR [1,8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "The difficulty here is that errors in other subsystems (e.g., layout analysis, OCR, user interface) will affect the results and make it impossible to distinguish which errors are due to which subsystem."
                    },
                    "intents": []
                }
            ],
            "corpusId": 35217863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c8add966609454965c2322385157fe9d7abd26c",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The decomposition of a document into segments such as text regions and graphics is a significant part of the document analysis process. The basic requirement for rating and improvement of page segmentation algorithms is systematic evaluation. The approaches known from the literature have the disadvantage that manually generated reference data (zoning ground truth) are needed for the evaluation task. The effort and cost of the creation of these data are very high. This paper describes the evaluation system SEE. The system requires the OCR generated text and the original text of the document in correct reading order (text ground truth) as input. No manually generated zoning ground truth is needed. The implicit structure information that is contained in the text ground truth is used for the evaluation of the automatic zoning. Therefore, an assignment of the corresponding text regions in the text ground truth and those in the OCR generated text (matches) is sought. A fault tolerant string matching algorithm is used to develop a method which tolerates OCR errors in the text. The segmentation errors are determined as a result of the evaluation of the matching. Subsequently, the edit operations which are necessary for the correction of the recognized segmentation errors are computed to estimate the correction costs."
            },
            "slug": "Benchmarking-of-document-page-segmentation-Agne-Rogger",
            "title": {
                "fragments": [],
                "text": "Benchmarking of document page segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The system requires the OCR generated text and the original text of the document in correct reading order (text ground truth) as input and a fault tolerant string matching algorithm is used to develop a method which tolerates OCR errors in the text."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757030"
                        ],
                        "name": "Berrin A. Yanikoglu",
                        "slug": "Berrin-A.-Yanikoglu",
                        "structuredName": {
                            "firstName": "Berrin",
                            "lastName": "Yanikoglu",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berrin A. Yanikoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 198
                            }
                        ],
                        "text": "Unlike existing approaches for the seemingly similar problem of page segmentation that also employ distance-type measures, our approach is based on logical structure, not on pixel-level comparisons [8,21] or matching the text characters output from OCR [1,8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16994816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23b63ccfe44badde2b162d26cd836839f2133a6f",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach for evaluating page segmentation algorithms. Unlike techniques that rely on OCR output, our method is region-based: the segmentation output, described as a set of regions together with their types, output order etc., is matched against the pre-stored set of ground-truth regions. Misclassifications, splitting, and merging of regions are among the errors that are detected by the system. Each error is weighted individually for a particular application and a global estimate of segmentation quality is derived. The system can be customized to benchmark specific aspects of segmentation (e.g., headline detection) and according to the type of error correction that might follow (e.g., re-typing). Segmentation ground-truth files are quickly and easily generated and edited using GroundsKeeper, an X-Window based tool that allows one to view a document, manually draw regions (arbitrary polygons) on it, and specify information about each region (e.g., type, parent)."
            },
            "slug": "Ground-truthing-and-benchmarking-document-page-Yanikoglu-Vincent",
            "title": {
                "fragments": [],
                "text": "Ground-truthing and benchmarking document page segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This work describes a new approach for evaluating page segmentation algorithms that is region-based: the segmentation output, described as a set of regions together with their types, output order etc., is matched against the pre-stored set of ground-truth regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16478946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0720209f479d9ad1063cd34ec07bfa896018f2e6",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Both users and developers of OCR systems benefit from objective performance evaluation and benchmarking. The need for improved tests has given additional impetus to research on evaluation methodology. We discuss some of the statistical and combinatorial principles underlying error estimation, propose a taxonomy for reference data, and review evaluation paradigms in current use. We provide pointers to recent work on the evaluation of isolated character classification, text reading, layout analysis, interpretation of hand-printed forms, and line-drawing conversion."
            },
            "slug": "DOCUMENT-IMAGE-ANALYSIS:-AUTOMATED-PERFORMANCE-Nagy",
            "title": {
                "fragments": [],
                "text": "DOCUMENT IMAGE ANALYSIS: AUTOMATED PERFORMANCE EVALUATION"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Some of the statistical and combinatorial principles underlying error estimation are discussed, a taxonomy for reference data is proposed, and evaluation paradigms in current use are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2494216"
                        ],
                        "name": "P. Pyreddy",
                        "slug": "P.-Pyreddy",
                        "structuredName": {
                            "firstName": "Pallavi",
                            "lastName": "Pyreddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pyreddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13991200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d674f1289f336d88c4ab93e7204a345a302ed2eb",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables form an important kind of data element in text retrieval. Often, the gist of an entire news article or other exposition can be concisely captured in tabular form. In this paper, we examine the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities. More specifically, we exploit the structural information in a document to identify tables and their component fields and let the users query based on these fields. Our empirical results have demonstrated that heuristic method based table extraction and component tagging can be performed effectively and efficiently. Moreover, our experiments in retrieval using the TINTIN system have strongly indicated that such structural decomposition can facilitate better representation of user\u2019s information needs and hence more effective retrieval of tables."
            },
            "slug": "TINTIN:-a-system-for-retrieval-in-text-tables-Pyreddy-Croft",
            "title": {
                "fragments": [],
                "text": "TINTIN: a system for retrieval in text tables"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper examines the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities and demonstrates that heuristic method based table extraction and component tagging can be performed effectively and efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "DL '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108023096"
                        ],
                        "name": "Xinxin Wang",
                        "slug": "Xinxin-Wang",
                        "structuredName": {
                            "firstName": "Xinxin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinxin Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "We chose to base our model on Wang\u2019s formalism [20] because it provides a clean separation of content (logical model) from form (physical/presentational model), and offers a rigorous mathematical representation as the logical model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16895319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb8327c5b091ea26e42ed924e25a02c564998f19",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools. A generic model is designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables. The model separates table's logical structure from its layout structure, which consists of tabular topology and typographic style. The notion of an abstract table, which describes the logical relationships among tabular items, is formally defined and a set of logical operations is proposed to manipulate tables based on these logical relationships. An abstract table can be visualized through a layout structure specified by a set of topological rules, which determine the relative placement of tabular items in two dimensions, and a set of style rules, which determine the final appearance of different items. The absolute placement of a concrete table can be automatically generated by applying a layout specification to an abstract line. An NP-complete problem arises in the formatting process that uses automatic line breaking and determines the physical dimension of a table to satisfy user-specified size constraints. An algorithm has been designed to solve the formatting problem in polynomial time for typical tables. Based on the tabular model, a prototype tabular composition system has been implemented in a UNIX, X Windows environment. This prototype provides an interactive interface to edit the logical structure, the topology and the styles of tables. It allows us to manipulate tables based on the logical relationships tabular items, regardless of where the items are placed in the layout structure, and capable of presenting a table in different topologies and styles so that we can select a high-quality layout structure."
            },
            "slug": "Tabular-Abstraction,-Editing,-and-Formatting-Wang",
            "title": {
                "fragments": [],
                "text": "Tabular Abstraction, Editing, and Formatting"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools using a generic model designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791054"
                        ],
                        "name": "A. Sanfeliu",
                        "slug": "A.-Sanfeliu",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Sanfeliu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sanfeliu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 113
                            }
                        ],
                        "text": "For the problem of evaluating structure recognition, there is already a fair amount of theory (see, for example, [6,11,16,17,19])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1087693,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea65866e3d1fd3e3e630005147e373ff7a886009",
            "isKey": false,
            "numCitedBy": 928,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A method to determine a distance measure between two nonhierarchical attributed relational graphs is presented. In order to apply this distance measure, the graphs are characterised by descriptive graph grammars (DGG). The proposed distance measure is based on the computation of the minimum number of modifications required to transform an input graph into the reference one. Specifically, the distance measure is defined as the cost of recognition of nodes plus the number of transformations which include node insertion, node deletion, branch insertion, branch deletion, node label substitution and branch label substitution. The major difference between the proposed distance measure and the other ones is the consideration of the cost of recognition of nodes in the distance computation. In order to do this, the principal features of the nodes are described by one or several cost functions which are used to compute the similarity between the input nodes and the reference ones. Finally, an application of this distance measure to the recognition of lower case handwritten English characters is presented."
            },
            "slug": "A-distance-measure-between-attributed-relational-Sanfeliu-Fu",
            "title": {
                "fragments": [],
                "text": "A distance measure between attributed relational graphs for pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A method to determine a distance measure between two nonhierarchical attributed relational graphs is presented and an application of this distance measure to the recognition of lower case handwritten English characters is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35126865"
                        ],
                        "name": "Yasuto Ishitani",
                        "slug": "Yasuto-Ishitani",
                        "structuredName": {
                            "firstName": "Yasuto",
                            "lastName": "Ishitani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yasuto Ishitani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 113
                            }
                        ],
                        "text": "For the problem of evaluating structure recognition, there is already a fair amount of theory (see, for example, [6,11,16,17,19])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9509988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "293aeae09b87fb5dc091b4572b76f2147fbf2795",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of image understanding for forms based on model matching is proposed in this paper as the basis of OCR which can read a variety of forms. The outline of this method is described as follows. Ruled lines are extracted from the input image of a form. These lines are used for understanding the form, taking into account their feature attributes and the relationships between them. Each line in the input image of a form as expected to correspond to a line in one of the model forms, which are described as structured features. This correspondence is represented by a node in an association graph where an arc represents compatible correspondences established on the basis of feature relationships. The best match is found as the largest maximal clique in the association graph. Experimental results show the method is robust and effective for poor quality document images and also for various styles of forms."
            },
            "slug": "Model-matching-based-on-association-graph-for-form-Ishitani",
            "title": {
                "fragments": [],
                "text": "Model matching based on association graph for form image understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "Experimental results show the proposed method of image understanding for forms based on model matching as the basis of OCR is robust and effective for poor quality document images and also for various styles of forms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809809"
                        ],
                        "name": "L. Shapiro",
                        "slug": "L.-Shapiro",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shapiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3361652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6d7fce10da0ceb8332ec63cdb55e0ee5ce3645e",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Relational models are frequently used in high-level computer vision. Finding a correspondence between a relational model and an image description is an important operation in the analysis of scenes. In this paper the process of finding the correspondence is formalized by defining a general relational distance measure that computes a numeric distance between any two relational descriptions-a model and an image description, two models, or two image descriptions. The distance measure is proved to be a metric, and is illustrated with examples of distance between object models. A variant measure used in our past studies is shown not to be a metric."
            },
            "slug": "A-Metric-for-Comparing-Relational-Descriptions-Shapiro-Haralick",
            "title": {
                "fragments": [],
                "text": "A Metric for Comparing Relational Descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The process of finding the correspondence is formalized by defining a general relational distance measure that computes a numeric distance between any two relational descriptions-a model and an image description, two models, or two image descriptions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145634459"
                        ],
                        "name": "M. Garey",
                        "slug": "M.-Garey",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Garey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444582"
                        ],
                        "name": "David S. Johnson",
                        "slug": "David-S.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 136
                            }
                        ],
                        "text": "The first is that a solution would imply a solution to the graph isomorphism problem which is not likely to have an efficient algorithm [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "Second, any procedure for solving this problem could also be used to solve the directed graph isomorphism problem, which is widely regarded to be hard [2]; hence, it seems unlikely that an efficient optimal algorithm exists."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2211006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdede1e17c947540b50e6e2db9e8467ddc6e7336",
            "isKey": false,
            "numCitedBy": 47653,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Horn formulae play a prominent role in artificial intelligence and logic programming. In this paper we investigate the problem of optimal compression of propositional Horn production rule knowledge bases. The standard approach to this problem, consisting in the removal of redundant rules from a knowledge base, leads to an \"irredundant\" but not necessarily optimal knowledge base. We prove here that the number of rules in any irredundant Horn knowledge base involving n propositional variables is at most n 0 1 times the minimum possible number of rules. In order to formalize the optimal compression problem, we define a Boolean function of a knowledge base as being the function whose set of true points is the set of models of the knowledge base. In this way the optimal compression of production rule knowledge bases becomes a problem of Boolean function minimization. In this paper we prove that the minimization of Horn functions (i.e. Boolean functions associated to Horn knowledge bases) is..."
            },
            "slug": "Computers-and-Intractability:-A-Guide-to-the-Theory-Garey-Johnson",
            "title": {
                "fragments": [],
                "text": "Computers and Intractability: A Guide to the Theory of NP-Completeness"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This is the second edition of a quarterly column the purpose of which is to provide a continuing update to the list of problems (NP-complete and harder) presented by M. R. Garey and myself in the authors' book \u2018\u2018Computers and Intractability: A Guide to the Theory of NP-Completeness\u2019\u2019."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144906845"
                        ],
                        "name": "J. Ousterhout",
                        "slug": "J.-Ousterhout",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Ousterhout",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ousterhout"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "The user interface portions of Daffy are written in Tcl/Tk, a powerful and well-known scripting language developed by Ousterhout [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 24003687,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "867bf3c9754ed15923a93ae17f588543995b47ce",
            "isKey": false,
            "numCitedBy": 2305,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Copyright \u00a9 1993 Addison-Wesley Publishing Company, Inc. All rights reserved. Duplication of this draft is permitted by individuals for personal use only. Any other form of duplication or reproduction requires prior written permission of the author or publisher. This statement must be easily visible on the first page of any reproduced copies. The publisher does not offer warranties in regard to this draft."
            },
            "slug": "Tcl-and-the-Tk-Toolkit-Ousterhout",
            "title": {
                "fragments": [],
                "text": "Tcl and the Tk Toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This draft is intended for educational purposes only and the publisher does not offer warranties in regard to this draft."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3252362"
                        ],
                        "name": "R. Schalkoff",
                        "slug": "R.-Schalkoff",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schalkoff",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schalkoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 223
                            }
                        ],
                        "text": "While it is traditional to regard document analysis results, and segmentation results in particular, as treestructured, we have adopted a slightly more general representation, a directed acyclic attribute graph (DAG) as in [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 113
                            }
                        ],
                        "text": "For the problem of evaluating structure recognition, there is already a fair amount of theory (see, for example, [6,11,16,17,19])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33656944,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cea28c8b2d211110b3e48b4c545420282ea68f67",
            "isKey": false,
            "numCitedBy": 1052,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "STATISTICAL PATTERN RECOGNITION (StatPR). Supervised Learning (Training) Using Parametric and Nonparametric Approaches. Linear Discriminant Functions and the Discrete and Binary Feature Cases. Unsupervised Learning and Clustering. SYNTACTIC PATTERN RECOGNITION (SyntPR). Overview. Syntactic Recognition via Parsing and Other Grammars. Graphical Approaches to SyntPR. Learning via Grammatical Inference. NEURAL PATTERN RECOGNITION (NeurPR). Introduction to Neural Networks. Introduction to Neural Pattern Associators and Matrix Approaches. Feedforward Networks and Training by Backpropagation. Content Addressable Memory Approaches and Unsupervised Learning in NeurPR. Appendices. References. Permission Source Notes. Index."
            },
            "slug": "Pattern-recognition-statistical,-structural-and-Schalkoff",
            "title": {
                "fragments": [],
                "text": "Pattern recognition - statistical, structural and neural approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This chapter discusses supervised learning using Parametric and Nonparametric Approaches and unsupervised Learning in NeurPR, and discusses feedforward Networks and Training by Backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087848"
                        ],
                        "name": "R. Dubes",
                        "slug": "R.-Dubes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dubes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dubes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "This cluster tree is constructed in a bottomup manner [7] \u2013 first, the leaf level clusters are generated where each word belongs to a unique cluster, then the two clusters with the minimum inter-cluster distance are merged into a new cluster."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29535089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa4bddbd10eafd8e1b54338517eedfee408f03ae",
            "isKey": false,
            "numCitedBy": 10559,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-for-Clustering-Data-Jain-Dubes",
            "title": {
                "fragments": [],
                "text": "Algorithms for Clustering Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "In this section we present our approach to evaluating algorithms that extract structure from tables [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "At the other end of the spectrum, we could embed our table recognition algorithm in a query-based table processing system ([4]), and measure the performance of the complete system on a specific task from a user\u2019s perspective: Does it provide the desired information? (This is \u201cgoal-directed evaluation\u201d as discussed by Nagy in [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 150
                            }
                        ],
                        "text": "In this section we describe a method for evaluating the performance of table detection algorithms building on the well-known concept of edit distance [3,4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A system for understanding and reformulating tables"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 4th IAPR International Workshop on Document Analysis Systems,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wilfong : Table structure recognition and its evaluation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "While heuristics exist that are sometimes fast, their worst-case behavior is still exponential (see, for example, [11])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 113
                            }
                        ],
                        "text": "For the problem of evaluating structure recognition, there is already a fair amount of theory (see, for example, [6,11,16,17,19])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient error-tolerant subgraph isomorphism detection"
            },
            "venue": {
                "fragments": [],
                "text": "D. Dori, A. Bruckstein (eds) Shape, structure and pattern recognition, pp 231\u2013 240. World Scientific, Singapore,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vincent : Groundtruthing and benchmarking document page segmentation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bunke : Efficient errortolerant subgraph isomorphism detection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "ventions vary depending on the document type, the subject domain, and the medium (see [9])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automated table processing: an (opinionated) survey"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 3rd IAPR International Workshop on Graphics Recognition,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "We begin by briefly reviewing an algorithm we have developed for locating tables in ASCII and scanned documents [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 135
                            }
                        ],
                        "text": "We have chosen white space correlation and vertical connected component analysis to model specific functions for meritpre and meritapp [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 150
                            }
                        ],
                        "text": "In this section we describe a method for evaluating the performance of table detection algorithms building on the well-known concept of edit distance [3,4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mediumindependent table detection"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Document Recognition and Retrieval VII, San Jose, Calif., USA, IS&T/SPIE Electron Imaging 3967:291\u2013302,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A system for table understanding"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Symposium on Document Image Understanding Technology, pp 55\u201362, Annapolis, Md., USA,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wood : A retargetable table reader"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nagy : Automated table processing : an ( opinionated ) survey"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Evaluating-the-performance-of-table-processing-Hu-Kashi/af42cc46f93bc9cf413770af4f7243f54a31336e?sort=total-citations"
}