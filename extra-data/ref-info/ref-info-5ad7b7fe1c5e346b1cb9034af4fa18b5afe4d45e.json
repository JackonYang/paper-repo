{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3055160"
                        ],
                        "name": "David J. Ittner",
                        "slug": "David-J.-Ittner",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ittner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Ittner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5360061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bc5bf7115142885992f99516169ea24bf18b529",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for isolating blocks, lines, words, and symbols within images of machine-printed textual documents that is, to a large existent, independent of language and writing system is described. This is achieved by exploiting a small number of nearly universal typesetting and layout conventions. The system does not require prior knowledge of page orientation (module 90/spl deg/), and copes well with nonzero skew and shear angles (within 10/spl deg/). Also it locates blocks of text without reliance on detailed a priori layout models, and in spite of unknown or mixed horizontal and vertical text-line orientations. Within blocks, it infers text-line orientation and isolates lines, without knowledge of the language, symbol set, text sizes, or the number of text lines. Segmentation into words and symbols, and determination of reading order, normally require some knowledge of the language: this is held to minimum by relying on shape-driven algorithms. The underlying algorithms are based on Fourier theory, digital signal processing, computational geometry, and statistical decision theory. Most of the computation occurs within algorithms that possess unambiguous semantics (that is, heuristics are kept to a minimum). The effectiveness of the method on English, Japanese, Hebrew, Thai, and Korean documents is discussed.<<ETX>>"
            },
            "slug": "Language-free-layout-analysis-Ittner-Baird",
            "title": {
                "fragments": [],
                "text": "Language-free layout analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A system for isolating blocks, lines, words, and symbols within images of machine-printed textual documents that is, to a large existent, independent of language and writing system is described, achieved by exploiting a small number of nearly universal typesetting and layout conventions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054537234"
                        ],
                        "name": "H. Kojima",
                        "slug": "H.-Kojima",
                        "structuredName": {
                            "firstName": "Haruhiko",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kojima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50738156"
                        ],
                        "name": "Teruo Akiyama",
                        "slug": "Teruo-Akiyama",
                        "structuredName": {
                            "firstName": "Teruo",
                            "lastName": "Akiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Teruo Akiyama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61101631,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c61270cb21fcfd1115126ba0abc053ea2bf731da",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Most documents include various layout objects such as headlines text lines charts and tables. In particular tables are powerful tools that allow large quantities of data to be easily understood. An automated document entry system is needed that can recognize the document layout objects and extract the information from tables. In this paper an effective table recognition method is described. The proposed method is composed of three steps: (1) document layout structure recognition (2) table layout structure recognition (3) table content recognition. To develop the table layout structure recognition step we first examined the layout structure of tables in existing documents and classified several common structures. As a result of the examination we created ten rules and designed a ruled line and box extraction algorithm based on these rules. The effectiveness of the proposed method has been confirmed in experiments. Accordingly the proposed method will greatly contribute to the creation of an automated document entry system to allow faster document recognition and permit the data in tables to be extracted."
            },
            "slug": "Table-recognition-for-automated-document-entry-Kojima-Akiyama",
            "title": {
                "fragments": [],
                "text": "Table recognition for automated document entry system"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The effectiveness of the proposed table recognition method has been confirmed and will greatly contribute to the creation of an automated document entry system to allow faster document recognition and permit the data in tables to be extracted."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741958"
                        ],
                        "name": "Katsuhiko Itonori",
                        "slug": "Katsuhiko-Itonori",
                        "structuredName": {
                            "firstName": "Katsuhiko",
                            "lastName": "Itonori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katsuhiko Itonori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2755403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a924e8096b3bd1b287cb4d07cc27a93b33fdfd07",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a new method to recognize table structures from document images. Each cell of a table is arranged regularly in two dimensions and is represented by a row-column pair. Even in the absence of ruled lines, its coordinates are explicitly found. Thus, it is assumed that an arrangement of textblocks defines the table structure, which is an arrangement of rows and columns, and ruled lines make clear their relationship. This process is composed of two procedures: the expansion of cell bounding boxes and the assignment of row-column numbers to each edge. It is shown that the method can be applied to partially ruled tables with some experimental results.<<ETX>>"
            },
            "slug": "Table-structure-recognition-based-on-textblock-and-Itonori",
            "title": {
                "fragments": [],
                "text": "Table structure recognition based on textblock arrangement and ruled line position"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new method to recognize table structures from document images is described, which is composed of the expansion of cell bounding boxes and the assignment of row-column numbers to each edge."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69485492"
                        ],
                        "name": "D. R. Ferguson",
                        "slug": "D.-R.-Ferguson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ferguson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. R. Ferguson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29472483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45bdf2e5368886fd77f7542d797f58909ce3a169",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The automatic reading of optically scanned forms consists of two major components: extraction of the data image from the form and interpretation of the image as coded alphanumerics. The second component is also known as optical character recognition, or OCR. We have implemented a method for entry of a wide variety of forms that contain machine-printed data and that are often produced in business environments. The function, called Intelligent Forms Processing (IFP), accepts conventional forms that call for information to be printed in designated blank areas, but in which the information may exceed boundaries due to poor registration during printing. The human eye easily accommodates data that impinge on form boundaries or on background text; however, the same powers of discrimination applied to machine processing pose a technical challenge. The IFP system uses a setup phase to create a model of each form that is to be read. Scanned forms containing data are compared against the matching form model. Special algorithms are employed to extract data fields while removing background printing (e.g., form lines) intersecting the data. The extracted data images are interpreted by an OCR process that reads typical monospace fonts. New fonts may be added easily in a separate design mode. If the data are alphabetic, a lexicon may be assembled to define the possible entries."
            },
            "slug": "Intelligent-Forms-Processing-Casey-Ferguson",
            "title": {
                "fragments": [],
                "text": "Intelligent Forms Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The automatic reading of optically scanned forms consists of two major components: extraction of the data image from the form and interpretation of the image as coded alphanumerics, also known as optical character recognition, or OCR."
            },
            "venue": {
                "fragments": [],
                "text": "IBM Syst. J."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48572350"
                        ],
                        "name": "S. Lam",
                        "slug": "S.-Lam",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Lam",
                            "middleNames": [
                                "Wang-Cheung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398880839"
                        ],
                        "name": "L. Javanbakht",
                        "slug": "L.-Javanbakht",
                        "structuredName": {
                            "firstName": "Ladan",
                            "lastName": "Javanbakht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Javanbakht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The literature on automatic analysis of forms (in our sense) is large: [CF90], [KA90], [PTGSl], [TFP92], and [ LJS93 ] are representative early examples."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 206774379,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1462c98095382d867cb9d026988ed6e3455f9617",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Forms are used extensively in today's offices. The task of an automated form reader is to locate data filled on a form and to encode the content into appropriate symbolic descriptions. The challenges in form reading are due to high volume and large variety. A robust form reader with high adaptability and trainability. The form reader consists of two modules: field registration and data recognition module. The field registration module acquires knowledge about the forms of interest and the data recognition module recognizes text data on filled forms using the acquired knowledge. The capability of the reader increases progressively through supervised learning. The form reader has been training to read a large variety of forms with machine-printed data. The adaptability and trainability of the system have been demonstrated through the experiments.<<ETX>>"
            },
            "slug": "Anatomy-of-a-form-reader-Lam-Javanbakht",
            "title": {
                "fragments": [],
                "text": "Anatomy of a form reader"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A robust form reader with high adaptability and trainability, training to read a large variety of forms with machine-printed data is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692608"
                        ],
                        "name": "N. Sugie",
                        "slug": "N.-Sugie",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Sugie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sugie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23198522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa208b677239912cb394e5dbc6e7483a75f16ea4",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Many approaches have reported that knowledge-based layout recognition methods are very successful in classifying the meaningful data from document images automatically. However, these approaches are applicable to only the same kind of documents because they are based on the paradigm that specifies the structure definition information in advance so as to be able to analyze a particular class of documents intelligently. In this paper, the authors propose a method to recognize the layout structures of multi-kinds of table-form document images. For this purpose, the authors introduce a classification tree to manage the relationships among different classes of layout structures. The authors' recognition system has two modes: layout knowledge acquisition and layout structure recognition. In the layout knowledge acquisition mode, table-form document images are distinguished according to this. Classification tree and then the structure description trees which specify the logical structures of table-form documents are generated automatically. While, in the layout structure recognition mode, individual item fields in the table-form document images are extracted and classified successfully by searching the classification tree and interpreting the structure description tree. >"
            },
            "slug": "Layout-Recognition-of-Multi-Kinds-of-Table-Form-Watanabe-Luo",
            "title": {
                "fragments": [],
                "text": "Layout Recognition of Multi-Kinds of Table-Form Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors introduce a classification tree to manage the relationships among different classes of layout structures and propose a method to recognize the layout structures of multi-kinds of table-form document images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728727"
                        ],
                        "name": "A. Laurentini",
                        "slug": "A.-Laurentini",
                        "structuredName": {
                            "firstName": "Aldo",
                            "lastName": "Laurentini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Laurentini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73412977"
                        ],
                        "name": "P. Viada",
                        "slug": "P.-Viada",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Viada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Viada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61361377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b22149f09750ef752196a7a31d0adccb762d14f0",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are important components of technical documents. This paper addresses the following problems: (i) identifying a tabular component in a scanned image of a compound document containing text, drawings, diagrams, etc.; (ii) understanding the content of the table in order to convert the table into electronic format. As far as the authors are aware, the problems addressed are new. An algorithm for performing both the above tasks has been studied and implemented. Preliminary experimental results indicate satisfactory performance for many table lay-out styles.<<ETX>>"
            },
            "slug": "Identifying-and-understanding-tabular-material-in-Laurentini-Viada",
            "title": {
                "fragments": [],
                "text": "Identifying and understanding tabular material in compound documents"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This paper addresses the following problems: identifying a tabular component in a scanned image of a compound document containing text, drawings, diagrams, etc."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143772136"
                        ],
                        "name": "O. Hori",
                        "slug": "O.-Hori",
                        "structuredName": {
                            "firstName": "Osamu",
                            "lastName": "Hori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Hori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The research literature does not consistently distinguish\u2019between \u201ctables\u201d and \u201cforms\u201d: for example, [TS94, WLS95, GK95,  HD95 , Ishi951 use the terms \u2018form,\u2019 \u2018table,\u2019 and \u2018table form\u2019 almost interchangeably."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2750254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92e74fde9c613dd22c193bb11d889d7a0428bced",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Table form document structure analysis is an important problem in the document processing domain. The paper presents a method called Box Driven Reasoning (BDR) to robustly analyze the structure of table form documents which include touching characters and broken lines. Most previous methods employ a line oriented approach. Real documents are copied repeatedly and overlaid with printed data, resulting in characters which touch cells and lines which are broken. BDR deals with regions directly, in contrast with other previous methods. Experimental tests show that BDR reliably recognizes cells and strings in document images with touching characters and broken lines."
            },
            "slug": "Robust-table-form-structure-analysis-based-on-Hori-Doermann",
            "title": {
                "fragments": [],
                "text": "Robust table-form structure analysis based on box-driven reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A method called Box Driven Reasoning (BDR) is presented to robustly analyze the structure of table form documents which include touching characters and broken lines."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144881104"
                        ],
                        "name": "E. A. Green",
                        "slug": "E.-A.-Green",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Green",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. A. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 866386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecb5fdcdeff0d56ebf61b151ac8617ae3b30881e",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a strategy for extracting the underlying relational information from the images of printed tables. Visual clues that exist in the image are used for extracting first the physical, and then the logical structure of the table. Since these visual clues generally have a logical meaning, there must be some association made between the graphical attributes extracted and their function of reflecting the logic expressed by the table; this knowledge is coordinated in a model. This approach, therefore, can be adapted to all tables which have graphical attributes discernible to the image analysis being used."
            },
            "slug": "Model-based-analysis-of-printed-tables-Green-Krishnamoorthy",
            "title": {
                "fragments": [],
                "text": "Model-based analysis of printed tables"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This strategy for extracting the underlying relational information from the images of printed tables is developed and can be adapted to all tables which have graphical attributes discernible to the image analysis being used."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25727408"
                        ],
                        "name": "Surekha Chandran",
                        "slug": "Surekha-Chandran",
                        "structuredName": {
                            "firstName": "Surekha",
                            "lastName": "Chandran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Surekha Chandran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30719791,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "4c8cb8fd8a87ff2e60094385492a13c30977554b",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for extraction of structural information of a table from its image is discussed. Following the initial binarization and deskewing operations, the image is scanned to extract all horizontal and vertical lines that are present. The table's dimensions are estimated based on these lines. Unlike other systems, the procedure described does not depend on the sole existence of lines to mark the item blocks. White streams are recognized in both the horizontal and vertical direction as substitutes for any missing demarcation lines. A structure interpretation procedure uses the extracted demarcation information to identify each of the item blocks in the table. Subsequently, the interrelations of these item blocks are used to recognize the structure of the tabulated data.<<ETX>>"
            },
            "slug": "Structural-recognition-of-tabulated-data-Chandran-Kasturi",
            "title": {
                "fragments": [],
                "text": "Structural recognition of tabulated data"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A system for extraction of structural information of a table from its image using white streams as substitutes for any missing demarcation lines to identify each of the item blocks in the table."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35126865"
                        ],
                        "name": "Yasuto Ishitani",
                        "slug": "Yasuto-Ishitani",
                        "structuredName": {
                            "firstName": "Yasuto",
                            "lastName": "Ishitani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yasuto Ishitani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9509988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "293aeae09b87fb5dc091b4572b76f2147fbf2795",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of image understanding for forms based on model matching is proposed in this paper as the basis of OCR which can read a variety of forms. The outline of this method is described as follows. Ruled lines are extracted from the input image of a form. These lines are used for understanding the form, taking into account their feature attributes and the relationships between them. Each line in the input image of a form as expected to correspond to a line in one of the model forms, which are described as structured features. This correspondence is represented by a node in an association graph where an arc represents compatible correspondences established on the basis of feature relationships. The best match is found as the largest maximal clique in the association graph. Experimental results show the method is robust and effective for poor quality document images and also for various styles of forms."
            },
            "slug": "Model-matching-based-on-association-graph-for-form-Ishitani",
            "title": {
                "fragments": [],
                "text": "Model matching based on association graph for form image understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "Experimental results show the proposed method of image understanding for forms based on model matching as the basis of OCR is robust and effective for poor quality document images and also for various styles of forms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775803"
                        ],
                        "name": "A. Pizano",
                        "slug": "A.-Pizano",
                        "structuredName": {
                            "firstName": "Arturo",
                            "lastName": "Pizano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pizano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118278778"
                        ],
                        "name": "May-Inn Tan",
                        "slug": "May-Inn-Tan",
                        "structuredName": {
                            "firstName": "May-Inn",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "May-Inn Tan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7827912"
                        ],
                        "name": "Naoto Gambo",
                        "slug": "Naoto-Gambo",
                        "structuredName": {
                            "firstName": "Naoto",
                            "lastName": "Gambo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naoto Gambo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37925986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa9cfb776a79460645f77703c96a0e3430b5a8c1",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A pattern recognition system is described that classifies digitized images of business forms according to a predefined set of templates. The process involves a training phase, where images of the template forms are scanned, analyzed and stored in a data dictionary; and a recognition phase, during which scanned form images are compared to templates in a dictionary to determine their class membership. The system has been tested under a variety of conditions and its performance has been proven to be satisfactory.<<ETX>>"
            },
            "slug": "A-business-form-recognition-system-Pizano-Tan",
            "title": {
                "fragments": [],
                "text": "A business form recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A pattern recognition system is described that classifies digitized images of business forms according to a predefined set of templates and its performance has been proven to be satisfactory."
            },
            "venue": {
                "fragments": [],
                "text": "[1991] Proceedings The Fifteenth Annual International Computer Software & Applications Conference"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39702442"
                        ],
                        "name": "Y. Tang",
                        "slug": "Y.-Tang",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Tang",
                            "middleNames": [
                                "Yan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The research literature does not consistently distinguish\u2019between \u201ctables\u201d and \u201cforms\u201d: for example, [ TS94 , WLS95, GK95, HD95, Ishi951 use the terms \u2018form,\u2019 \u2018table,\u2019 and \u2018table form\u2019 almost interchangeably."
                    },
                    "intents": []
                }
            ],
            "corpusId": 33614585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a064a18faf98b33d876b05d733c58031b148a655",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowing the structure of a document is the key to successful processing of that document. From different points of view, there exist different definitions for document structures. A survey which contains a collection of many methods of describing document structures is presented. Several novel concepts and theoretical analyses are also presented in this survey.<<ETX>>"
            },
            "slug": "Document-structures:-A-survey-Tang-Suen",
            "title": {
                "fragments": [],
                "text": "Document structures: A survey"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A survey which contains a collection of many methods of describing document structures is presented and several novel concepts and theoretical analyses are also presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776424"
                        ],
                        "name": "Eduard S\u00e4ckinger",
                        "slug": "Eduard-S\u00e4ckinger",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "S\u00e4ckinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduard S\u00e4ckinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120242409"
                        ],
                        "name": "J. Bromley",
                        "slug": "J.-Bromley",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Bromley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bromley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15574589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8bc656a1935f07e894833b608cc4671b9fa828f",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural network with 136000 connections for recognition of handwritten digits has been implemented using a mixed analog/digital neural network chip. The neural network chip is capable of processing 1000 characters/s. The recognition system has essentially the same rate (5%) as a simulation of the network with 32-b floating-point precision."
            },
            "slug": "Application-of-the-ANNA-neural-network-chip-to-S\u00e4ckinger-Boser",
            "title": {
                "fragments": [],
                "text": "Application of the ANNA neural network chip to high-speed character recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A neural network with 136000 connections for recognition of handwritten digits has been implemented using a mixed analog/digital neural network chip, capable of processing 1000 characters/s."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642099"
                        ],
                        "name": "F. Dubiel",
                        "slug": "F.-Dubiel",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Dubiel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Dubiel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29182513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5e263bb44c616c07479832d6b31d16a2b761870",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Formclas-a-System-for-OCR-Free-identification-of-Dubiel-Dengel",
            "title": {
                "fragments": [],
                "text": "Formclas - a System for OCR Free identification of Forms"
            },
            "venue": {
                "fragments": [],
                "text": "DAS"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cambo, \u201cA Business Form Recognition System,"
            },
            "venue": {
                "fragments": [],
                "text": "Ptoc.. Comput. Software Applrc. Conf.,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experiences with High-Volume, HighAccuracy Document Capture,"
            },
            "venue": {
                "fragments": [],
                "text": "Wurkshop on Document Analysis Systems"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/A-retargetable-table-reader-Shamilian-Baird/5ad7b7fe1c5e346b1cb9034af4fa18b5afe4d45e?sort=total-citations"
}