{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145307652"
                        ],
                        "name": "Li Dong",
                        "slug": "Li-Dong",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 96
                            }
                        ],
                        "text": ", 2015) has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 31
                            }
                        ],
                        "text": "Examples include tree decoders (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017), decoders constrained by a grammar model (Xiao et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 111
                            }
                        ],
                        "text": "More recently, neural sequence-to-sequence models have been applied to semantic parsing with promising results (Dong and Lapata, 2016; Jia and Liang, 2016; Ling et al., 2016), eschewing the need for extensive feature engineering."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15412473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "558ac446dc26bee9789d660a251b75728cb6eeb2",
            "isKey": false,
            "numCitedBy": 553,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic parsing aims at mapping natural language to machine interpretable meaning representations. Traditional approaches rely on high-quality lexicons, manually-built templates, and linguistic features which are either domain- or representation-specific. In this paper we present a general method based on an attention-enhanced encoder-decoder model. We encode input utterances into vector representations, and generate their logical forms by conditioning the output sequences or trees on the encoding vectors. Experimental results on four datasets show that our approach performs competitively without using hand-engineered features and is easy to adapt across domains and meaning representations."
            },
            "slug": "Language-to-Logical-Form-with-Neural-Attention-Dong-Lapata",
            "title": {
                "fragments": [],
                "text": "Language to Logical Form with Neural Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a general method based on an attention-enhanced encoder-decoder model that encode input utterances into vector representations, and generate their logical forms by conditioning the output sequences or trees on the encoding vectors."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1941442"
                        ],
                        "name": "Jianpeng Cheng",
                        "slug": "Jianpeng-Cheng",
                        "structuredName": {
                            "firstName": "Jianpeng",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianpeng Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145732771"
                        ],
                        "name": "Siva Reddy",
                        "slug": "Siva-Reddy",
                        "structuredName": {
                            "firstName": "Siva",
                            "lastName": "Reddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siva Reddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714061"
                        ],
                        "name": "V. Saraswat",
                        "slug": "V.-Saraswat",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Saraswat",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Saraswat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Cheng et al. (2017)\nuse a transition system to generate variable-free queries."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Preprocessing For GEO and ATIS, we used the preprocessed versions provided by Dong and Lapata (2016), where natural language expressions are lowercased and stemmed with NLTK (Bird et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2423360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db5be062d8b26b2e636b57cc8ca9761b673ec0e6",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a neural semantic parser which is interpretable and scalable. Our model converts natural language utterances to intermediate, domain-general natural language representations in the form of predicate-argument structures, which are induced with a transition system and subsequently mapped to target domains. The semantic parser is trained end-to-end using annotated logical forms or their denotations. We achieve the state of the art on SPADES and GRAPHQUESTIONS and obtain competitive results on GEOQUERY and WEBQUESTIONS. The induced predicate-argument structures shed light on the types of representations useful for semantic parsing and how these are different from linguistically motivated ones."
            },
            "slug": "Learning-Structured-Natural-Language-for-Semantic-Cheng-Reddy",
            "title": {
                "fragments": [],
                "text": "Learning Structured Natural Language Representations for Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A neural semantic parser which is interpretable and scalable, which converts natural language utterances to intermediate, domain-general natural language representations in the form of predicate-argument structures, which are induced with a transition system and subsequently mapped to target domains."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47426264"
                        ],
                        "name": "Jonathan Herzig",
                        "slug": "Jonathan-Herzig",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Herzig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Herzig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750652"
                        ],
                        "name": "Jonathan Berant",
                        "slug": "Jonathan-Berant",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Berant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Berant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 78
                            }
                        ],
                        "text": ", 2017), sharing parameters for multiple languages or meaning representations (Susanto and Lu, 2017; Herzig and Berant, 2017), and utilizing user feedback signals (Iyer et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14215409,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc7fcefa3e333d50463d524406d107060c4a0cec",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A fundamental challenge in developing semantic parsers is the paucity of strong supervision in the form of language utterances annotated with logical form. In this paper, we propose to exploit structural regularities in language in different domains, and train semantic parsers over multiple knowledge-bases (KBs), while sharing information across datasets. We find that we can substantially improve parsing accuracy by training a single sequence-to-sequence model over multiple KBs, when providing an encoding of the domain at decoding time. Our model achieves state-of-the-art performance on the Overnight dataset (containing eight domains), improves performance over a single KB baseline from 75.6% to 79.6%, while obtaining a 7x reduction in the number of model parameters."
            },
            "slug": "Neural-Semantic-Parsing-over-Multiple-Herzig-Berant",
            "title": {
                "fragments": [],
                "text": "Neural Semantic Parsing over Multiple Knowledge-bases"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper finds that it can substantially improve parsing accuracy by training a single sequence-to-sequence model over multiple KBs, when providing an encoding of the domain at decoding time."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117800368"
                        ],
                        "name": "Xing Fan",
                        "slug": "Xing-Fan",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38722908"
                        ],
                        "name": "Emilio Monti",
                        "slug": "Emilio-Monti",
                        "structuredName": {
                            "firstName": "Emilio",
                            "lastName": "Monti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emilio Monti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36299222"
                        ],
                        "name": "Lambert Mathias",
                        "slug": "Lambert-Mathias",
                        "structuredName": {
                            "firstName": "Lambert",
                            "lastName": "Mathias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lambert Mathias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40262269"
                        ],
                        "name": "Markus Dreyer",
                        "slug": "Markus-Dreyer",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Dreyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Dreyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 48
                            }
                        ],
                        "text": ", 2016; Jia and Liang, 2016), transfer learning (Fan et al., 2017), sharing parameters for multiple languages or meaning representations (Susanto and Lu, 2017; Herzig and Berant, 2017), and utilizing user feedback signals (Iyer et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 148
                            }
                        ],
                        "text": "\u2026been explored to enhance the performance of these models such as data augmentation (Koc\u030cisky\u0301 et al., 2016; Jia and Liang, 2016), transfer learning (Fan et al., 2017), sharing parameters for multiple languages or meaning representations (Susanto and Lu, 2017; Herzig and Berant, 2017), and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5955929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22ae9a4d587df06184a9ac2fa703a2d48b8edebd",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of semantic parsing is to map natural language to a machine interpretable meaning representation language (MRL). One of the constraints that limits full exploration of deep learning technologies for semantic parsing is the lack of sufficient annotation training data. In this paper, we propose using sequence-to-sequence in a multi-task setup for semantic parsing with focus on transfer learning. We explore three multi-task architectures for sequence-to-sequence model and compare their performance with the independently trained model. Our experiments show that the multi-task setup aids transfer learning from an auxiliary task with large labeled data to the target task with smaller labeled data. We see an absolute accuracy gain ranging from 1.0% to 4.4% in in our in-house data set and we also see good gains ranging from 2.5% to 7.0% on the ATIS semantic parsing tasks with syntactic and semantic auxiliary tasks."
            },
            "slug": "Transfer-Learning-for-Neural-Semantic-Parsing-Fan-Monti",
            "title": {
                "fragments": [],
                "text": "Transfer Learning for Neural Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes using sequence-to-sequence in a multi- task setup for semantic parsing with focus on transfer learning and shows that the multi-task setup aids transfer learning from an auxiliary task with large labeled data to the target task with smaller labeled data."
            },
            "venue": {
                "fragments": [],
                "text": "Rep4NLP@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143844110"
                        ],
                        "name": "Wei Lu",
                        "slug": "Wei-Lu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740222"
                        ],
                        "name": "Wee Sun Lee",
                        "slug": "Wee-Sun-Lee",
                        "structuredName": {
                            "firstName": "Wee",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wee Sun Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 336,
                                "start": 151
                            }
                        ],
                        "text": "Various models have been proposed over the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 212
                            }
                        ],
                        "text": "\u2026the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8045822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d39d39a6246c13928bbd66d122f3e61e67b584ef",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an algorithm for learning a generative model of natural language sentences together with their formal meaning representations with hierarchical structures. The model is applied to the task of mapping sentences to hierarchical representations of their underlying meaning. We introduce dynamic programming techniques for efficient training and decoding. In experiments, we demonstrate that the model, when coupled with a discriminative reranking technique, achieves state-of-the-art performance when tested on two publicly available corpora. The generative model degrades robustly when presented with instances that are different from those seen in training. This allows a notable improvement in recall compared to previous models."
            },
            "slug": "A-Generative-Model-for-Parsing-Natural-Language-to-Lu-Ng",
            "title": {
                "fragments": [],
                "text": "A Generative Model for Parsing Natural Language to Meaning Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The generative model is applied to the task of mapping sentences to hierarchical representations of their underlying meaning and achieves state-of-the-art performance when tested on two publicly available corpora."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422908"
                        ],
                        "name": "Robin Jia",
                        "slug": "Robin-Jia",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robin Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 102
                            }
                        ],
                        "text": "Several ideas have been explored to enhance the performance of these models such as data augmentation (Ko\u010disk\u00fd et al., 2016; Jia and Liang, 2016), transfer learning (Fan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 96
                            }
                        ],
                        "text": ", 2015) has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 111
                            }
                        ],
                        "text": "More recently, neural sequence-to-sequence models have been applied to semantic parsing with promising results (Dong and Lapata, 2016; Jia and Liang, 2016; Ling et al., 2016), eschewing the need for extensive feature engineering."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 46
                            }
                        ],
                        "text": "We handle OOV tokens with a copying mechanism (Gu et al., 2016; Gulcehre et al., 2016; Jia and Liang, 2016), which allows the fine meaning decoder (Section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7218315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7eac64a8410976759445cce235469163d23ee65",
            "isKey": true,
            "numCitedBy": 378,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling crisp logical regularities is crucial in semantic parsing, making it difficult for neural models with no task-specific prior knowledge to achieve good results. In this paper, we introduce data recombination, a novel framework for injecting such prior knowledge into a model. From the training data, we induce a high-precision synchronous context-free grammar, which captures important conditional independence properties commonly found in semantic parsing. We then train a sequence-to-sequence recurrent network (RNN) model with a novel attention-based copying mechanism on datapoints sampled from this grammar, thereby teaching the model about these structural properties. Data recombination improves the accuracy of our RNN model on three semantic parsing datasets, leading to new state-of-the-art performance on the standard GeoQuery dataset for models with comparable supervision."
            },
            "slug": "Data-Recombination-for-Neural-Semantic-Parsing-Jia-Liang",
            "title": {
                "fragments": [],
                "text": "Data Recombination for Neural Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Data recombination improves the accuracy of the RNN model on three semantic parsing datasets, leading to new state-of-the-art performance on the standard GeoQuery dataset for models with comparable supervision."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759772"
                        ],
                        "name": "Hoifung Poon",
                        "slug": "Hoifung-Poon",
                        "structuredName": {
                            "firstName": "Hoifung",
                            "lastName": "Poon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hoifung Poon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "8 GUSP++ (Poon, 2013) \u2014 83."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17281973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd78a271722fb9e0eaade4208860398de1d80b7f",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the first unsupervised approach for semantic parsing that rivals the accuracy of supervised approaches in translating natural-language questions to database queries. Our GUSP system produces a semantic parse by annotating the dependency-tree nodes and edges with latent states, and learns a probabilistic grammar using EM. To compensate for the lack of example annotations or question-answer pairs, GUSP adopts a novel grounded-learning approach to leverage database for indirect supervision. On the challenging ATIS dataset, GUSP attained an accuracy of 84%, effectively tying with the best published results by supervised approaches."
            },
            "slug": "Grounded-Unsupervised-Semantic-Parsing-Poon",
            "title": {
                "fragments": [],
                "text": "Grounded Unsupervised Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This work presents the first unsupervised approach for semantic parsing that rivals the accuracy of supervised approaches in translating natural-language questions to database queries, and adopts a novel grounded-learning approach to leverage database for indirect supervision."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33945581"
                        ],
                        "name": "Chunyang Xiao",
                        "slug": "Chunyang-Xiao",
                        "structuredName": {
                            "firstName": "Chunyang",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chunyang Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2954698"
                        ],
                        "name": "Marc Dymetman",
                        "slug": "Marc-Dymetman",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Dymetman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Dymetman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794075"
                        ],
                        "name": "Claire Gardent",
                        "slug": "Claire-Gardent",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Gardent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Gardent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 131
                            }
                        ],
                        "text": "Examples include tree decoders (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017), decoders constrained by a grammar model (Xiao et al., 2016; Yin and Neubig, 2017; Krishnamurthy et al., 2017), or modular\ndecoders which use syntax to dynamically compose various submodels (Rabinovich et al.,\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 130
                            }
                        ],
                        "text": "Examples include tree decoders (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017), decoders constrained by a grammar model (Xiao et al., 2016; Yin and Neubig, 2017; Krishnamurthy et al., 2017), or modular decoders which use syntax to dynamically compose various submodels (Rabinovich et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Xiao et al. (2016) and Krishnamurthy et al. (2017) employ the grammar to constrain the decoding process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16911296,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcf16c08a41009d9f9174c6f72b2ff534232c147",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach for semantic parsing that uses a recurrent neural network to map a natural language question into a logical form representation of a KB query. Building on recent work by (Wang et al., 2015), the interpretable logical forms, which are structured objects obeying certain constraints, are enumerated by an underlying grammar and are paired with their canonical realizations. In order to use sequence prediction, we need to sequentialize these logical forms. We compare three sequentializations: a direct linearization of the logical form, a linearization of the associated canonical realization, and a sequence consisting of derivation steps relative to the underlying grammar. We also show how grammatical constraints on the derivation sequence can easily be integrated inside the RNN-based sequential predictor. Our experiments show important improvements over previous results for the same dataset, and also demonstrate the advantage of incorporating the grammatical constraints."
            },
            "slug": "Sequence-based-Structured-Prediction-for-Semantic-Xiao-Dymetman",
            "title": {
                "fragments": [],
                "text": "Sequence-based Structured Prediction for Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An approach for semantic parsing that uses a recurrent neural network to map a natural language question into a logical form representation of a KB query and shows how grammatical constraints on the derivation sequence can easily be integrated inside the RNN-based sequential predictor."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112400"
                        ],
                        "name": "Jacob Andreas",
                        "slug": "Jacob-Andreas",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Andreas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Andreas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064056928"
                        ],
                        "name": "Andreas Vlachos",
                        "slug": "Andreas-Vlachos",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Vlachos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Vlachos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 336,
                                "start": 151
                            }
                        ],
                        "text": "Various models have been proposed over the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 255
                            }
                        ],
                        "text": "\u2026the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1954146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50c651e9f94f9d4927a726af0ef44818179d87da",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic parsing is the problem of deriving a structured meaning representation from a natural language utterance. Here we approach it as a straightforward machine translation task, and demonstrate that standard machine translation components can be adapted into a semantic parser. In experiments on the multilingual GeoQuery corpus we find that our parser is competitive with the state of the art, and in some cases achieves higher accuracy than recently proposed purpose-built systems. These results support the use of machine translation methods as an informative baseline in semantic parsing evaluations, and suggest that research in semantic parsing could benefit from advances in machine translation."
            },
            "slug": "Semantic-Parsing-as-Machine-Translation-Andreas-Vlachos",
            "title": {
                "fragments": [],
                "text": "Semantic Parsing as Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This work approaches semantic parsing as a straightforward machine translation task, and demonstrates that standard machine translation components can be adapted into a semantic parser that is competitive with the state of the art, and achieves higher accuracy than recently proposed purpose-built systems."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3167681"
                        ],
                        "name": "Yoav Artzi",
                        "slug": "Yoav-Artzi",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Artzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Artzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Artzi and Zettlemoyer (2013) and Zhang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9963298,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cde902f11b0870c695428d865a35eb819b1d24b7",
            "isKey": false,
            "numCitedBy": 433,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "The context in which language is used provides a strong signal for learning to recover its meaning. In this paper, we show it can be used within a grounded CCG semantic parsing approach that learns a joint model of meaning and context for interpreting and executing natural language instructions, using various types of weak supervision. The joint nature provides crucial benefits by allowing situated cues, such as the set of visible objects, to directly influence learning. It also enables algorithms that learn while executing instructions, for example by trying to replicate human actions. Experiments on a benchmark navigational dataset demonstrate strong performance under differing forms of supervision, including correctly executing 60% more instruction sets relative to the previous state of the art."
            },
            "slug": "Weakly-Supervised-Learning-of-Semantic-Parsers-for-Artzi-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper shows semantic parsing can be used within a grounded CCG semantic parsing approach that learns a joint model of meaning and context for interpreting and executing natural language instructions, using various types of weak supervision."
            },
            "venue": {
                "fragments": [],
                "text": "Transactions of the Association for Computational Linguistics"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2517825"
                        ],
                        "name": "J. Krishnamurthy",
                        "slug": "J.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Krishnamurthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2697425"
                        ],
                        "name": "Pradeep Dasigi",
                        "slug": "Pradeep-Dasigi",
                        "structuredName": {
                            "firstName": "Pradeep",
                            "lastName": "Dasigi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pradeep Dasigi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40642935"
                        ],
                        "name": "Matt Gardner",
                        "slug": "Matt-Gardner",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Gardner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Gardner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 130
                            }
                        ],
                        "text": "Examples include tree decoders (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017), decoders constrained by a grammar model (Xiao et al., 2016; Yin and Neubig, 2017; Krishnamurthy et al., 2017), or modular decoders which use syntax to dynamically compose various submodels (Rabinovich et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 23
                            }
                        ],
                        "text": "Xiao et al. (2016) and Krishnamurthy et al. (2017) employ the grammar to constrain the decoding process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 164
                            }
                        ],
                        "text": "\u2026include tree decoders (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017), decoders constrained by a grammar model (Xiao et al., 2016; Yin and Neubig, 2017; Krishnamurthy et al., 2017), or modular\ndecoders which use syntax to dynamically compose various submodels (Rabinovich et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1675452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c6f58ed0ebf379858c0bbe02c53ee51b3eb398a",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new semantic parsing model for answering compositional questions on semi-structured Wikipedia tables. Our parser is an encoder-decoder neural network with two key technical innovations: (1) a grammar for the decoder that only generates well-typed logical forms; and (2) an entity embedding and linking module that identifies entity mentions while generalizing across tables. We also introduce a novel method for training our neural model with question-answer supervision. On the WikiTableQuestions data set, our parser achieves a state-of-the-art accuracy of 43.3% for a single model and 45.9% for a 5-model ensemble, improving on the best prior score of 38.7% set by a 15-model ensemble. These results suggest that type constraints and entity linking are valuable components to incorporate in neural semantic parsers."
            },
            "slug": "Neural-Semantic-Parsing-with-Type-Constraints-for-Krishnamurthy-Dasigi",
            "title": {
                "fragments": [],
                "text": "Neural Semantic Parsing with Type Constraints for Semi-Structured Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A new semantic parsing model for answering compositional questions on semi-structured Wikipedia tables with a state-of-the-art accuracy and type constraints and entity linking are valuable components to incorporate in neural semantic parsers."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367821"
                        ],
                        "name": "Tom\u00e1s Kocisk\u00fd",
                        "slug": "Tom\u00e1s-Kocisk\u00fd",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Kocisk\u00fd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom\u00e1s Kocisk\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94303026"
                        ],
                        "name": "G\u00e1bor Melis",
                        "slug": "G\u00e1bor-Melis",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Melis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G\u00e1bor Melis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1864353"
                        ],
                        "name": "Edward Grefenstette",
                        "slug": "Edward-Grefenstette",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Grefenstette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1379953252"
                        ],
                        "name": "Wang Ling",
                        "slug": "Wang-Ling",
                        "structuredName": {
                            "firstName": "Wang",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685771"
                        ],
                        "name": "P. Blunsom",
                        "slug": "P.-Blunsom",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Blunsom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Blunsom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910877"
                        ],
                        "name": "K. Hermann",
                        "slug": "K.-Hermann",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Hermann",
                            "middleNames": [
                                "Moritz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 102
                            }
                        ],
                        "text": "Several ideas have been explored to enhance the performance of these models such as data augmentation (Ko\u010disk\u00fd et al., 2016; Jia and Liang, 2016), transfer learning (Fan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 103
                            }
                        ],
                        "text": "Several ideas have been explored to enhance the performance of these models such as data augmentation (Koc\u030cisky\u0301 et al., 2016; Jia and Liang, 2016), transfer learning (Fan et al., 2017), sharing parameters for multiple languages or meaning representations (Susanto and Lu, 2017; Herzig and Berant,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1152008,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d00075feb9f2fecc1d035897b98eb2f45461b2e",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel semi-supervised approach for sequence transduction and apply it to semantic parsing. The unsupervised component is based on a generative model in which latent sentences generate the unpaired logical forms. We apply this method to a number of semantic parsing tasks focusing on domains with limited access to labelled training data and extend those datasets with synthetically generated logical forms."
            },
            "slug": "Semantic-Parsing-with-Semi-Supervised-Sequential-Kocisk\u00fd-Melis",
            "title": {
                "fragments": [],
                "text": "Semantic Parsing with Semi-Supervised Sequential Autoencoders"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work presents a novel semi-supervised approach for sequence transduction and applies it to semantic parsing tasks focusing on domains with limited access to labelled training data and extend those datasets with synthetically generated logical forms."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754497"
                        ],
                        "name": "Slav Petrov",
                        "slug": "Slav-Petrov",
                        "structuredName": {
                            "firstName": "Slav",
                            "lastName": "Petrov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Slav Petrov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Coarse-to-fine methods have been popular in the NLP literature, and are perhaps best known for syntactic parsing (Charniak et al., 2006; Petrov, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7111881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbc8488784ee77d5a9921580788cb53f995aaaeb",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 142,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art natural language processing models are anything but compact. Syntactic parsers have huge grammars, machine translation systems have huge transfer tables, and so on across a range of tasks. With such complexity come two challenges. First, how can we learn highly complex models? Second, how can we efficiently infer optimal structures within them? \nHierarchical coarse-to-fine methods address both questions. Coarse-to-fine approaches exploit a sequence of models which introduce complexity gradually. At the top of the sequence is a trivial model in which learning and inference are both cheap. Each subsequent model refines the previous one, until a final, full-complexity model is reached. Because each refinement introduces only limited complexity, both learning and inference can be done in an incremental fashion. In this dissertation, we describe several coarse-to-fine systems. \nIn the domain of syntactic parsing, complexity is in the grammar. We present a latent variable approach which begins with an X-bar grammar and learns to iteratively refine grammar categories. For example, noun phrases might be split into subcategories for subjects and objects, singular and plural, and so on. This splitting process admits an efficient incremental inference scheme which reduces parsing times by orders of magnitude. Furthermore, it produces the best parsing accuracies across an array of languages, in a fully language-general fashion. \nIn the domain of acoustic modeling for speech recognition, complexity is needed to model the rich phonetic properties of natural languages. Starting from a mono-phone model, we learn increasingly refined models that capture phone internal structures, as well as context-dependent variations in an automatic way. Our approaches reduces error rates compared to other baseline approaches, while streamlining the learning procedure. \nIn the domain of machine translation, complexity arises because there and too many target language word types. To manage this complexity, we translate into target language clusterings of increasing vocabulary size. This approach gives dramatic speed-ups while additionally increasing final translation quality."
            },
            "slug": "Coarse-to-Fine-Natural-Language-Processing-Petrov",
            "title": {
                "fragments": [],
                "text": "Coarse-to-Fine Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This dissertation describes several coarse-to-fine systems that learn increasingly refined models that capture phone internal structures, as well as context-dependent variations in an automatic way, while streamlining the learning procedure."
            },
            "venue": {
                "fragments": [],
                "text": "Theory and Applications of Natural Language Processing"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32406168"
                        ],
                        "name": "Raymond Hendy Susanto",
                        "slug": "Raymond-Hendy-Susanto",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Susanto",
                            "middleNames": [
                                "Hendy"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond Hendy Susanto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143844110"
                        ],
                        "name": "Wei Lu",
                        "slug": "Wei-Lu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Lu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 78
                            }
                        ],
                        "text": ", 2017), sharing parameters for multiple languages or meaning representations (Susanto and Lu, 2017; Herzig and Berant, 2017), and utilizing user feedback signals (Iyer et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20138082,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "fe433d6c26e4a5abb9eff26cacee0da79e6bfe2d",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address semantic parsing in a multilingual context. We train one multilingual model that is capable of parsing natural language sentences from multiple different languages into their corresponding formal semantic representations. We extend an existing sequence-to-tree model to a multi-task learning framework which shares the decoder for generating semantic representations. We report evaluation results on the multilingual GeoQuery corpus and introduce a new multilingual version of the ATIS corpus."
            },
            "slug": "Neural-Architectures-for-Multilingual-Semantic-Susanto-Lu",
            "title": {
                "fragments": [],
                "text": "Neural Architectures for Multilingual Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper trains one multilingual model that is capable of parsing natural language sentences from multiple different languages into their corresponding formal semantic representations and extends an existing sequence-to-tree model to a multi-task learning framework which shares the decoder for generating semantic representations."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750652"
                        ],
                        "name": "Jonathan Berant",
                        "slug": "Jonathan-Berant",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Berant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Berant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059149862"
                        ],
                        "name": "A. Chou",
                        "slug": "A.-Chou",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Chou",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34765463"
                        ],
                        "name": "Roy Frostig",
                        "slug": "Roy-Frostig",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Frostig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roy Frostig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 18
                            }
                        ],
                        "text": "(2017) use SEMPRE (Berant et al., 2013) to map a sentence into SQL sketches which are completed using program synthesis techniques and iteratively repaired if they are faulty."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "Yaghmazadeh et al. (2017) use SEMPRE (Berant et al., 2013) to map a sentence into SQL sketches which are completed using program synthesis techniques and iteratively repaired if they are faulty."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6401679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b29447ba499507a259ae9d8f685d60cc1597d7d3",
            "isKey": false,
            "numCitedBy": 1337,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs. The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus. Second, we use a bridging operation to generate additional predicates based on neighboring predicates. On the dataset of Cai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser. Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline."
            },
            "slug": "Semantic-Parsing-on-Freebase-from-Question-Answer-Berant-Chou",
            "title": {
                "fragments": [],
                "text": "Semantic Parsing on Freebase from Question-Answer Pairs"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper trains a semantic parser that scales up to Freebase and outperforms their state-of-the-art parser on the dataset of Cai and Yates (2013), despite not having annotated logical forms."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15652489"
                        ],
                        "name": "T. Kwiatkowski",
                        "slug": "T.-Kwiatkowski",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Kwiatkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kwiatkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991315"
                        ],
                        "name": "S. Goldwater",
                        "slug": "S.-Goldwater",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Goldwater",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldwater"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8597719,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "36d69fec4884389c1709d3ca74394cac814ce4a4",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring."
            },
            "slug": "Lexical-Generalization-in-CCG-Grammar-Induction-for-Kwiatkowski-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Lexical Generalization in CCG Grammar Induction for Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model, which includes both lexemes to model word meaning and templates to model systematic variation in word usage are presented."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075292388"
                        ],
                        "name": "P. Liang",
                        "slug": "P.-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "0 \u2014 DCS+L (Liang et al., 2013) 87."
                    },
                    "intents": []
                }
            ],
            "corpusId": 340852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ecd3e00bbbfd94446c3adc9c6878de27e250f7c",
            "isKey": false,
            "numCitedBy": 568,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Suppose we want to build a system that answers a natural language question by representing its semantics as a logical forxm and computing the answer given a structured database of facts. The core part of such a system is the semantic parser that maps questions to logical forms. Semantic parsers are typically trained from examples of questions annotated with their target logical forms, but this type of annotation is expensive.Our goal is to instead learn a semantic parser from question\u2013answer pairs, where the logical form is modeled as a latent variable. We develop a new semantic formalism, dependency-based compositional semantics (DCS) and define a log-linear distribution over DCS logical forms. The model parameters are estimated using a simple procedure that alternates between beam search and numerical optimization. On two standard semantic parsing benchmarks, we show that our system obtains comparable accuracies to even state-of-the-art systems that do require annotated logical forms."
            },
            "slug": "Learning-Dependency-Based-Compositional-Semantics-Liang-Jordan",
            "title": {
                "fragments": [],
                "text": "Learning Dependency-Based Compositional Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new semantic formalism, dependency-based compositional semantics (DCS) is developed and a log-linear distribution over DCS logical forms is defined and it is shown that the system obtains comparable accuracies to even state-of-the-art systems that do require annotated logical forms."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787006"
                        ],
                        "name": "Ruifang Ge",
                        "slug": "Ruifang-Ge",
                        "structuredName": {
                            "firstName": "Ruifang",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruifang Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 336,
                                "start": 151
                            }
                        ],
                        "text": "Various models have been proposed over the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2046600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ae207cfaf01dc2b6799da67f454190b34994870",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a learning semantic parser, Scissor, that maps natural-language sentences to a detailed, formal, meaning-representation language. It first uses an integrated statistical parser to produce a semantically augmented parse tree, in which each non-terminal node has both a syntactic and a semantic label. A compositional-semantics procedure is then used to map the augmented parse tree into a final meaning representation. We evaluate the system in two domains, a natural-language database interface and an interpreter for coaching instructions in robotic soccer. We present experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches."
            },
            "slug": "A-Statistical-Semantic-Parser-that-Integrates-and-Ge-Mooney",
            "title": {
                "fragments": [],
                "text": "A Statistical Semantic Parser that Integrates Syntax and Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A learning semantic parser that maps natural-language sentences to a detailed, formal, meaning-representation language and presents experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108471978"
                        ],
                        "name": "Yuchen Zhang",
                        "slug": "Yuchen-Zhang",
                        "structuredName": {
                            "firstName": "Yuchen",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuchen Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2616463"
                        ],
                        "name": "Panupong Pasupat",
                        "slug": "Panupong-Pasupat",
                        "structuredName": {
                            "firstName": "Panupong",
                            "lastName": "Pasupat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Panupong Pasupat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 33
                            }
                        ],
                        "text": "Artzi and Zettlemoyer (2013) and Zhang et al. (2017) use coarse lexical entries or macro grammars to reduce the search space of semantic parsers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6073887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca25815b6fd7ce8f18ad3f371f3e2b4546b724a2",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "To learn a semantic parser from denotations, a learning algorithm must search over a combinatorially large space of logical forms for ones consistent with the annotated denotations. We propose a new online learning algorithm that searches faster as training progresses. The two key ideas are using macro grammars to cache the abstract patterns of useful logical forms found thus far, and holistic triggering to efficiently retrieve the most relevant patterns based on sentence similarity. On the WikiTableQuestions dataset, we first expand the search space of an existing model to improve the state-of-the-art accuracy from 38.7% to 42.7%, and then use macro grammars and holistic triggering to achieve an 11x speedup and an accuracy of 43.7%."
            },
            "slug": "Macro-Grammars-and-Holistic-Triggering-for-Semantic-Zhang-Pasupat",
            "title": {
                "fragments": [],
                "text": "Macro Grammars and Holistic Triggering for Efficient Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new online learning algorithm that searches faster as training progresses is proposed, using macro grammars to cache the abstract patterns of useful logical forms found thus far, and holistic triggering to efficiently retrieve the most relevant patterns based on sentence similarity."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1900163"
                        ],
                        "name": "Srini Iyer",
                        "slug": "Srini-Iyer",
                        "structuredName": {
                            "firstName": "Srini",
                            "lastName": "Iyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srini Iyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2621022"
                        ],
                        "name": "Ioannis Konstas",
                        "slug": "Ioannis-Konstas",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Konstas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Konstas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144385783"
                        ],
                        "name": "Alvin Cheung",
                        "slug": "Alvin-Cheung",
                        "structuredName": {
                            "firstName": "Alvin",
                            "lastName": "Cheung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alvin Cheung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2517825"
                        ],
                        "name": "J. Krishnamurthy",
                        "slug": "J.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Krishnamurthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 163
                            }
                        ],
                        "text": ", 2017), sharing parameters for multiple languages or meaning representations (Susanto and Lu, 2017; Herzig and Berant, 2017), and utilizing user feedback signals (Iyer et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 278
                            }
                        ],
                        "text": "\u2026these models such as data augmentation (Koc\u030cisky\u0301 et al., 2016; Jia and Liang, 2016), transfer learning (Fan et al., 2017), sharing parameters for multiple languages or meaning representations (Susanto and Lu, 2017; Herzig and Berant, 2017), and utilizing user feedback signals (Iyer et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 497108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32ce5467ff884d2f90a233f4d9606c6e18b1a9d6",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to rapidly and easily build natural language interfaces to databases for new domains, whose performance improves over time based on user feedback, and requires minimal intervention. To achieve this, we adapt neural sequence models to map utterances directly to SQL with its full expressivity, bypassing any intermediate meaning representations. These models are immediately deployed online to solicit feedback from real users to flag incorrect queries. Finally, the popularity of SQL facilitates gathering annotations for incorrect predictions using the crowd, which is directly used to improve our models. This complete feedback loop, without intermediate representations or database specific engineering, opens up new ways of building high quality semantic parsers. Experiments suggest that this approach can be deployed quickly for any new target domain, as we show by learning a semantic parser for an online academic database from scratch."
            },
            "slug": "Learning-a-Neural-Semantic-Parser-from-User-Iyer-Konstas",
            "title": {
                "fragments": [],
                "text": "Learning a Neural Semantic Parser from User Feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An approach to rapidly and easily build natural language interfaces to databases for new domains, whose performance improves over time based on user feedback, and requires minimal intervention is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15652489"
                        ],
                        "name": "T. Kwiatkowski",
                        "slug": "T.-Kwiatkowski",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Kwiatkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kwiatkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2890423"
                        ],
                        "name": "Eunsol Choi",
                        "slug": "Eunsol-Choi",
                        "structuredName": {
                            "firstName": "Eunsol",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eunsol Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3167681"
                        ],
                        "name": "Yoav Artzi",
                        "slug": "Yoav-Artzi",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Artzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Artzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5 KCAZ13 (Kwiatkowski et al., 2013) 89."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14341841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2ac51e10a3510eadac5eac5e4fb828f086fab88",
            "isKey": false,
            "numCitedBy": 317,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the challenge of learning semantic parsers that scale to large, open-domain problems, such as question answering with Freebase. In such settings, the sentences cover a wide variety of topics and include many phrases whose meaning is difficult to represent in a fixed target ontology. For example, even simple phrases such as \u2018daughter\u2019 and \u2018number of people living in\u2019 cannot be directly represented in Freebase, whose ontology instead encodes facts about gender, parenthood, and population. In this paper, we introduce a new semantic parsing approach that learns to resolve such ontological mismatches. The parser is learned from question-answer pairs, uses a probabilistic CCG to build linguistically motivated logicalform meaning representations, and includes an ontology matching model that adapts the output logical forms for each target ontology. Experiments demonstrate state-of-the-art performance on two benchmark semantic parsing datasets, including a nine point accuracy improvement on a recent Freebase QA corpus."
            },
            "slug": "Scaling-Semantic-Parsers-with-On-the-Fly-Ontology-Kwiatkowski-Choi",
            "title": {
                "fragments": [],
                "text": "Scaling Semantic Parsers with On-the-Fly Ontology Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new semantic parsing approach that learns to resolve ontological mismatches, which is learned from question-answer pairs, uses a probabilistic CCG to build linguistically motivated logicalform meaning representations, and includes an ontology matching model that adapts the output logical forms for each target ontology."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 87
                            }
                        ],
                        "text": "We used standard splits for both datasets: 600 training and 280 test instances for GEO (Zettlemoyer and Collins, 2005); 4, 480 training, 480 development, and 450 test examples for ATIS."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Configuration Model hyperparameters were cross-validated on the training set for GEO, and were validated on the development split for the other datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Preprocessing For GEO and ATIS, we used the preprocessed versions provided by Dong and Lapata (2016), where natural language expressions are lowercased and stemmed with NLTK (Bird et al., 2009), and entity mentions are replaced by numbered markers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Label smoothing (Szegedy et al., 2016) was employed for GEO and ATIS."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "Algorithm 1 Sketch for GEO and ATIS Input: t: Tree-structure \u03bb-calculus expression t.pred: Predicate name, or operator name Output: a: Meaning sketch ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "For our first task we used two benchmark datasets, namely GEO (880 language queries to a database of U.S. geography) and ATIS (5, 410 queries to a flight booking system)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "Table 2 presents our results on GEO and ATIS."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "Taken together (Tables 2\u20134), our results show that better sketches bring accuracy gains on GEO, ATIS, and DJANGO."
                    },
                    "intents": []
                }
            ],
            "corpusId": 449252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74fe7ec751cd50295b15cfd46389a8fefb37c414",
            "isKey": true,
            "numCitedBy": 874,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of mapping natural language sentences to lambda\u2013calculus encodings of their meaning. We describe a learning algorithm that takes as input a training set of sentences labeled with expressions in the lambda calculus. The algorithm induces a grammar for the problem, along with a log-linear model that represents a distribution over syntactic and semantic analyses conditioned on the input sentence. We apply the method to the task of learning natural language interfaces to databases and show that the learned parsers outperform previous methods in two benchmark database domains."
            },
            "slug": "Learning-to-Map-Sentences-to-Logical-Form:-with-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A learning algorithm is described that takes as input a training set of sentences labeled with expressions in the lambda calculus and induces a grammar for the problem, along with a log-linear model that represents a distribution over syntactic and semantic analyses conditioned on the input sentence."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060101052"
                        ],
                        "name": "Terry Koo",
                        "slug": "Terry-Koo",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Koo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terry Koo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754497"
                        ],
                        "name": "Slav Petrov",
                        "slug": "Slav-Petrov",
                        "structuredName": {
                            "firstName": "Slav",
                            "lastName": "Petrov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Slav Petrov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 106
                            }
                        ],
                        "text": "The successful application of recurrent neural networks to a variety of NLP tasks (Bahdanau et al., 2015; Vinyals et al., 2015) has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 82
                            }
                        ],
                        "text": "The successful application of recurrent neural networks to a variety of NLP tasks (Bahdanau et al., 2015; Vinyals et al., 2015) has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47570e7f63e296f224a0e7f9a0d08b0de3cbaf40",
            "isKey": false,
            "numCitedBy": 845,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic constituency parsing is a fundamental problem in natural language processing and has been the subject of intensive research and engineering for decades. As a result, the most accurate parsers are domain specific, complex, and inefficient. In this paper we show that the domain agnostic attention-enhanced sequence-to-sequence model achieves state-of-the-art results on the most widely used syntactic constituency parsing dataset, when trained on a large synthetic corpus that was annotated using existing parsers. It also matches the performance of standard parsers when trained only on a small human-annotated dataset, which shows that this model is highly data-efficient, in contrast to sequence-to-sequence models without the attention mechanism. Our parser is also fast, processing over a hundred sentences per second with an unoptimized CPU implementation."
            },
            "slug": "Grammar-as-a-Foreign-Language-Vinyals-Kaiser",
            "title": {
                "fragments": [],
                "text": "Grammar as a Foreign Language"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The domain agnostic attention-enhanced sequence-to-sequence model achieves state-of-the-art results on the most widely used syntactic constituency parsing dataset, when trained on a large synthetic corpus that was annotated using existing parsers."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40354648"
                        ],
                        "name": "Maxim Rabinovich",
                        "slug": "Maxim-Rabinovich",
                        "structuredName": {
                            "firstName": "Maxim",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maxim Rabinovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144872294"
                        ],
                        "name": "Mitchell Stern",
                        "slug": "Mitchell-Stern",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Stern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mitchell Stern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 87
                            }
                        ],
                        "text": ", 2017), or modular decoders which use syntax to dynamically compose various submodels (Rabinovich et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Rabinovich et al. (2017) propose a modular decoder whose submodels are dynamically composed according to the generated tree structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 272
                            }
                        ],
                        "text": "\u2026include tree decoders (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017), decoders constrained by a grammar model (Xiao et al., 2016; Yin and Neubig, 2017; Krishnamurthy et al., 2017), or modular\ndecoders which use syntax to dynamically compose various submodels (Rabinovich et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13529592,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c1e874c3b67510a3215e535f5646b362de5bc89",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7% exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering."
            },
            "slug": "Abstract-Syntax-Networks-for-Code-Generation-and-Rabinovich-Stern",
            "title": {
                "fragments": [],
                "text": "Abstract Syntax Networks for Code Generation and Semantic Parsing"
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 336,
                                "start": 151
                            }
                        ],
                        "text": "Various models have been proposed over the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12728987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "774113732db34ce0b797fc3dcceded811fb6edbc",
            "isKey": false,
            "numCitedBy": 448,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning to parse sentences to lambda-calculus representations of their underlying semantics and present an algorithm that learns a weighted combinatory categorial grammar (CCG). A key idea is to introduce non-standard CCG combinators that relax certain parts of the grammar\u2014for example allowing flexible word order, or insertion of lexical items\u2014 with learned costs. We also present a new, online algorithm for inducing a weighted CCG. Results for the approach on ATIS data show 86% F-measure in recovering fully correct semantic analyses and 95.9% F-measure by a partial-match criterion, a more than 5% improvement over the 90.3% partial-match figure reported by He and Young (2006)."
            },
            "slug": "Online-Learning-of-Relaxed-CCG-Grammars-for-Parsing-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Online Learning of Relaxed CCG Grammars for Parsing to Logical Form"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A key idea is to introduce non-standard CCG combinators that relax certain parts of the grammar\u2014for example allowing flexible word order, or insertion of lexical items\u2014 with learned costs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15652489"
                        ],
                        "name": "T. Kwiatkowski",
                        "slug": "T.-Kwiatkowski",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Kwiatkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kwiatkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991315"
                        ],
                        "name": "S. Goldwater",
                        "slug": "S.-Goldwater",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Goldwater",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldwater"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6228816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7a40c3ef180d847bb3db40fd01990e08a6264f7",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of learning to map sentences to logical form, given training data consisting of natural language sentences paired with logical representations of their meaning. Previous approaches have been designed for particular natural languages or specific meaning representations; here we present a more general method. The approach induces a probabilistic CCG grammar that represents the meaning of individual words and defines how these meanings can be combined to analyze complete sentences. We use higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develop an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model. Experiments demonstrate high accuracy on benchmark data sets in four languages with two different meaning representations."
            },
            "slug": "Inducing-Probabilistic-CCG-Grammars-from-Logical-Kwiatkowski-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper uses higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develops an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854385"
                        ],
                        "name": "\u00c7aglar G\u00fcl\u00e7ehre",
                        "slug": "\u00c7aglar-G\u00fcl\u00e7ehre",
                        "structuredName": {
                            "firstName": "\u00c7aglar",
                            "lastName": "G\u00fcl\u00e7ehre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c7aglar G\u00fcl\u00e7ehre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3103594"
                        ],
                        "name": "Sungjin Ahn",
                        "slug": "Sungjin-Ahn",
                        "structuredName": {
                            "firstName": "Sungjin",
                            "lastName": "Ahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sungjin Ahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701451"
                        ],
                        "name": "Ramesh Nallapati",
                        "slug": "Ramesh-Nallapati",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Nallapati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramesh Nallapati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145218984"
                        ],
                        "name": "Bowen Zhou",
                        "slug": "Bowen-Zhou",
                        "structuredName": {
                            "firstName": "Bowen",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bowen Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "We handle OOV tokens with a copying mechanism (Gu et al., 2016; Gulcehre et al., 2016; Jia and Liang, 2016), which allows the fine meaning decoder (Section 3.2) to directly copy tokens from the natural language input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 46
                            }
                        ],
                        "text": "We handle OOV tokens with a copying mechanism (Gu et al., 2016; Gulcehre et al., 2016; Jia and Liang, 2016), which allows the fine meaning decoder (Section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 969555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa5b35dcf8b024f5352db73cc3944e8fad4f3793",
            "isKey": true,
            "numCitedBy": 450,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of rare and unknown words is an important issue that can potentially influence the performance of many NLP systems, including both the traditional count-based and the deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models using attention. Our model uses two softmax layers in order to predict the next word in conditional language models: one predicts the location of a word in the source sentence, and the other predicts a word in the shortlist vocabulary. At each time-step, the decision of which softmax layer to use choose adaptively made by an MLP which is conditioned on the context.~We motivate our work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known.~We observe improvements on two tasks, neural machine translation on the Europarl English to French parallel corpora and text summarization on the Gigaword dataset using our proposed model."
            },
            "slug": "Pointing-the-Unknown-Words-G\u00fcl\u00e7ehre-Ahn",
            "title": {
                "fragments": [],
                "text": "Pointing the Unknown Words"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel way to deal with the rare and unseen words for the neural network models using attention is proposed using attention, which uses two softmax layers in order to predict the next word in conditional language models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390096054"
                        ],
                        "name": "David Alvarez-Melis",
                        "slug": "David-Alvarez-Melis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Alvarez-Melis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Alvarez-Melis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 31
                            }
                        ],
                        "text": "Examples include tree decoders (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017), decoders constrained by a grammar model (Xiao et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56763307,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c69926bdb72912725d20a55af7147f86bed01ae",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel neural network architecture specifically tailored to treestructured decoding, which: \u2022 maintains separate depth and width recurrent states and combines them to obtain hidden states for every node in the tree. \u2022 has a mechanism to predict tree topology explicitly (as opposed to implicitly by adding nodes with special tokens). Our experiments show that this architecture \u2022 is capable of recovering trees from encoded representations \u2022 achieves state-of-the-art performance in a task consisting of mapping sentences to simple functional programs \u2022 exhibits desirable invariance properties over sequential architectures"
            },
            "slug": "Tree-structured-decoding-with-doubly-recurrent-Alvarez-Melis-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Tree-structured decoding with doubly-recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A novel neural network architecture specifically tailored to treestructured decoding, which maintains separate depth and width recurrent states and combines them to obtain hidden states for every node in the tree, and exhibits desirable invariance properties over sequential architectures."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821711"
                        ],
                        "name": "Thang Luong",
                        "slug": "Thang-Luong",
                        "structuredName": {
                            "firstName": "Thang",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thang Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143950636"
                        ],
                        "name": "Hieu Pham",
                        "slug": "Hieu-Pham",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Pham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu Pham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 45
                            }
                        ],
                        "text": "Additionally, we use an attention mechanism (Luong et al., 2015) to learn soft alignments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1998416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93499a7c7f699b6630a86fad964536f9423bb6d0",
            "isKey": false,
            "numCitedBy": 5893,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT\u201915 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. 1"
            },
            "slug": "Effective-Approaches-to-Attention-based-Neural-Luong-Pham",
            "title": {
                "fragments": [],
                "text": "Effective Approaches to Attention-based Neural Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A global approach which always attends to all source words and a local one that only looks at a subset of source words at a time are examined, demonstrating the effectiveness of both approaches on the WMT translation tasks between English and German in both directions."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1379953252"
                        ],
                        "name": "Wang Ling",
                        "slug": "Wang-Ling",
                        "structuredName": {
                            "firstName": "Wang",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685771"
                        ],
                        "name": "P. Blunsom",
                        "slug": "P.-Blunsom",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Blunsom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Blunsom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1864353"
                        ],
                        "name": "Edward Grefenstette",
                        "slug": "Edward-Grefenstette",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Grefenstette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910877"
                        ],
                        "name": "K. Hermann",
                        "slug": "K.-Hermann",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Hermann",
                            "middleNames": [
                                "Moritz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367821"
                        ],
                        "name": "Tom\u00e1s Kocisk\u00fd",
                        "slug": "Tom\u00e1s-Kocisk\u00fd",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Kocisk\u00fd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom\u00e1s Kocisk\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115096249"
                        ],
                        "name": "Fumin Wang",
                        "slug": "Fumin-Wang",
                        "structuredName": {
                            "firstName": "Fumin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fumin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33666044"
                        ],
                        "name": "A. Senior",
                        "slug": "A.-Senior",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Senior",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Senior"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 261
                            }
                        ],
                        "text": "The successful application of recurrent neural networks to a variety of NLP tasks (Bahdanau et al., 2015; Vinyals et al., 2015) has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 96
                            }
                        ],
                        "text": ", 2015) has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 156
                            }
                        ],
                        "text": "More recently, neural sequence-to-sequence models have been applied to semantic parsing with promising results (Dong and Lapata, 2016; Jia and Liang, 2016; Ling et al., 2016), eschewing the need for extensive feature engineering."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14434979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e957747f4f8600940be4c5bb001aa70c84e53a53",
            "isKey": false,
            "numCitedBy": 285,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Many language generation tasks require the production of text conditioned on both structured and unstructured inputs. We present a novel neural network architecture which generates an output sequence conditioned on an arbitrary number of input functions. Crucially, our approach allows both the choice of conditioning context and the granularity of generation, for example characters or tokens, to be marginalised, thus permitting scalable and effective training. Using this framework, we address the problem of generating programming code from a mixed natural language and structured specification. We create two new data sets for this paradigm derived from the collectible trading card games Magic the Gathering and Hearthstone. On these, and a third preexisting corpus, we demonstrate that marginalising multiple predictors allows our model to outperform strong benchmarks."
            },
            "slug": "Latent-Predictor-Networks-for-Code-Generation-Ling-Blunsom",
            "title": {
                "fragments": [],
                "text": "Latent Predictor Networks for Code Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A novel neural network architecture is presented which generates an output sequence conditioned on an arbitrary number of input functions and allows both the choice of conditioning context and the granularity of generation, for example characters or tokens, to be marginalised, thus permitting scalable and effective training."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 83
                            }
                        ],
                        "text": "The successful application of recurrent neural networks to a variety of NLP tasks (Bahdanau et al., 2015; Vinyals et al., 2015) has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 82
                            }
                        ],
                        "text": "The successful application of recurrent neural networks to a variety of NLP tasks (Bahdanau et al., 2015; Vinyals et al., 2015) has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11212020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "isKey": false,
            "numCitedBy": 19342,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition."
            },
            "slug": "Neural-Machine-Translation-by-Jointly-Learning-to-Bahdanau-Cho",
            "title": {
                "fragments": [],
                "text": "Neural Machine Translation by Jointly Learning to Align and Translate"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and it is proposed to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 42
                            }
                        ],
                        "text": "Word embeddings were initialized by GloVe (Pennington et al., 2014), and were shared by table encoder"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 43
                            }
                        ],
                        "text": "Word embeddings were initialized by GloVe (Pennington et al., 2014), and were shared by table encoder and input encoder in Section 4.3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1957433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "isKey": true,
            "numCitedBy": 22536,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."
            },
            "slug": "GloVe:-Global-Vectors-for-Word-Representation-Pennington-Socher",
            "title": {
                "fragments": [],
                "text": "GloVe: Global Vectors for Word Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods and produces a vector space with meaningful substructure."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341916"
                        ],
                        "name": "Kai Zhao",
                        "slug": "Kai-Zhao",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768480"
                        ],
                        "name": "Liang Huang",
                        "slug": "Liang-Huang",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 336,
                                "start": 151
                            }
                        ],
                        "text": "Various models have been proposed over the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4328410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42f571fc75ccf57b44c1b9eeead67c84ee9d5979",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic parsing has made significant progress, but most current semantic parsers are extremely slow (CKY-based) and rather primitive in representation. We introduce three new techniques to tackle these problems. First, we design the first linear-time incremental shift-reduce-style semantic parsing algorithm which is more efficient than conventional cubic-time bottom-up semantic parsers. Second, our parser, being type-driven instead of syntax-driven, uses type-checking to decide the direction of reduction, which eliminates the need for a syntactic grammar such as CCG. Third, to fully exploit the power of type-driven semantic parsing beyond simple types (such as entities and truth values), we borrow from programming language theory the concepts of subtype polymorphism and parametric polymorphism to enrich the type system in order to better guide the parsing. Our system learns very accurate parses in GEOQUERY, JOBS and ATIS domains."
            },
            "slug": "Type-Driven-Incremental-Semantic-Parsing-with-Zhao-Huang",
            "title": {
                "fragments": [],
                "text": "Type-Driven Incremental Semantic Parsing with Polymorphism"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work designs the first linear-time incremental shift-reduce-style semantic parsing algorithm which is more efficient than conventional cubic-time bottom-up semantic parsers and borrows from programming language theory the concepts of subtype polymorphism and parametric polymorphism to enrich the type system in order to better guide the parsing."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3428769"
                        ],
                        "name": "Victor Zhong",
                        "slug": "Victor-Zhong",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Zhong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228109"
                        ],
                        "name": "Caiming Xiong",
                        "slug": "Caiming-Xiong",
                        "structuredName": {
                            "firstName": "Caiming",
                            "lastName": "Xiong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Caiming Xiong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 13
                            }
                        ],
                        "text": "The WIKISQL (Zhong et al., 2017) dataset contains 80, 654 examples of questions and SQL queries distributed across 24, 241 tables from Wikipedia."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 51
                            }
                        ],
                        "text": "WIKISQL was preprocessed by the script provided by Zhong et al. (2017), where inputs were lowercased and tokenized by Stanford CoreNLP (Manning et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 25156106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "116a877c774969b53399b1ccaa34d51bfb492ee4",
            "isKey": false,
            "numCitedBy": 564,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Relational databases store a significant amount of the worlds data. However, accessing this data currently requires users to understand a query language such as SQL. We propose Seq2SQL, a deep neural network for translating natural language questions to corresponding SQL queries. Our model uses rewards from in the loop query execution over the database to learn a policy to generate the query, which contains unordered parts that are less suitable for optimization via cross entropy loss. Moreover, Seq2SQL leverages the structure of SQL to prune the space of generated queries and significantly simplify the generation problem. In addition to the model, we release WikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables fromWikipedia that is an order of magnitude larger than comparable datasets. By applying policy based reinforcement learning with a query execution environment to WikiSQL, Seq2SQL outperforms a state-of-the-art semantic parser, improving execution accuracy from 35.9% to 59.4% and logical form accuracy from 23.4% to 48.3%."
            },
            "slug": "Seq2SQL:-Generating-Structured-Queries-from-Natural-Zhong-Xiong",
            "title": {
                "fragments": [],
                "text": "Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work proposes Seq2 SQL, a deep neural network for translating natural language questions to corresponding SQL queries, and releases WikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables fromWikipedia that is an order of magnitude larger than comparable datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1942300"
                        ],
                        "name": "M. Kudlur",
                        "slug": "M.-Kudlur",
                        "structuredName": {
                            "firstName": "Manjunath",
                            "lastName": "Kudlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kudlur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "Moreover, the sketch provides a canonical order of condition operators, which is beneficial for the decoding process (Vinyals et al., 2016; Xu et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13948549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d01379ebb53c66a4ccf5f4959d904dcf9e161e41",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequences have become first class citizens in supervised learning thanks to the resurgence of recurrent neural networks. Many complex tasks that require mapping from or to a sequence of observations can now be formulated with the sequence-to-sequence (seq2seq) framework which employs the chain rule to efficiently represent the joint probability of sequences. In many cases, however, variable sized inputs and/or outputs might not be naturally expressed as sequences. For instance, it is not clear how to input a set of numbers into a model where the task is to sort them; similarly, we do not know how to organize outputs when they correspond to random variables and the task is to model their unknown joint probability. In this paper, we first show using various examples that the order in which we organize input and/or output data matters significantly when learning an underlying model. We then discuss an extension of the seq2seq framework that goes beyond sequences and handles input sets in a principled way. In addition, we propose a loss which, by searching over possible orders during training, deals with the lack of structure of output sets. We show empirical evidence of our claims regarding ordering, and on the modifications to the seq2seq framework on benchmark language modeling and parsing tasks, as well as two artificial tasks -- sorting numbers and estimating the joint probability of unknown graphical models."
            },
            "slug": "Order-Matters:-Sequence-to-sequence-for-sets-Vinyals-Bengio",
            "title": {
                "fragments": [],
                "text": "Order Matters: Sequence to sequence for sets"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An extension of the seq2seq framework that goes beyond sequences and handles input sets in a principled way is discussed and a loss is proposed which, by searching over possible orders during training, deals with the lack of structure of output sets."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190169"
                        ],
                        "name": "L. Tang",
                        "slug": "L.-Tang",
                        "structuredName": {
                            "firstName": "Lappoon",
                            "lastName": "Tang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 336,
                                "start": 151
                            }
                        ],
                        "text": "Various models have been proposed over the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2036954,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "151411a7b32e40dca8a51503135c6e9e3cdbc70c",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The development of natural language interfaces (NLI's) for databases has been a challenging problem in natural language processing (NLP) since the 1970's. The need for NLI's has become more pronounced due to the widespread access to complex databases now available through the Internet. A challenging problem for empirical NLP is the automated acquisition of NLI's from training examples. We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches. Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic-based approach."
            },
            "slug": "Automated-Construction-of-Database-Interfaces:-and-Tang-Mooney",
            "title": {
                "fragments": [],
                "text": "Automated Construction of Database Interfaces: Intergrating Statistical and Relational Learning for Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches and suggests that such an approach is more robust than a previous purely logic-based approach."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3016273"
                        ],
                        "name": "Jiatao Gu",
                        "slug": "Jiatao-Gu",
                        "structuredName": {
                            "firstName": "Jiatao",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiatao Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11955007"
                        ],
                        "name": "Zhengdong Lu",
                        "slug": "Zhengdong-Lu",
                        "structuredName": {
                            "firstName": "Zhengdong",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengdong Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49404233"
                        ],
                        "name": "Hang Li",
                        "slug": "Hang-Li",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052674293"
                        ],
                        "name": "V. Li",
                        "slug": "V.-Li",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Li",
                            "middleNames": [
                                "O.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 47
                            }
                        ],
                        "text": "We handle OOV tokens with a copying mechanism (Gu et al., 2016; Gulcehre et al., 2016; Jia and Liang, 2016), which allows the fine meaning decoder (Section 3.2) to directly copy tokens from the natural language input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 46
                            }
                        ],
                        "text": "We handle OOV tokens with a copying mechanism (Gu et al., 2016; Gulcehre et al., 2016; Jia and Liang, 2016), which allows the fine meaning decoder (Section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8174613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba30df190664193514d1d309cb673728ed48f449",
            "isKey": true,
            "numCitedBy": 1194,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We address an important problem in sequence-to-sequence (Seq2Seq) learning referred to as copying, in which certain segments in the input sequence are selectively replicated in the output sequence. A similar phenomenon is observable in human language communication. For example, humans tend to repeat entity names or even long phrases in conversation. The challenge with regard to copying in Seq2Seq is that new machinery is needed to decide when to perform the operation. In this paper, we incorporate copying into neural network-based Seq2Seq learning and propose a new model called CopyNet with encoder-decoder structure. CopyNet can nicely integrate the regular way of word generation in the decoder with the new copying mechanism which can choose sub-sequences in the input sequence and put them at proper places in the output sequence. Our empirical study on both synthetic data sets and real world data sets demonstrates the efficacy of CopyNet. For example, CopyNet can outperform regular RNN-based model with remarkable margins on text summarization tasks."
            },
            "slug": "Incorporating-Copying-Mechanism-in-Learning-Gu-Lu",
            "title": {
                "fragments": [],
                "text": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper incorporates copying into neural network-based Seq2Seq learning and proposes a new model called CopyNet with encoder-decoder structure which can nicely integrate the regular way of word generation in the decoder with the new copying mechanism which can choose sub-sequences in the input sequence and put them at proper places in the output sequence."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21308992"
                        ],
                        "name": "Steven Bird",
                        "slug": "Steven-Bird",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Bird",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Bird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145606490"
                        ],
                        "name": "Ewan Klein",
                        "slug": "Ewan-Klein",
                        "structuredName": {
                            "firstName": "Ewan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ewan Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3213150"
                        ],
                        "name": "E. Loper",
                        "slug": "E.-Loper",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Loper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Loper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 175
                            }
                        ],
                        "text": "Preprocessing For GEO and ATIS, we used the preprocessed versions provided by Dong and Lapata (2016), where natural language expressions are lowercased and stemmed with NLTK (Bird et al., 2009), and entity mentions are replaced by numbered markers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "We employed the preprocessed DJANGO data provided by Yin and Neubig (2017), where input expressions are tokenized by NLTK, and quoted strings in the input are replaced with place holders."
                    },
                    "intents": []
                }
            ],
            "corpusId": 58803969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a65f23d990231d461418067c808b09d84c19b2c",
            "isKey": false,
            "numCitedBy": 3384,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication. Packed with examples and exercises, Natural Language Processing with Python will help you: Extract information from unstructured text, either to guess the topic or identify \"named entities\" Analyze linguistic structure in text, including parsing and semantic analysis Access popular linguistic databases, including WordNet and treebanks Integrate techniques drawn from fields as diverse as linguistics and artificial intelligence This book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages -- or if you're simply curious to have a programmer's perspective on how human language works -- you'll find Natural Language Processing with Python both fascinating and immensely useful."
            },
            "slug": "Natural-Language-Processing-with-Python-Bird-Klein",
            "title": {
                "fragments": [],
                "text": "Natural Language Processing with Python"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145177220"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689233"
                        ],
                        "name": "M. Elsner",
                        "slug": "M.-Elsner",
                        "structuredName": {
                            "firstName": "Micha",
                            "lastName": "Elsner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Elsner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2494174"
                        ],
                        "name": "Joseph L. Austerweil",
                        "slug": "Joseph-L.-Austerweil",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Austerweil",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph L. Austerweil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053675220"
                        ],
                        "name": "David Ellis",
                        "slug": "David-Ellis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ellis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2670246"
                        ],
                        "name": "Isaac Haxton",
                        "slug": "Isaac-Haxton",
                        "structuredName": {
                            "firstName": "Isaac",
                            "lastName": "Haxton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Isaac Haxton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114171252"
                        ],
                        "name": "Catherine Hill",
                        "slug": "Catherine-Hill",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2500455"
                        ],
                        "name": "R. Shrivaths",
                        "slug": "R.-Shrivaths",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Shrivaths",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shrivaths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49135127"
                        ],
                        "name": "J. Moore",
                        "slug": "J.-Moore",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39606782"
                        ],
                        "name": "M. Pozar",
                        "slug": "M.-Pozar",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Pozar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pozar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056253726"
                        ],
                        "name": "Theresa Vu",
                        "slug": "Theresa-Vu",
                        "structuredName": {
                            "firstName": "Theresa",
                            "lastName": "Vu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Theresa Vu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 114
                            }
                        ],
                        "text": "Coarse-to-fine methods have been popular in the NLP literature, and are perhaps best known for syntactic parsing (Charniak et al., 2006; Petrov, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15016852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "210c42712536f9b4e1a2904fff4312dfb82b4da0",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a PCFG parsing algorithm that uses a multilevel coarse-to-fine (mlctf) scheme to improve the efficiency of search for the best parse. Our approach requires the user to specify a sequence of nested partitions or equivalence classes of the PCFG nonterminals. We define a sequence of PCFGs corresponding to each partition, where the nonterminals of each PCFG are clusters of nonterminals of the original source PCFG. We use the results of parsing at a coarser level (i.e., grammar defined in terms of a coarser partition) to prune the next finer level. We present experiments showing that with our algorithm the work load (as measured by the total number of constituents processed) is decreased by a factor of ten with no decrease in parsing accuracy compared to standard CKY parsing with the original PCFG. We suggest that the search space over mlctf algorithms is almost totally unexplored so that future work should be able to improve significantly on these results."
            },
            "slug": "Multilevel-Coarse-to-Fine-PCFG-Parsing-Charniak-Johnson",
            "title": {
                "fragments": [],
                "text": "Multilevel Coarse-to-Fine PCFG Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A PCFG parsing algorithm that uses a multilevel coarse-to-fine (mlctf) scheme to improve the efficiency of search for the best parse and suggests that the search space over mlctf algorithms is almost totally unexplored."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108880352"
                        ],
                        "name": "Xiaojun Xu",
                        "slug": "Xiaojun-Xu",
                        "structuredName": {
                            "firstName": "Xiaojun",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaojun Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118484320"
                        ],
                        "name": "Chang Liu",
                        "slug": "Chang-Liu",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143711382"
                        ],
                        "name": "D. Song",
                        "slug": "D.-Song",
                        "structuredName": {
                            "firstName": "Dawn",
                            "lastName": "Song",
                            "middleNames": [
                                "Xiaodong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Song"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "0%, respectively, which is comparable to SQLNET (Xu et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 140
                            }
                        ],
                        "text": "Moreover, the sketch provides a canonical order of condition operators, which is beneficial for the decoding process (Vinyals et al., 2016; Xu et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 124
                            }
                        ],
                        "text": "COARSE2FINE\u2019s accuracies on aggregation agg op and agg col are 90.2% and 92.0%, respectively, which is comparable to SQLNET (Xu et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 10746949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47f65c165f7ccedd4c18189d4690eec5369dd9c5",
            "isKey": true,
            "numCitedBy": 234,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the \"order-matters\" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited. \nIn this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task."
            },
            "slug": "SQLNet:-Generating-Structured-Queries-From-Natural-Xu-Liu",
            "title": {
                "fragments": [],
                "text": "SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A sketch-based approach where the sketch contains a dependency graph, so that one prediction can be done by taking into consideration only the previous predictions that it depends on, and it is shown that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2247151"
                        ],
                        "name": "Navid Yaghmazadeh",
                        "slug": "Navid-Yaghmazadeh",
                        "structuredName": {
                            "firstName": "Navid",
                            "lastName": "Yaghmazadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navid Yaghmazadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2021637"
                        ],
                        "name": "Yuepeng Wang",
                        "slug": "Yuepeng-Wang",
                        "structuredName": {
                            "firstName": "Yuepeng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuepeng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714075"
                        ],
                        "name": "Isil Dillig",
                        "slug": "Isil-Dillig",
                        "structuredName": {
                            "firstName": "Isil",
                            "lastName": "Dillig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Isil Dillig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711860"
                        ],
                        "name": "Thomas Dillig",
                        "slug": "Thomas-Dillig",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dillig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Dillig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Yaghmazadeh et al. (2017) use SEMPRE (Berant et al., 2013) to map a sentence into SQL sketches which are completed using program synthesis techniques and iteratively repaired if they are faulty."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8210357,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7456179fa71bc237e051ecb3c02c043a50549029",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new technique for automatically synthesizing SQL queries from natural language (NL). At the core of our technique is a new NL-based program synthesis methodology that combines semantic parsing techniques from the NLP community with type-directed program synthesis and automated program repair. Starting with a program sketch obtained using standard parsing techniques, our approach involves an iterative refinement loop that alternates between probabilistic type inhabitation and automated sketch repair. We use the proposed idea to build an end-to-end system called SQLIZER that can synthesize SQL queries from natural language. Our method is fully automated, works for any database without requiring additional customization, and does not require users to know the underlying database schema. We evaluate our approach on over 450 natural language queries concerning three different databases, namely MAS, IMDB, and YELP. Our experiments show that the desired query is ranked within the top 5 candidates in close to 90% of the cases and that SQLIZER outperforms NALIR, a state-of-the-art tool that won a best paper award at VLDB'14."
            },
            "slug": "SQLizer:-query-synthesis-from-natural-language-Yaghmazadeh-Wang",
            "title": {
                "fragments": [],
                "text": "SQLizer: query synthesis from natural language"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This paper presents a new technique for automatically synthesizing SQL queries from natural language (NL) using a new NL-based program synthesis methodology that combines semantic parsing techniques from the NLP community with type-directed program synthesis and automated program repair."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ACM Program. Lang."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 336,
                                "start": 151
                            }
                        ],
                        "text": "Various models have been proposed over the years to learn semantic parsers from natural language expressions paired with their meaning representations (Tang and Mooney, 2000; Ge and Mooney, 2005; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Lu et al., 2008; Kwiatkowski et al., 2011; Andreas et al., 2013; Zhao and Huang, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9337134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2ecc66c0e5f976b0e0d95c64ed2d1e283a2625d",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the first empirical results to our knowledge on learning synchronous grammars that generate logical forms. Using statistical machine translation techniques, a semantic parser based on a synchronous context-free grammar augmented with \ufffdoperators is learned given a set of training sentences and their correct logical forms. The resulting parser is shown to be the bestperforming system so far in a database query domain."
            },
            "slug": "Learning-Synchronous-Grammars-for-Semantic-Parsing-Wong-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A semantic parser based on a synchronous context-free grammar augmented with \ufffdoperators is learned given a set of training sentences and their correct logical forms, and is shown to be the bestperforming system so far in a database query domain."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760868"
                        ],
                        "name": "M. Surdeanu",
                        "slug": "M.-Surdeanu",
                        "structuredName": {
                            "firstName": "Mihai",
                            "lastName": "Surdeanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Surdeanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661918"
                        ],
                        "name": "John Bauer",
                        "slug": "John-Bauer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784228"
                        ],
                        "name": "J. Finkel",
                        "slug": "J.-Finkel",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Finkel",
                            "middleNames": [
                                "Rose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Finkel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105138"
                        ],
                        "name": "Steven Bethard",
                        "slug": "Steven-Bethard",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Bethard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Bethard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2240597"
                        ],
                        "name": "David McClosky",
                        "slug": "David-McClosky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McClosky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David McClosky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 71
                            }
                        ],
                        "text": "(2017), where inputs were lowercased and tokenized by Stanford CoreNLP (Manning et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 136
                            }
                        ],
                        "text": "WIKISQL was preprocessed by the script provided by Zhong et al. (2017), where inputs were lowercased and tokenized by Stanford CoreNLP (Manning et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14068874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f5102ec3f70d0dea98c957cc2cab4d15d83a2da",
            "isKey": false,
            "numCitedBy": 6057,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage."
            },
            "slug": "The-Stanford-CoreNLP-Natural-Language-Processing-Manning-Surdeanu",
            "title": {
                "fragments": [],
                "text": "The Stanford CoreNLP Natural Language Processing Toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The design and use of the Stanford CoreNLP toolkit is described, an extensible pipeline that provides core natural language analysis, and it is suggested that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282833"
                        ],
                        "name": "Z. Wojna",
                        "slug": "Z.-Wojna",
                        "structuredName": {
                            "firstName": "Zbigniew",
                            "lastName": "Wojna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Wojna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 17
                            }
                        ],
                        "text": "Label smoothing (Szegedy et al., 2016) was employed for GEO and ATIS."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206593880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23ffaa0fe06eae05817f527a47ac3291077f9e58",
            "isKey": false,
            "numCitedBy": 15542,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set."
            },
            "slug": "Rethinking-the-Inception-Architecture-for-Computer-Szegedy-Vanhoucke",
            "title": {
                "fragments": [],
                "text": "Rethinking the Inception Architecture for Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work is exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 51694,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800179"
                        ],
                        "name": "Yusuke Oda",
                        "slug": "Yusuke-Oda",
                        "structuredName": {
                            "firstName": "Yusuke",
                            "lastName": "Oda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yusuke Oda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281695"
                        ],
                        "name": "Hiroyuki Fudaba",
                        "slug": "Hiroyuki-Fudaba",
                        "structuredName": {
                            "firstName": "Hiroyuki",
                            "lastName": "Fudaba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hiroyuki Fudaba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700325"
                        ],
                        "name": "Graham Neubig",
                        "slug": "Graham-Neubig",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Neubig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham Neubig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145050815"
                        ],
                        "name": "Hideaki Hata",
                        "slug": "Hideaki-Hata",
                        "structuredName": {
                            "firstName": "Hideaki",
                            "lastName": "Hata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hideaki Hata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783949"
                        ],
                        "name": "S. Sakti",
                        "slug": "S.-Sakti",
                        "structuredName": {
                            "firstName": "Sakriani",
                            "lastName": "Sakti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sakti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726559"
                        ],
                        "name": "T. Toda",
                        "slug": "T.-Toda",
                        "structuredName": {
                            "firstName": "Tomoki",
                            "lastName": "Toda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Toda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145223960"
                        ],
                        "name": "Satoshi Nakamura",
                        "slug": "Satoshi-Nakamura",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Nakamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satoshi Nakamura"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "DJANGO is a diverse dataset, spanning various real-world use cases and as a result models are often faced with out-of-vocabulary (OOV) tokens (e.g., variable names, and numbers) that are unseen during training."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 27
                            }
                        ],
                        "text": "Table 3 reports results on DJANGO where we observe similar tendencies."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 92
                            }
                        ],
                        "text": "In other cases, sketch tokens will not reveal the number of missing tokens (e.g., \u201cSTRING\u201d in DJANGO) but the decoder\u2019s\noutput will indicate whether missing details have been generated (e.g., if the decoder emits a closing quote token for \u201cSTRING\u201d)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 105
                            }
                        ],
                        "text": "Acknowledgments We would like to thank Pengcheng Yin for sharing with us the preprocessed version of the DJANGO dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 29
                            }
                        ],
                        "text": "We employed the preprocessed DJANGO data provided by Yin and Neubig (2017), where input expressions are tokenized by NLTK, and quoted strings in the input are replaced with place holders."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 46
                            }
                        ],
                        "text": "Our second semantic parsing task used DJANGO (Oda et al., 2015), a dataset built upon the Python code of the Django library."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 105
                            }
                        ],
                        "text": "Taken together (Tables 2\u20134), our results show that better sketches bring accuracy gains on GEO, ATIS, and DJANGO."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15979705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27e1dbe9f7c71cd6cc1b0357f49aef497e572d09",
            "isKey": true,
            "numCitedBy": 199,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Pseudo-code written in natural language can aid the comprehension of source code in unfamiliar programming languages. However, the great majority of source code has no corresponding pseudo-code, because pseudo-code is redundant and laborious to create. If pseudo-code could be generated automatically and instantly from given source code, we could allow for on-demand production of pseudo-code without human effort. In this paper, we propose a method to automatically generate pseudo-code from source code, specifically adopting the statistical machine translation (SMT) framework. SMT, which was originally designed to translate between two natural languages, allows us to automatically learn the relationship between source code/pseudo-code pairs, making it possible to create a pseudo-code generator with less human effort. In experiments, we generated English or Japanese pseudo-code from Python statements using SMT, and find that the generated pseudo-code is largely accurate, and aids code understanding."
            },
            "slug": "Learning-to-Generate-Pseudo-Code-from-Source-Code-Oda-Fudaba",
            "title": {
                "fragments": [],
                "text": "Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation (T)"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "SMT, which was originally designed to translate between two natural languages, allows us to automatically learn the relationship between source code/pseudo-code pairs, making it possible to create a pseudo-code generator with less human effort."
            },
            "venue": {
                "fragments": [],
                "text": "2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50202676"
                        ],
                        "name": "Sai Zhang",
                        "slug": "Sai-Zhang",
                        "structuredName": {
                            "firstName": "Sai",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sai Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109306742"
                        ],
                        "name": "Yuyin Sun",
                        "slug": "Yuyin-Sun",
                        "structuredName": {
                            "firstName": "Yuyin",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuyin Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 116
                            }
                        ],
                        "text": "The idea of using sketches as intermediate representations has also been explored in the field of program synthesis (Solar-Lezama, 2008; Zhang and Sun, 2013; Feng et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206511743,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da25db9f7be286072ae05b88e24dacc754c5908a",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer end-users, such as research scientists and business analysts, need to frequently query a database, yet lack enough programming knowledge to write a correct SQL query. To alleviate this problem, we present a programming by example technique (and its tool implementation, called SQLSynthesizer) to help end-users automate such query tasks. SQLSynthesizer takes from users an example input and output of how the database should be queried, and then synthesizes a SQL query that reproduces the example output from the example input. If the synthesized SQL query is applied to another, potentially larger, database with a similar schema, the synthesized SQL query produces a corresponding result that is similar to the example output. We evaluated SQLSynthesizer on 23 exercises from a classic database textbook and 5 forum questions about writing SQL queries. SQLSynthesizer synthesized correct answers for 15 textbook exercises and all 5 forum questions, and it did so from relatively small examples."
            },
            "slug": "Automatically-synthesizing-SQL-queries-from-Zhang-Sun",
            "title": {
                "fragments": [],
                "text": "Automatically synthesizing SQL queries from input-output examples"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a programming by example technique (and its tool implementation, called SQLSynthesizer) to help end-users automate such query tasks and synthesizes a SQL query that reproduces the example output from the example input."
            },
            "venue": {
                "fragments": [],
                "text": "2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991345"
                        ],
                        "name": "R. Bod\u00edk",
                        "slug": "R.-Bod\u00edk",
                        "structuredName": {
                            "firstName": "Rastislav",
                            "lastName": "Bod\u00edk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bod\u00edk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389870240"
                        ],
                        "name": "Armando Solar-Lezama",
                        "slug": "Armando-Solar-Lezama",
                        "structuredName": {
                            "firstName": "Armando",
                            "lastName": "Solar-Lezama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Armando Solar-Lezama"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The idea of using sketches as intermediate representations has also been explored in the field of program synthesis (Solar-Lezama, 2008; Zhang and Sun, 2013; Feng et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8149812,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae74531e6e73afaffb264b4e536b8fde95d03202",
            "isKey": false,
            "numCitedBy": 375,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of software synthesis is to generate programs automatically from high-level specifications. However, efficient implementations for challenging programs require a combination of high-level algorithmic insights and low-level implementation details. Deriving the low-level details is a natural job for a computer, but the synthesizer can not replace the human insight. Therefore, one of the central challenges for software synthesis is to establish a synergy between the programmer and the synthesizer, exploiting the programmer's expertise to reduce the burden on the synthesizer. \nThis thesis introduces sketching, a new style of synthesis that offers a fresh approach to the synergy problem. Previous approaches have relied on meta-programming, or variations of interactive theorem proving to help the synthesizer deduce an efficient implementation. The resulting systems are very powerful, but they require the programmer to master new formalisms far removed from traditional programming models. To make synthesis accessible, programmers must be able to provide their insight effortlessly, using formalisms they already understand. \nIn Sketching, insight is communicated through a partial program, a sketch that expresses the high-level structure of an implementation but leaves holes in place of the low-level details. This form of synthesis is made possible by a new SAT-based inductive synthesis procedure that can efficiently synthesize an implementation from a small number of test cases. This algorithm forms the core of a new counterexample guided inductive synthesis procedure (CEGIS) which combines the inductive synthesizer with a validation procedure to automatically generate test inputs and ensure that the generated program satisfies its specification. With a few extensions, CEGIS can even use its sequential inductive synthesizer to generate concurrent programs; all the concurrency related reasoning is delegated to an off-the-shelf validation procedure. \nThe resulting synthesis system scales to real programming problems from a variety of domains ranging from bit-level ciphers to manipulations of linked datastructures. The system was even used to produce a complete optimized implementation of the AES cipher. The concurrency aware synthesizer was also used to synthesize, in a matter of minutes, the details of a fine-locking scheme for a concurrent set, a sense reversing barrier, and even a solution to the dining philosophers problem. \nThe system was also extended with domain specific knowledge to better handle the problem of implementing stencil computations, an important domain in scientific computing. For this domain, we were able to encode domain specific insight as a problem reduction that converted stencil sketches into simplified sketch problems which CEGIS resolved in a matter of minutes. This specialized synthesizer was used to quickly implement a MultiGrid solver for partial differential equations containing many difficult implementation strategies from the literature. \nIn short, this thesis shows that sketching is a viable approach to making synthesis practical in a general programming context."
            },
            "slug": "Program-synthesis-by-sketching-Bod\u00edk-Solar-Lezama",
            "title": {
                "fragments": [],
                "text": "Program synthesis by sketching"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Sketching is introduced, a new style of synthesis that offers a fresh approach to the synergy problem and shows that sketching is a viable approach to making synthesis practical in a general programming context."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150671055"
                        ],
                        "name": "Yu Feng",
                        "slug": "Yu-Feng",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50780388"
                        ],
                        "name": "Ruben Martins",
                        "slug": "Ruben-Martins",
                        "structuredName": {
                            "firstName": "Ruben",
                            "lastName": "Martins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruben Martins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2021637"
                        ],
                        "name": "Yuepeng Wang",
                        "slug": "Yuepeng-Wang",
                        "structuredName": {
                            "firstName": "Yuepeng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuepeng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714075"
                        ],
                        "name": "Isil Dillig",
                        "slug": "Isil-Dillig",
                        "structuredName": {
                            "firstName": "Isil",
                            "lastName": "Dillig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Isil Dillig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703130"
                        ],
                        "name": "T. Reps",
                        "slug": "T.-Reps",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Reps",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Reps"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 158
                            }
                        ],
                        "text": "The idea of using sketches as intermediate representations has also been explored in the field of program synthesis (Solar-Lezama, 2008; Zhang and Sun, 2013; Feng et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 864767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92d38881d415f628532ddb14c7c00e836ce7dd64",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Component-based approaches to program synthesis assemble programs from a database of existing components, such as methods provided by an API. In this paper, we present a novel type-directed algorithm for component-based synthesis. The key novelty of our approach is the use of a compact Petri-net representation to model relationships between methods in an API. Given a target method signature S, our approach performs reachability analysis on the underlying Petri-net model to identify sequences of method calls that could be used to synthesize an implementation of S. The programs synthesized by our algorithm are guaranteed to type check and pass all test cases provided by the user. We have implemented this approach in a tool called SyPet, and used it to successfully synthesize real-world programming tasks extracted from on-line forums and existing code repositories. We also compare SyPet with two state-of-the-art synthesis tools, namely InSynth and CodeHint, and demonstrate that SyPet can synthesize more programs in less time. Finally, we compare our approach with an alternative solution based on hypergraphs and demonstrate its advantages."
            },
            "slug": "Component-based-synthesis-for-complex-APIs-Feng-Martins",
            "title": {
                "fragments": [],
                "text": "Component-based synthesis for complex APIs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a novel type-directed algorithm for component-based synthesis using a compact Petri-net representation to model relationships between methods in an API, and implements it in a tool called SyPet."
            },
            "venue": {
                "fragments": [],
                "text": "POPL 2017"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 130
                            }
                        ],
                        "text": "Examples include tree decoders (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017), decoders constrained by a grammar model (Xiao et al., 2016; Yin and Neubig, 2017; Krishnamurthy et al., 2017), or modular decoders which use syntax to dynamically compose various submodels (Rabinovich et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A syntactic neural model for general-purpose code generation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 440\u2013 450, Vancouver, Canada."
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 90
                            }
                        ],
                        "text": "Yin and Neubig (2017) design a grammar model for the generation of abstract syntax trees (Aho et al., 2007) in depth-first, left-to-right order."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Compilers: principles, techniques, and tools, volume 2"
            },
            "venue": {
                "fragments": [],
                "text": "Addison-wesley Reading."
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 31
                            }
                        ],
                        "text": "We used the RMSProp optimizer (Tieleman and Hinton, 2012) to train the models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lecture 6.5\u2014 RMSProp: Divide the gradient by a running average of its recent magnitude"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report"
            },
            "year": 2012
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 29,
            "methodology": 23,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 52,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Coarse-to-Fine-Decoding-for-Neural-Semantic-Parsing-Dong-Lapata/fd04e31c25451f9103a0ac2220ac8d7e7884c343?sort=total-citations"
}