{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "The methods using neural networks [20], distribution-based [24], Kullback relative information [4] and naive Bayes [23] report several experimental results based on di erent sets of parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "We tested the SNoW-based approach with both sets of features on the two sets of images collected by Rowley [20], and Sung [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Table 1: Experimental results on images from test set 1 (125 images with 483 faces) in [20] and test set 2 (20 images with 136 faces) in [24] (see text for details)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Sung and Poggio [24] report an example-based learning approach for locating vertical frontal views of human faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "Although it is extremely di\u00c6cult to collect a representative set of non-face examples, the bootstrap method [24] is used to include more non-face examples during training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 101
                            }
                        ],
                        "text": "In order to compare our approach with other methods, our experiments involve two benchmark data sets [20, 24] that have been used in other works on face detection."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": true,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 215
                            }
                        ],
                        "text": "The experimental results on these benchmark data sets (which consist of 225 images with 619 faces) show that our method outperforms all other methods evaluated on this problem, including those using neural networks [20], Kullback relative information [4], naive Bayes [23] and support vector machines [14], while being signi cantly more e\u00c6cient computationally."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 9
                            }
                        ],
                        "text": "In [20], Rowley et al. use an ensemble of neural networks to learn face and non-face patterns for face detection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "The methods using neural networks [20], distribution-based [24], Kullback relative information [4] and naive Bayes [23] report several experimental results based on di erent sets of parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "We tested the SNoW-based approach with both sets of features on the two sets of images collected by Rowley [20], and Sung [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "Table 1: Experimental results on images from test set 1 (125 images with 483 faces) in [20] and test set 2 (20 images with 136 faces) in [24] (see text for details)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "A recent method [21], addresses this problem by building upon a upright face detector [20] and rotating each test sample to upright position."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 101
                            }
                        ],
                        "text": "In order to compare our approach with other methods, our experiments involve two benchmark data sets [20, 24] that have been used in other works on face detection."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": true,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 885215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3dc56324bb35379ed7a9a1b174fc9bd75ea07f80",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a probabilistic method to detect human faces using a mixture of factor analyzers. One characteristic of this mixture model is that it concurrently performs clustering and, within each cluster, local dimensionality reduction. A wide range of face images including ones in different poses, with different expressions and under different lighting conditions are used as the training set to capture the variations of human faces. In order to fit the mixture model to the sample face images, the parameters are estimated using an EM algorithm. Experimental results show that faces in different poses, with different facial expressions, and under different lighting conditions are accurately detected by our method."
            },
            "slug": "Face-detection-using-a-mixture-of-factor-analyzers-Yang-Ahuja",
            "title": {
                "fragments": [],
                "text": "Face detection using a mixture of factor analyzers"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experimental results show that faces in different poses, with different facial expressions, and under different lighting conditions are accurately detected by the probabilistic method presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "A recent method [21], addresses this problem by building upon a upright face detector [20] and rotating each test sample to upright position."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1619589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fd1c99edbb3d22cec4adc9ba9319cfc2360e903",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a neural network-based face detection system. Unlike similar systems which are limited to detecting upright, frontal faces, this system detects faces at any degree of rotation in the image plane. The system employs multiple networks; a \"router\" network first processes each input window to determine its orientation and then uses this information to prepare the window for one or more \"detector\" networks. We present the training methods for both types of networks. We also perform sensitivity analysis on the networks, and present empirical results on a large test set. Finally, we present preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "slug": "Rotation-invariant-neural-network-based-face-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Rotation invariant neural network-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents a neural network-based face detection system, which is limited to detecting upright, frontal faces, and presents preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783224"
                        ],
                        "name": "A. Colmenarez",
                        "slug": "A.-Colmenarez",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Colmenarez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Colmenarez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9192390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e744c3eef4fbc4ac52b2458eb2d545a4432bcb86",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a visual learning technique that maximizes the discrimination between positive and negative examples in a training set. We demonstrate our technique in the context of face detection with complex background without color or motion information, which has proven to be a challenging problem. We use a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics. Then, we convert the learning process into an optimization, selecting the Markov process that optimizes the information-based discrimination between the two classes. The detection process is carried out by computing the likelihood ratio using the probability model obtained from the learning procedure. We show that because of the discrete nature of these models, the detection process is at least two orders of magnitude less computationally expensive than neural network approaches. However, no improvement in terms of correct-answer/false-alarm tradeoff is achieved."
            },
            "slug": "Face-detection-with-information-based-maximum-Colmenarez-Huang",
            "title": {
                "fragments": [],
                "text": "Face detection with information-based maximum discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A visual learning technique that maximizes the discrimination between positive and negative examples in a training set by using a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16705499,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29fe0a5209ad7c538aeaf9819644abac532bcce9",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two methods using mixtures of linear sub-spaces for face detection in gray level images. One method uses a mixture of factor analyzers to concurrently perform clustering and, within each cluster, perform local dimensionality reduction. The parameters of the mixture model are estimated using an EM algorithm. A face is detected if the probability of an input sample is above a predefined threshold. The other mixture of subspaces method uses Kohonen's self-organizing map for clustering and Fisher linear discriminant to find the optimal projection for pattern classification, and a Gaussian distribution to model the class-conditioned density function of the projected samples for each class. The parameters of the class-conditioned density functions are maximum likelihood estimates and the decision rule is also based on maximum likelihood. A wide range of face images including ones in different poses, with different expressions and under different lighting conditions are used as the training set to capture the variations of human faces. Our methods have been tested on three sets of 225 images which contain 871 faces. Experimental results on the first two datasets show that our methods perform as well as the best methods in the literature, yet have fewer false detects."
            },
            "slug": "Face-detection-using-mixtures-of-linear-subspaces-Yang-Ahuja",
            "title": {
                "fragments": [],
                "text": "Face detection using mixtures of linear subspaces"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Two methods using mixtures of linear sub-spaces for face detection in gray level images using Kohonen's self-organizing map for clustering and Fisher linear discriminant to find the optimal projection for pattern classification are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143891066"
                        ],
                        "name": "A. Rajagopalan",
                        "slug": "A.-Rajagopalan",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Rajagopalan",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rajagopalan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39219932"
                        ],
                        "name": "K. S. Kumar",
                        "slug": "K.-S.-Kumar",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "Sunil"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. S. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785111"
                        ],
                        "name": "J. Karlekar",
                        "slug": "J.-Karlekar",
                        "structuredName": {
                            "firstName": "Jayashree",
                            "lastName": "Karlekar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Karlekar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2269939"
                        ],
                        "name": "R. Manivasakan",
                        "slug": "R.-Manivasakan",
                        "structuredName": {
                            "firstName": "Rathinam",
                            "lastName": "Manivasakan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manivasakan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052261268"
                        ],
                        "name": "M. Patil",
                        "slug": "M.-Patil",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Patil",
                            "middleNames": [
                                "Milind"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Patil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144907915"
                        ],
                        "name": "U. Desai",
                        "slug": "U.-Desai",
                        "structuredName": {
                            "firstName": "Uday",
                            "lastName": "Desai",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Desai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2772733"
                        ],
                        "name": "P. G. Poonacha",
                        "slug": "P.-G.-Poonacha",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Poonacha",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. G. Poonacha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144527832"
                        ],
                        "name": "S. Chaudhuri",
                        "slug": "S.-Chaudhuri",
                        "structuredName": {
                            "firstName": "Subhasis",
                            "lastName": "Chaudhuri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chaudhuri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Finally, hidden Markov models [17], higher order statistics [17], and support vector machines (SVM) [14] have also been applied to face detection and demonstrated some success in detecting upright frontal faces under certain lighting conditions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11398552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c610939c03a450617a2d5290f0a4fa731407333",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Two new schemes are presented for finding human faces in a photograph. The first scheme approximates the unknown distributions of the face and the face-like manifolds wing higher order statistics (HOS). An HOS-based data clustering algorithm is also proposed. In the second scheme, the face to non-face and non-face to face transitions are learnt using a hidden Markov model (HMM). The HMM parameters are estimated corresponding to a given photograph and the faces are located by examining the optimal state sequence of the HMM. Experimental results are presented on the performance of both the schemes."
            },
            "slug": "Finding-faces-in-photographs-Rajagopalan-Kumar",
            "title": {
                "fragments": [],
                "text": "Finding faces in photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "Two new schemes for finding human faces in a photograph are presented, one of which approximates the unknown distributions of the face and the face-like manifolds wing higher order statistics (HOS)."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": false,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685300"
                        ],
                        "name": "J. Hespanha",
                        "slug": "J.-Hespanha",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Hespanha",
                            "middleNames": [
                                "Pedro"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hespanha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be86da00efdd8c2a7fdeb2334605796c24b370f0",
            "isKey": false,
            "numCitedBy": 11721,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed \"Fisherface\" method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases."
            },
            "slug": "Eigenfaces-vs.-Fisherfaces:-Recognition-Using-Class-Belhumeur-Hespanha",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A face recognition algorithm which is insensitive to large variation in lighting direction and facial expression is developed, based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variations in lighting and facial expressions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052858104"
                        ],
                        "name": "D. B. Graham",
                        "slug": "D.-B.-Graham",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Graham",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. B. Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50729465"
                        ],
                        "name": "N. Allinson",
                        "slug": "N.-Allinson",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Allinson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Allinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141914838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d40689398f8b055dc0111da1405fcedf16a403e",
            "isKey": false,
            "numCitedBy": 591,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an eigenspace manifold for the representation and recognition of pose-varying faces. The distribution of faces in this manifold allows us to determine theoretical recognition characteristics which are then verified experimentally. Using this manifold a framework is proposed which can be used for both familiar and unfamiliar face recognition. A simple implementation demonstrates the pose dependent nature of the system over the transition from unfamiliar to familiar face recognition. Furthermore we show that multiple test images, whether real or virtual, can be used to augment the recognition process. The results compare favourably with reported human face recognition experiments. Finally, we describe how this framework can be used as a mechanism for characterising faces from video for general purpose recognition."
            },
            "slug": "Characterising-Virtual-Eigensignatures-for-General-Graham-Allinson",
            "title": {
                "fragments": [],
                "text": "Characterising Virtual Eigensignatures for General Purpose Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An eigenspace manifold for the representation and recognition of pose-varying faces is described and a framework is proposed which can be used for both familiar and unfamiliar face recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 301
                            }
                        ],
                        "text": "The experimental results on these benchmark data sets (which consist of 225 images with 619 faces) show that our method outperforms all other methods evaluated on this problem, including those using neural networks [20], Kullback relative information [4], naive Bayes [23] and support vector machines [14], while being signi cantly more e\u00c6cient computationally."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "Finally, hidden Markov models [17], higher order statistics [17], and support vector machines (SVM) [14] have also been applied to face detection and demonstrated some success in detecting upright frontal faces under certain lighting conditions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Support vector machine [14] N/A N/A 74."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": false,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1060186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbe488bb190d75f4b665d43e306bcab1ab228890",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an algorithm for object recognition that explicitly models and estimated the posterior probability function, P(object/image). We have chosen a functional form of the posterior probability function that captures the joint statistics of local appearance and position on the object as well as the statistics of local appearance in the visual world at large. We use a discrete representation of local appearance consisting of approximately 10/sup 6/ patterns. We compute an estimate of P(object/image) in closed form by counting the frequency of occurrence of these patterns over various sets of training images. We have used this method for detecting human faces from frontal and profile views. The algorithm for frontal views has shown a detection rate of 93.0% with 88 false alarms on a set of 125 images containing 483 faces combining the MIT test set of Sung and Poggio with the CMU test sets of Rowley, Baluja, and Kanade. The algorithm for detection of profile views has also demonstrated promising results."
            },
            "slug": "Probabilistic-modeling-of-local-appearance-and-for-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "Probabilistic modeling of local appearance and spatial relationships for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "An algorithm for object recognition that explicitly models and estimated the posterior probability function, P(object/image) in closed form is described, which captures the joint statistics of local appearance and position on the object as well as the statistics ofLocal appearance in the visual world at large."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "In training the SNoW-based face detector, we use a set of 1,681 face images from Olivetti [22], UMIST [6], Harvard [7], Yale [1] and FERET [15] databases to capture the variations in face patterns."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "For training, we use a set of 1,681 face images (collected from Olivetti [22], UMIST [6], Harvard [7], Yale [1] and FERET [15] databases) which have wide variations in pose, facial expression and lighting condition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 127635371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6734e69323b52603f6d172cbb25c55da32488ecb",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. The FERET database is divided into two portions. The development portion is provided to researchers for algorithm development and the sequestered portion provides a set of images not seen by the researchers to test algorithms. The set of test is the third in a sequence of FERET tests. This test was administered in September 1996 and March 1997. The Sept96 test provided a detailed assesment of the state of the art, measurement of algorithm performance on large databases, and a comparison among face recognition algorithms."
            },
            "slug": "The-FERET-Evaluation-Phillips-Moon",
            "title": {
                "fragments": [],
                "text": "The FERET Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Sept96 test provided a detailed assesment of the state of the art, measurement of algorithm performance on large databases, and a comparison among face recognition algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717217"
                        ],
                        "name": "R. J. Qian",
                        "slug": "R.-J.-Qian",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Qian",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J. Qian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9413838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b54f72748b74fc815aa802aaef90c3685ca8f3d6",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new scale, position and orientation invariant approach to object detection. The proposed method first chooses attention regions in an image based on the region detection result on the image. Within the attention regions, the method then detects targets using a novel object detection algorithm that combines template matching methods with feature-based methods via hierarchical MRF and MAP estimation. Hierarchical MRF and MAP estimation provide a flexible framework to incorporate various visual clues. The combination of template matching and feature detection helps to achieve robustness against complex backgrounds and partial occlusions in object detection. Experimental results are given in the paper."
            },
            "slug": "Object-detection-using-hierarchical-MRF-and-MAP-Qian-Huang",
            "title": {
                "fragments": [],
                "text": "Object detection using hierarchical MRF and MAP estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel object detection algorithm that combines template matching methods with feature-based methods via hierarchical MRF and MAP estimation is presented, which helps to achieve robustness against complex backgrounds and partial occlusions in object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3190501"
                        ],
                        "name": "D. Zelenko",
                        "slug": "D.-Zelenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Zelenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zelenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1177419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1d3c5653dd4717df19b99709d81b08be44f268a",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an architecture and an on-line learning algorithm and apply it to the problem of part-of-speech tagging. The architecture presented, SNOW, is a network of linear separators in the feature space, utilizing the Winnow update algorithm.Multiplicative weight-update algorithms such as Winnow have been shown to have exceptionally good behavior when applied to very high dimensional problems, and especially when the target concepts depend on only a small subset of the features in the feature space. In this paper we describe an architecture that utilizes this mistake-driven algorithm for multi-class prediction-selecting the part of speech of a word. The experimental analysis presented here provides more evidence to that these algorithms are suitable for natural language problems.The algorithm used is an on-line algorithm: every example is used by the algorithm only once, and is then discarded. This has significance in terms of efficiency, as well as quick adaptation to new contexts.We present an extensive experimental study of our algorithm under various conditions; in particular, it is shown that the algorithm performs comparably to the best known algorithms for POS."
            },
            "slug": "Part-of-Speech-Tagging-Using-a-Network-of-Linear-Roth-Zelenko",
            "title": {
                "fragments": [],
                "text": "Part of Speech Tagging Using a Network of Linear Separators"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "An architecture and an on-line learning algorithm are presented that utilizes this mistake-driven algorithm for multi-class prediction-selecting the part of speech of a word and it is shown that the algorithm performs comparably to the best known algorithms for POS."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700597"
                        ],
                        "name": "Jyrki Kivinen",
                        "slug": "Jyrki-Kivinen",
                        "structuredName": {
                            "firstName": "Jyrki",
                            "lastName": "Kivinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyrki Kivinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6130401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98eed3f082351c4821d1edb315846207a8fefbe9",
            "isKey": false,
            "numCitedBy": 911,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider two algorithm for on-line prediction based on a linear model. The algorithms are the well-known Gradient Descent (GD) algorithm and a new algorithm, which we call EG(+/-). They both maintain a weight vector using simple updates. For the GD algorithm, the update is based on subtracting the gradient of the squared error made on a prediction. The EG(+/-) algorithm uses the components of the gradient in the exponents of factors that are used in updating the weight vector multiplicatively. We present worst-case loss bounds for EG(+/-) and compare them to previously known bounds for the GD algorithm. The bounds suggest that the losses of the algorithms are in general incomparable, but EG(+/-) has a much smaller loss if only a few components of the input are relevant for the predictions. We have performed experiments, which show that our worst-case upper bounds are quite tight already on simple artificial data."
            },
            "slug": "Exponentiated-Gradient-Versus-Gradient-Descent-for-Kivinen-Warmuth",
            "title": {
                "fragments": [],
                "text": "Exponentiated Gradient Versus Gradient Descent for Linear Predictors"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The bounds suggest that the losses of the algorithms are in general incomparable, but EG(+/-) has a much smaller loss if only a few components of the input are relevant for the predictions, which is quite tight already on simple artificial data."
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ed17a1114e2dc48597ab17cc8d5234006f525c9",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze a few of the commonly used statistics based and machine learning algorithms for natural language disambiguation tasks and observe that they can be recast as learning linear separators in the feature space. Each of the methods makes a priori assumptions which it employs, given the data, when searching for its hypothesis. Nevertheless, as we show, it searches a space that is as rich as the space of all linear separators. We use this to build an argument for a data driven approach which merely searches for a good linear separator in the feature space, without further assumptions on the domain or a specific problem.We present such an approach - a sparse network of linear separators, utilizing the Winnow learning algorithm - and show how to use it in a variety of ambiguity resolution problems. The learning approach presented is attribute-efficient and, therefore, appropriate for domains having very large number of attributes.In particular, we present an extensive experimental comparison of our approach with other methods on several well studied lexical disambiguation tasks such as context-sensitive spelling correction, prepositional phrase attachment and part of speech tagging. In all cases we show that our approach either outperforms other methods tried for these tasks or performs comparably to the best."
            },
            "slug": "Learning-to-Resolve-Natural-Language-Ambiguities:-A-Roth",
            "title": {
                "fragments": [],
                "text": "Learning to Resolve Natural Language Ambiguities: A Unified Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An extensive experimental comparison of the approach with other methods on several well studied lexical disambiguation tasks such as context-sensitive spelling correction, prepositional phrase attachment and part of speech tagging shows that it outperforms other methods tried for these tasks or performs comparably to the best."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 307,
                                "start": 300
                            }
                        ],
                        "text": "Winnow is known to learn e\u00c6ciently any linear threshold function and to be robust in the presence of various kinds of noise and in cases where no linear-threshold function can make perfect classi cation, and still maintain its abovementioned dependence on the number of total and relevant attributes [11, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35643382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba51a954699dd2df2c89c4972411a6f18235b81d",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Redundant-noisy-attributes,-attribute-errors,-and-Littlestone",
            "title": {
                "fragments": [],
                "text": "Redundant noisy attributes, attribute errors, and linear-threshold learning using winnow"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145528516"
                        ],
                        "name": "M. Mu\u00f1oz",
                        "slug": "M.-Mu\u00f1oz",
                        "structuredName": {
                            "firstName": "Marcia",
                            "lastName": "Mu\u00f1oz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mu\u00f1oz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474158"
                        ],
                        "name": "Vasin Punyakanok",
                        "slug": "Vasin-Punyakanok",
                        "structuredName": {
                            "firstName": "Vasin",
                            "lastName": "Punyakanok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vasin Punyakanok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2680974"
                        ],
                        "name": "Dav Zimak",
                        "slug": "Dav-Zimak",
                        "structuredName": {
                            "firstName": "Dav",
                            "lastName": "Zimak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dav Zimak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1599627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a31d6f597f78599c6df66dedf64cd5bc05c5327a",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A SNoW based learning approach to shallow parsing tasks is presented and studied experimentally. The approach learns to identify syntactic patterns by combining simple predictors to produce a coherent inference. Two instantiations of this approach are studied and experimental results for Noun-Phrases (NP) and Subject-Verb (SV) phrases that compare favorably with the best published results are presented. In doing that, we compare two ways of modeling the problem of learning to recognize patterns and suggest that shallow parsing patterns are better learned using open/close predictors than using inside/outside predictors.} thus contribute to the understanding of how to model shallow parsing tasks as learning problems."
            },
            "slug": "A-Learning-Approach-to-Shallow-Parsing-Mu\u00f1oz-Punyakanok",
            "title": {
                "fragments": [],
                "text": "A Learning Approach to Shallow Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work compares two ways of modeling the problem of learning to recognize patterns and suggests that shallow parsing patterns are better learned using open/close predictors than using inside/outside predictors and thus contribute to the understanding of how to model shallow parsing tasks as learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772099"
                        ],
                        "name": "D. Helmbold",
                        "slug": "D.-Helmbold",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Helmbold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmbold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 131
                            }
                        ],
                        "text": "In the on-line setting [10] this is usually phrased in terms of a mistake-bound but is known to imply convergence in the PAC sense [25, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16694241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c58afc1b7fd284351d6897f315617084087d4340",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is a weak learning algorithm if with some small probability it outputs a hypothesis with error slightly below 50%. This paper presents relationships between weak learning, weak prediction (where the probability of being correct is slightly larger than 50%), and consistency oracles (which decide whether or not a given set of examples is consistent with a concept in the class). Our main result is a simple polynomial prediction algorithm which makes only a single query to a consistency oracle and whose predictions have a polynomial edge over random guessing. We compare this prediction algorithm with several of the standard prediction techniques, deriving an improved worst case bound on Gibbs algorithm in the process. We use our algorithm to show that a concept class is polynomially learnable if and only if there is a polynomial probabilistic consistency oracle for the class. Since strong learning algorithms can be built from weak learning algorithms, our results also characterizes strong learnability."
            },
            "slug": "On-Weak-Learning-Helmbold-Warmuth",
            "title": {
                "fragments": [],
                "text": "On Weak Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents relationships between weak learning, weak prediction, and consistency oracles and uses an algorithm to show that a concept class is polynomially learnable if and only if there is a polynomial probabilistic consistency oracle for the class."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "SNoW (Sparse Network of Winnows) is a sparse network of linear functions that utilizes the Winnow update rule [9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "To make the detection method 1In the on-line setting [9] this is usually phrased in terms of a mistake-bound but is known to imply convergence in the PAC sense [24, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6334230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1dace286582d91916fe470d08f30381cf453f20",
            "isKey": false,
            "numCitedBy": 1612,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space."
            },
            "slug": "Learning-Quickly-When-Irrelevant-Attributes-Abound:-Littlestone",
            "title": {
                "fragments": [],
                "text": "Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions."
            },
            "venue": {
                "fragments": [],
                "text": "28th Annual Symposium on Foundations of Computer Science (sfcs 1987)"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 131
                            }
                        ],
                        "text": "In the on-line setting [10] this is usually phrased in terms of a mistake-bound but is known to imply convergence in the PAC sense [25, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10ddb646feddc12337b5a755c72e153e37088c02",
            "isKey": false,
            "numCitedBy": 4189,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learnt using it in a reasonable (polynomial) number of steps. We find that inherent algorithmic complexity appears to set serious limits to the range of concepts that can be so learnt. The methodology and results suggest concrete principles for designing realistic learning systems."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '84"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "In training the SNoW-based face detector, we use a set of 1,681 face images from Olivetti [22], UMIST [6], Harvard [7], Yale [1] and FERET [15] databases to capture the variations in face patterns."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "For training, we use a set of 1,681 face images (collected from Olivetti [22], UMIST [6], Harvard [7], Yale [1] and FERET [15] databases) which have wide variations in pose, facial expression and lighting condition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs. sherfaces: Recognition using class speci c linear projection"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic visual learning for object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs. sherfaces: Recognition using class speciic linear projection"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "4% 3 (4) Fisher linear discriminant [26] 93."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mixtures of linear subspaces for face detection"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the Foruth IEEE International Conference on Automatic Face and Gesture Recognition,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 91
                            }
                        ],
                        "text": "In this paper, we present a face detection method that uses the SNoW learning architecture [18, 3] to detect faces with di erent features and expressions, in di erent poses, and under di erent lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SNoW learning architecture"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report UIUCDCS-R-99-2101,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "In training the SNoW-based face detector, we use a set of 1,681 face images from Olivetti [22], UMIST [6], Harvard [7], Yale [1] and FERET [15] databases to capture the variations in face patterns."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "For training, we use a set of 1,681 face images (collected from Olivetti [22], UMIST [6], Harvard [7], Yale [1] and FERET [15] databases) which have wide variations in pose, facial expression and lighting condition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Deformable Model for Face Recognition Under Arbitrary Lighting Conditions"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, Harvard University,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Finding faces inphotographs Neural network - based face detection"
            },
            "venue": {
                "fragments": [],
                "text": "Face Recognition : From Theoryto Applications , volume 163 of NATO ASI Series F , Computer and Systems Sciences"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 91
                            }
                        ],
                        "text": "In this paper, we present a face detection method that uses the SNoW learning architecture [16, 17] to detect faces with di erent features and expressions, in different poses, and under di erent lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SNoW learning arcitecture"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report UIUCDCS-R-99-2101, UIUC Computer  Science Department,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Part of speech tagging using a network of linear separators The 17th Int. Conference on Computational Linguistics Neural network-based face detection"
            },
            "venue": {
                "fragments": [],
                "text": "COLING- ACL 98"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 91
                            }
                        ],
                        "text": "In this paper, we present a face detection method that uses the SNoW learning architecture [16, 17] to detect faces with di erent features and expressions, in different poses, and under di erent lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SNoW learning arcitecture"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report UIUCDCS-R-99-2101, UIUC Computer  Science Department,"
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 11,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/A-SNoW-Based-Face-Detector-Yang-Roth/23234a0f211a44d9706b2570d474427b8f899ec1?sort=total-citations"
}