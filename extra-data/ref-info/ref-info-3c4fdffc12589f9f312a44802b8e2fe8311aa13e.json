{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": false,
            "numCitedBy": 11229,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2432463"
                        ],
                        "name": "E. Hjelm\u00e5s",
                        "slug": "E.-Hjelm\u00e5s",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Hjelm\u00e5s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hjelm\u00e5s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054024193"
                        ],
                        "name": "B. K. Low",
                        "slug": "B.-K.-Low",
                        "structuredName": {
                            "firstName": "Boon",
                            "lastName": "Low",
                            "middleNames": [
                                "Kee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K. Low"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15724653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "887567782cb859ecd339693589056903b0071353",
            "isKey": false,
            "numCitedBy": 1649,
            "numCiting": 336,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a comprehensive and critical survey of face detection algorithms. Face detection is a necessary first-step in face recognition systems, with the purpose of localizing and extracting the face region from the background. It also has several applications in areas such as content-based image retrieval, video coding, video conferencing, crowd surveillance, and intelligent human?computer interfaces. However, it was not until recently that the face detection problem received considerable attention among researchers. The human face is a dynamic object and has a high degree of variability in its apperance, which makes face detection a difficult problem in computer vision. A wide variety of techniques have been proposed, ranging from simple edge-based algorithms to composite high-level approaches utilizing advanced pattern recognition methods. The algorithms presented in this paper are classified as either feature-based or image-based and are discussed in terms of their technical approach and performance. Due to the lack of standardized tests, we do not provide a comprehensive comparative evaluation, but in cases where results are reported on common datasets, comparisons are presented. We also give a presentation of some proposed applications and possible application areas."
            },
            "slug": "Face-Detection:-A-Survey-Hjelm\u00e5s-Low",
            "title": {
                "fragments": [],
                "text": "Face Detection: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A comprehensive and critical survey of face detection algorithms, ranging from simple edge-based algorithms to composite high-level approaches utilizing advanced pattern recognition methods, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50024179"
                        ],
                        "name": "Yongmin Li",
                        "slug": "Yongmin-Li",
                        "structuredName": {
                            "firstName": "Yongmin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongmin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934996"
                        ],
                        "name": "H. Liddell",
                        "slug": "H.-Liddell",
                        "structuredName": {
                            "firstName": "Heather",
                            "lastName": "Liddell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Liddell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1889567,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf0a5ddc4e80359418e8a66f6f6c068efd12c1d3",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A support vector machine-based multi-view face detection and recognition framework is described. Face detection is carried out by constructing several detectors, each of them in charge of one specific view. The symmetrical property of face images is employed to simplify the complexity of the modelling. The estimation of head pose, which is achieved by using the support vector regression technique, provides crucial information for choosing the appropriate face detector. This helps to improve the accuracy and reduce the computation in multi-view face detection compared to other methods. For video sequences, further computational reduction can be achieved by using a pose change smoothing strategy. When face detectors find a face in frontal view, a support vector machine-based multi-class classifier is activated for face recognition. All the above issues are integrated under a support vector machine framework. Test results on four video sequences are presented, among them the detection rate is above 95%, recognition accuracy is above 90%, average pose estimation error is around 10/spl deg/, and the full detection and recognition speed is up to 4 frames/second on a Pentium II 300 PC."
            },
            "slug": "Support-vector-regression-and-classification-based-Li-Gong",
            "title": {
                "fragments": [],
                "text": "Support vector regression and classification based multi-view face detection and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The estimation of head pose, which is achieved by using the support vector regression technique, provides crucial information for choosing the appropriate face detector, which helps to improve the accuracy and reduce the computation in multi-view face detection compared to other methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": false,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2721983"
                        ],
                        "name": "F. Fleuret",
                        "slug": "F.-Fleuret",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Fleuret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fleuret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6754141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b535f4edc4cbf8d4fb6182ec6b5c54db3c1cccb",
            "isKey": false,
            "numCitedBy": 339,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We study visual selection: Detect and roughly localize all instances of a generic object class, such as a face, in a greyscale scene, measuring performance in terms of computation and false alarms. Our approach is sequential testing which is coarse-to-fine in both in the exploration of poses and the representation of objects. All the tests are binary and indicate the presence or absence of loose spatial arrangements of oriented edge fragments. Starting from training examples, we recursively find larger and larger arrangements which are \u201cdecomposable,\u201d which implies the probability of an arrangement appearing on an object decays slowly with its size. Detection means finding a sufficient number of arrangements of each size along a decreasing sequence of pose cells. At the beginning, the tests are simple and universal, accommodating many poses simultaneously, but the false alarm rate is relatively high. Eventually, the tests are more discriminating, but also more complex and dedicated to specific poses. As a result, the spatial distribution of processing is highly skewed and detection is rapid, but at the expense of (isolated) false alarms which, presumably, could be eliminated with localized, more intensive, processing."
            },
            "slug": "Coarse-to-Fine-Face-Detection-Fleuret-Geman",
            "title": {
                "fragments": [],
                "text": "Coarse-to-Fine Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The approach is sequential testing which is coarse-to-fine in both in the exploration of poses and the representation of objects, and the spatial distribution of processing is highly skewed and detection is rapid, but at the expense of (isolated) false alarms which could be eliminated with localized, more intensive, processing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1709452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23234a0f211a44d9706b2570d474427b8f899ec1",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel learning approach for human face detection using a network of linear units is presented. The SNoW learning architecture is a sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of features. A wide range of face images in different poses, with different expressions and under different lighting conditions are used as a training set to capture the variations of human faces. Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others. Furthermore, learning and evaluation using the SNoW-based method are significantly more efficient than with other methods."
            },
            "slug": "A-SNoW-Based-Face-Detector-Yang-Roth",
            "title": {
                "fragments": [],
                "text": "A SNoW-Based Face Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6476085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76f560991d56ad689ec32f9e9d13291e0193f4cf",
            "isKey": false,
            "numCitedBy": 1604,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general trainable framework for object detection in static images of cluttered scenes. The detection technique we develop is based on a wavelet representation of an object class derived from a statistical analysis of the class instances. By learning an object class in terms of a subset of an overcomplete dictionary of wavelet basis functions, we derive a compact representation of an object class which is used as an input to a support vector machine classifier. This representation overcomes both the problem of in-class variability and provides a low false detection rate in unconstrained environments. We demonstrate the capabilities of the technique in two domains whose inherent information content differs significantly. The first system is face detection and the second is the domain of people which, in contrast to faces, vary greatly in color, texture, and patterns. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or motion-based segmentation. The paper also presents a motion-based extension to enhance the performance of the detection algorithm over video sequences. The results presented here suggest that this architecture may well be quite general."
            },
            "slug": "A-general-framework-for-object-detection-Papageorgiou-Oren",
            "title": {
                "fragments": [],
                "text": "A general framework for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A general trainable framework for object detection in static images of cluttered scenes based on a wavelet representation of an object class derived from a statistical analysis of the class instances and a motion-based extension to enhance the performance of the detection algorithm over video sequences is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3430625"
                        ],
                        "name": "R. F\u00e9raud",
                        "slug": "R.-F\u00e9raud",
                        "structuredName": {
                            "firstName": "Rapha\u00ebl",
                            "lastName": "F\u00e9raud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. F\u00e9raud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118328"
                        ],
                        "name": "O. Bernier",
                        "slug": "O.-Bernier",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bernier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bernier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35094984"
                        ],
                        "name": "J. Viallet",
                        "slug": "J.-Viallet",
                        "structuredName": {
                            "firstName": "Jean-Emmanuel",
                            "lastName": "Viallet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Viallet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586567"
                        ],
                        "name": "M. Collobert",
                        "slug": "M.-Collobert",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collobert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14916909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecbddc709e20fcec77fb7252941e0dacff6a93d5",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting faces in images with complex backgrounds is a difficult task. Our approach, which obtains state-of-the-art results, is based on a generative neural network model: the constrained generative model (CGM). To detect side-view faces and to decrease the number of false alarms, a conditional mixture of networks is used. To decrease the computational time cost, a fast search algorithm is proposed. The level of performance reached, in terms of detection accuracy and processing time, allows us to apply this detector to a real-world application: the indexation of face images on the WWW."
            },
            "slug": "A-fast-and-accurate-face-detector-for-indexation-of-F\u00e9raud-Bernier",
            "title": {
                "fragments": [],
                "text": "A fast and accurate face detector for indexation of face images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The level of performance reached in this approach, in terms of detection accuracy and processing time, allows this detector to apply to a real-world application: the indexation of face images on the WWW."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061346023"
                        ],
                        "name": "David",
                        "slug": "David",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1819046"
                        ],
                        "name": "Xuhui Shao",
                        "slug": "Xuhui-Shao",
                        "structuredName": {
                            "firstName": "Xuhui",
                            "lastName": "Shao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuhui Shao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10671627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac942c4870e55fe1d9822d62edcdb685d41cd2bf",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Most face recognition systems assume that the geometry of the image formation process is frontal. If additional poses, beyond the frontal one, are possible, then it becomes necessary to estimate the actual imaging pose. Once a face is detected and its pose is estimated one proceeds by normalizing the face images to account for geometrical and illumination changes, possibly using information about the location and appearance of facial landmarks such as the eyes. This paper describes a novel approach for the problem of pose estimation and eye detection using Support Vector Machines (SVM). Experimental results using frontal, and 33.75\u00b0 rotated left and right poses, respectively, demonstrate the feasibility of our approach for pose estimation. The image (face) data comes from the standard FERET data base, the training set consists of 150 images equally distributed among frontal, 33.75\u00b0 rotated left and right poses, respectively, and the test set consists of 450 images again equally distributed among the three different types of poses. The accuracy observed on test data, using both polynomials of degree 3 and Radial Basis Functions (RBFs) as kernel approximation functions, to determine the SVM separating hyperplanes, has been 100%. On the eye detection task, the training data consisted of 186 eye images and 186 non-eye images. SVM was tested against 200 test examples (eye and non-eye). The best generalization performance of 4% was achieved using polynomial kernels of second degree as the set of approximating functions. SVM appear to be robust classification schemes and this suggests their use for additional face recognition tasks, such as surveillance."
            },
            "slug": "Pose-Discriminiation-and-Eye-Detection-Using-Vector-Huang-David",
            "title": {
                "fragments": [],
                "text": "Pose Discriminiation and Eye Detection Using Support Vector Machines (SVM)"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel approach for the problem of pose estimation and eye detection using Support Vector Machines (SVM), which appears to be robust classification schemes and this suggests their use for additional face recognition tasks, such as surveillance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113532503"
                        ],
                        "name": "Wei Fan",
                        "slug": "Wei-Fan",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807433"
                        ],
                        "name": "S. Stolfo",
                        "slug": "S.-Stolfo",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Stolfo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Stolfo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49050246"
                        ],
                        "name": "Junxin Zhang",
                        "slug": "Junxin-Zhang",
                        "structuredName": {
                            "firstName": "Junxin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junxin Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207661373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b1b1899487d4c897df5bc66818d52dd3f326c24",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to use AdaBoost to efficiently learn classifiers over very large and possibly distributed data sets that cannot fit into main memory, as well as on-line learning where new data become available periodically. We propose two new ways to apply AdaBoost. The first allows the use of a small sample of the weighted training set to compute a weak hypothesis. The second approach involves using AdaBoost as a means to re-weight classifiers in an ensemble, and thus to reuse previously computed classifiers along with new classifier computed on a new increment of data. These two techniques of using AdaBoost provide scalable, distributed and on-line learning. We discuss these methods and their implementation in JAM, an agent-based learning system. Empirical studies on four real world and artifical data sets have shown results that are either comparable to or better than learning classifiers over the complete training set and, in some cases, are comparable to boosting on the complete data set. However, our algorithms use much smaller samples of the training set and require much less memory."
            },
            "slug": "The-application-of-AdaBoost-for-distributed,-and-Fan-Stolfo",
            "title": {
                "fragments": [],
                "text": "The application of AdaBoost for distributed, scalable and on-line learning"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "Two new ways to apply AdaBoost are proposed to efficiently learn classifiers over very large and possibly distributed data sets that cannot fit into main memory, as well as on-line learning where new data become available periodically."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9913392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f4493eff2531536a7aeb3fc11d62c30a8f487f6",
            "isKey": false,
            "numCitedBy": 4829,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting is one of the most important recent developments in classification methodology. Boosting works by sequentially applying a classification algorithm to reweighted versions of the training data and then taking a weighted majority vote of the sequence of classifiers thus produced. For many classification algorithms, this simple strategy results in dramatic improvements in performance. We show that this seemingly mysterious phenomenon can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multiclass generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multiclass generalizations of boosting in most situations, and far superior in some. We suggest a minor modification to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-first truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally, making it more suitable to large-scale data mining applications."
            },
            "slug": "Special-Invited-Paper-Additive-logistic-regression:-Friedman",
            "title": {
                "fragments": [],
                "text": "Special Invited Paper-Additive logistic regression: A statistical view of boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that this seemingly mysterious phenomenon of boosting can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood, and develops more direct approximations and shows that they exhibit nearly identical results to boosting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1893129"
                        ],
                        "name": "M. Bichsel",
                        "slug": "M.-Bichsel",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Bichsel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bichsel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62911157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b23f4919527264148762d476c58a7b21a21808dd",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract If we consider an n \u00d7 n image as an n2-dimensional vector, then images of faces can be considered as points in this n2-dimensional image space. Our previous studies of physical transformations of the face, including translation, small rotations, and illumination changes, showed that the set of face images consists of relatively simple connected subregions in image space. Consequently linear matching techniques can be used to obtain reliable face recognition. However, for more general transformations, such as large rotations or scale changes, the face subregions become highly non-convex. We have therefore developed a scale-space matching technique that allows us to take advantage of knowledge about important geometrical transformations and about the topology of the face subregion in image space. While recognition of faces is the focus of this paper, the algorithm is sufficiently general to be applicable to a large variety of object recognition tasks"
            },
            "slug": "Human-Face-Recognition-and-the-Face-Image-Set's-Bichsel-Pentland",
            "title": {
                "fragments": [],
                "text": "Human Face Recognition and the Face Image Set's Topology"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A scale-space matching technique that allows it to take advantage of knowledge about important geometrical transformations and about the topology of the face subregion in image space to be applicable to a large variety of object recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35651617"
                        ],
                        "name": "Kenneth Wilder",
                        "slug": "Kenneth-Wilder",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Wilder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Wilder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2023689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f7c640ea1fe32e017c68005ef5e18969039b3f4",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a very large family of binary features for two-dimensional shapes. The salient ones for separating particular shapes are determined by inductive learning during the construction of classification trees. There is a feature for every possible geometric arrangement of local topographic codes. The arrangements express coarse constraints on relative angles and distances among the code locations and are nearly invariant to substantial affine and nonlinear deformations. They are also partially ordered, which makes it possible to narrow the search for informative ones at each node of the tree. Different trees correspond to different aspects of shape. They are statistically and weakly dependent due to randomization and are aggregated in a simple way. Adapting the algorithm to a shape family is then fully automatic once training samples are provided. As an illustration, we classified handwritten digits from the NIST database; the error rate was 0.7 percent."
            },
            "slug": "Joint-Induction-of-Shape-Features-and-Tree-Amit-Wilder",
            "title": {
                "fragments": [],
                "text": "Joint Induction of Shape Features and Tree Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A very large family of binary features for two-dimensional shapes determined by inductive learning during the construction of classification trees is introduced, which makes it possible to narrow the search for informative ones at each node of the tree."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055592233"
                        ],
                        "name": "J. Ng",
                        "slug": "J.-Ng",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18504340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61823c18e0065300add3611dd113748d765cddf5",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines have shown great potential for learning classification functions that can be applied to object recognition. In this work, we extend SVMs to model the 2D appearance of human faces which undergo nonlinear change across the view sphere. The model enables simultaneous multi-view face detection and pose estimation at near-frame rate."
            },
            "slug": "Multi-view-face-detection-and-pose-estimation-using-Ng-Gong",
            "title": {
                "fragments": [],
                "text": "Multi-view face detection and pose estimation using a composite support vector machine across the view sphere"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work extends SVMs to model the 2D appearance of human faces which undergo nonlinear change across the view sphere and enables simultaneous multi-view face detection and pose estimation at near-frame rate."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1819046"
                        ],
                        "name": "Xuhui Shao",
                        "slug": "Xuhui-Shao",
                        "structuredName": {
                            "firstName": "Xuhui",
                            "lastName": "Shao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuhui Shao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1902304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c4c61440cfceddf1b1521ee7abf04ed31b79f37",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an approach for the problem of face pose discrimination using support vector machines (SVM). Face pose discrimination means that one can label the face image as one of several known poses. Face images are drawn from the standard FERET database. The training set consists of 150 images equally distributed among frontal, approximately 33.75/spl deg/ rotated left and right poses, respectively, and the test set consists of 450 images again equally distributed among the three different types of poses. SVM achieved perfect accuracy-100%-discriminating between the three possible face poses on unseen test data, using either polynomials of degree 3 or radial basis functions (RBF) as kernel approximation functions."
            },
            "slug": "Face-pose-discrimination-using-support-vector-(SVM)-Huang-Shao",
            "title": {
                "fragments": [],
                "text": "Face pose discrimination using support vector machines (SVM)"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This paper describes an approach for the problem of face pose discrimination using support vector machines (SVM), which achieved perfect accuracy-100%-discriminating between the three possible face poses on unseen test data, using either polynomials of degree 3 or radial basis functions (RBF) as kernel approximation functions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022386739"
                        ],
                        "name": "Peter Barlett",
                        "slug": "Peter-Barlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Barlett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Barlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740222"
                        ],
                        "name": "Wee Sun Lee",
                        "slug": "Wee-Sun-Lee",
                        "structuredName": {
                            "firstName": "Wee",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wee Sun Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 573509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d19272112b50547614479a0c409fca66e3b05f7",
            "isKey": false,
            "numCitedBy": 2844,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximum number of votes received by any incorrect label. We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error. We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples. Finally, we compare our explanation to those based on the bias-variance"
            },
            "slug": "Boosting-the-margin:-A-new-explanation-for-the-of-Schapire-Freund",
            "title": {
                "fragments": [],
                "text": "Boosting the margin: A new explanation for the effectiveness of voting methods"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2527920"
                        ],
                        "name": "Douglas E. Zongker",
                        "slug": "Douglas-E.-Zongker",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Zongker",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douglas E. Zongker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1764288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a5b31aaefd943b8eb3334fda53311b06f0bdbf5",
            "isKey": false,
            "numCitedBy": 2259,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "A large number of algorithms have been proposed for feature subset selection. Our experimental results show that the sequential forward floating selection algorithm, proposed by Pudil et al. (1994), dominates the other algorithms tested. We study the problem of choosing an optimal feature set for land use classification based on SAR satellite images using four different texture models. Pooling features derived from different texture models, followed by a feature selection results in a substantial improvement in the classification accuracy. We also illustrate the dangers of using feature selection in small sample size situations."
            },
            "slug": "Feature-Selection:-Evaluation,-Application,-and-Jain-Zongker",
            "title": {
                "fragments": [],
                "text": "Feature Selection: Evaluation, Application, and Small Sample Performance"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work studies the problem of choosing an optimal feature set for land use classification based on SAR satellite images using four different texture models and shows that pooling features derived from different texture Models, followed by a feature selection results in a substantial improvement in the classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14647160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2ef3d741a8d267b813781a73d4222b6dbba99fa",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Signal processing and pattern recognition algorithms make extensive use of convolution. In many cases, computational accuracy is not as important as computational speed. In feature extraction, for instance, the features of interest in a signal are usually quite distorted. This form of noise justifies some level of quantization in order to achieve faster feature extraction. Our approach consists of approximating regions of the signal with low degree polynomials, and then differentiating the resulting signals in order to obtain impulse functions (or derivatives of impulse functions). With this representation, convolution becomes extremely simple and can be implemented quite effectively. The true convolution can be recovered by integrating the result of the convolution. This method yields substantial speed up in feature extraction and is applicable to convolutional neural networks."
            },
            "slug": "Boxlets:-A-Fast-Convolution-Algorithm-for-Signal-Simard-Bottou",
            "title": {
                "fragments": [],
                "text": "Boxlets: A Fast Convolution Algorithm for Signal Processing and Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The approach consists of approximating regions of the signal with low degree polynomials, and then differentiating the resulting signals in order to obtain impulse functions (or derivatives of impulse functions) and yields substantial speed up in feature extraction."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12209481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3565c5a65842f26091578b9d71d496cc1561239d",
            "isKey": false,
            "numCitedBy": 1292,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints."
            },
            "slug": "A-statistical-method-for-3D-object-detection-to-and-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "A statistical method for 3D object detection applied to faces and cars"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using this method, this work has developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithms thatCan reliably detect passenger cars over a wide range of viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6435894"
                        ],
                        "name": "S. McKenna",
                        "slug": "S.-McKenna",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "McKenna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. McKenna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115271255"
                        ],
                        "name": "J. Collins",
                        "slug": "J.-Collins",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Collins",
                            "middleNames": [
                                "James"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5831654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2cb0ef99710f1894f4a09f407c90d40f6521cbc",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual perception of faces is invariant under many transformations, perhaps the most problematic of which is pose change (face rotating in depth). We use a variation of Gabor wavelet transform (GWT) as a representation framework for investigating face pose measurement. Dimensionality reduction using principal components analysis (PCA) enables pose changes to be visualised as manifolds in low-dimensional subspaces and provides a useful mechanism for investigating these changes. The effectiveness of measuring face pose with GWT representations was examined using PCA. We discuss our experimental results and draw a few preliminary conclusions."
            },
            "slug": "An-investigation-into-face-pose-distributions-Gong-McKenna",
            "title": {
                "fragments": [],
                "text": "An investigation into face pose distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This work uses a variation of Gabor wavelet transform as a representation framework for investigating face pose measurement and Dimensionality reduction using principal components analysis (PCA) enables pose changes to be visualised as manifolds in low-dimensional subspaces and provides a useful mechanism for investigating these changes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3176394"
                        ],
                        "name": "P. Somol",
                        "slug": "P.-Somol",
                        "structuredName": {
                            "firstName": "Petr",
                            "lastName": "Somol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Somol"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701197"
                        ],
                        "name": "P. Pudil",
                        "slug": "P.-Pudil",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Pudil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pudil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687265"
                        ],
                        "name": "J. Novovicov\u00e1",
                        "slug": "J.-Novovicov\u00e1",
                        "structuredName": {
                            "firstName": "Jana",
                            "lastName": "Novovicov\u00e1",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Novovicov\u00e1"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1897550"
                        ],
                        "name": "P. Pacl\u00edk",
                        "slug": "P.-Pacl\u00edk",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Pacl\u00edk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pacl\u00edk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13216311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9aaa7dcee5657b8d6e73ba89b2ff9723b45f093",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-floating-search-methods-in-feature-Somol-Pudil",
            "title": {
                "fragments": [],
                "text": "Adaptive floating search methods in feature selection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1832462"
                        ],
                        "name": "F. Crow",
                        "slug": "F.-Crow",
                        "structuredName": {
                            "firstName": "Franklin",
                            "lastName": "Crow",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Crow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2210332,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "8b22e1751f75be137b7b210981baccc1b9ab9222",
            "isKey": false,
            "numCitedBy": 1468,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Texture-map computations can be made tractable through use of precalculated tables which allow computational costs independent of the texture density. The first example of this technique, the \u201cmip\u201d map, uses a set of tables containing successively lower-resolution representations filtered down from the discrete texture function. An alternative method using a single table of values representing the integral over the texture function rather than the function itself may yield superior results at similar cost. The necessary algorithms to support the new technique are explained. Finally, the cost and performance of the new technique is compared to previous techniques."
            },
            "slug": "Summed-area-tables-for-texture-mapping-Crow",
            "title": {
                "fragments": [],
                "text": "Summed-area tables for texture mapping"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "Texture-map computations can be made tractable through use of precalculated tables which allow computational costs independent of the texture density, and the cost and performance of the new technique is compared to previous techniques."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '84"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701197"
                        ],
                        "name": "P. Pudil",
                        "slug": "P.-Pudil",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Pudil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pudil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687265"
                        ],
                        "name": "J. Novovicov\u00e1",
                        "slug": "J.-Novovicov\u00e1",
                        "structuredName": {
                            "firstName": "Jana",
                            "lastName": "Novovicov\u00e1",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Novovicov\u00e1"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12795832,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "c47e6bc5ca7c90abd7b352b34529e33213f3c8ae",
            "isKey": false,
            "numCitedBy": 3059,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Floating-search-methods-in-feature-selection-Pudil-Novovicov\u00e1",
            "title": {
                "fragments": [],
                "text": "Floating search methods in feature selection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3288397"
                        ],
                        "name": "A. Kuchinsky",
                        "slug": "A.-Kuchinsky",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Kuchinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kuchinsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761795"
                        ],
                        "name": "Celine Pering",
                        "slug": "Celine-Pering",
                        "structuredName": {
                            "firstName": "Celine",
                            "lastName": "Pering",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Celine Pering"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32150776"
                        ],
                        "name": "M. Creech",
                        "slug": "M.-Creech",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Creech",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Creech"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2049273"
                        ],
                        "name": "Dennis F. Freeze",
                        "slug": "Dennis-F.-Freeze",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Freeze",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis F. Freeze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8978779"
                        ],
                        "name": "B. Serra",
                        "slug": "B.-Serra",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Serra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Serra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082319"
                        ],
                        "name": "J. Gwizdka",
                        "slug": "J.-Gwizdka",
                        "structuredName": {
                            "firstName": "Jacek",
                            "lastName": "Gwizdka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gwizdka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16878029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6047b726e69ca6b05ecea9084ce2df252d86ef4d",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "FotoFile is an experimental system for multimediaorganization and retrieval, based upon the design goal of makingmultimedia content accessible to non-expert users. Search andretrieval are done in terms that are natural to the task. Thesystem blends human and automatic annotation methods. It extendstextual search, browsing, and retrieval technologies to supportmultimedia data types."
            },
            "slug": "FotoFile:-a-consumer-multimedia-organization-and-Kuchinsky-Pering",
            "title": {
                "fragments": [],
                "text": "FotoFile: a consumer multimedia organization and retrieval system"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "FotoFile is an experimental system for multimedia organization and retrieval, based upon the design goal of making multimedia content accessible to non-expert users that blends human and automatic annotation methods."
            },
            "venue": {
                "fragments": [],
                "text": "CHI '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143634477"
                        ],
                        "name": "J. Perkins",
                        "slug": "J.-Perkins",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Perkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Perkins"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 109711752,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e54af6e97f124d6e18b81b521bf7b7711f6aeca8",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-recognition-in-practice-Perkins",
            "title": {
                "fragments": [],
                "text": "Pattern recognition in practice"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30523165,
            "fieldsOfStudy": [],
            "id": "6f01963039d0a921b1930b4563d1601ff36b971f",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition by Elastic Bunch Graph Matching"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12646365,
            "fieldsOfStudy": [],
            "id": "14e53403a0055dbe5faaf9f1f3be96ca0e692a4d",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved Boosting Algorithms using Confidence-Rated Predictions"
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 30,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Statistical-Learning-of-Multi-view-Face-Detection-Li-Zhu/3c4fdffc12589f9f312a44802b8e2fe8311aa13e?sort=total-citations"
}