{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891751"
                        ],
                        "name": "E. Pasztor",
                        "slug": "E.-Pasztor",
                        "structuredName": {
                            "firstName": "Egon",
                            "lastName": "Pasztor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pasztor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2575670"
                        ],
                        "name": "Owen Carmichael",
                        "slug": "Owen-Carmichael",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Carmichael",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Owen Carmichael"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] propose an MRF model that uses example image patches and a measure of consistency between them to model scene structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1414109,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "861897df39716877fb1e03a7d09a234faca076e9",
            "isKey": false,
            "numCitedBy": 1218,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a learning-based method for low-level vision problems\u2014estimating scenes from images. We generate a synthetic world of scenes and their corresponding rendered images, modeling their relationships with a Markov network. Bayesian belief propagation allows us to efficiently find a local maximum of the posterior probability for the scene, given an image. We call this approach VISTA\u2014Vision by Image/Scene TrAining.We apply VISTA to the \u201csuper-resolution\u201d problem (estimating high frequency details from a low-resolution image), showing good results. To illustrate the potential breadth of the technique, we also apply it in two other problem domains, both simplified. We learn to distinguish shading from reflectance variations in a single image under particular lighting conditions. For the motion estimation problem in a \u201cblobs world\u201d, we show figure/ground discrimination, solution of the aperture problem, and filling-in arising from application of the same probabilistic machinery."
            },
            "slug": "Learning-Low-Level-Vision-Freeman-Pasztor",
            "title": {
                "fragments": [],
                "text": "Learning Low-Level Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A learning-based method for low-level vision problems\u2014estimating scenes from images with Bayesian belief propagation, applied to the \u201csuper-resolution\u201d problem (estimating high frequency details from a low-resolution image), showing good results."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217144"
                        ],
                        "name": "Simon Osindero",
                        "slug": "Simon-Osindero",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Osindero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Osindero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "What distinguishes this model from that of [24] is that it explicitly models the overlap of image patches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 23
                            }
                        ],
                        "text": "The resulting Field of Experts (FoE) models the prior probability of an image in terms of a random field with overlapping cliques, whose potentials are represented as a Product of Experts [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 24
                            }
                        ],
                        "text": "The resulting Fields-of-Experts model is based on a rich set of learned filters, and is trained on a generic image database using contrastive divergence."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 64
                            }
                        ],
                        "text": "To enable that, we represent the MRF potentials as a Product of Experts with the same basic form as in (1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] noted that in their PoE model the filter learning usually benefits from whitening the data distribution, since this removes potential scaling issues due to the very non-spherical covariance of image patches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 59
                            }
                        ],
                        "text": "We refer to the resulting translation-invariant Product-of-Experts model as a Field of Experts to emphasize how the probability density of an entire image involves the combination of overlapping local experts."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 86
                            }
                        ],
                        "text": "Welling et al. [24] went beyond this limitation with a model based on the Products-of-Experts framework [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] propose the use of Student-t experts."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] went beyond this limitation with a model based on the Products-of-Experts framework [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 215
                            }
                        ],
                        "text": "Starting from a variety of simple assumptions, numerous authors have obtained sparse representations of local image structure in terms of the statistics of filters that are local in position, orientation, and scale [18, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] suggest an algorithm for denoising images of arbitrary size."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 68
                            }
                        ],
                        "text": "It is possible to train models that are several times over-complete [18, 24]; the characteristics of the filters remain the same."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 48
                            }
                        ],
                        "text": "To do so, we exploit ideas from the Products-of-Experts (PoE) framework [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 12
                            }
                        ],
                        "text": "The Fieldof-Experts framework provides a principled way to learn MRFs from examples and the greatly improved modeling power makes them practical for complex tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "Previous efforts to model images using Products of Experts [24] were patch-based and hence inappropriate for learning generic priors for images of arbitrary size."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7406434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14d2d9b2e4c29fe105bfbb31f9749b60690303a7",
            "isKey": true,
            "numCitedBy": 152,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a model for natural images in which the probability of an image is proportional to the product of the probabilities of some filter outputs. We encourage the system to find sparse features by using a Student-t distribution to model each filter output. If the t-distribution is used to model the combined outputs of sets of neurally adjacent filters, the system learns a topographic map in which the orientation, spatial frequency and location of the filters change smoothly across the map. Even though maximum likelihood learning is intractable in our model, the product form allows a relatively efficient learning procedure that works well even for highly overcomplete sets of filters. Once the model has been learned it can be used as a prior to derive the \"iterated Wiener filter\" for the purpose of denoising images."
            },
            "slug": "Learning-Sparse-Topographic-Representations-with-of-Welling-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning Sparse Topographic Representations with Products of Student-t Distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A model for natural images in which the probability of an image is proportional to the product of the probabilities of some filter outputs is proposed and used as a prior to derive the \"iterated Wiener filter\" for the purpose of denoising images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2220563"
                        ],
                        "name": "Phil Sallee",
                        "slug": "Phil-Sallee",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Sallee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Phil Sallee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Some effort has gone into extending sparse coding models to full images [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 248729,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57b33942fa4fb4503691d5c725d242260485fdf2",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for learning sparse multiscale image representations using a sparse prior distribution over the basis function coefficients. The prior consists of a mixture of a Gaussian and a Dirac delta function, and thus encourages coefficients to have exact zero values. Coefficients for an image are computed by sampling from the resulting posterior distribution with a Gibbs sampler. The learned basis is similar to the Steerable Pyramid basis, and yields slightly higher SNR for the same number of active coefficients. De-noising using the learned image model is demonstrated for some standard test images, with results that compare favorably with other denoising methods."
            },
            "slug": "Learning-Sparse-Multiscale-Image-Representations-Sallee-Olshausen",
            "title": {
                "fragments": [],
                "text": "Learning Sparse Multiscale Image Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A method for learning sparse multiscale image representations using a sparse prior distribution over the basis function coefficients, which includes a mixture of a Gaussian and a Dirac delta function, and thus encourages coefficients to have exact zero values."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33523605"
                        ],
                        "name": "J. Portilla",
                        "slug": "J.-Portilla",
                        "structuredName": {
                            "firstName": "Javier",
                            "lastName": "Portilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Portilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2051519"
                        ],
                        "name": "V. Strela",
                        "slug": "V.-Strela",
                        "structuredName": {
                            "firstName": "Vasily",
                            "lastName": "Strela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Strela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "For various noise levels we denoised the images using the FoE model, the method from [20] (using the software and default settings provided at [1]), simple Wiener filtering (using MATLAB\u2019s wiener2), and a standard non-linear diffusion scheme [23] with a data term."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "(d) Denoised image using the approach from [20]; PSNR = 28."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] model these dependencies using a Gaussian scale mixture and derive a Bayesian decoding algorithm that appears to be the most accurate of this class of methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 191
                            }
                        ],
                        "text": "It has been often observed that, for a wide variety of linear filters, the marginal filter responses are non-Gaussian, and that the responses of different filters are usually not independent [13, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "For an excellent review and quantitative evaluation of the state of the art see [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "The first set consists of images commonly used in denoising experiments [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] report the most accurate results on these test images and their method is tuned to perform well on this dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "(from left to right): Wiener filter, standard non-linear diffusion, FoE model, and the two variants of [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": "The FoE model consistently outperforms both Wiener filtering and standard non-linear diffusion, while closely matching the performance of the current state of the art in image denoising [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52808855,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "85791491919e1f740f0e882366046acbe56fb14c",
            "isKey": true,
            "numCitedBy": 2403,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for removing noise from digital images, based on a statistical model of the coefficients of an overcomplete multiscale oriented basis. Neighborhoods of coefficients at adjacent positions and scales are modeled as the product of two independent random variables: a Gaussian vector and a hidden positive scalar multiplier. The latter modulates the local variance of the coefficients in the neighborhood, and is thus able to account for the empirically observed correlation between the coefficient amplitudes. Under this model, the Bayesian least squares estimate of each coefficient reduces to a weighted average of the local linear estimates over all possible values of the hidden multiplier variable. We demonstrate through simulations with images contaminated by additive white Gaussian noise that the performance of this method substantially surpasses that of previously published methods, both visually and in terms of mean squared error."
            },
            "slug": "Image-denoising-using-scale-mixtures-of-Gaussians-Portilla-Strela",
            "title": {
                "fragments": [],
                "text": "Image denoising using scale mixtures of Gaussians in the wavelet domain"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The performance of this method for removing noise from digital images substantially surpasses that of previously published methods, both visually and in terms of mean squared error."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115835876"
                        ],
                        "name": "G. Gimel'farb",
                        "slug": "G.-Gimel'farb",
                        "structuredName": {
                            "firstName": "Georgy",
                            "lastName": "Gimel'farb",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gimel'farb"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 115
                            }
                        ],
                        "text": "Another line of work modeled more complex spatial properties using multiple, non-local pairwise pixel interactions [10, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12111787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "426b5683b4f5f66b0244f51a8a5385a75c053986",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "A Markov random field model with a Gibbs probability distribution (GPD) is proposed for describing particular classes of grayscale images which can be called spatially uniform stochastic textures. The model takes into account only multiple short- and long-range pairwise interactions between the gray levels in the pixels. An effective learning scheme is introduced to recover structure and strength of the interactions using maximal likelihood estimates of the potentials in the GPD as desired parameters. The scheme is based on an analytic initial approximation of the estimates and their subsequent refinement by a stochastic approximation. Experiments in modeling natural textures show the utility of the proposed model."
            },
            "slug": "Texture-Modeling-by-Multiple-Pairwise-Pixel-Gimel'farb",
            "title": {
                "fragments": [],
                "text": "Texture Modeling by Multiple Pairwise Pixel Interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A Markov random field model with a Gibbs probability distribution (GPD) is proposed for describing particular classes of grayscale images which can be called spatially uniform stochastic textures and experiments in modeling natural textures show the utility of the proposed model."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38551815"
                        ],
                        "name": "Anat Levin",
                        "slug": "Anat-Levin",
                        "structuredName": {
                            "firstName": "Anat",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anat Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084674"
                        ],
                        "name": "A. Zomet",
                        "slug": "A.-Zomet",
                        "structuredName": {
                            "firstName": "Assaf",
                            "lastName": "Zomet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zomet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] have a similar motivation in that they exploit learned models of image statistics for inpainting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5464867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81410e41f92a63a4aa9618ce0032c9031203a1e7",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Inpainting is the problem of filling-in holes in images. Considerable progress has been made by techniques that use the immediate boundary of the hole and some prior information on images to solve this problem. These algorithms successfully solve the local inpainting problem but they must, by definition, give the same completion to any two holes that have the same boundary, even when the rest of the image is vastly different. We address a different, more global inpainting problem. How can we use the rest of the image in order to learn how to inpaint? We approach this problem from the context of statistical learning. Given a training image we build an exponential family distribution over images that is based on the histograms of local features. We then use this image specific distribution to inpaint the hole by finding the most probable image given the boundary and the distribution. The optimization is done using loopy belief propagation. We show that our method can successfully complete holes while taking into account the specific image statistics. In particular it can give vastly different completions even when the local neighborhoods are identical."
            },
            "slug": "Learning-how-to-inpaint-from-global-image-Levin-Zomet",
            "title": {
                "fragments": [],
                "text": "Learning how to inpaint from global image statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work addresses a different, more global inpainting problem, how can the rest of the image be used in order to learn how to inpaint and can give vastly different completions even when the local neighborhoods are identical."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 68
                            }
                        ],
                        "text": "It is possible to train models that are several times over-complete [18, 24]; the characteristics of the filters remain the same."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 215
                            }
                        ],
                        "text": "Starting from a variety of simple assumptions, numerous authors have obtained sparse representations of local image structure in terms of the statistics of filters that are local in position, orientation, and scale [18, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "In particular, sparse coding methods [18] represent an image patch in terms of a linear combination of learned filters, or \u201cbases\u201d, Ji \u2208 R,"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14208692,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2805537bec87a6177037b18f9a3a9d3f1038867b",
            "isKey": false,
            "numCitedBy": 3574,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sparse-coding-with-an-overcomplete-basis-set:-A-by-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Sparse coding with an overcomplete basis set: A strategy employed by V1?"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34725699"
                        ],
                        "name": "S. Audet",
                        "slug": "S.-Audet",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Audet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Audet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 133
                            }
                        ],
                        "text": "The results here are applicable to image super-resolution, image sharpening, and graphics applications such as image based rendering [6] and others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "This idea has recently been exploited as a prior model for image based rendering [6] and is related to example-based texture synthesis [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17948588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d78b523c9bafc73da74f75756acd7eb6b4c0076d",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "For this report, the view synthesis algorithm from the paper of the same title by Fitzgibbon et al. [1] was implemented. In this report, the geometric and probabilistic background of the algorithm, as well as necessary optimizations required to make the problem more tractable, are succinctly detailed. Results are then presented and analyzed. It was found that although the use of the texture prior improves the resulting rendered images, the initial photoconsistent estimate without use of the prior is of very good visual quality. There is still however a lot of room for improvements in terms of computational performance."
            },
            "slug": "Image-Based-Rendering-Using-Image-Based-Priors-Audet",
            "title": {
                "fragments": [],
                "text": "Image-Based Rendering Using Image-Based Priors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It was found that although the use of the texture prior improves the resulting rendered images, the initial photoconsistent estimate withoutUse of the prior is of very good visual quality."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143816432"
                        ],
                        "name": "G. Reynolds",
                        "slug": "G.-Reynolds",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Reynolds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Reynolds"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 157
                            }
                        ],
                        "text": "Without loss of generality we assume the maximal cliques in the MRF are square pixel patches of a fixed size; other, non-square, neighborhoods could be used [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41223961,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9c99944a1a8f03e1081cf574d6f37fc372a84a56",
            "isKey": false,
            "numCitedBy": 1197,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The linear image restoration problem is to recover an original brightness distribution X/sup 0/ given the blurred and noisy observations Y=KX/sup 0/+B, where K and B represent the point spread function and measurement error, respectively. This problem is typical of ill-conditioned inverse problems that frequently arise in low-level computer vision. A conventional method to stabilize the problem is to introduce a priori constraints on X/sup 0/ and design a cost functional H(X) over images X, which is a weighted average of the prior constraints (regularization term) and posterior constraints (data term); the reconstruction is then the image X, which minimizes H. A prominent weakness in this approach, especially with quadratic-type stabilizers, is the difficulty in recovering discontinuities. The authors therefore examine prior smoothness constraints of a different form, which permit the recovery of discontinuities without introducing auxiliary variables for marking the location of jumps and suspending the constraints in their vicinity. In this sense, discontinuities are addressed implicitly rather than explicitly. >"
            },
            "slug": "Constrained-Restoration-and-the-Recovery-of-Geman-Reynolds",
            "title": {
                "fragments": [],
                "text": "Constrained Restoration and the Recovery of Discontinuities"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The authors examine prior smoothness constraints of a different form, which permit the recovery of discontinuities without introducing auxiliary variables for marking the location of jumps and suspending the constraints in their vicinity."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "Zhu and Mumford took a step toward more practical MRFs with the introduction of the FRAME model [27], which allowed MRF priors to be learned from training data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 199529912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba58e6bcfc1f3d4f5f55a217a87077c0b33f1843",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ". This article presents a statistical theory for texture modeling. This theory combines \ufb01ltering theory and Markov random \ufb01eld modeling through the maximum entropy principle, and interprets and clari\ufb01es many previous concepts and methods for texture analysis and synthesis from a uni\ufb01ed point of view. Our theory characterizes the ensemble of images I with the same texture appearance by a probability distribution f . I / on a random \ufb01eld, and the objective of texture modeling is to make inference about f . I / , given a set of observed texture examples. In our theory, texture modeling consists of two steps. (1) A set of \ufb01lters is selected from a general \ufb01lter bank to capture features of the texture, these \ufb01lters are applied to observed texture images, and the histograms of the \ufb01ltered images are extracted. These histograms are estimates of the marginal distributions of f . I / . This step is called feature extraction. (2) The maximum entropy principle is employed to derive a distribution p . I / , which is restricted to have the same marginal distributions as those in (1). This p . I / is considered as an estimate of f . I / . This step is called feature fusion. A stepwise algorithm is proposed to choose \ufb01lters from a general \ufb01lter bank. The resulting model, called FRAME (Filters, Random \ufb01elds And Maximum Entropy), is a Markov random \ufb01eld (MRF) model, but with a much enriched vocabulary and hence much stronger descriptive ability than the previous MRF models used for texture modeling. Gibbs sampler is adopted to synthesize texture images by drawing typical samples from p . I / , thus the model is veri\ufb01ed by seeing whether the synthesized texture images have similar visual appearances to the texture images being modeled. Experiments on a variety of 1D and 2D textures are described to illustrate our theory and to show the performance of our algorithms. These experiments demonstrate that many textures which are previously considered as from different categories can be modeled and synthesized in a common framework."
            },
            "slug": "Filters,-Random-Fields-and-Maximum-Entropy-(FRAME):-Zhu",
            "title": {
                "fragments": [],
                "text": "Filters, Random Fields and Maximum Entropy (FRAME): Towards a Unified Theory for Texture Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The resulting model, called FRAME (Filters, Random fields And Maximum Entropy), is a Markov random field (MRF) model, but with a much enriched vocabulary and hence much stronger descriptive ability than the previous MRF models used for texture modeling."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41210105"
                        ],
                        "name": "Zhou Wang",
                        "slug": "Zhou-Wang",
                        "structuredName": {
                            "firstName": "Zhou",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhou Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747569"
                        ],
                        "name": "A. Bovik",
                        "slug": "A.-Bovik",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bovik",
                            "middleNames": [
                                "Conrad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bovik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2387140"
                        ],
                        "name": "H. Sheikh",
                        "slug": "H.-Sheikh",
                        "structuredName": {
                            "firstName": "Hamid",
                            "lastName": "Sheikh",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sheikh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "A signed rank test shows that the performance differences between the FoE and the other methods are statistically significant at a 95% confidence level (except for the SSIM of non-linear diffusion at the highest noise level)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "56dB); the image similarity metric from [22] shows a significant improvement as well (0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "In addition to PSNR we also computed a more perceptually-based similarity measure (SSIM) [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207761262,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eae2e0fa72e898c289365c0af16daf57a7a6cf40",
            "isKey": true,
            "numCitedBy": 30878,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/."
            },
            "slug": "Image-quality-assessment:-from-error-visibility-to-Wang-Bovik",
            "title": {
                "fragments": [],
                "text": "Image quality assessment: from error visibility to structural similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A structural similarity index is developed and its promise is demonstrated through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145738882"
                        ],
                        "name": "Jinggang Huang",
                        "slug": "Jinggang-Huang",
                        "structuredName": {
                            "firstName": "Jinggang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinggang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 191
                            }
                        ],
                        "text": "It has been often observed that, for a wide variety of linear filters, the marginal filter responses are non-Gaussian, and that the responses of different filters are usually not independent [13, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16242434,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c9001ca7266f67de55733477eeb48988481d7204",
            "isKey": false,
            "numCitedBy": 636,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Large calibrated datasets of 'random' natural images have recently become available. These make possible precise and intensive statistical studies of the local nature of images. We report results ranging from the simplest single pixel intensity to joint distribution of 3 Haar wavelet responses. Some of these statistics shed light on old issues such as the near scale-invariance of image statistics and some are entirely new. We fit mathematical models to some of the statistics and explain others in terms of local image features."
            },
            "slug": "Statistics-of-natural-images-and-models-Huang-Mumford",
            "title": {
                "fragments": [],
                "text": "Statistics of natural images and models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Results ranging from the simplest single pixel intensity to joint distribution of 3 Haar wavelet responses are reported, which shed light on old issues such as the near scale-invariance of image statistics and some are entirely new."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "Instead of running the Markov chain until convergence we use the idea of contrastive divergence [12] to initialize the sampler at the data points and only run it for a small, fixed number of steps."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Hinton [12] justifies this more formally and shows that contrastive divergence learning is typically a good approximation to a maximum likelihood estimation of the parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": false,
            "numCitedBy": 4570,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "The methods include Gibbs sampling [9], deterministic annealing, mean-field methods, belief propagation, non-linear diffusion, as well as many related PDE methods [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "In particular, MRF priors typically exploit handcrafted clique potentials and small neighborhood systems [9], which limit the expressiveness of the models and only crudely capture the statistics of natural images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18704,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111068362"
                        ],
                        "name": "Seunghyup Shin",
                        "slug": "Seunghyup-Shin",
                        "structuredName": {
                            "firstName": "Seunghyup",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seunghyup Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696605"
                        ],
                        "name": "T. Nishita",
                        "slug": "T.-Nishita",
                        "structuredName": {
                            "firstName": "Tomoyuki",
                            "lastName": "Nishita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nishita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11467825"
                        ],
                        "name": "Sung-yong Shin",
                        "slug": "Sung-yong-Shin",
                        "structuredName": {
                            "firstName": "Sung-yong",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sung-yong Shin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 135
                            }
                        ],
                        "text": "This idea has recently been exploited as a prior model for image based rendering [6] and is related to example-based texture synthesis [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17057484,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6aa4552f2187447853425d0b91a94b19f2f3059",
            "isKey": false,
            "numCitedBy": 1404,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-pixel-based-texture-synthesis-by-non-parametric-Shin-Nishita",
            "title": {
                "fragments": [],
                "text": "On pixel-based texture synthesis by non-parametric sampling"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698689"
                        ],
                        "name": "N. Jojic",
                        "slug": "N.-Jojic",
                        "structuredName": {
                            "firstName": "Nebojsa",
                            "lastName": "Jojic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Jojic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145721096"
                        ],
                        "name": "A. Kannan",
                        "slug": "A.-Kannan",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Kannan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kannan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[14] use a miniature version of an image or a set of images, called the epitome, to describe an image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 793640,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "581db5af31e5c557015aefc993c6bbfca4e9150f",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We present novel simple appearance and shape models that we call epitomes. The epitome of an image is its miniature, condensed version containing the essence of the textural and shape properties of the image. As opposed to previously used simple image models, such as templates or basis functions, the size of the epitome is considerably smaller than the size of the image or object it represents, but the epitome still contains most constitutive elements needed to reconstruct the image. A collection of images often shares an epitome, e.g., when images are a few consecutive frames from a video sequence, or when they are photographs of similar objects. A particular image in a collection is defined by its epitome and a smooth mapping from the epitome to the image pixels. When the epitomic representation is used within a hierarchical generative model, appropriate inference algorithms can be derived to extract the epitome from a single image or a collection of images and at the same time perform various inference tasks, such as image segmentation, motion estimation, object removal and super-resolution."
            },
            "slug": "Epitomic-analysis-of-appearance-and-shape-Jojic-Frey",
            "title": {
                "fragments": [],
                "text": "Epitomic analysis of appearance and shape"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The epitome of an image is its miniature, condensed version containing the essence of the textural and shape properties of the image, as opposed to previously used simple image models, such as templates or basis functions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "As observed by Zhu and Mumford [26], this is related to non-linear diffusion methods."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 203
                            }
                        ],
                        "text": "By introducing an iteration index t, an update rate \u03b7, and an optional weight \u03bb, we can write the gradient ascent denoising algorithm as:\nx(t+1) = x(t)+\u03b7\n[ N\u2211\ni=1\nJ\u2212i \u2217 \u03c8i(Ji \u2217 x(t)) + \u03bb\n\u03c32 (y \u2212 x(t))\n]\nAs observed by Zhu and Mumford [26], this is related to non-linear diffusion methods."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Fortunately, the gradient of the log-prior is also simple to compute [26]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Zhu and Mumford took a step toward more practical MRFs with the introduction of the FRAME model [27], which allowed MRF priors to be learned from training data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 27
                            }
                        ],
                        "text": "[27] S. Zhu, Y. Wu, and D. Mumford."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "[13] J. Huang and D. Mumford."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 19
                            }
                        ],
                        "text": "[26] S. Zhu and D. Mumford."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "We also define \u03c8i(y) = \u2202/\u2202y log \u03c6i(y;\u03b1i) and let Ji denote the filter obtained by mirroring Ji around its center pixel [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7423086,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adc69aebcee4af29e115f54e3a5f210c5cc7dadc",
            "isKey": true,
            "numCitedBy": 408,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This article addresses two important themes in early visual computation: it presents a novel theory for learning the universal statistics of natural images, and, it proposes a general framework of designing reaction-diffusion equations for image processing. We studied the statistics of natural images including the scale invariant properties, then generic prior models were learned to duplicate the observed statistics, based on minimax entropy theory. The resulting Gibbs distributions have potentials of the form U(I; /spl Lambda/, S)=/spl Sigma//sub /spl alpha/=1//sup k//spl Sigma//sub x,y//spl lambda//sup (/spl alpha/)/((F/sup (/spl alpha/)/*I)(x,y)) with S={F/sup (1)/, F/sup (2)/,...,F/sup (K)/} being a set of filters and /spl Lambda/={/spl lambda//sup (1)/(),/spl lambda//sup (2)/(),...,/spl lambda//sup (K)/()} the potential functions. The learned Gibbs distributions confirm and improve the form of existing prior models such as line-process, but, in contrast to all previous models, inverted potentials were found to be necessary. We find that the partial differential equations given by gradient descent on U(I; /spl Lambda/, S) are essentially reaction-diffusion equations, where the usual energy terms produce anisotropic diffusion, while the inverted energy terms produce reaction associated with pattern formation, enhancing preferred image features. We illustrate how these models can be used for texture pattern rendering, denoising, image enhancement, and clutter removal by careful choice of both prior and data models of this type, incorporating the appropriate features."
            },
            "slug": "Prior-Learning-and-Gibbs-Reaction-Diffusion-Zhu-Mumford",
            "title": {
                "fragments": [],
                "text": "Prior Learning and Gibbs Reaction-Diffusion"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is found that the partial differential equations given by gradient descent on U(I; /spl Lambda/, S) are essentially reaction-diffusion equations, where the usualEnergy terms produce anisotropic diffusion, while the inverted energy terms produce reaction associated with pattern formation, enhancing preferred image features."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082299938"
                        ],
                        "name": "D. Tal",
                        "slug": "D.-Tal",
                        "structuredName": {
                            "firstName": "Doron",
                            "lastName": "Tal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "The training data contains about 60000 image patches randomly cropped from the Berkeley Segmentation Benchmark [16] and converted to grayscale."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "We show how the model is trained on a standard database of natural images [16] and develop a diffusion-like scheme that exploits the prior for approximate Bayesian inference."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a1ed876196ec9733acb1daa6d65e35ff0414291",
            "isKey": false,
            "numCitedBy": 6038,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt grouping factors as well as statistics of image region properties."
            },
            "slug": "A-database-of-human-segmented-natural-images-and-to-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes is presented and an error measure is defined which quantifies the consistency between segmentations of differing granularities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694119"
                        ],
                        "name": "M. Bertalm\u00edo",
                        "slug": "M.-Bertalm\u00edo",
                        "structuredName": {
                            "firstName": "Marcelo",
                            "lastName": "Bertalm\u00edo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bertalm\u00edo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699339"
                        ],
                        "name": "G. Sapiro",
                        "slug": "G.-Sapiro",
                        "structuredName": {
                            "firstName": "Guillermo",
                            "lastName": "Sapiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sapiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8004695"
                        ],
                        "name": "V. Caselles",
                        "slug": "V.-Caselles",
                        "structuredName": {
                            "firstName": "Vicent",
                            "lastName": "Caselles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Caselles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702012"
                        ],
                        "name": "C. Ballester",
                        "slug": "C.-Ballester",
                        "structuredName": {
                            "firstName": "Coloma",
                            "lastName": "Ballester",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ballester"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 308278,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c",
            "isKey": false,
            "numCitedBy": 3531,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Inpainting, the technique of modifying an image in an undetectable form, is as ancient as art itself. The goals and applications of inpainting are numerous, from the restoration of damaged paintings and photographs to the removal/replacement of selected objects. In this paper, we introduce a novel algorithm for digital inpainting of still images that attempts to replicate the basic techniques used by professional restorators. After the user selects the regions to be restored, the algorithm automatically fills-in these regions with information surrounding them. The fill-in is done in such a way that isophote lines arriving at the regions' boundaries are completed inside. In contrast with previous approaches, the technique here introduced does not require the user to specify where the novel information comes from. This is automatically done (and in a fast way), thereby allowing to simultaneously fill-in numerous regions containing completely different structures and surrounding backgrounds. In addition, no limitations are imposed on the topology of the region to be inpainted. Applications of this technique include the restoration of old photographs and damaged film; removal of superimposed text like dates, subtitles, or publicity; and the removal of entire objects from the image like microphones or wires in special effects."
            },
            "slug": "Image-inpainting-Bertalm\u00edo-Sapiro",
            "title": {
                "fragments": [],
                "text": "Image inpainting"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel algorithm for digital inpainting of still images that attempts to replicate the basic techniques used by professional restorators, and does not require the user to specify where the novel information comes from."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "The filters learned by this model are the same kinds of Gabor-like filters obtained using a non-parametric ICA technique or standard sparse coding approaches."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "Since the components found by ICA are by assumption independent, one can simply multiply their marginal distributions to obtain a prior model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "The advantage of the PoE model over the ICA model is that the number of experts N is not necessarily equal to the number of dimensions n (i. e. pixels)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "Independent component analysis (ICA) [2] can be used to define a probabilistic model for images patches."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 152
                            }
                        ],
                        "text": "The overcomplete case is particularly interesting because it allows dependencies between filters to be modeled and consequently is more expressive than ICA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "ICANN, v. 1, pp. 1\u20136, 1999."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 136
                            }
                        ],
                        "text": "However, in case of image patches of n pixels it is generally impossible to find n fully independent linear components, which makes the ICA model only an approximation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1701422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d7d0e8c4791700defd4b0df82a26b50055346e0",
            "isKey": true,
            "numCitedBy": 8756,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in \"blind\" signal processing."
            },
            "slug": "An-Information-Maximization-Approach-to-Blind-and-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "An Information-Maximization Approach to Blind Separation and Blind Deconvolution"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is suggested that information maximization provides a unifying framework for problems in \"blind\" signal processing and dependencies of information transfer on time delays are derived."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2181857"
                        ],
                        "name": "R. Paget",
                        "slug": "R.-Paget",
                        "structuredName": {
                            "firstName": "Rupert",
                            "lastName": "Paget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Paget"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145325516"
                        ],
                        "name": "I. Longstaff",
                        "slug": "I.-Longstaff",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Longstaff",
                            "middleNames": [
                                "Dennis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Longstaff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Other MRF models used the Parzen window approach [19] to define the field potentials."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14050955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a89a3dea18886b7744da80c1bb88c1ae91e6ceec",
            "isKey": false,
            "numCitedBy": 237,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Our noncausal, nonparametric, multiscale, Markov random field (MRF) model is capable of synthesizing and capturing the characteristics of a wide variety of textures, from the highly structured to the stochastic. We use a multiscale synthesis algorithm incorporating local annealing to obtain larger realizations of texture visually indistinguishable from the training texture."
            },
            "slug": "Texture-synthesis-via-a-noncausal-nonparametric-Paget-Longstaff",
            "title": {
                "fragments": [],
                "text": "Texture synthesis via a noncausal nonparametric multiscale Markov random field"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work uses a multiscale synthesis algorithm incorporating local annealing to obtain larger realizations of texture visually indistinguishable from the training texture."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": "The resulting Field of Experts (FoE) models the prior probability of an image in terms of a random field with overlapping cliques, whose potentials are represented as a Product of Experts [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 24
                            }
                        ],
                        "text": "The resulting Fields-of-Experts model is based on a rich set of learned filters, and is trained on a generic image database using contrastive divergence."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 64
                            }
                        ],
                        "text": "To enable that, we represent the MRF potentials as a Product of Experts with the same basic form as in (1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 59
                            }
                        ],
                        "text": "We refer to the resulting translation-invariant Product-of-Experts model as a Field of Experts to emphasize how the probability density of an entire image involves the combination of overlapping local experts."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 86
                            }
                        ],
                        "text": "Welling et al. [24] went beyond this limitation with a model based on the Products-of-Experts framework [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "[24] went beyond this limitation with a model based on the Products-of-Experts framework [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "To do so, we exploit ideas from the Products-of-Experts (PoE) framework [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 12
                            }
                        ],
                        "text": "The Fieldof-Experts framework provides a principled way to learn MRFs from examples and the greatly improved modeling power makes them practical for complex tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 51
                            }
                        ],
                        "text": "Previous efforts to model images using Products of Experts [24] were patch-based and hence inappropriate for learning generic priors for images of arbitrary size."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15059668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bf65452ae566a052b00d919404f462470869600",
            "isKey": true,
            "numCitedBy": 194,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple probabilistic models of the same data by multiplying the probabilities together and then renormalizing. This is a very efficient way to model high-dimensional data which simultaneously satisfies many different low dimensional constraints. Each individual expert model can focus on giving high probability to data vectors that satisfy just one of the constraints. Data vectors that satisfy this one constraint but violate other constraints will be ruled out by their low probability under the other expert models. Training a product of models appears difficult because, in addition to maximizing the probabilities that the individual models assign to the observed data, it is necessary to make the models disagree on unobserved regions of the data space. However, if the individual models are tractable there is a fairly efficient way to train a product of models. This training algorithm suggests a biologically plausible way of learning neural population codes."
            },
            "slug": "Products-of-experts-Hinton",
            "title": {
                "fragments": [],
                "text": "Products of experts"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This training algorithm suggests a biologically plausible way of learning neural population codes by maximizing the probabilities that the individual models assign to the observed data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266057"
                        ],
                        "name": "A. Zalesny",
                        "slug": "A.-Zalesny",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Zalesny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zalesny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 115
                            }
                        ],
                        "text": "Another line of work modeled more complex spatial properties using multiple, non-local pairwise pixel interactions [10, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2423738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2fbd5b1a43d87ef142b59ce3a2028e4a19ed33e",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A texture synthesis method is presented that generates similar texture from an example image. It is based on the emulation of simple but rather carefully chosen image intensity statistics. The resulting texture models are compact and no longer require the example image from which they were derived. They make explicit some structural aspects of the textures and the modeling allows knitting together different textures with convincingly looking transition zones. As textures are seldom flat, it is important to also model 3D effects when textures change under changing viewpoint. The simulation of such changes is supported by the model, assuming examples for the different viewpoints are given."
            },
            "slug": "A-Compact-Model-for-Viewpoint-Dependent-Texture-Zalesny-Gool",
            "title": {
                "fragments": [],
                "text": "A Compact Model for Viewpoint Dependent Texture Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A texture synthesis method is presented that generates similar texture from an example image based on the emulation of simple but rather carefully chosen image intensity statistics."
            },
            "venue": {
                "fragments": [],
                "text": "SMILE"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065792748"
                        ],
                        "name": "G. Sapiro",
                        "slug": "G.-Sapiro",
                        "structuredName": {
                            "firstName": "Guillermo",
                            "lastName": "Sapiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sapiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082022606"
                        ],
                        "name": "David H. Marimont",
                        "slug": "David-H.-Marimont",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Marimont",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David H. Marimont"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065456097"
                        ],
                        "name": "David Heeger",
                        "slug": "David-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Heeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "Note that \u2212 log \u03c6i is a standard robust error function when \u03c6i has heavy tails, and that \u03c8i is proportional to its influence function [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18725318,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "132be6922c665f465f9232915de24195e0573879",
            "isKey": false,
            "numCitedBy": 1400,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Relations between anisotropic diffusion and robust statistics are described in this paper. Specifically, we show that anisotropic diffusion can be seen as a robust estimation procedure that estimates a piecewise smooth image from a noisy input image. The \"edge-stopping\" function in the anisotropic diffusion equation is closely related to the error norm and influence function in the robust estimation framework. This connection leads to a new \"edge-stopping\" function based on Tukey's biweight robust estimator that preserves sharper boundaries than previous formulations and improves the automatic stopping of the diffusion. The robust statistical interpretation also provides a means for detecting the boundaries (edges) between the piecewise smooth regions in an image that has been smoothed with anisotropic diffusion. Additionally, we derive a relationship between anisotropic diffusion and regularization with line processes. Adding constraints on the spatial organization of the line processes allows us to develop new anisotropic diffusion equations that result in a qualitative improvement in the continuity of edges."
            },
            "slug": "Robust-anisotropic-diffusion-Black-Sapiro",
            "title": {
                "fragments": [],
                "text": "Robust anisotropic diffusion"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is shown that anisotropic diffusion can be seen as a robust estimation procedure that estimates a piecewise smooth image from a noisy input image and the connection to the error norm and influence function in the robust estimation framework leads to a new \"edge-stopping\" function based on Tukey's biweight robust estimator that preserves sharper boundaries than previous formulations and improves the automatic stopping of the diffusion."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29700602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5aadfb932e8b0b33ead25ecd268564355d00a9f",
            "isKey": false,
            "numCitedBy": 630,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives an overview of scale-space and image enhancement techniques which are based on parabolic partial differential equations in divergence form. In the nonlinear setting this filter class allows to integrate a-priori knowledge into the evolution. We sketch basic ideas behind the different filter models, discuss their theoretical foundations and scale-space properties, discrete aspects, suitable algorithms, generalizations, and applications."
            },
            "slug": "A-Review-of-Nonlinear-Diffusion-Filtering-Weickert",
            "title": {
                "fragments": [],
                "text": "A Review of Nonlinear Diffusion Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An overview of scale-space and image enhancement techniques which are based on parabolic partial differential equations in divergence form and how this filter class allows to integrate a-priori knowledge into the evolution."
            },
            "venue": {
                "fragments": [],
                "text": "Scale-Space"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10336140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c55dfe48a3c49a6dc366d50a60521f73aa31151a",
            "isKey": false,
            "numCitedBy": 2435,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A basic problem when deriving information from measured data, such as images, originates from the fact that objects in the world, and hence image structures, exist as meaningful entities only over ..."
            },
            "slug": "Scale-Space-Theory-in-Computer-Vision-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Scale-Space Theory in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A basic problem when deriving information from measured data, such as images, originates from the fact that objects in the world, and hence image structures, exist as meaningful entities only over measured data."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "The inpainted result (Figure 6 (b)) is very similar to the original and qualitatively superior to those in [3]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "In image inpainting [3], the goal is to remove certain parts of an image, for example scratches on a photograph"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "To demonstrate the modeling power of the FoE model, we use it in two different applications: image denoising and image inpainting [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "Past approaches, such as [3], use a form of diffusion to fill in the masked pixels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "The advantage of the rich prior can be seen in the continuity of edges which is better preserved compared with [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "(c) Close-up comparison between a (left), b (middle), and the results from [3] (right)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "Figure 6 (c) shows a few detail regions comparing our method (center) with [3] (right)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and C"
            },
            "venue": {
                "fragments": [],
                "text": "Ballester. Image inpainting.ACM SIGGRAPH, pp. 417\u2013424"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144542130"
                        ],
                        "name": "J. Preston",
                        "slug": "J.-Preston",
                        "structuredName": {
                            "firstName": "Jr.",
                            "lastName": "Preston",
                            "middleNames": [
                                "Kendall"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Preston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "Zhu and Mumford took a step toward more practical MRFs with the introduction of the FRAME model [27], which allowed MRF priors to be learned from training data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 209745301,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5fe870d1534ee8eda65c499975691cbddaf3f438",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A new family of nonlinear digital convolution filters is described having unusual and valuable properties. The response is constant phase over the entire input frequency range and, in some forms, no signal whatsoever is passed beyond the cutoff frequency and side-lobes are identically zero. By simply iterating the transform upon which a \u039e-filter is based without changing the size of the convolution kernel, the cutoff frequency may be varied. Use of \u039e-filters is analyzed and demonstrated as applied to ultrahigh-speed image processing using table-lookup computation."
            },
            "slug": "\u039e-filters-Preston",
            "title": {
                "fragments": [],
                "text": "\u039e-filters"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sparse coding with an over - complete basis set : A strategy employed by V 1 ?"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 133
                            }
                        ],
                        "text": "To demonstrate the modeling power of the FoE model, we use it in two different applications: image denoising and image inpainting [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image inpainting. ACM SIGGRAPH"
            },
            "venue": {
                "fragments": [],
                "text": "Image inpainting. ACM SIGGRAPH"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "Note that\u2212 log \u03c6i is a standard robust error function when\u03c6i has heavy tails, and that \u03c8i is proportional to its influence function [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Heeger. Robust anisotropic diffusion.IEEE Trans. Image Proc.  , 7(3):421\u2013 432"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 19,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Fields-of-Experts:-a-framework-for-learning-image-Roth-Black/2077d0f30507d51a0d3bbec4957d55e817d66a59?sort=total-citations"
}