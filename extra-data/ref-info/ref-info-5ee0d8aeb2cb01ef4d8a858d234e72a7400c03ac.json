{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 116062098,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6c06333850b96721709b3162c6332939a2fdce31",
            "isKey": false,
            "numCitedBy": 2181,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Foundations: set theory 2. General topology 3. Measures 4. Integration 5. Lp spaces: introduction to functional analysis 6. Convex sets and duality of normed spaces 7. Measure, topology, and differentiation 8. Introduction to probability theory 9. Convergence of laws and central limit theorems 10. Conditional expectations and martingales 11. Convergence of laws on separable metric spaces 12. Stochastic processes 13. Measurability: Borel isomorphism and analytic sets Appendixes: A. Axiomatic set theory B. Complex numbers, vector spaces, and Taylor's theorem with remainder C. The problem of measure D. Rearranging sums of nonnegative terms E. Pathologies of compact nonmetric spaces Indices."
            },
            "slug": "Real-Analysis-and-Probability-Dudley",
            "title": {
                "fragments": [],
                "text": "Real Analysis and Probability"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145733439"
                        ],
                        "name": "G. Wahba",
                        "slug": "G.-Wahba",
                        "structuredName": {
                            "firstName": "Grace",
                            "lastName": "Wahba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wahba"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1247234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c4b40c80bb506acdb60b299e8ab4f1b29375029",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter is an expanded version of a talk presented in the NIPS 97 Workshop on Support Vector Machines. It consists of three parts: (1) A brief review of some old but relevant results on constrained optimization in Reproducing Kernel Hilbert Spaces (RKHS), and a review of the relationship between zero-mean Gaussian processes and RKHS. Application of tensor sums and products of RKHS including smoothing spline ANOVA spaces in the context of SVM's is also described. (2) A discussion of the relationship between penalized likelihood methods in RKHS for Bernoulli data when the goal is risk factor estimation, and SVM methods in RKHS when the goal is classiication. When the goal is classiication it is noted that replacing the likelihood functional of the logit (log odds ratio) with an appropriate SVM functional is a natural method for concentrating computational eeort on estimating the logit near the classiication boundary and ignoring data far away. Remarks concerning the potential of SVM's for variable selection as an eecient preprocessor for risk factor estimation are made. (3) A discussion of how the the GACV (Generalized Approximate Cross Validation) for choosing smoothing parameters proposed in Xiang and Wahba (1996, 1997) may be adapted and implemented in the context of certain convex SVM's."
            },
            "slug": "Support-Vector-Machines,-Reproducing-Kernel-Hilbert-Wahba",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines, Reproducing Kernel Hilbert Spaces and the Randomized Gacv 1 1 Support Vector Machines, Reproducing Kernel Hilbert Spaces and the Randomized Gacv"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This chapter is an expanded version of a talk presented in the NIPS 97 Workshop on Support Vector Machines and a brief review of some old but relevant results on constrained optimization in Reproducing Kernel Hilbert Spaces (RKHS), and a review of the relationship between zero-mean Gaussian processes and RKHS."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6082464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d27c7569fdbcbb57ff511f5293e32b547acca7b3",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "This article shows a relationship between two different approximation techniques: the support vector machines (SVM), proposed by V. Vapnik (1995) and a sparse approximation scheme that resembles the basis pursuit denoising algorithm (Chen, 1995; Chen, Donoho, & Saunders, 1995). SVM is a technique that can be derived from the structural risk minimization principle (Vapnik, 1982) and can be used to estimate the parameters of several different approximation schemes, including radial basis functions, algebraic and trigonometric polynomials, B-splines, and some forms of multilayer perceptrons. Basis pursuit denoising is a sparse approximation technique in which a function is reconstructed by using a small number of basis functions chosen from a large set (the dictionary). We show that if the data are noiseless, the modified version of basis pursuit denoising proposed in this article is equivalent to SVM in the following sense: if applied to the same data set, the two techniques give the same solution, which is obtained by solving the same quadratic programming problem. In the appendix, we present a derivation of the SVM technique in the framework of regularization theory, rather than statistical learning theory, establishing a connection between SVM, sparse approximation, and regularization theory."
            },
            "slug": "An-Equivalence-Between-Sparse-Approximation-and-Girosi",
            "title": {
                "fragments": [],
                "text": "An Equivalence Between Sparse Approximation and Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "If the data are noiseless, the modified version of basis pursuit denoising proposed in this article is equivalent to SVM in the following sense: if applied to the same data set, the two techniques give the same solution, which is obtained by solving the same quadratic programming problem."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722243"
                        ],
                        "name": "N. Linial",
                        "slug": "N.-Linial",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Linial",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Linial"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13826372"
                        ],
                        "name": "E. London",
                        "slug": "E.-London",
                        "structuredName": {
                            "firstName": "Eran",
                            "lastName": "London",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. London"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144147174"
                        ],
                        "name": "Yuri Rabinovich",
                        "slug": "Yuri-Rabinovich",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Rabinovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5071936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "826ad9d93afd1826a1b4146c88c1476cef5835df",
            "isKey": false,
            "numCitedBy": 997,
            "numCiting": 195,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractIn this paper we explore some implications of viewing graphs asgeometric objects. This approach offers a new perspective on a number of graph-theoretic and algorithmic problems. There are several ways to model graphs geometrically and our main concern here is with geometric representations that respect themetric of the (possibly weighted) graph. Given a graphG we map its vertices to a normed space in an attempt to (i) keep down the dimension of the host space, and (ii) guarantee a smalldistortion, i.e., make sure that distances between vertices inG closely match the distances between their geometric images.In this paper we develop efficient algorithms for embedding graphs low-dimensionally with a small distortion. Further algorithmic applications include:\u2022A simple, unified approach to a number of problems on multicommodity flows, including the Leighton-Rao Theorem [37] and some of its extensions. We solve an open question in this area, showing that the max-flow vs. min-cut gap in thek-commodities problem isO(logk). Our new deterministic polynomial-time algorithm finds a (nearly tight) cut meeting this bound.\u2022For graphs embeddable in low-dimensional spaces with a small distortion, we can find low-diameter decompositions (in the sense of [7] and [43]). The parameters of the decomposition depend only on the dimension and the distortion and not on the size of the graph.\u2022In graphs embedded this way, small balancedseparators can be found efficiently.\nGiven faithful low-dimensional representations of statistical data, it is possible to obtain meaningful and efficientclustering. This is one of the most basic tasks in pattern-recognition. For the (mostly heuristic) methods used in the practice of pattern-recognition, see [20], especially chapter 6.Our studies of multicommodity flows also imply that every embedding of (the metric of) ann-vertex, constant-degree expander into a Euclidean space (of any dimension) has distortion \u03a9(logn). This result is tight, and closes a gap left open by Bourgain [12]."
            },
            "slug": "The-geometry-of-graphs-and-some-of-its-algorithmic-Linial-London",
            "title": {
                "fragments": [],
                "text": "The geometry of graphs and some of its algorithmic applications"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Efficient algorithms for embedding graphs low-dimensionally with a small distortion, and a new deterministic polynomial-time algorithm that finds a (nearly tight) cut meeting this bound."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 35th Annual Symposium on Foundations of Computer Science"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884649"
                        ],
                        "name": "C. Saunders",
                        "slug": "C.-Saunders",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793317"
                        ],
                        "name": "A. Gammerman",
                        "slug": "A.-Gammerman",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Gammerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gammerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145675281"
                        ],
                        "name": "V. Vovk",
                        "slug": "V.-Vovk",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vovk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vovk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7099687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "922b81f11a71aa64cda78914e6356cce89cd4f86",
            "isKey": false,
            "numCitedBy": 797,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we study a dual version of the Ridge Regression procedure. It allows us to perform non-linear regression by constructing a linear regression function in a high dimensional feature space. The feature space representation can result in a large increase in the number of parameters used by the algorithm. In order to combat this \u201ccurse of dimensionality\u201d, the algorithm allows the use of kernel functions, as used in Support Vector methods. We also discuss a powerful family of kernel functions which is constructed using the ANOVA decomposition method from the kernel corresponding to splines with an infinite number of nodes. This paper introduces a regression estimation algorithm which is a combination of these two elements: the dual version of Ridge Regression is applied to the ANOVA enhancement of the infinitenode splines. Experimental results are then presented (based on the Boston Housing data set) which indicate the performance of this algorithm relative to other algorithms."
            },
            "slug": "Ridge-Regression-Learning-Algorithm-in-Dual-Saunders-Gammerman",
            "title": {
                "fragments": [],
                "text": "Ridge Regression Learning Algorithm in Dual Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A regression estimation algorithm which is a combination of the dual version of Ridge Regression is applied to the ANOVA enhancement of the infinitenode splines and the use of kernel functions, as used in Support Vector methods is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14336127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e45c2420e6dc59ba6d357fb0c996ebf43c861560",
            "isKey": false,
            "numCitedBy": 1619,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Generative probability models such as hidden Markov models provide a principled way of treating missing information and dealing with variable length sequences. On the other hand, discriminative methods such as support vector machines enable us to construct flexible decision boundaries and often result in classification performance superior to that of the model based approaches. An ideal classifier should combine these two complementary approaches. In this paper, we develop a natural way of achieving this combination by deriving kernel functions for use in discriminative methods such as support vector machines from generative probability models. We provide a theoretical justification for this combination as well as demonstrate a substantial improvement in the classification performance in the context of DNA and protein sequence analysis."
            },
            "slug": "Exploiting-Generative-Models-in-Discriminative-Jaakkola-Haussler",
            "title": {
                "fragments": [],
                "text": "Exploiting Generative Models in Discriminative Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A natural way of achieving this combination by deriving kernel functions for use in discriminative methods such as support vector machines from generative probability models is developed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116281095,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d3b01a9ce510c80c72a31595045bb40844e404a",
            "isKey": false,
            "numCitedBy": 487,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Feedforward neural networks such as multilayer perceptrons are popular tools for nonlinear regression and classification problems. From a Bayesian perspective, a choice of a neural network model can be viewed as defining a prior probability distribution over non-linear functions, and the neural network's learning process can be interpreted in terms of the posterior probability distribution over the unknown function. (Some learning algorithms search for the function with maximum posterior probability and other Monte Carlo methods draw samples from this posterior probability). In the limit of large but otherwise standard networks, Neal (1996) has shown that the prior distribution over non-linear functions implied by the Bayesian neural network falls in a class of probability distributions known as Gaussian processes. The hyperparameters of the neural network model determine the characteristic length scales of the Gaussian process. Neal's observation motivates the idea of discarding parameterized networks and working directly with Gaussian processes. Computations in which the parameters of the network are optimized are then replaced by simple matrix operations using the covariance matrix of the Gaussian process. In this chapter I will review work on this idea by Williams and Rasmussen (1996), Neal (1997), Barber and Williams (1997) and Gibbs and MacKay (1997), and will assess whether, for supervised regression and classification tasks, the feedforward network has been superceded."
            },
            "slug": "Introduction-to-Gaussian-processes-Mackay",
            "title": {
                "fragments": [],
                "text": "Introduction to Gaussian processes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This chapter will assess whether the feedforward network has been superceded, for supervised regression and classification tasks, and will review work on this idea by Williams and Rasmussen (1996), Neal (1997), Barber and Williams (1997) and Gibbs and MacKay (1997)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60502900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c4da62e9e89e65ac78ee271e424e8b498053e8c",
            "isKey": false,
            "numCitedBy": 5544,
            "numCiting": 260,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al."
            },
            "slug": "Advances-in-kernel-methods:-support-vector-learning-Sch\u00f6lkopf-Burges",
            "title": {
                "fragments": [],
                "text": "Advances in kernel methods: support vector learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Support vector machines for dynamic reconstruction of a chaotic system, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770745"
                        ],
                        "name": "P. Niyogi",
                        "slug": "P.-Niyogi",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1900499,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4a422669ec9b6a60b05d2d2595314008a5fb419",
            "isKey": false,
            "numCitedBy": 1314,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The support vector (SV) machine is a novel type of learning machine, based on statistical learning theory, which contains polynomial classifiers, neural networks, and radial basis function (RBF) networks as special cases. In the RBF case, the SV algorithm automatically determines centers, weights, and threshold that minimize an upper bound on the expected test error. The present study is devoted to an experimental comparison of these machines with a classical approach, where the centers are determined by X-means clustering, and the weights are computed using error backpropagation. We consider three machines, namely, a classical RBF machine, an SV machine with Gaussian kernel, and a hybrid system with the centers determined by the SV method and the weights trained by error backpropagation. Our results show that on the United States postal service database of handwritten digits, the SV machine achieves the highest recognition accuracy, followed by the hybrid system. The SV approach is thus not only theoretically well-founded but also superior in a practical application."
            },
            "slug": "Comparing-support-vector-machines-with-Gaussian-to-Sch\u00f6lkopf-Sung",
            "title": {
                "fragments": [],
                "text": "Comparing support vector machines with Gaussian kernels to radial basis function classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results show that on the United States postal service database of handwritten digits, the SV machine achieves the highest recognition accuracy, followed by the hybrid system, and the SV approach is thus not only theoretically well-founded but also superior in a practical application."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2671293"
                        ],
                        "name": "M. Diekhans",
                        "slug": "M.-Diekhans",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Diekhans",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Diekhans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5612883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f2be15cdf6f5b461b9c61495eb496351d7fc91a",
            "isKey": false,
            "numCitedBy": 477,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method, called the Fisher kernel method, for detecting remote protein homologies is introduced and shown to perform well in classifying protein domains by SCOP superfamily. The method is a variant of support vector machines using a new kernel function. The kernel function is derived from a hidden Markov model. The general approach of combining generative models like HMMs with discriminative methods such as support vector machines may have applications in other areas of biosequence analysis as well."
            },
            "slug": "Using-the-Fisher-Kernel-Method-to-Detect-Remote-Jaakkola-Diekhans",
            "title": {
                "fragments": [],
                "text": "Using the Fisher Kernel Method to Detect Remote Protein Homologies"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A new method, called the Fisher kernel method, for detecting remote protein homologies is introduced and shown to perform well in classifying protein domains by SCOP superfamily."
            },
            "venue": {
                "fragments": [],
                "text": "ISMB"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32427977"
                        ],
                        "name": "M. Linial",
                        "slug": "M.-Linial",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Linial",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Linial"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722243"
                        ],
                        "name": "N. Linial",
                        "slug": "N.-Linial",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Linial",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Linial"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714285"
                        ],
                        "name": "G. Yona",
                        "slug": "G.-Yona",
                        "structuredName": {
                            "firstName": "Golan",
                            "lastName": "Yona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Yona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16820467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5ed356c72ef8b45114c330d5d5704fa09aa9bf2",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "A global classification of all currently known protein sequences is performed. Every protein sequence is partitioned into segments of 50 amino acid residues and a dynamic programming distance is calculated between each pair of segments. This space of segments is initially embedded into Euclidean space. The algorithm that we apply embeds every finite metric space into Euclidean space so that (1) the dimension of the host space is small, (2) the metric distortion is small. A novel self-organized, cross-validated clustering algorithm is then applied to the embedded space with Euclidean distances. We monitor the validity of our clustering by randomly splitting the data into two parts and performing an hierarchical clustering algorithm independently on each part. At every level of the hierarchy we cross-validate the clusters in one part with the clusters in the other. The resulting hierarchical tree of clusters offers a new representation of protein sequences and families, which compares favorably with the most updated classifications based on functional and structural data about proteins. Some of the known families clustered into well distinct clusters. Motifs and domains such as the zinc finger, EF hand, homeobox, EGF-like and others are automatically correctly identified, and relations between protein families are revealed by examining the splits along the tree. This clustering leads to a novel representation of protein families, from which functional biological kinship of protein families can be deduced, as demonstrated for the transporter family. Finally, we introduce a new concise representation for complete proteins that is very useful in presenting multiple alignments, and in searching for close relatives in the database. The self-organization method presented is very general and applies to any data with a consistent and computable measure of similarity between data items."
            },
            "slug": "Global-self-organization-of-all-known-protein-Linial-Linial",
            "title": {
                "fragments": [],
                "text": "Global self-organization of all known protein sequences reveals inherent biological signatures."
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A global classification of all currently known protein sequences is performed, and a novel self-organized, cross-validated clustering algorithm leads to a novel representation of protein families, from which functional biological kinship ofprotein families can be deduced, as demonstrated for the transporter family."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1888591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c35cc80fe8c6cdea742d4fa1af1f2e698d41aba7",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a class of exible conditional probability models and techniques for classi cation regression problems Many existing methods such as generalized linear models and support vector machines are subsumed under this class The exibility of this class of techniques comes from the use of kernel functions as in support vector machines and the generality from dual formulations of stan dard regression models"
            },
            "slug": "Probabilistic-kernel-regression-models-Jaakkola-Haussler",
            "title": {
                "fragments": [],
                "text": "Probabilistic kernel regression models"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A class of exible conditional probability models and techniques for classi cation regression problems that comes from the use of kernel functions as in support vector machines and the generality from dual formulations of stan dard regression models is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187514"
                        ],
                        "name": "R. Durbin",
                        "slug": "R.-Durbin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Durbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Durbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708077"
                        ],
                        "name": "S. Eddy",
                        "slug": "S.-Eddy",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Eddy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Eddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197258"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145666307"
                        ],
                        "name": "G. Mitchison",
                        "slug": "G.-Mitchison",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Mitchison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mitchison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2852254,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "571f5bbecd3a083a2bb6844f59a3f8cea237252e",
            "isKey": false,
            "numCitedBy": 4477,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Probablistic models are becoming increasingly important in analyzing the huge amount of data being produced by large-scale DNA-sequencing efforts such as the Human Genome Project. For example, hidden Markov models are used for analyzing biological sequences, linguistic-grammar-based probabilistic models for identifying RNA secondary structure, and probabilistic evolutionary models for inferring phylogenies of sequences from different organisms. This book gives a unified, up-to-date and self-contained account, with a Bayesian slant, of such methods, and more generally to probabilistic methods of sequence analysis. Written by an interdisciplinary team of authors, it is accessible to molecular biologists, computer scientists, and mathematicians with no formal knowledge of the other fields, and at the same time presents the state of the art in this new and important field."
            },
            "slug": "Biological-Sequence-Analysis:-Probabilistic-Models-Durbin-Eddy",
            "title": {
                "fragments": [],
                "text": "Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This book gives a unified, up-to-date and self-contained account, with a Bayesian slant, of such methods, and more generally to probabilistic methods of sequence analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706504"
                        ],
                        "name": "J. Hopcroft",
                        "slug": "J.-Hopcroft",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopcroft",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopcroft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31901407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41a88a490d7ba9e383ecb16c4290083413a08258",
            "isKey": false,
            "numCitedBy": 13820,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Introduction-to-Automata-Theory,-Languages-and-Hopcroft-Ullman",
            "title": {
                "fragments": [],
                "text": "Introduction to Automata Theory, Languages and Computation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104228664"
                        ],
                        "name": "C. Fitzgerald",
                        "slug": "C.-Fitzgerald",
                        "structuredName": {
                            "firstName": "Ch",
                            "lastName": "Fitzgerald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fitzgerald"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120011769,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6289cc5bd23ecdd6171c9edf27d9947279165ff2",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-fractional-Hadamard-powers-of-positive-definite-Fitzgerald",
            "title": {
                "fragments": [],
                "text": "On fractional Hadamard powers of positive definite matrices*1, *2"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72184075"
                        ],
                        "name": "F. William",
                        "slug": "F.-William",
                        "structuredName": {
                            "firstName": "Feller",
                            "lastName": "William",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. William"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 65112646,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65ba8fd8ef9c2a70cee99d2e5cab9302d0307a1e",
            "isKey": false,
            "numCitedBy": 12391,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Office hours: MWF, immediately after class or early afternoon (time TBA). We will cover the mathematical foundations of probability theory. The basic terminology and concepts of probability theory include: random experiments, sample or outcome spaces (discrete and continuous case), events and their algebra, probability measures, conditional probability A First Course in Probability (8th ed.) by S. Ross. This is a lively text that covers the basic ideas of probability theory including those needed in statistics. Theoretical concepts are introduced via interesting concrete examples. In 394 I will begin my lectures with the basics of probability theory in Chapter 2. However, your first assignment is to review Chapter 1, which treats elementary counting methods. They are used in applications in Chapter 2. I expect to cover Chapters 2-5 plus portions of 6 and 7. You are encouraged to read ahead. In lectures I will not be able to cover every topic and example in Ross, and conversely, I may cover some topics/examples in lectures that are not treated in Ross. You will be responsible for all material in my lectures, assigned reading, and homework, including supplementary handouts if any."
            },
            "slug": "An-Introduction-To-Probability-Theory-And-Its-William",
            "title": {
                "fragments": [],
                "text": "An Introduction To Probability Theory And Its Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A First Course in Probability (8th ed.) by S. Ross is a lively text that covers the basic ideas of probability theory including those needed in statistics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029039"
                        ],
                        "name": "T. Booth",
                        "slug": "T.-Booth",
                        "structuredName": {
                            "firstName": "Taylor",
                            "lastName": "Booth",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Booth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10451876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "595b48a7eda9905a71ef7e01bbae391e3e6033e2",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Inference of high-dimensional grammars is discussed. Specifically, techniques for inferring tree grammars are briefly presented. The problem of inferring a stochastic grammar to model the behavior of an information source is also introduced and techniques for carrying out the inference process are presented for a class of stochastic finite-state and context-free grammars. The possible practical application of these methods is illustrated by examples."
            },
            "slug": "Grammatical-Inference:-Introduction-and-Survey-Part-Fu-Booth",
            "title": {
                "fragments": [],
                "text": "Grammatical Inference: Introduction and Survey - Part II"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The problem of inferring a stochastic grammar to model the behavior of an information source is introduced and techniques for carrying out the inference process are presented for a class of Stochastic finite-state and context-free grammars."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26320,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12841311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "188bcf4e56b6437098c612c063e0f97d4e8d6e9c",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive a new general representation for a function as a linear combination of local correlation kernels at optimal sparse locations (and scales) and characterize its relation to principal component analysis, regularization, sparsity principles, and support vector machines."
            },
            "slug": "A-Sparse-Representation-for-Function-Approximation-Poggio-Girosi",
            "title": {
                "fragments": [],
                "text": "A Sparse Representation for Function Approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new general representation for a function is derived as a linear combination of local correlation kernels at optimal sparse locations (and scales) and its relation to principal component analysis, regularization, sparsity principles, and support vector machines is characterized."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117154916"
                        ],
                        "name": "L. Rosen",
                        "slug": "L.-Rosen",
                        "structuredName": {
                            "firstName": "Lon",
                            "lastName": "Rosen",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rosen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123729722,
            "fieldsOfStudy": [
                "Mathematics",
                "Philosophy"
            ],
            "id": "2c5cc1756d2df1667a47af3604330be03ea9f568",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Let C be an n x n positive definite matrix. If C \u2265 0 in the sense that Cij \u2265 0 and if p > n \u2014 2, then C p \u2265 0. This implies the following \"positive minorant property\" for the norms \u2016A\u2016 p = [tr(A*A) p/2]1/P . Let 2 < p \u2260 4, 6, \u2026 . Then 0 \u2264 A \u2264 B => \u2016A\u2016 p \u2265 \u2016B\u2016 P if and only if n < p/2 + 1."
            },
            "slug": "Positive-Powers-of-Positive-Positive-Definite-Rosen",
            "title": {
                "fragments": [],
                "text": "Positive Powers of Positive Positive Definite Matrices"
            },
            "venue": {
                "fragments": [],
                "text": "Canadian Journal of Mathematics"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41211507"
                        ],
                        "name": "L. M\u00e1t\u00e9",
                        "slug": "L.-M\u00e1t\u00e9",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "M\u00e1t\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. M\u00e1t\u00e9"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116978655,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5cb5c240bb19d6b5283567f9714fcf57ba3cf2fa",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Fundamentals the geometry of Hilbert spaces reproducing kernel Hilbert space operator theory causal operators."
            },
            "slug": "Hilbert-Space-Methods-in-Science-and-Engineering-M\u00e1t\u00e9",
            "title": {
                "fragments": [],
                "text": "Hilbert Space Methods in Science and Engineering"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716207"
                        ],
                        "name": "R. Elliott",
                        "slug": "R.-Elliott",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Elliott",
                            "middleNames": [
                                "J",
                                "R"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Elliott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32578437"
                        ],
                        "name": "L. Aggoun",
                        "slug": "L.-Aggoun",
                        "structuredName": {
                            "firstName": "Lakhdar",
                            "lastName": "Aggoun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Aggoun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109008954"
                        ],
                        "name": "J. Moore",
                        "slug": "J.-Moore",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moore",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moore"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62082134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f937472778aee48d32bb7811569f70b78198f75",
            "isKey": false,
            "numCitedBy": 1347,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov Model Processing.- Discrete-Time HMM Estimation.- Discrete States and Discrete Observations.- Continuous-Range Observations.- Continuous-Range States and Observations.- A General Recursive Filter.- Practical Recursive Filters.- Continuous-Time HMM Estimation.- Discrete-Range States and Observations.- Markov Chains in Brownian Motion.- Two-Dimensional HMM Estimation.- Hidden Markov Random Fields.- HMM Optimal Control.- Discrete-Time HMM Control.- Risk-Sensitive Control of HMM.- Continuous-Time HMM Control."
            },
            "slug": "Hidden-Markov-Models:-Estimation-and-Control-Elliott-Aggoun",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Models: Estimation and Control"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a meta-modelling procedure called Markov Model Processing that automates the very labor-intensive and therefore time-heavy and therefore expensive process of HMMEstimation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029039"
                        ],
                        "name": "T. Booth",
                        "slug": "T.-Booth",
                        "structuredName": {
                            "firstName": "Taylor",
                            "lastName": "Booth",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Booth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1534493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddbef7c7990c4e412056df98ece9ef0df04b6c9a",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of grammatical inference is introduced, and its potential engineering applications are demonstrated. Inference algorithms for finite-state and context-free grammars are presented. The application of some of the algorithms to the inference of pattern grammars in syntactic pattern recognition is illustrated by examples."
            },
            "slug": "Grammatical-Inference:-Introduction-and-Survey-Part-Fu-Booth",
            "title": {
                "fragments": [],
                "text": "Grammatical Inference: Introduction and Survey-Part I"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The problem of grammatical inference is introduced, and its potential engineering applications are demonstrated, andference algorithms for finite-state and context-free grammars are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59820096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ea95d38e5b5a0bd8ef95184a95c29265a6d87e9",
            "isKey": false,
            "numCitedBy": 911,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphs and Conditional Independence.- Log-Linear Models.- Bayesian Networks.- Gaussian Graphical Models.- Mixed Interaction Models.- Graphical Models for Complex Stochastic Systems.- High dimensional modelling.- References.- Index."
            },
            "slug": "Graphical-models-in-R-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Graphical models in R"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper presents Graphical Models for Complex Stochastic Systems, a meta-modelling framework for graphical models of complex systems that combines Gaussian Graphical models, Mixed Interaction Models, and Log-Linear Models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145292822"
                        ],
                        "name": "V. Ponomarenko",
                        "slug": "V.-Ponomarenko",
                        "structuredName": {
                            "firstName": "Vadim",
                            "lastName": "Ponomarenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ponomarenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145780948"
                        ],
                        "name": "Donald Adams",
                        "slug": "Donald-Adams",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Adams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145850138"
                        ],
                        "name": "Rene Ardila",
                        "slug": "Rene-Ardila",
                        "structuredName": {
                            "firstName": "Rene",
                            "lastName": "Ardila",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rene Ardila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2918862"
                        ],
                        "name": "D. Hannasch",
                        "slug": "D.-Hannasch",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hannasch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hannasch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71451241"
                        ],
                        "name": "Audra E. Kosh",
                        "slug": "Audra-E.-Kosh",
                        "structuredName": {
                            "firstName": "Audra",
                            "lastName": "Kosh",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Audra E. Kosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144810067"
                        ],
                        "name": "Hanah McCarthy",
                        "slug": "Hanah-McCarthy",
                        "structuredName": {
                            "firstName": "Hanah",
                            "lastName": "McCarthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanah McCarthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524495"
                        ],
                        "name": "R. Rosenbaum",
                        "slug": "R.-Rosenbaum",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Rosenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14129967,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "7fd2449c74d4d04ed67dcdc754ec4b345da2a8c8",
            "isKey": false,
            "numCitedBy": 4792,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Linear-Algebra-and-its-Applications-Ponomarenko-Adams",
            "title": {
                "fragments": [],
                "text": "Linear Algebra and its Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195857038,
            "fieldsOfStudy": [],
            "id": "b7294ac444ae927f71ac442372903ff5e2a763e1",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Spline Models for Observational Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144403112"
                        ],
                        "name": "C. Berg",
                        "slug": "C.-Berg",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Berg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144027552"
                        ],
                        "name": "J. Christensen",
                        "slug": "J.-Christensen",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Christensen",
                            "middleNames": [
                                "Peter",
                                "Reus"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Christensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101172055"
                        ],
                        "name": "P. Ressel",
                        "slug": "P.-Ressel",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Ressel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ressel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117450983,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b9f4febf74f3802df63f3d73dd49cabd37eece15",
            "isKey": false,
            "numCitedBy": 1020,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Harmonic-Analysis-on-Semigroups-Berg-Christensen",
            "title": {
                "fragments": [],
                "text": "Harmonic Analysis on Semigroups"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2886380"
                        ],
                        "name": "S. Sturrock",
                        "slug": "S.-Sturrock",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Sturrock",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sturrock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 86397843,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abcab02ebe45bdfc4b8e5e272ebb3f7471a2cdec",
            "isKey": false,
            "numCitedBy": 772,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Time-Warps,-String-Edits,-and-Macromolecules-\u2013-The-Sturrock",
            "title": {
                "fragments": [],
                "text": "Time Warps, String Edits, and Macromolecules \u2013 The Theory and Practice of Sequence Comparison . David Sankoff and Joseph Kruskal. ISBN 1-57586-217-4. Price \u00a313.95 (US$22\u00b795)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62636588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2982aba3ad1a424ccd342895c308c9744f06ea6f",
            "isKey": false,
            "numCitedBy": 985,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Syntactic-Pattern-Recognition-And-Applications-Fu",
            "title": {
                "fragments": [],
                "text": "Syntactic Pattern Recognition And Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745619"
                        ],
                        "name": "S. German",
                        "slug": "S.-German",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "German",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. German"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121982077"
                        ],
                        "name": "D. German",
                        "slug": "D.-German",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "German",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. German"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59916588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1f9fcf2ccc313a5018e536e76e75d1f7992937b",
            "isKey": false,
            "numCitedBy": 2216,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stochastic-relaxation,-Gibbs-distributions,-and-the-German-German",
            "title": {
                "fragments": [],
                "text": "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644344103"
                        ],
                        "name": "J. C. BurgesChristopher",
                        "slug": "J.-C.-BurgesChristopher",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "BurgesChristopher",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. BurgesChristopher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215966761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6716697767fc601efc7690f40820d9ea7a7bf57c",
            "isKey": false,
            "numCitedBy": 13527,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, w..."
            },
            "slug": "A-Tutorial-on-Support-Vector-Machines-for-Pattern-BurgesChristopher",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Support Vector Machines for Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This tutorial starts with an overview of the concepts of VC dimension and structural risk minimization and describes linear Support Vector Machines (SVMs) for separable and non-separable data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Introduction to Probability Theory and its Applications , volume 1"
            },
            "venue": {
                "fragments": [],
                "text": "An Introduction to Probability Theory and its Applications , volume 1"
            },
            "year": 1971
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 33,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Convolution-kernels-on-discrete-structures-Haussler/5ee0d8aeb2cb01ef4d8a858d234e72a7400c03ac?sort=total-citations"
}