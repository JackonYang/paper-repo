{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "But, similarly to stalker and unlike WHISK, Rapier and SRV extract a particular item independently of the other relevant items."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "However, there are three such systems that are somewhat related to stalker: WHISK [15], Rapier [4], and SRV [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "The extraction rules induced by Rapier and SRV can use the landmarks that immediately precede and/or follow the item to be extracted, while WHISK is capable of using multiple landmarks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8125917,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd7cee21074ea6b346011d7463f7387ad9bfcc2a",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Because the World Wide Web consists primarily of text, information extraction is central to any effort that would use the Web as a resource for knowledge discovery. We show how information extraction can be cast as a standard machine learning problem, and argue for the suitability of relational learning in solving it. The implementation of a general-purpose relational learner for information extraction, SRV, is described. In contrast with earlier learning systems for information extraction, SRV makes no assumptions about document structure and the kinds of information available for use in learning extraction patterns. Instead, structural and other information is supplied as input in the form of an extensible token-oriented feature set. We demonstrate the effectiveness of this approach by adapting SRV for use in learning extraction rules for a domain consisting of university course and research project pages sampled from the Web. Making SRV Web-ready only involves adding several simple HTML-specific features to its basic feature set."
            },
            "slug": "Information-Extraction-from-HTML:-Application-of-a-Freitag",
            "title": {
                "fragments": [],
                "text": "Information Extraction from HTML: Application of a General Machine Learning Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work shows how information extraction can be cast as a standard machine learning problem, and argues for the suitability of relational learning in solving it, and the implementation of a general-purpose relational learner for information extraction, SRV."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2178614"
                        ],
                        "name": "N. Ashish",
                        "slug": "N.-Ashish",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Ashish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ashish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "In order to help the users cope with these di culties, Ashish and Knoblock [1] proposed an expert system approach that uses a xed set of heuristics of the type \\look for bold or italicized strings\"."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8200914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15b3cd323910de0551c680e8dae27d7413494a46",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "To simplify the task of obtaining information from the vast number of information sources that are available on the World Wide Web (WWW), the authors are building information mediators for extracting and integrating data from multiple Web sources. In a mediator based approach, wrappers are built around individual information sources to translate between the mediator query language and the individual sources. They present an approach for semi-automatically generating wrappers for structured Internet sources. The key idea is to exploit formatting information in Web pages to hypothesize the underlying structure of a page. From this structure the system generates a wrapper that facilitates querying of a source and possibly integrating it with other sources. They demonstrate the ease with which they are able to build wrappers for a number of Web sources using their implemented wrapper generation toolkit."
            },
            "slug": "Semi-automatic-wrapper-generation-for-Internet-Ashish-Knoblock",
            "title": {
                "fragments": [],
                "text": "Semi-automatic wrapper generation for Internet information sources"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The key idea is to exploit formatting information in Web pages to hypothesize the underlying structure of a page and generate a wrapper that facilitates querying of a source and possibly integrating it with other sources."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of CoopIS 97: 2nd IFCIS Conference on Cooperative Information Systems"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293454"
                        ],
                        "name": "Steven Minton",
                        "slug": "Steven-Minton",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Minton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2887330"
                        ],
                        "name": "J. Ambite",
                        "slug": "J.-Ambite",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Ambite",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ambite"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2178614"
                        ],
                        "name": "N. Ashish",
                        "slug": "N.-Ashish",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Ashish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ashish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2463523"
                        ],
                        "name": "P. J. Modi",
                        "slug": "P.-J.-Modi",
                        "structuredName": {
                            "firstName": "Pragnesh",
                            "lastName": "Modi",
                            "middleNames": [
                                "Jay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. J. Modi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276863"
                        ],
                        "name": "Ion Muslea",
                        "slug": "Ion-Muslea",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Muslea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ion Muslea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135707"
                        ],
                        "name": "A. Philpot",
                        "slug": "A.-Philpot",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Philpot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Philpot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145565197"
                        ],
                        "name": "S. Tejada",
                        "slug": "S.-Tejada",
                        "structuredName": {
                            "firstName": "Sheila",
                            "lastName": "Tejada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tejada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 67
                            }
                        ],
                        "text": "The most recent generation of information agents (e.g., WHIRL [7], Ariadne [11], and Information Manifold [10] ) address this problem by enabling information from pre-speci ed sets of Web sites to be accessed via database-like queries."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": ", WHIRL [7], Ariadne [11], and Information Manifold [10] ) address this problem by enabling information from pre-speci ed sets of Web sites to be accessed via database-like queries."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9829974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b04707bf7810f6030539638f93fef712b684d7a",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The Web is based on a browsing paradigm that makes it difficult to retrieve and integrate data from multiple sites. Today, the only way to do this is to build specialized applications, which are time-consuming to develop and difficult to maintain. We are addressing this problem by creating the technology and tools for rapidly constructing information agents that extract, query, and integrate data from web sources. Our approach is based on a simple, uniform representation that makes it efficient to integrate multiple sources. Instead of building specialized algorithms for handling web sources, we have developed methods for mapping web sources into this uniform representation. This approach builds on work from knowledge representation, machine learning and automated planning. The resulting system, called Ariadne, makes it fast and cheap to build new information agents that access existing web sources. Ariadne also makes it easy to maintain these agents and incorporate new sources as they become available."
            },
            "slug": "Modeling-Web-Sources-for-Information-Integration-Knoblock-Minton",
            "title": {
                "fragments": [],
                "text": "Modeling Web Sources for Information Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work has developed methods for mapping web sources into a simple, uniform representation that makes it efficient to integrate multiple sources and makes it easy to maintain these agents and incorporate new sources as they become available."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 56
                            }
                        ],
                        "text": "The most recent generation of information agents (e.g., WHIRL [7], Ariadne [11], and Information Manifold [10] ) address this problem by enabling information from pre-speci ed sets of Web sites to be accessed via database-like queries."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": ", where the extraction rules are written by a human expert), from procedural languages [2] and Perl scripts [7] to pattern matching [5] and LL(k) grammars [6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": ", WHIRL [7], Ariadne [11], and Information Manifold [10] ) address this problem by enabling information from pre-speci ed sets of Web sites to be accessed via database-like queries."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3522479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2dd1c332f65fea3a66f4a982428f31ce1a9dc70",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The degree to which information sources are pre-processed by Web-based information systems varies greatly. In search engines like Altavista, little pre-processing is done, while in \\knowledge integration\" systems, complex site-speciic \\wrappers\" are used integrate diierent information sources into a common database representation. In this paper we describe an intermediate between these two models. In our system, information sources are converted into a highly structured collection of small fragments of text. Database-like queries to this structured collection of text fragments are approximated using a novel logic called WHIRL, which combines inference in the style of deductive databases with ranked retrieval methods from information retrieval. WHIRL allows queries that integrate information from multiple Web sites, without requiring the extraction and nor-malization of object identiiers that can be used as keys; instead, operations that in conventional databases require equality tests on keys are approximated using IR similarity metrics for text. This leads to a reduction in the amount of human engineering required to eld a knowledge integration system. Experimental evidence is given showing that many information sources can be easily modeled with WHIRL, and that inferences in the logic are both accurate and eecient. 1 Introduction There are (at least) two diierent models for systems designed to access information on the Web. The rst model, which might be called the information retrieval (IR) model, is exempliied by search engines like Lycos and Altavista. In this model a large portion of the Web can be queried, but the query language is limited to keyword searches on single documents. The second model is exempliied by systems like the Information Manifold 14], TSIMMIS 9], and others 2, 4]. This \\knowledge integration model\" supports more complex database-like queries; in particular queries that integrate information from multiple Web sites can be formulated. However, current knowledge integration systems require extraction of database-like information from"
            },
            "slug": "A-Web-based-information-system-that-reasons-with-of-Cohen",
            "title": {
                "fragments": [],
                "text": "A Web-based information system that reasons with structured collections of text"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental evidence is given showing that many information sources can be easily modeled with WHIRL, and that inferences in the logic are both accurate and eecient."
            },
            "venue": {
                "fragments": [],
                "text": "AGENTS '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8551365"
                        ],
                        "name": "N. Kushmerick",
                        "slug": "N.-Kushmerick",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Kushmerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kushmerick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913159"
                        ],
                        "name": "Robert B. Doorenbos",
                        "slug": "Robert-B.-Doorenbos",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Doorenbos",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Doorenbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "The wrapper induction techniques introduced in wien [12] are better t to frequent format changes because they rely on learning techniques to generate the extraction rules."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "In Table 1, we present four illustrative information sources that were selected from the larger set of sources on which Kushmerick's wien [12] system was tested."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5119155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e7402ad740b73cc0bb64178f86df3478c3aaf5",
            "isKey": false,
            "numCitedBy": 1283,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Many Internet information resources present relational data|telephone directories, product catalogs, etc. Because these sites are formatted for people, mechanically extracting their content is di cult. Systems using such resources typically use hand-coded wrappers, procedures to extract data from information resources. We introduce wrapper induction, a method for automatically constructing wrappers, and identify hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources. We use PAC analysis to bound the problem's sample complexity, and show that the system degrades gracefully with imperfect labeling knowledge."
            },
            "slug": "Wrapper-Induction-for-Information-Extraction-Kushmerick-Weld",
            "title": {
                "fragments": [],
                "text": "Wrapper Induction for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces wrapper induction, a method for automatically constructing wrappers, and identifies hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967815"
                        ],
                        "name": "M. E. Califf",
                        "slug": "M.-E.-Califf",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Califf",
                            "middleNames": [
                                "Elaine"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. E. Califf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 44
                            }
                        ],
                        "text": "But, similarly to stalker and unlike WHISK, Rapier and SRV extract a particular item independently of the other relevant items."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "However, there are three such systems that are somewhat related to stalker: WHISK [15], Rapier [4], and SRV [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 32
                            }
                        ],
                        "text": "The extraction rules induced by Rapier and SRV can use the landmarks that immediately precede and/or follow the item to be extracted, while WHISK is capable of using multiple landmarks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 489775,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16bd1fbe3694173eda4ad4338a85f8288d19bf02",
            "isKey": false,
            "numCitedBy": 700,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction is a form of shallow text processing that locates a specified set of relevant items in a natural-language document. Systems for this task require significant domain-specific knowledge and are time-consuming and difficult to build by hand, making them a good application for machine learning. We present a system, RAPIER, that uses pairs of sample documents and filled templates to induce pattern-match rules that directly extract fillers for the slots in the template. RAPIER employs a bottom-up learning algorithm which incorporates techniques from several inductive logic programming systems and acquires unbounded patterns that include constraints on the words, part-of-speech tags, and semantic classes present in the filler and the surrounding text. We present encouraging experimental results on two domains."
            },
            "slug": "Relational-Learning-of-Pattern-Match-Rules-for-Califf-Mooney",
            "title": {
                "fragments": [],
                "text": "Relational Learning of Pattern-Match Rules for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "RAPIER employs a bottom-up learning algorithm which incorporates techniques from several inductive logic programming systems and acquires unbounded patterns that include constraints on the words, part-of-speech tags, and semantic classes present in the filler and the surrounding text."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741158"
                        ],
                        "name": "P. Atzeni",
                        "slug": "P.-Atzeni",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Atzeni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Atzeni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785690"
                        ],
                        "name": "G. Mecca",
                        "slug": "G.-Mecca",
                        "structuredName": {
                            "firstName": "Giansalvatore",
                            "lastName": "Mecca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mecca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796590"
                        ],
                        "name": "P. Merialdo",
                        "slug": "P.-Merialdo",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Merialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Merialdo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "Some systems, such as tsimmis [5] and araneus [3] depend on humans to write the necessary grammar rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2143322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b63fdd4c37bb6b72bf4ce61dda07d50be1b7c3f2",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Database systems offer efficient and reliable technology to query structured data. However, because of the explosion of the World Wide Web [11], an increasing amount of information is stored in repositories organized according to less rigid structures, usually as hypertextual documents, and data access is based on browsing and information retrieval techniques. Since browsing and search engines present important limitations [8], several query languages [19, 20, 23] for the Web have been recently proposed. These approaches are mainly based on a loose notion of structure, and tend to see the Web as a huge collection of unstructured objects, organized as a graph. Clearly, traditional database techniques are of little use in this field, and new techniques need to be developed. In this paper, we present the approach to the management of Web data as attacked in the ArtANEUS project carried out by the database group at Universith di l=toma Tre. Our approach is based on a generalization of the notion of view to the Web framework. In fact, in traditional databases, views represent an essential tool for restructuring and integrating da ta to be presented to the user. Since the Web is becoming a major computing platform and a uniform interface for sharing data, we believe that also in this field a sophisticate view mechanism is needed, with novel features due to the semi-structured nature of the Web. First, in this context, restructuring and presenting da ta under different perspectives requires the generation of derived Web hypertexts, in order to re-organize and re-use portions of the Web. To do this, da ta from existing Web sites must be extracted, and then queried and integrated in order to build new hypertexts, i.e., hypertextual views over the original sites; these manipulations can be better attained in a more structured framework, in which traditional database technology can be leveraged to analyze and correlate information. Therefore, there seem to be different view levels in this framework: (i) at the first level, da ta are extracted from the sites of interest and given a database structure, which represents a first structured view over the original semi-structured data; (ii) then, further database views can be built by means of reorganizations and integrations based on traditional database techniques; (iii) finally, a derived hypertext can be generated offering an alternative or integrated hypertextual view over the original sites. In the process, data go from a loosely structured organizat ion-the Web pages-to a very structured onethe database--and then again to Web structures."
            },
            "slug": "Semistructured-and-structured-data-in-the-Web:-back-Atzeni-Mecca",
            "title": {
                "fragments": [],
                "text": "Semistructured and structured data in the Web: going back and forth"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The approach to the management of Web data as attacked in the ArtANEUS project carried out by the database group at Universith di l=toma Tre is presented, based on a generalization of the notion of view to the Web framework."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729294"
                        ],
                        "name": "Boris Chidlovskii",
                        "slug": "Boris-Chidlovskii",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Chidlovskii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Chidlovskii"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067217778"
                        ],
                        "name": "Uwe M. Borghoff",
                        "slug": "Uwe-M.-Borghoff",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Borghoff",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uwe M. Borghoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144474509"
                        ],
                        "name": "P. Chevalier",
                        "slug": "P.-Chevalier",
                        "structuredName": {
                            "firstName": "Pierre-Yves",
                            "lastName": "Chevalier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chevalier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 155
                            }
                        ],
                        "text": ", where the extraction rules are written by a human expert), from procedural languages [2] and Perl scripts [7] to pattern matching [5] and LL(k) grammars [6]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13386925,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26bcf687a7fe2908ccea673ecfd316090e5ff164",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Access to on-line information via the Web is exploding. Index and retrieval engines already start to integrate a huge variety of heterogeneous repositories. However, the heterogeneity issue remains, both in terms of the search formats and the formats of the result pages. \n \nIn this paper we focus on html-based search and result presentations. We discuss our experience in the design, the development and the maintenance of wrappers (in the context of the Knowledge Broker project). We outline different ways to write wrappers, illustrate some of the lessons learned, and conclude by describing a semi-automatic approach for an efficient wrapping of Web-based information repositories. Throughout the paper, we give illustrating examples for hands-on readers."
            },
            "slug": "Towards-Sophisticated-Wrapping-of-Web-based-Chidlovskii-Borghoff",
            "title": {
                "fragments": [],
                "text": "Towards Sophisticated Wrapping of Web-based information Repositories"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper outlines different ways to write wrappers, illustrates some of the lessons learned, and concludes by describing a semi-automatic approach for an efficient wrapping of Web-based information repositories."
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34607455"
                        ],
                        "name": "Chun-Nan Hsu",
                        "slug": "Chun-Nan-Hsu",
                        "structuredName": {
                            "firstName": "Chun-Nan",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun-Nan Hsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "SoftMealy [9] uses a wrapper induction algorithm that generates extraction rules expressed as nite transducers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7276869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52a3bc5971752b7bd66b63dad1f0040e5b4540d2",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents SoftMealy, a novel Web wrapper representation formalism. This representation is based on a finite-state transducer (FST) and contextual rules, which allow a wrapper to wrap semistructured Web pages containing missing attributes, multiple attribute values, variant attribute permutations, exceptions and typos, the features that no previous work can handle. A SoftMealy wrapper can be learned from labeled example items using a simple induction algorithm. Learnability analysis shows that SoftMealy scales well with the number of attributes and the number of different attribute permutations. Experimental results show that the learning algorithm can learn correct wrappers for a wide range of Web pages with a handful of examples and generalize well over unseen pages and structural patterns."
            },
            "slug": "Initial-Results-on-Wrapping-Semistructured-Web-with-Hsu",
            "title": {
                "fragments": [],
                "text": "Initial Results on Wrapping Semistructured Web Pages with Finite-State Transducers and Contextual Rules"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results show that the learning algorithm can learn correct wrappers for a wide range of Web pages with a handful of examples and generalize well over unseen pages and structural patterns."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785690"
                        ],
                        "name": "G. Mecca",
                        "slug": "G.-Mecca",
                        "structuredName": {
                            "firstName": "Giansalvatore",
                            "lastName": "Mecca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mecca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741158"
                        ],
                        "name": "P. Atzeni",
                        "slug": "P.-Atzeni",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Atzeni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Atzeni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": ", where the extraction rules are written by a human expert), from procedural languages [2] and Perl scripts [7] to pattern matching [5] and LL(k) grammars [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15285677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e46905d83ee82fc5ce9f2af6c76157f49a2cef79",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper develops Editor, a language for manipulating semistructured documents, such as those typically available on the Web. Editor programs are based on two simple ideas, taken from text editors: \u201csearch\u201d instructions are used to select regions of interest in a document, and \u201ccut & paste\u201d instructions to restructure them. We study the expressive power and the complexity of these programs. We show that they are computationally complete, in the sense that any computable document restructuring can be expressed in Editor. We also study the complexity of a safe subclass of programs, showing that it captures exactly the class of polynomial-time restructurings. The language has been implemented in Java and is currently used in the Araneus project as a basis for a wrapper-generation toolkit."
            },
            "slug": "Cut-and-paste-Mecca-Atzeni",
            "title": {
                "fragments": [],
                "text": "Cut & Paste"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "The paper develops Editor, a language for manipulating semistructured documents, such as those typically available on the Web, that is computationally complete, in the sense that any computable document restructuring can be expressed in Editor."
            },
            "venue": {
                "fragments": [],
                "text": "PODS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9086294"
                        ],
                        "name": "S. Chawathe",
                        "slug": "S.-Chawathe",
                        "structuredName": {
                            "firstName": "Sudarshan",
                            "lastName": "Chawathe",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chawathe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398574232"
                        ],
                        "name": "H. Garcia-Molina",
                        "slug": "H.-Garcia-Molina",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Garcia-Molina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Garcia-Molina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144477659"
                        ],
                        "name": "J. Hammer",
                        "slug": "J.-Hammer",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Hammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144185412"
                        ],
                        "name": "K. Ireland",
                        "slug": "K.-Ireland",
                        "structuredName": {
                            "firstName": "Kelly",
                            "lastName": "Ireland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ireland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786049"
                        ],
                        "name": "Y. Papakonstantinou",
                        "slug": "Y.-Papakonstantinou",
                        "structuredName": {
                            "firstName": "Yannis",
                            "lastName": "Papakonstantinou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Papakonstantinou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737896"
                        ],
                        "name": "J. Widom",
                        "slug": "J.-Widom",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Widom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Widom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": ", where the extraction rules are written by a human expert), from procedural languages [2] and Perl scripts [7] to pattern matching [5] and LL(k) grammars [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "Some systems, such as tsimmis [5] and araneus [3] depend on humans to write the necessary grammar rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2113876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14348170a14b4e2edca01521184cb2cd60b83200",
            "isKey": false,
            "numCitedBy": 1264,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of the Tsimmis Project is to develop tools that facilitate the rapid integration of heterogeneous information sources that may include both structured and unstructured data. This paper gives an overview of the project, describing components that extract properties from unstructured objects, that translate information into a common object model, that combine information from several sources, that allow browsing of information, and that manage constraints across heterogeneous sites. Tsimmis is a joint project between Stanford and the IBM Almaden Research Center. 1 Overview A common problem facing many organizations today is that of multiple, disparate information sources and repositories, including databases, object stores, knowledge bases, file systems, digital libraries, information retrieval systems, and electronic mail systems. Decision makers often need information from multiple sources, but are unable to get and fuse the required information in a timely fashion due to the diffculties of accessing the different systems, and due to the fact that the information obtained can be inconsistent and contradictory. Research sponsored by the Wright Laboratory, Aeronautical Systems Center, Air Force Material Command, USAF, under Grant Number F33615-93-1-1339. The US Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation thereon. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the offcial policies or endorsements, either express or implied, of Wright Laboratory or the US Government. This work was also supported by the Reid and Polly Anderson Faculty Scholar Fund, the Center for Integrated Systems at Stanford University, and by Equipment Grants from Digital Equipment Corporation and IBM Corporation. The goal of the TSIMMIS 1 project is to provide tools for accessing, in an integrated fashion, multiple informati"
            },
            "slug": "The-TSIMMIS-Project:-Integration-of-Heterogeneous-Chawathe-Garcia-Molina",
            "title": {
                "fragments": [],
                "text": "The TSIMMIS Project: Integration of Heterogeneous Information Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An overview of the Tsimmis Project is given, describing components that extract properties from unstructured objects, that translate information into a common object model, that combine information from several sources, that allow browsing of information, and that manage constraints across heterogeneous sites."
            },
            "venue": {
                "fragments": [],
                "text": "IPSJ"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076231991"
                        ],
                        "name": "T. Kirk",
                        "slug": "T.-Kirk",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50874323"
                        ],
                        "name": "Alon Y. Levy",
                        "slug": "Alon-Y.-Levy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Levy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alon Y. Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714472"
                        ],
                        "name": "Y. Sagiv",
                        "slug": "Y.-Sagiv",
                        "structuredName": {
                            "firstName": "Yehoshua",
                            "lastName": "Sagiv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Sagiv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145860176"
                        ],
                        "name": "D. Srivastava",
                        "slug": "D.-Srivastava",
                        "structuredName": {
                            "firstName": "Divesh",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Srivastava"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 85
                            }
                        ],
                        "text": "The most recent generation of information agents (e.g., WHIRL [7], Ariadne [11], and Information Manifold [10] ) address this problem by enabling information from pre-speci ed sets of Web sites to be accessed via database-like queries."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": ", WHIRL [7], Ariadne [11], and Information Manifold [10] ) address this problem by enabling information from pre-speci ed sets of Web sites to be accessed via database-like queries."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63440469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8450a2666891b0fa6be16d0fa320db25abe9bbb",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the Information Manifold (IM), a system for browsing and querying of multiple networked information sources. As a first contribution, the system demonstrates the viability of knowledge representation technology for retrieval and organization of information from disparate (structured and unstructured) information sources. Such an organization allows the user to pose high-level queries that use data from multiple information sources. As a second contribution, we describe novel query processing algorithms used to combine information from multiple sources. In particular, our algorithms are guaranteed to find exactly the set of information sources relevant to a query, and to completely exploit knowledge about local closed world information (Etzioni et al. 1994)."
            },
            "slug": "The-Information-Manifold-Kirk-Levy",
            "title": {
                "fragments": [],
                "text": "The Information Manifold"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "The Information Manifold is described, a system for browsing and querying of multiple networked information sources that demonstrates the viability of knowledge representation technology for retrieval and organization of information from disparate information sources."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70674919"
                        ],
                        "name": "T. R. Chaudhur",
                        "slug": "T.-R.-Chaudhur",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Chaudhur",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. R. Chaudhur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119899233"
                        ],
                        "name": "Len Hamey",
                        "slug": "Len-Hamey",
                        "structuredName": {
                            "firstName": "Len",
                            "lastName": "Hamey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Len Hamey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 259
                            }
                        ],
                        "text": "Second, the fact that even for the hardest items in S4 we can nd a correct rule (remember that the low correctness comes from averaging correct rules with erroneous ones) means that we can try to improve stalker's behavior based on active learning techniques [13] that would allow the algorithm to select the few relevant cases that would lead to a correct rule."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61707444,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33be4001d7c415fa1b93206f0248447489570885",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper surveys published work in active learning research with the purpose of providing a unified understanding of the area. A passive learning system relies entirely on pre-gathered information, whereas an active learning algorithm has the capability of interacting with its environment in order to collect information and/or to select learning policy. Active learning systems produce improved generalisation, reduce data costs and are most useful where data is expensive and computation is cheap. There are three major recognised approaches to the implementation of active learning goal-driven learning, reinforcement learning and querying. While the first is largely a meta-level symbolic approach, the second is more a class of problems employing a policy-based approach to learning in non-deterministic dynamic environments; the third is based upon gathering the most useful examples by asking 'intelligent' questions. Research in the area is still mostly at a theoretical level."
            },
            "slug": "Active-Learning:-Approaches-and-Issues-Chaudhur-Hamey",
            "title": {
                "fragments": [],
                "text": "Active Learning: Approaches and Issues"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper surveys published work in active learning research with the purpose of providing a unified understanding of the area and identifies three major recognised approaches to the implementation of active learning goal-driven learning, reinforcement learning and querying."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 85
                            }
                        ],
                        "text": "The most recent generation of information agents (e.g., WHIRL [7], Ariadne [11], and Information Manifold [10] ) address this problem by enabling information from pre-speci ed sets of Web sites to be accessed via database-like queries."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": ", WHIRL [7], Ariadne [11], and Information Manifold [10] ) address this problem by enabling information from pre-speci ed sets of Web sites to be accessed via database-like queries."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The information manifold. AAAI  Spring Symposium: Information Gathering from Het-  erogeneous Distributed Environments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rise: A repository of online information sources used in information extraction tasks"
            },
            "venue": {
                "fragments": [],
                "text": "Information Sciences Institute"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The information manifold. AAAI Spring Symposium: Information Gathering from Heterogeneous Distributed Environments"
            },
            "venue": {
                "fragments": [],
                "text": "The information manifold. AAAI Spring Symposium: Information Gathering from Heterogeneous Distributed Environments"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rise : A repository of online information sources used in information extraction tasks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "Some systems, such as tsimmis [5] and araneus [3] depend on humans to write the necessary grammar rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semi-  structured and structured data in the web: going back  and forth"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ACM SIGMOD Workshop on  Management of Semi-structured Data"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Working Papers of the ACL-97 Workshop in Natural Language Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Working Papers of the ACL-97 Workshop in Natural Language Learning"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wrapper induction for information extraction TR UW-CSE-97-11-04 1997 Active learning-approaches and issues Rise: A repository of online information sources used in information extraction tasks"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Intelligent Systems"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information extraction from html: Ap plication of a general learning approach"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fifteenth Conference on Artificial Intelligence AAAI-98"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relational learn-  ing of pattern-match rules for information extraction.  Working Papers of the ACL-97 Workshop in Natural  Language Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information extraction from html: Ap-  plication of a general learning approach"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings  of the Fifteenth Conference on Arti cial Intelligence"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-hierarchical-approach-to-wrapper-induction-Muslea-Minton/1cc263c84b85027164bd39db169f5d5959ef6822?sort=total-citations"
}