{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059302634"
                        ],
                        "name": "H. Chuan",
                        "slug": "H.-Chuan",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Chuan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780232"
                        ],
                        "name": "M. Sakauchi",
                        "slug": "M.-Sakauchi",
                        "structuredName": {
                            "firstName": "Masao",
                            "lastName": "Sakauchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sakauchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35935929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c8c56a41f876a2b860d624dd0e249db38107c46",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "While general object recognition is difficult, it is relatively easy to capture some primitive image properties such as color distribution, prominent regions and their geometrical properties from an image and use these features to narrow down the search space when attempts to retrieving images by contents from an image database are made. The authors are building an image database in which images are indexed by both the numerical index keys generated automatically from the captured primitive image features using a set of rules, and traditional descriptive keywords entered by users when images are loaded. Users can either use the descriptive keywords or provide information regarding these image properties to query and retrieve images from the database. With this approach, the authors turn the difficult problem of image matching into image retrieval by index keys, which can be performed easily and rapidly using current database techniques. Initial experiments on the image database system show promising performance.<<ETX>>"
            },
            "slug": "An-image-database-system-with-content-capturing-and-Gong-Zhang",
            "title": {
                "fragments": [],
                "text": "An image database system with content capturing and fast image indexing abilities"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The authors are building an image database in which images are indexed by both the numerical index keys generated automatically from the captured primitive image features using a set of rules, and traditional descriptive keywords entered by users when images are loaded."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE International Conference on Multimedia Computing and Systems"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3146306"
                        ],
                        "name": "D. Tegolo",
                        "slug": "D.-Tegolo",
                        "structuredName": {
                            "firstName": "Domenico",
                            "lastName": "Tegolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tegolo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11368383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "119bb9ad8cc4cc71c22dfa1b3cc88d3bfffa69bf",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The main aim of this paper is to describe a method for locating a subimage of a stored image that approximately matches a given query image. This matching can support naive users in accessing an image database according to image contents rather symbolic attributes. The query image can be either composed using painting tools or cuts out of an actual scanned image. Our method is based on the extraction of features from the query image and from the stored images. The following three steps are involved: (1) an ISODATA algorithm is applied to segment (into region) both the query image and the stored images; (2) the normalized moment and geometrical features are computed from the segmented regions, and (3) a matching process is run on the resulting features to find those stored images which should be retrieved. The result is an ordered list of stored images or subimages from the database."
            },
            "slug": "Shape-analysis-for-image-retrieval-Tegolo",
            "title": {
                "fragments": [],
                "text": "Shape analysis for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A method for locating a subimage of a stored image that approximately matches a given query image that can support naive users in accessing an image database according to image contents rather symbolic attributes is described."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5493306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a8660582f5b07727906a43d737fda902a312eb",
            "isKey": false,
            "numCitedBy": 786,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the Photobook system, which is a set of interactive tools for browsing and searching images and image sequences. These tools differ from those used in standard image databases in that they make direct use of the image content rather than relying on annotations. Direct search on image content is made possible by use of semantics-preserving image compression, which reduces images to a small set of perceptually-significant coefficients. We describe three Photobook tools in particular: one that allows search based on grey-level appearance, one that uses 2D shape, and a third that allows search based on textural properties."
            },
            "slug": "Photobook:-tools-for-content-based-manipulation-of-Pentland-Picard",
            "title": {
                "fragments": [],
                "text": "Photobook: tools for content-based manipulation of image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The Photobook system is described, which is a set of interactive tools for browsing and searching images and image sequences that differ from those used in standard image databases in that they make direct use of the image content rather than relying on annotations."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767957"
                        ],
                        "name": "P. Pala",
                        "slug": "P.-Pala",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Pala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pala"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40084149,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f171179dd773978ab0a3b541fc9ea77af8b2b6a8",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Image retrieval by contents from database is a major research subject in advanced multimedia systems. The intrinsic visuality associated with pictorial data suggests the use of iconic indexes and visual techniques to perform retrieval effectively. In this paper we present a method for image retrieval based on sketches of object shapes. In our method, the shape drawn by the user is deformed to match as well as possible the objects in the images. The degree of match achieved, and the elastic deformation energy spent to achieve such a match are used as a measure of the similarity between the template and the image object. The elastic matching is integrated with arrangements to provide for scale invariance, to take into account rotations and spatial relationships between objects for multiple-object queries."
            },
            "slug": "Image-Retrieval-by-Elastic-Matching-of-User-Bimbo-Pala",
            "title": {
                "fragments": [],
                "text": "Image Retrieval by Elastic Matching of User Sketches"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "In this paper, a method for image retrieval based on sketches of object shapes is presented, in which the shape drawn by the user is deformed to match as well as possible the objects in the images."
            },
            "venue": {
                "fragments": [],
                "text": "ICIAP"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110164828"
                        ],
                        "name": "S.-K. Lim",
                        "slug": "S.-K.-Lim",
                        "structuredName": {
                            "firstName": "S.-K.",
                            "lastName": "Lim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S.-K. Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766776"
                        ],
                        "name": "H. Pung",
                        "slug": "H.-Pung",
                        "structuredName": {
                            "firstName": "Hung",
                            "lastName": "Pung",
                            "middleNames": [
                                "Keng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Pung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18504134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00a6ff44da7b64ac866c5c8f7feb350c06637815",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Most general content-based image retrieval techniques use colour and texture as main retrieval indices. A recent technique uses colour pairs to model distinct object boundaries for retrieval. These techniques have been applied to overall image contents without taking into account the characteristics of individual objects. While the techniques work well for the retrieval of images with similar overall contents (including backgrounds), their accuracies are limited because they are unable to take advantage of individual object's visual characteristics, and to perform object-level retrieval. This paper looks specifically at the use of colour-pair technique for fuzzy object-level image retrieval. Three extensions are applied to the basic colour-pair technique: (a) the development of a similarity-based ranking formula for colour-pairs matching; (b) the use of segmented objects for object-level retrieval; and (c) the inclusion of perceptually similar colours for fuzzy retrieval. A computer-aided segmentation technique is developed to segment the images' contents. Experimental results indicate that the extensions have led to substantial improvements in the retrieval performance. These extensions are sufficiently general and can be applied to other content-based image retrieval techniques."
            },
            "slug": "Content-based-retrieval-of-segmented-images-Chua-Lim",
            "title": {
                "fragments": [],
                "text": "Content-based retrieval of segmented images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Three extensions are applied to the basic colour-pair technique: the development of a similarity-based ranking formula for colour-pairs matching; the use of segmented objects for object-level retrieval; and the inclusion of perceptually similar colours for fuzzy retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152883679"
                        ],
                        "name": "J. Ashley",
                        "slug": "J.-Ashley",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Ashley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ashley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1391129943"
                        ],
                        "name": "Qian Huang",
                        "slug": "Qian-Huang",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786444"
                        ],
                        "name": "B. Dom",
                        "slug": "B.-Dom",
                        "structuredName": {
                            "firstName": "Byron",
                            "lastName": "Dom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087139"
                        ],
                        "name": "M. Gorkani",
                        "slug": "M.-Gorkani",
                        "structuredName": {
                            "firstName": "Monika",
                            "lastName": "Gorkani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gorkani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39311329"
                        ],
                        "name": "J. Hafner",
                        "slug": "J.-Hafner",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Hafner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hafner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499047"
                        ],
                        "name": "Denis Lee",
                        "slug": "Denis-Lee",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denis Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867341"
                        ],
                        "name": "D. Petkovic",
                        "slug": "D.-Petkovic",
                        "structuredName": {
                            "firstName": "Dragutin",
                            "lastName": "Petkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Petkovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144028064"
                        ],
                        "name": "David Steele",
                        "slug": "David-Steele",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Steele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Steele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70341848"
                        ],
                        "name": "P. Yanker",
                        "slug": "P.-Yanker",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yanker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yanker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 110716,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "dc139f901c869f80b54b41f89d5b7f35c7dfa3c7",
            "isKey": false,
            "numCitedBy": 4258,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Research on ways to extend and improve query methods for image databases is widespread. We have developed the QBIC (Query by Image Content) system to explore content-based retrieval methods. QBIC allows queries on large image and video databases based on example images, user-constructed sketches and drawings, selected color and texture patterns, camera and object motion, and other graphical information. Two key properties of QBIC are (1) its use of image and video content-computable properties of color, texture, shape and motion of images, videos and their objects-in the queries, and (2) its graphical query language, in which queries are posed by drawing, selecting and other graphical means. This article describes the QBIC system and demonstrates its query capabilities. QBIC technology is part of several IBM products. >"
            },
            "slug": "Query-by-Image-and-Video-Content:-The-QBIC-System-Flickner-Sawhney",
            "title": {
                "fragments": [],
                "text": "Query by Image and Video Content: The QBIC System"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The QBIC system is described and its query capabilities are demonstrated, which allows queries on large image and video databases based on example images, user-constructed sketches and drawings, selected color and texture patterns, camera and object motion, and other graphical information."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764131"
                        ],
                        "name": "R. Mehrotra",
                        "slug": "R.-Mehrotra",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mehrotra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50476996"
                        ],
                        "name": "James E. Gary",
                        "slug": "James-E.-Gary",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Gary",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James E. Gary"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42769186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ef7073a8db6dd706e432785564393871f38353e",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Addresses the problem of similar-shape retrieval, where shapes or images in a shape database that satisfy specified shape-similarity constraints with respect to the query shape or image must be retrieved from the database. In its simplest form, the similar-shape retrieval problem can be stated as, \"retrieve or select all shapes or images that are visually similar to the query shape or the query image's shape\". We focus on databases of 2D shapes-or equivalently, databases of images of flat or almost flat objects. (We use the terms \"object\" and \"shape\" interchangeably). Two common types of 2D objects are rigid objects, which have a single rigid component called a link, and articulated objects, which have two or more rigid components joined by movable (rotating or sliding) joints. An ideal similar-shape retrieval technique must be general enough to handle images of articulated as well as rigid objects. It must be flexible enough to handle simple query images, which have isolated shapes, and complex query images, which have partially visible, overlapping or touching objects. We discuss the central issues in similar-shape retrieval and explain how these issues are resolved in a shape retrieval scheme called FIBSSR (Feature Index-Based Similar-Shape Retrieval). This new similar-shape retrieval system effectively models real-world applications. >"
            },
            "slug": "Similar-Shape-Retrieval-in-Shape-Data-Management-Mehrotra-Gary",
            "title": {
                "fragments": [],
                "text": "Similar-Shape Retrieval in Shape Data Management"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work discusses the central issues in similar-shape retrieval and explains how these issues are resolved in a shape retrieval scheme called FIBSSR (Feature Index-Based Similar-Shape Retrieval)."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746338"
                        ],
                        "name": "D. Papadias",
                        "slug": "D.-Papadias",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Papadias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Papadias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144302930"
                        ],
                        "name": "T. Sellis",
                        "slug": "T.-Sellis",
                        "structuredName": {
                            "firstName": "Timos",
                            "lastName": "Sellis",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sellis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9911795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0c8b0540ad4ab007d1d99d5056cf71d7bfced7b",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A symbolic image is an array representing a set of objects and a set of spatial relations among them. Symbolic images and related structures have been used in a number of applications including image databases, spatial reasoning, path planning and spatial pattern matching. In this paper we describe a pictorial query-by-example (PQBE) language aimed at the retrieval of direction relations from symbolic images. As in the case of verbal query-by-example, PQBE generalizes from the example given by the user, but, instead of having queries in the form of skeleton tables showing the relation scheme, we have skeleton images which are themselves symbolic images. PQBE provides an intuitive interface for use in geographic applications because of its close correspondence with the structure of space."
            },
            "slug": "A-Pictorial-Query-by-Example-Language-Papadias-Sellis",
            "title": {
                "fragments": [],
                "text": "A Pictorial Query-by-Example Language"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A pictorial query-by-example (PQBE) language aimed at the retrieval of direction relations from symbolic images, which provides an intuitive interface for use in geographic applications because of its close correspondence with the structure of space."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Lang. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730368"
                        ],
                        "name": "A. Kitamoto",
                        "slug": "A.-Kitamoto",
                        "structuredName": {
                            "firstName": "Asanobu",
                            "lastName": "Kitamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kitamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110842595"
                        ],
                        "name": "Changming Zhou",
                        "slug": "Changming-Zhou",
                        "structuredName": {
                            "firstName": "Changming",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changming Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145238965"
                        ],
                        "name": "M. Takagi",
                        "slug": "M.-Takagi",
                        "structuredName": {
                            "firstName": "Mikio",
                            "lastName": "Takagi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Takagi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34620604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "764e18101bdbb67dcd75d12d90ede920098ffa13",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "An attributed relational graph (ARG) is introduced into our NOAA satellite image database system. The node and the branch of an ARG denotes a classified region and a spatial relationship between adjacent regions, respectively. Furthermore, a few attributes of a node/branch help to express numerical shape features of regions. Similarity retrieval thereby turns out to be equivalent to graph matching. The similarity retrieval process of the system is as follows: (1) select a visual example image as a query and generate its graph structure, (2) calculate an optimal graph matching cost between a query graph and an archived graph in the database, utilizing algorithm A* with heuristic information, (3) choose archived images in the ascending order of a corresponding matching cost."
            },
            "slug": "Similarity-retrieval-of-NOAA-satellite-imagery-by-Kitamoto-Zhou",
            "title": {
                "fragments": [],
                "text": "Similarity retrieval of NOAA satellite imagery by graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An attributed relational graph (ARG) is introduced into the NOAA satellite image database system and similarity retrieval thereby turns out to be equivalent to graph matching."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50204063"
                        ],
                        "name": "V. Ng",
                        "slug": "V.-Ng",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Ng",
                            "middleNames": [
                                "T.",
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065541303"
                        ],
                        "name": "D. Cheung",
                        "slug": "D.-Cheung",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cheung",
                            "middleNames": [
                                "Wai-Lok"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cheung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699363"
                        ],
                        "name": "A. Fu",
                        "slug": "A.-Fu",
                        "structuredName": {
                            "firstName": "Ada",
                            "lastName": "Fu",
                            "middleNames": [
                                "Wai-Chee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61328003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43119bc9915b61e864cd8f3df5fedfe9a1188306",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop an indexing scheme for medical images. In general, for a given medical image, there is one object which is clinically important amongst the rest. We name this object the dominant object. Our proposed index is composed of three parts: (1) the dominant objects in images are standardized; (2) each image will have its own quadtree constructed which depends on the color composition and the color variation in the image; and (3) an R-tree that supports the retrieval of color images. To demonstrate the effectiveness of the index developed, we use images of skin lesions as the image data. Our initial experiments gives promising results for image retrieval."
            },
            "slug": "Medical-image-retrieval-by-color-content-Ng-Cheung",
            "title": {
                "fragments": [],
                "text": "Medical image retrieval by color content"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed index is composed of three parts: the dominant objects in images are standardized, each image will have its own quadtree constructed which depends on the color composition and the color variation in the image; and an R-tree that supports the retrieval of color images."
            },
            "venue": {
                "fragments": [],
                "text": "1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145814117"
                        ],
                        "name": "D. Swanberg",
                        "slug": "D.-Swanberg",
                        "structuredName": {
                            "firstName": "Deborah",
                            "lastName": "Swanberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swanberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62366717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6384747308f9054a75a0264513a38c5474f4933e",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Research is well underway to investigate the appropriate use of similarity measures across complex objects such as faces and color histograms. This research is crucial in producing systems that support content-based retrieval. To support the successful integration of the these techniques into database systems, support tools and object definitions are needed that can assist with the data modeling process that segments, stores and accesses the data. Here, we define our first efforts to defining the classes and operations inherent in any segmentation process. We define a generic processor structures these essential processes. Finally, we define a set of video objects we have defined to support the segmentation of broadcast video streams.<<ETX>>"
            },
            "slug": "In-support-of-similarity-measures-Swanberg-Jain",
            "title": {
                "fragments": [],
                "text": "In support of similarity measures"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work defines its first efforts to defining the classes and operations inherent in any segmentation process, and defines a generic processor that structures these essential processes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 28th Asilomar Conference on Signals, Systems and Computers"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2160177"
                        ],
                        "name": "N. Dimitrova",
                        "slug": "N.-Dimitrova",
                        "structuredName": {
                            "firstName": "Nevenka",
                            "lastName": "Dimitrova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dimitrova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703912"
                        ],
                        "name": "F. Golshani",
                        "slug": "F.-Golshani",
                        "structuredName": {
                            "firstName": "Forouzan",
                            "lastName": "Golshani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Golshani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14324045,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54ecdf01c1bbbe8106cd27a35aed672c3564ef34",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Like other types of digital information, video sequences must be classified based on the semantics of their contents. A more-precise and completer extraction of semantic information will result in a more-effective classification. The most-discernible difference between still images and moving pictures stems from movements and variations. Thus, to go from the realm of still-image repositories to video databases, we must be able to deal with motion. Particularly, we need the ability to classify objects appearing in a video sequence based on their characteristics and features such as shape or color, as well as their movements. By describing the movements that we derive from the process of motion analysis, we introduce a dual hierarchy consisting of spatial and temporal parts for video sequence representation. This gives us the flexibility to examine arbitrary sequences of frames at various levels of abstraction and to retrieve the associated temporal information (say, object trajectories) in addition to the spatial representation. Our algorithm for motion detection uses the motion compensation component of the MPEG video-encoding scheme and then computes trajectories for objects of interest. The specification of a language for retrieval of video based on the spatial as well as motion characteristics is presented."
            },
            "slug": "Motion-recovery-for-video-content-classification-Dimitrova-Golshani",
            "title": {
                "fragments": [],
                "text": "Motion recovery for video content classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The specification of a language for retrieval of video based on the spatial as well as motion characteristics is presented and the algorithm for motion detection uses the motion compensation component of the MPEG video-encoding scheme and then computes trajectories for objects of interest."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170732251"
                        ],
                        "name": "Fang Liu",
                        "slug": "Fang-Liu",
                        "structuredName": {
                            "firstName": "Fang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17049261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b703ddbea8ccaf7554dae3a70375e7299322ed0",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the fundamental challenges in pattern recognition is choosing a set of features appropriate to a class of problems. In applications such as image retrieval, if is important that features used by the system in pattern comparison provide good measures of \"perceptual similarity\". The authors present a new set of features and an image model based on the three mutually orthogonal components produced by the 2-D Wold decomposition of random fields. These components have visual properties which approximate the three most important perceptual dimensions of human texture perception. The method presented here is different from the existing Wold-based models in that it tolerates certain local inhomogeneities which arise in natural textures and reduces computation for comparison of patterns subjected to transformations such as rotation. An image retrieval algorithm based on the new texture model is presented. The effectiveness of the new Wold features for retrieving perceptually similar natural textures is demonstrated by comparing it to that of other well-known pattern recognition methods. The Wold model appears to offer a perceptually more satisfying measure of pattern similarity."
            },
            "slug": "Periodicity,-directionality,-and-randomness:-Wold-Liu-Picard",
            "title": {
                "fragments": [],
                "text": "Periodicity, directionality, and randomness: Wold features for perceptual pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The authors present a new set of features and an image model based on the three mutually orthogonal components produced by the 2-D Wold decomposition of random fields which approximate the three most important perceptual dimensions of human texture perception."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IAPR International Conference on Pattern Recognition, Vol. 3 - Conference C: Signal Processing (Cat. No.94CH3440-5)"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792053"
                        ],
                        "name": "B. Scassellati",
                        "slug": "B.-Scassellati",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Scassellati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Scassellati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2914624"
                        ],
                        "name": "S. Alexopoulos",
                        "slug": "S.-Alexopoulos",
                        "structuredName": {
                            "firstName": "Sophoclis",
                            "lastName": "Alexopoulos",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Alexopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2404936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fa5856ce0aa7331c7a9ee70a225b0a7d5aa1d37",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In content based image retrieval, systems allow users to ask for objects similar in shape to a query object. However, there is no clear understanding of how computational shape similarity corresponds to human shape similarity. In this paper several shape similarity measures were evaluated on planar, connected, non-occluded binary shapes. Shape similarity using algebraic moments, spline curve distances, cumulative turning angle, signal of curvature and Hausdorff- distance were compared to human similarity judgments on twenty test shapes against a large image database."
            },
            "slug": "Retrieving-images-by-2D-shape:-a-comparison-of-with-Scassellati-Alexopoulos",
            "title": {
                "fragments": [],
                "text": "Retrieving images by 2D shape: a comparison of computation methods with human perceptual judgments"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Shape similarity using algebraic moments, spline curve distances, cumulative turning angle, signal of curvature and Hausdorff- distance were compared to human similarity judgments on twenty test shapes against a large image database."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14955,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121489653"
                        ],
                        "name": "B. Jones",
                        "slug": "B.-Jones",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jones"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62239566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c47f7fcda4071bce2e161beb66c278352a8e7daf",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The video monitoring of outdoor sites is a demanding task that is commonly tackled by having security guards look at arrays of CCTV monitors. Experience shows that this is largely ineffective, both as a detector and a deterrent. However, modern digital imaging systems can solve both these problems by maintaining constant vigilance 24 hours a day. These systems can be versatile and can operate in several different modes, video motion detection, video nonmotion detection and incident capture, thus providing a flexibility of application environment. By basing these systems on powerful PC technology the end user benefits from a large range of facilities at relatively low cost. In particular, it is possible to have low cost frame storage and high performance communications over telephones, ISDN or Ethernet. Image sequences both prior to and after an event can be stored and transmitted. Archiving and retrieval of events can be done efficiently through standard databases. However, in order that such systems be operationally viable it is essential that the detection algorithms be smart enough to reduce the number of false alarms to virtually zero. Most of the discussion concerns technology that is currently available and in everyday use: the author uses the ASTRAGUARD product as a specific example of such a system."
            },
            "slug": "Low-cost-outdoor-video-motion-and-non-motion-Jones",
            "title": {
                "fragments": [],
                "text": "Low-cost outdoor video motion and non-motion detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The author uses the ASTRAGUARD product as a specific example of such a system, which can be versatile and operate in several different modes, video motion detection, video nonmotion detection and incident capture, thus providing a flexibility of application environment."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings The Institute of Electrical and Electronics Engineers. 29th Annual 1995 International Carnahan Conference on Security Technology"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\" Shape analysis for image retrieval , \" Storage and Retrieval for Image and Video Databases II , San Jose , CA , USA , 7 - 8 Feb . 1994"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the SPIE - The International Society for Optical Engineering"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Virage-image-search-engine:-an-open-framework-for-Bach-Fuller/87cc226aa060db976fbf6ac3a07969b33b544b96?sort=total-citations"
}