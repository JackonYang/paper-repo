{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3331461"
                        ],
                        "name": "S. Hanif",
                        "slug": "S.-Hanif",
                        "structuredName": {
                            "firstName": "Shehzad",
                            "lastName": "Hanif",
                            "middleNames": [
                                "Muhammad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanif"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2554802"
                        ],
                        "name": "L. Prevost",
                        "slug": "L.-Prevost",
                        "structuredName": {
                            "firstName": "Lionel",
                            "lastName": "Prevost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Prevost"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "The work presented in this paper is a part of the project Intelligent Glasses which is an electronic aid to blind and visually impaired persons [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10603583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "841fd2a7bcc5eac695e548e298b5c943c84b7ba4",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a texture-based text detection scheme for detecting text in natural scene images. This is a preliminary work towards a complete system of text detection, localization and recognition in order to help visually impaired persons. We have employed spatial histograms computed from gray-level co-occurrence matrices for texture coding and three classifiers have been evaluated. Moreover, one feature selection mechanism is employed to select those histogram components that exhibit high discrimination power. The texture coding scheme is simple and can readily differentiate between text and non-text. The proposed scheme is evaluated on 50 images taken from ICDAR 2003 robust reading and text locating database. The results are encouraging with a text detection rate of 66% and a false alarms rate of 22% ."
            },
            "slug": "Detection-in-Natural-Scene-Images-using-Spatial-Hanif-Prevost",
            "title": {
                "fragments": [],
                "text": "Detection in Natural Scene Images using Spatial Histograms"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A texture-based text detection scheme for detecting text in natural scene images and one feature selection mechanism is employed to select those histogram components that exhibit high discrimination power."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772671"
                        ],
                        "name": "Xiangrong Chen",
                        "slug": "Xiangrong-Chen",
                        "structuredName": {
                            "firstName": "Xiangrong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangrong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 135
                            }
                        ],
                        "text": "Text detection, localization and recognition are basic parts of a variety of real world applications destined for diverse applications [2][4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 17
                            }
                        ],
                        "text": "Some researchers [2, 6] have replaced the simple processing in the first step by an elegant cascade detector."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61234963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37ba7b9a823e8a400046bd149b7756adf5d698da",
            "isKey": false,
            "numCitedBy": 512,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives an algorithm for detecting and reading text in natural images. The algorithm is intended for use by blind and visually impaired subjects walking through city scenes. We first obtain a dataset of city images taken by blind and normally sighted subjects. From this dataset, we manually label and extract the text regions. Next we perform statistical analysis of the text regions to determine which image features are reliable indicators of text and have low entropy (i.e. feature response is similar for all text images). We obtain weak classifiers by using joint probabilities for feature responses on and off text. These weak classifiers are used as input to an AdaBoost machine learning algorithm to train a strong classifier. In practice, we trained a cascade with 4 strong classifiers containing 79 features. An adaptive binarization and extension algorithm is applied to those regions selected by the cascade classifier. Commercial OCR software is used to read the text or reject it as a non-text region. The overall algorithm has a success rate of over 90% (evaluated by complete detection and reading of the text) on the test set and the unread text is typically small and distant from the viewer."
            },
            "slug": "Detecting-and-reading-text-in-natural-scenes-Chen-Yuille",
            "title": {
                "fragments": [],
                "text": "Detecting and reading text in natural scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The overall algorithm has a success rate of over 90% (evaluated by complete detection and reading of the text) on the test set and the unread text is typically small and distant from the viewer."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772547"
                        ],
                        "name": "Xilin Chen",
                        "slug": "Xilin-Chen",
                        "structuredName": {
                            "firstName": "Xilin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xilin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118579343"
                        ],
                        "name": "Jie Yang",
                        "slug": "Jie-Yang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155703534"
                        ],
                        "name": "Jing Zhang",
                        "slug": "Jing-Zhang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Text detection, localization and recognition are basic parts of a variety of real world applications destined for vehicle drivers [2], visually impaired [5] and blind persons [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6109448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5295b6770ebbbc27a4651ed44b4b7e184d884f8e",
            "isKey": false,
            "numCitedBy": 330,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an approach to automatic detection and recognition of signs from natural scenes, and its application to a sign translation task. The proposed approach embeds multiresolution and multiscale edge detection, adaptive searching, color analysis, and affine rectification in a hierarchical framework for sign detection, with different emphases at each phase to handle the text in different sizes, orientations, color distributions and backgrounds. We use affine rectification to recover deformation of the text regions caused by an inappropriate camera view angle. The procedure can significantly improve text detection rate and optical character recognition (OCR) accuracy. Instead of using binary information for OCR, we extract features from an intensity image directly. We propose a local intensity normalization method to effectively handle lighting variations, followed by a Gabor transform to obtain local features, and finally a linear discriminant analysis (LDA) method for feature selection. We have applied the approach in developing a Chinese sign translation system, which can automatically detect and recognize Chinese signs as input from a camera, and translate the recognized text into English."
            },
            "slug": "Automatic-detection-and-recognition-of-signs-from-Chen-Yang",
            "title": {
                "fragments": [],
                "text": "Automatic detection and recognition of signs from natural scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a local intensity normalization method to effectively handle lighting variations, followed by a Gabor transform to obtain local features, and finally a linear discriminant analysis (LDA) method for feature selection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3061097"
                        ],
                        "name": "N. Ezaki",
                        "slug": "N.-Ezaki",
                        "structuredName": {
                            "firstName": "Nobuo",
                            "lastName": "Ezaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ezaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806816"
                        ],
                        "name": "M. Bulacu",
                        "slug": "M.-Bulacu",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Bulacu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bulacu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799278"
                        ],
                        "name": "Lambert Schomaker",
                        "slug": "Lambert-Schomaker",
                        "structuredName": {
                            "firstName": "Lambert",
                            "lastName": "Schomaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lambert Schomaker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "Finally, all verified components are clustered together by applying the connected component rules as defined in [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 138
                            }
                        ],
                        "text": "Text detection, localization and recognition are basic parts of a variety of real world applications destined for diverse applications [2][4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2561294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95e6599c7ac506446c4feefbf5a22841d24b08b0",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a system that reads the text encountered in natural scenes with the aim to provide assistance to the visually impaired persons. This paper describes the system design and evaluates several character extraction methods. Automatic text recognition from natural images receives a growing attention because of potential applications in image retrieval, robotics and intelligent transport system. Camera-based document analysis becomes a real possibility with the increasing resolution and availability of digital cameras. However, in the case of a blind person, finding the text region is the first important problem that must be addressed, because it cannot be assumed that the acquired image contains only characters. At first, our system tries to find in the image areas with small characters. Then it zooms into the found areas to retake higher resolution images necessary for character recognition. In the present paper, we propose four character-extraction methods based on connected components. We tested the effectiveness of our methods on the ICDAR 2003 Robust Reading Competition data. The performance of the different methods depends on character size. In the data, bigger characters are more prevalent and the most effective extraction method proves to be the sequence: Sobel edge detection, Otsu binarization, connected component extraction and rule-based connected component filtering."
            },
            "slug": "Text-detection-from-natural-scene-images:-towards-a-Ezaki-Bulacu",
            "title": {
                "fragments": [],
                "text": "Text detection from natural scene images: towards a system for visually impaired persons"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A system that reads the text encountered in natural scenes with the aim to provide assistance to the visually impaired persons and evaluates several character extraction methods based on connected components."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20063251"
                        ],
                        "name": "Marc Lalonde",
                        "slug": "Marc-Lalonde",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Lalonde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Lalonde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145468862"
                        ],
                        "name": "L. Gagnon",
                        "slug": "L.-Gagnon",
                        "structuredName": {
                            "firstName": "Langis",
                            "lastName": "Gagnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gagnon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] have followed the same guidelines and with a different feature set, detected the text in documentary films."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 17
                            }
                        ],
                        "text": "Some researchers [2, 6] have replaced the simple processing in the first step by an elegant cascade detector."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15786232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a3df3ccda1f362c21636c65ef8e3c029cbabcf3",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for spotting key-text in videos, based on a cascade of classifiers trained with Adaboost. The video is first reduced to a set of key-frames. Each key-frame is then analyzed for its text content. Text spotting is performed by scanning the image with a variable-size window (to account for scale) within which simple features (mean/variance of grayscale values and x/y derivatives) are extracted in various sub-areas. Training builds classifiers using the most discriminant spatial combinations of features for text detection. The text-spotting module outputs a decision map of the size of the input key-frame showing regions of interest that may contain text suitable for recognition by an OCR system. Performance is measured against a dataset of 147 key-frames extracted from 22 documentary films of the National Film Board (NFB) of Canada. A detection rate of 97% is obtained with relatively few false alarms."
            },
            "slug": "Key-text-spotting-in-documentary-videos-using-Lalonde-Gagnon",
            "title": {
                "fragments": [],
                "text": "Key-text spotting in documentary videos using Adaboost"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper presents a method for spotting key-text in videos, based on a cascade of classifiers trained with Adaboost, which results in a detection rate of 97% and relatively few false alarms."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Moreover, these features can be computed in a fast manner using integral image [11] and integral histogram [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 75
                            }
                        ],
                        "text": "The use of local features in object detection has gained a lot of interest [3, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 121
                            }
                        ],
                        "text": "In [2], Chen et al. successfully employed the AdaBoost algorithm [5] and the attentional cascade, originally proposed by Viola and Jones [11] for face detection, to detect and locate text in city scenes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "successfully employed the AdaBoost algorithm [5] and the attentional cascade, originally proposed by Viola and Jones [11] for face detection, to detect and locate text in city scenes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Viola and Jone in [11] introduced an attentional cascade in their work on face detection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": true,
            "numCitedBy": 11222,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 220
                            }
                        ],
                        "text": "Three different types of features are extracted from a text segments: Mean Difference Feature (MDF), Standard Deviation (SD) and Histogram of oriented Gradients (HOG)- used in number of applications like human detection [3] etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 75
                            }
                        ],
                        "text": "The use of local features in object detection has gained a lot of interest [3, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29259,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "The first criterion is the one used in ICDAR 2005 competition [8] and second one is defined by Ezaki et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "Results of the competition can be found in [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1842569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf50fe5622253f401e892ed943a18033e18b7b9",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the results of the ICDAR 2005 competition for locating text in camera captured scenes. For this we used the same data as the ICDAR 2003 competition, which has been kept private until now. This allows a direct comparison with the 2003 entries. The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f-score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition. The paper also discusses the Web-based deployment and evaluation of text locating systems, and one of the leading entries has now been deployed in this way. This mode of usage could lead to more complete and more immediate knowledge of the strengths and weaknesses of each newly developed system."
            },
            "slug": "ICDAR-2005-text-locating-competition-results-Lucas",
            "title": {
                "fragments": [],
                "text": "ICDAR 2005 text locating competition results"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f- score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8015515"
                        ],
                        "name": "Xuezheng Liu",
                        "slug": "Xuezheng-Liu",
                        "structuredName": {
                            "firstName": "Xuezheng",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuezheng Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39089563"
                        ],
                        "name": "Lei Zhang",
                        "slug": "Lei-Zhang",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71136815"
                        ],
                        "name": "Dingxing Wang",
                        "slug": "Dingxing-Wang",
                        "structuredName": {
                            "firstName": "Dingxing",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dingxing Wang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Moreover, considering combinations of more features make the training time infinitely long as observed by [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 140083992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61c183fcdbeee45b78cb5b5dfa66d03cef090b92",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Boosting-image-classification-with-LDA-based-for-Liu-Zhang",
            "title": {
                "fragments": [],
                "text": "Boosting image classification with LDA-based feature combination for digital photograph management"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "For boosting, AdaBoost requires a weak learner that should perform better than random guessing [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 105
                            }
                        ],
                        "text": "The rest of this paper is organized as follows: in the section 2, we describe feature set, weak learner, AdaBoost algorithm and cascade detector."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 86
                            }
                        ],
                        "text": "Attentional cascade combines sequentially several strong classifiers trained by using AdaBoost algorithm and the threshold \u03b8s is adjusted in such a way as to satisfy three necessary conditions: 1) maximum allowable false alarm rate (FAmax), 2) minimum allowable detection rate (DTmin) and 3) overall false alarm rate of cascade (Fo)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 46
                            }
                        ],
                        "text": "In [2], Chen et al. successfully employed the AdaBoost algorithm [5] and the attentional cascade, originally proposed by Viola and Jones [11] for face detection, to detect and locate text in city scenes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "successfully employed the AdaBoost algorithm [5] and the attentional cascade, originally proposed by Viola and Jones [11] for face detection, to detect and locate text in city scenes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 128
                            }
                        ],
                        "text": "However, it has been shown that a strong weak learner can also be used in boosting and performs well in real world applications [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "We have used the discrete version of AdaBoost [5] to build a strong classifier using a set of weak classifiers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "AdaBoost iterations (T ) are set to 200."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1836349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68c1bfe375dde46777fe1ac8f3636fb651e3f0f8",
            "isKey": true,
            "numCitedBy": 8626,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In an earlier paper, we introduced a new \"boosting\" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that con- sistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a \"pseudo-loss\" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers (including decision trees and single attribute- value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem."
            },
            "slug": "Experiments-with-a-New-Boosting-Algorithm-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "Experiments with a New Boosting Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper describes experiments carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems and compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29905643"
                        ],
                        "name": "F. Porikli",
                        "slug": "F.-Porikli",
                        "structuredName": {
                            "firstName": "Fatih",
                            "lastName": "Porikli",
                            "middleNames": [
                                "Murat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Porikli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "Moreover, these features can be computed in a fast manner using integral image [11] and integral histogram [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1122429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbf4d36e787e2e5c8444e1a2229b821e9cd68adf",
            "isKey": false,
            "numCitedBy": 810,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method, which we refer as an integral histogram, to compute the histograms of all possible target regions in a Cartesian data space. Our method has three distinct advantages: 1) It is computationally superior to the conventional approach. The integral histogram method makes it possible to employ even an exhaustive search process in real-time, which was impractical before. 2) It can be extended to higher data dimensions, uniform and nonuniform bin formations, and multiple target scales without sacrificing its computational advantages. 3) It enables the description of higher level histogram features. We exploit the spatial arrangement of data points, and recursively propagate an aggregated histogram by starting from the origin and traversing through the remaining points along either a scan-line or a wave-front. At each step, we update a single bin using the values of integral histogram at the previously visited neighboring data points. After the integral histogram is propagated, histogram of any target region can be computed easily by using simple arithmetic operations."
            },
            "slug": "Integral-histogram:-a-fast-way-to-extract-in-spaces-Porikli",
            "title": {
                "fragments": [],
                "text": "Integral histogram: a fast way to extract histograms in Cartesian spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The integral histogram method makes it possible to employ even an exhaustive search process in real-time, which was impractical before, and enables the description of higher level histogram features."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "The ICDAR 2003 robust reading and text locating database [1] was made public in 2003 for the competition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Icdar 2003 robust reading and locating database"
            },
            "venue": {
                "fragments": [],
                "text": "Icdar 2003 robust reading and locating database"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 12,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/A-cascade-detector-for-text-detection-in-natural-Hanif-Prevost/1dc8be7a356184357178a03fdf03a71e710f52b3?sort=total-citations"
}