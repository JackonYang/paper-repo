{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[19]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15780310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3a74fe4e79add9de4803a825b6eae013215dfe7",
            "isKey": false,
            "numCitedBy": 731,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a methodology for evaluation of low-level image analysis methods, using binarization (two-level thresholding) as an example. Binarization of scanned gray scale images is the first step in most document image analysis systems. Selection of an appropriate binarization method for an input image domain is a difficult problem. Typically, a human expert evaluates the binarized images according to his/her visual criteria. However, to conduct an objective evaluation, one needs to investigate how well the subsequent image analysis steps will perform on the binarized image. We call this approach goal-directed evaluation, and it can be used to evaluate other low-level image processing methods as well. Our evaluation of binarization methods is in the context of digit recognition, so we define the performance of the character recognition module as the objective measure. Eleven different locally adaptive binarization methods were evaluated, and Niblack's method gave the best performance."
            },
            "slug": "Goal-Directed-Evaluation-of-Binarization-Methods-Trier-Jain",
            "title": {
                "fragments": [],
                "text": "Goal-Directed Evaluation of Binarization Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a methodology for evaluation of low-level image analysis methods, using binarization (two-level thresholding) as an example, and defines the performance of the character recognition module as the objective measure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49420283"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2510056"
                        ],
                        "name": "Richard Feinrich",
                        "slug": "Richard-Feinrich",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Feinrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Feinrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[4] propose a method for document image binarization focused on noisy and complex background problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45509488,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "e6704d8bf1ebe544b6a03099eb1bf8ff54f72f85",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image binarization is not a completely solved problem for unconstrained document images. Binarization algorithms, whether global or local, can easily fail on images with noisy or complex background, or poor contrast. The authors report preliminary results on a new approach to document image binarization, an algorithm based on gray scale histogram and run-length histogram analysis. Experimental results on unconstrained machine printed address blocks from the US letter mail stream show that over 99% of such address blocks can be correctly binarized.<<ETX>>"
            },
            "slug": "An-object-attribute-thresholding-algorithm-for-Liu-Feinrich",
            "title": {
                "fragments": [],
                "text": "An object attribute thresholding algorithm for document image binarization"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Preliminary results on a new approach to document image binarization, an algorithm based on gray scale histogram and run-length histogram analysis, show that over 99% of such address blocks can be correctly binarized."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1929009"
                        ],
                        "name": "Moon-Soo Chang",
                        "slug": "Moon-Soo-Chang",
                        "structuredName": {
                            "firstName": "Moon-Soo",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Moon-Soo Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303924"
                        ],
                        "name": "S. Kang",
                        "slug": "S.-Kang",
                        "structuredName": {
                            "firstName": "Sun-Mee",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282803"
                        ],
                        "name": "Woo-Sik Rho",
                        "slug": "Woo-Sik-Rho",
                        "structuredName": {
                            "firstName": "Woo-Sik",
                            "lastName": "Rho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Woo-Sik Rho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2898378"
                        ],
                        "name": "Heok-Gu Kim",
                        "slug": "Heok-Gu-Kim",
                        "structuredName": {
                            "firstName": "Heok-Gu",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heok-Gu Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111427671"
                        ],
                        "name": "Duck-Jin Kim",
                        "slug": "Duck-Jin-Kim",
                        "structuredName": {
                            "firstName": "Duck-Jin",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duck-Jin Kim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 6 ]. They propose an algorithm that uses two di!erent components: the background noise elimination using grey-level histogram equalization and enhancement of grey-levels of characters in the neighbourhood using an edge image composition technique."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43868201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee0d949f98397ab8bd696a6949f8e8150cf821bf",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A binarization method is presented to counter the stroke connectivity problems of characters arising from mid-level-quality binary image scanning systems. In the output of a binary image scanning system, separate strokes may look connected if the point size is small and the character strokes are complex while strokes may lose connectivity if they are generated at low intensity. Also, erroneous recognition may result if a blemished document surface distorts the image. To counter these problems and to further enhance the quality of character recognition, the authors have developed an integrated binarization scheme, exploiting synergistic use of an adaptive thresholding technique and variable histogram equalization. This algorithm is composed of two components. The first removes background noise via gray level histogram equalization while the second enhances the gray level of characters over and above the surrounding background via an edge image composition technique."
            },
            "slug": "Improved-binarization-algorithm-for-document-image-Chang-Kang",
            "title": {
                "fragments": [],
                "text": "Improved binarization algorithm for document image by histogram and edge detection"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An integrated binarization scheme is developed, exploiting synergistic use of an adaptive thresholding technique and variable histogram equalization to counter the stroke connectivity problems of characters arising from mid-level-quality binary image scanning systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "O'Gorman [3] proposes a global approach calculated from a measure of local connectivity information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44674932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2a5b702aec0aa01946f02d190bf9418000559bd",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Thresholding is a common image processing operation applied to gray-scale images to obtain binary or multilevel images. Traditionally, one of two approaches is used: global or locally adaptive processing. However, each of these approaches has a disadvantage: the global approach neglects local information, and the locally adaptive approach neglects global information. A thresholding method is described here that is global in approach, but uses a measure of local information, namely connectivity. Thresholds are found at the intensity levels that best preserve the connectivity of regions within the image. Thus, this method has advantages of both global and locally adaptive approaches. This method is applied here to document images. Experimental comparisons against other thresholding methods show that the connectivity-preserving method yields much improved results. On binary images, this method has been shown to improve subsequent OCR recognition rates from about 95% to 97,5%. More importantly, the new method has been shown to reduce the number of binarization failures (where text is so poorly binarized as to be totally unrecognizable by a commercial OCR system) from 33% to 6% on difficult images. For multilevel document images, as well, the results show similar improvement."
            },
            "slug": "Binarization-and-Multithresholding-of-Document-O'Gorman",
            "title": {
                "fragments": [],
                "text": "Binarization and Multithresholding of Document Images Using Connectivity"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This method has been shown to reduce the number of binarization failures from 33% to 6% on difficult images and to improve subsequent OCR recognition rates from about 95% to 97,5% on binary images."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704694"
                        ],
                        "name": "J. Sauvola",
                        "slug": "J.-Sauvola",
                        "structuredName": {
                            "firstName": "Jaakko",
                            "lastName": "Sauvola",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sauvola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141938"
                        ],
                        "name": "S. Haapakoski",
                        "slug": "S.-Haapakoski",
                        "structuredName": {
                            "firstName": "Sami",
                            "lastName": "Haapakoski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haapakoski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2304070"
                        ],
                        "name": "H. Kauniskangas",
                        "slug": "H.-Kauniskangas",
                        "structuredName": {
                            "firstName": "Hannu",
                            "lastName": "Kauniskangas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kauniskangas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48819369"
                        ],
                        "name": "T. Sepp\u00e4nen",
                        "slug": "T.-Sepp\u00e4nen",
                        "structuredName": {
                            "firstName": "Tapio",
                            "lastName": "Sepp\u00e4nen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sepp\u00e4nen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "article, letter, memo, fax, journal, scienti\"c, map, advertisement, etc.) [ 23 ]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 21052844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d7ea26dff82e88f90e02c964c8930a94d8eaf5d",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach to manage the testing of document analysis and understanding applications. We propose and present a collection of document images, a set of techniques to prepare the test cases interactively and means to control the testing process. The systems architecture is designed to be distributed, scalable and platform independent utilizing Java, C++ and object-oriented databases. The main features of this system are a basic document categorization and ground truth, degradation models, custom test case creation facilities, a test management module (pipelining, test history), the ability to embed document analysis algorithms into the system, remote usage facilities and robust graphical user interfaces."
            },
            "slug": "A-distributed-management-system-for-testing-image-Sauvola-Haapakoski",
            "title": {
                "fragments": [],
                "text": "A distributed management system for testing document image analysis algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A collection of document images, a set of techniques to prepare the test cases interactively and means to control the testing process to manage the testing of document analysis and understanding applications are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723479"
                        ],
                        "name": "J. Parker",
                        "slug": "J.-Parker",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Parker",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Parker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26920201,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "7c4f9d0b2f878e0b03c6895aaaed94bdb4811651",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The thresholding method involves first locating objects in an image by using the intensity gradient, then noting the levels that correspond to the objects in various areas of the image, and finally using these levels as initial guesses at a threshold. This method is capable of thresholding images that have been produced in the context of variable illumination. The thresholding method, called the local intensity gradient (LIG) method, was implemented in C using a Sun4 host running UNIX. The LIG method was compared against iterative selection (IS), gray level histograms (GLHs) and two correlation based algorithms on a dozen sample images under three different illumination effects. Overall, the LIG method, while it takes significantly longer, properly thresholds a larger set of images than does any other method examined over the sample images tested. >"
            },
            "slug": "Gray-Level-Thresholding-in-Badly-Illuminated-Images-Parker",
            "title": {
                "fragments": [],
                "text": "Gray Level Thresholding in Badly Illuminated Images"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The thresholding method, called the local intensity gradient (LIG) method, was implemented in C using a Sun4 host running UNIX and properly thresholds a larger set of images than does any other method examined over the sample images tested."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Pavlidis [7] presents a technique based on the observation that after blurring a bi-level image, the intensity of original pixels is related with the sign of the curvature of the pixels of the blurred image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41673946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0165f361f40868e9fd50f8c59f57c4e4becfe36",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "It is known that when a bilevel image is blurred, the intensity of the original pixels is related with the sign of the curvature of the pixels of the blurred image. A technique for threshold selection is presented where a partial histogram is constructed solely from the pixels where curvature achieves extrema values. The method is most suitable when low-contrast images with textured backgrounds (but not sparse dot matrices) are a large fraction of the input population.<<ETX>>"
            },
            "slug": "Threshold-selection-using-second-derivatives-of-the-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Threshold selection using second derivatives of the gray scale image"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A technique for threshold selection is presented where a partial histogram is constructed solely from the pixels where curvature achieves extrema values."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852526"
                        ],
                        "name": "V. Shapiro",
                        "slug": "V.-Shapiro",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Shapiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "108468599"
                        ],
                        "name": "P. Veleva",
                        "slug": "P.-Veleva",
                        "structuredName": {
                            "firstName": "Petya",
                            "lastName": "Veleva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Veleva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144088894"
                        ],
                        "name": "V. Sgurev",
                        "slug": "V.-Sgurev",
                        "structuredName": {
                            "firstName": "Vassil",
                            "lastName": "Sgurev",
                            "middleNames": [
                                "Stoyanov"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sgurev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[11] introduce a global thresholding scheme, where the independency is stressed in the object/background areas ratio, intensity transition slope, object/background shape and noise-insensitivity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62292044,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9e0420ba5fca61fbe7c292135ea2c3da20e5564e",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Thresholding is a traditional tool for image regions classification based on their grey-level properties, especially when there are two kinds of homogeneous regions of intensity say, object and background. A new global thresholding scheme is described in this paper. Unlike the previously developed methods the approach proposed is independent of the object/background areas ratio, intensity transition slope and object/background shape; it is also resistant to noise.<<ETX>>"
            },
            "slug": "An-adaptive-method-for-image-thresholding-Shapiro-Veleva",
            "title": {
                "fragments": [],
                "text": "An adaptive method for image thresholding"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new global thresholding scheme is described in this paper, which is independent of the object/ Background areas ratio, intensity transition slope and object/background shape; it is also resistant to noise."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol. III. Conference C: Image, Speech and Signal Analysis,"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2928016"
                        ],
                        "name": "Jeng-Daw Yang",
                        "slug": "Jeng-Daw-Yang",
                        "structuredName": {
                            "firstName": "Jeng-Daw",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeng-Daw Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9407097"
                        ],
                        "name": "Yung-Sheng Chen",
                        "slug": "Yung-Sheng-Chen",
                        "structuredName": {
                            "firstName": "Yung-Sheng",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yung-Sheng Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144887272"
                        ],
                        "name": "W. Hsu",
                        "slug": "W.-Hsu",
                        "structuredName": {
                            "firstName": "Wen-Hsing",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hsu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "'s [5] thresholding algorithm uses a statistical measurement, called &largest static state di!erence'."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35077768,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bd3a3b0887c54ab0ee35b426c80dd9bcf3efff1",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-thresholding-algorithm-and-its-hardware-Yang-Chen",
            "title": {
                "fragments": [],
                "text": "Adaptive thresholding algorithm and its hardware implementation"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723479"
                        ],
                        "name": "J. Parker",
                        "slug": "J.-Parker",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Parker",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Parker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072555931"
                        ],
                        "name": "C. Jennings",
                        "slug": "C.-Jennings",
                        "structuredName": {
                            "firstName": "Cullen",
                            "lastName": "Jennings",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jennings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741332"
                        ],
                        "name": "A. Salkauskas",
                        "slug": "A.-Salkauskas",
                        "structuredName": {
                            "firstName": "Arunas",
                            "lastName": "Salkauskas",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Salkauskas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[10]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 24782898,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "be1dd50c56afdd9c8541fe4a71e2bb38732d63c3",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Most grey-level thresholding methods produce good results in situations where the illumination gradient in the original raster image is regular and not too large. In other cases, such as a large linear change in illumination, a satisfactory bi-level image cannot be produced. If the object pixels can be identified in a variety of positions throughout the image, these can be used to construct a surface whose height is related to illumination at each pixel. This estimate can be used to produce a threshold for each pixel. The method described here uses the Shen-Castan edge detector to identify object pixels, and creates a surface using a moving least squares method that can be used to threshold the image.<<ETX>>"
            },
            "slug": "Thresholding-using-an-illumination-model-Parker-Jennings",
            "title": {
                "fragments": [],
                "text": "Thresholding using an illumination model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The method described here uses the Shen-Castan edge detector to identify object pixels, and creates a surface using a moving least squares method that can be used to threshold the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859170"
                        ],
                        "name": "Arie Pikaz",
                        "slug": "Arie-Pikaz",
                        "structuredName": {
                            "firstName": "Arie",
                            "lastName": "Pikaz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arie Pikaz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703304"
                        ],
                        "name": "A. Averbuch",
                        "slug": "A.-Averbuch",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Averbuch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Averbuch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Pikaz and Averbuch [ 12 ] propose an algorithm to perform thresholding for scenes containing distinct J. Sauvola, M. Pietika( inen / Pattern Recognition 33 (2000) 225}236 227"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2120049,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ca5e143183f41540aac9d184e0db5d2eebedd0e1",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Digital-image-thresholding,-based-on-topological-Pikaz-Averbuch",
            "title": {
                "fragments": [],
                "text": "Digital image thresholding, based on topological stable-state"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108903091"
                        ],
                        "name": "Russell C. Smith",
                        "slug": "Russell-C.-Smith",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Smith",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Russell C. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Rosenfeld and Smith [8] presented a global thresholding algorithm to deal with noise problem using an\niterative probabilistic model when separating background and object pixels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Rosenfeld and Smith [8] presented a global thresholding algorithm to deal with noise problem using an iterative probabilistic model when separating background and object pixels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 208669,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "16677abfe82555659d65c9e6d145e792c48d2508",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "If a picture contains dark objects on a light background (or vice versa), the objects can be extracted by thresholding, i.e., by classifying the pixels into ``light'' and ``dark'' classes. If the picture is noisy, so that the object and background gray level populations overlap, there will be errors in the thresholded output. A relaxation process can be used to reduce these errors; we classify the pixels probabilistically, and then adjust the probabilities for each pixel, based on its neighbors' probabilities, with light reinforcing light and dark dark. When this adjustment process is iterated, the dark probabilities become very high for pixels that belong to dark regions, and vice versa, so that thresholding becomes trivial."
            },
            "slug": "Thresholding-Using-Relaxation-Rosenfeld-Smith",
            "title": {
                "fragments": [],
                "text": "Thresholding Using Relaxation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "If a picture contains dark objects on a light background (or vice versa), the objects can be extracted by thresholding, i.e., by classifying the pixels into ``light'' and ``dark'' classes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "For example, a letter connectivity must be maintained for optical character recognition and textual compression [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61076153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0eb7232dc0ceae32aad26c918a24e2775020d46",
            "isKey": false,
            "numCitedBy": 339,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A lack of explicit quantitative models of imaging defects due to printing, optics, and digitization has retarded progress in some areas of document image analysis, including syntactic and structural approaches. Establishing the essential properties of such models, such as completeness (expressive power) and calibration (closeness of fit to actual image populations) remain open research problems. Work-in-progress towards a parameterized model of local imaging defects is described, together with a variety of motivating theoretical arguments and empirical evidence. A pseudo-random image generator implementing the model has been built. Applications of the generator are described, including a polyfont classifier for ASCII and a single-font classifier for a large alphabet (Tibetan U-Chen), both of which which were constructed with a minimum of manual effort. Image defect models and their associated generators permit a new kind of image database which is explicitly parameterized and indefinitely extensible, alleviating some drawbacks of existing databases."
            },
            "slug": "Document-image-defect-models-Baird",
            "title": {
                "fragments": [],
                "text": "Document image defect models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Work-in-progress towards a parameterized model of local imaging defects is described, together with a variety of motivating theoretical arguments and empirical evidence, and a pseudo-random image generator implementing the model has been built."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29917917"
                        ],
                        "name": "S. Nieminen",
                        "slug": "S.-Nieminen",
                        "structuredName": {
                            "firstName": "Sami",
                            "lastName": "Nieminen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nieminen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704694"
                        ],
                        "name": "J. Sauvola",
                        "slug": "J.-Sauvola",
                        "structuredName": {
                            "firstName": "Jaakko",
                            "lastName": "Sauvola",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sauvola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48819369"
                        ],
                        "name": "T. Sepp\u00e4nen",
                        "slug": "T.-Sepp\u00e4nen",
                        "structuredName": {
                            "firstName": "Tapio",
                            "lastName": "Sepp\u00e4nen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sepp\u00e4nen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20004008,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9f75601250fbadc27f9dcdb8e638350e6d41f59",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "With the increasing interest in document analysis research the number of available OCR, segmentation, noise removal and various other document analysis algorithms has grown considerably. However, algorithms are still purpose- specific, and to obtain optimal results, different algorithms for different situations are usually needed. The problem is to reliably evaluate the performance of an algorithm in a given situation. A framework for a benchmarking system for document analysis algorithms is presented. The system consists of a set of test cases for measuring the performance of different document analysis algorithms. The system is expandable, new algorithm types to be tested can be added by creating new test cases and benchmarking methods. The whole benchmarking process can be automated to allow mass performance testing with numerous algorithms. A set of weights is used to adjust the relative significance of the different aspects of a test case. The results of the benchmarking are expressed as a single value, which presents the performance of the algorithm in a given test case. The result can be easily compared with the results of other algorithms, which enables the ranking of the tested algorithms. Experiments with benchmarking system show promising results. The performance ranking also complies well with subjective human evaluation."
            },
            "slug": "Benchmarking-system-for-document-analysis-Nieminen-Sauvola",
            "title": {
                "fragments": [],
                "text": "Benchmarking system for document analysis algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A framework for a benchmarking system for document analysis algorithms is presented, which consists of a set of test cases for measuring the performance of different documentAnalysis algorithms, and which complies well with subjective human evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109090572"
                        ],
                        "name": "Wen-Tsuen Chen",
                        "slug": "Wen-Tsuen-Chen",
                        "structuredName": {
                            "firstName": "Wen-Tsuen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-Tsuen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068033126"
                        ],
                        "name": "Chia-Hsien Wen",
                        "slug": "Chia-Hsien-Wen",
                        "structuredName": {
                            "firstName": "Chia-Hsien",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chia-Hsien Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146395390"
                        ],
                        "name": "Chin-Wen Yang",
                        "slug": "Chin-Wen-Yang",
                        "structuredName": {
                            "firstName": "Chin-Wen",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Wen Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[14] by Chen et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18700802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c80ee2c7327de9b80adb9e372c2c0d709f1cacbd",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Two-dimensional entropic thresholding is one of the important thresholding techniques for image segmentation. Usually, the global threshold vector is selected from L2 (gray level, local average) pairs through a `maximum' optimization procedure with O(L4) computation complexity. This paper proposes a fast two-phase 2D entropic thresholding algorithm. In order to reduce the computation time, we estimate 9L2/3 candidate threshold vectors from a quantized image of the original in advance. The global threshold vector is then obtained by checking candidates only. The optimal computation complexity is O(L8/3) by quantizing the gray level in L2/3 levels. Experimental results show that the processing time of each image is reduced from more than two hours to about two minutes. The required memory space is also greatly reduced."
            },
            "slug": "Fast-two-dimensional-entropic-thresholding-Chen-Wen",
            "title": {
                "fragments": [],
                "text": "A fast two-dimensional entropic thresholding algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A fast two-phase 2D entropic thresholding algorithm that reduces the processing time of each image from more than two hours to about two minutes and the required memory space is greatly reduced."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110380565"
                        ],
                        "name": "Arnulfo Perez",
                        "slug": "Arnulfo-Perez",
                        "structuredName": {
                            "firstName": "Arnulfo",
                            "lastName": "Perez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnulfo Perez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145061328"
                        ],
                        "name": "R. Gonz\u00e1lez",
                        "slug": "R.-Gonz\u00e1lez",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Gonz\u00e1lez",
                            "middleNames": [
                                "Corsino"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gonz\u00e1lez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "The thresholding algorithm by Perez and Gonzalez [9] was designed to manage situations where imperfect illumination occurs in an image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 227763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5180a52ababc4303a68dabd7d8bf04a6ddc1af69",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A thresholding technique is developed for segmenting digital images with bimodal reflectance distributions under nonuniform illumination. The algorithm works in a raster format, thus making it an attractive segmentation tool in situations requiring fast data throughput. The theoretical base of the algorithm is a recursive Taylor expansion of a continuously varying threshold tracking function."
            },
            "slug": "An-Iterative-Thresholding-Algorithm-for-Image-Perez-Gonz\u00e1lez",
            "title": {
                "fragments": [],
                "text": "An Iterative Thresholding Algorithm for Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A thresholding technique is developed for segmenting digital images with bimodal reflectance distributions under nonuniform illumination in a raster format, thus making it an attractive segmentation tool in situations requiring fast data throughput."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704694"
                        ],
                        "name": "J. Sauvola",
                        "slug": "J.-Sauvola",
                        "structuredName": {
                            "firstName": "Jaakko",
                            "lastName": "Sauvola",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sauvola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Most document analysis algorithms are built on taking advantage of the underlying binarized image data [ 1 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6709739,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe98e6ee18dfa1d37c74736e9e88995a267b9bdf",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Page segmentation and classification are important parts of the document analysis process. The aim is to extract and classify different parts of the page. This paper proposes an approach in which these two phases are combined. The integration process includes fast feature extraction with rule-based classification and label propagation using connectivity analysis providing classified areas in three categories: background, text and picture."
            },
            "slug": "Page-segmentation-and-classification-using-fast-and-Sauvola-Pietik\u00e4inen",
            "title": {
                "fragments": [],
                "text": "Page segmentation and classification using fast feature extraction and connectivity analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes an approach in which fast feature extraction with rule-based classification and label propagation using connectivity analysis providing classified areas in three categories: background, text and picture."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89125003"
                        ],
                        "name": "Andr\u00e9 Marion",
                        "slug": "Andr\u00e9-Marion",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Marion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9 Marion"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "For text binarization we use a modi\"ed version of Niblack's algorithm [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6825818,
            "fieldsOfStudy": [
                "Mathematics",
                "Art"
            ],
            "id": "731cc6cf4f60a6cf6dc96b925940c16b59858a0e",
            "isKey": false,
            "numCitedBy": 334,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 The image as an analogue signal.- 2 Scanning of an image by an aperture.- 3 Extension of the aperture notion.- 4 Photographic images.- 5 Digitizing and reconstructing images.- 6 Basic techniques of digital image processing.- 7 Algebraic operations between images.- 8 Coloured images.- 9 Linear processing of signals and images."
            },
            "slug": "Introduction-to-Image-Processing-Marion",
            "title": {
                "fragments": [],
                "text": "Introduction to Image Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "The image as an analogue signal, scanning of an image by an aperture, and extension of the aperture notion are illustrated."
            },
            "venue": {
                "fragments": [],
                "text": "Springer US"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923100"
                        ],
                        "name": "Peter V. Henstock",
                        "slug": "Peter-V.-Henstock",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Henstock",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter V. Henstock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3217825"
                        ],
                        "name": "D. Chelberg",
                        "slug": "D.-Chelberg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chelberg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Chelberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Henstock and Chelberg [13] propose a statistical model-based threshold selection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6586342,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "28d31992ca0eef92e3d5e57bf92a45820c99dc65",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method to automatically find gradient thresholds to separate edge from nonedge pixels. A statistical model that is the weighted sum of two gamma densities corresponding to edge and nonedge pixels is used to identify a threshold. Results closely match human perceptual thresholds even under low signal-to-noise ratio (SNR) levels."
            },
            "slug": "Automatic-gradient-threshold-determination-for-edge-Henstock-Chelberg",
            "title": {
                "fragments": [],
                "text": "Automatic gradient threshold determination for edge detection"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A statistical model that is the weighted sum of two gamma densities corresponding to edge and nonedge pixels is used to identify a threshold and results closely match human perceptual thresholds even under low signal-to-noise ratio (SNR) levels."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913875"
                        ],
                        "name": "S. Welstead",
                        "slug": "S.-Welstead",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Welstead",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Welstead"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For defuzzi\"cation we use Mamdani\u2019s method [ 17 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43614337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82b313ca48234aec85b4a0027f60eb8b5ee435a4",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nMany books discuss the theory of neural and fuzzy systems, but this is the only one that gives you everything you need to actually design and implement neural and fuzzy programs for real-world scientific, engineering, and financial applications. Each chapter is self-contained and takes the reader through all the steps - from data preparation to the presentation of results - necessary to develop a complete working application, many of which feature interactive graphics. In addition to basics such as backpropagation for feedforward networks, the book also covers a number of advanced methods, including genetic algorithms, simulated annealing, and conjugate gradient methods. A complete, step-by-step guide to developing fuzzy and neural applications; applications for financial forecasting, modeling of chaotic dynamics, pattern classification, and control of unstable systems; provides a wealth of sample code for all applications; critically evaluates how well each application works; and features a guide to creating a complete object-oriented interactive interface framework through which all applications can be run."
            },
            "slug": "Neural-network-and-fuzzy-logic-applications-in-Welstead",
            "title": {
                "fragments": [],
                "text": "Neural network and fuzzy logic applications in C/C++"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A complete, step-by-step guide to developing fuzzy and neural applications; applications for financial forecasting, modeling of chaotic dynamics, pattern classification, and control of unstable systems; provides a wealth of sample code for all applications; critically evaluates how well each application works; and features a guide to creating a complete object-oriented interactive interface framework through which all applications can be run."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley professional computing"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144080449"
                        ],
                        "name": "L. Dorst",
                        "slug": "L.-Dorst",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Dorst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Dorst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 195706206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "425480b863236a657c19f5beddc91151fcd6426a",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-introduction-to-image-processing-Dorst-Smeulders",
            "title": {
                "fragments": [],
                "text": "An introduction to image processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A fast adaptive method for binarization of document images"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Document Analysis and Recognition, ICDAR '91, France"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Pikaz and Averbuch [12] propose an algorithm to perform thresholding for scenes containing distinct\nFig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Pikaz and Averbuch [12] propose an algorithm to perform thresholding for scenes containing distinct J."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Digital image thresholding"
            },
            "venue": {
                "fragments": [],
                "text": "based on topological stable-state, Pattern Recognition 29 (5) "
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic thresholding of grey-level images"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Eighth ICPR"
            },
            "year": 1986
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 24,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Adaptive-document-image-binarization-Sauvola-Pietik\u00e4inen/be97923dbcdaf8b1496b637ed156656d8874f552?sort=total-citations"
}