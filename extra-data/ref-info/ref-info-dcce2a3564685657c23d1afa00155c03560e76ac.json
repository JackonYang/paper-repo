{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13723620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb0419bccc2244ed33c9c42341f342511262daa3",
            "isKey": false,
            "numCitedBy": 2148,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief networks are directed acyclic graphs in which the nodes represent propositions (or variables), the arcs signify direct dependencies between the linked propositions, and the strengths of these dependencies are quantified by conditional probabilities. A network of this sort can be used to represent the generic knowledge of a domain expert, and it turns into a computational architecture if the links are used not merely for storing factual knowledge but also for directing and activating the data flow in the computations which manipulate this knowledge. The first part of the paper deals with the task of fusing and propagating the impacts of new information through the networks in such a way that, when equilibrium is reached, each proposition will be assigned a measure of belief consistent with the axioms of probability theory. It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network. The second part of the paper deals with the problem of finding a tree-structured representation for a collection of probabilistically coupled propositions using auxiliary (dummy) variables, colloquially called \"hidden causes.\" It is shown that if such a tree-structured representation exists, then it is possible to uniquely uncover the topology of the tree by observing pairwise dependencies among the available propositions (i.e., the leaves of the tree). The entire tree structure, including the strengths of all internal relationships, can be reconstructed in time proportional to n log n, where n is the number of leaves."
            },
            "slug": "Fusion,-Propagation,-and-Structuring-in-Belief-Pearl",
            "title": {
                "fragments": [],
                "text": "Fusion, Propagation, and Structuring in Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network."
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5770960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e0daca0acc6ee3baf7573fe2e2b3cc94276e7f4",
            "isKey": false,
            "numCitedBy": 1287,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An influence diagram is a graphical structure for modeling uncertain variables and decisions and explicitly revealing probabilistic dependence and the flow of information. It is an intuitive framework in which to formulate problems as perceived by decision makers and to incorporate the knowledge of experts. At the same time, it is a precise description of information that can be stored and manipulated by a computer. We develop an algorithm that can evaluate any well-formed influence diagram and determine the optimal policy for its decisions. Since the diagram can be analyzed directly, there is no need to construct other representations such as a decision tree. As a result, the analysis can be performed using the decision maker's perspective on the problem. Questions of sensitivity and the value of information are natural and easily posed. Modifications to the model suggested by such analyses can be made directly to the problem formulation, and then evaluated directly."
            },
            "slug": "Evaluating-Influence-Diagrams-Shachter",
            "title": {
                "fragments": [],
                "text": "Evaluating Influence Diagrams"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm is developed that can evaluate any well-formed influence diagram and determine the optimal policy for its decisions and can be performed using the decision maker's perspective on the problem."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144238498"
                        ],
                        "name": "B. N. Larsen",
                        "slug": "B.-N.-Larsen",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Larsen",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. N. Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "74208271"
                        ],
                        "name": "H.-G. Leimer",
                        "slug": "H.-G.-Leimer",
                        "structuredName": {
                            "firstName": "H.-G.",
                            "lastName": "Leimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H.-G. Leimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20450895,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f78884604e3fb89b1fb24d2a9403191dc9e63bd3",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate directed Markov fields over finite graphs without positivity assumptions on the densities involved. A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property. We give a simple proof of the fact that the directed, local Markov property and directed, global Markov property are equivalent and \u2013 in the case of absolute continuity w. r. t. a product measure \u2013 equivalent to the recursive factorization of densities. It is argued that our criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl. It follows that our criterion cannot be sharpened."
            },
            "slug": "Independence-properties-of-directed-markov-fields-Lauritzen-Dawid",
            "title": {
                "fragments": [],
                "text": "Independence properties of directed markov fields"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property and it is argued that this criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl."
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144537223"
                        ],
                        "name": "D. Lindley",
                        "slug": "D.-Lindley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lindley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lindley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 119578120,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "114257a84f4cd7571c965f2504f0e5a70d7bac86",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary. This paper describes how data from a multinomial distribution, and in particular data in the form of a contingency table, may be studied by using a prior distribution of the parameters and expressing the results in the form of a posterior distribution, or some aspects thereof, of the parameters. The analysis used must depend on the prior distribution and the form described here only applies to a certain type of prior knowledge but, for reasons given below, it is believed that this type is of frequent occurrence. The binomial situation is first considered and the results obtained there suggest a general result for the multinomial distribution, which is then established. A few remarks on Bayesian analysis in general enable the result to be applied, first to certain multinomial problems and then, with the aid of another general result, to contingency tables. The method used there has close connections with the Analysis of Variance and these connections are examined, particularly with a view to simplifying the analysis of contingency tables involving three or more factors. 1. Binomial distributions. Although it will appear as a special case of results to be established for the general multinomial situation, it is instructive to begin with the binomial distribution which suggested the generalizations. Let N independent trials with constant probability 0 of success result in n successes and (N - n) failures. The likelihood is"
            },
            "slug": "The-Bayesian-Analysis-of-Contingency-Tables-Lindley",
            "title": {
                "fragments": [],
                "text": "The Bayesian Analysis of Contingency Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "20 (1990) 579-605 0 1990 John Wiley & Sons, Inc."
                    },
                    "intents": []
                }
            ],
            "corpusId": 120364423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a543809956d2831007f78c4687ba306fc940aaf",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "SYNOPTIC ABSTRACTMany reasoning schemes have been proposed for propagating the effects of fragmentary evidence through a knowledge-base characterised by sparse, uncertain relationships. Strict probabilistic methods have often been rejected, but recent statistical research into graphical representation of large joint distributions appears to provide an ideal tool for expert system developers. A review of this work is given with reference to a small example, and some important areas of research suggested."
            },
            "slug": "Probabilistic-reasoning-in-expert-systems-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Recent statistical research into graphical representation of large joint distributions appears to provide an ideal tool for expert system developers in propagating the effects of fragmentary evidence through a knowledge-base characterised by sparse, uncertain relationships."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41744030,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e9c168f6d744174efad3764e03522fe55be5ada",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-Reasoning-in-Predictive-Expert-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Probabilistic Reasoning in Predictive Expert Systems"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093317607"
                        ],
                        "name": "S. Walker",
                        "slug": "S.-Walker",
                        "structuredName": {
                            "firstName": "S",
                            "lastName": "Walker",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7794845"
                        ],
                        "name": "D. B. Duncan",
                        "slug": "D.-B.-Duncan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Duncan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. B. Duncan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31019475,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "64028a98638ce3652f045c90de2640736f8f1c33",
            "isKey": false,
            "numCitedBy": 1613,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A method for estimating the probability of occurrence of an event from dichotomous or polychotomous data is developed, using a recursive approach. The method in the dichotomous case is applied to the data of a 10-year prospective study of coronary disease. Other areas of application are briefly indicated. The purpose of this paper is to develop a method for estimating from dichotomous (quantal) or polychotomous data, the probability of occurrence of an event as a function of a relatively large number of independent variables. A key feature of the method is a recursive approach based on Kalman's work (Kalman, 1960 and unpublished report) in linear dynamic filtering and prediction, derivable also from the work of Swerling (1959), which provides an example of many other possible uses of recursive techniques in nonlinear estimation and in related areas. The problem that motivated the investigation is a central one in the epidemiology of coronary heart disease, and it will be used to fix ideas and illustrate the method. Some indication of the range of applications will be given in the conclusion."
            },
            "slug": "Estimation-of-the-probability-of-an-event-as-a-of-Walker-Duncan",
            "title": {
                "fragments": [],
                "text": "Estimation of the probability of an event as a function of several independent variables."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A recursive approach based on Kalman's work in linear dynamic filtering and prediction is applied, derivable also from the work of Swerling (1959), which provides an example of many other possible uses of recursive techniques in nonlinear estimation and in related areas."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrika"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144410210"
                        ],
                        "name": "Tom Leonard",
                        "slug": "Tom-Leonard",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Leonard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Leonard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121726669,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f4f7885c41444c663baaa520bd28456de6a4be45",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A Bayesian procedure is obtained for the simultaneous estimation of the parameters of m binomial distributions. The method uses logistic transformations for the parameters and an exchangeable prior distribution. Information is combined between the binomial distributions to obtain estimates which, under certain circumstances, will be superior to the usual proportions. This paper is intended as a forerunner to a more general theory for the analysis of nonlinear models."
            },
            "slug": "Bayesian-methods-for-binomial-data-Leonard",
            "title": {
                "fragments": [],
                "text": "Bayesian methods for binomial data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31781461"
                        ],
                        "name": "M. Tanner",
                        "slug": "M.-Tanner",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Tanner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tanner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143725639"
                        ],
                        "name": "W. Wong",
                        "slug": "W.-Wong",
                        "structuredName": {
                            "firstName": "Wing",
                            "lastName": "Wong",
                            "middleNames": [
                                "Hung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122088924,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a44241bf4d932fc09bc683f211360c43f02fd106",
            "isKey": false,
            "numCitedBy": 4041,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The idea of data augmentation arises naturally in missing value problems, as exemplified by the standard ways of filling in missing cells in balanced two-way tables. Thus data augmentation refers to a scheme of augmenting the observed data so as to make it more easy to analyze. This device is used to great advantage by the EM algorithm (Dempster, Laird, and Rubin 1977) in solving maximum likelihood problems. In situations when the likelihood cannot be approximated closely by the normal likelihood, maximum likelihood estimates and the associated standard errors cannot be relied upon to make valid inferential statements. From the Bayesian point of view, one must now calculate the posterior distribution of parameters of interest. If data augmentation can be used in the calculation of the maximum likelihood estimate, then in the same cases one ought to be able to use it in the computation of the posterior distribution. It is the purpose of this article to explain how this can be done. The basic idea ..."
            },
            "slug": "The-calculation-of-posterior-distributions-by-data-Tanner-Wong",
            "title": {
                "fragments": [],
                "text": "The calculation of posterior distributions by data augmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "If data augmentation can be used in the calculation of the maximum likelihood estimate, then in the same cases one ought to be able to use it in the computation of the posterior distribution of parameters of interest."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726406"
                        ],
                        "name": "G. Cooper",
                        "slug": "G.-Cooper",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Cooper",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58075571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "808f6f159094c7eb20d7878a6a8944d463a49de0",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "An expert system is a computer program that is designed to solve problems at a level comparable to that of a human expert in a given domain. Often expert systems require a representation of uncertainty. This paper highlights some of the key developments in the history of representing uncertainty in expert systems. An uncertainty representation called belief networks is then introduced and its use in expert systems is motivated. The paper concludes with a discussion of current directions in belief network research."
            },
            "slug": "Current-research-directions-in-the-development-of-Cooper",
            "title": {
                "fragments": [],
                "text": "Current research directions in the development of expert systems based on belief networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Some of the key developments in the history of representing uncertainty in expert systems are highlighted and an uncertainty representation called belief networks is introduced and its use in Expert systems is motivated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742419"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59699866,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "15cf26b46bb92cafa4f78c13de30c1bc7328ebe5",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A Bayesian approach is made to the problem of using individuals of unconfirmed categories to provide information supplementary to a basic data bank of categorized observations. The exact analysis is briefly presented, followed by suggestions for more practicable approximate procedures, which are applied to examples involving medical and simulated data. The general conclusion is that the discriminatory performance of the data bank can be usefully improved by making use of uncategorized observations."
            },
            "slug": "Updating-a-Diagnostic-System-using-Unconfirmed-Titterington",
            "title": {
                "fragments": [],
                "text": "Updating a Diagnostic System using Unconfirmed Cases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The general conclusion is that the discriminatory performance of the data bank can be usefully improved by making use of uncategorized observations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 156814850,
            "fieldsOfStudy": [],
            "id": "718be63e91c4965b905c99456f0c2651426b7806",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis of Binary Data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125277945,
            "fieldsOfStudy": [],
            "id": "0e3632a3fe53468142e28a400be793513a90c81f",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis of Binary Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414560"
                        ],
                        "name": "E. Thompson",
                        "slug": "E.-Thompson",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414560"
                        ],
                        "name": "E. Thompson",
                        "slug": "E.-Thompson",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 203839767,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "9396c78c9681c4b97c5e9b1d482eb25d382e22cf",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pedigree-Analysis-in-Human-Genetics-Thompson-Thompson",
            "title": {
                "fragments": [],
                "text": "Pedigree Analysis in Human Genetics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3027365"
                        ],
                        "name": "D. Pregibon",
                        "slug": "D.-Pregibon",
                        "structuredName": {
                            "firstName": "Daryl",
                            "lastName": "Pregibon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pregibon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121371059,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "69149ad2bfaeb0977a265a2c943becdea8dd0af4",
            "isKey": false,
            "numCitedBy": 1189,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Logistic-Regression-Diagnostics-Pregibon",
            "title": {
                "fragments": [],
                "text": "Logistic Regression Diagnostics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Scene"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Bayesian analysis of simple mixture models"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian Statistics,"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Sequential-updating-of-conditional-probabilities-on-Spiegelhalter-Lauritzen/dcce2a3564685657c23d1afa00155c03560e76ac?sort=total-citations"
}