{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 86367536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6acd45949c2b167928211c562c8d9c445651f1ef",
            "isKey": false,
            "numCitedBy": 777,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "We review recent developments in applying Bayesian probabilistic and statistical ideas to expert systems. Using a real, moderately complex, medical example we illustrate how qualitative and quantitative knowledge can be represented within a directed graphical model, generally known as a belief network in this context. Exact probabilistic inference on individual cases is possible using a general propagation procedure. When data on a series of cases are available, Bayesian statistical techniques can be used for updating the original subjective quantitative inputs, and we present a sets of diagnostics for identifying conflicts between the data and the prior specification. A model comparison procedure is explored, and a number of links made with mainstream statistical methods. Details are given on the use of Dirichlet prior distributions for learning about parameters and the process of transforming the original graphical model to a junction tree as the basis for efficient computation."
            },
            "slug": "Bayesian-analysis-in-expert-systems-Spiegelhalter-Dawid",
            "title": {
                "fragments": [],
                "text": "Bayesian analysis in expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Using a real, moderately complex, medical example, it is illustrated how qualitative and quantitative knowledge can be represented within a directed graphical model, generally known as a belief network in this context."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120177012"
                        ],
                        "name": "Frank Jensen",
                        "slug": "Frank-Jensen",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Jensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102502008"
                        ],
                        "name": "S. K. Anderson",
                        "slug": "S.-K.-Anderson",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Anderson",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Anderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Jensen (1996) is a very good tutorial introduction, while Castillo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 111
                            }
                        ],
                        "text": "The savings can be large: a reduction in storage space of 93 percent was achieved in one of the Munin networks (Jensen and Andersen 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 211
                            }
                        ],
                        "text": "He suggests a hybrid approach in which first edges having little effect on the joint distribution are removed to yield a new chordal graph and junction tree, and then truncation of small entries as described by Jensen and Andersen (1990) is performed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14851013,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4caab8957a369f4e021dc78bc54e45b1f9b7309e",
            "isKey": true,
            "numCitedBy": 105,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "When expert systems based on causal probabilistic networks (CPNs) reach a certain size and complexity, the \"combinatorial explosion monster\" tends to be present. We propose an approximation scheme that identifies rarely occurring cases and excludes these from being processed as ordinary cases in a CPN-based expert system. Depending on the topology and the probability distributions of the CPN, the numbers (representing probabilities of state combinations) in the underlying numerical representation can become very small. Annihilating these numbers and utilizing the resulting sparseness through data structuring techniques often results in several orders of magnitude of improvement in the consumption of computer resources. Bounds on the errors introduced into a CPN-based expert system through approximations are established. Finally, reports on empirical studies of applying the approximation scheme to a real-world CPN are given."
            },
            "slug": "Approximations-in-Bayesian-Belief-Universe-for-Jensen-Anderson",
            "title": {
                "fragments": [],
                "text": "Approximations in Bayesian Belief Universe for Knowledge Based Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes an approximation scheme that identifies rarely occurring cases and excludes these from being processed as ordinary cases in a CPN-based expert system."
            },
            "venue": {
                "fragments": [],
                "text": "UAI 1990"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14437598,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c403081c41dce4a1dff1a31a468b4e55aadef3d8",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 142,
            "paperAbstract": {
                "fragments": [],
                "text": "I address practical issues concerning the construction of normative expert systems--expert systems that encode knowledge within a decision-theoretic framework. In particular, I examine the similarity network and partition, two extensions to the influence diagram. A similarity network is a tool for building an influence diagram, whereas a partition is a tool for assessing the probabilities associated with an influence diagram. Both representations encode asymmetric forms of conditional independence that are not represented conveniently in an ordinary influence diagram. Similarity networks and partitions exploit these forms of conditional independence to facilitate the construction and assessment of influence diagrams for problems of diagnosis. \nThe representations aided considerably the construction of Pathfinder, a large normative expert system for the diagnosis of lymph-node diseases (the domain contains approximately 60 diseases and 110 disease findings). In an early version of the system, I encoded the knowledge of the expert using an erroneous assumption that all disease findings were conditionally independent, given each disease. When the expert and I attempted to build an influence diagram for the domain to capture the dependencies among the disease findings, we failed. Using a similarity network, however, we were able to construct the influence diagram for the entire domain in approximately 40 hours. Furthermore, using the partition representation, the expert was able to decrease the time required to assess a probability--on average--by almost one order of magnitude. Most important, through a comparison procedure based in decision theory, I found that the improvements in diagnostic accuracy afforded by the more sophisticated model of the domain were well worth the additional effort that we had invested to build the revised version of the system. \nIn this work, I examine in detail the theoretical properties of similarity networks and partitions, and discuss the application of these representations to the construction of Pathfinder. This research suggests strongly that, by identifying specific forms of conditional independence, and by developing representations that exploit these forms of independence for knowledge acquisition, knowledge engineers can construct normative expert systems for domains of larger scope and greater complexity than the domains previously through to be amenable to the decision-theoretic approach."
            },
            "slug": "Probabilistic-similarity-networks-Heckerman",
            "title": {
                "fragments": [],
                "text": "Probabilistic similarity networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This research suggests strongly that, by identifying specific forms of conditional independence, and by developing representations that exploit these forms of independence for knowledge acquisition, knowledge engineers can construct normative expert systems for domains of larger scope and greater complexity than the domains previously through to be amenable to the decision-theoretic approach."
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3467671"
                        ],
                        "name": "R. Curds",
                        "slug": "R.-Curds",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Curds",
                            "middleNames": [
                                "Morgan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Curds"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 302,
                                "start": 215
                            }
                        ],
                        "text": "Another trend is the development of variants of the algorithm that perform slightly different or additional tasks (Jensen 1995), or that work in a somewhat modified way (Bloemeke and Valtorta 1998) or approximately (Kj\u00e6rulff 1993; Jensen et al. 1995; Saul et al. 1996; Curds 1997; Kearns and Saul 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 308,
                                "start": 89
                            }
                        ],
                        "text": "within theoretical statistics include: sufficiency and ancillarity; nuisance parameters (Dawid 1980a); Simpson\u2019s paradox; optional stopping, selection and missing data effects (Dawid 1976; Dawid and Dickey 1977); invariance (Dawid 1985); and model-building (Dawid 1982). An overview is given by Dawid (1998). Graphical representations of probability models have a long history."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Curds (1997) has attacked this problem using computer algebra."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27417466,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6a97595833d7bb08404d5985cc79645c320da180",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Techniques for the construction of probabilistic expert systems comprising both \ndiscrete and continuous random variables are presented. In particular we are \nconcerned with how continuous random variables may be incorporated into an \nexpert system - an area which has previously received relatively little attention. \nWe investigate and extend the numeric techniques of other authors, and develop \ntwo new approaches. The first approach makes use of computer algebra. This \nexact technique enables a probability distribution to be expressed and manipulated \nin terms of its algebraic formula resulting in no loss of information. \nOur second approach is an approximate method based upon cubic spline interpolation. \nWe constrain the probability density function of a continuous variable \nto a finite set of points at which we have both function values and first derivatives. \nThese values may then be held in a potential table and treated in an almost \nidentical fashion to discrete variables. While symbolic techniques are shown to be \nonly appropriate in special cases, cubic spline interpolation, though less accurate, \nis widely applicable. \nWe combine these techniques to form a hybrid methodology in which discrete \nvariables, symbolic continuous variables, and spline interpolated continuous variables \nmay exist not only in the same junction tree, but also in the same universe. \nWe show how propagation algorithms may be constructed for these various cases \nand investigate how the means, variances and probability density functions of the \nmarginal distributions in the system may be generated. It is shown how evidence \nof either a numeric or a symbolic nature may be incorporated into such systems \nand how simulation studies may be performed. The techniques we develop are \nimplemented in the computer language Mathematica and an outline of how this \nmay be accomplished is presented."
            },
            "slug": "Propagation-techniques-in-probabilistic-expert-Curds",
            "title": {
                "fragments": [],
                "text": "Propagation techniques in probabilistic expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Techniques for the construction of probabilistic expert systems comprising both discrete and continuous random variables are presented and evidence of either a numeric or a symbolic nature may be incorporated into such systems and how simulation studies may be performed are shown."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 155
                            }
                        ],
                        "text": "However, it is possible to generate samples directly and efficiently from the joint distribution on the junction tree by propagation, even with evidence E (Dawid 1992a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61247712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9abff70b0acf9c6bb74d85f3141d76bef2039a5",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic expert system provides a graphical representation of a joint probability distribution which can be used to simplify and localize calculations. Jensenet al. (1990) introduced a \u2018flow-propagation\u2019 algorithm for calculating marginal and conditional distributions in such a system. This paper analyses that algorithm in detail, and shows how it can be modified to perform other tasks, including maximization of the joint density and simultaneous \u2018fast retraction\u2019 of evidence entered on several variables."
            },
            "slug": "Applications-of-a-general-propagation-algorithm-for-Dawid",
            "title": {
                "fragments": [],
                "text": "Applications of a general propagation algorithm for probabilistic expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper analyses a \u2018flow-propagation\u2019 algorithm for calculating marginal and conditional distributions in a probabilistic expert system in detail, and shows how it can be modified to perform other tasks, including maximization of the joint density and simultaneous 'fast retraction' of evidence entered on several variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868274"
                        ],
                        "name": "B. Thiesson",
                        "slug": "B.-Thiesson",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Thiesson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Thiesson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2554138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ebc0685ec436f5ea9357f1bc55deac6d0b430b8",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic expert systems based on Bayesian networks (BNs) require initial specification of both a qualitative graphical structure and quantitative assessment of conditional probability tables. This paper considers statistical batch learning of the probability tables on the basis of incomplete data and expert knowledge. The EM algorithm with a generalized conjugate gradient acceleration method has been dedicated to quantification of BNs by maximum posterior likelihood estimation for a super-class of the recursive graphical models. This new class of models allows a great variety of local functional restrictions to be imposed on the statistical model, which hereby extents the control and applicability of the constructed method for quantifying BNs."
            },
            "slug": "Accelerated-Quantification-of-Bayesian-Networks-Thiesson",
            "title": {
                "fragments": [],
                "text": "Accelerated Quantification of Bayesian Networks with Incomplete Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper considers statistical batch learning of the probability tables on the basis of incomplete data and expert knowledge and proposes a new class of models that allows a great variety of local functional restrictions to be imposed on the statistical model."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624867"
                        ],
                        "name": "John Binder",
                        "slug": "John-Binder",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Binder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Binder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40359484"
                        ],
                        "name": "K. Kanazawa",
                        "slug": "K.-Kanazawa",
                        "structuredName": {
                            "firstName": "Keiji",
                            "lastName": "Kanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kanazawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 144
                            }
                        ],
                        "text": "The EM algorithm can be slow to converge, but can be speeded up near the maximum using gradient descent methods, which can be performed locally (Russell et al. 1995; Thiesson 1995, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1773555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06c27c96b5201f6fc57c434856c1865135f4bbb5",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic networks which provide compact descriptions of complex stochastic relationships among several random variables are rapidly becoming the tool of choice for uncertain reasoning in artificial intelligence. We show that networks with fixed structure containing hidden variables can be learned automatically from data using a gradient-descent mechanism similar to that used in neural networks We also extend the method to networks with intensionally represented distributions, including networks with continuous variables and dynamic probabilistic networks Because probabilistic networks provide explicit representations of causal structure human experts can easily contribute pnor knowledge to the training process, thereby significantly improving the learning rate Adaptive probabilistic networks (APNs) may soon compete directly with neural networks as models in computational neuroscience as well as in industrial and financial applications."
            },
            "slug": "Local-Learning-in-Probabilistic-Networks-with-Russell-Binder",
            "title": {
                "fragments": [],
                "text": "Local Learning in Probabilistic Networks with Hidden Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that networks with fixed structure containing hidden variables can be learned automatically from data using a gradient-descent mechanism similar to that used in neural networks, which is extended to networks with intensionally represented distributions."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 78
                            }
                        ],
                        "text": "Other good sources of tutorial material are the special issues of AI Magazine (Charniak 1991; Henrion et al. 1991) and of the Communications of the ACM (Heckerman and Wellman 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8439549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57d47f58ec3674066ebf6e71170dff1b7bdd9b3a",
            "isKey": false,
            "numCitedBy": 943,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "I give an introduction to Bayesian networks for AI researchers with a limited grounding in probability theory. Over the last few years, this method of reasoning using probabilities has become popular within the AI probability and uncertainty community. Indeed, it is probably fair to say that Bayesian networks are to a large segment of the AI-uncertainty community what resolution theorem proving is to the AIlogic community. Nevertheless, despite what seems to be their obvious importance, the ideas and techniques have not spread much beyond the research community responsible for them. This is probably because the ideas and techniques are not that easy to understand. I hope to rectify this situation by making Bayesian networks more accessible to the probabilistically unsophisticated."
            },
            "slug": "Bayesian-Networks-without-Tears-Charniak",
            "title": {
                "fragments": [],
                "text": "Bayesian Networks without Tears"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "An introduction to Bayesian networks for AI researchers with a limited grounding in probability theory is given, to make Bayesian Networks more accessible to the probabilistically unsophisticated."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70219052"
                        ],
                        "name": "Wray L. Buntine",
                        "slug": "Wray-L.-Buntine",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "Buntine",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. Buntine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 57
                            }
                        ],
                        "text": "The \u2018peeling\u2019 algorithm for pedigree analysis derived by Cannings et al. (1978) was shown by Spiegelhalter (1990) to be very similar to the local computation algorithm of Lauritzen and Spiegelhalter (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 57
                            }
                        ],
                        "text": "The \u2018peeling\u2019 algorithm for pedigree analysis derived by Cannings et al. (1978) was shown by Spiegelhalter (1990) to be very similar to the local computation algorithm of Lauritzen and Spiegelhalter (1988). Similarly, much of image analysis is dominated by Markov field models which are defined in terms of local dependencies and can be described graphically (Besag and Green 1993), although simulation methods are generally required for inference."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7434212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09c8db333ffbd1acb2fa78df5ed6efd6a06b415b",
            "isKey": false,
            "numCitedBy": 558,
            "numCiting": 254,
            "paperAbstract": {
                "fragments": [],
                "text": "The literature review presented discusses different methods under the general rubric of learning Bayesian networks from data, and includes some overlapping work on more general probabilistic networks. Connections are drawn between the statistical, neural network, and uncertainty communities, and between the different methodological communities, such as Bayesian, description length, and classical statistics. Basic concepts for learning and Bayesian networks are introduced and methods are then reviewed. Methods are discussed for learning parameters of a probabilistic network, for learning the structure, and for learning hidden variables. The article avoids formal definitions and theorems, as these are plentiful in the literature, and instead illustrates key concepts with simplified examples."
            },
            "slug": "A-Guide-to-the-Literature-on-Learning-Probabilistic-Buntine",
            "title": {
                "fragments": [],
                "text": "A Guide to the Literature on Learning Probabilistic Networks from Data"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The literature review presented discusses different methods under the general rubric of learning Bayesian networks from data, and includes some overlapping work on more general probabilistic networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 668248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3867ca2223bd369fa0c7107b60c1e7b37d3c6a1",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic expert systems based on Bayesian networks require initial specification of both qualitative graphical structure and quantitative conditional probability assessments. As (possibly incomplete) data accumulate on real cases, the parameters of the system may adapt, but it is also essential that the initial specifications be monitored with respect to their predictive performance. A range of monitors based on standardized scoring rules that are designed to detect both qualitative and quantitative departures from the specified model is presented. A simulation study demonstrates the efficacy of these monitors at uncovering such departures. >"
            },
            "slug": "Sequential-Model-Criticism-in-Probabilistic-Expert-Cowell-Dawid",
            "title": {
                "fragments": [],
                "text": "Sequential Model Criticism in Probabilistic Expert Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A range of monitors based on standardized scoring rules that are designed to detect both qualitative and quantitative departures from the specified model is presented and a simulation study demonstrates the efficacy of these monitors at uncovering such departures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750921"
                        ],
                        "name": "M. Ramoni",
                        "slug": "M.-Ramoni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Ramoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ramoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714284"
                        ],
                        "name": "P. Sebastiani",
                        "slug": "P.-Sebastiani",
                        "structuredName": {
                            "firstName": "Paola",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sebastiani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 151304539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2420119b449eb0d188d88f1e41f197a67ae84711",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Robust-Parameter-Learning-in-Bayesian-Networks-with-Ramoni-Sebastiani",
            "title": {
                "fragments": [],
                "text": "Robust Parameter Learning in Bayesian Networks with Missing Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796536"
                        ],
                        "name": "Michael P. Wellman",
                        "slug": "Michael-P.-Wellman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wellman",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael P. Wellman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 43
                            }
                        ],
                        "text": "1991) and of the Communications of the ACM (Heckerman and Wellman 1995)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14495011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "489124f1d28932fb0f93d6b2820dd965a3d3d513",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "This brief tutorial on Bayesian networks serves to introduce readers to some of the concepts, terminology, and notation employed by articles in this special section. In a Bayesian network, a variable takes on values from a collection of mutually exclusive and collective exhaustive states. A variable may be discrete, having a finite or countable number of states, or it may be continuous. Often the choice of states itself presents an interesting modeling question. For example, in a system for troubleshooting a problem with printing, we may choose to model the variable \u201cprint output\u201d with two states\u2014\u201cpresent\u201d and \u201cabsent\u201d\u2014or we may want to model the variable with finer distinctions such as \u201cabsent,\u201d \u201cblurred ,\u201d \u201ccut off,\u201d and \u201cok.\u201d"
            },
            "slug": "Bayesian-networks-Heckerman-Wellman",
            "title": {
                "fragments": [],
                "text": "Bayesian networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This brief tutorial on Bayesian networks serves to introduce readers to some of the concepts, terminology, and notation employed by articles in this special section."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3009522"
                        ],
                        "name": "M. Henrion",
                        "slug": "M.-Henrion",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Henrion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Henrion"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778725"
                        ],
                        "name": "J. Breese",
                        "slug": "J.-Breese",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Breese",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Breese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145479841"
                        ],
                        "name": "E. Horvitz",
                        "slug": "E.-Horvitz",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Horvitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Horvitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 78
                            }
                        ],
                        "text": "Other good sources of tutorial material are the special issues of AI Magazine (Charniak 1991; Henrion et al. 1991) and of the Communications of the ACM (Heckerman and Wellman 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18217939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17fea86726fcf2a185953c3dd8c35945ef58f3b2",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "Decision analysis and knowledge-based expert systems share some common goals. Both technologies are designed to improve human decision making; they attempt to do this by formalizing human expert knowledge so that it is amenable to mechanized reasoning. However, the technologies are based on rather different principles. Decision analysis is the application of the principles of decision theory supplemented with insights from the psychology of judgment. Expert systems, at least as we use this term here, involve the application of various logical and computational techniques of AI to the representation of human knowledge for automated inference. AI and decision theory both emerged from research on systematic methods for problem solving and decision making that first blossomed in the 1940s. They even share a common progenitor, John von Neumann, who was a coauthor with Oscar Morgenstern of the best-known formulation of decision theory as well a key player in the development"
            },
            "slug": "Decision-Analysis-and-Expert-Systems-Henrion-Breese",
            "title": {
                "fragments": [],
                "text": "Decision Analysis and Expert Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "AI and decision theory both emerged from research on systematic methods for problem solving and decision making that first blossomed in the 1940s and share a common progenitor, John von Neumann."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069377948"
                        ],
                        "name": "Lars Rude Andersen",
                        "slug": "Lars-Rude-Andersen",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Rude"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lars Rude Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102539472"
                        ],
                        "name": "Jens Herman Krebs",
                        "slug": "Jens-Herman-Krebs",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Krebs",
                            "middleNames": [
                                "Herman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Herman Krebs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074151064"
                        ],
                        "name": "J. D. Andersen",
                        "slug": "J.-D.-Andersen",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Damgaard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Andersen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 760,
                                "start": 101
                            }
                        ],
                        "text": "Such statistical models include loglinear models for discrete data (Edwards and Havr\u00e1nek 1985, 1987; Andersen et al. 1991), multivariate normal models for continuous data (Wermuth 1976; Whittaker 1990), and mixed continuous and discrete models (Lauritzen and Wermuth 1989; Edwards 1990, 1995; Lauritzen 1996). The statistical literature has largely used selection strategies based on maximized likelihood to construct on directed graphical models from data. For a marginal likelihood approach, we further need to specify suitable priors for the parameters of our undirected models. In the case of decomposable graphical models, priors having the hyper Markov property of Dawid and Lauritzen (1993) (see Section 9.9) are particularly convenient. Giudici (1996) has applied and extended these ideas to structural learning of undirected Gaussian models, using priors related to the inverse Wishart distribution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 698,
                                "start": 101
                            }
                        ],
                        "text": "Such statistical models include loglinear models for discrete data (Edwards and Havr\u00e1nek 1985, 1987; Andersen et al. 1991), multivariate normal models for continuous data (Wermuth 1976; Whittaker 1990), and mixed continuous and discrete models (Lauritzen and Wermuth 1989; Edwards 1990, 1995; Lauritzen 1996). The statistical literature has largely used selection strategies based on maximized likelihood to construct on directed graphical models from data. For a marginal likelihood approach, we further need to specify suitable priors for the parameters of our undirected models. In the case of decomposable graphical models, priors having the hyper Markov property of Dawid and Lauritzen (1993) (see Section 9."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 67
                            }
                        ],
                        "text": "Such statistical models include loglinear models for discrete data (Edwards and Havr\u00e1nek 1985, 1987; Andersen et al. 1991), multivariate normal models for continuous data (Wermuth 1976; Whittaker 1990), and mixed continuous and discrete models (Lauritzen and Wermuth 1989; Edwards 1990, 1995; Lauritzen 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 119483019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0439a9bf44b3015feea573a4ab68d5c921af5fd",
            "isKey": true,
            "numCitedBy": 32,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Causal probabilistic models have been suggested for representing diagnostic knowledge in expert systems. This paper describes the theoretical basis for and the implementation of an expert system based on causal probabilistic networks. The system includes model search for building the knowledge base, a shell for making the knowledge base available for users in consultation sessions, and a user interface. The system contains facilities for storing knowledge and propagating new knowledge, and mechanisms for building the knowledge base by semi-automated analysis of a large sparse contingency table. The contingency table contains data acquired for patients in the same diagnostic category as the intended application area of the expert system. The knowledge base of the expert system is created by combining expert knowledge and a statistical model search in a model conversion scheme based on a theory developed by Lauritzen & Spiegelhalter and using exact tests as suggested by Kreiner. The system is implemented on..."
            },
            "slug": "STENO:an-expert-system-for-medical-diagnosis-based-Andersen-Krebs",
            "title": {
                "fragments": [],
                "text": "STENO:an expert system for medical diagnosis based on graphical models and model search"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The theoretical basis for and the implementation of an expert system based on causal probabilistic networks is described, which contains facilities for storing knowledge and propagating new knowledge, and mechanisms for building the knowledge base by semi-automated analysis of a large sparse contingency table."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 66
                            }
                        ],
                        "text": "Neural networks have been reconstructed as probabilistic networks (Neal 1996; Frey 1998), which again produce shallow but densely connected graphs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 87
                            }
                        ],
                        "text": "For this broader perspective, see, for example, Lauritzen (1996), Gilks et al. (1996), Neal (1996), Frey (1998), and Jordan (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60809283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db869fa192a3222ae4f2d766674a378e47013b1b",
            "isKey": false,
            "numCitedBy": 3642,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "Artificial \"neural networks\" are widely used as flexible models for classification and regression applications, but questions remain about how the power of these models can be safely exploited when training data is limited. This book demonstrates how Bayesian methods allow complex neural network models to be used without fear of the \"overfitting\" that can occur with traditional training methods. Insight into the nature of these complex Bayesian models is provided by a theoretical investigation of the priors over functions that underlie them. A practical implementation of Bayesian neural network learning using Markov chain Monte Carlo methods is also described, and software for it is freely available over the Internet. Presupposing only basic knowledge of probability and statistics, this book should be of interest to researchers in statistics, engineering, and artificial intelligence."
            },
            "slug": "Bayesian-Learning-for-Neural-Networks-Neal",
            "title": {
                "fragments": [],
                "text": "Bayesian Learning for Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Bayesian Learning for Neural Networks shows that Bayesian methods allow complex neural network models to be used without fear of the \"overfitting\" that can occur with traditional neural network learning methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13723620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb0419bccc2244ed33c9c42341f342511262daa3",
            "isKey": false,
            "numCitedBy": 2148,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief networks are directed acyclic graphs in which the nodes represent propositions (or variables), the arcs signify direct dependencies between the linked propositions, and the strengths of these dependencies are quantified by conditional probabilities. A network of this sort can be used to represent the generic knowledge of a domain expert, and it turns into a computational architecture if the links are used not merely for storing factual knowledge but also for directing and activating the data flow in the computations which manipulate this knowledge. The first part of the paper deals with the task of fusing and propagating the impacts of new information through the networks in such a way that, when equilibrium is reached, each proposition will be assigned a measure of belief consistent with the axioms of probability theory. It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network. The second part of the paper deals with the problem of finding a tree-structured representation for a collection of probabilistically coupled propositions using auxiliary (dummy) variables, colloquially called \"hidden causes.\" It is shown that if such a tree-structured representation exists, then it is possible to uniquely uncover the topology of the tree by observing pairwise dependencies among the available propositions (i.e., the leaves of the tree). The entire tree structure, including the strengths of all internal relationships, can be reconstructed in time proportional to n log n, where n is the number of leaves."
            },
            "slug": "Fusion,-Propagation,-and-Structuring-in-Belief-Pearl",
            "title": {
                "fragments": [],
                "text": "Fusion, Propagation, and Structuring in Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network."
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868274"
                        ],
                        "name": "B. Thiesson",
                        "slug": "B.-Thiesson",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Thiesson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Thiesson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 169
                            }
                        ],
                        "text": "The process can be speeded up by using gradient-descent search near the maximum, a process of the same order of complexity as calculating the E-step of the EM algorithm (Thiesson 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15204319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9153cec71cc567f9258bfa1f5b327b09924dfdde",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Recursive graphical models usually underlie the statistical modelling concerning probabilistic expert systems based on Bayesian networks. This paper defines a version of these models, denoted as recursive exponential models, which have evolved by the desire to impose sophisticated domain knowledge onto local fragments of a model. Besides the structural knowledge, as specified by a given model, the statistical modelling may also include expert opinion about the values of parameters in the model. It is shown how to translate imprecise expert knowledge into approximately conjugate prior distributions. Based on possibly incomplete data, the score and the observed information are derived for these models. This accounts for both the traditional score and observed information, derived as derivatives of the log-likelihood, and the posterior score and observed information, derived as derivatives of the log-posterior distribution. Throughout the paper the specialization into recursive graphical models is accounted for by a simple example."
            },
            "slug": "Score-and-Information-for-Recursive-Exponential-Thiesson",
            "title": {
                "fragments": [],
                "text": "Score and Information for Recursive Exponential Models with Incomplete Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown how to translate imprecise expert knowledge into approximately conjugate prior distributions for recursive exponential models, which have evolved by the desire to impose sophisticated domain knowledge onto local fragments of a model."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143818472"
                        ],
                        "name": "E. Castillo",
                        "slug": "E.-Castillo",
                        "structuredName": {
                            "firstName": "Enrique",
                            "lastName": "Castillo",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Castillo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144614855"
                        ],
                        "name": "J. Guti\u00e9rrez",
                        "slug": "J.-Guti\u00e9rrez",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Guti\u00e9rrez",
                            "middleNames": [
                                "Manuel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Guti\u00e9rrez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145353422"
                        ],
                        "name": "A. Hadi",
                        "slug": "A.-Hadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Hadi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hadi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 58
                            }
                        ],
                        "text": "Jensen (1996) is a very good tutorial introduction, while Castillo et al. (1997) provides another sound introduction with many worked examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41024324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "837ae38d8eba5635fb8a2e0a5cdb4764e8ea348a",
            "isKey": false,
            "numCitedBy": 763,
            "numCiting": 226,
            "paperAbstract": {
                "fragments": [],
                "text": "Artificial intelligence and expert systems have seen a great deal of research in recent years, much of which has been devoted to methods for incorporating uncertainty into models. This book is devoted to providing a thorough and up-to-date survey of this field for researchers and students."
            },
            "slug": "Expert-Systems-and-Probabilistic-Network-Models-Castillo-Guti\u00e9rrez",
            "title": {
                "fragments": [],
                "text": "Expert Systems and Probabilistic Network Models"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This book is devoted to providing a thorough and up-to-date survey of this field for researchers and students."
            },
            "venue": {
                "fragments": [],
                "text": "Monographs in Computer Science"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145306532"
                        ],
                        "name": "S. Normand",
                        "slug": "S.-Normand",
                        "structuredName": {
                            "firstName": "Sharon-Lise",
                            "lastName": "Normand",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Normand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144386114"
                        ],
                        "name": "D. Tritchler",
                        "slug": "D.-Tritchler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tritchler",
                            "middleNames": [
                                "L"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tritchler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 115
                            }
                        ],
                        "text": "They are one of the oldest graphical approaches in decision analysis; for a thorough development of the theory see Raiffa and Schlaifer (1961) and Raiffa (1968). They are fine for small problems, but for larger problems they can become unwieldy, because they explicitly display all possible scenarios."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 62
                            }
                        ],
                        "text": "Textbooks on probabilistic expert systems include the classic Pearl (1988). Neapolitan (1990) explains the basic propagation algorithms, and these are studied in detail by Shafer (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 115
                            }
                        ],
                        "text": "They are one of the oldest graphical approaches in decision analysis; for a thorough development of the theory see Raiffa and Schlaifer (1961) and Raiffa (1968)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120347135,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f3d51ecb65ff67fdccbe368f0a90fca697fd6895",
            "isKey": true,
            "numCitedBy": 39,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A Bayes network is a directed acyclic graph in which the links are quantified by fixed conditional probabilities and the nodes represent random variables. The primary use of the network is to provide an efficient method for updating conditional probabilities in the graph. We consider the consequences of using the network as the computational device for updating parameter estimates in the dynamic linear model, a discrete time Bayesian model. We show that using the network characterizes the dynamic linear model and its computations in a unified way. The generality of the network permits nonsequential data collection and thereby provides a straightforward method of incorporating delayed data. An on-line diagnostic is offered to complement the conventional forecast error and an approximation to the posterior distribution is proposed. Algorithms for data propagation in multivariate Gaussian causal trees are presented."
            },
            "slug": "Parameter-Updating-in-a-Bayes-Network-Normand-Tritchler",
            "title": {
                "fragments": [],
                "text": "Parameter Updating in a Bayes Network"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that using the network characterizes the dynamic linear model and its computations in a unified way and permits nonsequential data collection and thereby provides a straightforward method of incorporating delayed data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 68
                            }
                        ],
                        "text": "Decision trees have their origin in game theory as developed by von Neumann and Morgenstern (1944). They are one of the oldest graphical approaches in decision analysis; for a thorough development of the theory see Raiffa and Schlaifer (1961) and Raiffa (1968)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 31
                            }
                        ],
                        "text": "A major simplifying assumption (Spiegelhalter and Lauritzen 1990) is that of global independence: the parameters (\u03b8 : v \u2208 V ) are taken to be a priori probabilistically independent, so that the joint prior density factorizes as"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 145
                            }
                        ],
                        "text": "A further simplification is obtained if the model exhibits local meta independence, and in the prior we are willing to assume local independence (Spiegelhalter and Lauritzen 1990), meaning that all local parameters (\u03b8) in the network are mutually probabilistically independent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10739577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcce2a3564685657c23d1afa00155c03560e76ac",
            "isKey": false,
            "numCitedBy": 615,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A directed acyclic graph or influence diagram is frequently used as a representation for qualitative knowledge in some domains in which expert system techniques have been applied, and conditional probability tables on appropriate sets of variables form the quantitative part of the accumulated experience. It is shown how one can introduce imprecision into such probabilities as a data base of cases accumulates. By exploiting the graphical structure, the updating can be performed locally, either approximately or exactly, and the setup makes it possible to take advantage of a range of well-established statistical techniques. As examples we discuss discrete models, models based on Dirichlet distributions and models of the logistic regression type."
            },
            "slug": "Sequential-updating-of-conditional-probabilities-on-Spiegelhalter-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Sequential updating of conditional probabilities on directed graphical structures"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is shown how one can introduce imprecision into such probabilities as a data base of cases accumulates and how to take advantage of a range of well-established statistical techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724065"
                        ],
                        "name": "D. M. Chickering",
                        "slug": "D.-M.-Chickering",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chickering",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Chickering"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 99
                            }
                        ],
                        "text": "One can impose some structure on this table in order to reduce the overall complexity of the model (Buntine 1994; Chickering et al. 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1621481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f7e689a465ac321ce607427d86dd17163c12bc4",
            "isKey": false,
            "numCitedBy": 386,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently several researchers have investigated techniques for using data to learn Bayesian networks containing compact representations for the conditional probability distributions (CPDs) stored at each node. The majority of this work has concentrated on using decision-tree representations for the CPDs. In addition, researchers typically apply non-Bayesian (or asymptotically Bayesian) scoring functions such as MDL to evaluate the goodness-of-fit of networks to the data. \n \nIn this paper we investigate a Bayesian approach to learning Bayesian networks that contain the more general decision-graph representations of the CPDs. First, we describe how to evaluate the posterior probability-- that is, the Bayesian score--of such a network, given a database of observed cases. Second, we describe various search spaces that can be used, in conjunction with a scoring function and a search procedure, to identify one or more high-scoring networks. Finally, we present an experimentd evaluation of the search spaces, using a greedy algorithm and a Bayesian scoring function."
            },
            "slug": "A-Bayesian-Approach-to-Learning-Bayesian-Networks-Chickering-Heckerman",
            "title": {
                "fragments": [],
                "text": "A Bayesian Approach to Learning Bayesian Networks with Local Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A Bayesian approach to learning Bayesian networks that contain the more general decision-graph representations of the CPDs is investigated, and how to evaluate the posterior probability-- that is, the Bayesian score--of such a network, given a database of observed cases is described."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8399344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c0d8c0e4c5895a358009a32ad58a4319f9e22e8",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the benefits of belief networks and influence diagrams is that so much knowledge is captured in the graphical structure. In particular, statements of conditional irrelevance (or independence) can be verified in time linear in the size of the graph. To resolve a particular inference query or decision problem, only some of the possible states and probability distributions must be specified, the \"requisite information.\" \n \nThis paper presents a new, simple, and efficient \"Bayes-ball\" algorithm which is wellsuited to both new students of belief networks and state of the art implementations. The Bayes-ball algorithm determines irrelevant sets and requisite information more efficiently than existing methods, and is linear in the size of the graph for belief networks and influence diagrams."
            },
            "slug": "Bayes-Ball:-The-Rational-Pastime-(for-Determining-Shachter",
            "title": {
                "fragments": [],
                "text": "Bayes-Ball: The Rational Pastime (for Determining Irrelevance and Requisite Information in Belief Networks and Influence Diagrams)"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new, simple, and efficient \"Bayes-ball\" algorithm is presented which determines irrelevant sets and requisite information more efficiently than existing methods, and is linear in the size of the graph for belief networks and influence diagrams."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709111"
                        ],
                        "name": "E. Shortliffe",
                        "slug": "E.-Shortliffe",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Shortliffe",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Shortliffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740513"
                        ],
                        "name": "B. Buchanan",
                        "slug": "B.-Buchanan",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Buchanan",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Buchanan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 174
                            }
                        ],
                        "text": "\u2026IF influenza THEN sneezing (certainty 0.9)\n\u2022 IF influenza THEN weakness (certainty 0.6)\nAn early example of a backward chaining system with certainty factors is theMycin program (Shortliffe and Buchanan 1975), designed to assist doctors in prescribing treatment for bacteriological blood disorders."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 90
                            }
                        ],
                        "text": "An early example of a backward chaining system with certainty factors is theMycin program (Shortliffe and Buchanan 1975), designed to assist doctors in prescribing treatment for bacteriological blood disorders."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118063112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad9ac8938d230ef41cf2aa6a795743c8b1520200",
            "isKey": true,
            "numCitedBy": 1375,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-model-of-inexact-reasoning-in-medicine-Shortliffe-Buchanan",
            "title": {
                "fragments": [],
                "text": "A model of inexact reasoning in medicine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783037"
                        ],
                        "name": "M. Peot",
                        "slug": "M.-Peot",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Peot",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Peot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2886011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6049c0a410322aa74f362c0b749e812b7b556a78",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Simulation-Approaches-to-General-Probabilistic-on-Shachter-Peot",
            "title": {
                "fragments": [],
                "text": "Simulation Approaches to General Probabilistic Inference on Belief Networks"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144880939"
                        ],
                        "name": "A. Madsen",
                        "slug": "A.-Madsen",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Madsen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Madsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 185
                            }
                        ],
                        "text": "Current research concerning propagation in discrete probabilistic networks is concerned with studying and improving the efficiency of one or more variants of the propagation algorithms (Kj\u00e6rulff 1998; Shenoy 1997; Madsen and Jensen 1998), or exploiting cutset conditioning to trade time for space (Shachter et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6757049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3236a4df536647ad82f9d8dc1665abab49ba481",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The efficiency of algorithms using secondary structures for probabilistic inference in Bayesian networks can be improved by exploiting independence relations induced by evidence and the direction of the links in the original network. In this paper we present an algorithm that on-line exploits independence relations induced by evidence and the direction of the links in the original network to reduce both time and space costs. Instead of multiplying the conditional probability distributions for the various cliques, we determine on-line which potentials to multiply when a message is to be produced. The performance improvement of the algorithm is emphasized through empirical evaluations involving large real world Bayesian networks, and we compare the method with the HUGIN and Shafer-Shenoy inference algorithms."
            },
            "slug": "Lazy-Propagation-in-Junction-Trees-Madsen-Jensen",
            "title": {
                "fragments": [],
                "text": "Lazy Propagation in Junction Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm that on-line exploits independence relations induced by evidence and the direction of the links in the original network to reduce both time and space costs is presented."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057429665"
                        ],
                        "name": "Stefano Monti",
                        "slug": "Stefano-Monti",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Monti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Monti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726406"
                        ],
                        "name": "G. Cooper",
                        "slug": "G.-Cooper",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Cooper",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 126
                            }
                        ],
                        "text": "Suggestions have included structuring the tables as classification trees (Friedman and Goldszmidt 1998) or as neural networks (Monti and Cooper 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8396622,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e572606cfbc2fb70882674f6294f43af463ffccb",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a method for learning Bayesian belief networks from data. The method uses artificial neural networks as probability estimators, thus avoiding the need for making prior assumptions on the nature of the probability distributions governing the relationships among the participating variables. This new method has the potential for being applied to domains containing both discrete and continuous variables arbitrarily distributed. We compare the learning performance of this new method with the performance of the method proposed by Cooper and Herskovits in [7]. The experimental results show that, although the learning scheme based on the use of ANN estimators is slower, the learning accuracy of the two methods is comparable."
            },
            "slug": "Learning-Bayesian-Belief-Networks-with-Neural-Monti-Cooper",
            "title": {
                "fragments": [],
                "text": "Learning Bayesian Belief Networks with Neural Network Estimators"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This paper proposes a method for learning Bayesian belief networks from data that uses artificial neural networks as probability estimators, thus avoiding the need for making prior assumptions on the nature of the probabilities governing the relationships among the participating variables."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1852530"
                        ],
                        "name": "C. Robert Kenley",
                        "slug": "C.-Robert-Kenley",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Kenley",
                            "middleNames": [
                                "Robert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Robert Kenley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119913293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5e1c09bad43cd9bffa3f88dbc99b668a6694385",
            "isKey": false,
            "numCitedBy": 310,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "An influence diagram is a network representation of probabilistic inference and decision analysis models. The nodes correspond to variables that can be either constants, uncertain quantities, decisions, or objectives. The arcs reveal probabilistic dependence of the uncertain quantities and information available at the time of the decisions. The influence diagram focuses attention on relationships among the variables. As a result, it is increasingly popular for eliciting and communicating the structure of a decision or probabilistic model. \n \nThis paper develops the framework for assessment and analysis of linear-quadratic-Gaussian models within the influence diagram representation. The \"Gaussian influence diagram\" exploits conditional independence in a model to simplify elicitation of parameters for the multivariate normal distribution. It is straightforward to assess and maintain a positive semi-definite covariance matrix. Problems of inference and decision making can be analyzed using simple transformations to the assessed model, and these procedures have attractive numerical properties. Algorithms are also provided to translate between the Gaussian influence diagram and covariance matrix representations for the normal distribution."
            },
            "slug": "Gaussian-influence-diagrams-Shachter-Kenley",
            "title": {
                "fragments": [],
                "text": "Gaussian influence diagrams"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper develops the framework for assessment and analysis of linear-quadratic-Gaussian models within the influence diagram representation, and provides algorithms to translate between the Gaussian influence diagram and covariance matrix representations for the normal distribution."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 22
                            }
                        ],
                        "text": "Estimates, taken from Spiegelhalter et al. (1993) for the Child example, of conditional probabilities obtained from batch learning (using direct posterior mode and approximate posterior mean) and sequential learning (using a moment-matching approximation)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Spiegelhalter et al. (1994) describe standardization of parent-child monitors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 98
                            }
                        ],
                        "text": "using data on 168 cases which became available subsequent to the construction of the network (see Spiegelhalter et al. (1993) for additional discussion of this dataset)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 165
                            }
                        ],
                        "text": "3 shows some results using both batch and sequential learning procedure for direct posterior modes and approximate posterior means for the Child example reported in Spiegelhalter et al. (1993). Sequential learning is treated in detail in Section 9."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Spiegelhalter et al. (1993) proposed a method of expansion and contraction, somewhat analogous to (11."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 120364423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a543809956d2831007f78c4687ba306fc940aaf",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "SYNOPTIC ABSTRACTMany reasoning schemes have been proposed for propagating the effects of fragmentary evidence through a knowledge-base characterised by sparse, uncertain relationships. Strict probabilistic methods have often been rejected, but recent statistical research into graphical representation of large joint distributions appears to provide an ideal tool for expert system developers. A review of this work is given with reference to a small example, and some important areas of research suggested."
            },
            "slug": "Probabilistic-reasoning-in-expert-systems-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Recent statistical research into graphical representation of large joint distributions appears to provide an ideal tool for expert system developers in propagating the effects of fragmentary evidence through a knowledge-base characterised by sparse, uncertain relationships."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 63
                            }
                        ],
                        "text": "One implementation of this idea is the structural EM algorithm (Friedman 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 447055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41e0bb90262160c26d8c9ec216716d57122c8672",
            "isKey": false,
            "numCitedBy": 688,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years there has been a flurry of works on learning Bayesian networks from data. One of the hard problems in this area is how to effectively learn the structure of a belief network from incomplete data--that is, in the presence of missing values or hidden variables. In a recent paper, I introduced an algorithm called Structural EM that combines the standard Expectation Maximization (EM) algorithm, which optimizes parameters, with structure search for model selection. That algorithm learns networks based on penalized likelihood scores, which include the BIC/MDL score and various approximations to the Bayesian score. In this paper, I extend Structural EM to deal directly with Bayesian model selection. I prove the convergence of the resulting algorithm and show how to apply it for learning a large class of probabilistic models, including Bayesian networks and some variants thereof."
            },
            "slug": "The-Bayesian-Structural-EM-Algorithm-Friedman",
            "title": {
                "fragments": [],
                "text": "The Bayesian Structural EM Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper extends Structural EM to deal directly with Bayesian model selection and proves the convergence of the resulting algorithm and shows how to apply it for learning a large class of probabilistic models, including Bayesian networks and some variants thereof."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145668856"
                        ],
                        "name": "A. Pfeffer",
                        "slug": "A.-Pfeffer",
                        "structuredName": {
                            "firstName": "Avi",
                            "lastName": "Pfeffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pfeffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1939888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "419438bc4f6652784f42cf3e62c975a5c89b817e",
            "isKey": false,
            "numCitedBy": 607,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian networks provide a modeling language and associated inference algorithm for stochastic domains. They have been successfully applied in a variety of medium-scale applications. However, when faced with a large complex domain, the task of modeling using Bayesian networks begins to resemble the task of programming using logical circuits. In this paper, we describe an object-oriented Bayesian network (OOBN) language, which allows complex domains to be described in terms of inter-related objects. We use a Bayesian network fragment to describe the probabilistic relations between the attributes of an object. These attributes can themselves be objects, providing a natural framework for encoding part-of hierarchies, Classes are used to provide a reusable probabilistic model which can be applied to multiple similar objects. Classes also support inheritance of model fragments from a class to a subclass, allowing the common aspects of related classes to be defined only once. Our language has clear declarative semantics: an OOBN can be interpreted as a stochastic functional program, so that it uniquely specifies a probabilistic model. We provide an inference algorithm for OOBNs, and show that much of the structural information encoded by an OOBN--particularly the encapsulation of variables within an object and the reuse of model fragments in different contexts---can also be used to speed up the inference process."
            },
            "slug": "Object-Oriented-Bayesian-Networks-Koller-Pfeffer",
            "title": {
                "fragments": [],
                "text": "Object-Oriented Bayesian Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper provides an inference algorithm for OOBNs, and shows that much of the structural information encoded by an OOBN--particularly the encapsulation of variables within an object and the reuse of model fragments in different contexts---can also be used to speed up the inference process."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70219052"
                        ],
                        "name": "Wray L. Buntine",
                        "slug": "Wray-L.-Buntine",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "Buntine",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. Buntine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 803,
                                "start": 0
                            }
                        ],
                        "text": "Buntine (1994, 1996) provides extensive reviews with many references. Jordan (1998) presents a recent collection, which contains both tutorial introductions to Bayesian networks and also recent developments about learning. The proceedings of the yearly UAI conferences are a good source to keep up with recent developments. Buntine (1994) emphasized the importance of exponential families for learning about probabilities in Bayesian networks. Thiesson (1997) defined a class of recursive exponential models for learning in directed Markov models. Geiger and Meek (1998) showed formally that curved exponential families arise for some probabilistic networks. The treatment of sequential learning presented in Section 9.7 is the natural generalization of the theory of Spiegelhalter and Lauritzen (1990), who also developed other representations of priors for networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 968,
                                "start": 0
                            }
                        ],
                        "text": "Buntine (1994, 1996) provides extensive reviews with many references. Jordan (1998) presents a recent collection, which contains both tutorial introductions to Bayesian networks and also recent developments about learning. The proceedings of the yearly UAI conferences are a good source to keep up with recent developments. Buntine (1994) emphasized the importance of exponential families for learning about probabilities in Bayesian networks. Thiesson (1997) defined a class of recursive exponential models for learning in directed Markov models. Geiger and Meek (1998) showed formally that curved exponential families arise for some probabilistic networks. The treatment of sequential learning presented in Section 9.7 is the natural generalization of the theory of Spiegelhalter and Lauritzen (1990), who also developed other representations of priors for networks. Consonni and Giudici (1993) presented learning using hierarchical priors. Heckerman et al. (1995b) looked at parameter and structural learning for discrete"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 0
                            }
                        ],
                        "text": "Buntine (1994, 1996) provides extensive reviews with many references. Jordan (1998) presents a recent collection, which contains both tutorial introductions to Bayesian networks and also recent developments about learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 81
                            }
                        ],
                        "text": "General reviews of structural learning in graphical models have been provided by Buntine (1994, 1996), Sanguesa and Cortes (1997) and various papers in the collection edited by Jordan (1998), particularly that by Heckerman (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 339,
                                "start": 0
                            }
                        ],
                        "text": "Buntine (1994, 1996) provides extensive reviews with many references. Jordan (1998) presents a recent collection, which contains both tutorial introductions to Bayesian networks and also recent developments about learning. The proceedings of the yearly UAI conferences are a good source to keep up with recent developments. Buntine (1994) emphasized the importance of exponential families for learning about probabilities in Bayesian networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 460,
                                "start": 0
                            }
                        ],
                        "text": "Buntine (1994, 1996) provides extensive reviews with many references. Jordan (1998) presents a recent collection, which contains both tutorial introductions to Bayesian networks and also recent developments about learning. The proceedings of the yearly UAI conferences are a good source to keep up with recent developments. Buntine (1994) emphasized the importance of exponential families for learning about probabilities in Bayesian networks. Thiesson (1997) defined a class of recursive exponential models for learning in directed Markov models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Buntine (1994) gives a comprehensive review of the theory; here we present an outline."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 571,
                                "start": 0
                            }
                        ],
                        "text": "Buntine (1994, 1996) provides extensive reviews with many references. Jordan (1998) presents a recent collection, which contains both tutorial introductions to Bayesian networks and also recent developments about learning. The proceedings of the yearly UAI conferences are a good source to keep up with recent developments. Buntine (1994) emphasized the importance of exponential families for learning about probabilities in Bayesian networks. Thiesson (1997) defined a class of recursive exponential models for learning in directed Markov models. Geiger and Meek (1998) showed formally that curved exponential families arise for some probabilistic networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 897,
                                "start": 0
                            }
                        ],
                        "text": "Buntine (1994, 1996) provides extensive reviews with many references. Jordan (1998) presents a recent collection, which contains both tutorial introductions to Bayesian networks and also recent developments about learning. The proceedings of the yearly UAI conferences are a good source to keep up with recent developments. Buntine (1994) emphasized the importance of exponential families for learning about probabilities in Bayesian networks. Thiesson (1997) defined a class of recursive exponential models for learning in directed Markov models. Geiger and Meek (1998) showed formally that curved exponential families arise for some probabilistic networks. The treatment of sequential learning presented in Section 9.7 is the natural generalization of the theory of Spiegelhalter and Lauritzen (1990), who also developed other representations of priors for networks. Consonni and Giudici (1993) presented learning using hierarchical priors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11672931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa7a32d9ce76cd016cf21d4f956e19d90e87b0dc",
            "isKey": true,
            "numCitedBy": 654,
            "numCiting": 143,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a multidisciplinary review of empirical, statistical learning from a graphical model perspective. Well-known examples of graphical models include Bayesian networks, directed graphs representing a Markov chain, and undirected networks representing a Markov field. These graphical models are extended to model data analysis and empirical learning using the notation of plates. Graphical operations for simplifying and manipulating a problem are provided including decomposition, differentiation, andthe manipulation of probability models from the exponential family. Two standard algorithm schemas for learning are reviewed in a graphical framework: Gibbs sampling and the expectation maximizationalgorithm. Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification. This includes versions of linear regression, techniques for feed-forward networks, and learning Gaussian and discrete Bayesian networks from data. The paper concludes by sketching some implications for data analysis and summarizing how some popular algorithms fall within the framework presented. The main original contributions here are the decompositiontechniques and the demonstration that graphical models provide a framework for understanding and developing complex learning algorithms."
            },
            "slug": "Operations-for-Learning-with-Graphical-Models-Buntine",
            "title": {
                "fragments": [],
                "text": "Operations for Learning with Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main original contributions here are the decompositiontechniques and the demonstration that graphical models provide a framework for understanding and developing complex learning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47559480"
                        ],
                        "name": "C. S. Jensen",
                        "slug": "C.-S.-Jensen",
                        "structuredName": {
                            "firstName": "Claus",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Skaanning"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. S. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775921"
                        ],
                        "name": "Uffe Kj\u00e6rulff",
                        "slug": "Uffe-Kj\u00e6rulff",
                        "structuredName": {
                            "firstName": "Uffe",
                            "lastName": "Kj\u00e6rulff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uffe Kj\u00e6rulff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49504816"
                        ],
                        "name": "A. Kong",
                        "slug": "A.-Kong",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Kong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 228
                            }
                        ],
                        "text": "Irreducibility is a particular problem in models for genetic pedigrees, where one promising way of overcoming this type of problem has been to update large blocks of variables simultaneously in so-called blocking Gibbs sampling (Jensen et al. 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 261
                            }
                        ],
                        "text": "The final flows back to W from those neighbours in which it has called Collect Evidence may be effected as soon as each such neighbour is ready, or be delayed until the last is ready, all flows then passing into W simultaneously, a process termed absorption by Jensen et al. (1990a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 44
                            }
                        ],
                        "text": "5 using the elimination ordering taken from Jensen et al. (1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1027,
                                "start": 0
                            }
                        ],
                        "text": "Jensen et al. (1990a) propose a twophase schedule. This requires the selection of an arbitrary clique C0 \u2208 C to be the root-clique. An initial collection phase involves passing active flows only along edges directed toward C0; this is then followed by a distribution phase, in which, starting from C0, active flows are passed back toward the periphery. After collection, the potential for C0 will be fC0 , and if this is all that is desired the distribution phase may be omitted. Any fully active schedule implicitly defines a two-phase routine, with root the first clique to become live, and may thus be divided into its collection and distribution phases. As a variant of this and other scheduling routines, some flows can be passed in parallel, and a receiving node can process several incoming flows simultaneously by multiplying all their update ratios into its potential \u2014 which it can delay until required to calculate an active output flow. Yet another routine, similar to the one described by Shafer and Shenoy (1990) treats each clique as an autonomous processor, which at time t examines each of the edges incident on it to see if a new flow has been passed along it, and if so, multiplies the associated update ratio into its potential."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 24
                            }
                        ],
                        "text": "This is the approach of Jensen et al. (1994). After the moralization process is completed, one then deletes the utility nodes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Jensen and Andersen (1990) use this to construct an iterative method of selecting elements of a clique table to set to zero."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 302,
                                "start": 215
                            }
                        ],
                        "text": "Another trend is the development of variants of the algorithm that perform slightly different or additional tasks (Jensen 1995), or that work in a somewhat modified way (Bloemeke and Valtorta 1998) or approximately (Kj\u00e6rulff 1993; Jensen et al. 1995; Saul et al. 1996; Curds 1997; Kearns and Saul 1998)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15392897,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1354660aba6bbcadb569f684d5a309ae57f58a79",
            "isKey": true,
            "numCitedBy": 154,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We introduce a methodology for performing approximate computations in very complex probabilistic systems (e.g. huge pedigrees). Our approach, called blocking Gibbs, combines exact local computations with Gibbs sampling in a way that complements the strengths of both. The methodology is illustrated on a real-world problem involving a heavily inbred pedigreee containing 20 000 individuals. We present results showing that blocking-Gibbs sampling converges much faster than plain Gibbs sampling for very complex problems."
            },
            "slug": "Blocking-Gibbs-sampling-in-very-large-probabilistic-Jensen-Kj\u00e6rulff",
            "title": {
                "fragments": [],
                "text": "Blocking Gibbs sampling in very large probabilistic expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results are presented showing that blocking-Gibbs sampling converges much faster than plain Gibbs sampling for very complex problems."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Hum. Comput. Stud."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17051088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a87f270ac2c8420db2669e5e12abb6aff0755115",
            "isKey": false,
            "numCitedBy": 493,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A scheme is presented for modeling and local computation of exact probabilities, means, and variances for mixed qualitative and quantitative variables. The models assume that the conditional distribution of the quantitative variables, given the qualitative, is multivariate Gaussian. The computational architecture is set up by forming a tree of belief universes, and the calculations are then performed by local message passing between universes. The asymmetry between the quantitative and qualitative variables sets some additional limitations for the specification and propagation structure. Approximate methods when these are not appropriately fulfilled are sketched. It has earlier been shown how to exploit the local structure in the specification of a discrete probability model for fast and efficient computation, thereby paving the way for exploiting probability-based models as parts of realistic systems for planning and decision support. The purpose of this article is to extend this computational s..."
            },
            "slug": "Propagation-of-Probabilities,-Means,-and-Variances-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Propagation of Probabilities, Means, and Variances in Mixed Graphical Association Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The purpose of this article is to extend the local structure in the specification of a discrete probability model for fast and efficient computation, thereby paving the way for exploiting probability-based models as parts of realistic systems for planning and decision support."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775921"
                        ],
                        "name": "Uffe Kj\u00e6rulff",
                        "slug": "Uffe-Kj\u00e6rulff",
                        "structuredName": {
                            "firstName": "Uffe",
                            "lastName": "Kj\u00e6rulff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uffe Kj\u00e6rulff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 302,
                                "start": 215
                            }
                        ],
                        "text": "Another trend is the development of variants of the algorithm that perform slightly different or additional tasks (Jensen 1995), or that work in a somewhat modified way (Bloemeke and Valtorta 1998) or approximately (Kj\u00e6rulff 1993; Jensen et al. 1995; Saul et al. 1996; Curds 1997; Kearns and Saul 1998)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8581122,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce412157e629989b0af4abdaf5251255a8c3e29a",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Computational-Scheme-for-Reasoning-in-Dynamic-Kj\u00e6rulff",
            "title": {
                "fragments": [],
                "text": "A Computational Scheme for Reasoning in Dynamic Probabilistic Networks"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50860274"
                        ],
                        "name": "Padhraic Smyth",
                        "slug": "Padhraic-Smyth",
                        "structuredName": {
                            "firstName": "Padhraic",
                            "lastName": "Smyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Padhraic Smyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 255
                            }
                        ],
                        "text": "For applications involving processes that evolve over time, a natural representation is in terms of hidden Markov models, in which the relationship between adjacent observations is explained through their common dependence on an unobserved Markov process (Smyth et al. 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 72
                            }
                        ],
                        "text": "1998), can likewise be considered as special cases of Bayesian networks (Smyth et al. 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10043879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0999dc17b35c0d893974f03d98293f71f27698b",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical techniques for modeling the dependencies of random variables have been explored in a variety of different areas, including statistics, statistical physics, artificial intelligence, speech recognition, image processing, and genetics. Formalisms for manipulating these models have been developed relatively independently in these research communities. In this paper we explore hidden Markov models (HMMs) and related structures within the general framework of probabilistic independence networks (PINs). The paper presents a self-contained review of the basic principles of PINs. It is shown that the well-known forward-backward (F-B) and Viterbi algorithms for HMMs are special cases of more general inference algorithms for arbitrary PINs. Furthermore, the existence of inference and estimation algorithms for more general graphical models provides a set of analysis tools for HMM practitioners who wish to explore a richer class of HMM structures. Examples of relatively complex models to handle sensor fusion and coarticulation in speech recognition are introduced and treated within the graphical model framework to illustrate the advantages of the general approach."
            },
            "slug": "Probabilistic-Independence-Networks-for-Hidden-Smyth-Heckerman",
            "title": {
                "fragments": [],
                "text": "Probabilistic Independence Networks for Hidden Markov Probability Models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that the well-known forward-backward and Viterbi algorithms for HMMs are special cases of more general inference algorithms for arbitrary PINs and the existence of inference and estimation algorithms for more general graphical models provides a set of analysis tools for HMM practitioners who wish to explore a richer class of HMM structures."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3293700"
                        ],
                        "name": "R. Almond",
                        "slug": "R.-Almond",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Almond",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Almond"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 92
                            }
                        ],
                        "text": "There is also some efficiency to be gained by constructing junction trees of special types (Almond 1995; Shenoy 1997). For recent results on triangulation algorithms, see Becker and Geiger (1996), Larra\u00f1aga et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 92
                            }
                        ],
                        "text": "There is also some efficiency to be gained by constructing junction trees of special types (Almond 1995; Shenoy 1997). For recent results on triangulation algorithms, see Becker and Geiger (1996), Larra\u00f1aga et al. (1997), and Meil\u0103 and Jordan (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 91
                            }
                        ],
                        "text": "There is also some efficiency to be gained by constructing junction trees of special types (Almond 1995; Shenoy 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35986501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fab37e2702fe40d6c64ebd98f930a6e2f64c339d",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis innovative volume explores graphical models using belieffunctions as a representation of uncertainty, offering an alternative approach to problems where probability proves inadequate. Graphical Belief Modeling makes it easy to compare the two approaches while evaluating their relative strengths and limitations. \nThe author examines both theory and computation, incorporating practical notes from the author's own experience with the BELIEF software package. As one of the first volumes to apply the Dempster-Shafer belief functions to a practical model, a substantial portion of the book is devoted to a single example--calculating the reliability of a complex system. This special feature enables readers to gain a thorough understanding of the application of this methodology. \nThe first section provides a description of graphical belief models and probablistic graphical models that form an important subset: the second section discusses the algorithm used in the manipulation of graphical models: the final segment of the book offers a complete description of the risk assessment example, as well as the methodology used to describe it. \nGraphical Belief Modeling offers researchers and graduate students in artificial intelligence and statistics more than just a new approach to an old reliability task: it provides them with an invaluable illustration of the process of graphical belief modeling."
            },
            "slug": "Graphical-belief-modeling-Almond",
            "title": {
                "fragments": [],
                "text": "Graphical belief modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This innovative volume explores graphical models using belieffunctions as a representation of uncertainty, offering an alternative approach to problems where probability proves inadequate, and provides an invaluable illustration of the process of graphical belief modeling."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46558286"
                        ],
                        "name": "S. K. Andersen",
                        "slug": "S.-K.-Andersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Kj\u00e6r"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34760449"
                        ],
                        "name": "K. Olesen",
                        "slug": "K.-Olesen",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Olesen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Olesen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120177012"
                        ],
                        "name": "Frank Jensen",
                        "slug": "Frank-Jensen",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Jensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 62
                            }
                        ],
                        "text": "7 show a sequence of screen dumps taken from the Hugin system (Andersen et al. 1989), illustrating the propagation algorithm in use on Child."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 44
                            }
                        ],
                        "text": "This has been exploited in the Hugin system (Andersen et al. 1989) by a procedure called compression, in which an efficient representation of the clique tables is used so that these zeros do not need to be stored explicitly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16250237,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "181b3b89260b8859d86bf641b7e2b2a4c2663e98",
            "isKey": false,
            "numCitedBy": 466,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Causal probabilistic networks have proved to be a useful knowledge representation tool for modelling domains where causal relations in a broad sense are a natural way of relating domain objects and where uncertainty is inherited in these relations. This paper outlines an implementation the HUGIN shell - for handling a domain model expressed by a causal probabilistic network. The only topological restriction imposed on the network is that, it must not contain any directed loops. The approach is illustrated step by step by solving a genetic breeding problem. A graph representation of the domain model is interactively created by using instances of the basic network components-- nodes and arcs--as building blocks. This structure, together with the quantitative relations between nodes and their immediate causes expressed as conditional probabilities, are automatically transformed into a tree structure, a junction tree. Here a computationally efficient and conceptually simple algebra of Bayesian belief universes supports incorporation of new evidence, propagation of information, and calculation of revised beliefs in the states of the nodes in the network. Finally, as an exam ple of a real world application, MUNIN an expert system for electromyography is discussed."
            },
            "slug": "HUGIN-A-Shell-for-Building-Bayesian-Belief-for-Andersen-Olesen",
            "title": {
                "fragments": [],
                "text": "HUGIN - A Shell for Building Bayesian Belief Universes for Expert Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper outlines an implementation the HUGIN shell - for handling a domain model expressed by a causal probabilistic network, and a computationally efficient and conceptually simple algebra of Bayesian belief universes supports incorporation of new evidence, propagation of information, and calculation of revised beliefs in the states of the nodes in the network."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770007"
                        ],
                        "name": "M. Goldszmidt",
                        "slug": "M.-Goldszmidt",
                        "structuredName": {
                            "firstName": "Mois\u00e9s",
                            "lastName": "Goldszmidt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goldszmidt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 73
                            }
                        ],
                        "text": "Suggestions have included structuring the tables as classification trees (Friedman and Goldszmidt 1998) or as neural networks (Monti and Cooper 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15634497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c9e02656982419870ccc0b60d4c8b1a6e4b449d",
            "isKey": false,
            "numCitedBy": 584,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we examine a novel addition to the known methods for learning Bayesian networks from data that improves the quality of the learned networks. Our approach explicitly represents and learns the local structure in the conditional probability tables (CPTs), that quantify these networks. This increases the space of possible models, enabling the representation of CPTs with a variable number of parameters that depends on the learned local structures. The resulting learning procedure is capable of inducing models that better emulate the real complexity of the interactions present in the data. We describe the theoretical foundations and practical aspects of learning local structures, as well as an empirical evaluation of the proposed method. This evaluation indicates that learning curves characterizing the procedure that exploits the local structure converge faster than these of the standard procedure. Our results also show that networks learned with local structure tend to be more complex (in terms of arcs), yet require less parameters."
            },
            "slug": "Learning-Bayesian-Networks-with-Local-Structure-Friedman-Goldszmidt",
            "title": {
                "fragments": [],
                "text": "Learning Bayesian Networks with Local Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel addition to the known methods for learning Bayesian networks from data that improves the quality of the learned networks and indicates that learning curves characterizing the procedure that exploits the local structure converge faster than these of the standard procedure."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34760449"
                        ],
                        "name": "K. Olesen",
                        "slug": "K.-Olesen",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Olesen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Olesen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46558286"
                        ],
                        "name": "S. K. Andersen",
                        "slug": "S.-K.-Andersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Kj\u00e6r"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Andersen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206313561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e7c8ac116f3d3b3052d23fa4b269b0000286105",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Causal probabilistic networks (CPNs) have proved to be a useful knowledge representation tool for modeling domains where causal relations-in a broad sense-are a natural way of relating domain concepts and where uncertainty is inherited in these relations. The domain is modeled in a CPN by use of a directed graph where the nodes represent concepts in the domain and the arcs represent causal relations. Furthermore, the quantitative relation between a node and its immediate causes is expressed as conditional probabilities. During the last few years, several schemes based on probability theory for incorporating and propagating new information throughout a CPN has emerged. As long as the domain can be modeled by use of a singly connected CPN (i. e., no more than one path between any pair of nodes), the schemes operate directly in the CPN and perform conceptually simple operations in this structure. When it comes to more complicated structures such as multiply connected CPNs (i. e., more than one path is allowed between pairs of nodes), the schemes operate in derived structures where the embedded domain knowledge no longer is as explicit and transparent as in the CPN. Furthermore, the simplicity in the operations is lost also. This report outlines a scheme-the algebra of Bayesian belief universes-for absorbing and propagating evidence in multiply connected CPNs. The scheme provides a secondary structure, a junction tree, and a simple set of algebraic operations between objects in this structure, Collect Evidence and Distribute Evidence. These are the basic tools for making inference in a CPN domain model and yield a calculus as simple as in the case of singly connected CPNs."
            },
            "slug": "An-algebra-of-bayesian-belief-universes-for-systems-Jensen-Olesen",
            "title": {
                "fragments": [],
                "text": "An algebra of bayesian belief universes for knowledge-based systems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A scheme-the algebra of Bayesian belief universes-for absorbing and propagating evidence in multiply connected CPNs is outlined, which provides a secondary structure, a junction tree, and a simple set of algebraic operations between objects in this structure, Collect Evidence and Distribute Evidence."
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724065"
                        ],
                        "name": "D. M. Chickering",
                        "slug": "D.-M.-Chickering",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chickering",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Chickering"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1147,
                                "start": 0
                            }
                        ],
                        "text": "Chickering (1996) shows that the general problem of determining the optimal structure is NP-hard, and so since an exhaustive analysis of all possible structures is generally infeasible a selective search algorithm needs to be established. It seems appropriate for this to be local, in some sense, to the original graph. In particular, in examples such as Figure 3.1, which have a clear block structure, we might be convinced by the partial order expressed by the blocks, and hence not entertain thoughts of links going from lower to higher blocks, but might question the existence of links between blocks or from higher to lower blocks. Heckerman (1998) describes a number of search strategies that have been adopted for comparisons based on scoring, noting that with complete data the factorization of the score associated with any model makes it straightforward to carry out a search from any current model by evaluating the effect of adding or removing all feasible arcs. Thus we perform a walk through the model space by adding or dropping single links at a time. The walk can be performed either deterministically or randomly. Gabriel (1969) proposed two coherence rules for pruning this search space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 654,
                                "start": 0
                            }
                        ],
                        "text": "Chickering (1996) shows that the general problem of determining the optimal structure is NP-hard, and so since an exhaustive analysis of all possible structures is generally infeasible a selective search algorithm needs to be established. It seems appropriate for this to be local, in some sense, to the original graph. In particular, in examples such as Figure 3.1, which have a clear block structure, we might be convinced by the partial order expressed by the blocks, and hence not entertain thoughts of links going from lower to higher blocks, but might question the existence of links between blocks or from higher to lower blocks. Heckerman (1998) describes a number of search strategies that have been adopted for comparisons based on scoring, noting that with complete data the factorization of the score associated with any model makes it straightforward to carry out a search from any current model by evaluating the effect of adding or removing all feasible arcs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Chickering (1996) shows that the general problem of determining the optimal structure is NP-hard, and so since an exhaustive analysis of all possible structures is generally infeasible a selective search algorithm needs to be established."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14226732,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fb874a1c8106a5b2b2779ee8e1433149109ba00",
            "isKey": true,
            "numCitedBy": 1055,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for learning Bayesian networks from data have two components: a scoring metric and a search procedure. The scoring metric computes a score reflecting the goodness-of-fit of the structure to the data. The search procedure tries to identify network structures with high scores. Heckerman et al. (1995) introduce a Bayesian metric, called the BDe metric, that computes the relative posterior probability of a network structure given data. In this paper, we show that the search problem of identifying a Bayesian network\u2014among those where each node has at most K parents\u2014that has a relative posterior probability greater than a given constant is NP-complete, when the BDe metric is used."
            },
            "slug": "Learning-Bayesian-Networks-is-NP-Complete-Chickering",
            "title": {
                "fragments": [],
                "text": "Learning Bayesian Networks is NP-Complete"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the search problem of identifying a Bayesian network\u2014among those where each node has at most K parents\u2014that has a relative posterior probability greater than a given constant is NP-complete, when the BDe metric is used."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144594306"
                        ],
                        "name": "Wai Lam",
                        "slug": "Wai-Lam",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai Lam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 175
                            }
                        ],
                        "text": "Exceptions include Riva and Bellazzi (1996), who use scoring metrics to compare pre-specified models for medical monitoring applications using one-step-ahead predictions, and Lam (1998), who uses a Minimum Description Length approach to refine a network on the basis of new data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20649350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ec47080fcb2967cbedf2b9d821d7b458aff8799",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to refining Bayesian network structures from new data is developed. Most previous work has only considered the refinement of the network's conditional probability parameters and has not addressed the issue of refining the network's structure. We tackle this problem by a machine learning approach based on a formalism known as the minimum description length (MDL) principle. The MDL principle is well suited to this task since it can perform tradeoffs between the accuracy, simplicity, and closeness to the existent structure. Another salient feature of this refinement approach is the capability of refining a network structure using partially specified data. Moreover, a localization scheme is developed for efficient computation of the description lengths since direct evaluation involves exponential time resources."
            },
            "slug": "Bayesian-Network-Refinement-Via-Machine-Learning-Lam",
            "title": {
                "fragments": [],
                "text": "Bayesian Network Refinement Via Machine Learning Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "An approach to refining Bayesian network structures from new data by a machine learning approach based on a formalism known as the minimum description length (MDL) principle, which has the capability of refining a network structure using partially specified data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2565899"
                        ],
                        "name": "Mark Bloemeke",
                        "slug": "Mark-Bloemeke",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Bloemeke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Bloemeke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145638099"
                        ],
                        "name": "M. Valtorta",
                        "slug": "M.-Valtorta",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Valtorta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Valtorta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 169
                            }
                        ],
                        "text": "Another trend is the development of variants of the algorithm that perform slightly different or additional tasks (Jensen 1995), or that work in a somewhat modified way (Bloemeke and Valtorta 1998) or approximately (Kj\u00e6rulff 1993; Jensen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8569888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "208589caa8f21fde6c90c182d9298b286a55c422",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "There exist two general forms of exact algorithms for updating probabilities in Bayesian Networks. The first approach involves using a structure, usually a clique tree, and performing local message based calculation to extract the belief in each variable. The second general class of algorithm involves the use of non-serial dynamic programming techniques to extract the belief in some desired group of variables. In this paper we present a hybrid algorithm based on the latter approach yet possessing the ability to retrieve the belief in all single variables. The technique is advantageous in that it saves a NP-hard computation step over using one algorithm of each type. Furthermore, this technique re-enforces a conjecture of Jensen and Jensen [JJ94] in that it still requires a single NP-hard step to set up the structure on which inference is performed, as we show by confirming Li and D'Ambrosio's [LD94] conjectured NP-hardness of OFP."
            },
            "slug": "A-Hybrid-Algorithm-to-Compute-Marginal-and-Joint-in-Bloemeke-Valtorta",
            "title": {
                "fragments": [],
                "text": "A Hybrid Algorithm to Compute Marginal and Joint Beliefs in Bayesian Networks and Its Complexity"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a hybrid algorithm based on the latter approach yet possessing the ability to retrieve the belief in all single variables, and confirms Li and D'Ambrosio's [LD94] conjectured NP-hardness of OFP."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177076"
                        ],
                        "name": "D. Draper",
                        "slug": "D.-Draper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Draper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Draper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 181
                            }
                        ],
                        "text": "However, when there is uncertainty about the true model, selecting and using a single \u2018best\u2019 model to make predictions will result in underestimation of the appropriate uncertainty (Draper 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 23
                            }
                        ],
                        "text": "The search strategy of Edwards and Havr\u00e1nek (1985) uses both these rules; Madigan and Raftery (1994), undertaking a model-averaging search, use only the first."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18948315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6673b0aefae40ce236bd8568e4e1a1483d27df46",
            "isKey": false,
            "numCitedBy": 1514,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "Assessment and Propagation of Model Uncertainty By DAVID DRAPER* University of Bath, UK SUMMARY In most examples of inference and prediction, the expression of uncertainty about unknown quantities y on the basis of known quantities x is based on a model M that formalizes assumptions about how x and y are related. M will typically have two parts: structural assumptions S, such as the form of the link function and the choice of error distribution in a generalized linear model, and parameters 6 whose meaning is specific to a given choice of S. It is common in statistical theory and practice to acknowledge parametric uncertainty about 9 given a particular assumed structure S; it is less common to acknowledge structural uncertainty about S itself. A widely used approach, in fact, involves enlisting the aid of x to specify a plausible single best choice S* for S, and then proceeding as if S* were known to be correct. In general this approach fails to fully assess and propagate structural uncertainty, and may lead to miscali- brated uncertainty assessments about y given x. When miscalibration occurs it will often be in the direction of understatement of inferential or predictive uncertainty about y, leading to inaccurate scientific summaries and overconfi- dent decisions that do not incorporate sufficient hedging against uncertainty. In this paper I discuss a Bayesian approach to solving this problem that has long been available in principle but is only now becoming routinely feasible, by virtue of recent computational advances, and examine its implementation in examples that involve forecasting the price of oil and estimating the chance of catastrophic failure of the U.S. Space Shuttle. Keywords: BAYES FACTORS; CALIBRATION; FORECASTING; HIERARCHICAL MODELS; INFERENCE; MODEL SPECIFICATION; OVER-FITTING; PREDICTION; ROBUSTNESS; SENSITIVITY ANALYSIS; UNCERTAINTY ASSESSMENT 1. INTRODUCTION The general framework of problems in inference and prediction involves two sets of ingredients: unknown (s) y\u2014such as the causal effect of a treatment in inference, or the price of something next year in prediction\u2014and known (s) x, which will typically include both data and context. The desire is usually to express uncertainty about y in light of x, for instance through a probability specification of the form p(y\\x). Specifications of this type that involve conditioning only on things that are known are rare, even in comparatively simple settings (e.g., Lindley, 1982); instead one typically appeals to a model M that formalizes judgments about how x and y are related. 1.1. Structural Uncertainty The model may be expressed (e.g., Draper et al., 1987; Hodges, 1987) in two parts as M = (S, 9), where S represents one or more sets of structural assumptions\u2014 such as a particular link function in a generalized linear model, or a particular form of heteroscedasticity or time dependence with non-IID data\u2014and 9 represents parameters whose meaning is specific to the chosen structure(s). (It will often be possible to express a given model M in more than one way using this notation, but that does not affect the discussion that follows.) Once S is chosen, 9 typically follows ' Address for correspondence: Statistics Group, School of Mathematical Sciences, University of Bath, Claverton Down, Bath BA2 7AY, UK (d.draper@maths.bath.ac.uk)."
            },
            "slug": "Assessment-and-Propagation-of-Model-Uncertainty-Draper",
            "title": {
                "fragments": [],
                "text": "Assessment and Propagation of Model Uncertainty"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A Bayesian approach to solving this problem that has long been available in principle but is only now becoming routinely feasible, by virtue of recent computational advances, is discussed and its implementation is examined in examples that involve forecasting the price of oil and estimating the chance of catastrophic failure of the U.S. Space Shuttle."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089883"
                        ],
                        "name": "W. Gilks",
                        "slug": "W.-Gilks",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Gilks",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gilks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107218881"
                        ],
                        "name": "A. Thomas",
                        "slug": "A.-Thomas",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Thomas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 179
                            }
                        ],
                        "text": "These ideas form the basis of the BUGS (Bayesian Updating with Gibbs Sampling) computer program, which uses a specially designed high-level language to describe a graphical model (Gilks et al. 1994) and automatically constructs the necessary full conditional sampling procedures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41819931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a1e584f9a91472d6e15184f1648f57256216198",
            "isKey": false,
            "numCitedBy": 718,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Gibbs sampling has enormous potential for analysing complex data sets. However, routine use of Gibbs sampling has been hampered by the lack of general purpose software for its implementation. Until now all applications have involved writing one-off computer code in low or intermediate level languages such as C or Fortran. We describe some general purpose software that we are currently developing for implementing Gibbs sampling: BUGS (Bayesian inference using Gibbs sampling). The BUGS system comprises three components: first, a natural language for specifying complex models; second, an 'expert system' for deciding appropriate methods for obtaining samples required by the Gibbs sampler; third, a sampling module containing numerical routines to perform the sampling. S objects are used for data input and output. BUGS is written in Modula-2 and runs under both DOS and UNIX."
            },
            "slug": "A-Language-and-Program-for-Complex-Bayesian-Gilks-Thomas",
            "title": {
                "fragments": [],
                "text": "A Language and Program for Complex Bayesian Modelling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work describes some general purpose software that is currently developing for implementing Gibbs sampling: BUGS (Bayesian inference using Gibbs sampling), written in Modula-2 and runs under both DOS and UNIX."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144527211"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 146
                            }
                        ],
                        "text": ", Gaussian or having a positive density) exists displaying all and only the conditional properties displayed by a given graphical representation (Geiger and Pearl 1990, 1993; Studen\u00fd and Bouckaert 1998). Studen\u00fd (1997) and Andersson et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5521191,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "640e79936e620fa3436b4e9f16dbba00b9a26c2a",
            "isKey": false,
            "numCitedBy": 438,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Gaussian-Networks-Geiger-Heckerman",
            "title": {
                "fragments": [],
                "text": "Learning Gaussian Networks"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710305"
                        ],
                        "name": "D. Madigan",
                        "slug": "D.-Madigan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Madigan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Madigan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804386"
                        ],
                        "name": "A. Raftery",
                        "slug": "A.-Raftery",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Raftery",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Raftery"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 127
                            }
                        ],
                        "text": "Even averaging over a small number, 10 or 20 say, of the best models can yield a significantly improved predictive performance (Madigan and Raftery 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 2
                            }
                        ],
                        "text": ", Madigan and Raftery (1994)) that this predictive distribution will give better predictions (as evaluated by means of the logarithmic scoring rule) than are expected from the use of a single model:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18709953,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cbb7afa526e1f947520ffeec8f734794802ee3c7",
            "isKey": false,
            "numCitedBy": 1301,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We consider the problem of model selection and accounting for model uncertainty in high-dimensional contingency tables, motivated by expert system applications. The approach most used currently is a stepwise strategy guided by tests based on approximate asymptotic P values leading to the selection of a single model; inference is then conditional on the selected model. The sampling properties of such a strategy are complex, and the failure to take account of model uncertainty leads to underestimation of uncertainty about quantities of interest. In principle, a panacea is provided by the standard Bayesian formalism that averages the posterior distributions of the quantity of interest under each of the models, weighted by their posterior model probabilities. Furthermore, this approach is optimal in the sense of maximizing predictive ability. But this has not been used in practice, because computing the posterior model probabilities is hard and the number of models is very large (often greater than 1..."
            },
            "slug": "Model-Selection-and-Accounting-for-Model-in-Models-Madigan-Raftery",
            "title": {
                "fragments": [],
                "text": "Model Selection and Accounting for Model Uncertainty in Graphical Models Using Occam's Window"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750921"
                        ],
                        "name": "M. Ramoni",
                        "slug": "M.-Ramoni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Ramoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ramoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714284"
                        ],
                        "name": "P. Sebastiani",
                        "slug": "P.-Sebastiani",
                        "structuredName": {
                            "firstName": "Paola",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sebastiani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2495005,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b60bd9928ec0552f291023ce487eebfc0ec0256d",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian approaches to learn the graphical structure of Bayesian Belief Networks (BBNS) from databases share the assumption that the database is complete, that is, no entry is reported as unknown. Attempts to relax this assumption involve the use of expensive iterative methods to discriminate among different structures. This paper introduces a deterministic method to learn the graphical structure of a BBN from a possibly incomplete database. Experimental evaluations show a significant robustness of this method and a remarkable independence of its execution time from the number of missing data."
            },
            "slug": "Learning-Bayesian-Networks-from-Incomplete-Ramoni-Sebastiani",
            "title": {
                "fragments": [],
                "text": "Learning Bayesian Networks from Incomplete Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Experimental evaluations show a significant robustness of this method and a remarkable independence of its execution time from the number of missing data."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 302,
                                "start": 215
                            }
                        ],
                        "text": "Another trend is the development of variants of the algorithm that perform slightly different or additional tasks (Jensen 1995), or that work in a somewhat modified way (Bloemeke and Valtorta 1998) or approximately (Kj\u00e6rulff 1993; Jensen et al. 1995; Saul et al. 1996; Curds 1997; Kearns and Saul 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 295004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92e5999c1f733725ce5468e43085dce26d08f8c5",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We study two-layer belief networks of binary random variables in which the conditional probabilities Pr [child|parents] depend monotonically on weighted sums of the parents. In large networks where exact probabilistic inference is intractable, we show how to compute upper and lower bounds on many probabilities of interest. In particular, using methods from large deviation theory, we derive rigorous bounds on marginal probabilities such as Pr[children] and prove rates of convergence for the accuracy of our bounds as a function of network size. Our results apply to networks with generic transfer function parameterizations of the conditional probability tables, such as sigmoid and noisy-OR. They also explicitly illustrate the types of averaging behavior that can simplify the problem of inference in large networks."
            },
            "slug": "Large-Deviation-Methods-for-Approximate-Inference-Kearns-Saul",
            "title": {
                "fragments": [],
                "text": "Large Deviation Methods for Approximate Probabilistic Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Using methods from large deviation theory, rigorous bounds on marginal probabilities such as Pr[children] are derived and rates of convergence for the accuracy of the authors' bounds as a function of network size are proved."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 117
                            }
                        ],
                        "text": "For this broader perspective, see, for example, Lauritzen (1996), Gilks et al. (1996), Neal (1996), Frey (1998), and Jordan (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60578841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c9529259e180dea589447d9b7414a998286e1c2",
            "isKey": false,
            "numCitedBy": 1466,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 Inference: introduction to inference for Bayesian networks, Robert Cowell advanced inference in Bayesian networks, Robert Cowell inference in Bayesian networks using nested junction trees, Uffe Kjoerulff bucket elimination - a unifying framework for probabilistic inference, R. Dechter an introduction to variational methods for graphical models, Michael I. Jordan et al improving the mean field approximation via the use of mixture distributions, Tommi S. Jaakkola and Michael I. Jordan introduction to Monte Carlo methods, D.J.C. MacKay suppressing random walls in Markov chain Monte Carlo using ordered overrelaxation, Radford M. Neal. Part 2 Independence: chain graphs and symmetric associations, Thomas S. Richardson the multiinformation function as a tool for measuring stochastic dependence, M. Studeny and J. Vejnarova. Part 3 Foundations for learning: a tutorial on learning with Bayesian networks, David Heckerman a view of the EM algorithm that justifies incremental, sparse and other variants, Radford M. Neal and Geoffrey E. Hinton. Part 4 Learning from data: latent variable models, Christopher M. Bishop stochastic algorithms for exploratory data analysis - data clustering and data visualization, Joachim M. Buhmann learning Bayesian networks with local structure, Nir Friedman and Moises Goldszmidt asymptotic model selection for directed networks with hidden variables, Dan Geiger et al a hierarchical community of experts, Geoffrey E. Hinton et al an information-theoretic analysis of hard and soft assignment methods for clustering, Michael J. Kearns et al learning hybrid Bayesian networks from data, Stefano Monti and Gregory F. Cooper a mean field learning algorithm for unsupervised neural networks, Lawrence Saul and Michael Jordan edge exclusion tests for graphical Gaussian models, Peter W.F. Smith and Joe Whittaker hepatitis B - a case study in MCMC, D.J. Spiegelhalter et al prediction with Gaussian processes - from linear regression to linear prediction and beyond, C.K.I. Williams."
            },
            "slug": "Learning-in-Graphical-Models-Jordan",
            "title": {
                "fragments": [],
                "text": "Learning in Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper presents an introduction to inference for Bayesian networks and a view of the EM algorithm that justifies incremental, sparse and other variants, as well as an information-theoretic analysis of hard and soft assignment methods for clustering."
            },
            "venue": {
                "fragments": [],
                "text": "NATO ASI Series"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 193
                            }
                        ],
                        "text": "Alternatively, if the number of assessments made is insufficient to specify a joint distribution uniquely, it has been suggested that the distribution be completed by maximum entropy arguments (Nilsson 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9800575,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "35bbc5ce402e88705e6e599f9aa45f8889b9e369",
            "isKey": false,
            "numCitedBy": 1331,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-Logic-Nilsson",
            "title": {
                "fragments": [],
                "text": "Probabilistic Logic"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4470043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dda5aad027477d46903384228b6120d09af2432",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we describe a way to propagate belief functions in certain kinds of trees using only local computations. This scheme generalizes the computational scheme proposed by Shafer and Logan ' for diagnostic trees of the type studied by Gordon and Shortliffe2,3 and the slightly more general scheme proposed by Shafer4 for hierarchical evidence. It also generalizes the computational scheme proposed by Pearl5 for Bayesian causal trees. Pearl's causal trees and Gordon and Shortliffe's diagnostic trees are both ways of breaking down the evidence that bears on a large problem into smaller items of evidence that bear on smaDler parts of the problem so that these smaller problems can be dealt with one at a time. This localization of effort is often essential to make the process of probability judgment feasible, both for the person who is making probability judgments and for the machine that is combining them. The basic structure for our scheme is a type of tree that generalizes both Pearl's and Gordon and Shortliffe's trees. Trees of this type permit localized computation in Pearl's sense. They are based on qualitative judgments of conditional independence. We believe that the scheme we describe here will prove useful in expert systems. It is now clear that the successful propagation of probability or certainty factors in expert systems requires much more structure than can be provided in a pure production-system framework. Bayesian schemes, on the other hand, often make unrealistic demands for structure. The propagation of belief functions in trees and more general networks occupies a middle ground where some sensible and useful things can be done. We would like to emphasize that the basic idea of local computation for propagating probabilities is Judea Pearl's. It is an innovative idea; we do not believe that it can be found in the Bayesian literature prior to Pearl's work. We see our contribution as extending Pearl's idea from Bayesian probabilities to belief functions. We wil describe the scheme proposed by Pearl5 for Bayesian causal trees. Then, we will describe the scheme proposed by Shafer and Logan I for diagnostic trees, and, afterwards, as a background to our own scheme, we will describe qualitative Markov trees. Finaly, we wil describe our belieffunction scheme, which has Pearl's and Shafer and Logan's schemes as special cases."
            },
            "slug": "Propagating-Belief-Functions-with-Local-Shenoy-Shafer",
            "title": {
                "fragments": [],
                "text": "Propagating Belief Functions with Local Computations"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A way to propagate belief functions in certain kinds of trees using only local computations, which generalizes the computational scheme proposed by Pearl5 for Bayesian causal trees and describes qualitative Markov trees."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Expert"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714284"
                        ],
                        "name": "P. Sebastiani",
                        "slug": "P.-Sebastiani",
                        "structuredName": {
                            "firstName": "Paola",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sebastiani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750921"
                        ],
                        "name": "M. Ramoni",
                        "slug": "M.-Ramoni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Ramoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ramoni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1435692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89c321cba1301a6336c717b0c139eedf82363cfd",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a decision theoretic formulation of learning the graphical structure of a Bayesian Belief Network from data. This framework subsumes the standard Bayesian approach of choosing the model with the largest posterior probability as the solution of a decision problem with a 0-1 loss function and allows the use of more general loss functions able to trade-off the complexity of the selected model and the error of choosing an over-simplified model. A new class of loss functions, called disintegrable, is introduced, to allow the decision problem to match the decomposability of the graphical model. With this class of loss functions, the optimal solution to the decision problem can be found using an efficient bottom-up search strategy."
            },
            "slug": "Decision-Theoretic-Foundations-of-Graphical-Model-Sebastiani-Ramoni",
            "title": {
                "fragments": [],
                "text": "Decision Theoretic Foundations of Graphical Model Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This framework subsumes the standard Bayesian approach of choosing the model with the largest posterior probability as the solution of a decision problem with a 0-1 loss function and allows the use of more general loss functions able to trade-off the complexity of the selected model and the error of choosing an over-simplified model."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152674014"
                        ],
                        "name": "Jin H. Kim",
                        "slug": "Jin-H.-Kim",
                        "structuredName": {
                            "firstName": "Jin",
                            "lastName": "Kim",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin H. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1907708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8d16924d37ac2ad2fe23e641673f9f2b5434733",
            "isKey": false,
            "numCitedBy": 398,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a representation of evidential relationships which permits updating of belief in two simultaneous modes: causal (i. e. top-down) and diagnostic (i.e. bottom-up). It extends the hierarchical tree representation by allowing multiple causes to a given manifestation. We develop an updating scheme that obeys the axioms of probability, is computationally efficient, and is compatible with experts reasoning. The belief parameters of each variable are defined and updated by those of its neighbors in such a way that the impact of each new evidence propagates and settles through the network in a single pass."
            },
            "slug": "A-Computational-Model-for-Causal-and-Diagnostic-in-Kim-Pearl",
            "title": {
                "fragments": [],
                "text": "A Computational Model for Causal and Diagnostic Reasoning in Inference Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A representation of evidential relationships which permits updating of belief in two simultaneous modes: causal and diagnostic is introduced, which extends the hierarchical tree representation by allowing multiple causes to a given manifestation."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 192
                            }
                        ],
                        "text": "In influence diagrams the required probabilities are found during the solution process by arc-reversals and barren node eliminations, the standard processes of solution via influence diagrams (Shachter 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 155
                            }
                        ],
                        "text": "Originally developed as a structuring tool, the development of algorithms for their evaluation (using barren node elimination and arc-reversal) came later (Olmsted 1983; Shachter 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 45
                            }
                        ],
                        "text": "(1994), the latter taking influence diagrams (Howard and Matheson 1984; Shachter 1986) as their starting point, though both approaches have much in common with the valuation network formulation advocated earlier by Shenoy (1992)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5770960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e0daca0acc6ee3baf7573fe2e2b3cc94276e7f4",
            "isKey": false,
            "numCitedBy": 1287,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An influence diagram is a graphical structure for modeling uncertain variables and decisions and explicitly revealing probabilistic dependence and the flow of information. It is an intuitive framework in which to formulate problems as perceived by decision makers and to incorporate the knowledge of experts. At the same time, it is a precise description of information that can be stored and manipulated by a computer. We develop an algorithm that can evaluate any well-formed influence diagram and determine the optimal policy for its decisions. Since the diagram can be analyzed directly, there is no need to construct other representations such as a decision tree. As a result, the analysis can be performed using the decision maker's perspective on the problem. Questions of sensitivity and the value of information are natural and easily posed. Modifications to the model suggested by such analyses can be made directly to the problem formulation, and then evaluated directly."
            },
            "slug": "Evaluating-Influence-Diagrams-Shachter",
            "title": {
                "fragments": [],
                "text": "Evaluating Influence Diagrams"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm is developed that can evaluate any well-formed influence diagram and determine the optimal policy for its decisions and can be performed using the decision maker's perspective on the problem."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1840562"
                        ],
                        "name": "R. Kass",
                        "slug": "R.-Kass",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Kass",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804386"
                        ],
                        "name": "A. Raftery",
                        "slug": "A.-Raftery",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Raftery",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Raftery"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 60
                            }
                        ],
                        "text": "Various approximations to this integral have been suggested (Kass and Raftery 1995; Heckerman 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 2
                            }
                        ],
                        "text": ", Kass and Raftery (1995)) in favour of the hypothesis that the expert\u2019s prior is the more appropriate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17191147,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "42d671ae17a611ac474cb39f59f4cf31f65b51ef",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 189,
            "paperAbstract": {
                "fragments": [],
                "text": "In a 1935 paper, and in his book Theory of Probability, Jeffreys developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpiece was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes factor as a practical tool of applied statistics. In this paper we review and discuss the uses of Bayes factors in the context of five scientific applications. The points we emphasize are: from Jeffreys's Bayesian point of view, the purpose of hypothesis testing is to evaluate the evidence in favor of a scientific theory; Bayes factors offer a way of evaluating evidence in favor of a null hypothesis; Bayes factors provide a way of incorporating external information into the evaluation of evidence about a hypothesis; Bayes factors are very general, and do not require alternative models to be nested; several techniques are available for computing Bayes factors, including asymptotic approximations which are easy to compute using the output from standard packages that maximize likelihoods; in \"non-standard\" statistical models that do not satisfy common regularity conditions, it can be technically simpler to calculate Bayes factors than to derive non-Bayesian significance tests; the Schwarz criterion (or BIC) gives a crude approximation to the logarithm of the Bayes factor, which is easy to use and does not require evaluation of prior distributions; when one is interested in estimation or prediction, Bayes factors may be converted to weights to be attached to various models so that a composite estimate or prediction may be obtained that takes account of structural or model uncertainty; algorithms have been proposed that allow model uncertainty to be taken into account when the class of models initially considered is very large; Bayes factors are useful for guiding an evolutionary model-building process; and, finally, it is important, and feasible, to assess the sensitivity of conclusions to the prior distributions used."
            },
            "slug": "Bayes-factors-and-model-uncertainty-Kass-Raftery",
            "title": {
                "fragments": [],
                "text": "Bayes factors and model uncertainty"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper reviews and discusses the uses of Bayes factors in the context of five scientific applications and suggests that it is important, and feasible, to assess the sensitivity of conclusions to the prior distributions used."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47915356"
                        ],
                        "name": "M. Shwe",
                        "slug": "M.-Shwe",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Shwe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shwe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684231"
                        ],
                        "name": "Blackford Middleton",
                        "slug": "Blackford-Middleton",
                        "structuredName": {
                            "firstName": "Blackford",
                            "lastName": "Middleton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Blackford Middleton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3009522"
                        ],
                        "name": "M. Henrion",
                        "slug": "M.-Henrion",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Henrion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Henrion"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145479841"
                        ],
                        "name": "E. Horvitz",
                        "slug": "E.-Horvitz",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Horvitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Horvitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21059200"
                        ],
                        "name": "H. Lehmann",
                        "slug": "H.-Lehmann",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Lehmann",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lehmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726406"
                        ],
                        "name": "G. Cooper",
                        "slug": "G.-Cooper",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Cooper",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 50
                            }
                        ],
                        "text": "elicited (Pathfinder), and \u2018noisy\u2013or gates\u2019 (QMR) (Shwe et al. 1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 48
                            }
                        ],
                        "text": "Examples include a probabilistic reconstruction (Shwe et al. 1991) of the QMR/Internist system for general medical diagnosis (Miller et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2279911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a06b0667e6b5fb30da8d3fb57f1c3d925023bfaf",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In Part I of this two-part series, we report the design of a probabilistic reformulation of the Quick Medical Reference (QMR) diagnostic decision-support tool. We describe a two-level multiply connected belief-network representation of the QMR knowledge base of internal medicine. In the belief-network representation of the QMR knowledge base, we use probabilities derived from the QMR disease profiles, from QMR imports of findings, and from National Center for Health Statistics hospital-discharge statistics. We use a stochastic simulation algorithm for inference on the belief network. This algorithm computes estimates of the posterior marginal probabilities of diseases given a set of findings. In Part II of the series, we compare the performance of QMR to that of our probabilistic system on cases abstracted from continuing medical education materials from Scientific American Medicine. In addition, we analyze empirically several components of the probabilistic model and simulation algorithm."
            },
            "slug": "Probabilistic-diagnosis-using-a-reformulation-of-I.-Shwe-Middleton",
            "title": {
                "fragments": [],
                "text": "Probabilistic diagnosis using a reformulation of the INTERNIST-1/QMR knowledge base. I. The probabilistic model and inference algorithms."
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The design of a probabilistic reformulation of the Quick Medical Reference (QMR) diagnostic decision-support tool is reported and a two-level multiply connected belief-network representation of the QMR knowledge base of internal medicine is described."
            },
            "venue": {
                "fragments": [],
                "text": "Methods of information in medicine"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 23255286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b396da26c275f97dd0dd068ac53cc1f454c91bce",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new method for representing and solving Bayesian decision problems. The representation is called a valuation-based system and has some similarities to influence diagrams. However, unlike influence diagrams which emphasize conditional independence among random variables, valuation-based systems emphasize factorizations of joint probability distributions. Also, whereas influence diagram representation allows only conditional probabilities, valuation-based system representation allows all probabilities. The solution method is a hybrid of local computational methods for the computation of marginals of joint probability distributions and the local computational methods for discrete optimization problems. We briefly compare our representation and solution methods to those of influence diagrams."
            },
            "slug": "Valuation-Based-Systems-for-Bayesian-Decision-Shenoy",
            "title": {
                "fragments": [],
                "text": "Valuation-Based Systems for Bayesian Decision Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A new method for representing and solving Bayesian decision problems is proposed, called a valuation-based system and has some similarities to influence diagrams, but unlike influence diagrams which emphasize conditional independence among random variables, valuation- based systems emphasize factorizations of joint probability distributions."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733387"
                        ],
                        "name": "Ramon Sang\u00fcesa",
                        "slug": "Ramon-Sang\u00fcesa",
                        "structuredName": {
                            "firstName": "Ramon",
                            "lastName": "Sang\u00fcesa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramon Sang\u00fcesa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742700"
                        ],
                        "name": "U. Cort\u00e9s",
                        "slug": "U.-Cort\u00e9s",
                        "structuredName": {
                            "firstName": "Ulises",
                            "lastName": "Cort\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Cort\u00e9s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17362767,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "e2add27d9c690abb8a9a3da7b5dc16feca08296f",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": "Causal concepts play a crucial role in many reasoning tasks. Organised as a model revealing the causal structure of a domain, they can guide inference through relevant knowledge. This is an especially difficult kind of knowledge to acquire, so some methods for automating the induction of causal models from data have been put forth. Here we review those that have a graph representation. Most work has been done on the problem of recovering belief nets from data but some extensions are appearing that claim to exhibit a true causal semantics. We will review the analogies between belief networks and \u201ctrue\u201d causal networks and to what extent methods for learning belief networks can be used in learning causal representations. Some new results in recovering possibilistic causal networks will also be presented."
            },
            "slug": "Learning-Causal-Networks-from-Data:-A-Survey-and-a-Sang\u00fcesa-Cort\u00e9s",
            "title": {
                "fragments": [],
                "text": "Learning Causal Networks from Data: A Survey and a New Algorithm for Recovering Possibilistic Causal Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is reviewed the analogies between belief networks and \u201ctrue\u201d causal networks and to what extent methods for learning belief networks can be used in learning causal representations and some new results in recovering possibilistic causal networks will be presented."
            },
            "venue": {
                "fragments": [],
                "text": "AI Commun."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46558286"
                        ],
                        "name": "S. K. Andersen",
                        "slug": "S.-K.-Andersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Kj\u00e6r"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679873"
                        ],
                        "name": "Peter Szolovits",
                        "slug": "Peter-Szolovits",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Szolovits",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Szolovits"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 319,
                                "start": 297
                            }
                        ],
                        "text": "Current research concerning propagation in discrete probabilistic networks is concerned with studying and improving the efficiency of one or more variants of the propagation algorithms (Kj\u00e6rulff 1998; Shenoy 1997; Madsen and Jensen 1998), or exploiting cutset conditioning to trade time for space (Shachter et al. 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17602100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "767e4b4cc2fe67f12e7cffccf824f64803f39207",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Global-Conditioning-for-Probabilistic-Inference-in-Shachter-Andersen",
            "title": {
                "fragments": [],
                "text": "Global Conditioning for Probabilistic Inference in Belief Networks"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 94
                            }
                        ],
                        "text": "Note that another consequence is that the axioms of Shafer and Shenoy (1990) or Lauritzen and Jensen (1997) are not fulfilled."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 104
                            }
                        ],
                        "text": "Axioms validating the specific propagation scheme described in this chapter were given by Lauritzen and Jensen (1997). We describe below some useful applications of this more general approach to propagation in expert systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 114
                            }
                        ],
                        "text": "Another trend is the development of variants of the algorithm that perform slightly different or additional tasks (Jensen 1995), or that work in a somewhat modified way (Bloemeke and Valtorta 1998) or approximately (Kj\u00e6rulff 1993; Jensen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5459365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90da13af5b76b90776e5e38229870f376f33accf",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider the situation where some evidence e has been entered to a Bayesian network. When performing conflict analysis, sensitivity analysis, or when answering questions like \"What if the finding on X had been y instead of x?\", you need probabilities P(e\u2032|h) where e\u2032 is a subset of e, and h is a configuration of a (possibly empty) set of variables. \n \nCautious propagation is a modification of HUGIN propagation into a Shafer-Shenoy-like architecture. It is less efficient than HUGIN propagation; however, it provides easy access to P(e\u2032|h) for a great deal of relevant subsets e\u2032."
            },
            "slug": "Cautious-Propagation-in-Bayesian-Networks-Jensen",
            "title": {
                "fragments": [],
                "text": "Cautious Propagation in Bayesian Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Cautious propagation is a modification of HUGIN propagation into a Shafer-Shenoy-like architecture and provides easy access to P(e\u2032|h) for a great deal of relevant subsets e\u2032."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 256
                            }
                        ],
                        "text": "Instead other ad hoc rules for manipulating and combining certainty factors were developed, or alternative measures of uncertainty were developed or applied, that allowed modularity to be retained, for example fuzzy logic (Zadeh 1983) and belief functions (Dempster 1967; Shafer 1976)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 131
                            }
                        ],
                        "text": "Further application areas of interest in artificial intelligence include concepts of conditional independence for belief functions (Shafer 1976) and various purely logical structures such as, e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 27
                            }
                        ],
                        "text": "The approach of Shenoy and Shafer (1990) is not affected by such problems because their propagation scheme avoids division operations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27862354,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4cd91c51098783ec972f6a0ab430cacdd634a5b2",
            "isKey": false,
            "numCitedBy": 14560,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Both in science and in practical affairs we reason by combining facts only inconclusively supported by evidence. Building on an abstract understanding of this process of combination, this book constructs a new theory of epistemic probability. The theory draws on the work of A. P. Dempster but diverges from Depster's viewpoint by identifying his \"lower probabilities\" as epistemic probabilities and taking his rule for combining \"upper and lower probabilities\" as fundamental. The book opens with a critique of the well-known Bayesian theory of epistemic probability. It then proceeds to develop an alternative to the additive set functions and the rule of conditioning of the Bayesian theory: set functions that need only be what Choquet called \"monotone of order of infinity.\" and Dempster's rule for combining such set functions. This rule, together with the idea of \"weights of evidence,\" leads to both an extensive new theory and a better understanding of the Bayesian theory. The book concludes with a brief treatment of statistical inference and a discussion of the limitations of epistemic probability. Appendices contain mathematical proofs, which are relatively elementary and seldom depend on mathematics more advanced that the binomial theorem."
            },
            "slug": "A-Mathematical-Theory-of-Evidence-Shafer",
            "title": {
                "fragments": [],
                "text": "A Mathematical Theory of Evidence"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This book develops an alternative to the additive set functions and the rule of conditioning of the Bayesian theory: set functions that need only be what Choquet called \"monotone of order of infinity.\" and Dempster's rule for combining such set functions."
            },
            "venue": {
                "fragments": [],
                "text": "A Mathematical Theory of Evidence"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 57
                            }
                        ],
                        "text": "9) is difficult, but some specific results are available (Cowell 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18268271,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1ef2c50e015da26f67086547f79b2fa30ad45017",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a Bayesian network of discrete random variables with a hyper-Dirichlet prior, a method is proposed for assigning Dirichlet priors to the conditional probabilities of structurally different networks. It defines a distance measure between priors which is to be minimized for the assignment process. Intuitively one would expect that if two models priors are to qualify as being 'close' in some sense, then their posteriors should also be nearby after an observation. However one does not know in advance what will be observed next. Thus we are led to propose an expectation of Kullback-Leibler distances over all possible next observations to define a measure of distance between priors. In conjunction with the additional assumptions of global and local independence of the parameters, a number of theorems emerge which are usually taken as reasonable assumptions in the Bayesian network literature. A simple example is given to illustrate the technique."
            },
            "slug": "On-Compatible-Priors-for-Bayesian-Networks-Cowell",
            "title": {
                "fragments": [],
                "text": "On Compatible Priors for Bayesian Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Given a Bayesian network of discrete random variables with a hyper-Dirichlet prior, a method is proposed for assigning Dirichlet priors to the conditional probabilities of structurally different networks which defines a distance measure between priors which is to be minimized for the assignment process."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143648560"
                        ],
                        "name": "P. Spirtes",
                        "slug": "P.-Spirtes",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Spirtes",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Spirtes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3058012"
                        ],
                        "name": "C. Glymour",
                        "slug": "C.-Glymour",
                        "structuredName": {
                            "firstName": "Clark",
                            "lastName": "Glymour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Glymour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2758080"
                        ],
                        "name": "R. Scheines",
                        "slug": "R.-Scheines",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Scheines",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Scheines"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 145
                            }
                        ],
                        "text": "For example, standard statistical hypothesis testing procedures based on likelihood ratio tests can be used for selecting among graphical models (Whittaker 1990; Spirtes et al. 1993; Edwards 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 146
                            }
                        ],
                        "text": "However, latent variable models may also impose probabilistic constraints over and above those expressible as conditional independence properties (Spirtes et al. 1993; Settimi and Smith 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117765107,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b3b9fe128e6849d59a26d7ceda57baad2524815",
            "isKey": false,
            "numCitedBy": 3255,
            "numCiting": 154,
            "paperAbstract": {
                "fragments": [],
                "text": "What assumptions and methods allow us to turn observations into causal knowledge, and how can even incomplete causal knowledge be used in planning and prediction to influence and control our environment? In this book Peter Spirtes, Clark Glymour, and Richard Scheines address these questions using the formalism of Bayes networks, with results that have been applied in diverse areas of research in the social, behavioral, and physical sciences. The authors show that although experimental and observational study designs may not always permit the same inferences, they are subject to uniform principles. They axiomatize the connection between causal structure and probabilistic independence, explore several varieties of causal indistinguishability, formulate a theory of manipulation, and develop asymptotically reliable procedures for searching over equivalence classes of causal models, including models of categorical data and structural equation models with and without latent variables. The authors show that the relationship between causality and probability can also help to clarify such diverse topics in statistics as the comparative power of experimentation versus observation, Simpson's paradox, errors in regression models, retrospective versus prospective sampling, and variable selection. The second edition contains a new introduction and an extensive survey of advances and applications that have appeared since the first edition was published in 1993."
            },
            "slug": "Causation,-prediction,-and-search-Spirtes-Glymour",
            "title": {
                "fragments": [],
                "text": "Causation, prediction, and search"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors axiomatize the connection between causal structure and probabilistic independence, explore several varieties of causal indistinguishability, formulate a theory of manipulation, and develop asymptotically reliable procedures for searching over equivalence classes of causal models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775921"
                        ],
                        "name": "Uffe Kj\u00e6rulff",
                        "slug": "Uffe-Kj\u00e6rulff",
                        "structuredName": {
                            "firstName": "Uffe",
                            "lastName": "Kj\u00e6rulff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uffe Kj\u00e6rulff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120529537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0de6e9beaa984d31a34b5f230d2398e14cbe5aeb",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the applicability of a Monte Carlo technique known as \u2018simulated annealing\u2019 to achieve optimum or sub-optimum decompositions of probabilistic networks under bounded resources. High-quality decompositions are essential for performing efficient inference in probabilistic networks. Optimum decomposition of probabilistic networks is known to be NP-hard (Wen, 1990). The paper proves that cost-function changes can be computed locally, which is essential to the efficiency of the annealing algorithm. Pragmatic control schedules which reduce the running time of the annealing algorithm are presented and evaluated. Apart from the conventional temperature parameter, these schedules involve the radius of the search space as a new control parameter. The evaluation suggests that the inclusion of this new parameter is important for the success of the annealing algorithm for the present problem."
            },
            "slug": "Optimal-decomposition-of-probabilistic-networks-by-Kj\u00e6rulff",
            "title": {
                "fragments": [],
                "text": "Optimal decomposition of probabilistic networks by simulated annealing"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "This paper investigates the applicability of a Monte Carlo technique known as \u2018simulated annealing\u2019 to achieve optimum or sub-optimum decompositions of probabilistic networks under bounded resources and proves that cost-function changes can be computed locally."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724065"
                        ],
                        "name": "D. M. Chickering",
                        "slug": "D.-M.-Chickering",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chickering",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Chickering"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 168
                            }
                        ],
                        "text": "The technical issues then centre on constructing suitable approximations for scores based on incompletely observed cases, exactly as in the context of latent variables (Chickering and Heckerman 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 254734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41e77b3fc31f1c4898ad8670f47c61a2ee3f4700",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine asymptotic approximations for the marginal likelihood of incomplete data given a Bayesian network. We consider the Laplace approximation and the less accurate but more efficient BIC/MDL approximation. We also consider approximations proposed by Draper (1993) and Cheeseman and Stutz (1995). These approximations are as efficient as BIC/MDL, but their accuracy has not been studied in any depth. We compare the accuracy of these approximations under the assumption that the Laplace approximation is the most accurate. In experiments using synthetic data generated from discrete naive-Bayes models having a hidden root node, we find that (1) the BIC/MDL measure is the least accurate, having a bias in favor of simple models, and (2) the Draper and CS measures are the most accurate, having a bias in favor of simple and complex models, respectively."
            },
            "slug": "Efficient-Approximations-for-the-Marginal-of-Data-a-Chickering-Heckerman",
            "title": {
                "fragments": [],
                "text": "Efficient Approximations for the Marginal Likelihood of Incomplete Data Given a Bayesian Network"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In experiments using synthetic data generated from discrete naive-Bayes models having a hidden root node, it is found that the BIC/MDL measure is the least accurate and the Draper and CS measures are the most accurate, having a bias in favor of simple and complex models, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145392702"
                        ],
                        "name": "P. Green",
                        "slug": "P.-Green",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Green",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145880785"
                        ],
                        "name": "D. Higdon",
                        "slug": "D.-Higdon",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Higdon",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Higdon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3069617"
                        ],
                        "name": "K. Mengersen",
                        "slug": "K.-Mengersen",
                        "structuredName": {
                            "firstName": "Kerrie",
                            "lastName": "Mengersen",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mengersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 36
                            }
                        ],
                        "text": "1997) and agricultural field trials (Besag et al. 1995)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 120361769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41fb79ea7f0fcde0f2f55a2979446a28a733b6b9",
            "isKey": false,
            "numCitedBy": 1055,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov chain Monte Carlo (MCMC) methods have been used extensively in statistical physics over the last 40 years, in spatial statistics for the past 20 and in Bayesian image analysis over the last decade. In the last five years, MCMC has been introduced into significance testing, general Bayesian inference and maximum likelihood estimation. This paper presents basic methodology of MCMC, emphasizing the Bayesian paradigm, conditional probability and the intimate relationship with Markov random fields in spatial statistics. Hastings algorithms are discussed, including Gibbs, Metropolis and some other variations. Pairwise difference priors are described and are used subsequently in three Bayesian applications, in each of which there is a pronounced spatial or temporal aspect to the modeling. The examples involve logistic regression in the presence of unobserved covariates and ordinal factors; the analysis of agricultural field experiments, with adjustment for fertility gradients; and processing of low-resolution medical images obtained by a gamma camera. Additional methodological issues arise in each of these applications and in the Appendices. The paper lays particular emphasis on the calculation of posterior probabilities and concurs with others in its view that MCMC facilitates a fundamental breakthrough in applied Bayesian modeling."
            },
            "slug": "Bayesian-Computation-and-Stochastic-Systems-Besag-Green",
            "title": {
                "fragments": [],
                "text": "Bayesian Computation and Stochastic Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Basic methodology of MCMC is presented, emphasizing the Bayesian paradigm, conditional probability and the intimate relationship with Markov random fields in spatial statistics, and particular emphasis on the calculation of posterior probabilities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750921"
                        ],
                        "name": "M. Ramoni",
                        "slug": "M.-Ramoni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Ramoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ramoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714284"
                        ],
                        "name": "P. Sebastiani",
                        "slug": "P.-Sebastiani",
                        "structuredName": {
                            "firstName": "Paola",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sebastiani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27363380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5e0f244b2d70a0dc753b80cb8e0526dc9687688",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Current methods to learn Bayesian Belief Networks (bbns) from incomplete databases share the common assumption that the unreported data are missing at random. This paper describes a method \u2014 called Bound and Collapse (bc) \u2014 to learn bbns from incomplete databases which allows the analyst to efficiently integrate information provided by the database and exogenous knowledge about the pattern of missing data. bc starts by bounding the set of estimates consistent with the information conveyed by the database and then collapses the resulting set to a point via a convex combination of the extreme points, with weights depending on the assumed pattern of missing data. Experiments comparing bc to Gibbs Sampling are provided."
            },
            "slug": "The-Use-of-Exogenous-Knowledge-to-Learn-Bayesian-Ramoni-Sebastiani",
            "title": {
                "fragments": [],
                "text": "The Use of Exogenous Knowledge to Learn Bayesian Networks from Incomplete Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A method \u2014 called Bound and Collapse (bc) \u2014 to learn Bayesian Belief Networks from incomplete databases which allows the analyst to efficiently integrate information provided by the database and exogenous knowledge about the pattern of missing data."
            },
            "venue": {
                "fragments": [],
                "text": "IDA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144594306"
                        ],
                        "name": "Wai Lam",
                        "slug": "Wai-Lam",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736882"
                        ],
                        "name": "F. Bacchus",
                        "slug": "F.-Bacchus",
                        "structuredName": {
                            "firstName": "Fahiem",
                            "lastName": "Bacchus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bacchus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Lauritzen and Wermuth (1989), Wermuth and Lauritzen (1990) and Lauritzen (1996) consider the problem of selecting a chain graph structure based on complete data, based on maximum likelihood approach and substantive knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 148
                            }
                        ],
                        "text": "The Minimum Description Length (MDL) principle or Stochastic Complexity criterion (Rissanen 1987) has also been suggested as a model scoring device (Lam and Bacchus 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 622909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3ada89151b8f2582f48dd2c086f56727f4693fd",
            "isKey": false,
            "numCitedBy": 861,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "A new approach for learning Bayesian belief networks from raw data is presented. The approach is based on Rissanen's minimal description length (MDL) principle, which is particularly well suited for this task. Our approach does not require any prior assumptions about the distribution being learned. In particular, our method can learn unrestricted multiply\u2010connected belief networks. Furthermore, unlike other approaches our method allows us to trade off accuracy and complexity in the learned model. This is important since if the learned model is very complex (highly connected) it can be conceptually and computationally intractable. In such a case it would be preferable to use a simpler model even if it is less accurate. The MDL principle offers a reasoned method for making this trade\u2010off. We also show that our method generalizes previous approaches based on Kullback cross\u2010entropy. Experiments have been conducted to demonstrate the feasibility of the approach."
            },
            "slug": "LEARNING-BAYESIAN-BELIEF-NETWORKS:-AN-APPROACH-ON-Lam-Bacchus",
            "title": {
                "fragments": [],
                "text": "LEARNING BAYESIAN BELIEF NETWORKS: AN APPROACH BASED ON THE MDL PRINCIPLE"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A new approach for learning Bayesian belief networks from raw data is presented, based on Rissanen's minimal description length (MDL) principle, which can learn unrestricted multiply\u2010connected belief networks and allows for trade off accuracy and complexity in the learned model."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46730757"
                        ],
                        "name": "C. Goutis",
                        "slug": "C.-Goutis",
                        "structuredName": {
                            "firstName": "Constantinos",
                            "lastName": "Goutis",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Goutis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 57
                            }
                        ],
                        "text": "For the numerical specification we take the numbers from Goutis (1995). The values of probabilities and utilities are given in Table 8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 53
                            }
                        ],
                        "text": "An alternative method avoiding this increase, due to Goutis (1995), is adopted here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 96
                            }
                        ],
                        "text": "We now present a second, larger, example which is the Asia example from page 20, as extended by Goutis (1995) to include two decisions, which we shall refer to as Dec-Asia:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12192002,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "4e4372a6b30b831558d60e4f86011b60ea00cf85",
            "isKey": true,
            "numCitedBy": 13,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for solving multistage decision analysis problems under uncertainty is proposed. The method is appropriate when the utility function can be decomposed to smaller factors and the joint probability function of the random variables also factorises to probabilities defined in smaller subsets of random variables. We use the factorisations and the corresponding graphical structure of the problem to compute efficiently the expected utility at each stage, All computations are local in the sense that they involve a small number of variables. Then, using dynamic programming, we can identify an optimum strategy, depending on the available knowledge at the time that decisions are taken. The algorithm is illustrated by a worked example, and a comparison with existing approaches is included. >"
            },
            "slug": "A-graphical-method-for-solving-a-decision-analysis-Goutis",
            "title": {
                "fragments": [],
                "text": "A graphical method for solving a decision analysis problem"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A method for solving multistage decision analysis problems under uncertainty when the utility function can be decomposed to smaller factors and the joint probability function of the random variables also factorises to probabilities defined in smaller subsets of random variables."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2500179"
                        ],
                        "name": "R. Aleliunas",
                        "slug": "R.-Aleliunas",
                        "structuredName": {
                            "firstName": "Romas",
                            "lastName": "Aleliunas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Aleliunas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10627111,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "d013fa39fd5f67398dd9396141fef9470adfcc7b",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-summary-of-a-new-normative-theory-of-logic-Aleliunas",
            "title": {
                "fragments": [],
                "text": "A summary of a new normative theory of probabilistic logic"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775921"
                        ],
                        "name": "Uffe Kj\u00e6rulff",
                        "slug": "Uffe-Kj\u00e6rulff",
                        "structuredName": {
                            "firstName": "Uffe",
                            "lastName": "Kj\u00e6rulff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uffe Kj\u00e6rulff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 166
                            }
                        ],
                        "text": "The theory for Bayesian learning on undirected graphs or general chain graphs is less well developed, whereas the maximum likelihood theory is described in detail in Lauritzen (1996) and fully implemented in the software program CoCo (see Appendix C)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18464832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3ba4d6fdc472ed9716bd7fc0cbad9884659cc26",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Reduction-of-Computational-Complexity-in-Bayesian-Kj\u00e6rulff",
            "title": {
                "fragments": [],
                "text": "Reduction of Computational Complexity in Bayesian Networks Through Removal of Weak Dependences"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40404712"
                        ],
                        "name": "N. Harris",
                        "slug": "N.-Harris",
                        "structuredName": {
                            "firstName": "Nomi",
                            "lastName": "Harris",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144467804"
                        ],
                        "name": "K. Bull",
                        "slug": "K.-Bull",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Bull",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055175446"
                        ],
                        "name": "R. Franklin",
                        "slug": "R.-Franklin",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Franklin",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Franklin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 33
                            }
                        ],
                        "text": "For tree-like Bayesian networks, Sy (1993) developed a computation scheme based upon an algorithm by Pearl (1988) for finding the most probable configuration in such networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 80
                            }
                        ],
                        "text": "A very early variant of the basic propagation algorithm was derived and used by Thiele (1880), who derived the simplest special case of what is now known as the Kalman filter and smoother (Kalman and Bucy 1961); see Lauritzen (1981)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 97
                            }
                        ],
                        "text": "Other values have been tried but good predictive performance has been found with this assumption (Spiegelhalter et al. 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120966508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a048d768037d83b54f2da08e510247db655a88a",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We consider the problem of critiquing prior beliefs concerning the distribution of a discrete random variable in the light of a sequentially obtained sample. A topical application concerns a probabilistic expert system for the diagnosis of congenital heart disease, which requires specification of a large number of conditional probabilities that are initially imprecisely estimated by a suitable \u201cexpert.\u201d These prior beliefs may be formally updated as data become available, but it would seem essential to contrast the original expert assessments with the data obtained to quickly identify inappropriate subjective inputs. We consider both Bayes factor and significance testing techniques for such a prior/data comparison, both in nonsequential and sequential forms. The common basis as alternative standardizations of the logarithm of the predictive ordinate of the observed data is emphasised, and a Bayesian discrepancy statistic with a variety of interpretations provides a formal means of discounting the..."
            },
            "slug": "Empirical-evaluation-of-prior-beliefs-about-:-and-a-Spiegelhalter-Harris",
            "title": {
                "fragments": [],
                "text": "Empirical evaluation of prior beliefs about frequencies : methodology and a case study in congenital heart disease"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work considers the problem of critiquing prior beliefs concerning the distribution of a discrete random variable in the light of a sequentially obtained sample, and considers both Bayes factor and significance testing techniques for such a prior/data comparison, both in nonsequential and sequential forms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59696157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c915e4c2181bc39fc1e3d9ba6d6c7c99c6d82ab5",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Multivariate Probability. Probability Distributions Marginalization Conditionals Continuation Posterior Distributions Expectation Classifying Probability Distributions A Limitation 2. Construction Sequences. Multiplying Conditionals DAGs and Belief Nets Bubble Graphs Other Graphical Representations 3. Propagation in Join Trees. Variable-by-Variable Summing Out The Elementary Architecture The Shafer-Shenoy Architecture The Lauritzen-Spiegelhalter Architecture The Aalborg Architecture Collect and Distribute Scope and Alternatives 4. Resources and References. Meetings Software Books Review Articles Other Sources Index."
            },
            "slug": "Probabilistic-expert-systems-Shafer",
            "title": {
                "fragments": [],
                "text": "Probabilistic expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The aim of this monograph is to provide a Discussion of the Foundations of Probability Distributions and their Applications to Architecture."
            },
            "venue": {
                "fragments": [],
                "text": "CBMS-NSF regional conference series in applied mathematics"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057702866"
                        ],
                        "name": "Eric Bauer",
                        "slug": "Eric-Bauer",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Bauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 453,
                                "start": 0
                            }
                        ],
                        "text": "Bauer et al. (1997) also discussed ways to speed up the convergence of the EM algorithm. Ramoni and Sebastiani (1997b, 1997c) have proposed a batch learning method for analysing incomplete data for discrete models, which they called bound and collapse, in which upper and lower bounds are calculated and combined using prior information regarding the missing data mechanism to yield point estimates and credible intervals. Ramoni and Sebastiani (1997a) extended the method to structural learning (see Chapter 11)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 328,
                                "start": 68
                            }
                        ],
                        "text": "There are many general textbooks on graph theory: Harary (1972) and Berge (1973) are standard references. Chordal graphs are well-studied objects which appear under a variety of names, including triangulated and decomposable graphs, and also rigid circuit graphs (Dirac 1961). They are extensively dealt with in Golumbic (1980). Chain graphs were introduced by Lauritzen and Wermuth (1984); see also Lauritzen and Wermuth (1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 68
                            }
                        ],
                        "text": "There are many general textbooks on graph theory: Harary (1972) and Berge (1973) are standard references."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Bauer et al. (1997) also discussed ways to speed up the convergence of the EM algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 429,
                                "start": 68
                            }
                        ],
                        "text": "There are many general textbooks on graph theory: Harary (1972) and Berge (1973) are standard references. Chordal graphs are well-studied objects which appear under a variety of names, including triangulated and decomposable graphs, and also rigid circuit graphs (Dirac 1961). They are extensively dealt with in Golumbic (1980). Chain graphs were introduced by Lauritzen and Wermuth (1984); see also Lauritzen and Wermuth (1989). The notion of a graph decomposition has deep connections to many areas of mathematics (Lauritzen et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8047085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97016181c645b638859fb3cc7003e3c2f6cbde72",
            "isKey": true,
            "numCitedBy": 123,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper re-examines the problem of parameter estimation in Bayesian networks with missing values and hidden variables from the perspective of recent work in on-line learning [Kivinen & Warmuth, 1994]. We provide a unified framework for parameter estimation that encompasses both on-line learning, where the model is continuously adapted to new data cases as they arrive, and the more traditional batch learning, where a pre-accumulated set of samples is used in a one-time model selection process. In the batch case, our framework encompasses both the gradient projection algorithm and the EM algorithm for Bayesian networks. The framework also leads to new on-line and batch parameter update schemes, including a parameterized version of EM. We provide both empirical and theoretical results indicating that parameterized EM allows faster convergence to the maximum likelihood parameters than does standard EM."
            },
            "slug": "Update-Rules-for-Parameter-Estimation-in-Bayesian-Bauer-Koller",
            "title": {
                "fragments": [],
                "text": "Update Rules for Parameter Estimation in Bayesian Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper provides a unified framework for parameter estimation that encompasses both on-line learning and batch learning, and provides both empirical and theoretical results indicating that parameterized EM allows faster convergence to the maximum likelihood parameters than does standard EM."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881895"
                        ],
                        "name": "B. Sy",
                        "slug": "B.-Sy",
                        "structuredName": {
                            "firstName": "Bon",
                            "lastName": "Sy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 105
                            }
                        ],
                        "text": "Computer programs can be written, for example in languages such as LISP or Prolog, which manipulate such symbolic production rules and logic (see Lucas and van der Gaag (1991) for examples)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7309038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b44ec5571a373480c2256d8cc4649834526a1704",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-recurrence-local-computation-approach-towards-in-Sy",
            "title": {
                "fragments": [],
                "text": "A recurrence local computation approach towards ordering composite beliefs in bayesian belief networks"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Approx. Reason."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144999310"
                        ],
                        "name": "P. Larra\u00f1aga",
                        "slug": "P.-Larra\u00f1aga",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Larra\u00f1aga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Larra\u00f1aga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992012"
                        ],
                        "name": "Cindy M. H. Kuijpers",
                        "slug": "Cindy-M.-H.-Kuijpers",
                        "structuredName": {
                            "firstName": "Cindy",
                            "lastName": "Kuijpers",
                            "middleNames": [
                                "M.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cindy M. H. Kuijpers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37758035"
                        ],
                        "name": "M. Poza",
                        "slug": "M.-Poza",
                        "structuredName": {
                            "firstName": "Mikel",
                            "lastName": "Poza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Poza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40512454"
                        ],
                        "name": "R. Murga",
                        "slug": "R.-Murga",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Murga",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Murga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Lauritzen (1995) showed how evidence propagation on the junction tree can be exploited to perform the E-step of the EM algorithm for the discrete DAG models of Example 9."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 108
                            }
                        ],
                        "text": "This assumption can be relaxed, but then we have to use approximate methods in the specification phase, see Lauritzen (1992) for some suggestions; and also Gammerman et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 89
                            }
                        ],
                        "text": "In the second class, the matched-moment approximate learning scheme of Spiegelhalter and Lauritzen (1990) was employed to update probabilities sequentially."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18816623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f298ea31480136e1b254ffd397b7c0824f7b7078",
            "isKey": true,
            "numCitedBy": 98,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider the optimal decomposition of Bayesian networks. More concretely, we examine empirically the applicability of genetic algorithms to the problem of the triangulation of moral graphs. This problem constitutes the only difficult step in the evidence propagation algorithm of Lauritzen and Spiegelhalter (1988) and is known to be NP-hard (Wen, 1991). We carry out experiments with distinct crossover and mutation operators and with different population sizes, mutation rates and selection biasses. The results are analysed statistically. They turn out to improve the results obtained with most other known triangulation methods (Kj\u00e6rulff, 1990) and are comparable to results obtained with simulated annealing (Kj\u00e6rulff, 1990; Kj\u00e6rulff, 1992)."
            },
            "slug": "Decomposing-Bayesian-networks:-triangulation-of-the-Larra\u00f1aga-Kuijpers",
            "title": {
                "fragments": [],
                "text": "Decomposing Bayesian networks: triangulation of the moral graph with genetic algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The optimal decomposition of Bayesian networks is considered and the applicability of genetic algorithms to the problem of the triangulation of moral graphs is examined empirically."
            },
            "venue": {
                "fragments": [],
                "text": "Stat. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51962239"
                        ],
                        "name": "John P. Moussouris",
                        "slug": "John-P.-Moussouris",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moussouris",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John P. Moussouris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121299906,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "26593b3e9d20a98539538f47428a9ce2c150fda8",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper concerns random systems made up out of a finite collection of elements. We are interested in how a fixed structure of interactions reflects on the assignment of probabilities to overall states. In particular, we consider two simple models of random systems: one generalizing the notion of \u201cGibbs ensemble\u201d abstracted from statistical physics; the other, \u201cMarkov fields\u201d derived from the idea of a Markov chain. We give background for these two types, review proofs that they are in fact identical for systems with nonzero probabilities, and explore the new behavior that arises with constraints. Finally, we discuss unsolved problems and make suggestions for further work."
            },
            "slug": "Gibbs-and-Markov-random-systems-with-constraints-Moussouris",
            "title": {
                "fragments": [],
                "text": "Gibbs and Markov random systems with constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Two simple models of random systems made up out of a finite collection of elements are considered: one generalizing the notion of \u201cGibbs ensemble\u201d abstracted from statistical physics; the other, \u201cMarkov fields\u201d derived from the idea of a Markov chain."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145479841"
                        ],
                        "name": "E. Horvitz",
                        "slug": "E.-Horvitz",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Horvitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Horvitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287810"
                        ],
                        "name": "B. Nathwani",
                        "slug": "B.-Nathwani",
                        "structuredName": {
                            "firstName": "Bharat",
                            "lastName": "Nathwani",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Nathwani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 164
                            }
                        ],
                        "text": "The Pathfinder system for the diagnosis of lymph vertex pathology concerned over 60 diseases and required the specification of over 75,000 subjective probabilities (Heckerman et al. 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14672300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0d6eaab60a57a5416490d5026a78770a5da3d57",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Pathfinder is an expert system that assists surgical pathologists with the diagnosis of lymph-node diseases. The program is one of a growing number of normative expert systems that use probability and decision theory to acquire, represent, manipulate, and explain uncertain medical knowledge. In this article, we describe Pathfinder and our research in uncertain-reasoning paradigms that was stimulated by the development of the program. We discuss limitations with early decision-theoretic methods for reasoning under uncertainty and our initial attempts to use non-decision-theoretic methods. Then, we describe experimental and theoretical results that directed us to return to reasoning methods based in probability and decision theory."
            },
            "slug": "Toward-normative-expert-systems:-Part-I.-The-Heckerman-Horvitz",
            "title": {
                "fragments": [],
                "text": "Toward normative expert systems: Part I. The Pathfinder project."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article describes Pathfinder and research in uncertain-reasoning paradigms that was stimulated by the development of the program, and describes experimental and theoretical results that directed the authors to return to reasoning methods based in probability and decision theory."
            },
            "venue": {
                "fragments": [],
                "text": "Methods of information in medicine"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40484982"
                        ],
                        "name": "P. Cheeseman",
                        "slug": "P.-Cheeseman",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Cheeseman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cheeseman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87277825"
                        ],
                        "name": "J. Stutz",
                        "slug": "J.-Stutz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Stutz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stutz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 446,
                                "start": 121
                            }
                        ],
                        "text": "In connection with log-linear models for contingency tables, the algorithm was studied by Fuchs (1982) extending work of Chen and Fienberg (1974, 1976) and Hocking and Oxspring (1974). Generalized EM algorithms are discussed by Thiesson (1991). The EM algorithm can be slow to converge, but can be speeded up near the maximum using gradient descent methods, which can be performed locally (Russell et al. 1995; Thiesson 1995, 1997). Zhang (1996) showed that increases in efficiency for sequential learning, the EM algorithm, and gradient descent can be achieved by exploiting independence relationships."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 121
                            }
                        ],
                        "text": "In connection with log-linear models for contingency tables, the algorithm was studied by Fuchs (1982) extending work of Chen and Fienberg (1974, 1976) and Hocking and Oxspring (1974). Generalized EM algorithms are discussed by Thiesson (1991). The EM algorithm can be slow to converge, but can be speeded up near the maximum using gradient descent methods, which can be performed locally (Russell et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 124
                            }
                        ],
                        "text": "This model can be used as a basis for a clustering or unsupervised learning procedure, as embodied in the Autoclass program (Cheeseman and Stutz 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 121
                            }
                        ],
                        "text": "In connection with log-linear models for contingency tables, the algorithm was studied by Fuchs (1982) extending work of Chen and Fienberg (1974, 1976) and Hocking and Oxspring (1974). Generalized EM algorithms are discussed by Thiesson (1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1202,
                                "start": 125
                            }
                        ],
                        "text": "This model can be used as a basis for a clustering or unsupervised learning procedure, as embodied in the Autoclass program (Cheeseman and Stutz 1997). In a causal modelling setting, the Tetrad program (Glymour et al. 1987) infers the existence of hidden variables that can explain observed relationships. When we allow latent variables, we extend enormously the number and the complexity of the models that we can entertain. Indeed, even for a given model structure, we have a good deal of freedom in specifying the number of states, or more generally the state space, of a latent variable. Scoring alternative structures is made difficult by the fact that, even with simple conjugate prior distributions, the marginal likelihood no longer factorizes and exact calculation is generally impossible (see Section 9.5). Again, approximations are necessary: the Cheeseman-Stutz method (Cheeseman and Stutz 1997) has been found useful (Geiger et al. 1998). A further attractive extension is to allow the conditional independence structure relating the observables to vary, according to the values of the latent variables. Experience with such \u2018mixture of DAGs\u2019 models is described by Thiesson et al. (1998). For applications involving processes that evolve over time, a natural representation is in terms of hidden Markov models, in which the relationship between adjacent observations is explained through their common dependence on an unobserved Markov process (Smyth et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 64
                            }
                        ],
                        "text": "Again, approximations are necessary: the Cheeseman-Stutz method (Cheeseman and Stutz 1997) has been found useful (Geiger et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6176762,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42f75b297aed474599c8e598dd211a1999804138",
            "isKey": true,
            "numCitedBy": 1298,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe AutoClass an approach to unsupervised classi cation based upon the classical mixture model supplemented by a Bayesian method for determining the optimal classes We include a moderately detailed exposition of the mathematics behind the AutoClass system We emphasize that no current unsupervised classi cation system can produce maximally useful results when operated alone It is the interaction between domain experts and the machine searching over the model space that generates new knowledge Both bring unique information and abilities to the database analysis task and each enhances the others e ectiveness We illustrate this point with several applications of AutoClass to complex real world databases and describe the resulting successes and failures"
            },
            "slug": "Bayesian-Classification-(AutoClass):-Theory-and-Cheeseman-Stutz",
            "title": {
                "fragments": [],
                "text": "Bayesian Classification (AutoClass): Theory and Results"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is emphasized that no current unsupervised classi cation system can produce maximally useful results when operated alone and that it is the interaction between domain experts and the machine searching over the model space that generates new knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Knowledge Discovery and Data Mining"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145948621"
                        ],
                        "name": "G. Box",
                        "slug": "G.-Box",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Box",
                            "middleNames": [
                                "E.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Box"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1457,
                                "start": 195
                            }
                        ],
                        "text": "For models that are specified by means of prior information elicited from experts, it is particularly important that the initial assumptions be critically examined in the light of data obtained (Box 1980, 1983). In probabilistic expert systems, we need to check both the qualitative structural assumptions and the quantitative prior assessments. One can take either a Bayesian or classical (frequentist) approach, and process the data either sequentially or as a single batch. Here we concentrate on some sequential techniques for model checking, using both a classically motivated \u2018absolute\u2019 approach and a Bayesianly motivated \u2018relative\u2019 approach. Four types of diagnostic monitor for probabilistic networks will be described. A parent-child monitor provides a direct check on the adequacy of the beliefs about the conditional probability distribution of a chain component given its parents. An unconditional node monitor checks the suitability of the probability distribution at a node given the evidence on previous cases, while a conditional node monitor checks how well the node is predicted, given, in addition, all the other available evidence on the current case. A global monitor measures the overall degree of support supplied by the data for the model. Many other types of monitor could be envisaged, all aimed at checking on how well the system is predicting the incoming data. Our constructions follow the prequential approach of Dawid (1984) in basing criticism of a model on the quality of the predictions it makes sequentially."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 38
                            }
                        ],
                        "text": "(1994) relate this to the proposal of Box (1980) for comparing prior with data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53550111,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dff42f982bba41e8a467b5a10f489efa3e31d914",
            "isKey": false,
            "numCitedBy": 876,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Scientific learning is an iterative process employing Criticism and Estimation. Correspondingly the formulated model factors into two complimentary parts - a predictive part allowing model criticism, and a Bayes posterior part allowing estimation. Implications for significance tests, the theory of precise measurement, and for ridge estimates are considered. Predictive checking functions for transformation, serial correlation, bad values, and their relation with Bayesian options are considered. Robustness is seen from a Bayesian viewpoint and examples are given. For the bad value problem a comparison with M estimators is made. (Author)"
            },
            "slug": "Sampling-and-Bayes'-inference-in-scientific-and-Box",
            "title": {
                "fragments": [],
                "text": "Sampling and Bayes' inference in scientific modelling and robustness"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Predictive checking functions for transformation, serial correlation, bad values, and their relation with Bayesian options are considered, and robustness is seen from a Bayesian viewpoint and examples are given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2875953"
                        ],
                        "name": "M. Jerrum",
                        "slug": "M.-Jerrum",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Jerrum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jerrum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153936"
                        ],
                        "name": "A. Sinclair",
                        "slug": "A.-Sinclair",
                        "structuredName": {
                            "firstName": "Alistair",
                            "lastName": "Sinclair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sinclair"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 433545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16f4cf679a7e0095b52804893baf847e557e3d81",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 120,
            "paperAbstract": {
                "fragments": [],
                "text": "In the area of statistical physics, Monte Carlo algorithms based on Markov chain simulation have been in use for many years. The validity of these algorithms depends crucially on the rate of convergence to equilibrium of the Markov chain being simulated. Unfortunately, the classical theory of stochastic processes hardly touches on the sort of non-asymptotic analysis required in this application. As a consequence, it had previously not been possible to make useful, mathematically rigorous statements about the quality of the estimates obtained. Within the last ten years, analytical tools have been devised with the aim of correcting this deficiency. As well as permitting the analysis of Monte Carlo algorithms for classical problems in statistical physics, the introduction of these tools has spurred the development of new approximation algorithms for a wider class of problems in combinatorial enumeration and optimization. The \u201cMarkov chain Monte Carlo\u201d method has been applied to a variety of such problems, and often provides the only known efficient (i.e., polynomial time) solution technique."
            },
            "slug": "The-Markov-chain-Monte-Carlo-method:-an-approach-to-Jerrum-Sinclair",
            "title": {
                "fragments": [],
                "text": "The Markov chain Monte Carlo method: an approach to approximate counting and integration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The introduction of analytical tools with the aim of permitting the analysis of Monte Carlo algorithms for classical problems in statistical physics has spurred the development of new approximation algorithms for a wider class of problems in combinatorial enumeration and optimization."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10052393"
                        ],
                        "name": "S\u00f8ren H\u00f8jsgaard",
                        "slug": "S\u00f8ren-H\u00f8jsgaard",
                        "structuredName": {
                            "firstName": "S\u00f8ren",
                            "lastName": "H\u00f8jsgaard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00f8ren H\u00f8jsgaard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868274"
                        ],
                        "name": "B. Thiesson",
                        "slug": "B.-Thiesson",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Thiesson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Thiesson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 47
                            }
                        ],
                        "text": "The programs DiGram (Kreiner 1989) and Bifrost (H\u00f8jsgaard and Thiesson 1995) select chain graph models based upon maximized likelihood."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14448012,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01acbac40fe2f1aeaa6a19ba8a9e6df2f3868b6b",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "BIFROST\u2014block-recursive-models-induced-from-and-H\u00f8jsgaard-Thiesson",
            "title": {
                "fragments": [],
                "text": "BIFROST\u2014block recursive models induced from relevant knowledge, observations, and statistical techniques"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37814588"
                        ],
                        "name": "M. Puterman",
                        "slug": "M.-Puterman",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Puterman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Puterman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 81
                            }
                        ],
                        "text": "An extreme case of such independent decisions occurs in Markov decision problems (Howard 1960; Puterman 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122678161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8090121ad488b4af27bc59bf91b62e9c6a6f49c6",
            "isKey": false,
            "numCitedBy": 11619,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThe past decade has seen considerable theoretical and applied research on Markov decision processes, as well as the growing use of these models in ecology, economics, communications engineering, and other fields where outcomes are uncertain and sequential decision-making processes are needed. A timely response to this increased activity, Martin L. Puterman's new work provides a uniquely up-to-date, unified, and rigorous treatment of the theoretical, computational, and applied research on Markov decision process models. It discusses all major research directions in the field, highlights many significant applications of Markov decision processes models, and explores numerous important topics that have previously been neglected or given cursory coverage in the literature. Markov Decision Processes focuses primarily on infinite horizon discrete time models and models with discrete time spaces while also examining models with arbitrary state spaces, finite horizon models, and continuous-time discrete state models. The book is organized around optimality criteria, using a common framework centered on the optimality (Bellman) equation for presenting results. The results are presented in a \"theorem-proof\" format and elaborated on through both discussion and examples, including results that are not available in any other book. A two-state Markov decision process model, presented in Chapter 3, is analyzed repeatedly throughout the book and demonstrates many results and algorithms. Markov Decision Processes covers recent research advances in such areas as countable state space models with average reward criterion, constrained models, and models with risk sensitive optimality criteria. It also explores several topics that have received little or no attention in other books, including modified policy iteration, multichain models with average reward criterion, and sensitive optimality. In addition, a Bibliographic Remarks section in each chapter comments on relevant historic"
            },
            "slug": "Markov-Decision-Processes:-Discrete-Stochastic-Puterman",
            "title": {
                "fragments": [],
                "text": "Markov Decision Processes: Discrete Stochastic Dynamic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Markov Decision Processes covers recent research advances in such areas as countable state space models with average reward criterion, constrained models, and models with risk sensitive optimality criteria, and explores several topics that have received little or no attention in other books."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley Series in Probability and Statistics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2768149"
                        ],
                        "name": "Pierre Ndilikilikesha",
                        "slug": "Pierre-Ndilikilikesha",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Ndilikilikesha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Ndilikilikesha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 957720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f298081542136b9351d927ee146737a517f0b9b",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Using-Potential-Influence-Diagrams-for-Inference-Shachter-Ndilikilikesha",
            "title": {
                "fragments": [],
                "text": "Using Potential Influence Diagrams for Probabilistic Inference and Decision Making"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104248723"
                        ],
                        "name": "L. C. Gaag",
                        "slug": "L.-C.-Gaag",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Gaag",
                            "middleNames": [
                                "C.",
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. C. Gaag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 164
                            }
                        ],
                        "text": "Computer programs can be written, for example in languages such as LISP or Prolog, which manipulate such symbolic production rules and logic (see Lucas and van der Gaag (1991) for examples)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2460008,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "554d2462c7a084b44cf075d342c4c962a238a28a",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Many AI researchers argue that probability theory is only capable of dealing with uncertainty in situations where a fully specified joint probability distribution is available, and conclude that it is not suitable for application in AI systems. Probability intervals, however, constitute a means for expressing incompleteness of information. We present a method for computing probability interval! for probabilities of interest from a partial specification of a joint probability distribution. Our method improves on earlier approaches by all owing for independency relation\u00ad ships between statistical variables to be exploited ."
            },
            "slug": "Computing-probability-intervals-under-independency-Gaag",
            "title": {
                "fragments": [],
                "text": "Computing probability intervals under independency constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work presents a method for computing probability interval! for probabilities of interest from a partial specification of a joint probability distribution, and improves on earlier approaches by all owing for independency relation\u00ad ships between statistical variables to be exploited."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3043475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03196f8ab9df9663826b37d0d2821775e7beb1f0",
            "isKey": false,
            "numCitedBy": 382,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-Interpretation-for-MYCIN's-Certainty-Heckerman",
            "title": {
                "fragments": [],
                "text": "Probabilistic Interpretation for MYCIN's Certainty Factors"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2975527"
                        ],
                        "name": "L. Zadeh",
                        "slug": "L.-Zadeh",
                        "structuredName": {
                            "firstName": "Lotfi",
                            "lastName": "Zadeh",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zadeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 222
                            }
                        ],
                        "text": "Instead other ad hoc rules for manipulating and combining certainty factors were developed, or alternative measures of uncertainty were developed or applied, that allowed modularity to be retained, for example fuzzy logic (Zadeh 1983) and belief functions (Dempster 1967; Shafer 1976)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53121887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3f40eb2a52040440a54b1b61421f52c9da83920",
            "isKey": false,
            "numCitedBy": 1301,
            "numCiting": 110,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-role-of-fuzzy-logic-in-the-management-of-in-Zadeh",
            "title": {
                "fragments": [],
                "text": "The role of fuzzy logic in the management of uncertainty in expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32620901"
                        ],
                        "name": "A. H. Murphy",
                        "slug": "A.-H.-Murphy",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Murphy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. H. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830895"
                        ],
                        "name": "R. L. Winkler",
                        "slug": "R.-L.-Winkler",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Winkler",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Winkler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122150550,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "76923718c4ae5ccc73e5e79209ace14a97ca7dbc",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Efforts to quantify the uncertainty in weather forecasts began more than 75 years ago, and many studies and experiments involving objective and subjective probability forecasting have been conducted in meteorology in the intervening period. Moreover, the U.S. National Weather Service (NWS) initiated a nationwide program in 1965 in which precipitation probability forecasts were formulated on an operational basis and routinely disseminated to the general public. In addition, the NWS now prepares objective probability forecasts for many variables, using statistical procedures. Hence probability forecasting in meteorology is unique in that very large sets of probability forecasts that have been subjected to detailed evaluation are available. This article has four objectives: (a) to review the history of probability forecasting in meteorology to acquaint statisticians with this body of literature; (b) to describe recent methodological, experimental, and operational activities in this field; (c) to exa..."
            },
            "slug": "Probability-Forecasting-in-Meteorology-Murphy-Winkler",
            "title": {
                "fragments": [],
                "text": "Probability Forecasting in Meteorology"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The history of probability forecasting in meteorology is reviewed to acquaint statisticians with this body of literature and recent methodological, experimental, and operational activities in this field are described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751239"
                        ],
                        "name": "R. Dechter",
                        "slug": "R.-Dechter",
                        "structuredName": {
                            "firstName": "Rina",
                            "lastName": "Dechter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dechter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10450863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f14c0c0da852fd14ff208ad5d82dbece3444d311",
            "isKey": false,
            "numCitedBy": 554,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic inference algorithms for finding the most probable explanation, the maximum aposteriori hypothesis, and the maximum expected utility and for updating belief are reformulated as an elimination-type algorithm called bucket elimination. This emphasizes the principle common to many of the algorithms appearing in that literature and clarifies their relationship to nonserial dynamic programming algorithms. We also present a general way of combining conditioning and elimination within this framework. Bounds on complexity are given for all the aigorithms as a function of the problem's structure."
            },
            "slug": "Bucket-elimination:-A-unifying-framework-for-Dechter",
            "title": {
                "fragments": [],
                "text": "Bucket elimination: A unifying framework for probabilistic inference"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Probabilistic inference algorithms for finding the most probable explanation, the maximum aposteriori hypothesis, and the maximum expected utility and for updating belief are reformulated as an elimination-type algorithm called bucket elimination, emphasizing the principle common to many of the algorithms appearing in that literature."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1988445"
                        ],
                        "name": "Thomas Verma",
                        "slug": "Thomas-Verma",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Verma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Verma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 27807863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17d451204a460a4739c7b1627a128a125f4af120",
            "isKey": false,
            "numCitedBy": 1230,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Scientists often use directed acyclic graphs (dags) to model the qualitative struc\u00ad ture of causal theories, allowing the parameters to be estimated from observational data. Two causal models are equivalent if there is no experiment which could dis\u00ad tinguish one from the other. A canonical representation for causal models is pre\u00ad sented which yields an efficient graphical criterion for deciding equivalence, and provides a theoretical basis for extracting causal structures from empirical data. This representation is then extended to the more general case of an embedded causal model, that is, a dag in which only a subset of the variables are observ\u00ad able. The canonical representation presented here yields an efficient algorithm for determining when two embedded causal models reflect the same dependency information. This algorithm leads to a model theoretic definition of causation in terms of statistical dependencies. Equivalence and Synthesis of Causal Models"
            },
            "slug": "Equivalence-and-Synthesis-of-Causal-Models-Verma-Pearl",
            "title": {
                "fragments": [],
                "text": "Equivalence and Synthesis of Causal Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The canonical representation presented here yields an efficient algorithm for determining when two embedded causal models reflect the same dependency information, which leads to a model theoretic definition of causation in terms of statistical dependencies."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144527211"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9619412,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b545619ad936034c4773139421c8f4f86d8f978f",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "This article develops an axiomatic basis for the relationship between conditional independence and graphical models in statistical analysis. In particular, the following relationships are established: (1) every axiom for conditional independence is an axiom for graph separation, (2) every graph represents a consistent set of independence and dependence constraints, (3) all binary factorizations of strictly positive probability models can be encoded and determined in polynomial time using their correspondence to graph separation, (4) binary factorizations of non-strictly positive probability models can also be derived in polynomial time albeit less efficiently and (5) unconditional independence relative to normal models can be axiomatized with a finite set of axioms."
            },
            "slug": "Logical-and-Algorithmic-Properties-of-Conditional-Geiger-Pearl",
            "title": {
                "fragments": [],
                "text": "Logical and Algorithmic Properties of Conditional Independence and Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An axiomatic basis is developed for the relationship between conditional independence and graphical models in statistical analysis and unconditional independence relative to normal models can be axiomatized with a finite set of axioms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775921"
                        ],
                        "name": "Uffe Kj\u00e6rulff",
                        "slug": "Uffe-Kj\u00e6rulff",
                        "structuredName": {
                            "firstName": "Uffe",
                            "lastName": "Kj\u00e6rulff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uffe Kj\u00e6rulff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 18
                            }
                        ],
                        "text": "Spiegelhalter and Lauritzen (1990) approximated the mixture (9."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 185
                            }
                        ],
                        "text": "Current research concerning propagation in discrete probabilistic networks is concerned with studying and improving the efficiency of one or more variants of the propagation algorithms (Kj\u00e6rulff 1998; Shenoy 1997; Madsen and Jensen 1998), or exploiting cutset conditioning to trade time for space (Shachter et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 23754305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf26ff5a06c83d0fe6d39ef855a0661dedc0dfd1",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The efficiency of inference in both the Hugin and, most notably, the Shafer-Shenoy architectures can be improved by exploiting the independence relations induced by the incoming messages of a clique. That is, the message to be sent from a clique can be computed via a factorization of the clique potential in the form of a junction tree. In this paper we show that by exploiting such nested junction trees in the computation of messages both space and time costs of the conventional propagation methods may be reduced. The paper presents a structured way of exploiting the nested junction trees technique to achieve such reductions. The usefulness of the method is emphasized through a thorough empirical evaluation involving ten large real-world Bayesian networks and the Hugin inference algorithm."
            },
            "slug": "Nested-Junction-Trees-Kj\u00e6rulff",
            "title": {
                "fragments": [],
                "text": "Nested Junction Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that by exploiting such nested junction trees in the computation of messages both space and time costs of the conventional propagation methods may be reduced."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104199178"
                        ],
                        "name": "David Lindley",
                        "slug": "David-Lindley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lindley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Lindley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118415039,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f6f2f95405922022acfee38a58aadb3cd853140f",
            "isKey": false,
            "numCitedBy": 311,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Let a person express his uncertainty about an event E, conditional upon an event F, by a number x and let him be given, as a result, a score which depends on x and the truth or falsity of E when F is true. It is shown that if the scores are additive for different events and if the person chooses admissible values only, then there exists a known transform of the values x to values which are probabilities. In particular, it follows that values x derived by significance tests, confidence intervals or by the rules of fuzzy logic are inadmissible. Only probability is a sensible description of uncertainty."
            },
            "slug": "Scoring-rules-and-the-inevitability-of-probability-Lindley",
            "title": {
                "fragments": [],
                "text": "Scoring Rules and the Inevitability of Probability"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 89
                            }
                        ],
                        "text": "However, for Bayesian learning with complete case data on undirected decomposable graphs Dawid and Lauritzen (1993) have presented a general theory."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 35
                            }
                        ],
                        "text": "For further details and proofs see Dawid (1992a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 42
                            }
                        ],
                        "text": "This construction is analogous to that of Dawid and Lauritzen (1993) for the discrete decomposable undirected case, in which the undirected hyper Dirichlet prior is represented by its mean probability values and a single number to represent precision, and indeed the two approaches are essentially equivalent if we confine attention to perfect DAGs, which are Markov equivalent to decomposable undirected graphical models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 56
                            }
                        ],
                        "text": "Markov properties of decomposable graphs are studied by Dawid and Lauritzen (1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 389,
                                "start": 261
                            }
                        ],
                        "text": "Although we have presented predictive assessment of a model in terms of a criterion function based on the logarithm of the density, there is no difficulty in principle in extending the approach to other measures of goodness of prediction fit (see, for example, Dawid (1992b)). Ideally, such a measure should be directly related to the purpose of the analysis. Sebastiani and Ramoni (1998) have suggested using a formal loss function, while Heckerman (1998) discusses \u2018local scoring\u2019, which confines attention to the marginal density for a particular variable of interest."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Dawid and Lauritzen (1993) give examples of the construction of a range of specific hyper Markov laws, including the hyper normal, hyper Multinomial, hyper Dirichlet, the hyper Wishart, and hyper inverse Wishart laws."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 261
                            }
                        ],
                        "text": "Although we have presented predictive assessment of a model in terms of a criterion function based on the logarithm of the density, there is no difficulty in principle in extending the approach to other measures of goodness of prediction fit (see, for example, Dawid (1992b))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 176
                            }
                        ],
                        "text": "within theoretical statistics include: sufficiency and ancillarity; nuisance parameters (Dawid 1980a); Simpson\u2019s paradox; optional stopping, selection and missing data effects (Dawid 1976; Dawid and Dickey 1977); invariance (Dawid 1985); and model-building (Dawid 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 55
                            }
                        ],
                        "text": "Were the asymptotic theory of SeillierMoiseiwitsch and Dawid (1993) to be applicable to this short sequence, we could regard this as an observation on a random variable which has an approximate standard normal distribution, under the null hypothesis that the data are consistent with the assigned probabilities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46644233,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "fc34b14dc7c8170433e7f0f502e78b5a670f3bb0",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In applications of statistical methods to medical diagnosis, information on patients' diseases and symptoms is collected and the resulting data-base is used to diagnose new patients. The data-structure is complicated by a number of factors, two of which are examined here: selection bias and unstable population. Under reasonable conditions, no correction for selection bias is required when assessing probabilities for diseases based on symptom information, and it is suggested that these \"diagnostic distributions\" should form the principal object of study. Transformation of these distributions under changing population structure is considered and shown to take on a simple form in many situations. It is argued that the prevailing paradigm of diagnostic statistics, which concentrates on incidence of symptoms for given disease, is largely inappropriate and should be replaced by an emphasis on diagnostic distributions. The generalized logistic model is seen to fit naturally into the new framework."
            },
            "slug": "Properties-of-diagnostic-data-distributions.-Dawid",
            "title": {
                "fragments": [],
                "text": "Properties of diagnostic data distributions."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is argued that the prevailing paradigm of diagnostic statistics, which concentrates on incidence of symptoms for given disease, is largely inappropriate and should be replaced by an emphasis on diagnostic distributions, and the generalized logistic model is seen to fit naturally into the new framework."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25238251"
                        ],
                        "name": "R. Fung",
                        "slug": "R.-Fung",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fung",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2997706"
                        ],
                        "name": "B. D. Favero",
                        "slug": "B.-D.-Favero",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Favero",
                            "middleNames": [
                                "Del"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Favero"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22592126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6a61b699181e62d5e817b66e29eeaf47a753207",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Information retrieval (IR) is the identification of documents or other units of information in a collection that are relevant to a particular information need. An information need is a set of questions to which someone would like to find an answer. Here are some examples of IR tasks: finding articles in the New York Times that discuss the Iran-Contra affair; searching the recent postings in a Usenet newsgroup for references to a particular model of personal computer; finding the entries referring to butterflies in an online CD-ROM encyclopedia."
            },
            "slug": "Applying-Bayesian-networks-to-information-retrieval-Fung-Favero",
            "title": {
                "fragments": [],
                "text": "Applying Bayesian networks to information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Information retrieval (IR) is the identification of documents or other units of information in a collection that are relevant to a particular information need."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2991777"
                        ],
                        "name": "M. Golumbic",
                        "slug": "M.-Golumbic",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Golumbic",
                            "middleNames": [
                                "Charles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Golumbic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122758481,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "d53aa6487575762c1a14addf273ea271fef24d29",
            "isKey": false,
            "numCitedBy": 2874,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithmic-graph-theory-and-perfect-graphs-Golumbic",
            "title": {
                "fragments": [],
                "text": "Algorithmic graph theory and perfect graphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49223598"
                        ],
                        "name": "J. Darroch",
                        "slug": "J.-Darroch",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Darroch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Darroch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29989822"
                        ],
                        "name": "T. Speed",
                        "slug": "T.-Speed",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Speed",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Speed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 161
                            }
                        ],
                        "text": "One way to proceed is by specifying interaction terms of the conditional probabilities, in analogy with procedures in log-linear models and Markov random fields (Darroch et al. 1980)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 36
                            }
                        ],
                        "text": "A range of examples is described by Dawid (1998). Important statistical applications include meta conditional independence, which generalizes the concept of a cut in a parametric statistical family (Barndorff-Nielsen 1978); and hyper conditional independence, which imposes, in addition, corresponding independence properties on a prior distribution over the parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3545924,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "10143673f3f1a49d346120928d6b9a56851d6cf0",
            "isKey": false,
            "numCitedBy": 437,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We use a close connection between the theory of Markov fields and that of log-linear interaction models for contingency tables to define and investigate a new class of models for such tables, graphical models. These models are hierarchical models that can be represented by a simple, undirected graph on as many vertices as the dimension of the corresponding table. Further all these models can be given an interpretation in terms of conditional independence and the interpretation can be read directly off the graph in the form of a Markov property. The class of graphical models contains that of decomposable models and we give a simple criterion for decomposability of a given graphical model. To some extent we discuss estimation problems and give suggestions for further work."
            },
            "slug": "Markov-Fields-and-Log-Linear-Interaction-Models-for-Darroch-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Markov Fields and Log-Linear Interaction Models for Contingency Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738567"
                        ],
                        "name": "A. Nicholson",
                        "slug": "A.-Nicholson",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Nicholson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nicholson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120971205"
                        ],
                        "name": "M. Brady",
                        "slug": "M.-Brady",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brady"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 98
                            }
                        ],
                        "text": "For example, temporal networks and tracking problems require an evolving but repetitive structure (Kj\u00e6rulff 1995; Nicholson and Brady 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16579377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c66b1320a4e67d6fcb667d86934a37adbc99e13",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the development of a monitoring system which uses sensor observation data about discrete events to construct dynamically a probabilistic model of the world. This model is a Bayesian network incorporating temporal aspects, which we call a dynamic belief network; it is used to reason under uncertainty about both the causes and consequences of the events being monitored. The basic dynamic construction of the network is data-driven. However the model construction process combines sensor data about events with externally provided information about agents' behavior, and knowledge already contained within the model, to control the size and complexity of the network. This means that both the network structure within a time interval, and the amount of history and detail maintained, can vary over time. We illustrate the system with the example domain of monitoring robot vehicles and people in a restricted dynamic environment using light-beam sensor data. In addition to presenting a generic network structure for monitoring domains, we describe the use of more complex network structures which address two specific monitoring problems, sensor validation and the data association problem. >"
            },
            "slug": "Dynamic-Belief-Networks-for-Discrete-Monitoring-Nicholson-Brady",
            "title": {
                "fragments": [],
                "text": "Dynamic Belief Networks for Discrete Monitoring"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A monitoring system which uses sensor observation data about discrete events to construct dynamically a probabilistic model of the world, a Bayesian network incorporating temporal aspects, which is a dynamic belief network used to reason under uncertainty about both the causes and consequences of the events being monitored."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern. Syst."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729111"
                        ],
                        "name": "C. Cannings",
                        "slug": "C.-Cannings",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Cannings",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cannings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057177943"
                        ],
                        "name": "E. Thompson",
                        "slug": "E.-Thompson",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49933092"
                        ],
                        "name": "M. Skolnick",
                        "slug": "M.-Skolnick",
                        "structuredName": {
                            "firstName": "M",
                            "lastName": "Skolnick",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Skolnick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120853189,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0b12ebb3801710ed3d15b5c97a8761640a0a1a0",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The calculation of probabilities on pedigrees of arbitrary complexity is discussed for a basic model of transmission and penetrance (encompassing Mendelian inheritance, and certain environmental influences). The structure of pedigrees, and the types of loops occurring, is discussed. Some results in graph theory are obtained and, using these, a recurrence relation derived for certain probabilities. The recursive procedure enables the successive peeling off of certain members of the pedigree, and the condensation of the information on those individuals into a function on a subset of those remaining. The underlying theory is set out, and examples given of the utilization of the resulting algorithm. PEDIGREE; PROBABILITY; LOOPS; PEELING; GRAPH; OUSIOTYPE; GENETICS"
            },
            "slug": "Probability-functions-on-complex-pedigrees-Cannings-Thompson",
            "title": {
                "fragments": [],
                "text": "Probability functions on complex pedigrees"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The calculation of probabilities on pedigrees of arbitrary complexity is discussed for a basic model of transmission and penetrance (encompassing Mendelian inheritance, and certain environmental influences)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144527211"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 119
                            }
                        ],
                        "text": "member of m; this dimension is not always straightforward to calculate for graphical models involving latent variables (Geiger et al. 1998; Settimi and Smith 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 113
                            }
                        ],
                        "text": "Again, approximations are necessary: the Cheeseman-Stutz method (Cheeseman and Stutz 1997) has been found useful (Geiger et al. 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5423501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4293caf0e8446679165c7fc9ff908321854d1c43",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the Bayesian Information Criterion (BIC), an asymptotic approximation for tile marginal likelihood, to Bayesian networks with hidden variables. This approximation can be used to select models given large sampies of data. Tile standard BIC as well as our extension punishes the complexity of a model according to tile dimension of its parameters. We argue that the dimension of a Bayesian uetwork with hidden variables is tile rank of the Jacobian matrix of the transformation between the parameters of the network and the parameters of the observable variables. We compute the dimensions of several networks including the naive Bayes model with a hidden root node."
            },
            "slug": "Asymptotic-Model-Selection-for-Directed-Networks-Geiger-Heckerman",
            "title": {
                "fragments": [],
                "text": "Asymptotic Model Selection for Directed Networks with Hidden Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The Bayesian Information Criterion (BIC), an asymptotic approximation for tile marginal likelihood, is extended to Bayesian networks with hidden variables and it is argued that the dimension of a Bayesian uetwork withhidden variables is tile rank of the Jacobian matrix of the transformation between the parameters of the network and the parametersof the observable variables."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 302,
                                "start": 215
                            }
                        ],
                        "text": "Another trend is the development of variants of the algorithm that perform slightly different or additional tasks (Jensen 1995), or that work in a somewhat modified way (Bloemeke and Valtorta 1998) or approximately (Kj\u00e6rulff 1993; Jensen et al. 1995; Saul et al. 1996; Curds 1997; Kearns and Saul 1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 127
                            }
                        ],
                        "text": "Various analytical approximations are possible: current attention focuses on variational methods and mean field approximations (Saul et al. 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7424318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a79433b5feacd9e8feeafa629dae5a85f362fef",
            "isKey": false,
            "numCitedBy": 438,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a mean field theory for sigmoid belief networks based on ideas from statistical mechanics. Our mean field theory provides a tractable approximation to the true probability distribution in these networks; it also yields a lower bound on the likelihood of evidence. We demonstrate the utility of this framework on a benchmark problem in statistical pattern recognition-the classification of handwritten digits."
            },
            "slug": "Mean-Field-Theory-for-Sigmoid-Belief-Networks-Saul-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Mean Field Theory for Sigmoid Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The utility of a mean field theory for sigmoid belief networks based on ideas from statistical mechanics is demonstrated on a benchmark problem in statistical pattern recognition-the classification of handwritten digits."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50094606"
                        ],
                        "name": "J. Koster",
                        "slug": "J.-Koster",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koster",
                            "middleNames": [
                                "T.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koster"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53330417,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5e2a833cedf42aa50ce36999d5f64975e88f619e",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper aims to solve an often noted incompatibility between graphical chain models which elucidate the conditional independence structure of a set of random variables and simultaneous equations systems which focus on direct linear interactions and correlations between random variables. Various authors have argued that the incompatibility arises mainly from the fact that in a simultaneous equations system (e.g., a LISREL model) reciprocal causality is possible whereas this is not so in the case of graphical chain models. In this article it is shown that this view is not correct. In fact, the definition of the Markov property embodied in a graph can be generalized to a wider class of graphs which includes certain nonrecursive graphs. The resulting class of reciprocal graph probability models strictly includes the class of chain graph probability models. The class of lattice conditional independence probability models is also strictly included. It is shown that the resulting methodology is directly applicable to quite general simultaneous equations systems that are subject to mild restrictions only. Provided some adjustments are made, general simultaneous equations systems can be handled as well. In all cases, consistency with the LISREL methodology is maintained."
            },
            "slug": "Markov-properties-of-nonrecursive-causal-models-Koster",
            "title": {
                "fragments": [],
                "text": "Markov properties of nonrecursive causal models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109683373"
                        ],
                        "name": "Jim Q. Smith",
                        "slug": "Jim-Q.-Smith",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Smith",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Q. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119674460,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cd527bd5a2471e83e63749747c655d16d332dd4",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Influence-diagrams-for-Bayesian-decision-analysis-Smith",
            "title": {
                "fragments": [],
                "text": "Influence diagrams for Bayesian decision analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 51
                            }
                        ],
                        "text": "This is a consequence of the theorem below, due to Pearl and Paz (1987) (see also Pearl (1988))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 79
                            }
                        ],
                        "text": "An alternative formulation of the global directed Markov property was given by Pearl (1986a) with a formal treatment in Verma and Pearl (1990). Recall that a trail in D is a sequence of vertices that forms a path in the undirected version D\u223c of D, i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 17
                            }
                        ],
                        "text": "As emphasized by Pearl (1988), such models are intended to encode natural judgements of relevance and irrelevance, and can be formed prior to any probabilistic considerations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 79
                            }
                        ],
                        "text": "An alternative formulation of the global directed Markov property was given by Pearl (1986a) with a formal treatment in Verma and Pearl (1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Pearl (1986b) presented an alternative way of finding these properties for a DAG in terms of a concept called d-separation (see Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 156
                            }
                        ],
                        "text": "The above example has heuristically argued for the explanatory power of probabilistic models based on Bayesian reasoning, following closely the insights of Pearl (1986b) and Pearl (1988), which largely provided the foundation for probabilistic evidence propagation in complex systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14936636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99485775cce4c1afa7361a7fcbd3c9d362309554",
            "isKey": true,
            "numCitedBy": 886,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents generalizations of Bayes likelihood-ratio updating rule which facilitate an asynchronous propagation of the impacts of new beliefs and/or new evidence in hierarchically organized inference structures with multi-hypotheses variables. The computational scheme proposed specifies a set of belief parameters, communication messages and updating rules which guarantee that the diffusion of updated beliefs is accomplished in a single pass and complies with the tenets of Bayes calculus."
            },
            "slug": "Reverend-Bayes-on-Inference-Engines:-A-Distributed-Pearl",
            "title": {
                "fragments": [],
                "text": "Reverend Bayes on Inference Engines: A Distributed Hierarchical Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "Generalizations of Bayes likelihood-ratio updating rule are presented which facilitate an asynchronous propagation of the impacts of new beliefs and/or new evidence in hierarchically organized inference structures with multi-hypotheses variables."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2719679"
                        ],
                        "name": "J. A. Tatman",
                        "slug": "J.-A.-Tatman",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Tatman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Tatman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9355082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "357f051056b9a3005d4b04aaa204d63b4efcab06",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The concept of a super value node is developed to extend the theory of influence diagrams to allow dynamic programming to be performed within this graphical modeling framework. The operations necessary to exploit the presence of these nodes and efficiently analyze the models are developed. The key result is that by representing value function separability in the structure of the graph of the influence diagram, formulation is simplified and operations on the model can take advantage of the separability. From the decision analysis perspective, this allows simple exploitation of separability in the value function of a decision problem. This allows algorithms to be designed to solve influence diagrams that automatically recognize the opportunity for applying dynamic programming. From the decision processes perspective, influence diagrams with super value nodes allow efficient formulation and solution of nonstandard decision process structures. They also allow the exploitation of conditional independence between state variables. >"
            },
            "slug": "Dynamic-programming-and-influence-diagrams-Tatman-Shachter",
            "title": {
                "fragments": [],
                "text": "Dynamic programming and influence diagrams"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "By representing value function separability in the structure of the graph of the influence diagram, formulation is simplified and operations on the model can take advantage of the separability, this allows simple exploitation in the value function of a decision problem."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62611185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a266b1906fb9a3bff100efea2ba39f86a92903c",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "We present and justify a propagation algorithm to facilitate the simultaneous calculation, for every node in a probabilistic exper system of the distribution of the associated random quantity, conditional on all the evidence obtained about the remaining nodes."
            },
            "slug": "Fast-retraction-of-evidence-in-a-probabilistic-Cowell-Dawid",
            "title": {
                "fragments": [],
                "text": "Fast retraction of evidence in a probabilistic expert system"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A propagation algorithm is presented and justified to facilitate the simultaneous calculation, for every node in a probabilistic exper system of the distribution of the associated random quantity, conditional on all the evidence obtained about the remaining nodes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735963"
                        ],
                        "name": "Raffaella Settimi",
                        "slug": "Raffaella-Settimi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Settimi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raffaella Settimi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109683373"
                        ],
                        "name": "Jim Q. Smith",
                        "slug": "Jim-Q.-Smith",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Smith",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Q. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 146
                            }
                        ],
                        "text": "However, latent variable models may also impose probabilistic constraints over and above those expressible as conditional independence properties (Spirtes et al. 1993; Settimi and Smith 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 126
                            }
                        ],
                        "text": "When there are hidden variables, such as in the Child example, the likelihood function typically has a number of local maxima (Settimi and Smith 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 33
                            }
                        ],
                        "text": "This was exploited by Shenoy and Shafer (1990), who gave a set of abstract axioms under which a form of local computation is possible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 52
                            }
                        ],
                        "text": "Note that another consequence is that the axioms of Shafer and Shenoy (1990) or Lauritzen and Jensen (1997) are not fulfilled."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 119
                            }
                        ],
                        "text": "member of m; this dimension is not always straightforward to calculate for graphical models involving latent variables (Geiger et al. 1998; Settimi and Smith 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14667385,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "3768d88fd61e8de1e7376588d8b6d7c17636f43d",
            "isKey": true,
            "numCitedBy": 47,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we investigate the geometry of the likelihood of the unknown parameters in a simple class of Bayesian directed graphs with hidden variables. This enables us, before any numerical algorithms are employed, to obtain certain insights in the nature of the unidentifiability inherent in such models, the way posterior densities will be sensitive to prior densities and the typical geometrical form these posterior densities might take. Many of these insights carry over into more complicated Bayesian networks with systematic missing data."
            },
            "slug": "On-the-Geometry-of-Bayesian-Graphical-Models-with-Settimi-Smith",
            "title": {
                "fragments": [],
                "text": "On the Geometry of Bayesian Graphical Models with Hidden Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The geometry of the likelihood of the unknown parameters in a simple class of Bayesian directed graphs with hidden variables is investigated to obtain certain insights in the nature of the unidentifiability inherent in such models."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145948621"
                        ],
                        "name": "G. Box",
                        "slug": "G.-Box",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Box",
                            "middleNames": [
                                "E.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Box"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118343637,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "06c58d9c61a4d3e1da509b2dfe2597d0e112ef6c",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Apology-for-Ecumenism-in-Statistics.-Box",
            "title": {
                "fragments": [],
                "text": "An Apology for Ecumenism in Statistics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145392702"
                        ],
                        "name": "P. Green",
                        "slug": "P.-Green",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Green",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Green"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 74
                            }
                        ],
                        "text": "The EM algorithm can be adapted for maximizing such penalized likelihoods (Green 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122443027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1535c4f1e0c76a934598ec36c41b3759972dada",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY The EM algorithm is a popular approach to maximum likelihood estimation but has not been much used for penalized likelihood or maximum a posteriori estimation. This paper discusses properties of the EM algorithm in such contexts, concentrating on rates of conver- gence, and presents an alternative that is usually more practical and converges at least as quickly. The EM algorithm is a general approach to maximum likelihood estimation, rather than a specific algorithm. Dempster et al. (1977) discussed the method and derived basic properties, demonstrating that a variety of procedures previously developed rather informally could be unified. The common strand to problems where the approach is applicable is a notion of 'incomplete data'; this includes the conventional sense of 'missing data' but is much broader than that. The EM algorithm demon- strates its strength in situations where some hypothetical experiment yields data from which estimation is particularly convenient and economical: the 'incomplete' data actually at hand are regarded as observable functions of these 'complete' data. The resulting algorithms, while usually slow to converge, are often extremely simple and remain practical in large problems where no other approaches may be feasible. Dempster et al. (1977) briefly refer to the use of the same approach to the problem of finding the posterior mode (maximum a posteriori estimate) in a Bayesian estima-"
            },
            "slug": "On-Use-of-the-EM-Algorithm-for-Penalized-Likelihood-Green",
            "title": {
                "fragments": [],
                "text": "On Use of the EM Algorithm for Penalized Likelihood Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Property of the EM algorithm in such contexts are discussed, concentrating on rates of conver- gence, and an alternative that is usually more practical and converges at least as quickly is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12334765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5669148e6026516720940558086def2ab92b04e2",
            "isKey": false,
            "numCitedBy": 394,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Evidential-Reasoning-Using-Stochastic-Simulation-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Evidential Reasoning Using Stochastic Simulation of Causal Models"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 32
                            }
                        ],
                        "text": "1987),Markov tree and hypertree (Shenoy and Shafer 1990), or simply clique tree have also been used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 307,
                                "start": 237
                            }
                        ],
                        "text": "There has also been some activity concerned with algorithms to solve rather different tasks, possibly at a more abstract level, including belief function propagation, constraint satisfaction, discrete optimization, and decision analysis (Shenoy and Shafer 1990; Shenoy 1991, 1992; Lauritzen and Jensen 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34413970,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "13976cfe3be7e0873fa9814ac5c08cf27bfa91f1",
            "isKey": false,
            "numCitedBy": 675,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an abstract framework and axioms under which exact local computation of marginals is possible. The primitive objects of the framework are variables and valuations. The primitive operators of the framework are combination and marginalization. These operate on valuations. We state three axioms for these operators and we derive the possibility of local computation from the axioms. Next, we describe a propagation scheme for computing marginals of a valuation when we have a factorization of the valuation on a hypertree. Finally we show how the problem of computing marginals of joint probability distributions and joint belief functions fits the general framework."
            },
            "slug": "Axioms-for-probability-and-belief-function-Shenoy-Shafer",
            "title": {
                "fragments": [],
                "text": "Axioms for probability and belief-function proagation"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes an abstract framework and axioms under which exact local computation of marginals is possible and shows how the problem of computing marginals of joint probability distributions and joint belief functions fits the general framework."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58792451,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a3767909649cf31d32e087693d93171af28ebe0",
            "isKey": false,
            "numCitedBy": 4303,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Local-computations-with-probabilities-on-graphical-Lauritzen-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Local computations with probabilities on graphical structures and their application to expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2746221"
                        ],
                        "name": "S. A. Andersson",
                        "slug": "S.-A.-Andersson",
                        "structuredName": {
                            "firstName": "Steen",
                            "lastName": "Andersson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Andersson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710305"
                        ],
                        "name": "D. Madigan",
                        "slug": "D.-Madigan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Madigan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Madigan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2830733"
                        ],
                        "name": "M. Perlman",
                        "slug": "M.-Perlman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Perlman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Perlman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 872,
                                "start": 36
                            }
                        ],
                        "text": "This approach is related to that of Andersson et al. (1996a), who use chain graphs, but with a new \u2018AMP\u2019 semantics, based on a graph separation property different from that considered here, which they term \u2018LWF.\u2019 The AMP semantics is related to the interpretation of structural equation models (Bollen 1988). It gives rise to many questions similar to those for the LWF approach: equivalence of different descriptions of graphical separation, Markov equivalence of distinct graphs, etc. However, it does not correspond in a simple fashion to a factorization property of the joint density, an aspect that is crucial for computational efficiency. Further graphical representations include possibly cyclic directed graphs using essentially the same moralization semantics as in the acyclic case; Markov equivalence and related issues have been addressed by Richardson (1996). An extension to \u2018reciprocal graphs,\u2019 a generalization of chain graphs, has been studied by Koster (1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 19
                            }
                        ],
                        "text": "Studen\u00fd (1997) and Andersson et al. (1998) give good overviews of recent issues and advances in graphical descriptions of conditional independence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 36
                            }
                        ],
                        "text": "This approach is related to that of Andersson et al. (1996a), who use chain graphs, but with a new \u2018AMP\u2019 semantics, based on a graph separation property different from that considered here, which they term \u2018LWF."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 978,
                                "start": 36
                            }
                        ],
                        "text": "This approach is related to that of Andersson et al. (1996a), who use chain graphs, but with a new \u2018AMP\u2019 semantics, based on a graph separation property different from that considered here, which they term \u2018LWF.\u2019 The AMP semantics is related to the interpretation of structural equation models (Bollen 1988). It gives rise to many questions similar to those for the LWF approach: equivalence of different descriptions of graphical separation, Markov equivalence of distinct graphs, etc. However, it does not correspond in a simple fashion to a factorization property of the joint density, an aspect that is crucial for computational efficiency. Further graphical representations include possibly cyclic directed graphs using essentially the same moralization semantics as in the acyclic case; Markov equivalence and related issues have been addressed by Richardson (1996). An extension to \u2018reciprocal graphs,\u2019 a generalization of chain graphs, has been studied by Koster (1996). Starting from any graphical Markov criterion, we can also consider the effects of collapsing out over unobservable variables, or conditioning on \u2018selection variables,\u2019 thus broadening still further the range of conditional independence structures that may be represented (Cox andWermuth 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16200736,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9ad3340b0fb0f714ee8f63ef7992680fee604a26",
            "isKey": true,
            "numCitedBy": 65,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical Markov models use graphs, either undirected, directed, or mixed, to represent possible dependences among statistical variables. Applications of undirected graphs (UDGs) include models for spatial dependence and image analysis, while acyctic directed graphs (ADGs), which are especially convenient for statistical analysis, arise in such fields as genetics and psychometrics and as models for expert systems and Bayesian belief networks. Lauritzen, Wermuth, and Frydenberg (LWF) introduced a Markov property for chain graphs, which are mixed graphs that can be used to represent simultaneously both causal and associative dependencies and which include both UDGs and ADGs as special cases. In this paper an alternative Markov property (AMP) for chain graphs is introduced, which in some ways is a more direct extension of the ADG Markov property than is the LWF property for chain graph."
            },
            "slug": "An-Alternative-Markov-Property-for-Chain-Graphs-Andersson-Madigan",
            "title": {
                "fragments": [],
                "text": "An Alternative Markov Property for Chain Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An alternative Markov property (AMP) for chain graphs is introduced, which in some ways is a more direct extension of the ADG Markovproperty than is the LWF property for chain graph."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775921"
                        ],
                        "name": "Uffe Kj\u00e6rulff",
                        "slug": "Uffe-Kj\u00e6rulff",
                        "structuredName": {
                            "firstName": "Uffe",
                            "lastName": "Kj\u00e6rulff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uffe Kj\u00e6rulff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 78
                            }
                        ],
                        "text": "An example of this arises in the analysis of time-series using dynamic graphs (Kj\u00e6rulff 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 98
                            }
                        ],
                        "text": "For example, temporal networks and tracking problems require an evolving but repetitive structure (Kj\u00e6rulff 1995; Nicholson and Brady 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14753120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca67e73e7289fc92ac038b615ee7161a30d73bbc",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "dHugin:-a-computational-system-for-dynamic-Bayesian-Kj\u00e6rulff",
            "title": {
                "fragments": [],
                "text": "dHugin: a computational system for dynamic time-sliced Bayesian networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98889565"
                        ],
                        "name": "A. Riva",
                        "slug": "A.-Riva",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Riva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Riva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781522"
                        ],
                        "name": "R. Bellazzi",
                        "slug": "R.-Bellazzi",
                        "structuredName": {
                            "firstName": "Riccardo",
                            "lastName": "Bellazzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bellazzi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 10662436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "833d79bb5e7b754c074c7b7be546c62daa83648b",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-temporal-probabilistic-causal-models-from-Riva-Bellazzi",
            "title": {
                "fragments": [],
                "text": "Learning temporal probabilistic causal models from longitudinal data"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell. Medicine"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144527211"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 13
                            }
                        ],
                        "text": "Note however (Geiger and Meek 1998) that the required smoothness conditions may not hold in some graphical models with latent variables, and in such cases these asymptotic equivalences are no longer assured."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1604461,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b0daa933f70082494de9e17c47bbe2ddfc2987e9",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide a classification of graphical models according to their representation as subfamilies of exponential families. Undirected graphical models with no hidden variables are linear exponential families (LEFs), directed acyclic graphical models and chain graphs with no hidden variables, including Bayesian networks with several families of local distributions, are curved exponential families (CEFs) and graphical models with hidden variables are stratified exponential families (SEFs). An SEF is a finite union of CEFs satisfying a frontier condition. In addition, we illustrate how one can automatically generate independence and non-independence constraints on the distributions over the observable variables implied by a Bayesian network with hidden variables. The relevance of these results for model selection is examined."
            },
            "slug": "Graphical-Models-and-Exponential-Families-Geiger",
            "title": {
                "fragments": [],
                "text": "Graphical Models and Exponential Families"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is illustrated how one can automatically generate independence and non-independence constraints on the distributions over the observable variables implied by a Bayesian network with hidden variables."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34760449"
                        ],
                        "name": "K. Olesen",
                        "slug": "K.-Olesen",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Olesen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Olesen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10059313,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8e78faf8d09c194200efdd697c1c8b9df9374592",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "aHUGIN:-A-System-Creating-Adaptive-Causal-Networks-Olesen-Lauritzen",
            "title": {
                "fragments": [],
                "text": "aHUGIN: A System Creating Adaptive Causal Probabilistic Networks"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144389145"
                        ],
                        "name": "A. Gelman",
                        "slug": "A.-Gelman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Gelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145779280"
                        ],
                        "name": "J. Carlin",
                        "slug": "J.-Carlin",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carlin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38818938"
                        ],
                        "name": "H. Stern",
                        "slug": "H.-Stern",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Stern",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Stern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39775017"
                        ],
                        "name": "D. Dunson",
                        "slug": "D.-Dunson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Dunson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dunson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3104170"
                        ],
                        "name": "Aki Vehtari",
                        "slug": "Aki-Vehtari",
                        "structuredName": {
                            "firstName": "Aki",
                            "lastName": "Vehtari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aki Vehtari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62610127,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "8d76672d52622d9c45014d630717ce911d1292ba",
            "isKey": false,
            "numCitedBy": 11104,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "FUNDAMENTALS OF BAYESIAN INFERENCE Probability and Inference Single-Parameter Models Introduction to Multiparameter Models Asymptotics and Connections to Non-Bayesian Approaches Hierarchical Models FUNDAMENTALS OF BAYESIAN DATA ANALYSIS Model Checking Evaluating, Comparing, and Expanding Models Modeling Accounting for Data Collection Decision Analysis ADVANCED COMPUTATION Introduction to Bayesian Computation Basics of Markov Chain Simulation Computationally Efficient Markov Chain Simulation Modal and Distributional Approximations REGRESSION MODELS Introduction to Regression Models Hierarchical Linear Models Generalized Linear Models Models for Robust Inference Models for Missing Data NONLINEAR AND NONPARAMETRIC MODELS Parametric Nonlinear Models Basic Function Models Gaussian Process Models Finite Mixture Models Dirichlet Process Models APPENDICES A: Standard Probability Distributions B: Outline of Proofs of Asymptotic Theorems C: Computation in R and Stan Bibliographic Notes and Exercises appear at the end of each chapter."
            },
            "slug": "Bayesian-Data-Analysis-Gelman-Carlin",
            "title": {
                "fragments": [],
                "text": "Bayesian Data Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Detailed notes on Bayesian Computation Basics of Markov Chain Simulation, Regression Models, and Asymptotic Theorems are provided."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144527211"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Geiger and Pearl (1990) show that the criterion of d-separation cannot be improved, in the sense that, for any given directed acyclic graph D, one can find state spaces X\u03b1, \u03b1 \u2208 V and a probability P such that"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8820133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96e1f75ba0447cd4d07ce371861b3cba5bf00d42",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-logic-of-causal-models-Geiger-Pearl",
            "title": {
                "fragments": [],
                "text": "On the logic of causal models"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8564770"
                        ],
                        "name": "C. Fuchs",
                        "slug": "C.-Fuchs",
                        "structuredName": {
                            "firstName": "Camil",
                            "lastName": "Fuchs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fuchs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121553237,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "95af63ab1f7d34d8a54b165cd90dacc916cac036",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In many studies the values of one or more variables are missing for subsets of the original sample. This article focuses on the problem of obtaining maximum likelihood estimates (MLE) for the parameters of log-linear models under this type of incomplete data. The appropriate systems of equations are presented and the expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977) is suggested as one of the possible methods for solving them. The algorithm has certain advantages but other alternatives may be computationally more effective. Tests of fit for log-linear models in the presence of incomplete data are considered. The data from the Protective Services Project for Older Persons (Blenkner, Bloom, and Nielsen 1971; Blenkner, Bloom, and Weber 1974) are used to illustrate the procedures discussed in the article."
            },
            "slug": "Maximum-Likelihood-Estimation-and-Model-Selection-Fuchs",
            "title": {
                "fragments": [],
                "text": "Maximum Likelihood Estimation and Model Selection in Contingency Tables with Missing Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868274"
                        ],
                        "name": "B. Thiesson",
                        "slug": "B.-Thiesson",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Thiesson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Thiesson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724065"
                        ],
                        "name": "D. M. Chickering",
                        "slug": "D.-M.-Chickering",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chickering",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Chickering"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5574895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b73ffe5e76c3f7e6239ae3e4fc34a931ea716e01",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe computationally efficient methods for learning mixtures in which each component is a directed acyclic graphical model (mixtures of DAGs or MDAGs). We argue that simple search-and-score algorithms are infeasible for a variety of problems, and introduce a feasible approach in which parameter and structure search is interleaved and expected data is treated as real data. Our approach can be viewed as a combination of (1) the Cheeseman-Stutz asymptotic approximation for model posterior probability and (2) the Expectation-Maximization algorithm. We evaluate our procedure for selecting among MDAGs on synthetic and real examples."
            },
            "slug": "Learning-Mixtures-of-DAG-Models-Thiesson-Meek",
            "title": {
                "fragments": [],
                "text": "Learning Mixtures of DAG Models"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a feasible approach in which parameter and structure search is interleaved and expected data is treated as real data, and can be viewed as a combination of the Cheeseman-Stutz asymptotic approximation for model posterior probability and the Expectation-Maximization algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 93
                            }
                        ],
                        "text": "This controversial area is explored from a maximized likelihood perspective by, for example, Spirtes et al. (1993). As the number of parents of a node increases, the node\u2019s conditional probability table grows exponentially."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6309493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c86800e9e5f232cd05238507ccc8db4ee4ac14c",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-comparison-of-graphical-techniques-for-decision-Shenoy",
            "title": {
                "fragments": [],
                "text": "A comparison of graphical techniques for decision analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2768149"
                        ],
                        "name": "Pierre Ndilikilikesha",
                        "slug": "Pierre-Ndilikilikesha",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Ndilikilikesha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Ndilikilikesha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9674276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f859f9642b47c82f647324c0ed243337902e9e64",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Potential-influence-diagrams-Ndilikilikesha",
            "title": {
                "fragments": [],
                "text": "Potential influence diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Approx. Reason."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143648560"
                        ],
                        "name": "P. Spirtes",
                        "slug": "P.-Spirtes",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Spirtes",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Spirtes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13639275,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "81a639fcb49984aa1a8a7622306ab5d12c6b5dc0",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Following the terminology of Lauritzen et. al. (1990) say that a probability measure over a set of variables V satisfies the local directed Markov property for a directed acyclic graph (DAG) G with vertices V if and only if for every Win V, Wis independent of the set of all its non-descendants conditional on the set of its parents. One natural question that arises with respect to DAGs is when two DAGs are \"statistically equivalent\". One interesting sense of \"statistical equivalence\" is \"conditional independence equivalence\" which holds when two DAGs entail the same set of conditional independence relations. In the case of DAGs, conditional independence equivalence also corresponds to a variety of other natural senses of statistical equivalence (such as representing the same set of distributions). Theorems characterizing conditional independence equivalence for directed acyclic graphs and that can be used as the basis for polynomial time algorithms for checking conditional independence equivalence were provided by Verma and Pearl (1990), and Frydenberg (1990). The question we will examine is how to extend these results to cases where a DAG may have latent (unmeasured) variables or selection bias (i.e. some of the variables in the DAG have been conditioned on.) Conditional independence equivalence is of interest in part because there are algorithms for constructing DAGs with latent variables and selection bias that are based on observed conditional independence relations. For this class of algorithms, it is impossible to determine which of two conditional independence equivalent causal structures generated a given probability distribution, given only the set of conditional independence and dependence relations true of the observed distribution. We will describe a polynomial (in the number of vertices) time algorithm for determining when two DAGs which may have latent variables or selection bias are conditional independence equivalent. A DAG G entails a conditional independence relation R if and only if R is true in every probability measure satisfying the local directed Markov property for G. (We place definitions and sets of variables in boldface.) Pearl, Geiger, and Verma (Pearl 1988) have shown that there is a graphical relation, ct-separation, that holds among three disjoint sets of variable A, and B, and C in DAG G if and only if G entails that A is independent of B given C. A vertex Y is a collider on an undirected path U if U contains a subpath X \u2794 Y ~ Z. Say that a vertex V on an undirected path U between X and Y is active on U given Z (Z not containing X and Y) if and only if either V is not a collider on U and not in Z, or V is a collider on U and is an ancestor of Z. For three disjoint sets of variables A, B, and C, A is d-connected to B given C in graph G, if and only if there is an undirected path from some member of A to a member of B such that every vertex on U is active given C; for three disjoint sets of variables A, B, and C, A is dseparated from B given C in graph G, if and only A is not cl-connected to B given C. Two DAGs are conditional independence equivalent if and only if they have the same vertices and entail the same set of conditional independence relations . If two DAGs G 1 and G2 are conditional independence equivalent, the set of distributions that satisfy the local directed Markov property for G1 equals the set of distribution that satisfy the local directed Markov property for G2\u2022 Theorems that provide the basis for polynomial time algorithms for testing conditional independence equivalence for DAGs were given in Verma and Pearl (1990), for cyclic directed graphs in Richardson (1994), and for directed acyclic graphs with latent variables in Spirtes and Verma (1992)."
            },
            "slug": "A-Polynomial-Time-Algorithm-For-Determining-DAG-in-Spirtes",
            "title": {
                "fragments": [],
                "text": "A Polynomial Time Algorithm For Determining DAG Equivalence in the Presence of Latent Variables and Selection Bias"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102636025"
                        ],
                        "name": "C. Chow",
                        "slug": "C.-Chow",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Chow",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119394814"
                        ],
                        "name": "C. N. Liu",
                        "slug": "C.-N.-Liu",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Liu",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. N. Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 137
                            }
                        ],
                        "text": "However, finding the best representation of a probability distribution in terms of an undirected tree has a simple solution, as shown by Chow and Liu (1968). First we define the cross-entropy between X and Y as"
                    },
                    "intents": []
                }
            ],
            "corpusId": 27127853,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "683fe3bbf2b2e628cf40d90e35fb39effc63b7e9",
            "isKey": false,
            "numCitedBy": 2729,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented to approximate optimally an n -dimensional discrete probability distribution by a product of second-order distributions, or the distribution of the first-order tree dependence. The problem is to find an optimum set of n - 1 first order dependence relationship among the n variables. It is shown that the procedure derived in this paper yields an approximation of a minimum difference in information. It is further shown that when this procedure is applied to empirical observations from an unknown distribution of tree dependence, the procedure is the maximum-likelihood estimate of the distribution."
            },
            "slug": "Approximating-discrete-probability-distributions-Chow-Liu",
            "title": {
                "fragments": [],
                "text": "Approximating discrete probability distributions with dependence trees"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that the procedure derived in this paper yields an approximation of a minimum difference in information when applied to empirical observations from an unknown distribution of tree dependence, and the procedure is the maximum-likelihood estimate of the distribution."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798654"
                        ],
                        "name": "M. Studen\u00fd",
                        "slug": "M.-Studen\u00fd",
                        "structuredName": {
                            "firstName": "Milan",
                            "lastName": "Studen\u00fd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Studen\u00fd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 96
                            }
                        ],
                        "text": ", embedded multi-valued dependencies (Sagiv and Walecka 1982) and natural conditional functions (Spohn 1988; Studen\u00fd 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6132780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10da817a21b6c5b45a2e177de1950cbef4728f96",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Conditional-independence-and-natural-conditional-Studen\u00fd",
            "title": {
                "fragments": [],
                "text": "Conditional independence and natural conditional functions"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Approx. Reason."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3184408"
                        ],
                        "name": "N. Wermuth",
                        "slug": "N.-Wermuth",
                        "structuredName": {
                            "firstName": "Nanny",
                            "lastName": "Wermuth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wermuth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124985704,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d9646d48c8e8032f06d67108a780e96af186297a",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY Graphs consisting of points, and lines or arrows as connections between selected pairs of points, are used to formulate hypotheses about relations between variables. Points stand for variables, connections represent associations. When a missing connection is interpreted as a conditional independence, the graph characterizes a conditional independence structure as well. Statistical models, called graphical chain models, correspond to special types of graphs which are interpreted in this fashion. Examples are used to illustrate how conditional independences are reflected in summary statistics derived from the models and how the graphs help to identify analogies and equivalences between different models. Graphical chain models are shown to provide a unifying concept for many statistical techniques that in the past have proven to be useful in analyses of data. They also provide tools for new types of analysis."
            },
            "slug": "On-Substantive-Research-Hypotheses,-Conditional-and-Wermuth-Lauritzen",
            "title": {
                "fragments": [],
                "text": "On Substantive Research Hypotheses, Conditional Independence Graphs and Graphical Chain Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1452149100"
                        ],
                        "name": "F. Seillier-Moiseiwitsch",
                        "slug": "F.-Seillier-Moiseiwitsch",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Seillier-Moiseiwitsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Seillier-Moiseiwitsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 205
                            }
                        ],
                        "text": "It can be shown that, under broad conditions not requiring independence, as M \u2192 \u221e the distribution of ZM will be asymptotically standard normal under the null hypothesis that the data arise from the model (Seillier-Moiseiwitsch and Dawid 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122746062,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "70f90f5cb19862c4b270257d5db811fbea5dfad6",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Events are observed sequentially, and at each stage a probability for the next event is assessed. We consider the relationship between the sequence of probability forecasts and the sequence of outcomes. We argue that the forecasts may be considered \u201cempirically valid\u201d when both these sequences are consistent with a common joint distribution for the events. To aid in assessing validity, we introduce various test statistics that measure, in a natural way, the empirical performance of the probability forecasts in the light of the outcomes obtained. It is shown that under the null hypothesis of forecast validity, such statistics will, after suitable normalization, have a Standard normal (or chi-squared) distribution, virtually irrespective of the common joint distribution supposed to underlie both sequences."
            },
            "slug": "On-Testing-the-Validity-of-Sequential-Probability-Seillier-Moiseiwitsch-Dawid",
            "title": {
                "fragments": [],
                "text": "On Testing the Validity of Sequential Probability Forecasts"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3166332"
                        ],
                        "name": "J. Charnes",
                        "slug": "J.-Charnes",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Charnes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Charnes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11849964,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e5b6ef173b41debb95de8997fa4644a7b1a2860e",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "The main goal of this paper is to describe a new Monte Carlo method for solving influence diagrams using local computation. We propose a forward Monte Carlo sampling technique that draws independent and identically distributed observations. Methods that have been proposed in this spirit sample from the entire distribution. However, when the number of variables is large, the state space of all variables is exponentially large, and the sample size required for good estimates may be too large to be practical. In this paper, we develop a forward Monte Carlo method, which generates observations from only a small set of chance variables for each decision node in the influence diagram. We use methods developed for exact solution of influence diagrams to limit the number of chance variables sampled at any time. Because influence diagrams model each chance variable with a conditional probability distribution, the forward Monte Carlo solution method lends itself very well to influence-diagram representations."
            },
            "slug": "A-Forward-Monte-Carlo-Method-For-Solving-Influence-Charnes-Shenoy",
            "title": {
                "fragments": [],
                "text": "A Forward Monte Carlo Method For Solving Influence Diagrams Using Local Computation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2746221"
                        ],
                        "name": "S. A. Andersson",
                        "slug": "S.-A.-Andersson",
                        "structuredName": {
                            "firstName": "Steen",
                            "lastName": "Andersson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Andersson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710305"
                        ],
                        "name": "D. Madigan",
                        "slug": "D.-Madigan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Madigan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Madigan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2830733"
                        ],
                        "name": "M. Perlman",
                        "slug": "M.-Perlman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Perlman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Perlman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 181
                            }
                        ],
                        "text": "If we restrict attention to directed acyclic graphs, there is no natural representative of an equivalence class within the class, but it can be characterized by its essential graph (Andersson et al. 1996b), the chain graph (with the same skeleton) in which an edge has an arrow if and only if at least one member of the equivalence class has that arrow, and none has the reverse arrow (see Section 11."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123558157,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5da1cd2fcf7ed34fbc1f667cfec2712997ca0368",
            "isKey": false,
            "numCitedBy": 463,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Undirected graphs and acyclic digraphs (ADGs), as well as their mutual extension to chain graphs, are widely used to describe dependencies among variables in multivariate distributions. In particular, the likelihood functions of ADG models admit convenient recursive factorizations that often allow explicit maximum likelihood estimates and that are well suited to building Bayesian networks for expert systems. Whereas the undirected graph associated with a dependence model is uniquely determined, there may, however, be many ADGs that determine the same dependence (= Markov) model. Thus, the family of all ADGs with a given set of vertices is naturally partitioned into Markov-equivalence classes, each class being associated with a unique statistical model. Statistical procedures, such as model selection or model averaging, that fail to take into account these equivalence classes, may incur substantial computational or other inefficiencies. Here it is shown that each Markov-equivalence class is uniquely determined by a single chain graph, the essential graph, that is itself simultaneously Markov equivalent to all ADGs in the equivalence class. Essential graphs are characterized, a polynomial-time algorithm for their construction is given, and their applications to model selection and other statistical questions are described."
            },
            "slug": "A-characterization-of-Markov-equivalence-classes-Andersson-Madigan",
            "title": {
                "fragments": [],
                "text": "A characterization of Markov equivalence classes for acyclic digraphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 45
                            }
                        ],
                        "text": "2 respectively, using the numbers taken from Shenoy (1992), but with utilities scaled down by a factor of 1000."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1365514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29a1d5f0c7b4512a293e6e8de19a90550b17a1b0",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes valuation-based systems for representing and solving discrete optimization problems. In valuation-based systems, we represent information in an optimization problem using variables, sample spaces of variables, a set of values, and functions that map sample spaces of sets of variables to the set of values. The functions, called valuations, represent the factors of an objective function. Solving the optimization problem involves using two operations called combination and marginalization. Combination tells us how to combine the factors of the joint objective function. Marginalization is either maximization or minimization. Solving an optimization problem can be simply described as finding the marginal of the joint objective function for the empty set. We state some simple axioms that combination and marginalization need to satisfy to enable us to solve an optimization problem using local computation. For optimization problems, the solution method of valuation-based systems reduces to non-serial dynamic programming. Thus our solution method for VBS can be regarded as an abstract description of dynamic programming. And our axioms can be viewed as conditions that permit the use of dynamic programming."
            },
            "slug": "Valuation-based-systems-for-discrete-optimisation-Shenoy",
            "title": {
                "fragments": [],
                "text": "Valuation-based systems for discrete optimisation"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The solution method of valuation-based systems reduces to non-serial dynamic programming, and some simple axioms need to satisfy to enable us to solve an optimization problem using local computation."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6645021"
                        ],
                        "name": "P. Walley",
                        "slug": "P.-Walley",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Walley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Walley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 131
                            }
                        ],
                        "text": "There has also been research into incomplete specification of the full joint distribution, using say upper and lower probabilities (Walley 1990), in which resulting intervals of probabilities may be computed using linear (van der Gaag 1991) or non-linear (Andersen and Hooker 1994) programming techniques."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119675760,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f2814b81596f4c0184dfe87ad22e47308a5b0338",
            "isKey": false,
            "numCitedBy": 3407,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Reasoning-with-Imprecise-Probabilities-Walley",
            "title": {
                "fragments": [],
                "text": "Statistical Reasoning with Imprecise Probabilities"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 535323,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ac789d8e373cbb3260b2881d66fe00789adf291f",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we give a simple account of local computation of marginal probabilities when the joint probability distribution is given in factored form and the sets of variables involved in the factors form a hypertree. Previous expositions of such local computation have emphasized conditional probability. We believe this emphasis is misplaced. What is essential to local computation is a factorization. It is not essential that this factorization be interpreted in terms of conditional probabilities. The account given here avoids the divisions required by conditional probabilities and generalizes readily to alternative measures of subjective probability, such as Dempster-Shafer or Spohnian belief functions."
            },
            "slug": "Probability-propagation-Shafer-Shenoy",
            "title": {
                "fragments": [],
                "text": "Probability propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The account given here avoids the divisions required by conditional probabilities and generalizes readily to alternative measures of subjective probability, such as Dempster-Shafer or Spohnian belief functions."
            },
            "venue": {
                "fragments": [],
                "text": "Annals of Mathematics and Artificial Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102765719"
                        ],
                        "name": "Z. Covaliu",
                        "slug": "Z.-Covaliu",
                        "structuredName": {
                            "firstName": "Z.",
                            "lastName": "Covaliu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Covaliu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867429"
                        ],
                        "name": "R. M. Oliver",
                        "slug": "R.-M.-Oliver",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Oliver",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. M. Oliver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 202
                            }
                        ],
                        "text": "The valuation network method of Shenoy (1996) adapted to asymmetric problems is one such proposal; others include contingent influence diagrams (Fung and Shachter 1990) and sequential decision diagrams (Covaliu and Oliver 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121381472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cfa4d916e73e0df0a17d5c6c515d142090fa4a6",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce a new graph, the sequential decision diagram, to aid in modeling formulation, and solution of sequential decision problems under uncertainty. While as compact as an influence diagram, the sequential diagram captures the asymmetric and sequential aspects of decision problems as effectively as decision trees. We show that a unified framework consisting of a sequential diagram, an influence diagram, and a common formulation table for the problem's data, suffices for compact and consistent representation, economical formulation, and efficient solution of (asymmetric) decision problems. In addition to asymmetry, the framework exploits other sources of computational efficiency, such as conditional independence and value function decomposition, making it also useful in evaluating dynamic-programming problems. The formulation table and recursive algorithm can be readily implemented in computers for solving large-scale problems. Examples are provided to illustrate the methodology in both asymmetric and symmetric cases."
            },
            "slug": "Representation-and-solution-of-decision-problems-Covaliu-Oliver",
            "title": {
                "fragments": [],
                "text": "Representation and solution of decision problems using sequential decision diagrams"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that a unified framework consisting of a sequential diagram, an influence diagram, and a common formulation table for the problem's data, suffices for compact and consistent representation, economical formulation, and efficient solution of (asymmetric) decision problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144238498"
                        ],
                        "name": "B. N. Larsen",
                        "slug": "B.-N.-Larsen",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Larsen",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. N. Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "74208271"
                        ],
                        "name": "H.-G. Leimer",
                        "slug": "H.-G.-Leimer",
                        "structuredName": {
                            "firstName": "H.-G.",
                            "lastName": "Leimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H.-G. Leimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20450895,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f78884604e3fb89b1fb24d2a9403191dc9e63bd3",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate directed Markov fields over finite graphs without positivity assumptions on the densities involved. A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property. We give a simple proof of the fact that the directed, local Markov property and directed, global Markov property are equivalent and \u2013 in the case of absolute continuity w. r. t. a product measure \u2013 equivalent to the recursive factorization of densities. It is argued that our criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl. It follows that our criterion cannot be sharpened."
            },
            "slug": "Independence-properties-of-directed-markov-fields-Lauritzen-Dawid",
            "title": {
                "fragments": [],
                "text": "Independence properties of directed markov fields"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property and it is argued that this criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl."
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917749"
                        ],
                        "name": "N. Best",
                        "slug": "N.-Best",
                        "structuredName": {
                            "firstName": "Nicky",
                            "lastName": "Best",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Best"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107218881"
                        ],
                        "name": "A. Thomas",
                        "slug": "A.-Thomas",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Thomas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143999144"
                        ],
                        "name": "C. E. G. Brayne",
                        "slug": "C.-E.-G.-Brayne",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Brayne",
                            "middleNames": [
                                "E.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. E. G. Brayne"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 799,
                                "start": 257
                            }
                        ],
                        "text": "In principle it is possible to incorporate additional \u201cselection variables\u201d into one\u2019s model, thus modelling explicitly the dependence of the observation process on the values, observed or unobserved, for the variables in the case (Diggle and Kenward 1994; Best et al. 1996). One then needs to take account of the fact that the probability structure of the observed data has been modified by conditioning on the fact of selection. However, any conclusions drawn can be very sensitive to the specific modelling assumptions made concerning the selection process, and external evidence about this may be very weak. Cowell et al. (1993a) consider the implementation of directed graphical models incorporating selection in the context of biased reporting of adverse drug reactions. Spirtes et al. (1995) treat some general aspects of causal inference from observational data in the presence of latent variables and selection bias."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 634,
                                "start": 257
                            }
                        ],
                        "text": "In principle it is possible to incorporate additional \u201cselection variables\u201d into one\u2019s model, thus modelling explicitly the dependence of the observation process on the values, observed or unobserved, for the variables in the case (Diggle and Kenward 1994; Best et al. 1996). One then needs to take account of the fact that the probability structure of the observed data has been modified by conditioning on the fact of selection. However, any conclusions drawn can be very sensitive to the specific modelling assumptions made concerning the selection process, and external evidence about this may be very weak. Cowell et al. (1993a) consider the implementation of directed graphical models incorporating selection in the context of biased reporting of adverse drug reactions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 231
                            }
                        ],
                        "text": "In principle it is possible to incorporate additional \u201cselection variables\u201d into one\u2019s model, thus modelling explicitly the dependence of the observation process on the values, observed or unobserved, for the variables in the case (Diggle and Kenward 1994; Best et al. 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120497206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "502566caeab0534f47e8a38fb8b377c6792b8d8c",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Models with complex structure arise in many social science applications and appear natural candidates for the use of Markov chain Monte Carlo methods for inference. Conditional independence assumptions simplify the model specification and make estimation using Gibbs sampling particularly appropriate. Two examples are discussed: random effects models for repeated ordered categorical data and sensitivity analysis to assumptions concerning the mechanism underlying informative drop\u2010out in a longitudinal study. The use of a program bugs is demonstrated."
            },
            "slug": "Bayesian-Analysis-of-Realistically-Complex-Models-Best-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Bayesian Analysis of Realistically Complex Models"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Models with complex structure arise in many social science applications and appear natural candidates for the use of Markov chain Monte Carlo methods for inference, including random effects models for repeated ordered categorical data and sensitivity analysis to assumptions concerning the mechanism underlying informative drop\u2010out in a longitudinal study."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2847371"
                        ],
                        "name": "M. Cowles",
                        "slug": "M.-Cowles",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Cowles",
                            "middleNames": [
                                "Kathryn"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cowles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9894852"
                        ],
                        "name": "B. Carlin",
                        "slug": "B.-Carlin",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Carlin",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Carlin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 117
                            }
                        ],
                        "text": ", the Markov chain has converged to its equilibrium distribution) is a topic of current research \u2014 see, for example, Cowles and Carlin (1996) for a review."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46906175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d96b4d467044e420a87ed99b07e23ad68e2a401f",
            "isKey": false,
            "numCitedBy": 1657,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A critical issue for users of Markov chain Monte Carlo (MCMC) methods in applications is how to determine when it is safe to stop sampling and use the samples to estimate characteristics of the distribution of interest. Research into methods of computing theoretical convergence bounds holds promise for the future but to date has yielded relatively little of practical use in applied work. Consequently, most MCMC users address the convergence problem by applying diagnostic tools to the output produced by running their samplers. After giving a brief overview of the area, we provide an expository review of 13 convergence diagnostics, describing the theoretical basis and practical implementation of each. We then compare their performance in two simple models and conclude that all of the methods can fail to detect the sorts of convergence failure that they were designed to identify. We thus recommend a combination of strategies aimed at evaluating and accelerating MCMC sampler convergence, including ap..."
            },
            "slug": "Markov-Chain-Monte-Carlo-conver-gence-diagnostics:-Cowles-Carlin",
            "title": {
                "fragments": [],
                "text": "Markov Chain Monte Carlo conver-gence diagnostics: a comparative review"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "All of the methods in this work can fail to detect the sorts of convergence failure that they were designed to identify, so a combination of strategies aimed at evaluating and accelerating MCMC sampler convergence are recommended."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775921"
                        ],
                        "name": "Uffe Kj\u00e6rulff",
                        "slug": "Uffe-Kj\u00e6rulff",
                        "structuredName": {
                            "firstName": "Uffe",
                            "lastName": "Kj\u00e6rulff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uffe Kj\u00e6rulff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33581946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca52654f8dceeb83b1efc11e9f4b163ca9b4038d",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a methodology for performing approximate computations in complex probabilistic expert systems, when some components can be handled exactly and others require approximation or simulation. This is illustrated by means of a modified version of the familiar \u2018chest-clinic\u2019 problem."
            },
            "slug": "Hybrid-Propagation-in-Junction-Trees-Dawid-Kj\u00e6rulff",
            "title": {
                "fragments": [],
                "text": "Hybrid Propagation in Junction Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A methodology for performing approximate computations in complex probabilistic expert systems, when some components can be handled exactly and others require approximation or simulation, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "IPMU"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 160
                            }
                        ],
                        "text": "Also, one can consider the \u2018complete data\u2019 for each case just to include the values for the ancestral set of the observed variables, an idea related to that of Geng et al. (1996) and Didelez and Pigeot (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 96
                            }
                        ],
                        "text": "One can also use simulation schemes which are derivatives of those explored in image processing (Geman and Geman 1984)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 97
                            }
                        ],
                        "text": "One can also use simulation schemes which are derivatives of those explored in image processing (Geman and Geman 1984). This general statistical computational technique was originally suggested by Pearl (1987) for use in expert systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": true,
            "numCitedBy": 18709,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722047"
                        ],
                        "name": "C. Beeri",
                        "slug": "C.-Beeri",
                        "structuredName": {
                            "firstName": "Catriel",
                            "lastName": "Beeri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Beeri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144112511"
                        ],
                        "name": "Ronald Fagin",
                        "slug": "Ronald-Fagin",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Fagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Fagin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145249669"
                        ],
                        "name": "D. Maier",
                        "slug": "D.-Maier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Maier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682406"
                        ],
                        "name": "A. Mendelzon",
                        "slug": "A.-Mendelzon",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Mendelzon",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mendelzon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748179"
                        ],
                        "name": "M. Yannakakis",
                        "slug": "M.-Yannakakis",
                        "structuredName": {
                            "firstName": "Mihalis",
                            "lastName": "Yannakakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yannakakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1788509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a758b4bbd0e58f30d18eb8c7cb092e7853c900a3",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a class of database descriptions, involving one \u201cacyclic\u201d join dependency and a collection of functional dependencies, and nothing else, that appears powerful enough to describe most any real-world body of data in relational database terms. Further, this class has many desirable properties. Some properties make operations like updates and the selection of joins to implement a query over a universal relation especially easy. Other properties of interest were studied by other researchers who described the same class in radically different terms, and found desirable properties in their own contexts. It is the purpose of this paper to define the class formally, to give its important properties and the equivalences with the other classes mentioned, and to explain the importance of each property. This paper is intended to summarize the results that will appear in more detail in [FMU] and [BFMY]."
            },
            "slug": "Properties-of-acyclic-database-schemes-Beeri-Fagin",
            "title": {
                "fragments": [],
                "text": "Properties of acyclic database schemes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The purpose of this paper is to define the class formally, to give its important properties and the equivalences with the other classes mentioned, and to explain the importance of each property."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '81"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1988445"
                        ],
                        "name": "Thomas Verma",
                        "slug": "Thomas-Verma",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Verma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Verma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9752884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eacbaf29e97fcce761171cc9b3b8ca0c229e4576",
            "isKey": false,
            "numCitedBy": 469,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Causal-networks:-semantics-and-expressiveness-Verma-Pearl",
            "title": {
                "fragments": [],
                "text": "Causal networks: semantics and expressiveness"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145673139"
                        ],
                        "name": "D. Edwards",
                        "slug": "D.-Edwards",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Edwards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34892196"
                        ],
                        "name": "T. Havr\u00e1nek",
                        "slug": "T.-Havr\u00e1nek",
                        "structuredName": {
                            "firstName": "Tom\u00e1\u0161",
                            "lastName": "Havr\u00e1nek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Havr\u00e1nek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123135389,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "714f86fa05e3f0f905525a08131e1a692184f4d3",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract An efficient procedure for model selection from large families of models is described. It is closely related to the all possible models approach but is considerably faster. It is based on two principles: first, if a model is accepted, then all models that include it are considered to be accepted; second, if a model is rejected, then all of its submodels are considered to be rejected. Application of the procedure to variable selection in multiple regression is illustrated. General algorithms are described that enable the procedure to be applied to any family of models that forms a lattice. As an example, a problem in multiple comparisons is considered."
            },
            "slug": "A-fast-model-selection-procedure-for-large-families-Edwards-Havr\u00e1nek",
            "title": {
                "fragments": [],
                "text": "A fast model selection procedure for large families of models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49715681"
                        ],
                        "name": "P. Games",
                        "slug": "P.-Games",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Games",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Games"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 145546766,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "6fbe9b95e35bed4294b8089056c3c2548c454745",
            "isKey": false,
            "numCitedBy": 845,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractPage and various collaborators (Keith, Page, & Robertson, 1984; Page, 1981; Page & Keith, 1981, 1982) have defended the use of data from investigations (correlational studies) to make causative conclusions. These methods are not defensible logically or statistically. They can only suggest hypotheses that then should be tested by proper experiments. At worst, as in the Coleman studies, they have been used to make social policy based on unjustified conclusions. The logical flaw of the methods of path analysis or structural equation modeling is shown. A proper evaluation of the role of investigations versus experiments is cited in the work of Cochran (as described by Rubin [1983])."
            },
            "slug": "Correlation-and-Causation:-A-Logical-Snafu-Games",
            "title": {
                "fragments": [],
                "text": "Correlation and Causation: A Logical Snafu"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31211229"
                        ],
                        "name": "R. K\u00e1lm\u00e1n",
                        "slug": "R.-K\u00e1lm\u00e1n",
                        "structuredName": {
                            "firstName": "Rudolf",
                            "lastName": "K\u00e1lm\u00e1n",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. K\u00e1lm\u00e1n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2813233"
                        ],
                        "name": "R. Bucy",
                        "slug": "R.-Bucy",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Bucy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bucy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 581,
                                "start": 189
                            }
                        ],
                        "text": "A very early variant of the basic propagation algorithm was derived and used by Thiele (1880), who derived the simplest special case of what is now known as the Kalman filter and smoother (Kalman and Bucy 1961); see Lauritzen (1981). This algorithm is essentially an instance of the propagation algorithm as described here; see Normand and Tritchler (1992) for the pure continuous case. In effect one is then using local computation to solve sparse systems of linear equations, which also was an early instance of the algorithm (Parter 1961; Rose 1970). Shachter and Kenley (1989) introduced Gaussian influence diagrams to model networks of Gaussian random variables for decision problems and they were later extended to the mixed-discrete Gaussian case (Poland 1994); see also the next chapter."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 188
                            }
                        ],
                        "text": "A very early variant of the basic propagation algorithm was derived and used by Thiele (1880), who derived the simplest special case of what is now known as the Kalman filter and smoother (Kalman and Bucy 1961); see Lauritzen (1981)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 189
                            }
                        ],
                        "text": "A very early variant of the basic propagation algorithm was derived and used by Thiele (1880), who derived the simplest special case of what is now known as the Kalman filter and smoother (Kalman and Bucy 1961); see Lauritzen (1981). This algorithm is essentially an instance of the propagation algorithm as described here; see Normand and Tritchler (1992) for the pure continuous case."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8141345,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5c2f635fd11d2d001b7f9921007c6d3cf201eebf",
            "isKey": false,
            "numCitedBy": 5952,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonlinear differential equation of the Riccati type is derived for the covariance matrix of the optimal filtering error. The solution of this \"variance equation\" completely specifies the optimal filter for either finite or infinite smoothing intervals and stationary or nonstationary statistics. The variance equation is closely related to the Hamiltonian (canonical) differential equations of the calculus of variations. Analytic solutions are available in some cases. The significance of the variance equation is illustrated by examples which duplicate, simplify, or extend earlier results in this field. The Duality Principle relating stochastic estimation and deterministic control problems plays an important role in the proof of theoretical results. In several examples, the estimation problem and its dual are discussed side-by-side. Properties of the variance equation are of great interest in the theory of adaptive systems. Some aspects of this are considered briefly."
            },
            "slug": "New-Results-in-Linear-Filtering-and-Prediction-K\u00e1lm\u00e1n-Bucy",
            "title": {
                "fragments": [],
                "text": "New Results in Linear Filtering and Prediction Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The Duality Principle relating stochastic estimation and deterministic control problems plays an important role in the proof of theoretical results and properties of the variance equation are of great interest in the theory of adaptive systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67236102"
                        ],
                        "name": "R. Miller",
                        "slug": "R.-Miller",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2221779"
                        ],
                        "name": "H. E. Pople",
                        "slug": "H.-E.-Pople",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Pople",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. E. Pople"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145274770"
                        ],
                        "name": "J. Myers",
                        "slug": "J.-Myers",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Myers",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Myers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 64
                            }
                        ],
                        "text": "1991) of the QMR/Internist system for general medical diagnosis (Miller et al. 1982)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 75
                            }
                        ],
                        "text": "Any such model of these abstract axioms has been termed a semi-graphoid by Pearl (1988) or, if (P5) is also satisfied, a graphoid."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3005462,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "0c7df16c0839c7517a91b63b82348fd30e033d53",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Internist-I is an experimental computer program capable of making multiple and complete diagnoses in internal medicine. It differs from most other programs for computer-assisted diagnosis in the generality of its approach and the size and diversity of its knowledge base. To document the strengths and weaknesses of the program we performed a systematic evaluation of the capabilities of INTERNIST-I. Its performance on a series of 19 clinicopathological exercises (Case Records of the Massachusetts General Hospital) published in the Journal appeared qualitatively similar to that of the hospital clinicians but inferior to that of the case discussants. The evaluation demonstrated that the present form of the program is not sufficiently reliable for clinical applications. Specific deficiencies that must be overcome include the program's inability to reason anatomically or temporally, its inability to construct differential diagnoses spanning multiple areas, its occasional attribution of findings to improper causes, and its inability to explain its \"thinking\"."
            },
            "slug": "Internist-1,-an-experimental-computer-based-for-Miller-Pople",
            "title": {
                "fragments": [],
                "text": "Internist-1, an experimental computer-based diagnostic consultant for general internal medicine."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The evaluation demonstrated that the present form of the program is not sufficiently reliable for clinical applications and specific deficiencies that must be overcome include the program's inability to reason anatomically or temporally, its inability to construct differential diagnoses spanning multiple areas."
            },
            "venue": {
                "fragments": [],
                "text": "The New England journal of medicine"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34577797"
                        ],
                        "name": "D. Rose",
                        "slug": "D.-Rose",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rose",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rose"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123179639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5b0a11b0de16a2c600d8cf27d38d764236d3284",
            "isKey": false,
            "numCitedBy": 411,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-GRAPH-THEORETIC-STUDY-OF-THE-NUMERICAL-SOLUTION-Rose",
            "title": {
                "fragments": [],
                "text": "A GRAPH-THEORETIC STUDY OF THE NUMERICAL SOLUTION OF SPARSE POSITIVE DEFINITE SYSTEMS OF LINEAR EQUATIONS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774015"
                        ],
                        "name": "A. Becker",
                        "slug": "A.-Becker",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Becker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Becker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144527211"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5055742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78097f6d232d06349e1de4457c48128ca1fa2a1a",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Au algorithm is developed for findiug a close to optimal junction tree of a given graph G. The algorithm has a worst case complexity O(ckna) where a and c are constants, n is the nmnber of vertices, and k is the size of the largest clique in a juuction tree of G in which this size is minimized. The algorithm guarantees that the logarithm of the size of the state space of the heaviest clique in the junction tree produced is less than a constant factor off the optional value. When k = O(log n) our algorithm yields a polynomial inference algorithm for Bayesian networks."
            },
            "slug": "A-sufficiently-fast-algorithm-for-finding-close-to-Becker-Geiger",
            "title": {
                "fragments": [],
                "text": "A sufficiently fast algorithm for finding close to optimal junction trees"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The Au algorithm is developed for findiug a close to optimal junction tree of a given graph G in which this size is minimized and yields a polynomial inference algorithm for Bayesian networks."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145673139"
                        ],
                        "name": "D. Edwards",
                        "slug": "D.-Edwards",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Edwards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102772771"
                        ],
                        "name": "Havr\u00e1nek TOM\u00c1\u02c7",
                        "slug": "Havr\u00e1nek-TOM\u00c1\u02c7",
                        "structuredName": {
                            "firstName": "Havr\u00e1nek",
                            "lastName": "TOM\u00c1\u02c7",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Havr\u00e1nek TOM\u00c1\u02c7"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122315129,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "7a43bb3614abd35c897c36e0d7c1a5ed7ad38f44",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A procedure to select the simplest acceptable models for a multidimensional contingency table is proposed. It is based on two rules: first, that if a model is accepted, then all models that include it are considered to be accepted, and secondly, that if a model is rejected, then all its submodels are considered to be rejected. Two versions are described, one for the class of graphical models, and the other for the class of hierarchical log linear models. Application of both versions to a six-dimensional table is illustrated. The procedure can be regarded as an alternative to fitting all possible models, made computationally feasible by application of the two rules. It is a generalization of the procedure proposed by Havr'anek (1984), but is in many cases considerably faster."
            },
            "slug": "A-fast-procedure-for-model-search-in-contingency-Edwards-TOM\u00c1\u02c7",
            "title": {
                "fragments": [],
                "text": "A fast procedure for model search in multidimensional contingency tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144725965"
                        ],
                        "name": "R. R. Hocking",
                        "slug": "R.-R.-Hocking",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Hocking",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. R. Hocking"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47151940"
                        ],
                        "name": "H. Oxspring",
                        "slug": "H.-Oxspring",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Oxspring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Oxspring"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39120511,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6cb3418ae7a4eae035d539055c0f782a5f87deb6",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The literature on categorized data has been primarily concerned with the analysis of contingency tables. In the usual situation, it is assumed that we have sampled a multinomial population in which the classes are described according to two or more categories and the data are summarized in a contingency table with corresponding dimension. Specifically, in a two-way table with r rows and c columns, it is assumed that the data in the rc cells follow a multinomial distribution with cell probabilities 7iij . The usual analysis consists of estimating the rii and testing certain hypotheses on these parameters. In this paper, we consider situations in which the data have been taken from such a multinomial population, but, because of partial categorization of some of the observations, the summary is in the form of two or more related tables. For example, we may have data ni;, i = 1, 2; j = 1, 2, 3, in a 2 X 3 table from a population with six classes described by two categories with two and three classes, respectively. Let us assume that in addition, we have data mij , i = 1, 2; j = 1, 2, in a 2 X 2 table whose description is derived from the original table in the sense that the first two column classifications have been combined. For the purpose of gaining additional precision in the analysis, it is desired to combine the information in the two sets of data. If the data nii are assumed to follow a multinomial distribution with parameters irij, = 1, 2; j = 1, 2, 3, then the data mij are also multinomial with parameters (7ril + 7r12), 713 , (X21 + r22), r23 . Assuming that the two sets of data are independent, we may obtain maximum likelihood estimates of the parameters from the combined data using the procedure described by Hocking and Oxspring [1971] (hereafter abbreviated (HO)). The purpose of this paper is to illustrate the application of (HO) to the estimation of parameters from contingency data when, in addition to the basic table, we have tables which arise because row and/or column classifications have been combined. In some cases, the partially categorized data arises because of the nature of the data and the manner in which it was collected. Alternatively, the experiment may have been intentionally designed"
            },
            "slug": "The-analysis-of-partially-categorized-contingency-Hocking-Oxspring",
            "title": {
                "fragments": [],
                "text": "The analysis of partially categorized contingency data."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The purpose of this paper is to illustrate the application of (HO) to the estimation of parameters from contingency data when, in addition to the basic table, the authors have tables which arise because row and/or column classifications have been combined."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135764"
                        ],
                        "name": "A. Kolmogorov",
                        "slug": "A.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Kolmogorov",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kolmogorov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 72
                            }
                        ],
                        "text": "These axioms are not quite in the form given in the standard account by Kolmogorov (1950). Our Axiom 3 relates unconditional and conditional probabilities, regarded as having independent existence on an equal footing (indeed, from our viewpoint any \u2018unconditional\u2019 probability is only really so by appearance, the background information behind its assessment having been implicitly assumed and omitted from the notation)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117215830,
            "fieldsOfStudy": [
                "Geology",
                "Mathematics",
                "Economics"
            ],
            "id": "42eda8d46ca9fb35d9c844baa37b578e24cf20e3",
            "isKey": false,
            "numCitedBy": 1868,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Theories of ProbabilityFoundations of Probabilistic Logic ProgrammingGood ThinkingStatistical Foundations of Data ScienceFoundations of Risk AnalysisFoundations of Estimation TheoryThe Foundations of StatisticsProbability Theory in FinanceFoundations of Agnostic StatisticsProbability, Statistics, and TruthFoundations of ProbabilityFoundations of Quantization for Probability DistributionsMathematical Foundations of the Calculus of ProbabilityThe Foundations of Causal Decision TheoryAn Objective Theory of Probability (Routledge Revivals)Probability TheoryDelaware Seminar in the Foundations of PhysicsFoundations of Stochastic AnalysisTheoretical Foundations of Functional Data Analysis, with an Introduction to Linear OperatorsTheories of ProbabilityProbabilistic Foundations of Statistical Network AnalysisElements of the Theory of Functions and Functional Analysis [Two Volumes in One]Probability TheoryPhilosophical Foundations of Probability TheoryProbability Foundations of Economic TheoryGame-Theoretic Foundations for Probability and FinanceFoundations of Statistical MechanicsProbability Foundations for EngineersFoundations of Data ScienceFoundations and Philosophy of Epistemic Applications of Probability TheoryFoundations of Probability Theory, Statistical Inference, and Statistical Theories of ScienceRandom Measures, Theory and ApplicationsModern Probability Theory and Its ApplicationsRethinking the Foundations of StatisticsMathematical Foundations of Information TheoryFoundations of the Theory of ProbabilityFoundations of Modern ProbabilityFoundations of the theory of probabilityMathematical Foundations of Infinite-Dimensional Statistical ModelsFoundations of Statistics"
            },
            "slug": "Foundations-of-the-theory-of-probability-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "Foundations of the theory of probability"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "Theories of ProbabilityFoundation of Probabilistic Logic ProgrammingGood ThinkingStatistical Foundations of Data ScienceFoundations of Risk Analysis foundations of Estimation Theory findations of the theory of probability."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10023329,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "81a15463a09b9555a78b755e43f9a1c278321ce3",
            "isKey": false,
            "numCitedBy": 1887,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY The primary aim of this paper is to show how graphical models can be used as a mathematical language for integrating statistical and subject-matter information. In particular, the paper develops a principled, nonparametric framework for causal inference, in which diagrams are queried to determine if the assumptions available are sufficient for identifying causal effects from nonexperimental data. If so the diagrams can be queried to produce mathematical expressions for causal effects in terms of observed distributions; otherwise, the diagrams can be queried to suggest additional observations or auxiliary experiments from which the desired inferences can be obtained."
            },
            "slug": "Causal-diagrams-for-empirical-research-Pearl",
            "title": {
                "fragments": [],
                "text": "Causal diagrams for empirical research"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038700"
                        ],
                        "name": "V. Didelez",
                        "slug": "V.-Didelez",
                        "structuredName": {
                            "firstName": "Vanessa",
                            "lastName": "Didelez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Didelez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773280"
                        ],
                        "name": "I. Pigeot",
                        "slug": "I.-Pigeot",
                        "structuredName": {
                            "firstName": "Iris",
                            "lastName": "Pigeot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pigeot"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1765731,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cb6acf6f8d0af5f70ae4b906f7abd64ff541ed52",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we discuss maximum likelihood estimation when some observations are missing in mixed graphical interaction models assuming a conditional Gaussian distribution as introduced by Lauritzen&Wermuth (1989). For the saturated case ML estimation with missing values via the EM algorithm has been proposed by Little&Schluchter (1985). We expand their results to the special restrictions in graphical models and indicate a more efficient way to compute the E--step. The main purpose of the paper is to show that for certain missing patterns the computational effort can considerably be reduced."
            },
            "slug": "Maximum-likelihood-estimation-in-graphical-models-Didelez-Pigeot",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation in graphical models with missing values"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102488892"
                        ],
                        "name": "Tar Chen",
                        "slug": "Tar-Chen",
                        "structuredName": {
                            "firstName": "Tar",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tar Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684961"
                        ],
                        "name": "S. Fienberg",
                        "slug": "S.-Fienberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Fienberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fienberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125052870,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "89302c1b750307880315dc8e069435173dea9f11",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In many practical situations, investigators are forced to study the structure underlying the crossclassification of several categorical variables via tables of observed counts in which the observations corresponding to certain sets of cells are indistinguishable. Methods are presented for the analysis of such contingency tables with incompletely cross-classified data via loglinear models. The method of maximum likelihood is used to estimate the expected cell counts which are then used to test the goodness-of-fit of the model. Extensions to incomplete (or truncated) contingency tables are indicated and several examples are given."
            },
            "slug": "The-Analysis-of-Contingency-Tables-with-Classified-Chen-Fienberg",
            "title": {
                "fragments": [],
                "text": "The Analysis of Contingency Tables with Incompletely Classified Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798654"
                        ],
                        "name": "M. Studen\u00fd",
                        "slug": "M.-Studen\u00fd",
                        "structuredName": {
                            "firstName": "Milan",
                            "lastName": "Studen\u00fd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Studen\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680097"
                        ],
                        "name": "R. Bouckaert",
                        "slug": "R.-Bouckaert",
                        "structuredName": {
                            "firstName": "Remco",
                            "lastName": "Bouckaert",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bouckaert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 145
                            }
                        ],
                        "text": ", Gaussian or having a positive density) exists displaying all and only the conditional properties displayed by a given graphical representation (Geiger and Pearl 1990, 1993; Studen\u00fd and Bouckaert 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8446858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c82b8d2142aebc1e65d032ea784adb91cc468ac",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "A chain graph (CG) is a graph admitting both directed and undirected edges with (partially) directed cycles forbidden. It generalizes both the concept of undirected graph (UG) and the concept of directed acyclic graph (DAG). A chain graph can be used to describe efficiently the conditional independence structure of a multidimensional discrete probability distribution in the form of a graphoid, that is, in the form of a list of statements X is independent of Y given Z obeying a set of five properties (axioms). An input list of independency statements for every CG is defined and it is shown that the classic moralization criterion for CGs embraces exactly the graphoid closure of the input list. A new direct separation criterion for reading independency statements from a CG is introduced and shown to be equivalent to the moralization criterion. Using this new criterion, it is proved that for every CG, there exists a strictly positive discrete probability distribution that embodies exactly the independency statements displayed by the graph. Thus, both criteria are shown to be complete and the use of CGs as tools for description of conditional independence structures is justified."
            },
            "slug": "On-chain-graph-models-for-description-of-structures-Studen\u00fd-Bouckaert",
            "title": {
                "fragments": [],
                "text": "On chain graph models for description of conditional independence structures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proved that for every CG, there exists a strictly positive discrete probability distribution that embodies exactly the independency statements displayed by the graph."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10726446"
                        ],
                        "name": "T. Richardson",
                        "slug": "T.-Richardson",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Richardson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Richardson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7512539,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b0c90801d5cfebccb623a0a53efd8d60a0d02117",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Although the concept of d-separation was originally defined for directed acyclic graphs (see Pearl 1988), there is a natural extension of the concept to directed cyclic graphs. When exactly the same set of d-separation relations hold in two directed graphs, no matter whether respectively cyclic or acyclic, we say that they are Markov equivalent. In other words, when two directed cyclic graphs are Markov equivalent, the set of distributions that satisfy a natural extension of the Global Directed Markov Condition (Lauritzen et al. 1990) is exactly the same for each graph. There is an obvious exponential (in the number of vertices) time algorithm for deciding Markov equivalence of two directed cyclic graphs; simply check all of the d-separation relations in each graph. In this paper I state a theorem that gives necessary and sufficient conditions for the Markov equivalence of two directed cyclic graphs, where each of the conditions can be checked in polynomial time. Hence, the theorem can be easily adapted into a polynomial time algorithm for deciding the Markov equivalence of two directed cyclic graphs. Although space prohibits inclusion of correctness proofs, they are fully described in Richardson (1994b)."
            },
            "slug": "A-Polynomial-Time-Algorithm-for-Deciding-Markov-of-Richardson",
            "title": {
                "fragments": [],
                "text": "A Polynomial-Time Algorithm for Deciding Markov Equivalence of Directed Cyclic Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A theorem is state that gives necessary and sufficient conditions for the Markov equivalence of two directed cyclic graphs, where each of the conditions can be checked in polynomial time."
            },
            "venue": {
                "fragments": [],
                "text": "UAI 1996"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8191738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73ba229d5fe920e33ad0509707602a97ef492ffd",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Constraint-Propagation-Approach-to-Probabilistic-Pearl",
            "title": {
                "fragments": [],
                "text": "A Constraint-Propagation Approach to Probabilistic Reasoning"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722047"
                        ],
                        "name": "C. Beeri",
                        "slug": "C.-Beeri",
                        "structuredName": {
                            "firstName": "Catriel",
                            "lastName": "Beeri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Beeri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144112511"
                        ],
                        "name": "Ronald Fagin",
                        "slug": "Ronald-Fagin",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Fagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Fagin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145249669"
                        ],
                        "name": "D. Maier",
                        "slug": "D.-Maier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Maier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748179"
                        ],
                        "name": "M. Yannakakis",
                        "slug": "M.-Yannakakis",
                        "structuredName": {
                            "firstName": "Mihalis",
                            "lastName": "Yannakakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yannakakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2418740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "666dfa8258914bf17970b20d2f7247c7c1468307",
            "isKey": false,
            "numCitedBy": 782,
            "numCiting": 101,
            "paperAbstract": {
                "fragments": [],
                "text": "A class of database schemes, called acychc, was recently introduced. It is shown that this class has a number of desirable properties. In particular, several desirable properties that have been studied by other researchers m very different terms are all shown to be eqmvalent to acydicity. In addition, several equivalent charactenzauons of the class m terms of graphs and hypergraphs are given, and a smaple algorithm for determining acychclty is presented. Also given are several eqmvalent characterizations of those sets M of multivalued dependencies such that M is the set of muRlvalued dependencies that are the consequences of a given join dependency. Several characterizations for a conflict-free (in the sense of Lien) set of muluvalued dependencies are provided."
            },
            "slug": "On-the-Desirability-of-Acyclic-Database-Schemes-Beeri-Fagin",
            "title": {
                "fragments": [],
                "text": "On the Desirability of Acyclic Database Schemes"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "It is shown that this class of database schemes, called acychc, has a number of desirable properties that have been studied by other researchers and are shown to be eqmvalent to acydicity."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145673139"
                        ],
                        "name": "D. Edwards",
                        "slug": "D.-Edwards",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Edwards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Edwards"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125834889,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6b6324c21aa6662e26c2a6315ab70dd9e988cfd0",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Lauritzen and Wermuth have proposed a class of models for mixed qualitative and continuous data, defined by two properties: that the continuous variables are normally distributed given the qualitative variables and that a set of conditional independence relations hold between specified pairs of variables. The present paper examines an extension to this class called hierarchical interaction models. A compact form for model representation is described and an estimation algorithm is given. Some properties of the models. A compact form for model representation is described and an estimation algorithm is given. Some properties of the models concerning marginalization and conditioning are examined. The class includes and generalizes hierarchical log-linear models, standard fixed effect ANOVA, multivariate ANOVA and multivariate regression models"
            },
            "slug": "Hierarchical-interaction-models-Edwards",
            "title": {
                "fragments": [],
                "text": "Hierarchical interaction models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48700578"
                        ],
                        "name": "L. J. Savage",
                        "slug": "L.-J.-Savage",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Savage",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. J. Savage"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120427654,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "0763865ef0555d4b24c3802f8110313a3abedb6c",
            "isKey": false,
            "numCitedBy": 1106,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Proper scoring rules, i.e., devices of a certain class for eliciting a person's probabilities and other expectations, are studied, mainly theoretically but with some speculations about application. The relation of proper scoring rules to other economic devices and to the foundations of the personalistic theory of probability is brought out. The implications of various restrictions, especially symmetry restrictions, on scoring rules is explored, usually with a minimum of regularity hypothesis."
            },
            "slug": "Elicitation-of-Personal-Probabilities-and-Savage",
            "title": {
                "fragments": [],
                "text": "Elicitation of Personal Probabilities and Expectations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1849084"
                        ],
                        "name": "H. Warner",
                        "slug": "H.-Warner",
                        "structuredName": {
                            "firstName": "Homer",
                            "lastName": "Warner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Warner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11769320"
                        ],
                        "name": "A. Toronto",
                        "slug": "A.-Toronto",
                        "structuredName": {
                            "firstName": "Alan F.",
                            "lastName": "Toronto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Toronto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83126137"
                        ],
                        "name": "L. Veasey",
                        "slug": "L.-Veasey",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Veasey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Veasey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068764054"
                        ],
                        "name": "R. Stephenson",
                        "slug": "R.-Stephenson",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "Stephenson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stephenson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34658272,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "3e67f926cafcf029b3583ff44acf3f6dccdd0fae",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "An equation of conditional probability is derived to express the logical process used by a clinician in making a diagnosis from clinical data. Solutions of this equation take the form of a differential diagnosis. The probability that each disease represents the correct diagnosis in any particular patient may be calculated. Sufficient statistical data regarding the incidence of clinical signs, symptoms, and electrocardiographic findings in patients with congenital heart disease have been assembled to allow application of this approach to differential diagnosis in this field. This approach provides a means by which electronic computing equipment may be used to advantage in clinical medicine."
            },
            "slug": "A-mathematical-approach-to-medical-diagnosis.-to-Warner-Toronto",
            "title": {
                "fragments": [],
                "text": "A mathematical approach to medical diagnosis. Application to congenital heart disease."
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "An equation of conditional probability is derived to express the logical process used by a clinician in making a diagnosis from clinical data, and provides a means by which electronic computing equipment may be used to advantage in clinical medicine."
            },
            "venue": {
                "fragments": [],
                "text": "JAMA"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70055706"
                        ],
                        "name": "Hollis J. Call",
                        "slug": "Hollis-J.-Call",
                        "structuredName": {
                            "firstName": "Hollis",
                            "lastName": "Call",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hollis J. Call"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50472182"
                        ],
                        "name": "W. A. Miller",
                        "slug": "W.-A.-Miller",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. A. Miller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60969414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f9c52068be313734fa7df019d2dc36693a7bd34",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-comparison-of-approaches-and-implementations-for-Call-Miller",
            "title": {
                "fragments": [],
                "text": "A comparison of approaches and implementations for automating decision analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585616"
                        ],
                        "name": "L. Burnell",
                        "slug": "L.-Burnell",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Burnell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Burnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145479841"
                        ],
                        "name": "E. Horvitz",
                        "slug": "E.-Horvitz",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Horvitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Horvitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 106
                            }
                        ],
                        "text": "Which of the various approaches is the most efficient seems to be proble dependent; see Shenoy (1994) and Call and Miller (1990) for discussions of these issues. More recently Charnes and Shenoy (1997) have proposed an efficient forward\u2013sampling method for solving decision problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 106
                            }
                        ],
                        "text": "Which of the various approaches is the most efficient seems to be proble dependent; see Shenoy (1994) and Call and Miller (1990) for discussions of these issues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 125
                            }
                        ],
                        "text": "The March 1995 issue of The Communications of the ACM contains useful articles on structuring systems for software debugging (Burnell and Horvitz 1995) and information retrieval (Fung and Del Favero 1995); Microsoft Research\u2019s work in this area is briefly described on their Web page (see Appendix C)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 437,
                                "start": 106
                            }
                        ],
                        "text": "Which of the various approaches is the most efficient seems to be proble dependent; see Shenoy (1994) and Call and Miller (1990) for discussions of these issues. More recently Charnes and Shenoy (1997) have proposed an efficient forward\u2013sampling method for solving decision problems. Current research interest is focused on finding more efficient solutions for asymmetric decision problems. The valuation network method of Shenoy (1996) adapted to asymmetric problems is one such proposal; others include contingent influence diagrams (Fung and Shachter 1990) and sequential decision diagrams (Covaliu and Oliver 1995)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9644536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0351b711dc0e1e21bae03a37b16b8b53b2bb1819",
            "isKey": true,
            "numCitedBy": 63,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Software errors abound in the world of computing. Sophisticated computer programs rank high on the list of the most complex systems ever created by humankind. The complexity of a program or a set of interacting programs makes it extremely difficult to perform offline verification of run-time behavior. Thus, the creation and maintenance of program code is often linked to a process of incremental refinement and ongoing detection and correction of errors. To be sure, the detection and repair of program errors is an inescapable part of the process of software development. However, run-time software errors may be discovered in fielded applications days, months, or even years after the software was last modified\u2014especially in applications composed of a plethora of separate programs created and updated by different people at different times. In such complex applications, software errors are revealed through the run-time interaction of hundreds of distinct processes competing for limited memory and CPU resources. Software developers and support engineers responsible for correcting software problems face difficult challenges in tracking down the source of run-time errors in complex applications. The information made available to engineers about the nature of a failure often leaves open a wide range of possibilities that must be sifted through carefully in searching for an underlying error."
            },
            "slug": "Structure-and-chance:-melding-logic-and-probability-Burnell-Horvitz",
            "title": {
                "fragments": [],
                "text": "Structure and chance: melding logic and probability for software debugging"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Information made available to engineers about the nature of a failure often leaves open a wide range of possibilities that must be sifted through carefully in searching for an underlying error."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759366"
                        ],
                        "name": "S. Arnborg",
                        "slug": "S.-Arnborg",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Arnborg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Arnborg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806664"
                        ],
                        "name": "D. Corneil",
                        "slug": "D.-Corneil",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Corneil",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Corneil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753890"
                        ],
                        "name": "A. Proskurowski",
                        "slug": "A.-Proskurowski",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Proskurowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Proskurowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 141
                            }
                        ],
                        "text": "The first explicit identification seems to be in relational databases, where it has been known as a join tree (Maier 1983); the terms k\u2013tree (Arnborg et al. 1987),Markov tree and hypertree (Shenoy and Shafer 1990), or simply clique tree have also been used."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123254044,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "656f4417b8651f472c6faa370823c307056ffa48",
            "isKey": false,
            "numCitedBy": 1267,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A k-tree is a graph that can be reduced to the k-complete graph by a sequence of removals of a degree k vertex with completely connected neighbors. We address the problem of determining whether a graph is a partial graph of a k-tree. This problem is motivated by the existence of polynomial time algorithms for many combinatorial problems on graphs when the graph is constrained to be a partial k-tree for fixed k. These algorithms have practical applications in areas such as reliability, concurrent broadcasting and evaluation of queries in a relational database system. We determine the complexity status of two problems related to finding the smallest number k such that a given graph is a partial k-tree. First, the corresponding decision problem is NP-complete. Second, for a fixed (predetermined) value of k, we present an algorithm with polynomially bounded (but exponential in k) worst case time complexity. Previously, this problem had only been solved for $k = 1,2,3$."
            },
            "slug": "Complexity-of-finding-embeddings-in-a-k-tree-Arnborg-Corneil",
            "title": {
                "fragments": [],
                "text": "Complexity of finding embeddings in a k -tree"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work determines the complexity status of two problems related to finding the smallest number k such that a given graph is a partial k-tree and presents an algorithm with polynomially bounded (but exponential in k) worst case time complexity."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39416713"
                        ],
                        "name": "M. Degroot",
                        "slug": "M.-Degroot",
                        "structuredName": {
                            "firstName": "Morris",
                            "lastName": "Degroot",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Degroot"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 103
                            }
                        ],
                        "text": "In general, an exponential family of distributions for complete data admits tractable conjugate priors (DeGroot 1970), such that the prior-to-posterior calculation can be performed easily."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119884967,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "81c8a5823de21d98ea395081cbfe647bfb456cd6",
            "isKey": false,
            "numCitedBy": 4235,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Foreword.Preface.PART ONE. SURVEY OF PROBABILITY THEORY.Chapter 1. Introduction.Chapter 2. Experiments, Sample Spaces, and Probability.2.1 Experiments and Sample Spaces.2.2 Set Theory.2.3 Events and Probability.2.4 Conditional Probability.2.5 Binomial Coefficients.Exercises.Chapter 3. Random Variables, Random Vectors, and Distributions Functions.3.1 Random Variables and Their Distributions.3.2 Multivariate Distributions.3.3 Sums and Integrals.3.4 Marginal Distributions and Independence.3.5 Vectors and Matrices.3.6 Expectations, Moments, and Characteristic Functions.3.7 Transformations of Random Variables.3.8 Conditional Distributions.Exercises.Chapter 4. Some Special Univariate Distributions.4.1 Introduction.4.2 The Bernoulli Distributions.4.3 The Binomial Distribution.4.4 The Poisson Distribution.4.5 The Negative Binomial Distribution.4.6 The Hypergeometric Distribution.4.7 The Normal Distribution.4.8 The Gamma Distribution.4.9 The Beta Distribution.4.10 The Uniform Distribution.4.11 The Pareto Distribution.4.12 The t Distribution.4.13 The F Distribution.Exercises.Chapter 5. Some Special Multivariate Distributions.5.1 Introduction.5.2 The Multinomial Distribution.5.3 The Dirichlet Distribution.5.4 The Multivariate Normal Distribution.5.5 The Wishart Distribution.5.6 The Multivariate t Distribution.5.7 The Bilateral Bivariate Pareto Distribution.Exercises.PART TWO. SUBJECTIVE PROBABILITY AND UTILITY.Chapter 6. Subjective Probability.6.1 Introduction.6.2 Relative Likelihood.6.3 The Auxiliary Experiment.6.4 Construction of the Probability Distribution.6.5 Verification of the Properties of a Probability Distribution.6.6 Conditional Likelihoods.Exercises.Chapter 7. Utility.7.1 Preferences Among Rewards.7.2 Preferences Among Probability Distributions.7.3 The Definitions of a Utility Function.7.4 Some Properties of Utility Functions.7.5 The Utility of Monetary Rewards.7.6 Convex and Concave Utility Functions.7.7 The Anxiomatic Development of Utility.7.8 Construction of the Utility Function.7.9 Verification of the Properties of a Utility Function.7.10 Extension of the Properties of a Utility Function to the Class ?E.Exercises.PART THREE. STATISTICAL DECISION PROBLEMS.Chapter 8. Decision Problems.8.1 Elements of a Decision Problem.8.2 Bayes Risk and Bayes Decisions.8.3 Nonnegative Loss Functions.8.4 Concavity of the Bayes Risk.8.5 Randomization and Mixed Decisions.8.6 Convex Sets.8.7 Decision Problems in Which ~2 and D Are Finite.8.8 Decision Problems with Observations.8.9 Construction of Bayes Decision Functions.8.10 The Cost of Observation.8.11 Statistical Decision Problems in Which Both ? and D contains Two Points.8.12 Computation of the Posterior Distribution When the Observations Are Made in More Than One Stage.Exercises.Chapter 9. Conjugate Prior Distributions.9.1 Sufficient Statistics.9.2 Conjugate Families of Distributions.9.3 Construction of the Conjugate Family.9.4 Conjugate Families for Samples from Various Standard Distributions.9.5 Conjugate Families for Samples from a Normal Distribution.9.6 Sampling from a Normal Distribution with Unknown Mean and Unknown Precision.9.7 Sampling from a Uniform Distribution.9.8 A Conjugate Family for Multinomial Observations.9.9 Conjugate Families for Samples from a Multivariate Normal Distribution.9.10 Multivariate Normal Distributions with Unknown Mean Vector and Unknown Precision matrix.9.11 The Marginal Distribution of the Mean Vector.9.12 The Distribution of a Correlation.9.13 Precision Matrices Having an Unknown Factor.Exercises.Chapter 10. Limiting Posterior Distributions.10.1 Improper Prior Distributions.10.2 Improper Prior Distributions for Samples from a Normal Distribution.10.3 Improper Prior Distributions for Samples from a Multivariate Normal Distribution.10.4 Precise Measurement.10.5 Convergence of Posterior Distributions.10.6 Supercontinuity.10.7 Solutions of the Likelihood Equation.10.8 Convergence of Supercontinuous Functions.10.9 Limiting Properties of the Likelihood Function.10.10 Normal Approximation to the Posterior Distribution.10.11 Approximation for Vector Parameters.10.12 Posterior Ratios.Exercises.Chapter 11. Estimation, Testing Hypotheses, and linear Statistical Models.11.1 Estimation.11.2 Quadratic Loss.11.3 Loss Proportional to the Absolute Value of the Error.11.4 Estimation of a Vector.11.5 Problems of Testing Hypotheses.11.6 Testing a Simple Hypothesis About the Mean of a Normal Distribution.11.7 Testing Hypotheses about the Mean of a Normal Distribution.11.8 Deciding Whether a Parameter Is Smaller or larger Than a Specific Value.11.9 Deciding Whether the Mean of a Normal Distribution Is Smaller or larger Than a Specific Value.11.10 Linear Models.11.11 Testing Hypotheses in Linear Models.11.12 Investigating the Hypothesis That Certain Regression Coefficients Vanish.11.13 One-Way Analysis of Variance.Exercises.PART FOUR. SEQUENTIAL DECISIONS.Chapter 12. Sequential Sampling.12.1 Gains from Sequential Sampling.12.2 Sequential Decision Procedures.12.3 The Risk of a Sequential Decision Procedure.12.4 Backward Induction.12.5 Optimal Bounded Sequential Decision procedures.12.6 Illustrative Examples.12.7 Unbounded Sequential Decision Procedures.12.8 Regular Sequential Decision Procedures.12.9 Existence of an Optimal Procedure.12.10 Approximating an Optimal Procedure by Bounded Procedures.12.11 Regions for Continuing or Terminating Sampling.12.12 The Functional Equation.12.13 Approximations and Bounds for the Bayes Risk.12.14 The Sequential Probability-ratio Test.12.15 Characteristics of Sequential Probability-ratio Tests.12.16 Approximating the Expected Number of Observations.Exercises.Chapter 13. Optimal Stopping.13.1 Introduction.13.2 The Statistician's Reward.13.3 Choice of the Utility Function.13.4 Sampling Without Recall.13.5 Further Problems of Sampling with Recall and Sampling without Recall.13.6 Sampling without Recall from a Normal Distribution with Unknown Mean.13.7 Sampling with Recall from a Normal Distribution with Unknown Mean.13.8 Existence of Optimal Stopping Rules.13.9 Existence of Optimal Stopping Rules for Problems of Sampling with Recall and Sampling without Recall.13.10 Martingales.13.11 Stopping Rules for Martingales.13.12 Uniformly Integrable Sequences of Random Variables.13.13 Martingales Formed from Sums and Products of Random Variables.13.14 Regular Supermartingales.13.15 Supermartingales and General Problems of Optimal Stopping.13.16 Markov Processes.13.17 Stationary Stopping Rules for Markov Processes.13.18 Entrance-fee Problems.13.19 The Functional Equation for a Markov Process.Exercises.Chapter 14. Sequential Choice of Experiments.14.1 Introduction.14.2 Markovian Decision Processes with a Finite Number of Stages.14.3 Markovian Decision Processes with an Infinite Number of Stages.14.4 Some Betting Problems.14.5 Two-armed-bandit Problems.14.6 Two-armed-bandit Problems When the Value of One Parameter Is Known.14.7 Two-armed-bandit Problems When the Parameters Are Dependent.14.8 Inventory Problems.14.9 Inventory Problems with an Infinite Number of Stages.14.10 Control Problems.14.11 Optimal Control When the Process Cannot Be Observed without Error.14.12 Multidimensional Control Problems.14.13 Control Problems with Actuation Errors.14.14 Search Problems.14.15 Search Problems with Equal Costs.14.16 Uncertainty Functions and Statistical Decision Problems.14.17 Sufficient Experiments.14.18 Examples of Sufficient Experiments.Exercises.References.Supplementary Bibliography.Name Index.Subject Index."
            },
            "slug": "Optimal-Statistical-Decisions-Degroot",
            "title": {
                "fragments": [],
                "text": "Optimal Statistical Decisions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1888694"
                        ],
                        "name": "K. Gabriel",
                        "slug": "K.-Gabriel",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Gabriel",
                            "middleNames": [
                                "Ruben"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Gabriel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15828066,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "01e24da9f2b579983f372821e150e6e86067110e",
            "isKey": false,
            "numCitedBy": 352,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction and summary. When a hypothesis is tested by a significanice test and is not rejected, it is generally agreed that all hypotheses implied by that hypothesis (its \"components\") must also be considered as non-rejected. However, when the hypothesis is rejected the question remains as to which components may also be rejected. Various writers have given attention to this question and have proposed a variety of multiple comparisons methods based either on tests of each one of the components or on simultaneous confidence bounds on parametric functions related to the various hypotheses. An approach to such methods, apparently originally due to Tukey [27], is to test each component hypothesis by comparing its statistic with the a level critical value of the statistic for the overall hypothesis. This is called a Simultaneous Test Procedure (STP for short) as all hypotheses may be tested simultaneously and without reference to one another. An STP involves no stepwise testing of the kind employed by some other methods of multiple comparisons for means, in which subsets are tested for equality only if they are contained in sets which have already been found significant. (See 13], [4], [10], [18]). A general formalization of STP's is attempted in this paper. Section 2 introduces the requisite concepts of families of hypotheses and the implication relations between them, as well as the monotonicity relations between the related statistics. Section 3 defines STP's and shows conditions for coherence and consonance of their decisions, these properties being that hypothesis implication relations are preserved in the decisions of the STP. Section 4 discusses comparison of various STP's for the same hypotheses and shows the advantages of the unionintersection type of statistics and of reducing the family of hypotheses tested as much as possible. Section 5 translates all these results to simultaneous confidence statements after introducing the definitions necessary to allow such translation. The analogy between simultaneous test and confidence methods is of special importance as it brings a wide spectrum of methods within this framework, most of which was originally formulated in confidence region terms. This covers the original work of Tukey [27] and Scheff6 [25] and continues with that of Roy and his associates [21] and most recently Krishnaiah [12], [13]. A general discussion of this confidence approach has been given by Aitchison [1) since the first draft of the present paper. In view of the close analogies pointed out in Section 5, it is"
            },
            "slug": "SIMULTANEOUS-TEST-PROCEDURES-SOME-THEORY-OF-Gabriel",
            "title": {
                "fragments": [],
                "text": "SIMULTANEOUS TEST PROCEDURES-SOME THEORY OF MULTIPLE COMPARISONS'"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60750190,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7ad09bf49cb267a06dba6547c28cde1592b720e",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Most everyday reasoning and decision making is based on uncertain premises. This volume collects 42 key papers from the literature, addressing the methods that have been used in artificial intelligence to build systems with the ability to manage uncertainty. The editors have added volume and sectio"
            },
            "slug": "Readings-in-Uncertain-Reasoning-Shafer-Pearl",
            "title": {
                "fragments": [],
                "text": "Readings in Uncertain Reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This volume collects 42 key papers from the literature addressing the methods that have been used in artificial intelligence to build systems with the ability to manage uncertainty."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 6
                            }
                        ],
                        "text": "13 of Lauritzen (1996)) shows how to modify the ordering when a redundant subset is to be deleted."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 106
                            }
                        ],
                        "text": "To handle this more general case, the properties of conditional Gaussian (CG) distributions introduced by Lauritzen and Wermuth (1984, 1989) are exploited. We shall briefly review some standard notation, but refer the reader to Lauritzen (1996) for further details and derivations of formulae."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 50
                            }
                        ],
                        "text": "32) reduces to equation (11) of Spiegelhalter and Lauritzen (1990). For a node v with k states, and initially m terms in the mixture for each parent configuration, after processing an incomplete case this could grow to up to (k + 1) \u00d7 m terms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 50
                            }
                        ],
                        "text": "A generalization to mixed models was developed by Lauritzen (1992), in which both discrete and continuous variables can be present and for which the conditional distribution of the continuous (or quantitative) variables given the discrete (or qualitative) variables is restricted to be multivariate Gaussian."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "Note that there is a slight difference between the notation used here and that of Lauritzen (1996), in that we allow p(i) to be equal to 0 for some entries i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 51
                            }
                        ],
                        "text": "We refer the interested reader to Leimer (1989) or Lauritzen (1996) for a detailed graph-theoretic study of the problems, as well as all proofs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 85
                            }
                        ],
                        "text": "An example was given by Moussouris (1974) for the graph being a four-cycle (see also Lauritzen (1996))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 18
                            }
                        ],
                        "text": "Spiegelhalter and Lauritzen (1990) proposed approximating the mixture generated on processing each successive incomplete case by a single conjugate density."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 48
                            }
                        ],
                        "text": "The following fictitious example, Asia , due to Lauritzen and Spiegelhalter (1988), illustrates the nature of the more complex graphical structures we shall be analysing in this book."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 43
                            }
                        ],
                        "text": "A fictitious but simple example taken from Lauritzen (1992) is used to illustrate the general theory for conditional Gaussian models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122619983,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "42c90f9c02e23527f564e74854a4f64b876bc181",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary We describe and discuss a paper of T.N. Thiele from 1880 where he formulates and analyses a model for a time series consisting of a sum of a regression component, a Brownian motion and a white noise. He derives a recursive procedure for estimating the regression component and predicting the Brownian motion. The procedure is now known as Kalman filtering. He estimates the unknown variances of the Brownian motion and the white noise by an iterative procedure that essentially is the EM-algorithm. We finally give a short account of an application of Thiele's model and method to the description of hormone production during normal pregnancy."
            },
            "slug": "Time-Series-Analysis-in-1880:-A-Discussion-of-Made-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Time Series Analysis in 1880: A Discussion of Contributions Made by T.N. Thiele"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122985977,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "2e67c0312b81b698834315ea33f8a23be6eed6eb",
            "isKey": false,
            "numCitedBy": 765,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-EM-algorithm-for-graphical-association-models-Lauritzen",
            "title": {
                "fragments": [],
                "text": "The EM algorithm for graphical association models with missing data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145522250"
                        ],
                        "name": "Wolfgang Spohn",
                        "slug": "Wolfgang-Spohn",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Spohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Spohn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 96
                            }
                        ],
                        "text": ", embedded multi-valued dependencies (Sagiv and Walecka 1982) and natural conditional functions (Spohn 1988; Studen\u00fd 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49938833,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "10ee418d0058b8e771f28e24fc28cbf968cbabbb",
            "isKey": false,
            "numCitedBy": 955,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Many of the philosophically most interesting notions are overtly or covertly epistemological. Overtly epistemological notions are, of course, the concept of belief itself, the concept of subjective probability, and, presumably the most important, the concept of a reason in the sense of a theoretical reason for believing something. Covertly epistemological notions are much more difficult to understand; maybe, they are not epistemological at all. However, a very promising strategy for understanding them is to try to conceive of them as covertly epistemological. One such notion is the concept of objective probability;1 the concept of explanation is another. A third, very important one is the notion of causation, which has been epistemologically problematic ever since Hume. Finally, there is the notion of truth. Many philosophers believe that there is much to be said for a coherence theory of truth or internal realism; they hold some version of the claim that something for which it is impossible to get a true reason cannot be true, and that truth is therefore covertly epistemological."
            },
            "slug": "Ordinal-Conditional-Functions:-A-Dynamic-Theory-of-Spohn",
            "title": {
                "fragments": [],
                "text": "Ordinal Conditional Functions: A Dynamic Theory of Epistemic States"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2590616,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f8e40ec9ded7c877af9a04cac38b35fc2b9f81c3",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the problem of reducing a mixture of conjugate priors to a smaller mixture, from the perspective of the application of a distance measure between priors. The analysis focuses on mixtures of Dirichlet priors, but it has wider applicability. In respect to the proposed scheme, it emerges that for mixtures of \u03b2-distributions a simple moment-matching reduction procedure is optimal and very good for the more general case of Dirichlet mixtures."
            },
            "slug": "Mixture-reduction-via-predictive-scores-Cowell",
            "title": {
                "fragments": [],
                "text": "Mixture reduction via predictive scores"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper explores the problem of reducing a mixture of conjugate priors to a smaller mixture, from the perspective of the application of a distance measure between priors, and emerges that for mixtures of \u03b2-distributions a simple moment-matching reduction procedure is optimal and very good for the more general case of Dirichlet mixtures."
            },
            "venue": {
                "fragments": [],
                "text": "Stat. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742419"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 215
                            }
                        ],
                        "text": "Techniques include the \u2018probabilistic teacher\u2019, in which the missing variables are randomly fixed according to their current posterior distribution, and \u2018quasi-Bayes\u2019 (Smith and Makov 1978) or \u2018fractional updating\u2019 (Titterington 1976)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59699866,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "15cf26b46bb92cafa4f78c13de30c1bc7328ebe5",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A Bayesian approach is made to the problem of using individuals of unconfirmed categories to provide information supplementary to a basic data bank of categorized observations. The exact analysis is briefly presented, followed by suggestions for more practicable approximate procedures, which are applied to examples involving medical and simulated data. The general conclusion is that the discriminatory performance of the data bank can be usefully improved by making use of uncategorized observations."
            },
            "slug": "Updating-a-Diagnostic-System-using-Unconfirmed-Titterington",
            "title": {
                "fragments": [],
                "text": "Updating a Diagnostic System using Unconfirmed Cases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The general conclusion is that the discriminatory performance of the data bank can be usefully improved by making use of uncategorized observations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 120
                            }
                        ],
                        "text": "Further generalization leads into the extensive areas of probability models for pattern recognition and neural networks (Ripley 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9584248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "877a887e7af7daebcb685e4d7b5e80f764035581",
            "isKey": false,
            "numCitedBy": 4043,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Title Type pattern recognition with neural networks in c++ PDF pattern recognition and neural networks PDF neural networks for pattern recognition advanced texts in econometrics PDF neural networks for applied sciences and engineering from fundamentals to complex pattern recognition PDF an introduction to biological and artificial neural networks for pattern recognition spie tutorial text vol tt04 tutorial texts in optical engineering PDF"
            },
            "slug": "Pattern-Recognition-and-Neural-Networks-LeCun-Bengio",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31878411"
                        ],
                        "name": "M. Frydenberg",
                        "slug": "M.-Frydenberg",
                        "structuredName": {
                            "firstName": "Morten",
                            "lastName": "Frydenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Frydenberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 74
                            }
                        ],
                        "text": "Extending a result of Verma and Pearl (1991) for directed acyclic graphs, Frydenberg (1990) showed that two chain graphs are Markov equivalent if and only if they have the same skeleton (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 90
                            }
                        ],
                        "text": "It appears that this property depends on the particular partitioning, but it can be shown (Frydenberg 1990) that \u2014 if P satisfies (P5) \u2014 it is equivalent to any of the above."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116029196,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e3b9ffde49c9b4a57b09a651187a2e194cb35693",
            "isKey": false,
            "numCitedBy": 417,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A new class of graphs, chain graphs, suitable for modelling conditional independencies are introduced and their Markov properties investigated. This class of graphs, which includes the undirected and directed acyclic graphs, enables modelling recursive models with multivariate response variables. Results concerning the equivalence of different definitions of their Markov properties including a factorization of the density are shown. We give a necessary and sufficient condition for two chain graphs to have the same Markov properties"
            },
            "slug": "The-chain-graph-Markov-property-Frydenberg",
            "title": {
                "fragments": [],
                "text": "The chain graph Markov property"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34577797"
                        ],
                        "name": "D. Rose",
                        "slug": "D.-Rose",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rose",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811309"
                        ],
                        "name": "G. S. Lueker",
                        "slug": "G.-S.-Lueker",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Lueker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. S. Lueker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 95
                            }
                        ],
                        "text": "It includes other algorithms for checking decomposability of a graph and finding their cliques (Rose et al. 1976; Gavril 1972), for constructing optimal junction trees for given decomposable graphs (Jensen and Jensen 1994), and for constructing optimal decompositions of a non-chordal graph into its indecomposable components (Tarjan 1985; Leimer 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 154
                            }
                        ],
                        "text": "The rejection step can be avoided by generating weighted samples from the DAG, but then one does not sample directly from the posterior distribution (see Shachter and Peot (1990) for a comparison of a number of algorithms of this type)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207050855,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "17d87b9ac0bedad64489022ef415df05829843ad",
            "isKey": false,
            "numCitedBy": 1196,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a graph-theoretic elimination process which is related to performing Gaussian elimination on sparse symmetric positive definite systems of linear equations. We give a new linear-time algorithm to calculate the fill-in produced by any elimination ordering, and we give two new related algorithms for finding orderings with special properties. One algorithm, based on breadth-first search, finds a perfect elimination ordering, if any exists, in $O(n + e)$ time, if the problem graph has n vertices and e edges. An extension of this algorithm finds a minimal (but not necessarily minimum) ordering in $O(ne)$ time. We conjecture that the problem of finding a minimum ordering is NP-complete"
            },
            "slug": "Algorithmic-Aspects-of-Vertex-Elimination-on-Graphs-Rose-Tarjan",
            "title": {
                "fragments": [],
                "text": "Algorithmic Aspects of Vertex Elimination on Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A graph-theoretic elimination process which is related to performing Gaussian elimination on sparse symmetric positive definite systems of linear equations is considered, and it is conjecture that the problem of finding a minimum ordering is NP-complete."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145673139"
                        ],
                        "name": "D. Edwards",
                        "slug": "D.-Edwards",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Edwards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Edwards"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 145
                            }
                        ],
                        "text": "For example, standard statistical hypothesis testing procedures based on likelihood ratio tests can be used for selecting among graphical models (Whittaker 1990; Spirtes et al. 1993; Edwards 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 18
                            }
                        ],
                        "text": "The PRESS system (Gammerman et al. 1995) incorporates options for both local propagation and Gibbs sampling for mixed discrete-Gaussian models. Jensen et al. (1995) describe blocking Gibbs sampling, a variant of Gibbs sampling for expert system purposes, when the cliques of a junction tree are too large for practical computation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118614006,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f982cec960c064f4fe78d0287ae321408876a50f",
            "isKey": false,
            "numCitedBy": 543,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Preliminaries.- 1.1 Independence and Conditional Independence.- 1.2 Undirected Graphs.- 1.3 Data, Models, and Graphs.- 1.4 Simpson's Paradox.- 1.5 Overview of the Book.- 2 Discrete Models.- 2.1 Three-Way Tables.- 2.1.1 Example: Lizard Perching Behaviour.- 2.2 Multi-Way Tables.- 2.2.1 Likelihood Equations.- 2.2.2 Deviance.- 2.2.3 Graphs and Formulae.- 2.2.4 Example: Risk Factors for Coronary Heart Disease.- 2.2.5 Example: Chromosome Mapping.- 2.2.6 Example: University Admissions.- 3 Continuous Models.- 3.1 Graphical Gaussian Models.- 3.1.1 Likelihood.- 3.1.2 Maximum Likelihood Estimation.- 3.1.3 Deviance.- 4 3.1.4 Example: Digoxin Clearance.- 3.1.5 Example: Anxiety and Anger.- 3.1.6 Example: Mathematics Marks.- 3.2 Regression Models.- 3.2.1 Example: Determinants of Bone Mineral Content.- 4 Mixed Models.- 4.1 Hierarchical Interaction Models.- 4.1.1 Models with One Discrete and One Continuous Variable.- 4.1.2 A Model with Two Discrete and Two Continuous Variables.- 4.1.3 Model Formulae.- 4.1.4 Formulae and Graphs.- 4.1.5 Maximum Likelihood Estimation.- 4.1.6 Deviance.- 4.1.7 A Simple Example.- 4.1.8 Example: A Drug Trial Using Mice.- 4.1.9 Example: Rats' Weights.- 4.1.10 Example: Estrogen and Lipid Metabolism.- 4.2 Breaking Models into Smaller Ones.- 4.3 Mean Linearity.- 4.4 Decomposable Models.- 4.5 CG-Regression Models.- 4.5.1 Example: Health Status Indicators.- 4.5.2 Example: Side Effects of an Antiepileptic Drug.- 4.6 Incomplete Data.- 4.6.1 Assumptions for Missing Data.- 4.6.2 Some Latent Variable Models.- 4.6.3 Example: The Components of a Normal Mixture.- 4.6.4 Example: Mathematics Marks, Revisited.- 4.7 Discriminant Analysis.- 4.7.1 Example: Breast Cancer.- 5 Hypothesis Testing.- 5.1 An Overview.- 5.2 X2-Tests.- 5.3 F-Tests.- 5.4 Exact Conditional Tests.- 5.5 Deviance-Based Tests.- 5.6 Permutation F-Test.- 5.7 Pearson x2-Test.- 5.8 Fisher's Exact Test.- 5.9 Rank Tests.- 5.10 Wilcoxon Test.- 5.11 Kruskal-Wallis Test.- 5.12 Jonckheere-Terpstra Test.- 5.13 Tests for Variance Homogeneity.- 5.14 Tests for Equality of Means Given Homogeneity.- 5.15 Hotelling's T2.- 6 Model Selection and Criticism.- 6.1 Stepwise Selection.- 6.1.1 Forward Selection.- 6.1.2 Restricting Selection to Decomposable Models.- 6.1.3 Using F-Tests.- 6.1.4 Coherence.- 6.1.5 Other Variants of Stepwise Selection.- 6.2 The EH-Procedure.- 6.2.1 Example: Estrogen and Lipid Metabolism, Continued.- 6.3 Selection Using Information Criteria.- 6.4 Comparison of the Methods.- 6.5 Box-Cox Transformations.- 6.6 Residual Analysis.- 6.7 Dichotomization.- 7 Directed Graphs and Their Models.- 7.1 Directed Acyclic Graphs.- 7.1.1 Markov Properties of DAGs.- 7.1.2 Modelling with DAGs.- 7.1.3 Example: Side Effects of Neuroleptics.- 7.2 Chain Graphs.- 7.2.1 Markov Properties of Chain Graphs.- 7.2.2 Modelling with Chain Graphs.- 7.2.3 Example: Membership of the \"Leading Crowd\".- 7.3 Local Independence Graphs.- 7.4 Covariance Graphs.- 7.5 Chain Graphs with Alternative Markov Properties.- 7.6 Reciprocal Graphs.- 8 Causal Inference.- 8.1 Philosophical Aspects.- 8.2 Rubin's Causal Model.- 8.2.1 Estimating Causal Effects.- 8.2.2 Ignorability.- 8.2.3 Propensity Score.- 8.2.4 Causal Hypothesis Testing.- 8.3 Pearl's Causal Graphs.- 8.3.1 A Simple Causal model.- 8.3.2 Causal Graphs.- 8.3.3 The Back-Door Criterion.- 8.3.4 The Front-Door Criterion.- 8.4 Discussion.- 8.4.1 Comparison of the Two Approaches.- 8.4.2 Operational Implications.- A The MINI Command Language.- A.1 Introduction.- A.2 Declaring Variables.- A.3 Undirected Models.- A.3.1 Deleting Edges.- A.3.2 Adding Edges.- A.3.3 Other Model-Changing Commands.- A.3.4 Model Properties.- A.4 Block-Recursive Models.- A.4.1 Defining the Block Structure.- A.4.2 Block Mode.- A.4.3 Defining Block-Recursive Models.- A.4.4 Working with Component Models.- A.5 Reading and Manipulating Data.- A.5.1 Reading Casewise Data.- A.5.2 Reading Counts, Means, and Covariances.- A.5.3 Transforming Data.- A.5.4 Restricting Observations.- A.5.5 Generating Raw Data.- A.5.6 Deleting Variables.- A.6 Estimation.- A.6.1 Undirected Models (Complete Data).- A.6.2 Undirected Models (Missing Data).- A.6.3 CG-Regression Models.- A.7 Hypothesis Testing.- A.7.1 x2-Tests.- A.7.2 Test of Homogeneity.- A.7.3 F-Tests.- A.7.4 Edge Deletion Tests.- A.7.5 Edge Deletion F-Tests.- A.7.6 Exact Tests.- A.7.7 Symmetry Tests.- A.7.8 Randomisation Tests.- A.8 Model Selection.- A.8.1 Stepwise Selection.- A.8.2 The EH-Procedure.- A.8.3 Selection Using Information Criteria.- A.9 The Box-Cox Transformation.- A.10 Residuals.- A.11 Discriminant Analysis.- A.12 Utilities.- A.12.1 File Input.- A.12.2 The Workspace.- A.12.3 Printing Information.- A.12.4 Displaying Parameter Estimates.- A.12.5 Displaying Summary Statistics.- A.12.6 Setting the Maximum Model.- A.12.7 Fixing Variables.- A.12.8 Macros.- B Implementation Specifics of MB'!.- B.1 Calling MIM.- B.2 The Main Menu.- B.3 Entering Commands and Navigating the Work Area.- B.4 The Built-In Editor.- B.5 Interactive Data Entry.- B.6 Independence Graphs.- B.7 Simple Data Graphics.- B.7.1 Scatter Plots.- B.7.2 Histograms.- B.7.3 Box Plots.- B.8 Graphics Export Formats.- B.9 Direct Database Access.- B.10 Program Intercommunication.- C On Multivariate Symmetry.- D On the Estimation Algorithms.- D.1 The MIPS Algorithm.- D.1.1 Notation.- D.1.2 The Likelihood Equations.- D.1.3 The General Algorithm.- D.1.4 The A-Collapsible Variant.- D.1.5 The Mean Linear Variant.- D.1.6 The Q-Equivalent Variant.- D.1.7 The Step-Halving Variant.- D.2 The EM-Algorithm.- D.3 The ME-Algorithm.- References."
            },
            "slug": "Introduction-to-graphical-modelling-Edwards",
            "title": {
                "fragments": [],
                "text": "Introduction to graphical modelling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 239
                            }
                        ],
                        "text": "Also, given two decomposable graphs on n vertices, G1 and G2, it is possible to go from one graph to the other by a sequence of single-edge additions and deletions keeping at all intermediate stages within the class of decomposable graphs (Lauritzen 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 127
                            }
                        ],
                        "text": "1991), multivariate normal models for continuous data (Wermuth 1976; Whittaker 1990), and mixed continuous and discrete models (Lauritzen and Wermuth 1989; Edwards 1990, 1995; Lauritzen 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 48
                            }
                        ],
                        "text": "For this broader perspective, see, for example, Lauritzen (1996), Gilks et al. (1996), Neal (1996), Frey (1998), and Jordan (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59820096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ea95d38e5b5a0bd8ef95184a95c29265a6d87e9",
            "isKey": false,
            "numCitedBy": 911,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphs and Conditional Independence.- Log-Linear Models.- Bayesian Networks.- Gaussian Graphical Models.- Mixed Interaction Models.- Graphical Models for Complex Stochastic Systems.- High dimensional modelling.- References.- Index."
            },
            "slug": "Graphical-models-in-R-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Graphical models in R"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper presents Graphical Models for Complex Stochastic Systems, a meta-modelling framework for graphical models of complex systems that combines Gaussian Graphical models, Mixed Interaction Models, and Log-Linear Models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 163
                            }
                        ],
                        "text": "The importance of avoiding over-fitting by means of some such trade-off between model fit and model complexity has long been recognized in classification problems (Breiman et al. 1984)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29458883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8017699564136f93af21575810d557dba1ee6fc6",
            "isKey": false,
            "numCitedBy": 16307,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Background. Introduction to Tree Classification. Right Sized Trees and Honest Estimates. Splitting Rules. Strengthening and Interpreting. Medical Diagnosis and Prognosis. Mass Spectra Classification. Regression Trees. Bayes Rules and Partitions. Optimal Pruning. Construction of Trees from a Learning Sample. Consistency. Bibliography. Notation Index. Subject Index."
            },
            "slug": "Classification-and-Regression-Trees-Breiman-Friedman",
            "title": {
                "fragments": [],
                "text": "Classification and Regression Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This chapter discusses tree classification in the context of medicine, where right Sized Trees and Honest Estimates are considered and Bayes Rules and Partitions are used as guides to optimal pruning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 224
                            }
                        ],
                        "text": "within theoretical statistics include: sufficiency and ancillarity; nuisance parameters (Dawid 1980a); Simpson\u2019s paradox; optional stopping, selection and missing data effects (Dawid 1976; Dawid and Dickey 1977); invariance (Dawid 1985); and model-building (Dawid 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121991824,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "58441c1e5474056f6dfd7d2ff40a76a2434b9d6f",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Invariance-and-independence-in-multivariate-theory-Dawid",
            "title": {
                "fragments": [],
                "text": "Invariance and independence in multivariate distribution theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709976"
                        ],
                        "name": "R. Diestel",
                        "slug": "R.-Diestel",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Diestel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Diestel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 30003027,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "87cf440b22c7e44dc1eb201e27895b171e29842e",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Simplicial-decompositions-of-graphs-Some-uniqueness-Diestel",
            "title": {
                "fragments": [],
                "text": "Simplicial decompositions of graphs - Some uniqueness results"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comb. Theory, Ser. B"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2316129"
                        ],
                        "name": "M. Meil\u0103",
                        "slug": "M.-Meil\u0103",
                        "structuredName": {
                            "firstName": "Marina",
                            "lastName": "Meil\u0103",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meil\u0103"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 504437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac0a36915b9f88fcab2d89bd39216dbbe757b7bf",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "When triangulating a belief network we aim to obtain a junction tree of minimum state space. According to (Rose, 1970), searching for the optimal triangulation can be cast as a search over all the permutations of the graph's vertices. Our approach is to embed the discrete set of permutations in a convex continuous domain D. By suitably extending the cost function over D and solving the continous nonlinear optimization task we hope to obtain a good triangulation with respect to the aformentioned cost. This paper presents two ways of embedding the triangulation problem into continuous domain and shows that they perform well compared to the best known heuristic."
            },
            "slug": "Triangulation-by-Continuous-Embedding-Meil\u0103-Jordan",
            "title": {
                "fragments": [],
                "text": "Triangulation by Continuous Embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Two ways of embedding the triangulation problem into continuous domain are presented and it is shown that they perform well compared to the best known heuristic."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120971461,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "7ce10624b09c54d2604f60b4c2d48409201fcc5b",
            "isKey": false,
            "numCitedBy": 5025,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Two results are presented concerning inference when data may be missing. First, ignoring the process that causes missing data when making sampling distribution inferences about the parameter of the data, \u03b8, is generally appropriate if and only if the missing data are \u201cmissing at random\u201d and the observed data are \u201cobserved at random,\u201d and then such inferences are generally conditional on the observed pattern of missing data. Second, ignoring the process that causes missing data when making Bayesian inferences about \u03b8 is generally appropriate if and only if the missing data are missing at random and the parameter of the missing data is \u201cindependent\u201d of \u03b8. Examples and discussion indicating the implications of these results are included."
            },
            "slug": "INFERENCE-AND-MISSING-DATA-Rubin",
            "title": {
                "fragments": [],
                "text": "INFERENCE AND MISSING DATA"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157745208"
                        ],
                        "name": "Jung-Fu Cheng",
                        "slug": "Jung-Fu-Cheng",
                        "structuredName": {
                            "firstName": "Jung-Fu",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung-Fu Cheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 19
                            }
                        ],
                        "text": "Later Shachter and Ndilikilikesha (1993) and Ndilikilikesha (1994) showed how to modify these standard algorithms to make them as computationally efficient as the fusion algorithm. Which of the various approaches is the most efficient seems to be proble dependent; see Shenoy (1994) and Call and Miller (1990) for discussions of these issues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 19
                            }
                        ],
                        "text": "Later Shachter and Ndilikilikesha (1993) and Ndilikilikesha (1994) showed how to modify these standard algorithms to make them as computationally efficient as the fusion algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "Recent experiments show exceptional performance of so-called turbo-codes which are decoded by algorithms based on approximate probability propagation (McEliece et al. 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14553992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26d953005dd08a863c157b528bbabdf5671d18b6",
            "isKey": true,
            "numCitedBy": 1004,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the close connection between the now celebrated iterative turbo decoding algorithm of Berrou et al. (1993) and an algorithm that has been well known in the artificial intelligence community for a decade, but which is relatively unknown to information theorists: Pearl's (1982) belief propagation algorithm. We see that if Pearl's algorithm is applied to the \"belief network\" of a parallel concatenation of two or more codes, the turbo decoding algorithm immediately results. Unfortunately, however, this belief diagram has loops, and Pearl only proved that his algorithm works when there are no loops, so an explanation of the experimental performance of turbo decoding is still lacking. However, we also show that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's (1962) low-density parity-check codes, serially concatenated codes, and product codes. Thus, belief propagation provides a very attractive general methodology for devising low-complexity iterative decoding algorithms for hybrid coded systems."
            },
            "slug": "Turbo-Decoding-as-an-Instance-of-Pearl's-\"Belief-McEliece-Mackay",
            "title": {
                "fragments": [],
                "text": "Turbo Decoding as an Instance of Pearl's \"Belief Propagation\" Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's low-density parity-check codes, serially concatenated codes, and product codes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE J. Sel. Areas Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "74208271"
                        ],
                        "name": "H.-G. Leimer",
                        "slug": "H.-G.-Leimer",
                        "structuredName": {
                            "firstName": "H.-G.",
                            "lastName": "Leimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H.-G. Leimer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43696636,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e5e5f9d0395e7e209e84d35ea032f0d9f25b0bf5",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-decomposition-by-clique-separators-Leimer",
            "title": {
                "fragments": [],
                "text": "Optimal decomposition by clique separators"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Math."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838789"
                        ],
                        "name": "S. Parter",
                        "slug": "S.-Parter",
                        "structuredName": {
                            "firstName": "Seymour",
                            "lastName": "Parter",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Parter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 141
                            }
                        ],
                        "text": "In effect one is then using local computation to solve sparse systems of linear equations, which also was an early instance of the algorithm (Parter 1961; Rose 1970)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 181
                            }
                        ],
                        "text": "1984; Diestel 1987, 1990), including the four-colour problem (Wagner 1937), measure theory (Kellerer 1964a, 1964b; Vorob\u2019ev 1962, 1963), the solution of systems of linear equations (Parter 1961; Rose 1970, 1973), game theory (Vorob\u2019ev 1967), and relational databases (Beeri et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 88
                            }
                        ],
                        "text": "This result for the special case that each node in D has at most one parent is given by Pearl (1988), Theorem 1, \u00a78."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122343771,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "16539d2f9aaaf87e5d6160a381ca4e292eb89be9",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "A procedure to study the effect of \"sparseness\" in Gauss elimination and to choose an elimination scheme if practical is introduced. The associations between graphs and matrices are developed and illustrated, and properties of special graphs, the trees, are discussed. Finally, the occasional breakdown of the Gauss procedure is also illustrated."
            },
            "slug": "The-Use-of-Linear-Graphs-in-Gauss-Elimination-Parter",
            "title": {
                "fragments": [],
                "text": "The Use of Linear Graphs in Gauss Elimination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120177012"
                        ],
                        "name": "Frank Jensen",
                        "slug": "Frank-Jensen",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Jensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 90
                            }
                        ],
                        "text": "1976; Gavril 1972), for constructing optimal junction trees for given decomposable graphs (Jensen and Jensen 1994), and for constructing optimal decompositions of a non-chordal graph into its indecomposable components (Tarjan 1985; Leimer 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5505903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "523db2d9c2b68246a0e102ba4144a0b3162ba810",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-junction-Trees-Jensen-Jensen",
            "title": {
                "fragments": [],
                "text": "Optimal junction Trees"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714284"
                        ],
                        "name": "P. Sebastiani",
                        "slug": "P.-Sebastiani",
                        "structuredName": {
                            "firstName": "Paola",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sebastiani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 115606926,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "3930376440ffd434b15c727c898790b0c1a36079",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This invention relates to an improved golf ball retriever of the type which may be lowered directly over the ball. The retriever has a telescopic handle for reaching into water hazards and the like. The handle is pivotally connected to a body member which has a pair of lower forwardly extending curved arms and a retaining ring pivotally connected at its rear to the body member at a point above the plane of the curved arms. Thus the retaining ring normally slopes forwardly downward and rests on the ends of the curved arms. The ring is slightly larger in diameter than a golf ball and when the retriever is lowered over a golf ball, the ring pivots slightly upward to increase the effective size of the opening between it and the curved arms to allow the ball to pass therethrough. When it has, the ring drops down past the outside of the ball, and the retriever is then lifted upwards with the ball engaged by the ring and the curved arms. The body member has an upper curved holding finger which prevents the ball from being dislodged and to which the handle is pivotally connected. This structure provides the advantage that the ball may be released simply by resting the body member on the ground and pulling forward on the handle. This automatically pivots the body portion about the ball and the retaining ring to release the ball. In other embodiments, the retaining ring may be rectangular or triangular with the body portion having arms to match."
            },
            "slug": "A-comparison-of-sequential-learning-methods-for-Cowell-Dawid",
            "title": {
                "fragments": [],
                "text": "A comparison of sequential learning methods for incomplete data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144505108"
                        ],
                        "name": "Z. Geng",
                        "slug": "Z.-Geng",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Geng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Geng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064877942"
                        ],
                        "name": "F. Tao",
                        "slug": "F.-Tao",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "108726499"
                        ],
                        "name": "K. Wan",
                        "slug": "K.-Wan",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69935840"
                        ],
                        "name": "C. Asano",
                        "slug": "C.-Asano",
                        "structuredName": {
                            "firstName": "Choichiro",
                            "lastName": "Asano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Asano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46550966"
                        ],
                        "name": "M. Ichimura",
                        "slug": "M.-Ichimura",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Ichimura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ichimura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068606"
                        ],
                        "name": "M. Kuroda",
                        "slug": "M.-Kuroda",
                        "structuredName": {
                            "firstName": "Masahiro",
                            "lastName": "Kuroda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kuroda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 42
                            }
                        ],
                        "text": "For the case of no prior causal ordering, Heckerman et al. (1995b) introduced some simple and appealing qualitative requirements as to how prior distributions for different models should be related."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 66
                            }
                        ],
                        "text": "For this broader perspective, see, for example, Lauritzen (1996), Gilks et al. (1996), Neal (1996), Frey (1998), and Jordan (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116768643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec5e763514960fb4385541f2723ebe99e1d5fa20",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The expectation maximization(EM) algorithm is a general iterative algorithm for the maximum-likelihood estimation(MLE) in incomplete-data problems. Dempster, Laird and Rubin(1977, henceforth DLR) showed that convergence is linear with rate proportional to the ratio of the missing information to the complete information. When a large proportion of data are missing, the speed of convergence can be very slow."
            },
            "slug": "Partial-Imputation-Method-in-the-EM-Algorithm-Geng-Tao",
            "title": {
                "fragments": [],
                "text": "Partial Imputation Method in the EM Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The expectation maximization(EM) algorithm is a general iterative algorithm for the maximum-likelihood estimation(MLE) in incomplete-data problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710305"
                        ],
                        "name": "D. Madigan",
                        "slug": "D.-Madigan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Madigan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Madigan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145614962"
                        ],
                        "name": "J. York",
                        "slug": "J.-York",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "York",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. York"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 67
                            }
                        ],
                        "text": "The use of Gibbs sampling in expert systems was first suggested by Pearl (1987). The PRESS system (Gammerman et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 72
                            }
                        ],
                        "text": "schemes to explore multiple model structures and their parameter spaces (Madigan and York 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5224321,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "31592816ac2c50ec22bcef38052d9dcc20a9171c",
            "isKey": false,
            "numCitedBy": 1107,
            "numCiting": 140,
            "paperAbstract": {
                "fragments": [],
                "text": "Pendant plus d'un demi-siecle, les graphes ont ete utilises pour representer des modeles statistiques en analyse de donnees. En particulier, les graphes decrivant l'independance conditionnelle sont apparus comme une classe importante de ces modeles. Des applications en analyse d'image, analyse de pedigree, ou encore en systeme expert sont a l'origine de leur developpement, et plusieurs livres de synthese ont deja ete publies a ce sujet. Le developpement d'un cadre Bayesien de ces modeles est en revanche moins connu, et les applications en systemes experts ont motive la recherche dans ce domaine. La possibilite de construire des modeles capables de se remettre a jour au fur et a mesure que de nouvelles donnees sont disponibles est a l'origine d'un interet intense de la part de la communaute travaillant en intelligence artificielle. Cependent, leur application a une classe plus vaste d'analyse de donnees a ete largement negligee. L'objet de cet article est de montrer comment les modeles Bayesiens de graphes permettent d'unifier et de simplifier des problemes standards, tels que les modeles log-lineaires Bayesiens (avec des donnees completes ou non), l'estimation d'une population fermee ou le double echantillonnage. Dans la mesure ou le choix d'un modele conventionel unique echoue dans ce type de situation, nous construisons des distributions a posteriori des quantites d'interet en moyennant sur les modeles possibles. Plus particulierement, nous introduisons la composition de chaines de Markov-Monte Carlo, une methode de Monte-Carlo permettant de moyenner sur les modeles retenus."
            },
            "slug": "Bayesian-Graphical-Models-for-Discrete-Data-Madigan-York",
            "title": {
                "fragments": [],
                "text": "Bayesian Graphical Models for Discrete Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2656437"
                        ],
                        "name": "M. West",
                        "slug": "M.-West",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "West",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. West"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48276437"
                        ],
                        "name": "J. Harrison",
                        "slug": "J.-Harrison",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Harrison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Harrison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 96
                            }
                        ],
                        "text": "A related problem is encountered in sequential analyses of multi-process models for time series (West and Harrison 1989), for which good approximations have been achieved by collapsing a mixture with a large number of terms down to a mixture with far fewer terms by merging \u2018similar\u2019 components (West 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121876157,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "63e3cfe166358f5a97a79880abf599a0d0699603",
            "isKey": false,
            "numCitedBy": 1558,
            "numCiting": 158,
            "paperAbstract": {
                "fragments": [],
                "text": "to the DLM: The First-Order Polynomial Model.- to the DLM: The Dynamic Regression Model.- The Dynamic Linear Model.- Univariate Time Series DLM Theory.- Model Specification and Design.- Polynomial Trend Models.- Seasonal Models.- Regression, Autoregression, and Related Models.- Illustrations and Extensions of Standard DLMs.- Intervention and Monitoring.- Multi-Process Models.- Non-Linear Dynamic Models: Analytic and Numerical Approximations.- Exponential Family Dynamic Models.- Simulation-Based Methods in Dynamic Models.- Multivariate Modelling and Forecasting.- Distribution Theory and Linear Algebra."
            },
            "slug": "Bayesian-forecasting-and-dynamic-models-West-Harrison",
            "title": {
                "fragments": [],
                "text": "Bayesian forecasting and dynamic models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748179"
                        ],
                        "name": "M. Yannakakis",
                        "slug": "M.-Yannakakis",
                        "structuredName": {
                            "firstName": "Mihalis",
                            "lastName": "Yannakakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yannakakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 83
                            }
                        ],
                        "text": "A related problem arises in the area of \u2018unsupervised learning\u2019: see, for example, Titterington et al. (1985) and Bernardo and Gir\u00f3n (1988), in which a Dirichlet mixture is approximated by a single Dirichlet distribution D(\u03b1\u2217 1, ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2995077,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "1ffc977d82798cfab971e4abdb46ae7b707c57c0",
            "isKey": false,
            "numCitedBy": 1113,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "An article of golfing equipment has a golf tee attached to a spring-biassed reel by a length of string. The reel is mounted in a casing which receives the tee when the spring rotates the reel to wind the spring onto it. The reel is normally locked by a one-way ratchet but is released to wind in the string by a push-button which has a spike and is detachable from the casing so as to be usable as a ball marker. When practising, the cord can be aligned with the green or hole and used as an aid in swinging the club face in the correct direction. The casing has a spring-clip so that the article can be clipped into the golfer's pocker when he is not using it."
            },
            "slug": "Simple-Linear-Time-Algorithms-to-Test-Chordality-of-Tarjan-Yannakakis",
            "title": {
                "fragments": [],
                "text": "Simple Linear-Time Algorithms to Test Chordality of Graphs, Test Acyclicity of Hypergraphs, and Selectively Reduce Acyclic Hypergraphs"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An article of golfing equipment has a golf tee attached to a spring-biassed reel by a length of string which can be aligned with the green or hole and used as an aid in swinging the club face in the correct direction."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120177012"
                        ],
                        "name": "Frank Jensen",
                        "slug": "Frank-Jensen",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Jensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52216590"
                        ],
                        "name": "S\u00f6ren Dittmer",
                        "slug": "S\u00f6ren-Dittmer",
                        "structuredName": {
                            "firstName": "S\u00f6ren",
                            "lastName": "Dittmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00f6ren Dittmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 906396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1348b2d7138b564ee8bb4ba974bb45427695e86f",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "From-Influence-Diagrams-to-junction-Trees-Jensen-Jensen",
            "title": {
                "fragments": [],
                "text": "From Influence Diagrams to junction Trees"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145353394"
                        ],
                        "name": "I. Adams",
                        "slug": "I.-Adams",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Adams",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66582841"
                        ],
                        "name": "M. Chan",
                        "slug": "M.-Chan",
                        "structuredName": {
                            "firstName": "Melissa",
                            "lastName": "Chan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964192"
                        ],
                        "name": "P. Clifford",
                        "slug": "P.-Clifford",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Clifford",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Clifford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93927772"
                        ],
                        "name": "W. M. Cooke",
                        "slug": "W.-M.-Cooke",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cooke",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. M. Cooke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11592513"
                        ],
                        "name": "V. Dallos",
                        "slug": "V.-Dallos",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Dallos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Dallos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88100316"
                        ],
                        "name": "F. T. de Dombal",
                        "slug": "F.-T.-de-Dombal",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "de Dombal",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. T. de Dombal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406040564"
                        ],
                        "name": "M. Edwards",
                        "slug": "M.-Edwards",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Edwards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98543757"
                        ],
                        "name": "D. Hancock",
                        "slug": "D.-Hancock",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Hancock",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hancock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83858514"
                        ],
                        "name": "D. Hewett",
                        "slug": "D.-Hewett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hewett",
                            "middleNames": [
                                "J"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hewett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143605796"
                        ],
                        "name": "N. Mcintyre",
                        "slug": "N.-Mcintyre",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Mcintyre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Mcintyre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 168
                            }
                        ],
                        "text": "1972), which has been implemented in a number of hospitals and remote sites such as submarines, and has been claimed to have a significant impact on care and resources (Adams et al. 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39354547,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "9f9683be67113685fb822a18cdfc5c48ba819703",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A multicentre study of computer aided diagnosis for patients with acute abdominal pain was performed in eight centres with over 250 participating doctors and 16,737 patients. Performance in diagnosis and decision making was compared over two periods: a test period (when a small computer system was provided to aid diagnosis) and a baseline period (before the system was installed). The two periods were well matched for type of case and rate of accrual. The system proved reliable and was used in 75.1% of possible cases. User reaction was broadly favourable. During the test period improvements were noted in diagnosis, decision making, and patient outcome. Initial diagnostic accuracy rose from 45.6% to 65.3%. The negative laparotomy rate fell by almost half, as did the perforation rate among patients with appendicitis (from 23.7% to 11.5%). The bad management error rate fell from 0.9% to 0.2%, and the observed mortality fell by 22.0%. The savings made were estimated as amounting to 278 laparotomies and 8,516 bed nights during the trial period--equivalent throughout the National Health Service to annual savings in resources worth over 20m pounds and direct cost savings of over 5m pounds. Computer aided diagnosis is a useful system for improving diagnosis and encouraging better clinical practice."
            },
            "slug": "Computer-aided-diagnosis-of-acute-abdominal-pain:-a-Adams-Chan",
            "title": {
                "fragments": [],
                "text": "Computer aided diagnosis of acute abdominal pain: a multicentre study."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Computer aided diagnosis is a useful system for improving diagnosis and encouraging better clinical practice and savings made were estimated as amounting to 278 laparotomies and 8,516 bed nights during the trial period--equivalent to annual savings in resources worth over 20m pounds and direct cost savings of over 5m pounds."
            },
            "venue": {
                "fragments": [],
                "text": "British medical journal"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109683373"
                        ],
                        "name": "Jim Q. Smith",
                        "slug": "Jim-Q.-Smith",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Smith",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Q. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123625088,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d5498fff1970a2b32e1e703efce07711f2296fb0",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY This paper generalizes and extends the idea of a steady evolution of a time series to multiparameter processes with any observational distribution. Particular examples of such processes are given. These include the multivariate steady process, univariate normal processes where the observational variance is unknown and series of multinomial observations with a steady model on the cell probabilities."
            },
            "slug": "The-Multiparameter-Steady-Model-Smith",
            "title": {
                "fragments": [],
                "text": "The Multiparameter Steady Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143648560"
                        ],
                        "name": "P. Spirtes",
                        "slug": "P.-Spirtes",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Spirtes",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Spirtes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10726446"
                        ],
                        "name": "T. Richardson",
                        "slug": "T.-Richardson",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Richardson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Richardson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11987717,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "998689f250121428024eed926b3c9e57727be83c",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that there is a general, informative and reliable procedure for discovering causal relations when, for all the investigator knows, both latent variables and selection bias may be at work. Given information about conditional independence and dependence relations between measured variables, even when latent variables and selection bias may be present, there are sufficient conditions for reliably concluding that there is a causal path from one variable to another, and sufficient conditions for reliably concluding when no such causal path exists."
            },
            "slug": "Causal-Inference-in-the-Presence-of-Latent-and-Bias-Spirtes-Meek",
            "title": {
                "fragments": [],
                "text": "Causal Inference in the Presence of Latent Variables and Selection Bias"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is shown that there is a general, informative and reliable procedure for discovering causal relations when, for all the investigator knows, both latent variables and selection bias may be at work."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "74208271"
                        ],
                        "name": "H.-G. Leimer",
                        "slug": "H.-G.-Leimer",
                        "structuredName": {
                            "firstName": "H.-G.",
                            "lastName": "Leimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H.-G. Leimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 115704979,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ed8a0af0e66b84142d7423c951900eb1724acf52",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Triangulated-Graphs-with-Marked-Vertices-Leimer",
            "title": {
                "fragments": [],
                "text": "Triangulated Graphs with Marked Vertices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49257912"
                        ],
                        "name": "G. Sutton",
                        "slug": "G.-Sutton",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Sutton",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sutton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 99
                            }
                        ],
                        "text": "directed networks using Dirichlet priors; their work was extended to directed Gaussian networks by Geiger and Heckerman (1994). Heckerman et al. (1995b) referred to global and local independence as global parameter independence and local parameter independence respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 99
                            }
                        ],
                        "text": "directed networks using Dirichlet priors; their work was extended to directed Gaussian networks by Geiger and Heckerman (1994). Heckerman et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8571482,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "ef3bba02833e4f6f64843abccc84b47a29c5b2e8",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "a correct decision in 84% and a combined bad diagnostic and management error rate of 3-2%.' We used a different approach, which requires the surgeon to categorise patients into management pathways at the time ofadmission (definitely needs operation, definitely does not require operation, uncertain). Laparoscopy was done in the uncertain group. We consider that this management approach to acute abdominal pain is more appropriate than a system based on diagnostic accuracy. We emphasise the point made by the authors that improved results during the study period are due not to the use of a computer but to accurate collection ofinformation and feedback of results to the doctors concerned. Improvement in this important area stems from interest, analysis, and feedback. Computers are one way of achieving this, rigorous analysis of decision making is another. We prefer the latter."
            },
            "slug": "Computer-aided-diagnosis-of-acute-abdominal-pain-Sutton",
            "title": {
                "fragments": [],
                "text": "Computer aided diagnosis of acute abdominal pain"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Improved results during the study period are due not to the use of a computer but to accurate collection of information and feedback of results to the doctors concerned, emphasise the point made by the authors."
            },
            "venue": {
                "fragments": [],
                "text": "British medical journal"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909853"
                        ],
                        "name": "A. Skene",
                        "slug": "A.-Skene",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Skene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Skene"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45813168,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "c80c7ab615b2fad5148a7848dbdd26a2dc50dd3d",
            "isKey": false,
            "numCitedBy": 1451,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In compiling a patient record many facets are subject to errors of measurement. A model is presented which allows individual error-rates to be estimated for polytomous facets even when the patient's \"true\" response is not available. The EM algorithm is shown to provide a slow but sure way of obtaining maximum likelihood estimates of the parameters of interest. Some preliminary experience is reported and the limitations of the method are described."
            },
            "slug": "Maximum-Likelihood-Estimation-of-Observer-Using-the-Dawid-Skene",
            "title": {
                "fragments": [],
                "text": "Maximum Likelihood Estimation of Observer Error\u2010Rates Using the EM Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The EM algorithm is shown to provide a slow but sure way of obtaining maximum likelihood estimates of the parameters of interest in compiling a patient record."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Meek (1995) proved a similar result for the case where the state spaces are all binary."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 0
                            }
                        ],
                        "text": "Meek (1995) proved a similar result for the case where the state spaces are all binary. A variant on the d-separation criterion, well-suited to computation of separating sets, is the \u201cBayes-ball\u201d algorithm of Shachter (1998). To complete this section we say that P obeys the local directed Markov property (DL) if any variable is conditionally independent of its non-descendants, given its parents"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 24
                            }
                        ],
                        "text": "An example was given by Moussouris (1974) for the graph being a four-cycle (see also Lauritzen (1996))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13267760,
            "fieldsOfStudy": [
                "Philosophy",
                "Economics"
            ],
            "id": "70e7ae486fc4cf97a6bb2c006daa3333e4997a01",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents correct algorithms for answering the following two questions; (i) Does there exist a causal explanation consistent with a set of background knowledge which explains all of the observed independence facts in a sample? (ii) Given that there is such a causal explanation what are the causal relationships common to every such causal explanation?"
            },
            "slug": "Causal-inference-and-causal-explanation-with-Meek",
            "title": {
                "fragments": [],
                "text": "Causal inference and causal explanation with background knowledge"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70056214"
                        ],
                        "name": "S. Wright",
                        "slug": "S.-Wright",
                        "structuredName": {
                            "firstName": "Sewall",
                            "lastName": "Wright",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121382684,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "f6d9ba13cb2f6354787e1c8fe4ee30cbd5f6addb",
            "isKey": false,
            "numCitedBy": 1791,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The Method of path coefficients was suggested a number of years ago (Wright 1918, more fully 1920, 1921), as a flexible means of relating the correlation coefficients between variables in a multiple system to the functional relations among them. The method has been applied in quite a variety of cases. It seems desirable now to make a restatement of the theory and to review the types of application, especially as there has been a certain amount of misunderstanding both of purpose and of procedure."
            },
            "slug": "The-Method-of-Path-Coefficients-Wright",
            "title": {
                "fragments": [],
                "text": "The Method of Path Coefficients"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1934
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32620901"
                        ],
                        "name": "A. H. Murphy",
                        "slug": "A.-H.-Murphy",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Murphy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. H. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830895"
                        ],
                        "name": "R. L. Winkler",
                        "slug": "R.-L.-Winkler",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Winkler",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Winkler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Neapolitan (1990) explains the basic propagation algorithms, and these are studied in detail by Shafer (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 0
                            }
                        ],
                        "text": "Neapolitan (1990) explains the basic propagation algorithms, and these are studied in detail by Shafer (1996). Jensen (1996) is a very good tutorial introduction, while Castillo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 127203550,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "1d87ab2973df3937e19bdebbb5be6a9ef02764c8",
            "isKey": false,
            "numCitedBy": 335,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY This paper briefly describes some results of operational and experimental programmes in the United States involving subjective probability forecasts of precipitation occurrence and of maximum and minimum temperatures. These results indicate that weather forecasters can formulate such forecasts in a reliable manner."
            },
            "slug": "Reliability-of-Subjective-Probability-Forecasts-of-Murphy-Winkler",
            "title": {
                "fragments": [],
                "text": "Reliability of Subjective Probability Forecasts of Precipitation and Temperature"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152591573"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15974963"
                        ],
                        "name": "A. F. Smith",
                        "slug": "A.-F.-Smith",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. F. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580190"
                        ],
                        "name": "U. Makov",
                        "slug": "U.-Makov",
                        "structuredName": {
                            "firstName": "Udi",
                            "lastName": "Makov",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Makov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 62
                            }
                        ],
                        "text": "An alternative approach is that of the \u2018probabilistic editor\u2019 (Titterington et al. 1985), in which the approximating distribution attempts to match the moments of the correct mixture."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124992180,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "54a1f6ab4cc6cb749c2b8d15c1dd3449e072362f",
            "isKey": false,
            "numCitedBy": 3447,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical Problems. Applications of Finite Mixture Models. Mathematical Aspects of Mixtures. Learning About the Parameters of a Mixture. Learning About the Components of a Mixture. Sequential Problems and Procedures."
            },
            "slug": "Statistical-analysis-of-finite-mixture-Titterington-Smith",
            "title": {
                "fragments": [],
                "text": "Statistical analysis of finite mixture distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This course discusses Mathematical Aspects of Mixtures, Sequential Problems and Procedures, and Applications of Finite Mixture Models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28322530,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "89c81a7f685fda0105eb577c1b384b68125086f5",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with asymmetric decision problems. We describe a generalization of the valuation network representation and solution technique to enable efficient representation and solution of asymmetric decision problems. The generalization includes the concepts of indicator valuations and effective frames. We illustrate our technique by solving Raiffa\u2019s oil wildcatter\u2019s problem in complete detail."
            },
            "slug": "Representing-and-Solving-Asymmetric-Decision-Using-Shenoy",
            "title": {
                "fragments": [],
                "text": "Representing and Solving Asymmetric Decision Problems Using Valuation Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A generalization of the valuation network representations and solution technique to enable efficient representation and solution of asymmetric decision problems is described."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2260625"
                        ],
                        "name": "R. Franklin",
                        "slug": "R.-Franklin",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Franklin",
                            "middleNames": [
                                "C.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Franklin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144433605"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8516933"
                        ],
                        "name": "F. Macartney",
                        "slug": "F.-Macartney",
                        "structuredName": {
                            "firstName": "Fergus",
                            "lastName": "Macartney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Macartney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144467804"
                        ],
                        "name": "K. Bull",
                        "slug": "K.-Bull",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Bull",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 107
                            }
                        ],
                        "text": "4 do considerably worse, in terms of simple accuracy, than a simple algorithmic approach; the algorithm of Franklin et al. (1991) described in Section 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 45
                            }
                        ],
                        "text": "It was developed and evaluated on 400 cases (Franklin et al. 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27312242,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "81c4822e5f83964eb19992de38ae3258aaf1ccec",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "OBJECTIVE--To develop, test, and validate an algorithm for diagnosing disease in neonates during an over the telephone referral to a specialist cardiac centre. DESIGN--A draft algorithm requiring only data available to a referring paediatrician was generated. This was modified in the light of a retrospective review of case records. A questionnaire to elicit all the data required by the algorithm was then generated. There followed a prospective three phase evaluation during consecutive over the telephone referrals. This consisted of (a) a conventional phase with unstructured referral consultations, (b) a phase with referrals structured around the questionnaire but independent of the algorithm, and (c) a validation phase with the algorithm (and its previous errors) available during the referral consultation. SETTING--59 paediatric centres in south east England and a central specialist paediatric cardiology unit. PATIENTS--Consecutive neonates (aged less than 31 days) referred with suspected heart disease. The retrospective review was of records of 174 neonates from 1979. In the prospective evaluation (1987-90) the conventional phase comprised 71 neonates (over 5.5 months), the structured phase 203 neonates (over 14 months), and the validation phase 195 neonates (over 12 months). MAIN OUTCOME MEASURES--Diagnostic accuracy (assigning patients to the correct diagnostic category (out of 27)), of the referring paediatrician, the specialist after the referral consultation, and the algorithm as compared with the definitive diagnosis by echocardiography at the specialist centre, and score for the appropriateness of management in transit. RESULTS--Simply structuring the consultation by questionnaire (that is, proceeding from the conventional phase to the structured phase) improved the diagnostic accuracy of both paediatricians (from 34% (24/71 cases) to 48% (97/203) correct) and specialists (from 54% (38/71 cases) to 64% (130/203) correct). The algorithm (structured phase) would have been even more accurate (78% (158/203 cases); p less than 0.01). Management scores in the structured phase were also better than in the conventional phase (80%(162/203 cases)v 58% (41/71) appropriate; p less than 0.01). Management scores would have improved to 91% appropriate (185/203; p less than 0.001) had the algorithmic diagnoses dictated management. The superiority of the algorithm was maintained but not bettered in the validation phase. CONCLUSIONS--Applying the algorithm should reduce the morbidity and mortality of neonates with critical heart disease by aiding clinicians in therapeutic decisions for in transit care."
            },
            "slug": "Evaluation-of-a-diagnostic-algorithm-for-heart-in-Franklin-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Evaluation of a diagnostic algorithm for heart disease in neonates."
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "Applying an algorithm for diagnosing disease in neonates during an over the telephone referral to a specialist cardiac centre should reduce the morbidity and mortality of neonates with critical heart disease by aiding clinicians in therapeutic decisions for in transit care."
            },
            "venue": {
                "fragments": [],
                "text": "BMJ"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17590643,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c82ece582386d0a0df0c3fbd67ee461a3336e870",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "This article has been prepared as an entry for the Wiley Encyclopedia of Statistical Sciences (Update). It gives a brief overview of fundamental properties and applications of conditional independence."
            },
            "slug": "Conditional-Independence-Dawid",
            "title": {
                "fragments": [],
                "text": "Conditional Independence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3184408"
                        ],
                        "name": "N. Wermuth",
                        "slug": "N.-Wermuth",
                        "structuredName": {
                            "firstName": "Nanny",
                            "lastName": "Wermuth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wermuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 54
                            }
                        ],
                        "text": "1991), multivariate normal models for continuous data (Wermuth 1976; Whittaker 1990), and mixed continuous and discrete models (Lauritzen and Wermuth 1989; Edwards 1990, 1995; Lauritzen 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123123032,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "13546e62146361d3165870d83b65ddfb41f0a44c",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a non-iterative model search technique to find simple patterns of association for several variables. Our selection procedure is restricted to multiplicative models, therefore all patterns under consideration are interpretable in terms of zero partial associations of variable pairs. Wie illustrate the selection technique on two sets of data, one in a contingency table, one in a covariance matrix."
            },
            "slug": "Model-Search-among-Multiplicative-Models-Wermuth",
            "title": {
                "fragments": [],
                "text": "Model Search among Multiplicative Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410117753"
                        ],
                        "name": "N. N. Vorob\u2019ev",
                        "slug": "N.-N.-Vorob\u2019ev",
                        "structuredName": {
                            "firstName": "Nikolay",
                            "lastName": "Vorob\u2019ev",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. N. Vorob\u2019ev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 40
                            }
                        ],
                        "text": "The n\u00e4\u0131ve Bayes model was first used by Warner et al. (1961) for the diagnosis of congenital heart disease."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118915216,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e2d367cbb64f5d52caf884b056b3b962d17819b7",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Let $\\Sigma $ be a family of Borel fields of subsets of a set S and $\\mu_\\mathfrak{S} $ probabilistic measures on measurable spaces $\\langle {\\mathfrak{S},S} \\rangle $, where $\\mathfrak{S} \\in \\Sigma $. The family of measures $\\mu_\\mathfrak{S} $, $\\mathfrak{S} \\in \\Sigma $ is denoted by $\\mu_\\Sigma $.The measures $\\mu_{\\mathfrak{S}_1 } $ and $\\mu_{\\mathfrak{S}_2 } $ are said to be consistent if $\\mu_{\\mathfrak{S}_1 } (A) = \\mu_{\\mathfrak{S}_2 } (A)$ for any $A \\in \\mathfrak{S}_1 \\cap \\mathfrak{S}_2 $. If any pair of measures of the family $\\mu_\\Sigma $ is consistent, the family itself is referred to as consistent.The consistent family $\\mu_\\Sigma $ is said to be extendable if there is a measure $\\mu_{[\\Sigma ]} $ on the measurable space $\\langle {[\\Sigma ],S} \\rangle $ consistent with each measure of $\\mu_\\Sigma $ ($[\\Sigma ]$ is the smallest Borel field containing all $\\mathfrak{S} \\in \\Sigma $).For the purposes of the theory of games the following special case of extendability is important. Let ${\\bf \\m..."
            },
            "slug": "Consistent-Families-of-Measures-and-Their-Vorob\u2019ev",
            "title": {
                "fragments": [],
                "text": "Consistent Families of Measures and Their Extensions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 218
                            }
                        ],
                        "text": "1976; Gavril 1972), for constructing optimal junction trees for given decomposable graphs (Jensen and Jensen 1994), and for constructing optimal decompositions of a non-chordal graph into its indecomposable components (Tarjan 1985; Leimer 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Tarjan and Yannakakis (1984) gave the following efficient algorithm, and proved its correctness, for deciding whether a given undirected graph G = (V,E) is chordal or not; they also showed that it can be implemented to run in O(n+ e) time where n = |V | is the number of nodes and e = |E| the number of edges:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 204987180,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "cdf10a56ed096a03d840efa3f6dbae0193f28d52",
            "isKey": false,
            "numCitedBy": 419,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Decomposition-by-clique-separators-Tarjan",
            "title": {
                "fragments": [],
                "text": "Decomposition by clique separators"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Math."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48455749"
                        ],
                        "name": "J. Dickey",
                        "slug": "J.-Dickey",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Dickey",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dickey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 176
                            }
                        ],
                        "text": "within theoretical statistics include: sufficiency and ancillarity; nuisance parameters (Dawid 1980a); Simpson\u2019s paradox; optional stopping, selection and missing data effects (Dawid 1976; Dawid and Dickey 1977); invariance (Dawid 1985); and model-building (Dawid 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123191433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10b29e63bcc2652673ac358f1392b1154714f261",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract If the reported data of an experiment have been subject to selection, then inference from such data should be modified accordingly. We investigate the modification required to the face-value likelihood. In particular, we derive conditions under which no modification is necessary and the data can be taken at face value."
            },
            "slug": "Likelihood-and-Bayesian-Inference-from-Selectively-Dawid-Dickey",
            "title": {
                "fragments": [],
                "text": "Likelihood and Bayesian Inference from Selectively Reported Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The modification required to the face-value likelihood is investigated and conditions under which no modification is necessary and the data can be taken at face value are derived."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49253201"
                        ],
                        "name": "R. W. Robinson",
                        "slug": "R.-W.-Robinson",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Robinson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W. Robinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Robinson (1977) gives the following recursive formula (no closed form formula is known) for calculating the number f(n) of unlabelled DAGs on n nodes:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122527054,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "931adb3e4758aeca8a09ce8ec02fc2548ff2df01",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The previously known ways to count acyclic digraphs, both labeled and unlabeled, are reviewed. Then a new method of enumerating unlabeled acyclic digraphs is developed. It involves computing the sum of the cyclic indices of the automorphism groups of the acyclic digraphs, achieving a considerable gain in efficiency through an application of the inclusion-exclusion principle. Numerical results are reported on, and a table of the numbers of unlabeled acyclic digraphs on up to 18 points is included."
            },
            "slug": "Counting-unlabeled-acyclic-digraphs-Robinson",
            "title": {
                "fragments": [],
                "text": "Counting unlabeled acyclic digraphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2613549"
                        ],
                        "name": "P. Sham",
                        "slug": "P.-Sham",
                        "structuredName": {
                            "firstName": "Pak",
                            "lastName": "Sham",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sham"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 107
                            }
                        ],
                        "text": "Interesting instances of mixed discrete-Gaussian networks appear in polygenic models for genetic pedigrees (Sham 1998), where major genes correspond to discrete variables and polygenic effects to continuous."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 83187274,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "279e0f13e917cdf076f29082e00a91c057768ff8",
            "isKey": false,
            "numCitedBy": 550,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In human genetic research sophisticated statistical methods are increasingly used to analyse results. This text assumes an understanding of basic statistical concepts, but the objectives, principles and limitations of the methods are discussed in full."
            },
            "slug": "Statistics-in-human-genetics-Sham",
            "title": {
                "fragments": [],
                "text": "Statistics in human genetics"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "In human genetic research sophisticated statistical methods are increasingly used to analyse results and the objectives, principles and limitations of the methods are discussed in full."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 88
                            }
                        ],
                        "text": "within theoretical statistics include: sufficiency and ancillarity; nuisance parameters (Dawid 1980a); Simpson\u2019s paradox; optional stopping, selection and missing data effects (Dawid 1976; Dawid and Dickey 1977); invariance (Dawid 1985); and model-building (Dawid 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123681722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2018292127dd6b15f9606307e09bd9e8b90da28",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryThe elimination of nuisance parameters has classically been tackled by variousad hoc devices, and has led to a number of attempts to define partial sufficiency and ancillarity. The Bayesian approach is clearly defined. This paper examines some classical procedures in order to see when they can be given a Bayesian justification."
            },
            "slug": "A-Bayesian-look-at-nuisance-parameters-Dawid",
            "title": {
                "fragments": [],
                "text": "A Bayesian look at nuisance parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper examines some classical procedures in order to see when they can be given a Bayesian justification."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144327830"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Cox",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3184408"
                        ],
                        "name": "N. Wermuth",
                        "slug": "N.-Wermuth",
                        "structuredName": {
                            "firstName": "Nanny",
                            "lastName": "Wermuth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wermuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123524682,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "60184ac85daa921b74c51876fbd32aaea6d6c669",
            "isKey": false,
            "numCitedBy": 565,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction Aspects of Interpretation Technical Considerations Statistical Analysis Special Methods for Joint Responses Some Examples Strategical Aspects More Specialized Topics Appendices"
            },
            "slug": "Multivariate-Dependencies:-Models,-Analysis-and-Cox-Wermuth",
            "title": {
                "fragments": [],
                "text": "Multivariate Dependencies: Models, Analysis and Interpretation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29989822"
                        ],
                        "name": "T. Speed",
                        "slug": "T.-Speed",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Speed",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Speed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40336289"
                        ],
                        "name": "K. Vijayan",
                        "slug": "K.-Vijayan",
                        "structuredName": {
                            "firstName": "Kaipillil",
                            "lastName": "Vijayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Vijayan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 86
                            }
                        ],
                        "text": "The notion of a graph decomposition has deep connections to many areas of mathematics (Lauritzen et al. 1984; Diestel 1987, 1990), including the four-colour problem (Wagner 1937), measure theory (Kellerer 1964a, 1964b; Vorob\u2019ev 1962, 1963), the solution of systems of linear equations (Parter 1961; Rose 1970, 1973), game theory (Vorob\u2019ev 1967), and relational databases (Beeri et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119982532,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c561aaeb73289589891ffdf803979e55c346f2f5",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We define and investigate the notion of a decomposable hypergraph, showing that such a hypergraph always is conformal, that is, can be viewed as the class of maximal cliques of a graph. We further show that the clique hypergraph of a graph is decomposable if and only if the graph is triangulated and characterise such graphs in terms of a combinatorial identity."
            },
            "slug": "Decomposable-graphs-and-hypergraphs-Lauritzen-Speed",
            "title": {
                "fragments": [],
                "text": "Decomposable graphs and hypergraphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714472"
                        ],
                        "name": "Y. Sagiv",
                        "slug": "Y.-Sagiv",
                        "structuredName": {
                            "firstName": "Yehoshua",
                            "lastName": "Sagiv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Sagiv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428874"
                        ],
                        "name": "Scott F. Walecka",
                        "slug": "Scott-F.-Walecka",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Walecka",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott F. Walecka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 37
                            }
                        ],
                        "text": ", embedded multi-valued dependencies (Sagiv and Walecka 1982) and natural conditional functions (Spohn 1988; Studen\u00fd 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Shenoy (1992) developed an alternative formulation based upon valuation systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 404,
                                "start": 0
                            }
                        ],
                        "text": "Shenoy (1992) developed an alternative formulation based upon valuation systems. The representation and solution process takes place on a hypergraph tree structure called a rooted Markov tree, similar in many respects to the elimination tree, using marginalization and combination of valuations (which represent the probabilities and utilities) according to a fusion algorithm described in Shenoy (1992). The algorithm is slightly more efficient computationally than the standard arc-reversal and nodeelimination method for solving influence diagrams."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7785002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9ccc19674eedcae69a070aa7e9c300c5363dbbd",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "It tS shown that embedded multwalued dependencies do not have a complete axlomatizatlon A new type of dependenoes, called subset dependencies, is introduced. Subset dependencies are a generahzauon of embedded multtvalued dependencies It is shown that a subclass of subset dependenoes (that does not include all the embedded multwalued dependenoes) has a complete axlomatlzation consisting of reflexivity and translt~vity rules As a result, ~t ~s shown how to test implications of embedded muluvalued dependencies under some restricted conditions"
            },
            "slug": "Subset-Dependencies-and-a-Completeness-Result-for-a-Sagiv-Walecka",
            "title": {
                "fragments": [],
                "text": "Subset Dependencies and a Completeness Result for a Subclass of Embedded Multivalued Dependencies"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "It is shown how to test implications of embedded muluvalued dependencies under some restricted conditions and a new type of dependenoes, called subset dependencies, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143946660"
                        ],
                        "name": "S. Wright",
                        "slug": "S.-Wright",
                        "structuredName": {
                            "firstName": "S",
                            "lastName": "Wright",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8664449,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "4bb5cc4fb92154401f359f0d124d8b6e541872e7",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "PAGE INTRODUCTION. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239 General applications of the theory. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240 Mathematics of path coefficients. ................................................. 243 Definitions. .................................................................... 243 Path coefficients and correlation. .................................................. 244 Degree of determination.. ....................................................... 245 Precautions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246 Direction of influence. .................................... ,, ..................... 247 Application to causal relations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248 The relative importance of heredity and environment. ............................... 250 The consequences of different systems of mating .................................... 251 Miscellaneous applications. ................................................... , .. 252 Relation to multiple correlation. .................................................. 252 CONCLUSIONS. .. ............................................................... 254 LITERATURE CITED. .. .......................................................... 255"
            },
            "slug": "The-Theory-of-Path-Coefficients-a-Reply-to-Niles's-Wright",
            "title": {
                "fragments": [],
                "text": "The Theory of Path Coefficients a Reply to Niles's Criticism."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The author examines the relationship of heredity and environment to mating, the consequences of different systems of mating, and the application of causal relations to causal relations."
            },
            "venue": {
                "fragments": [],
                "text": "Genetics"
            },
            "year": 1923
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 66
                            }
                        ],
                        "text": "Neural networks have been reconstructed as probabilistic networks (Neal 1996; Frey 1998), which again produce shallow but densely connected graphs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 21
                            }
                        ],
                        "text": "(1996), Neal (1996), Frey (1998), and Jordan (1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 21
                            }
                        ],
                        "text": "(1996), Neal (1996), Frey (1998), and Jordan (1998). The last is a particularly good guide to the wide variety of models that now shelter under the graphical umbrella."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 100
                            }
                        ],
                        "text": "For this broader perspective, see, for example, Lauritzen (1996), Gilks et al. (1996), Neal (1996), Frey (1998), and Jordan (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62488180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "629cc74dcaf655feea40f64cd74617ac884ed0f8",
            "isKey": true,
            "numCitedBy": 621,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic inference in graphical models pattern classification unsupervised learning data compression channel coding future research directions."
            },
            "slug": "Graphical-Models-for-Machine-Learning-and-Digital-Frey",
            "title": {
                "fragments": [],
                "text": "Graphical Models for Machine Learning and Digital Communication"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "Probabilistic inference in graphical models pattern classification unsupervised learning data compression channel coding future research directions and how this affects research directions is investigated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34577797"
                        ],
                        "name": "D. Rose",
                        "slug": "D.-Rose",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rose",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rose"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 141
                            }
                        ],
                        "text": "In effect one is then using local computation to solve sparse systems of linear equations, which also was an early instance of the algorithm (Parter 1961; Rose 1970)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121363539,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1d0fcea0c333f80d265818c79a5f63a4bec65922",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Triangulated-graphs-and-the-elimination-process-Rose",
            "title": {
                "fragments": [],
                "text": "Triangulated graphs and the elimination process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742419"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145615522"
                        ],
                        "name": "G. D. Murray",
                        "slug": "G.-D.-Murray",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Murray",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. D. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077428528"
                        ],
                        "name": "L. Murray",
                        "slug": "L.-Murray",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Murray",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144433605"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079543026"
                        ],
                        "name": "A. Skene",
                        "slug": "A.-Skene",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Skene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Skene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145217017"
                        ],
                        "name": "J. Habbema",
                        "slug": "J.-Habbema",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Habbema",
                            "middleNames": [
                                "Dik",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Habbema"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8302174"
                        ],
                        "name": "G. Gelpke",
                        "slug": "G.-Gelpke",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Gelpke",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gelpke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 136
                            }
                        ],
                        "text": "34 3.3.1 The clique-marginal representation . . . . . . . . . . 36 3.3.2 Incorporation of evidence . . . . . . . . . . . . . . . 36 3.4 Bayesian networks as expert systems . . . . . . . . . . . . . 37 3.5 Background references and further reading . . . . . . . . . . 40\n3.5.1 Structuring the graph . . . . . . . . . . . . . . . ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 8
                            }
                        ],
                        "text": "192 9.4 Bayesian updating with complete data . . . . . . . . . . ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 79
                            }
                        ],
                        "text": "11 2.7 Axioms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.8 Bayes\u2019 theorem . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.9 Bayesian reasoning in expert systems . . . . . . . . . . . . . 17 2.10 A broader context for probabilistic expert systems . . . . . 21"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 140
                            }
                        ],
                        "text": "These, in turn, can be expressed by means of a powerful and appealing graphical representation, and the resulting networks are often termed Bayesian networks, although in this book we prefer the term probabilistic networks, reflecting an increased generality in the representations we consider."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 45
                            }
                        ],
                        "text": "The book concludes with three appendices: on Bayesian conjugate analysis of discrete data, on stochastic simulation and Gibbs sampling, and on information and software available on the World Wide Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 184
                            }
                        ],
                        "text": "Calculating the posterior probability of each disease on the basis of observed findings is extremely straightforward: this simple model has been termed n\u00e4\u0131ve \u2014 or even idiot\u2019s \u2014 Bayes (Titterington et al. 1981)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 51
                            }
                        ],
                        "text": "Our various enthusiasms for multivariate analysis, Bayesian statistics, computer algorithms, conditional independence, graph theory, decision-support systems, and so on, have since found a common area of application in probabilistic networks for expert systems, and we have been fortunate to enjoy a long and fruitful period of joint work which has been little hindered by the intervening North Sea."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 8
                            }
                        ],
                        "text": "204\n9.7 Bayesian updating with incomplete data . . . . . . . . . . ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Bayes\u2019 theorem then forms the fundamental tool for belief revision, and \u2018Bayesian networks\u2019 can be formed by superimposing a probability model on a graph representing qualitative conditional independence assumptions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 86399946,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "d7b811758bf6de6923d9b8363f5afd155a26e8a1",
            "isKey": true,
            "numCitedBy": 304,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Several techniques for discriminant analysis are applied to a set of data from patients with severe head injuries, for the purpose of prognosis. The data are such that multidimensionality, continuous, binary and ordered categorical variables and missing data must be coped with. The various methods are compared using criteria of prognostic success and reliability. In general, performance varies more with choice of the set of predictor variables than with that of the discriminant rule."
            },
            "slug": "Comparison-of-Discrimination-Techniques-Applied-to-Titterington-Murray",
            "title": {
                "fragments": [],
                "text": "Comparison of Discrimination Techniques Applied to a Complex Data Set of Head Injured Patients"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "In this work, several techniques for discriminant analysis are applied to a set of data from patients with severe head injuries, for the purpose of prognosis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5048279"
                        ],
                        "name": "L. Bernardinelli",
                        "slug": "L.-Bernardinelli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bernardinelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bernardinelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5953322"
                        ],
                        "name": "C. Pascutto",
                        "slug": "C.-Pascutto",
                        "structuredName": {
                            "firstName": "Cristiana",
                            "lastName": "Pascutto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pascutto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34949056"
                        ],
                        "name": "N. G. Best",
                        "slug": "N.-G.-Best",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Best",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. G. Best"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089883"
                        ],
                        "name": "W. Gilks",
                        "slug": "W.-Gilks",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Gilks",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gilks"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 388,
                                "start": 64
                            }
                        ],
                        "text": "Such spatial models are also used in geographical epidemiology (Bernardinelli et al. 1997) and agricultural field trials (Besag et al. 1995). Within the artificial intelligence community, neural networks are natural candidates for interpretation as probabilistic graphical models, and are increasingly being analysed within a Bayesian statistical framework (see, for example, Neal (1996))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 63
                            }
                        ],
                        "text": "Such spatial models are also used in geographical epidemiology (Bernardinelli et al. 1997) and agricultural field trials (Besag et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36714599,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "68a9ac9043a9ce173fc48479cc0c47d26897d33e",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe Bayesian hierarchical-spatial models for disease mapping with imprecisely observed ecological covariates. We posit smoothing priors for both the disease submodel and the covariate submodel. We apply the models to an analysis of insulin Dependent Diabetes Mellitus incidence in Sardinia, with malaria prevalence as a covariate."
            },
            "slug": "Disease-mapping-with-errors-in-covariates.-Bernardinelli-Pascutto",
            "title": {
                "fragments": [],
                "text": "Disease mapping with errors in covariates."
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Bayesian hierarchical-spatial models for disease mapping with imprecisely observed ecological covariates and smoothing priors are described and applied to an analysis of insulin Dependent Diabetes Mellitus incidence in Sardinia."
            },
            "venue": {
                "fragments": [],
                "text": "Statistics in medicine"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145785254"
                        ],
                        "name": "P. Diggle",
                        "slug": "P.-Diggle",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Diggle",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Diggle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2400157"
                        ],
                        "name": "M. Kenward",
                        "slug": "M.-Kenward",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kenward",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kenward"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 231
                            }
                        ],
                        "text": "In principle it is possible to incorporate additional \u201cselection variables\u201d into one\u2019s model, thus modelling explicitly the dependence of the observation process on the values, observed or unobserved, for the variables in the case (Diggle and Kenward 1994; Best et al. 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124188078,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "99adba48dcc77ac76a28d4375728f0ae77e60217",
            "isKey": false,
            "numCitedBy": 987,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "A model is proposed for continuous longitudinal data with non-ignorable or informative drop-out (ID). The model combines a multivariate linear model for the underlying response with a logistic regression model for the drop-out process. The latter incorporates dependence of the probability of drop-out on unobserved, or missing, observations. Parameters in the model are estimated by using maximum likelihood (ML) and inferences drawn through conventional likelihood procedures. In particular, likelihood ratio tests can be used to assess the informativeness of the drop-out process through comparison of the full model with reduced models corresponding to random drop-out (RD) and completely random processes"
            },
            "slug": "Informative-Drop\u2010Out-in-Longitudinal-Data-Analysis-Diggle-Kenward",
            "title": {
                "fragments": [],
                "text": "Informative Drop\u2010Out in Longitudinal Data Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709976"
                        ],
                        "name": "R. Diestel",
                        "slug": "R.-Diestel",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Diestel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Diestel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118612774,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bf69eddc4efacdaf33c135009d468df52ef77f1c",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Note to the reader Introduction Fundamental facts and concepts Separating simplices and the existence of prime decompositions Simplicial minors and the existence of prime decompositions The uniqueness of prime decompositions Decompositions into small factors Applications of simplicial decompositions Appendix: Some notes on set theory References Subject index Index of symbols."
            },
            "slug": "Graph-Decompositions:-A-Study-in-Infinite-Graph-Diestel",
            "title": {
                "fragments": [],
                "text": "Graph Decompositions: A Study in Infinite Graph Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145249669"
                        ],
                        "name": "D. Maier",
                        "slug": "D.-Maier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Maier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 110
                            }
                        ],
                        "text": "The first explicit identification seems to be in relational databases, where it has been known as a join tree (Maier 1983); the terms k\u2013tree (Arnborg et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215753726,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dca5a035bf1d99e5e01adc77d6ed9f2338f254f5",
            "isKey": false,
            "numCitedBy": 1791,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The method of operating a water-cooled neutronic reactor having a graphite moderator which comprises flowing a gaseous mixture of carbon dioxide and helium, in which the helium comprises 40-60 volume percent of the mixture, in contact with the graphite moderator."
            },
            "slug": "The-Theory-of-Relational-Databases-Maier",
            "title": {
                "fragments": [],
                "text": "The Theory of Relational Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The method of operating a water-cooled neutronic reactor having a graphite moderator which comprises flowing a gaseous mixture of carbon dioxide and helium, in which the helium comprises 40-60 volume percent of the mixture, in contact with thegraphite moderator."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153356158"
                        ],
                        "name": "P. Jones",
                        "slug": "P.-Jones",
                        "structuredName": {
                            "firstName": "Pauline",
                            "lastName": "Jones",
                            "middleNames": [
                                "Macon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 167
                            }
                        ],
                        "text": "The optimality criterion by which decisions are judged is that of maximizing overall expected utility, or the equivalent criterion of minimizing overall expected loss (Savage 1954; Raiffa and Schlaifer 1961; Lindley 1985)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4285725,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b8afae0d03e3282a6fb78b58af9862ccd9cfe986",
            "isKey": false,
            "numCitedBy": 438,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Making Decisions. By D. V. Lindley. Pp. 195. (Wiley-Interscience: London and New York, March 1971.) \u00a31.95."
            },
            "slug": "Making-Decisions-Jones",
            "title": {
                "fragments": [],
                "text": "Making Decisions"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62740051,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "f95148ead0c888e159dbc39f6f43a2d71c9ea167",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": "This is an unpublished monograph that was widely distributed (and cited). It was first written in August 1988 and subseqently revised."
            },
            "slug": "Local-Computation-in-Hypertrees-Shafer-Shenoy",
            "title": {
                "fragments": [],
                "text": "Local Computation in Hypertrees"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This is an unpublished monograph that was widely distributed (and cited) and was first written in August 1988 and subseqently revised in August 1989."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778725"
                        ],
                        "name": "J. Breese",
                        "slug": "J.-Breese",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Breese",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Breese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2892558"
                        ],
                        "name": "Koos Rommelse",
                        "slug": "Koos-Rommelse",
                        "structuredName": {
                            "firstName": "Koos",
                            "lastName": "Rommelse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Koos Rommelse"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13084909,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "44021862638c6e934f5d9fc3a110aa2aef596aba",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "You have just finished typing that big report into your word processor. It is formatted correctly and looks beautiful on the screen. You hit print, go to the printer\u2014and nothing is there. Your try again\u2014still nothing. The report needs to go out today. What do you do?"
            },
            "slug": "Decision-theoretic-troubleshooting-Heckerman-Breese",
            "title": {
                "fragments": [],
                "text": "Decision-theoretic troubleshooting"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "You have just finished typing that big report into your word processor, it is formatted correctly and looks beautiful on the screen, you hit print, go to the printer\u2014and nothing is there."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46184313"
                        ],
                        "name": "B. D. Finetti",
                        "slug": "B.-D.-Finetti",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Finetti",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Finetti"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 151186410,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "c849e6b52f562be3dc984196b61114b93516bb8c",
            "isKey": false,
            "numCitedBy": 863,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The word \u201cequivalent\u201d of the original has been translated throughout as \u201cexchangeable.\u201d The original term (used also by Khinchin) and even the term \u201csymmetric\u201d (used by Savage and Hewitt) appear to admit ambiguity. The word \u201cexchangeable,\u201d proposed by Frechet, seems expressive and unambiguous and has been adopted and recommended by most authors, including de Finetti."
            },
            "slug": "Foresight:-Its-Logical-Laws,-Its-Subjective-Sources-Finetti",
            "title": {
                "fragments": [],
                "text": "Foresight: Its Logical Laws, Its Subjective Sources"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748179"
                        ],
                        "name": "M. Yannakakis",
                        "slug": "M.-Yannakakis",
                        "structuredName": {
                            "firstName": "Mihalis",
                            "lastName": "Yannakakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yannakakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 177
                            }
                        ],
                        "text": "The problem of obtaining a good triangulation is thus one of finding a good ordering, but the general problem of finding optimal triangulations for undirected graphs is NP-hard (Yannakakis 1981), so heuristic algorithms must be developed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122001383,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8561d23058501c8f2c245bffb3001e488192a7a3",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that the following problem is NP-complete. Given a graph, find the minimum number of edges (fill-in) whose addition makes the graph chordal. This problem arises in the solution of sparse symmetric positive definite systems of linear equations by Gaussian elimination."
            },
            "slug": "Computing-the-Minimum-Fill-in-is-NP^Complete-Yannakakis",
            "title": {
                "fragments": [],
                "text": "Computing the Minimum Fill-in is NP^Complete"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "It is shown that the following problem is NP-complete: given a graph, find the minimum number of edges (fill-in) whose addition makes the graph chordal."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 185
                            }
                        ],
                        "text": "Current research concerning propagation in discrete probabilistic networks is concerned with studying and improving the efficiency of one or more variants of the propagation algorithms (Kj\u00e6rulff 1998; Shenoy 1997; Madsen and Jensen 1998), or exploiting cutset conditioning to trade time for space (Shachter et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 91
                            }
                        ],
                        "text": "There is also some efficiency to be gained by constructing junction trees of special types (Almond 1995; Shenoy 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14471299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46be16a191060f77baa794a52849a9a85e879475",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Binary-join-trees-for-computing-marginals-in-the-Shenoy",
            "title": {
                "fragments": [],
                "text": "Binary join trees for computing marginals in the Shenoy-Shafer architecture"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Approx. Reason."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144716964"
                        ],
                        "name": "J. Cocke",
                        "slug": "J.-Cocke",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cocke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16512130"
                        ],
                        "name": "J. Raviv",
                        "slug": "J.-Raviv",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Raviv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Raviv"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 195
                            }
                        ],
                        "text": "The much-used Viterbi algorithm for hidden Markov models (Viterbi 1967) is a special instance of max-propagation as described here; likewise, other decoding algorithms such as the BCJR algorithm (Bahl et al. 1974) are instances of propagation algorithms (see Frey (1998) for further details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1511,
                                "start": 196
                            }
                        ],
                        "text": "The much-used Viterbi algorithm for hidden Markov models (Viterbi 1967) is a special instance of max-propagation as described here; likewise, other decoding algorithms such as the BCJR algorithm (Bahl et al. 1974) are instances of propagation algorithms (see Frey (1998) for further details). Recent experiments show exceptional performance of so-called turbo-codes which are decoded by algorithms based on approximate probability propagation (McEliece et al. 1998). Algorithms for solving related propagation tasks go at least as far back as 1880 (see Section 7.11). Algorithms very close indeed to those described here were derived by Cannings et al. (1976, 1978) in the context of human genetic pedigrees. Pearl (1982), Kim and Pearl (1983), and Pearl (1986b, 1988) demonstrated the feasibility of local computation in probabilistic networks, inspiring further work by Shachter (1986), Shenoy and Shafer (1986), Lauritzen and Spiegelhalter (1988), and others, thereby paving the way for the exploitation of probability-based models as parts of realistic systems for planning and decision support. The technique was subsequently improved by Jensen et al. (1990b), utilizing the propagation of simple flows through the junction-tree, each such flow involving only two adjacent vertices and the associated edge, that is pairs of cliques joined by a separator. Dawid (1992a) described a generalization of this algorithm and showed how the basic idea can be extended to solve numerous other tasks. Dechter (1996) proposed a general algorithm, bucket elimination, which is closely related to propagation in the elimination tree."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 722,
                                "start": 196
                            }
                        ],
                        "text": "The much-used Viterbi algorithm for hidden Markov models (Viterbi 1967) is a special instance of max-propagation as described here; likewise, other decoding algorithms such as the BCJR algorithm (Bahl et al. 1974) are instances of propagation algorithms (see Frey (1998) for further details). Recent experiments show exceptional performance of so-called turbo-codes which are decoded by algorithms based on approximate probability propagation (McEliece et al. 1998). Algorithms for solving related propagation tasks go at least as far back as 1880 (see Section 7.11). Algorithms very close indeed to those described here were derived by Cannings et al. (1976, 1978) in the context of human genetic pedigrees. Pearl (1982), Kim and Pearl (1983), and Pearl (1986b, 1988) demonstrated the feasibility of local computation in probabilistic networks, inspiring further work by Shachter (1986), Shenoy and Shafer (1986), Lauritzen and Spiegelhalter (1988), and others, thereby paving the way for the exploitation of probability-based models as parts of realistic systems for planning and decision support."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1165,
                                "start": 196
                            }
                        ],
                        "text": "The much-used Viterbi algorithm for hidden Markov models (Viterbi 1967) is a special instance of max-propagation as described here; likewise, other decoding algorithms such as the BCJR algorithm (Bahl et al. 1974) are instances of propagation algorithms (see Frey (1998) for further details). Recent experiments show exceptional performance of so-called turbo-codes which are decoded by algorithms based on approximate probability propagation (McEliece et al. 1998). Algorithms for solving related propagation tasks go at least as far back as 1880 (see Section 7.11). Algorithms very close indeed to those described here were derived by Cannings et al. (1976, 1978) in the context of human genetic pedigrees. Pearl (1982), Kim and Pearl (1983), and Pearl (1986b, 1988) demonstrated the feasibility of local computation in probabilistic networks, inspiring further work by Shachter (1986), Shenoy and Shafer (1986), Lauritzen and Spiegelhalter (1988), and others, thereby paving the way for the exploitation of probability-based models as parts of realistic systems for planning and decision support. The technique was subsequently improved by Jensen et al. (1990b), utilizing the propagation of simple flows through the junction-tree, each such flow involving only two adjacent vertices and the associated edge, that is pairs of cliques joined by a separator."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1374,
                                "start": 196
                            }
                        ],
                        "text": "The much-used Viterbi algorithm for hidden Markov models (Viterbi 1967) is a special instance of max-propagation as described here; likewise, other decoding algorithms such as the BCJR algorithm (Bahl et al. 1974) are instances of propagation algorithms (see Frey (1998) for further details). Recent experiments show exceptional performance of so-called turbo-codes which are decoded by algorithms based on approximate probability propagation (McEliece et al. 1998). Algorithms for solving related propagation tasks go at least as far back as 1880 (see Section 7.11). Algorithms very close indeed to those described here were derived by Cannings et al. (1976, 1978) in the context of human genetic pedigrees. Pearl (1982), Kim and Pearl (1983), and Pearl (1986b, 1988) demonstrated the feasibility of local computation in probabilistic networks, inspiring further work by Shachter (1986), Shenoy and Shafer (1986), Lauritzen and Spiegelhalter (1988), and others, thereby paving the way for the exploitation of probability-based models as parts of realistic systems for planning and decision support. The technique was subsequently improved by Jensen et al. (1990b), utilizing the propagation of simple flows through the junction-tree, each such flow involving only two adjacent vertices and the associated edge, that is pairs of cliques joined by a separator. Dawid (1992a) described a generalization of this algorithm and showed how the basic idea can be extended to solve numerous other tasks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 28594190,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b51c6a5610be2c5648d1476b6f70e8037e0e8cb8",
            "isKey": true,
            "numCitedBy": 6485,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The general problem of estimating the a posteriori probabilities of the states and transitions of a Markov source observed through a discrete memoryless channel is considered. The decoding of linear block and convolutional codes to minimize symbol error probability is shown to be a special case of this problem. An optimal decoding algorithm is derived."
            },
            "slug": "Optimal-decoding-of-linear-codes-for-minimizing-Bahl-Cocke",
            "title": {
                "fragments": [],
                "text": "Optimal decoding of linear codes for minimizing symbol error rate (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The general problem of estimating the a posteriori probabilities of the states and transitions of a Markov source observed through a discrete memoryless channel is considered and an optimal decoding algorithm is derived."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144127885"
                        ],
                        "name": "J. Venn",
                        "slug": "J.-Venn",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Venn",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Venn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 86
                            }
                        ],
                        "text": "The most influential objective interpretation has been the frequentist interpretation (Venn 1866; von Mises 1939), in which probabilities of events are defined as limiting proportions in an infinite ensemble or sequence of experiments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121857214,
            "fieldsOfStudy": [
                "Physics",
                "Environmental Science",
                "Engineering"
            ],
            "id": "60226ab3c090ca7bb7092f0362da84d99ec9edf5",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A pressurized-water coolant nuclear reactor steam generator has a vertical housing for the steam generating water and containing an upstanding heat exchanger to which the pressurized-water coolant passes and which is radially surrounded by a guide jacket supporting a water separator on its top. By thermo - siphon action the steam generating water flows upward through and around the heat exchanger within the guide chamber to the latter's top from which it flows radially outwardly and downwardly through a down draft space formed between the outside of the jacket and the housing. The water separator discharges separated water downwardly. The housing has a feed water inlet opening adjacent to the lower portion of the heat exchanger, providing preheating of the introduced feed water. This preheated feed water is conveyed by a duct upwardly to a location where it mixes with the water discharged from the water separator."
            },
            "slug": "The-Logic-Of-Chance-Venn",
            "title": {
                "fragments": [],
                "text": "The Logic Of Chance"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A pressurized-water coolant nuclear reactor steam generator has a vertical housing for the steam generating water and containing an upstanding heat exchanger to which thePressurized- water coolant passes and which is radially surrounded by a guide jacket supporting a water separator on its top."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1888
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 96
                            }
                        ],
                        "text": "Hidden Markov models, which form the basis for work in such diverse areas as speech recognition (Rabiner and Juang 1993) and gene sequencing (Durbin et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7788300,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "df50c6e1903b1e2d657f78c28ab041756baca86a",
            "isKey": false,
            "numCitedBy": 8924,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Fundamentals of Speech Recognition. 2. The Speech Signal: Production, Perception, and Acoustic-Phonetic Characterization. 3. Signal Processing and Analysis Methods for Speech Recognition. 4. Pattern Comparison Techniques. 5. Speech Recognition System Design and Implementation Issues. 6. Theory and Implementation of Hidden Markov Models. 7. Speech Recognition Based on Connected Word Models. 8. Large Vocabulary Continuous Speech Recognition. 9. Task-Oriented Applications of Automatic Speech Recognition."
            },
            "slug": "Fundamentals-of-speech-recognition-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "Fundamentals of speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book presents a meta-modelling framework for speech recognition that automates the very labor-intensive and therefore time-heavy and therefore expensive and expensive process of manually modeling speech."
            },
            "venue": {
                "fragments": [],
                "text": "Prentice Hall signal processing series"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146720638"
                        ],
                        "name": "F. Krauss",
                        "slug": "F.-Krauss",
                        "structuredName": {
                            "firstName": "Flavia",
                            "lastName": "Krauss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Krauss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 32
                            }
                        ],
                        "text": "In models with latent structure (Lazarsfeld and Henry 1968) data are missing systematically."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118409087,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "89c1678393602fba0d3c1d62b97b1402922987c2",
            "isKey": false,
            "numCitedBy": 1038,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Die Latent Structure Analysis (LSA) von LAZARSFELD wird hier im wesentlichen fur den wichtigen Spezialfall der Latent Class Analysis (LCA) vorgestellt. Ziel der LSA ist es, nicht direkt zu beobachtende latente Variablen aufzufinden, die den Zusammenhang der manifesten Variablen erklaren. Von diesem Ansatz her besteht eine Parallele zur Faktorenanalyse. Speiziell die LCA kann jedoch auch als nicht metrische Clusteranalyse aufgefast werden."
            },
            "slug": "Latent-Structure-Analysis-Krauss",
            "title": {
                "fragments": [],
                "text": "Latent Structure Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1960,
                                "start": 27
                            }
                        ],
                        "text": "34) generally gives a very good approximation to the exact mixture distribution. It is also of interest to examine the effects of the approximations of retaining global, or local, independence between cases. Intuitively, retaining only global independence should be better, but the complexity of the required calculations then becomes much greater in general. This may be surprising in view of the remark at the end of Section 9.7.3, that more terms are generated overall when local independence is enforced. But one must now consider the complexity of the reduction process. The sequential reduction of Section 9.7.4 requires an ordering of terms, which has complexity O(n log n), followed by a set of n pairwise comparisons for each clustering of two terms, hence O(n2) pairwise comparisons in achieving the desired clustering. Hence, the updating process may be dominated by this mixture reduction phase which will have complexity O(n3 log n). However, the complexity will usually be much smaller if one retains local independence, because although the numbers of terms over all the parent configurations can be larger, each mixture that requires reduction will have a number of terms of the order of the number of states of the variable, instead of the number of configurations of the family. That is, instead of reducing one large mixture, one reduces a number of much smaller mixtures with, for each node v, a reduction in complexity given by a factor approximately equal to the square of the number of parent configurations of v. We now describe a simulation study of approximate mixture learning to compare the effects of retaining global independence only with those of insisting on local independence. We use the Asia network (see page 20), in which all parent-child conditional probability tables are regarded as unknown parameters. From a complete database of 100 cases, simulated using the probability values of Lauritzen and Spiegelhalter (1988), incomplete databases corresponding to 75 percent complete, 50 percent complete and 25 percent complete were generated by randomly altering the known state on each variable to unknown with probabilities of 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 34
                            }
                        ],
                        "text": "Usually the approximation will be good, resulting in significant savings in computational requirements. See Jensen and Andersen (1990) for further details and analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 667,
                                "start": 27
                            }
                        ],
                        "text": "The problem of obtaining a good triangulation is thus one of finding a good ordering, but the general problem of finding optimal triangulations for undirected graphs is NP-hard (Yannakakis 1981), so heuristic algorithms must be developed. Kj\u00e6rulff (1992) examined various algorithms for triangulating a nonchordal graph. For problems in which large cliques are unavoidable the method of simulated annealing performs well. Although using simulated annealing to find a triangulation of a graph may be time-consuming, for any given probabilistic network it only needs to be performed once, so it can be a worthwhile investment of time for some problems. Kj\u00e6rulff (1992) also looked at a number of heuristic algorithms that involve selecting the next node v on the basis of some optimality criterion c(v), for example, either maximizing or minimizing some cost or utility function which depends upon the node being selected."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 27
                            }
                        ],
                        "text": "The problem of obtaining a good triangulation is thus one of finding a good ordering, but the general problem of finding optimal triangulations for undirected graphs is NP-hard (Yannakakis 1981), so heuristic algorithms must be developed. Kj\u00e6rulff (1992) examined various algorithms for triangulating a nonchordal graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 122
                            }
                        ],
                        "text": "Examples of such so-called proper scoring rules include the quadratic Brier score (Brier 1950), and the logarithmic score (Good 1952)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 419,
                                "start": 153
                            }
                        ],
                        "text": "For models with discrete random variables, selecting c(vj) to be the cardinality of the joint state space for the variables in the set Cj usually yields good results. Another possibility, which does not depend upon the interpretation of the variables, is to take c(v) to be the number of fill-in edges required if v were to be selected for labelling. For other methods and comparisons between them, see Kj\u00e6rulff (1992). Although the maximum cardinality search algorithm is efficient for testing the chordality of a graph, as a numbering method for generating a chordal graph from a non-chordal graph it tends to introduce many more fill-in edges than are necessary, which in turn leads to larger than necessary cliques and reduces the efficiency of the algorithms for probabilistic computations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 972,
                                "start": 27
                            }
                        ],
                        "text": "The problem of obtaining a good triangulation is thus one of finding a good ordering, but the general problem of finding optimal triangulations for undirected graphs is NP-hard (Yannakakis 1981), so heuristic algorithms must be developed. Kj\u00e6rulff (1992) examined various algorithms for triangulating a nonchordal graph. For problems in which large cliques are unavoidable the method of simulated annealing performs well. Although using simulated annealing to find a triangulation of a graph may be time-consuming, for any given probabilistic network it only needs to be performed once, so it can be a worthwhile investment of time for some problems. Kj\u00e6rulff (1992) also looked at a number of heuristic algorithms that involve selecting the next node v on the basis of some optimality criterion c(v), for example, either maximizing or minimizing some cost or utility function which depends upon the node being selected. The basic algorithm is described by Olmsted (1983) and Kong (1986) and runs as follows for an undirected graph G with k vertices."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rational decisions"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Royal Statistical Society, Series B, 14, 107\u201314."
            },
            "year": 1952
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 32
                            }
                        ],
                        "text": "For discrete directed networks, Cooper and Herskovits (1992) applied the marginal likelihood criterion (11.3) to evaluate and compare different directed belief networks. This was extended by Heckerman et al. (1995b). Because they consider pure belief networks, with no attempt to interpret them as causal explanations, they require that any set of data should assign an identical score to two structurally different but Markov equivalent belief networks, having different directions on some of the arrows but implying identical conditional independence properties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1174,
                                "start": 36
                            }
                        ],
                        "text": "This has been used, for example, by Cooper and Herskovits (1992) in their reconstruction of the Alarm network, and in the Bifrost program (Lauritzen et al. 1994). Within the constraint-based framework, Spirtes et al. (1993) review a number of search algorithms for recovering an assumed causal structure underlying a joint distribution; for example, their pc algorithm first constructs a preliminary undirected graph, and then systematically attempts to remove edges based on conditional independence tests of increasing order, exploiting the global Markov property or, equivalently, d-separation. If a search strategy allows the addition of an edge, for directed graphs one must be careful that one does not create a directed cycle. This can be avoided by defining a prior ordering of the nodes, so that any edges added are always directed from, say, the first node to the second node with respect to the ordering. This is used in the k2 search heuristic of Cooper and Herskovits (1992), who survey a number of other approaches. For decomposable graphs one must be careful that adding or removing an edge does not destroy the decomposability of the graph. Lauritzen (1996) shows that if an edge belongs to only one clique of a decomposable graph G, then on removing that edge the resulting graph is also decomposable (see also Kj\u00e6rulff (1994))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 32
                            }
                        ],
                        "text": "For discrete directed networks, Cooper and Herskovits (1992) applied the marginal likelihood criterion (11."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 36
                            }
                        ],
                        "text": "This has been used, for example, by Cooper and Herskovits (1992) in their reconstruction of the Alarm network, and in the Bifrost program (Lauritzen et al. 1994). Within the constraint-based framework, Spirtes et al. (1993) review a number of search algorithms for recovering an assumed causal structure underlying a joint distribution; for example, their pc algorithm first constructs a preliminary undirected graph, and then systematically attempts to remove edges based on conditional independence tests of increasing order, exploiting the global Markov property or, equivalently, d-separation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 36
                            }
                        ],
                        "text": "This has been used, for example, by Cooper and Herskovits (1992) in their reconstruction of the Alarm network, and in the Bifrost program (Lauritzen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 988,
                                "start": 36
                            }
                        ],
                        "text": "This has been used, for example, by Cooper and Herskovits (1992) in their reconstruction of the Alarm network, and in the Bifrost program (Lauritzen et al. 1994). Within the constraint-based framework, Spirtes et al. (1993) review a number of search algorithms for recovering an assumed causal structure underlying a joint distribution; for example, their pc algorithm first constructs a preliminary undirected graph, and then systematically attempts to remove edges based on conditional independence tests of increasing order, exploiting the global Markov property or, equivalently, d-separation. If a search strategy allows the addition of an edge, for directed graphs one must be careful that one does not create a directed cycle. This can be avoided by defining a prior ordering of the nodes, so that any edges added are always directed from, say, the first node to the second node with respect to the ordering. This is used in the k2 search heuristic of Cooper and Herskovits (1992), who survey a number of other approaches."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 59
                            }
                        ],
                        "text": "It is this that makes the general decision problem NP-hard (Cooper 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The computational complexity of probabilistic inference using belief networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence, 42, 393\u2013405."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40692911"
                        ],
                        "name": "M. Bartlett",
                        "slug": "M.-Bartlett",
                        "structuredName": {
                            "firstName": "Maurice",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "Stevenson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bartlett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 358,
                                "start": 123
                            }
                        ],
                        "text": "Directed models can be traced back to the path analysis of Wright (1921, 1923, 1934), and undirected models to the work of Bartlett (1935) on interactions in contingency tables. The latter was taken up by Darroch et al. (1980) and has led to intensive investigation of graphical models in statistics, well summarized by Whittaker (1990) and Lauritzen (1996). The connections between undirected graphs and conditional independence were first made in the unpublished work of Hammersley and Clifford (1971)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 891,
                                "start": 123
                            }
                        ],
                        "text": "Directed models can be traced back to the path analysis of Wright (1921, 1923, 1934), and undirected models to the work of Bartlett (1935) on interactions in contingency tables. The latter was taken up by Darroch et al. (1980) and has led to intensive investigation of graphical models in statistics, well summarized by Whittaker (1990) and Lauritzen (1996). The connections between undirected graphs and conditional independence were first made in the unpublished work of Hammersley and Clifford (1971). Statistical use of directed graphs came into its own with the introduction of influence diagrams (Howard and Matheson 1984), but it was the application by Pearl (1986b) (see also Pearl (1988)) to probability calculations in graphical networks which initiated the recent explosion of interest in directed graphical representations. Their Markov properties were explored by Pearl (1986a) and Verma and Pearl (1990) using d-separation, while Lauritzen et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 123
                            }
                        ],
                        "text": "Directed models can be traced back to the path analysis of Wright (1921, 1923, 1934), and undirected models to the work of Bartlett (1935) on interactions in contingency tables. The latter was taken up by Darroch et al. (1980) and has led to intensive investigation of graphical models in statistics, well summarized by Whittaker (1990) and Lauritzen (1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 504,
                                "start": 123
                            }
                        ],
                        "text": "Directed models can be traced back to the path analysis of Wright (1921, 1923, 1934), and undirected models to the work of Bartlett (1935) on interactions in contingency tables. The latter was taken up by Darroch et al. (1980) and has led to intensive investigation of graphical models in statistics, well summarized by Whittaker (1990) and Lauritzen (1996). The connections between undirected graphs and conditional independence were first made in the unpublished work of Hammersley and Clifford (1971). Statistical use of directed graphs came into its own with the introduction of influence diagrams (Howard and Matheson 1984), but it was the application by Pearl (1986b) (see also Pearl (1988)) to probability calculations in graphical networks which initiated the recent explosion of interest in directed graphical representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 123
                            }
                        ],
                        "text": "Directed models can be traced back to the path analysis of Wright (1921, 1923, 1934), and undirected models to the work of Bartlett (1935) on interactions in contingency tables."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 968,
                                "start": 123
                            }
                        ],
                        "text": "Directed models can be traced back to the path analysis of Wright (1921, 1923, 1934), and undirected models to the work of Bartlett (1935) on interactions in contingency tables. The latter was taken up by Darroch et al. (1980) and has led to intensive investigation of graphical models in statistics, well summarized by Whittaker (1990) and Lauritzen (1996). The connections between undirected graphs and conditional independence were first made in the unpublished work of Hammersley and Clifford (1971). Statistical use of directed graphs came into its own with the introduction of influence diagrams (Howard and Matheson 1984), but it was the application by Pearl (1986b) (see also Pearl (1988)) to probability calculations in graphical networks which initiated the recent explosion of interest in directed graphical representations. Their Markov properties were explored by Pearl (1986a) and Verma and Pearl (1990) using d-separation, while Lauritzen et al. (1990) introduced the moralization criterion."
                    },
                    "intents": []
                }
            ],
            "corpusId": 125916605,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0bb36c65918aed31994c7715111220b8b28ef9ac",
            "isKey": true,
            "numCitedBy": 281,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Contingency-Table-Interactions-Bartlett",
            "title": {
                "fragments": [],
                "text": "Contingency Table Interactions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1935
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144209397"
                        ],
                        "name": "J. Bernardo",
                        "slug": "J.-Bernardo",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Bernardo",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bernardo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2107,
                                "start": 55
                            }
                        ],
                        "text": "Thus, the technique obeys the desiderata formulated by Bernardo and Gir\u00f3n (1988). It is even possible for the precision to decrease on obtaining evidence. This phenomenon occurs when an event that has a high estimated prior probability is contradicted by the available evidence, and this behaviour seems not unreasonable. While the need to contain the combinatorial explosion of the mixtures is urgent, one might nevertheless feel that collapsing a mixture down to a single term might be too extreme; in particular, multi-modality and skewness information can be lost. Hence, we might instead attempt to reduce the mixture to a smaller but still non-trivial mixture. A related problem is encountered in sequential analyses of multi-process models for time series (West and Harrison 1989), for which good approximations have been achieved by collapsing a mixture with a large number of terms down to a mixture with far fewer terms by merging \u2018similar\u2019 components (West 1992). This approach was examined in the current context by Cowell et al. (1995) using a simple test model consisting of a single node having three possible states, for which incomplete information on a case consists of a finding that one of the three states has not occurred. For this very simple model an exact analysis could be performed for a database of 200 randomly incomplete cases, and compared with various mixture approximation methods. A general sequential reduction procedure based on the clustering of West (1992) was employed as follows. Suppose a fixed limit of N is set for the number of terms allowed in a mixture, and that an exact update with an incomplete case results in a mixture with n > N terms. To reduce the number of terms, repeatedly: (i) identify the term with smallest weight, (ii) pair it with the \u2018closest\u2019 of the remaining terms, then (iii) combine this pair of terms into single term (adding the weights). This is repeated until only N terms remain in the mixture. Step (ii) requires some notion of a distance between two Dirichlet distributions. There is some arbitrariness in this; Cowell et al. (1995) used the simple squared Euclidean distance between the predictive means, \u2211 j(\u1fb11j\u2212 \u1fb12j)(2)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 61
                            }
                        ],
                        "text": "A good account of modern Bayesian statistics may be found in Bernardo and Smith (1994). In this book we mostly adopt both the subjectivist interpretation of probability and the subjectivist Bayesian approach to statistical inference."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 164
                            }
                        ],
                        "text": "It is (for multi-attribute variables) the only proper scoring rule whose value is determined solely by the probability attached to the outcome that actually occurs (Bernardo 1979), and for a multivariate outcome it is just the sum of the component logarithmic scores based on sequential observation of the individual variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1495,
                                "start": 55
                            }
                        ],
                        "text": "Thus, the technique obeys the desiderata formulated by Bernardo and Gir\u00f3n (1988). It is even possible for the precision to decrease on obtaining evidence. This phenomenon occurs when an event that has a high estimated prior probability is contradicted by the available evidence, and this behaviour seems not unreasonable. While the need to contain the combinatorial explosion of the mixtures is urgent, one might nevertheless feel that collapsing a mixture down to a single term might be too extreme; in particular, multi-modality and skewness information can be lost. Hence, we might instead attempt to reduce the mixture to a smaller but still non-trivial mixture. A related problem is encountered in sequential analyses of multi-process models for time series (West and Harrison 1989), for which good approximations have been achieved by collapsing a mixture with a large number of terms down to a mixture with far fewer terms by merging \u2018similar\u2019 components (West 1992). This approach was examined in the current context by Cowell et al. (1995) using a simple test model consisting of a single node having three possible states, for which incomplete information on a case consists of a finding that one of the three states has not occurred. For this very simple model an exact analysis could be performed for a database of 200 randomly incomplete cases, and compared with various mixture approximation methods. A general sequential reduction procedure based on the clustering of West (1992) was employed as follows."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 55
                            }
                        ],
                        "text": "Thus, the technique obeys the desiderata formulated by Bernardo and Gir\u00f3n (1988). It is even possible for the precision to decrease on obtaining evidence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 11
                            }
                        ],
                        "text": "(1985) and Bernardo and Gir\u00f3n (1988), in which a Dirichlet mixture is approximated by a single Dirichlet distribution D(\u03b1\u2217 1, ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1049,
                                "start": 55
                            }
                        ],
                        "text": "Thus, the technique obeys the desiderata formulated by Bernardo and Gir\u00f3n (1988). It is even possible for the precision to decrease on obtaining evidence. This phenomenon occurs when an event that has a high estimated prior probability is contradicted by the available evidence, and this behaviour seems not unreasonable. While the need to contain the combinatorial explosion of the mixtures is urgent, one might nevertheless feel that collapsing a mixture down to a single term might be too extreme; in particular, multi-modality and skewness information can be lost. Hence, we might instead attempt to reduce the mixture to a smaller but still non-trivial mixture. A related problem is encountered in sequential analyses of multi-process models for time series (West and Harrison 1989), for which good approximations have been achieved by collapsing a mixture with a large number of terms down to a mixture with far fewer terms by merging \u2018similar\u2019 components (West 1992). This approach was examined in the current context by Cowell et al. (1995) using a simple test model consisting of a single node having three possible states, for which incomplete information on a case consists of a finding that one of the three states has not occurred."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121507326,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "2ba5a1d91d3c13d42291d99bde3ca9b4bd576352",
            "isKey": true,
            "numCitedBy": 597,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Expected-Information-as-Expected-Utility-Bernardo",
            "title": {
                "fragments": [],
                "text": "Expected Information as Expected Utility"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48133796"
                        ],
                        "name": "R. T. Cox",
                        "slug": "R.-T.-Cox",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Cox",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. T. Cox"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 735,
                                "start": 13
                            }
                        ],
                        "text": "The paper of Dawid and Lauritzen (1993) is the standard reference to hyper Markov laws for undirected graphs. Giudici (1996) applied the hyper Markov ideas of Dawid and Lauritzen (1993) to structural learning for undirected Gaussian graphical models using inverse Wishart distributions to represent the prior (see also Chapter 11). Rubin (1976) introduced the term \u2018missing at random\u2019, and this paper is a standard reference on the treatment of missing data. A recent accessible treatment of the analysis of missing data from a Bayesian perspective can be found in Gelman et al. (1995). Maximum likelihood estimation is a standard technique treated in most statistics textbooks. The EM algorithm was promoted by Dempster et al. (1977) for finding maximum likelihood estimates involving missing data or incomplete information in some sense."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 13
                            }
                        ],
                        "text": "The paper of Dawid and Lauritzen (1993) is the standard reference to hyper Markov laws for undirected graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 345,
                                "start": 13
                            }
                        ],
                        "text": "The paper of Dawid and Lauritzen (1993) is the standard reference to hyper Markov laws for undirected graphs. Giudici (1996) applied the hyper Markov ideas of Dawid and Lauritzen (1993) to structural learning for undirected Gaussian graphical models using inverse Wishart distributions to represent the prior (see also Chapter 11). Rubin (1976) introduced the term \u2018missing at random\u2019, and this paper is a standard reference on the treatment of missing data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 13
                            }
                        ],
                        "text": "The paper of Dawid and Lauritzen (1993) is the standard reference to hyper Markov laws for undirected graphs. Giudici (1996) applied the hyper Markov ideas of Dawid and Lauritzen (1993) to structural learning for undirected Gaussian graphical models using inverse Wishart distributions to represent the prior (see also Chapter 11)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1008,
                                "start": 13
                            }
                        ],
                        "text": "The paper of Dawid and Lauritzen (1993) is the standard reference to hyper Markov laws for undirected graphs. Giudici (1996) applied the hyper Markov ideas of Dawid and Lauritzen (1993) to structural learning for undirected Gaussian graphical models using inverse Wishart distributions to represent the prior (see also Chapter 11). Rubin (1976) introduced the term \u2018missing at random\u2019, and this paper is a standard reference on the treatment of missing data. A recent accessible treatment of the analysis of missing data from a Bayesian perspective can be found in Gelman et al. (1995). Maximum likelihood estimation is a standard technique treated in most statistics textbooks. The EM algorithm was promoted by Dempster et al. (1977) for finding maximum likelihood estimates involving missing data or incomplete information in some sense. In models with latent structure (Lazarsfeld and Henry 1968) data are missing systematically. The algorithm was used in a special case of this by Dawid and Skene (1979). In connection with log-linear models for contingency tables, the algorithm was studied by Fuchs (1982) extending work of Chen and Fienberg (1974, 1976) and Hocking and Oxspring (1974)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 586,
                                "start": 13
                            }
                        ],
                        "text": "The paper of Dawid and Lauritzen (1993) is the standard reference to hyper Markov laws for undirected graphs. Giudici (1996) applied the hyper Markov ideas of Dawid and Lauritzen (1993) to structural learning for undirected Gaussian graphical models using inverse Wishart distributions to represent the prior (see also Chapter 11). Rubin (1976) introduced the term \u2018missing at random\u2019, and this paper is a standard reference on the treatment of missing data. A recent accessible treatment of the analysis of missing data from a Bayesian perspective can be found in Gelman et al. (1995). Maximum likelihood estimation is a standard technique treated in most statistics textbooks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120613997,
            "fieldsOfStudy": [
                "Physics",
                "Mathematics"
            ],
            "id": "636b6040f970c0a1857039de2b3ea49cd4ac2101",
            "isKey": true,
            "numCitedBy": 1272,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probability,-frequency-and-reasonable-expectation-Cox",
            "title": {
                "fragments": [],
                "text": "Probability, frequency and reasonable expectation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 419,
                                "start": 0
                            }
                        ],
                        "text": "Nilsson (1994) proposed an iterative divide-and-conquer algorithm for finding the top M most probable configurations in a probabilistic network, which exploits the use of multiple max-propagations, the fact that one can find the top three most probable configurations directly by inspection of clique potentials after a max-propagation, and the fact that one can also propagate likelihood vectors. Later Nilsson (1998) presented a more efficient version of the algorithm which avoids multiple max-propagations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 40
                            }
                        ],
                        "text": "Full proofs and details can be found in Nilsson (1998). Regarding implementation: at each stage one keeps a list of all configurations found and also a list of candidate evidence partitions with their max-normalization weights."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 855,
                                "start": 12
                            }
                        ],
                        "text": "However, as Nilsson (1998) shows, it is not necessary to perform full initializations and max-collect operations for these evidences. This is because of the way the residual sets have been ordered. Thus, for example, for evidence E1 j no new evidence over and above the initial evidence E has been entered in any clique having a label larger than j. Thus, all of these cliques and separators are initially in max-equilibrium, so if one were to perform a max-collect their contributions would cancel out in calculating the maxnormalization. Furthermore, for the cliques and separators having labels i smaller than j, the evidence is such that for each clique Ci and separator Si, only one configuration (which we denote by xCi and x \u2217 Si ) is allowed. Thus, the max-normalization constant for evidence E1 j has the simple form (Theorem 3 of Nilsson (1998)): \u220fj\u22121 i=0 p max Ci (xCi) \u220fj\u22121 i=0 p max Si (xSi) max pmax Cj (xCj & E 1 j )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Nilsson (1994) proposed an iterative divide-and-conquer algorithm for finding the top M most probable configurations in a probabilistic network, which exploits the use of multiple max-propagations, the fact that one can find the top three most probable configurations directly by inspection of clique potentials after a max-propagation, and the fact that one can also propagate likelihood vectors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 12
                            }
                        ],
                        "text": "However, as Nilsson (1998) shows, it is not necessary to perform full initializations and max-collect operations for these evidences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithm for finding the most probable configurations of discrete variables that are specified in probabilistic expert systems"
            },
            "venue": {
                "fragments": [],
                "text": "M. Sc. Thesis, Department of Mathematical Statistics, University of Copenhagen, Denmark."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Cowell (1997) showed that one can employ Nilsson\u2019s partitioning scheme, as described in Section 6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 26
                            }
                        ],
                        "text": "This approach was used in Cowell et al. (1993a). Finally, some conditional probability tables were adjusted in order to give the system reasonable behaviour when \u2018archetypal\u2019 cases were put through the system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 45
                            }
                        ],
                        "text": "For the proof that this algorithm works, see Cowell (1992). Evidence, if any, can be incorporated into the clique potentials \u03c6C(xC) at Stage 2, before the collection operation of Stage 4."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 49
                            }
                        ],
                        "text": "1 is adapted from one shown in Spiegelhalter and Cowell (1992), which was elicited using the technique of similarity graphs described by Heckerman (1990): the expert first identifies sets of diseases that typically present a diagnostic problem (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 50
                            }
                        ],
                        "text": "Essentially identical extensions were proposed by Cowell (1994) and, independently, by Jensen et al. (1994), the latter taking influence diagrams (Howard and Matheson 1984; Shachter 1986) as their starting point, though both approaches have much in common with the valuation network formulation advocated earlier by Shenoy (1992)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 330,
                                "start": 50
                            }
                        ],
                        "text": "Essentially identical extensions were proposed by Cowell (1994) and, independently, by Jensen et al. (1994), the latter taking influence diagrams (Howard and Matheson 1984; Shachter 1986) as their starting point, though both approaches have much in common with the valuation network formulation advocated earlier by Shenoy (1992). We shall describe a variation of the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 70
                            }
                        ],
                        "text": "Further details and proofs, together with conditions, may be found in Cowell and Dawid (1992). We describe how the basic propagation algorithm can be modified so as to calculate, simultaneously for every clique, the clique-density engendered by retraction of the evidence entered into that clique, under the assumption that the overall probability density p is strictly positive."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 24
                            }
                        ],
                        "text": "formulation proposed by Cowell (1994), where the concept of an influence diagram is extended to decision networks which encompass chain graph structures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 50
                            }
                        ],
                        "text": "Essentially identical extensions were proposed by Cowell (1994) and, independently, by Jensen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Calculating moments of decomposable functions in Bayesian networks"
            },
            "venue": {
                "fragments": [],
                "text": "Research Report 109, Department of Statistical Science, University College London, London, United Kingdom."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144717221"
                        ],
                        "name": "J. Acz\u00e9l",
                        "slug": "J.-Acz\u00e9l",
                        "structuredName": {
                            "firstName": "J\u00e1nos",
                            "lastName": "Acz\u00e9l",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Acz\u00e9l"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152940656"
                        ],
                        "name": "H. Oser",
                        "slug": "H.-Oser",
                        "structuredName": {
                            "firstName": "Hansj\u00f6rg",
                            "lastName": "Oser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Oser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 122
                            }
                        ],
                        "text": "Cox\u2019s paper required certain differentiability assumptions, but these have been relaxed to assumptions of continuity only (Acz\u00e9l 1966); more recently Aleliunas (1990) has produced a stronger result in a discrete setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 411,
                                "start": 123
                            }
                        ],
                        "text": "Cox\u2019s paper required certain differentiability assumptions, but these have been relaxed to assumptions of continuity only (Acz\u00e9l 1966); more recently Aleliunas (1990) has produced a stronger result in a discrete setting. Interestingly, the introduction of certainty factors into Mycin was just such an attempt to use numerical values to represent uncertainty, and, as mentioned in Section 2.4, Heckerman (1986) showed that for a consistent interpretation of the way that certainty factors combine there has to be a monotonic mapping of their values to ratios of conditional probabilities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120227903,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9aaa254ed4878bc1c1f1f95542ab196143c59a1b",
            "isKey": true,
            "numCitedBy": 2585,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lectures-on-Functional-Equations-and-Their-Acz\u00e9l-Oser",
            "title": {
                "fragments": [],
                "text": "Lectures on Functional Equations and Their Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46558286"
                        ],
                        "name": "S. K. Andersen",
                        "slug": "S.-K.-Andersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Kj\u00e6r"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1972776"
                        ],
                        "name": "S. Andreassen",
                        "slug": "S.-Andreassen",
                        "structuredName": {
                            "firstName": "Steen",
                            "lastName": "Andreassen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Andreassen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47643639"
                        ],
                        "name": "B. Falck",
                        "slug": "B.-Falck",
                        "structuredName": {
                            "firstName": "Bj\u00f6rn",
                            "lastName": "Falck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Falck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51420357"
                        ],
                        "name": "Uffe Kjaerulff",
                        "slug": "Uffe-Kjaerulff",
                        "structuredName": {
                            "firstName": "Uffe",
                            "lastName": "Kjaerulff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uffe Kjaerulff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3692291"
                        ],
                        "name": "A. Rosenfalck",
                        "slug": "A.-Rosenfalck",
                        "structuredName": {
                            "firstName": "Annelise",
                            "lastName": "Rosenfalck",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfalck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2027362130"
                        ],
                        "name": "A. R. S\u00f8rensen",
                        "slug": "A.-R.-S\u00f8rensen",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "S\u00f8rensen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. R. S\u00f8rensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2209769"
                        ],
                        "name": "M. Woldbye",
                        "slug": "M.-Woldbye",
                        "structuredName": {
                            "firstName": "Marianne",
                            "lastName": "Woldbye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Woldbye"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1166,
                                "start": 19
                            }
                        ],
                        "text": "The Munin network (Andreassen et al. 1989), representing some of the muscles and nerves necessary for interpreting electromyographic data, had over 1,000 vertices each with up to 21 states, whose structuring was simplified by the repetition of similar subgraphs. This idea has been formalized in Koller and Pfeffer (1997). The Pathfinder system for the diagnosis of lymph vertex pathology concerned over 60 diseases and required the specification of over 75,000 subjective probabilities (Heckerman et al. 1991). This has been converted to a commercial system, Intellipath. More recent applications have involved a range of structuring issues. For example, temporal networks and tracking problems require an evolving but repetitive structure (Kj\u00e6rulff 1995; Nicholson and Brady 1994). Neural networks have been reconstructed as probabilistic networks (Neal 1996; Frey 1998), which again produce shallow but densely connected graphs. A major application area has been troubleshooting and diagnostics, with the Decision Theory and Adaptive Systems Group at Microsoft Research taking a leading role. The background for this work is discussed in Heckerman et al. (1995a), and a number of applications have been implemented in Microsoft software."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 18
                            }
                        ],
                        "text": "The Munin network (Andreassen et al. 1989), representing some of the muscles and nerves necessary for interpreting electromyographic data, had over 1,000 vertices each with up to 21 states, whose structuring was simplified by the repetition of similar subgraphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 322,
                                "start": 19
                            }
                        ],
                        "text": "The Munin network (Andreassen et al. 1989), representing some of the muscles and nerves necessary for interpreting electromyographic data, had over 1,000 vertices each with up to 21 states, whose structuring was simplified by the repetition of similar subgraphs. This idea has been formalized in Koller and Pfeffer (1997). The Pathfinder system for the diagnosis of lymph vertex pathology concerned over 60 diseases and required the specification of over 75,000 subjective probabilities (Heckerman et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 67705172,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c16bd47dbe5e633e6c75ebce937a36ef3694d87b",
            "isKey": true,
            "numCitedBy": 149,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "MUNIN:-an-expert-EMG-assistant-Andersen-Andreassen",
            "title": {
                "fragments": [],
                "text": "MUNIN: an expert EMG assistant"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8500383"
                        ],
                        "name": "W. Hays",
                        "slug": "W.-Hays",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Hays",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hays"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 142
                            }
                        ],
                        "text": "Because of this possible data-dependence of Em and Vm, the standardization can be regarded as performed in the prequential frame of reference (Dawid 1984)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 139
                            }
                        ],
                        "text": "A scoring rule is a procedure for evaluating the quality of a probability statement about an event or variable in the light of its outcome (Dawid 1984)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 177
                            }
                        ],
                        "text": "An alternative approach avoiding this problem, which is equally applicable when the cases are not modelled as independent and identically distributed, is prequential validation (Dawid 1984), where the estimate \u03b8\u0302 m is based on the data for just the first i \u2212 1 observations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6902356,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "0b068a4b05b6cfaf4c412e112bf7d60ab7a1ef1e",
            "isKey": true,
            "numCitedBy": 325,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-theory.-Hays",
            "title": {
                "fragments": [],
                "text": "Statistical theory."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of psychology"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726406"
                        ],
                        "name": "G. Cooper",
                        "slug": "G.-Cooper",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Cooper",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49397975"
                        ],
                        "name": "E. Herskovits",
                        "slug": "E.-Herskovits",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Herskovits",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Herskovits"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 39
                            }
                        ],
                        "text": "14)) for each parent-child combination (Cooper and Herskovits 1992; Heckerman et al. 1995b)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 57701457,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1beba69cdaedd78a8a02b080bdd4f0183590c98e",
            "isKey": false,
            "numCitedBy": 1348,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a Bayesian method for constructing probabilistic networks from databases. In particular, we focus on constructing Bayesian belief networks. Potential applications include computer-assisted hypothesis testing, automated scientific discovery, and automated construction of probabilistic expert systems. We extend the basic method to handle missing data and hidden (latent) variables. We show how to perform probabilistic inference by averaging over the inferences of multiple belief networks. Results are presented of a preliminary evaluation of an algorithm for constructing a belief network from a database of cases. Finally, we relate the methods in this paper to previous work, and we discuss open problems."
            },
            "slug": "A-Bayesian-Method-for-the-Induction-of-Networks-Cooper-Herskovits",
            "title": {
                "fragments": [],
                "text": "A Bayesian Method for the Induction of Probabilistic Networks from Data"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper presents a Bayesian method for constructing probabilistic networks from databases, focusing on constructing Bayesian belief networks, and extends the basic method to handle missing data and hidden variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109683373"
                        ],
                        "name": "Jim Q. Smith",
                        "slug": "Jim-Q.-Smith",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Smith",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Q. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125839422,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dbce37fd4a98f5d999c39002e30cadf5814c7860",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Generalization-of-the-Bayesian-Steady-Forecasting-Smith",
            "title": {
                "fragments": [],
                "text": "A Generalization of the Bayesian Steady Forecasting Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145671626"
                        ],
                        "name": "S. Pearce",
                        "slug": "S.-Pearce",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Pearce",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pearce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3058012"
                        ],
                        "name": "C. Glymour",
                        "slug": "C.-Glymour",
                        "structuredName": {
                            "firstName": "Clark",
                            "lastName": "Glymour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Glymour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2758080"
                        ],
                        "name": "R. Scheines",
                        "slug": "R.-Scheines",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Scheines",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Scheines"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143648560"
                        ],
                        "name": "P. Spirtes",
                        "slug": "P.-Spirtes",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Spirtes",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Spirtes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11486538"
                        ],
                        "name": "Kevin T. Kelly",
                        "slug": "Kevin-T.-Kelly",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Kelly",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin T. Kelly"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 100
                            }
                        ],
                        "text": "This approach underlies much of the work in discovering causal structure developed by, for example, Glymour et al. (1987) and Pearl (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 50
                            }
                        ],
                        "text": "In a causal modelling setting, the Tetrad program (Glymour et al. 1987) infers the existence of hidden variables that can explain observed relationships."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 126261084,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "5925604a2e195222a70fdd0dbbf3c2e094af1a8d",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Discovering-Causal-Structure.-Pearce-Glymour",
            "title": {
                "fragments": [],
                "text": "Discovering Causal Structure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187514"
                        ],
                        "name": "R. Durbin",
                        "slug": "R.-Durbin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Durbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Durbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708077"
                        ],
                        "name": "S. Eddy",
                        "slug": "S.-Eddy",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Eddy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Eddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197258"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145666307"
                        ],
                        "name": "G. Mitchison",
                        "slug": "G.-Mitchison",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Mitchison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mitchison"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "Hidden Markov models, which form the basis for work in such diverse areas as speech recognition (Rabiner and Juang 1993) and gene sequencing (Durbin et al. 1998), can likewise be considered as special cases of Bayesian networks (Smyth et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123739817,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d771e343711ccebe602cde596341b955da7b6d42",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Biological-sequence-analysis:-Background-on-Durbin-Eddy",
            "title": {
                "fragments": [],
                "text": "Biological sequence analysis: Background on probability"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102407518"
                        ],
                        "name": "R. V. Mises",
                        "slug": "R.-V.-Mises",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Mises",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. V. Mises"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123017545,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "d184e74dfbedefdea1d12b505de840acc38f21a8",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probability,-statistics-and-truth-Mises",
            "title": {
                "fragments": [],
                "text": "Probability, Statistics and Truth."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1939
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52052145"
                        ],
                        "name": "Van Nostrand",
                        "slug": "Van-Nostrand",
                        "structuredName": {
                            "firstName": "Van",
                            "lastName": "Nostrand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Van Nostrand"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 57
                            }
                        ],
                        "text": "The much-used Viterbi algorithm for hidden Markov models (Viterbi 1967) is a special instance of max-propagation as described here; likewise, other decoding algorithms such as the BCJR algorithm (Bahl et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 124355301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b5c1d0844714588cf59629cbbc8e5f2e01f4a15",
            "isKey": false,
            "numCitedBy": 1882,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Error-Bounds-for-Convolutional-Codes-and-an-Optimum-Nostrand",
            "title": {
                "fragments": [],
                "text": "Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 123127517,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ab32d9e0adf7bc2b3920ed6504617cea305cce54",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Prequential-data-analysis-Dawid",
            "title": {
                "fragments": [],
                "text": "Prequential data analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 123404339,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "29078de469ffadb3070c2851f0f7ba3b72d598c5",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Conditional-Independence-for-Statistical-Operations-Dawid",
            "title": {
                "fragments": [],
                "text": "Conditional Independence for Statistical Operations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102929231"
                        ],
                        "name": "H. Kellerer",
                        "slug": "H.-Kellerer",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Kellerer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kellerer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 38
                            }
                        ],
                        "text": "Such an approach has been examined by Kj\u00e6rulff (1994), who presents an approximation scheme for removing edges, providing local and overall bounds on the errors induced by edge removals, using the Kullback\u2013Leibler divergence(Kullback and Leibler 1951) to measure the effect of removing edges."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123002802,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2e55812a5de99932f949d7eb485886e2a39913b9",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Verteilungsfunktionen-mit-gegebenen-Kellerer",
            "title": {
                "fragments": [],
                "text": "Verteilungsfunktionen mit gegebenen Marginalverteilungen"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068277777"
                        ],
                        "name": "K. Wagner",
                        "slug": "K.-Wagner",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Wagner",
                            "middleNames": [
                                "Von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Wagner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 61
                            }
                        ],
                        "text": "1984; Diestel 1987, 1990), including the four-colour problem (Wagner 1937), measure theory (Kellerer 1964a, 1964b; Vorob\u2019ev 1962, 1963), the solution of systems of linear equations (Parter 1961; Rose 1970, 1973), game theory (Vorob\u2019ev 1967), and relational databases (Beeri et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123534907,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c7491269268189f3f5fed8638310738e56f09abe",
            "isKey": false,
            "numCitedBy": 703,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "\u00dcber-eine-Eigenschaft-der-ebenen-Komplexe-Wagner",
            "title": {
                "fragments": [],
                "text": "\u00dcber eine Eigenschaft der ebenen Komplexe"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1937
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3382525"
                        ],
                        "name": "D. Lindley",
                        "slug": "D.-Lindley",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Lindley",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lindley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 176
                            }
                        ],
                        "text": "The apparent discrepancy between this finding and the support for the hypothesis that the expert is correct under the relative approach is an illustration of Lindley\u2019s paradox (Lindley 1957), whereby a null hypothesis, even though not itself a particularly good explanation for the data in an absolute sense, can still be better than a profession of \u2018ignorance\u2019 over a wide range of possible parameter values."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 121246127,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "23cd72eb56680b74fb09f7d805703a0898045d98",
            "isKey": false,
            "numCitedBy": 924,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-STATISTICAL-PARADOX-Lindley",
            "title": {
                "fragments": [],
                "text": "A STATISTICAL PARADOX"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102929231"
                        ],
                        "name": "H. Kellerer",
                        "slug": "H.-Kellerer",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Kellerer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kellerer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121733438,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f3c34e2a344f5ccfaef1c78599764be30b8e925b",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Ma\u00dftheoretische-Marginalprobleme-Kellerer",
            "title": {
                "fragments": [],
                "text": "Ma\u00dftheoretische Marginalprobleme"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47106318"
                        ],
                        "name": "J. Neyman",
                        "slug": "J.-Neyman",
                        "structuredName": {
                            "firstName": "Jerzy",
                            "lastName": "Neyman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Neyman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28582490"
                        ],
                        "name": "E. S. Pearson",
                        "slug": "E.-S.-Pearson",
                        "structuredName": {
                            "firstName": "Egon",
                            "lastName": "Pearson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. S. Pearson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121992179,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e5e4f894cf34dc80e2302ae17b74593311d50ca",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Joint-Statistical-Papers-Neyman-Pearson",
            "title": {
                "fragments": [],
                "text": "Joint Statistical Papers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3184408"
                        ],
                        "name": "N. Wermuth",
                        "slug": "N.-Wermuth",
                        "structuredName": {
                            "firstName": "Nanny",
                            "lastName": "Wermuth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wermuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 127
                            }
                        ],
                        "text": "1991), multivariate normal models for continuous data (Wermuth 1976; Whittaker 1990), and mixed continuous and discrete models (Lauritzen and Wermuth 1989; Edwards 1990, 1995; Lauritzen 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121833680,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "082f19517c2039668715b04f7619d7e4b95f3e0c",
            "isKey": false,
            "numCitedBy": 733,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Graphical-Models-for-Associations-between-some-of-Lauritzen-Wermuth",
            "title": {
                "fragments": [],
                "text": "Graphical Models for Associations between Variables, some of which are Qualitative and some Quantitative"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48350707"
                        ],
                        "name": "G. Dirac",
                        "slug": "G.-Dirac",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Dirac",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Dirac"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 157
                            }
                        ],
                        "text": "Chordal graphs are well-studied objects which appear under a variety of names, including triangulated and decomposable graphs, and also rigid circuit graphs (Dirac 1961)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120608513,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e381867a2bccfe776c0384d38189cd98e69db931",
            "isKey": false,
            "numCitedBy": 877,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-rigid-circuit-graphs-Dirac",
            "title": {
                "fragments": [],
                "text": "On rigid circuit graphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102488892"
                        ],
                        "name": "Tar Chen",
                        "slug": "Tar-Chen",
                        "structuredName": {
                            "firstName": "Tar",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tar Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684961"
                        ],
                        "name": "S. Fienberg",
                        "slug": "S.-Fienberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Fienberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fienberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120495851,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a4eb10073a679a0a55cf88a7a9601dd204097801",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Two-Dimensional-Contingency-Tables-with-Both-and-Chen-Fienberg",
            "title": {
                "fragments": [],
                "text": "Two-Dimensional Contingency Tables with Both Completely and Partially Cross-Classified Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776322"
                        ],
                        "name": "J. Q. Smith",
                        "slug": "J.-Q.-Smith",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Smith",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Q. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 119775991,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b759b6c282c8720b6267db09b5cbd3e38b69e249",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Influence-Diagrams-for-Statistical-Modelling-Smith",
            "title": {
                "fragments": [],
                "text": "Influence Diagrams for Statistical Modelling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2748598"
                        ],
                        "name": "S. Kullback",
                        "slug": "S.-Kullback",
                        "structuredName": {
                            "firstName": "Solomon",
                            "lastName": "Kullback",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kullback"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102909471"
                        ],
                        "name": "R. A. Leibler",
                        "slug": "R.-A.-Leibler",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Leibler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. A. Leibler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "For this broader perspective, see, for example, Lauritzen (1996), Gilks et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 224
                            }
                        ],
                        "text": "Such an approach has been examined by Kj\u00e6rulff (1994), who presents an approximation scheme for removing edges, providing local and overall bounds on the errors induced by edge removals, using the Kullback\u2013Leibler divergence(Kullback and Leibler 1951) to measure the effect of removing edges."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120349231,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c054360ec3ccadae977fdd0d77694c9655478a41",
            "isKey": false,
            "numCitedBy": 10535,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-Information-and-Sufficiency-Kullback-Leibler",
            "title": {
                "fragments": [],
                "text": "On Information and Sufficiency"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145392702"
                        ],
                        "name": "P. Green",
                        "slug": "P.-Green",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Green",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Green"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 152
                            }
                        ],
                        "text": "Similarly, much of image analysis is dominated by Markov field models which are defined in terms of local dependencies and can be described graphically (Besag and Green 1993), although simulation methods are generally required for inference."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118809049,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ed06b87c995df02966ea5dad7fb73ecafb22e6c6",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spatial-statistics-and-Bayesian-computation-(with-Besag-Green",
            "title": {
                "fragments": [],
                "text": "Spatial statistics and Bayesian computation (with discussion)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2746221"
                        ],
                        "name": "S. A. Andersson",
                        "slug": "S.-A.-Andersson",
                        "structuredName": {
                            "firstName": "Steen",
                            "lastName": "Andersson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Andersson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710305"
                        ],
                        "name": "D. Madigan",
                        "slug": "D.-Madigan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Madigan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Madigan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2830733"
                        ],
                        "name": "M. Perlman",
                        "slug": "M.-Perlman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Perlman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Perlman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10726446"
                        ],
                        "name": "T. Richardson",
                        "slug": "T.-Richardson",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Richardson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Richardson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118870382,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3cad6838063452921b588e12a7e2e1f9bbc424e7",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Graphical-Markov-models-in-mul-tivariate-analysis-Andersson-Madigan",
            "title": {
                "fragments": [],
                "text": "Graphical Markov models in mul-tivariate analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145409928"
                        ],
                        "name": "J. Hammersley",
                        "slug": "J.-Hammersley",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hammersley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hammersley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145578421"
                        ],
                        "name": "P. Clifford",
                        "slug": "P.-Clifford",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Clifford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Clifford"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118635048,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ec75e3ca906681bd900218a348a4a35dfed3d6fd",
            "isKey": false,
            "numCitedBy": 946,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-fields-on-finite-graphs-and-lattices-Hammersley-Clifford",
            "title": {
                "fragments": [],
                "text": "Markov fields on finite graphs and lattices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15974963"
                        ],
                        "name": "A. F. Smith",
                        "slug": "A.-F.-Smith",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. F. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580190"
                        ],
                        "name": "U. Makov",
                        "slug": "U.-Makov",
                        "structuredName": {
                            "firstName": "Udi",
                            "lastName": "Makov",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Makov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 167
                            }
                        ],
                        "text": "Techniques include the \u2018probabilistic teacher\u2019, in which the missing variables are randomly fixed according to their current posterior distribution, and \u2018quasi-Bayes\u2019 (Smith and Makov 1978) or \u2018fractional updating\u2019 (Titterington 1976)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Spiegelhalter et al. (1994) relate this to the proposal of Box (1980) for comparing prior with data."
                    },
                    "intents": []
                }
            ],
            "corpusId": 116135487,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7dfd4dfb19d9d2df213a57970072867d997a215e",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Quasi\u2010Bayes-Sequential-Procedure-for-Mixtures-Smith-Makov",
            "title": {
                "fragments": [],
                "text": "A Quasi\u2010Bayes Sequential Procedure for Mixtures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 115903686,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7c0ab0348620413211135f9cdf1f855809597131",
            "isKey": false,
            "numCitedBy": 1388,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Conditional-Independence-in-Statistical-Theory-Dawid",
            "title": {
                "fragments": [],
                "text": "Conditional Independence in Statistical Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14942773"
                        ],
                        "name": "M. Stone",
                        "slug": "M.-Stone",
                        "structuredName": {
                            "firstName": "Mervyn",
                            "lastName": "Stone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "A popular approach for the random sampling case is cross-validation (Stone 1974), which, in its simplest form, takes as \u03b8\u0302 m the maximum likelihood estimate based on all observations excluding the ith."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 23
                            }
                        ],
                        "text": "However, the inherent asymmetry between discrete and continuous variables in the CG distributions implies that one also needs to take proper account of the behaviour of the markings of the graph. We refer the interested reader to Leimer (1989) or Lauritzen (1996) for a detailed graph-theoretic study of the problems, as well as all proofs."
                    },
                    "intents": []
                }
            ],
            "corpusId": 116210394,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c61149de2d5aca78932729a16c657f811edc63b5",
            "isKey": false,
            "numCitedBy": 828,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cross\u2010Validatory-Choice-and-Assessment-of-(With-Stone",
            "title": {
                "fragments": [],
                "text": "Cross\u2010Validatory Choice and Assessment of Statistical Predictions (With Discussion)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 108494397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a76158a32f842f40e1dade2d933aec6fbaecb59",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sampling-without-replacement-in-junction-trees-Cowell",
            "title": {
                "fragments": [],
                "text": "Sampling without replacement in junction trees"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37754903"
                        ],
                        "name": "T. Hutchinson",
                        "slug": "T.-Hutchinson",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Hutchinson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hutchinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40494915"
                        ],
                        "name": "S. Roden",
                        "slug": "S.-Roden",
                        "structuredName": {
                            "firstName": "Sue",
                            "lastName": "Roden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Cox and Wermuth (1996) allow their graph edges to be dashed as well as solid lines and arrows, introducing an appropriately modified semantics to relate the graph structure to marginal and conditional independence properties of Gaussian distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63283129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba6e7e5d4f2c59c144d3315ac0c51ab89d93c920",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bayesian-networks-for-the-analysis-of-drug-safety-Cowell-Dawid",
            "title": {
                "fragments": [],
                "text": "Bayesian networks for the analysis of drug safety"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103862143"
                        ],
                        "name": "G. Jason",
                        "slug": "G.-Jason",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Jason",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jason"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 27
                            }
                        ],
                        "text": "Popper\u2019s propensity theory (Popper 1959), for example, in which probability measures an innate disposition of an event to occur in identified circumstances, is one such objective theory."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60275120,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "21ac70b681c534cd6e7cd2a5155a0789828451f7",
            "isKey": false,
            "numCitedBy": 7789,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Logic-of-Scientific-Discovery-Jason",
            "title": {
                "fragments": [],
                "text": "The Logic of Scientific Discovery"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820860"
                        ],
                        "name": "R. Neapolitan",
                        "slug": "R.-Neapolitan",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Neapolitan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Neapolitan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59866093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc8b13639c55b4d66693ff3ba3d7dad6548d8216",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-reasoning-in-expert-systems-Neapolitan",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144395291"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Dudley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 101
                            }
                        ],
                        "text": "For tree-like Bayesian networks, Sy (1993) developed a computation scheme based upon an algorithm by Pearl (1988) for finding the most probable configuration in such networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 101
                            }
                        ],
                        "text": "For tree-like Bayesian networks, Sy (1993) developed a computation scheme based upon an algorithm by Pearl (1988) for finding the most probable configuration in such networks. For more general networks, Seroussi and Golmard (1992) proposed a search method based on a bottom-up search of the junction tree, storing at each stage the M most probable configurations of the subtree examined."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59635642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88eb717d0799aeda1a8dcdcee397445d6a86601c",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Influence-Diagrams,-Belief-Nets-and-Decision-Dudley",
            "title": {
                "fragments": [],
                "text": "Influence Diagrams, Belief Nets and Decision Analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68984513"
                        ],
                        "name": "Scott M. Olmsted",
                        "slug": "Scott-M.-Olmsted",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Olmsted",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott M. Olmsted"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 155
                            }
                        ],
                        "text": "Originally developed as a structuring tool, the development of algorithms for their evaluation (using barren node elimination and arc-reversal) came later (Olmsted 1983; Shachter 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59682188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "365d4a85981f5b9d1bd297baa6e9f5b139f304bb",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-representing-and-solving-decision-problems-Olmsted",
            "title": {
                "fragments": [],
                "text": "On representing and solving decision problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 56
                            }
                        ],
                        "text": "We say that the model exhibits global meta independence (Dawid and Lauritzen 1993) if there are no logical constraints linking the (\u03b8 : v \u2208 V ); and local meta independence if, further, this property extends to the collection of all the (\u03b8 : v \u2208 V, \u03c1 a configuration of Xpa(v))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121850609,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a79313b40c75124d20ba645516823e332303e3c2",
            "isKey": false,
            "numCitedBy": 530,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hyper-Markov-Laws-in-the-Statistical-Analysis-of-Dawid-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Hyper Markov Laws in the Statistical Analysis of Decomposable Graphical Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34760449"
                        ],
                        "name": "K. Olesen",
                        "slug": "K.-Olesen",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Olesen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Olesen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53880385,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb75e5a3b46ec37a72922c706acd87ebab35b666",
            "isKey": false,
            "numCitedBy": 763,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bayesian-updating-in-causal-probabilistic-networks-Jensen-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Bayesian updating in causal probabilistic networks by local computations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7544534"
                        ],
                        "name": "H. Jeffreys",
                        "slug": "H.-Jeffreys",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Jeffreys",
                            "middleNames": [
                                "Sir"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Jeffreys"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 62
                            }
                        ],
                        "text": "Epistemological theories further divide into logical theories (Keynes 1921; Jeffreys 1939; Carnap 1950) and subjectivist theories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 440888,
            "fieldsOfStudy": [],
            "id": "ae3abde9f9df2cddd6d9c896e91a93fca5034480",
            "isKey": false,
            "numCitedBy": 1159,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Treatise-on-Probability-Jeffreys",
            "title": {
                "fragments": [],
                "text": "A Treatise on Probability"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1922
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123729051"
                        ],
                        "name": "L. M. M.-T.",
                        "slug": "L.-M.-M.-T.",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "M.-T.",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. M. M.-T."
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 3
                            }
                        ],
                        "text": "5 (Jensen et al. 1994). Nodes d1 to d4 are the decision nodes, u1 to u4 the additive components of the utility, and the remaining nodes the random variables. Using the elimination sequence deployed by Jensen et al. (1994) results in the elimination tree of Figure 8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 62
                            }
                        ],
                        "text": "Epistemological theories further divide into logical theories (Keynes 1921; Jeffreys 1939; Carnap 1950) and subjectivist theories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4036480,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f1f4386524be3ed96caaf05f661aacb94db1e566",
            "isKey": false,
            "numCitedBy": 5289,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theory-of-Probability-M.-T.",
            "title": {
                "fragments": [],
                "text": "Theory of Probability"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1929
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3350254"
                        ],
                        "name": "K. A. Andersen",
                        "slug": "K.-A.-Andersen",
                        "structuredName": {
                            "firstName": "Kim",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Allan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. A. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31305070"
                        ],
                        "name": "J. Hooker",
                        "slug": "J.-Hooker",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hooker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hooker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 281,
                                "start": 255
                            }
                        ],
                        "text": "There has also been research into incomplete specification of the full joint distribution, using say upper and lower probabilities (Walley 1990), in which resulting intervals of probabilities may be computed using linear (van der Gaag 1991) or non-linear (Andersen and Hooker 1994) programming techniques."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37675002,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "964ae4780e41a1febcbe01ab8c75abfaa3e48d11",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bayesian-logic-Andersen-Hooker",
            "title": {
                "fragments": [],
                "text": "Bayesian logic"
            },
            "venue": {
                "fragments": [],
                "text": "Decis. Support Syst."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750484"
                        ],
                        "name": "F. Harary",
                        "slug": "F.-Harary",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Harary",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Harary"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 149
                            }
                        ],
                        "text": "Issues of equivalence of seemingly distinct representations need careful attention when attempting statistical model selection on the basis of data (Heckerman et al. 1995b). Extending a result of Verma and Pearl (1991) for directed acyclic graphs, Frydenberg (1990) showed that two chain graphs are Markov equivalent if and only if they have the same skeleton (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 552300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ee0abcb8f0afd74d602255d529d7c2a036a8f02",
            "isKey": false,
            "numCitedBy": 15406,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Graph-theory-Harary",
            "title": {
                "fragments": [],
                "text": "Graph theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1381840545"
                        ],
                        "name": "H. Brachinger",
                        "slug": "H.-Brachinger",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Brachinger",
                            "middleNames": [
                                "Wolfgang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Brachinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13727836"
                        ],
                        "name": "P. Monney",
                        "slug": "P.-Monney",
                        "structuredName": {
                            "firstName": "Paul-Andr\u00e9",
                            "lastName": "Monney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Monney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 49
                            }
                        ],
                        "text": "We present a small example of a problem posed by Raiffa (1968) in the variation given by Shenoy (1992), which we shall refer to as Oil wildcatter."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 98
                            }
                        ],
                        "text": "3) by working backwards; detailed proofs and justification of the solution method can be found in Raiffa and Schlaifer (1961). Finding the decision mapping for each decision variable is done in two steps, first by forming an expectation and then by maximizing the result."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 642562,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "1822db1975db13bf46ca9944dc77663cbc1744be",
            "isKey": false,
            "numCitedBy": 1028,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Decision-analysis.-Brachinger-Monney",
            "title": {
                "fragments": [],
                "text": "Decision analysis."
            },
            "venue": {
                "fragments": [],
                "text": "The New England journal of medicine"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144101487"
                        ],
                        "name": "C. Berge",
                        "slug": "C.-Berge",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Berge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Berge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 26
                            }
                        ],
                        "text": "The result is well-known (Berge 1973; Golumbic 1980). The present proof is taken from Lauritzen (1996). We proceed by induction on the number of vertices |V | of G."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118551464,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f56c5c67c4382335fc486af02af19d7c985a356f",
            "isKey": false,
            "numCitedBy": 2459,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Graphs-and-hypergraphs-Berge",
            "title": {
                "fragments": [],
                "text": "Graphs and hypergraphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144833497"
                        ],
                        "name": "Peter J.F. Lucas",
                        "slug": "Peter-J.F.-Lucas",
                        "structuredName": {
                            "firstName": "Peter J.F.",
                            "lastName": "Lucas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter J.F. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104248723"
                        ],
                        "name": "L. C. Gaag",
                        "slug": "L.-C.-Gaag",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Gaag",
                            "middleNames": [
                                "C.",
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. C. Gaag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 24277152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69d286ca17ed988339a418ebdb6b61360e23deac",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Principles-of-expert-systems-Lucas-Gaag",
            "title": {
                "fragments": [],
                "text": "Principles of expert systems"
            },
            "venue": {
                "fragments": [],
                "text": "International computer science series"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40318103"
                        ],
                        "name": "G. Brier",
                        "slug": "G.-Brier",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Brier",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Brier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 82
                            }
                        ],
                        "text": "Examples of such so-called proper scoring rules include the quadratic Brier score (Brier 1950), and the logarithmic score (Good 1952)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122906757,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "feee6551179612b9691f021b583d8a99b81b9b86",
            "isKey": false,
            "numCitedBy": 3921,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "VERIFICATION-OF-FORECASTS-EXPRESSED-IN-TERMS-OF-Brier",
            "title": {
                "fragments": [],
                "text": "VERIFICATION OF FORECASTS EXPRESSED IN TERMS OF PROBABILITY"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 59
                            }
                        ],
                        "text": "The following are examples of production rules (taken from Winston (1984))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Artificial Intelligence, (2 edn)"
            },
            "venue": {
                "fragments": [],
                "text": "Addison\u2013Wesley, Reading, Massachusetts."
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 95
                            }
                        ],
                        "text": "It includes other algorithms for checking decomposability of a graph and finding their cliques (Rose et al. 1976; Gavril 1972), for constructing optimal junction trees for given decomposable graphs (Jensen and Jensen 1994), and for constructing optimal decompositions of a non-chordal graph into its indecomposable components (Tarjan 1985; Leimer 1993)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithms for minimum coloring, maximum clique, minimum coloring by cliques and maximum independent set of a graph"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM Journal on Computing, 1, 180\u20137."
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Graphoids: A graph based logic for reasoning about relevancy relations"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Artificial Intelligence \u2013 II, (ed. B. D. Boulay, D. Hogg, and L. Steel), pp. 357\u201363. North-Holland, Amsterdam, The Netherlands."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An efficient algorithm for finding the M most probable configurations in a probabilistic expert system"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics and Computing, 8, 159\u201373."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning in probabilistic expert systems"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian Statistics 4, (ed. J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith), pp. 447\u201365. Clarendon Press, Oxford, United Kingdom."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 306,
                                "start": 295
                            }
                        ],
                        "text": "A related problem is encountered in sequential analyses of multi-process models for time series (West and Harrison 1989), for which good approximations have been achieved by collapsing a mixture with a large number of terms down to a mixture with far fewer terms by merging \u2018similar\u2019 components (West 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modelling with mixtures"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian Statistics 4, (ed. J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith), pp. 503\u2013524 (with discussion). Clarendon Press, Oxford, United Kingdom."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 257
                            }
                        ],
                        "text": "within theoretical statistics include: sufficiency and ancillarity; nuisance parameters (Dawid 1980a); Simpson\u2019s paradox; optional stopping, selection and missing data effects (Dawid 1976; Dawid and Dickey 1977); invariance (Dawid 1985); and model-building (Dawid 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Intersubjective statistical models"
            },
            "venue": {
                "fragments": [],
                "text": "Exchangeability in Probability and Statistics, (ed. G. Koch and F. Spizzichino), pp. 217\u2013"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 257
                            }
                        ],
                        "text": "within theoretical statistics include: sufficiency and ancillarity; nuisance parameters (Dawid 1980a); Simpson\u2019s paradox; optional stopping, selection and missing data effects (Dawid 1976; Dawid and Dickey 1977); invariance (Dawid 1985); and model-building (Dawid 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Intersubjective statistical models"
            },
            "venue": {
                "fragments": [],
                "text": "Exchangeability in Probability and Statistics, (ed. G. Koch and F. Spizzichino), pp. 217\u2013"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 82
                            }
                        ],
                        "text": "The Minimum Description Length (MDL) principle or Stochastic Complexity criterion (Rissanen 1987) has also been suggested as a model scoring device (Lam and Bacchus 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 19
                            }
                        ],
                        "text": "Exceptions include Riva and Bellazzi (1996), who use scoring metrics to compare pre-specified models for medical monitoring applications using one-step-ahead predictions, and Lam (1998), who uses a Minimum Description Length approach to refine a network on the basis of new data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic complexity"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Royal Statistical Society, Series B, 49, 223\u201339."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 20
                            }
                        ],
                        "text": "The programs DiGram (Kreiner 1989) and Bifrost (H\u00f8jsgaard and Thiesson 1995) select chain graph models based upon maximized likelihood."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User\u2019s guide to DiGram \u2014 a program for discrete graphical modelling"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report 89\u201310, Statistical Research Unit, University of Copenhagen."
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 215
                            }
                        ],
                        "text": "The appropriate way of dealing with the many sources of uncertainty in such problems has long been a matter of dispute, but since the late 1980s, particularly following the publication of Judea Pearl\u2019s classic text (Pearl 1988), a fully probabilistic approach has steadily gained acceptance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic Inference in Intelligent Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann, San Mateo, California."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recursive derivation of likelihoods on pedigrees of arbitrary complexity"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Applied Probability, 8, 622\u20135."
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 200
                            }
                        ],
                        "text": "Shachter and Kenley (1989) introduced Gaussian influence diagrams to model networks of Gaussian random variables for decision problems and they were later extended to the mixed-discrete Gaussian case (Poland 1994); see also the next chapter."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Decision Analysis with Continuous and Discrete Variables: A Mixture Distribution Approach"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. Thesis, Department of Engineering\u2013Economic Systems, Stanford University, Stanford, California."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 49
                            }
                        ],
                        "text": "This method generalizes the Baum\u2013Welch algorithm (Baum 1972), which was introduced for the special case of hidden Markov models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An equality and associated maximization technique in statistical estimation for probabilistic functions of Markov processes"
            },
            "venue": {
                "fragments": [],
                "text": "Inequalities, 3, 1\u20138."
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Irrelevance and parameter learning in Bayesian networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence, 88, 359\u201373."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 138
                            }
                        ],
                        "text": "This has been used, for example, by Cooper and Herskovits (1992) in their reconstruction of the Alarm network, and in the Bifrost program (Lauritzen et al. 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Diagnostic systems created by model selection methods: A case study"
            },
            "venue": {
                "fragments": [],
                "text": "Selecting Models from Data: AI and Statistics IV, (ed. P. Cheeseman and R. Oldford), pp. 143\u201352. Springer\u2013Verlag, New York. Lecture Notes in Statistics 89."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning in graphical Gaussian models"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian Statistics 5, (ed. J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith), pp. 621\u20138. Clarendon Press, Oxford, United Kingdom."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 156
                            }
                        ],
                        "text": "This assumption can be relaxed, but then we have to use approximate methods in the specification phase, see Lauritzen (1992) for some suggestions; and also Gammerman et al. (1995). Thus, we specify, for each discrete variable A, the conditional distribution at A given the states at its parent vertices (which are then all discrete)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 17
                            }
                        ],
                        "text": "The PRESS system (Gammerman et al. 1995) incorporates options for both local propagation and Gibbs sampling for mixed discrete-Gaussian models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exact and approximate algorithms and their implementations in mixed graphical models"
            },
            "venue": {
                "fragments": [],
                "text": "Probabilistic Reasoning and Bayesian Belief Networks, (ed. A. Gammerman), pp. 33\u201353. Alfred Walker, Henley-onThames, United Kingdom."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 68
                            }
                        ],
                        "text": "The EM algorithm has many generalizations, including GEM algorithms (Thiesson 1991), which operate by not necessarily maximizing Q, but only finding a value of \u03b8\u2032 that makes Q(\u03b8\u2032 | \u03b8) strictly increase over Q(\u03b8 | \u03b8)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "G)EM algorithms for maximum likelihood in recursive graphical association models"
            },
            "venue": {
                "fragments": [],
                "text": "M. Sc. Thesis, Department of Mathematics and Computer Science, Aalborg University."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theory of Probability (Volumes 1 and 2)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian Theory"
            },
            "venue": {
                "fragments": [],
                "text": "John Wiley and Sons, Chichester, United Kingdom."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Bayesian analysis of simple mixture problems"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian Statistics, (ed. J. M. Bernardo, M. H. DeGroot, D. V. Lindley, and A. F. M. Smith), pp. 67\u201378 (with discussion). Clarendon Press, Oxford, United Kingdom."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 144
                            }
                        ],
                        "text": "The valuation network method of Shenoy (1996) adapted to asymmetric problems is one such proposal; others include contingent influence diagrams (Fung and Shachter 1990) and sequential decision diagrams (Covaliu and Oliver 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contingent influence diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "Working paper, Department of Engineering\u2013Economic Systems, Stanford University."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Henrion (1988) proposed an algorithm called probabilistic logic sampling for DAGs to generate such samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Propagation of uncertainty by probabilistic logic sampling in Bayes\u2019 networks"
            },
            "venue": {
                "fragments": [],
                "text": "Uncertainty in Artificial Intelligence 2, (ed. J. F. Lemmer and L. N. Kanal), pp. 149\u201363. North-Holland, Amsterdam, The Netherlands."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning in probabilistic expert systems"
            },
            "venue": {
                "fragments": [],
                "text": "S.I.S. Workshop on Probabilistic Expert Systems, Roma, Oct. 14\u201315, (ed. R. Scozzafava), pp. 57\u201378."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 191
                            }
                        ],
                        "text": "Such comparisons can form the basis of an investigation of model adequacy, using general methods of assessing the success of probability forecasts, such as scoring rules or calibration plots (Dawid 1986)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probability forecasting"
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Statistical Sciences, (ed. S. Kotz, N. L. Johnson, and C. B. Read), pp. 210\u20138. Wiley\u2013Interscience, New York."
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multivariate Belief Functions and Graphical Models"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. Thesis, Department of Statistics, Harvard University, Massachusetts."
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Om Anvendelse af mindste Kvadraters Methode i nogle Tilf\u00e6lde, hvor en Komplikation af visse Slags uensartede tilf\u00e6ldige Fejlkilder giver Fejlene en \u2018systematisk\u2019 Karakter"
            },
            "venue": {
                "fragments": [],
                "text": "Vidensk."
            },
            "year": 1880
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 157
                            }
                        ],
                        "text": "Since the structures involved will have different complexity, particular care has to be taken in setting the probabilities of jumps between different models (Green 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reversible jump MCMC computation and Bayesian model determination"
            },
            "venue": {
                "fragments": [],
                "text": "Biometrika, 82, 711\u201332."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithm for finding theK most probable configurations in Bayesian networks"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Approximate Reasoning, 1, 205\u201333."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 142
                            }
                        ],
                        "text": "These sets are called the elimination sets induced by the numbering, and they may be used to form a tree structure called an elimination tree (Cowell 1994); this can be useful as an intermediate step to forming a junction tree of cliques and as the basis for the propagation algorithms (see Chapters 6 and 8)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Decision networks: a new formulation for multistage decision problems"
            },
            "venue": {
                "fragments": [],
                "text": "Research Report 132, Department of Statistical Science, University College London, London, United Kingdon."
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 137,
            "methodology": 79,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 314,
        "totalPages": 32
    },
    "page_url": "https://www.semanticscholar.org/paper/Probabilistic-Networks-and-Expert-Systems-Cowell-Dawid/c3f680d9c248d396bb3920fcf98ce9a7ba0a9c88?sort=total-citations"
}