{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "Using feature selection to reduce this set (or, equivalently, to lock all but a few values at 0) can improve e ectiveness [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 261
                            }
                        ],
                        "text": "1 A Probabilistic Classi er Classi ers which estimate the posterior probability via Bayes' Rule: P (Cijw) = P (wjCi) P (Ci) Pqj=1 P (wjCj) P (Cj) (1) have been applied to a variety of text classi cation tasks, including text retrieval [18], text categorization [19, 20], and word sense identi cation [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16644750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07f0f4553cfb42c0ed2bd6b07c9b22777b313d8",
            "isKey": false,
            "numCitedBy": 694,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic phrase indexing and term clustering have been widely explored as text representation techniques for text retrieval. In this paper we study the properties of phrasal and clustered indexing languages on a text categorization task, enabling us to study their properties in isolation from query interpretation issues. We show that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing. We also present results suggesting that traditional term clustering method are unlikely to provide significantly improved text representations. An improved probabilistic text categorization method is also presented."
            },
            "slug": "An-evaluation-of-phrasal-and-clustered-on-a-text-Lewis",
            "title": {
                "fragments": [],
                "text": "An evaluation of phrasal and clustered representations on a text categorization task"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144864352"
                        ],
                        "name": "M. Maron",
                        "slug": "M.-Maron",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Maron",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 261
                            }
                        ],
                        "text": "1 A Probabilistic Classi er Classi ers which estimate the posterior probability via Bayes' Rule: P (Cijw) = P (wjCi) P (Ci) Pqj=1 P (wjCj) P (Cj) (1) have been applied to a variety of text classi cation tasks, including text retrieval [18], text categorization [19, 20], and word sense identi cation [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6692916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c390dbf06af49d3691bc7b906f5fd9b909c2f89b",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "This inquiry examines a technique for automatically classifying (indexing) documents according to their subject content. The task, in essence, is to have a computing machine read a document and on the basis of the occurrence of selected clue words decide to which of many subject categories the document in question belongs. This paper describes the design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexing."
            },
            "slug": "Automatic-Indexing:-An-Experimental-Inquiry-Maron",
            "title": {
                "fragments": [],
                "text": "Automatic Indexing: An Experimental Inquiry"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexed documents according to their subject content are described."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131200"
                        ],
                        "name": "A. Bookstein",
                        "slug": "A.-Bookstein",
                        "structuredName": {
                            "firstName": "Abraham",
                            "lastName": "Bookstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bookstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "the texts from which the system will learn the most must be considered [31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38357029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84268411bca71ca01a3cc611124682d373b7966b",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The fundamental problem of information retrieval is how to decide, on the basis of clues, each of which is an imperfect indicator of docuemnt relevance, which documents to retrieve and the order in which to present them. The most satisfying conceptual approaches have been based on probabilistic decision theoretic models. However, those previously used make a decision about a single document at a time, and extend this to retreiv e multiple docuemnts by ignoring interdocument interaction. The purpose of the articles is to present decision\u2010theoretic models which intrinsically include the multiple retrieval case. In particular, we argue that information retrieval should be envisioned as a process, in which the information retrieval system responds to a request by presenting documents to the patron in a sequence, gathering feedback as the process proceeds, and using this information to modify future retrieval. A retrieval strategy that naturally results from this model is described. Two examples are examined in detail."
            },
            "slug": "Information-retrieval:-A-sequential-learning-Bookstein",
            "title": {
                "fragments": [],
                "text": "Information retrieval: A sequential learning process"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is argued that information retrieval should be envisioned as a process, in which the information retrieval system responds to a request by presenting documents to the patron in a sequence, gathering feedback as the process proceeds, and using this information to modify future retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "Relevance feedback has also been proposed for nding examples of unusual word senses [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 303,
                                "start": 300
                            }
                        ],
                        "text": "1 A Probabilistic Classi er Classi ers which estimate the posterior probability via Bayes' Rule: P (Cijw) = P (wjCi) P (Ci) Pqj=1 P (wjCj) P (Cj) (1) have been applied to a variety of text classi cation tasks, including text retrieval [18], text categorization [19, 20], and word sense identi cation [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17567112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf35ed0864ff6cf524a24f0a65aa6951f9d6f214",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Word sense disambiguation has been recognized as a major problem in natural language processing research for over forty years. Both quantitive and qualitative methods have been tried, but much of this work has been stymied by difficulties in acquiring appropriate lexical resources. The availability of this testing and training material has enabled us to develop quantitative disambiguation methods that achieve 92% accuracy in discriminating between two very distinct senses of a noun. In the training phase, we collect a number of instances of each sense of the polysemous noun. Then in the testing phase, we are given a new instance of the noun, and are asked to assign the instance to one of the senses. We attempt to answer this question by comparing the context of the unknown instance with contexts of known instances using a Bayesian argument that has been applied successfully in related tasks such as author identification and information retrieval. The proposed method is probably most appropriate for those aspects of sense disambiguation that are closest to the information retrieval task. In particular, the proposed method was designed to disambiguate senses that are usually associated with different topics."
            },
            "slug": "A-method-for-disambiguating-word-senses-in-a-large-Gale-Church",
            "title": {
                "fragments": [],
                "text": "A method for disambiguating word senses in a large corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The proposed method was designed to disambiguate senses that are usually associated with different topics using a Bayesian argument that has been applied successfully in related tasks such as author identification and information retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144356748"
                        ],
                        "name": "J. Catlett",
                        "slug": "J.-Catlett",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Catlett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Catlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Other efficiency improvements include using a less accurate but more efficiently trained classifier during sampling [32], and picking the first examples satisfying a threshold on uncertainty rather than the most uncertain examples."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5319590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b69e0cce79eb288ffb43ad7ae3b99b8dea9ac5ac",
            "isKey": false,
            "numCitedBy": 1095,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Heterogeneous-Uncertainty-Sampling-for-Supervised-Lewis-Catlett",
            "title": {
                "fragments": [],
                "text": "Heterogeneous Uncertainty Sampling for Supervised Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2126632"
                        ],
                        "name": "W. S. Cooper",
                        "slug": "W.-S.-Cooper",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cooper",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. S. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772996"
                        ],
                        "name": "F. Gey",
                        "slug": "F.-Gey",
                        "structuredName": {
                            "firstName": "Fredric",
                            "lastName": "Gey",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3170235"
                        ],
                        "name": "D. Dabney",
                        "slug": "D.-Dabney",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Dabney",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dabney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2471f7b9ec544554415dcc374049a507e460a415",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of a probabilistic retrieval system design is to rank the elements of the search universe in descending order of their estimated probability of usefulness to the user. Previously explored methods for computing such a ranking have involved the use of statistical independence assumptions and multiple regression analysis on a learning sample. In this paper these techniques are recombined in a new way to achieve greater accuracy of probabilistic estimate without undue additional computational complexity. The novel element of the proposed design is that the regression analysis be carried out in two or more levels or stages. Such an approach allows composite or grouped retrieval clues to be analyzed in an orderly manner -- first within groups, and then between. It compensates automatically for systematic biases introduced by the statistical simplifying assumptions, and gives rise to search algorithms of reasonable computational efficiency."
            },
            "slug": "Probabilistic-retrieval-based-on-staged-logistic-Cooper-Gey",
            "title": {
                "fragments": [],
                "text": "Probabilistic retrieval based on staged logistic regression"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper proposes a novel element of the proposed design of a probabilistic retrieval system design that the regression analysis be carried out in two or more levels or stages, and compensates automatically for systematic biases introduced by the statistical simplifying assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "This is an ad hoc estimator, loosely justi ed by its analogy to the expected likelihood estimator [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10164826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d30aa623fd96da99a16c0c3bde73f50c92a5c42",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "It is difficult to estimate the probability of a word's context because of sparse data problems. If appropriate care is taken, we find that it is possible to make useful estimates of contextual probabilities that improve performance in a spelling correction application. In contrast, less careful estimates are found to be useless. Specifically, we will show that the Good-Turing method makes the use of contextual information practical for a spelling corrector, while attempts to use the maximum likelihood estimator (MLE) or expected likelihood estimator (ELE) fail. Spelling correction was selected as an application domain because it is analogous to many important recognition applications based on a noisy channel model (such as speech recognition), though somewhat simpler and therefore possibly more amenable to detailed statistical analysis."
            },
            "slug": "Poor-Estimates-of-Context-are-Worse-than-None-Gale-Church",
            "title": {
                "fragments": [],
                "text": "Poor Estimates of Context are Worse than None"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "It is found that it is possible to make useful estimates of contextual probabilities that improve performance in a spelling correction application, and it is shown that the Good-Turing method makes the use of contextual information practical for a spelling corrector."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725719"
                        ],
                        "name": "David J. Harper",
                        "slug": "David-J.-Harper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harper",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Harper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33071665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "036b631a2ecd1781f348231a0a2b123a52a31357",
            "isKey": false,
            "numCitedBy": 515,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Most probabilistic retrieval models incorporate information about the occurrence of index terms in relevant and non\u2010relevant documents. In this paper we consider the situation where no relevance information is available, that is, at the start of the search. Based on a probabilistic model, strategies are proposed for the initial search and an intermediate search. Retrieval experiments with the Cranfield collection of 1,400 documents show that this initial search strategy is better than conventional search strategies both in terms of retrieval effectiveness and in terms of the number of queries that retrieve relevant documents. The intermediate search is shown to be a useful substitute for a relevance feedback search. Experiments with queries that do not retrieve relevant documents at high rank positions indicate that a cluster search would be an effective alternative strategy."
            },
            "slug": "Using-Probabilistic-Models-of-Document-Retrieval-Croft-Harper",
            "title": {
                "fragments": [],
                "text": "Using Probabilistic Models of Document Retrieval without Relevance Information"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper considers the situation where no relevance information is available, that is, at the start of the search, based on a probabilistic model, and proposes strategies for the initial search and an intermediate search."
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870604"
                        ],
                        "name": "E. Shamir",
                        "slug": "E.-Shamir",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Shamir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Shamir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Freund, Seung, Shamir, and Tishby extend the QBC result to a wide range of classi er forms [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6191578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7789158665db67295e2758aa4b1c11c3372f0e31",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze the \"query by committee\" algorithm, a method for filtering informative queries from a random stream of inputs. We show that if the two-member committee algorithm achieves information gain with positive lower bound, then the prediction error decreases exponentially with the number of queries. We show that, in particular, this exponential decrease holds for query learning of thresholded smooth functions."
            },
            "slug": "Information,-Prediction,-and-Query-by-Committee-Freund-Seung",
            "title": {
                "fragments": [],
                "text": "Information, Prediction, and Query by Committee"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "It is shown that if the two-member committee algorithm achieves information gain with positive lower bound, then the prediction error decreases exponentially with the number of queries, and this exponential decrease holds for query learning of thresholded smooth functions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2126632"
                        ],
                        "name": "W. S. Cooper",
                        "slug": "W.-S.-Cooper",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cooper",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. S. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "By making certain independence assumptions [21], we can make the following decomposition: P (Cjw) P ( Cjw) = P (C) P ( C) d Y i=1 P (wijC) P (wij C) (3) Then, using the fact that P ( Cjw) = 1 P (Cjw), plus some arithmetic manipulations, we can get the following expression for P (Cjw): P (Cjw) = exp(log P (C) 1 P (C) +Pdi=1 log P (wi jC) P (wi j C) ) 1 + exp(log P (C) 1 P (C) +Pdi=1 log P (wijC) P (wij C) ) (4) Equation 4 is rarely used directly in text classi cation, probably because its estimates of P (Cjw) are systematically inaccurate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16376601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5857780939512bf49b5f56fdb2355d1840e382f5",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The probabilistic theory of information retrieval involves the construction of mathematical models based on statistical assumptions of various sorts. One of the hazards inherent in this kind of theory construction is that the assumptions laid down may be inconsistent with the data to which they are applied. Another hazard is that the stated assumptions may not be the real assumptions on which the derived modelling equations or resulting experiments are actually based. Both kinds of error have been made repeatedly in research on probabilistic information retrieval. One consequence of these lapses is that the statistical character of certain probabilistic IR models, including the so-called \u2018binary independence\u2019 model, has been seriously misapprehended."
            },
            "slug": "Some-inconsistencies-and-misnomers-in-probabilistic-Cooper",
            "title": {
                "fragments": [],
                "text": "Some inconsistencies and misnomers in probabilistic information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The statistical character of certain probabilistic IR models, including the so-called \u2018binary independence\u2019 model, has been seriously misapprehended."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145222174"
                        ],
                        "name": "J. Bovey",
                        "slug": "J.-Bovey",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bovey",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bovey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 94
                            }
                        ],
                        "text": "A number of approaches to using logistic regression in text classification have been proposed [23, 24, 25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57953635,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "bbe3cfae7716ceb8a9d2d543df24e49bd6f73b1b",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Some statistical problems arising in the use of probabilistic models in retrieval are analysed. An attempt is made to identify statistical methods from other fields which may be useful in retrieval. The logistic model, or class of models, which was developed for medical diagnostics, is identified as a promising approach. Retrieval methods based on the logistic model are developed and tested on three test collections; but the results indicate that the logistic models do not achieve the performance levels of traditional methods. Reasons for this discussed. The logistic approach remains an attractive one for research purposes, particularly because it allows parameters to be added or removed at will. An attempt is made to derive a formal rule to determine when a new parameter (representing say an interaction between two terms) should be added. A single applicable rule is not reached, but the analysis throws some light on the problem."
            },
            "slug": "Statistical-problems-in-the-application-of-models-Robertson-Bovey",
            "title": {
                "fragments": [],
                "text": "Statistical problems in the application of probabilistic models to information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The logistic model, or class of models, which was developed for medical diagnostics, is identified as a promising approach and developed and tested; but the results indicate that the logistic models do not achieve the performance levels of traditional methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145159381"
                        ],
                        "name": "Jenq-Neng Hwang",
                        "slug": "Jenq-Neng-Hwang",
                        "structuredName": {
                            "firstName": "Jenq-Neng",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jenq-Neng Hwang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28184513"
                        ],
                        "name": "J. J. Choi",
                        "slug": "J.-J.-Choi",
                        "structuredName": {
                            "firstName": "Jai",
                            "lastName": "Choi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. J. Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3235479"
                        ],
                        "name": "Seho Oh",
                        "slug": "Seho-Oh",
                        "structuredName": {
                            "firstName": "Seho",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seho Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47398186"
                        ],
                        "name": "R. Marks",
                        "slug": "R.-Marks",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Marks",
                            "middleNames": [
                                "J."
                            ],
                            "suffix": "Jr"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Marks"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "In addition, there is also some evidence that training on pairs of examples on opposite sides of a decision boundary is useful [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "On the other hand, experiments using a single classifier to make arbitrary queries [14] or select subsets of labeled data [8, 15] have shown substantial speedups in learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26254146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0bd6e0c494ca277aeaa5ef00da41da5b2600b9c",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach is presented for query-based neural network learning. A layered perceptron partially trained for binary classification is considered. The single-output neuron is trained to be either a zero or a one. A test decision is made by thresholding the output at, for example, one-half. The set of inputs that produce an output of one-half forms the classification boundary. The authors adopted an inversion algorithm for the neural network that allows generation of this boundary. For each boundary point, the classification gradient can be generated. The gradient provides a useful measure of the steepness of the multidimensional decision surfaces. Conjugate input pairs are generated using the boundary point and gradient information and presented to an oracle for proper classification. These data are used to refine further the classification boundary, thereby increasing the classification accuracy. The result can be a significant reduction in the training set cardinality in comparison with, for example, randomly generated data points. An application example to power system security assessment is given."
            },
            "slug": "Query-based-learning-applied-to-partially-trained-Hwang-Choi",
            "title": {
                "fragments": [],
                "text": "Query-based learning applied to partially trained multilayer perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An approach is presented for query-based neural network learning that combines a layered perceptron partially trained for binary classification with an inversion algorithm for the neural network that allows generation of this boundary."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 183
                            }
                        ],
                        "text": "A single classi er approach to uncertainty sampling has several theoretical failings, including underestimation of true uncertainty, and biases caused by nonrepresentative classi ers [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 137
                            }
                        ],
                        "text": "Recently, several algorithms for learning via queries have been proposed that lter existing examples rather than creating arti cial ones [9, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6530745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abda1941534d3bb558dd959025d67f1df526303",
            "isKey": false,
            "numCitedBy": 792,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Three Bayesian ideas are presented for supervised adaptive classifiers. First, it is argued that the output of a classifier should be obtained by marginalizing over the posterior distribution of the parameters; a simple approximation to this integral is proposed and demonstrated. This involves a \"moderation\" of the most probable classifier's outputs, and yields improved performance. Second, it is demonstrated that the Bayesian framework for model comparison described for regression models in MacKay (1992a,b) can also be applied to classification problems. This framework successfully chooses the magnitude of weight decay terms, and ranks solutions found using different numbers of hidden units. Third, an information-based data selection criterion is derived and demonstrated within this framework."
            },
            "slug": "The-Evidence-Framework-Applied-to-Classification-Mackay",
            "title": {
                "fragments": [],
                "text": "The Evidence Framework Applied to Classification Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is demonstrated that the Bayesian framework for model comparison described for regression models in MacKay (1992a,b) can also be applied to classification problems and an information-based data selection criterion is derived and demonstrated within this framework."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Relevance feedback [4] does a kind of nonrandom sampling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17637032,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2ebb3dd597bbd7028d8c68bcf509e5bb09ea1e78",
            "isKey": false,
            "numCitedBy": 1442,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback is an automatic process, introduced over 20 years ago, designed to produce query formulations following an initial retrieval operation. The principal relevance feedback methods described over the years are examined briefly, and evaluation data are included to demonstrate the effectiveness of the various methods. Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback."
            },
            "slug": "Improving-retrieval-performance-by-relevance-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Improving retrieval performance by relevance feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback, and evaluation data are included to demonstrate the effectiveness of the various methods."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720547"
                        ],
                        "name": "H. Sompolinsky",
                        "slug": "H.-Sompolinsky",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Sompolinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sompolinsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Seung, Opper, and Sompolinsky [11] present a theoretical analysis of query by committee (QBC), \nan algorithm that, for each unlabeled example, draws two classifiers randomly from the version space, \ni.e. the set of all classifiers consistent with the labeled training data [12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Seung, Opper, and Sompolinsky [11] present a theoretical analysis of \\query by committee\" (QBC), an algorithm that, for each unlabeled example, draws two classi ers randomly from the version space, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 30
                            }
                        ],
                        "text": "H. S. Seung, M. Opper, and H. Sompolinsky."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 137
                            }
                        ],
                        "text": "Recently, several algorithms for learning via queries have been proposed that lter existing examples rather than creating arti cial ones [9, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7869993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "941ef255d31b5becbf0a3281bcf7ac0122e4c833",
            "isKey": true,
            "numCitedBy": 1619,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an algorithm called query by commitee, in which a committee of students is trained on the same data set. The next query is chosen according to the principle of maximal disagreement. The algorithm is studied for two toy models: the high-low game and perceptron learning of another perceptron. As the number of queries goes to infinity, the committee algorithm yields asymptotically finite information gain. This leads to generalization error that decreases exponentially with the number of examples. This in marked contrast to learning from randomly chosen inputs, for which the information gain approaches zero and the generalization error decreases with a relatively slow inverse power law. We suggest that asymptotically finite information gain may be an important characteristic of good query algorithms."
            },
            "slug": "Query-by-committee-Seung-Opper",
            "title": {
                "fragments": [],
                "text": "Query by committee"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is suggested that asymptotically finite information gain may be an important characteristic of good query algorithms, in which a committee of students is trained on the same data set."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2195972"
                        ],
                        "name": "P. Utgoff",
                        "slug": "P.-Utgoff",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Utgoff",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Utgoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45642591,
            "fieldsOfStudy": [
                "Computer Science",
                "Education"
            ],
            "id": "b688e2cc7f39186d64bb63f978fa360b0f6a8e65",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Improved-Training-Via-Incremental-Learning-Utgoff",
            "title": {
                "fragments": [],
                "text": "Improved Training Via Incremental Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ML"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15424327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61af1deb7a3016cd0760aca0f0a38a4fecda3d61",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Models-for-retrieval-with-probabilistic-indexing-Fuhr",
            "title": {
                "fragments": [],
                "text": "Models for retrieval with probabilistic indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30639427"
                        ],
                        "name": "D. Davis",
                        "slug": "D.-Davis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Davis",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145159381"
                        ],
                        "name": "Jenq-Neng Hwang",
                        "slug": "Jenq-Neng-Hwang",
                        "structuredName": {
                            "firstName": "Jenq-Neng",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jenq-Neng Hwang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 121
                            }
                        ],
                        "text": "On the other hand, experiments using a single classi er to make arbitrary queries [14] or select subsets of labeled data [8, 15] have shown substantial speedups in learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62095352,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "7a756f567fd5b28d774970dd14bc5148d6410f3d",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An attempt is made to improve the classification performance of a trained multilayer perceptron. Using inversion to locate boundary points of the partially trained classification surfaces, the authors have defined boundary regions and selected those training data which fell within the boundary regions. Continuing the training with only the boundary region data, the authors improved classification performance by 6% in an automated cytological classification application.<<ETX>>"
            },
            "slug": "Attentional-focus-training-by-boundary-region-data-Davis-Hwang",
            "title": {
                "fragments": [],
                "text": "Attentional focus training by boundary region data selection"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An attempt is made to improve the classification performance of a trained multilayer perceptron by using inversion to locate boundary points of the partially trained classification surfaces."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1992] IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "the set of all classi ers consistent with the labeled training data [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17162574,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "0df1aac45ff562089a3bdbcb34e2481a71478651",
            "isKey": false,
            "numCitedBy": 1775,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalization-as-Search-Mitchell",
            "title": {
                "fragments": [],
                "text": "Generalization as Search"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865251"
                        ],
                        "name": "M. Plutowski",
                        "slug": "M.-Plutowski",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Plutowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Plutowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149702798"
                        ],
                        "name": "H. White",
                        "slug": "H.-White",
                        "structuredName": {
                            "firstName": "Halbert",
                            "lastName": "White",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. White"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 121
                            }
                        ],
                        "text": "On the other hand, experiments using a single classi er to make arbitrary queries [14] or select subsets of labeled data [8, 15] have shown substantial speedups in learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 196
                            }
                        ],
                        "text": "2 Learning with Queries A classi er can often be learned from fewer examples if the learning algorithm is allowed to create arti cial examples ormembership queries and ask a teacher to label them [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6936422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e06680314e1cf32706686e6520107976fdb7064",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors derive a method for selecting exemplars for training a multilayer feedforward network architecture to estimate an unknown (deterministic) mapping from clean data, i.e., data measured either without error or with negligible error. The objective is to minimize the data requirement of learning. The authors choose a criterion for selecting training examples that works well in conjunction with the criterion used for learning, here, least squares. They proceed sequentially, selecting an example that, when added to the previous set of training examples and learned, maximizes the decrement of network squared error over the input space. When dealing with clean data and deterministic relationships, concise training sets that minimize the integrated squared bias (ISB) are desired. The ISB is used to derive a selection criterion for evaluating individual training examples, the DISB, that is maximized to select new exemplars. They conclude with graphical illustrations of the method, and demonstrate its use during network training. Experimental results indicate that training upon exemplars selected in this fashion can save computation in general purpose use as well."
            },
            "slug": "Selecting-concise-training-sets-from-clean-data-Plutowski-White",
            "title": {
                "fragments": [],
                "text": "Selecting concise training sets from clean data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results indicate that training upon exemplars selected in this fashion can save computation in general purpose use as well, and its use during network training is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16927,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16907511"
                        ],
                        "name": "C. Hilborn",
                        "slug": "C.-Hilborn",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Hilborn",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hilborn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645792"
                        ],
                        "name": "D. Lainiotis",
                        "slug": "D.-Lainiotis",
                        "structuredName": {
                            "firstName": "Demetrios",
                            "lastName": "Lainiotis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lainiotis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 86
                            }
                        ],
                        "text": "Uncertainty sampling is similar to the strategy of training on misclassi ed instances [16, 17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9664198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c3771fd6829630cf450af853df728ecd8da4ab2",
            "isKey": false,
            "numCitedBy": 985,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Since, by (8) pertaining to the nearest neighbor decision rule (NN rule). We briefly review the NN rule and then describe the CNN rule. The NN rule['l-[ \" I assigns an unclassified sample to the same class as the nearest of n stored, correctly classified samples. In other words, given a collection of n reference points, each classified by some external source, a new point is assigned to the same class as its nearest neighbor. The most interesting t)heoretical property of the NN rule is that under very mild regularity assumptions on the underlying statistics, for any metric, and for a variety of loss functions , the large-sample risk incurred is less than twice the Bayes risk. (The Bayes decision rule achieves minimum risk but ,requires complete knowledge of the underlying statistics.) From a practical point of view, however, the NN rule is not a prime candidate for many applications because of the storage requirements it imposes. The CNN rule is suggested as a rule which retains the basic approach of the NN rule without imposing such stringent storage requirements. Before describing the CNN rule we first define the notion of a consistent subset of a sample set. This is a subset which, when used as a stored reference set for the NN rule, correctly classifies all of the remaining points in the sample set. A minimal consistent subset is a consistent subset with a minimum number of elements. Every set has a consistent subset, since every set is trivially a consistent subset of itself. Obviously, every finite set has a minimal consistent subset, although the minimum size is not, in general, achieved uniquely. The CNN rule uses the following algorithm to determine a consistent subset of the original sample set. In general, however, the algorithm will not find a minimal consistent subset. We assume that the original sample set is arranged in some order; then we set up bins called STORE and GRABHAG and proceed as follows. 1) The first sample is placed in STORE. 2) The second sample is classified by the NN rule, using as a reference set the current contents of STORE. (Since STORE has only one point, the classification is trivial at this stage.) If the second sample is classified correctly it is placed in GRABBAG; otherwise it is placed in STORE. 3) Proceeding inductively, the ith sample is classified by the current contents of \u2026"
            },
            "slug": "The-Condensed-Nearest-Neighbor-Rule-Hilborn-Lainiotis",
            "title": {
                "fragments": [],
                "text": "The Condensed Nearest Neighbor Rule"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The CNN rule is suggested as a rule which retains the basic approach of the NN rule without imposing such stringent storage requirements, and the notion of a consistent subset of a sample set is defined."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094660110"
                        ],
                        "name": "Peter Biebricher",
                        "slug": "Peter-Biebricher",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Biebricher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Biebricher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084356644"
                        ],
                        "name": "G. Lustig",
                        "slug": "G.-Lustig",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Lustig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lustig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1959019"
                        ],
                        "name": "M. Schwantner",
                        "slug": "M.-Schwantner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schwantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schwantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084310078"
                        ],
                        "name": "Gerhard Knorz",
                        "slug": "Gerhard-Knorz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Knorz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerhard Knorz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 193
                            }
                        ],
                        "text": "1 An exception is when large quantities of previously labeled text are available, as when automated text categorization is being deployed to replace or aid an existing staff of manual indexers [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16543804,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dacc3d6d45ec9bec3d2eedccd9dbb35881f0a225",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Since October 1985, the automatic indexing system AIR/PHYS has been used in the input production of the physics data base of the Fachinformationsentrum Karlsruhe/West Germany. The texts to be indexed are abstracts written in English. The system of descriptors is prescribed. For the application of the AIR/PHYS system a large-scale dictionary containing more than 600 000 word-descriptor relations reap. phrase-descriptor relations has been developed. Most of these relations have been obtained by means of statistical and heuristical methods. In consequence, the relation system is rather imperfect. Therefore, the indexing system needs some fault- tolerating features. An appropriate indexing approach and the corresponding structure of the AIR/PHYS system are described. Finally, the conditions of the application as well as problems of further development are discussed."
            },
            "slug": "The-automatic-indexing-system-AIR/PHYS-from-to-Biebricher-Fuhr",
            "title": {
                "fragments": [],
                "text": "The automatic indexing system AIR/PHYS - from research to applications"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An appropriate indexing approach and the corresponding structure of the AIR/PHYS system are described, and the conditions of the application as well as problems of further development are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092997919"
                        ],
                        "name": "Ulrich Pfeifer",
                        "slug": "Ulrich-Pfeifer",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Pfeifer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ulrich Pfeifer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12649458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efc81bfb2ac385f60318102456e0ef5a780eed66",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Proceedings of the Fourteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval"
            },
            "slug": "Combining-model-oriented-and-description-oriented-Fuhr-Pfeifer",
            "title": {
                "fragments": [],
                "text": "Combining model-oriented and description-oriented approaches for probabilistic indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Proceedings of the Fourteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval describe the research and development activities at this conference and provide some of the initial ideas for future research."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '91"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126123958,
            "fieldsOfStudy": [],
            "id": "358fe49d4eab63e89ce9ca21de4f35ea27d078e4",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized Linear Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428001"
                        ],
                        "name": "P. Hayes",
                        "slug": "P.-Hayes",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Hayes",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hayes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 197
                            }
                        ],
                        "text": "While using machine learning does require manually annotating training data with class labels, this annotation takes less skill and expense than, for instance, building classi cation rules by hand [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59636574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5dbe14b353da06dfce7202aed3a605636df0cc1",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Intelligent-high-volume-text-processing-using-Hayes",
            "title": {
                "fragments": [],
                "text": "Intelligent high-volume text processing using shallow, domain-specific techniques"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206729609,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e67c9964a9defedd4f9dbe50f6e38ee58d52d62",
            "isKey": false,
            "numCitedBy": 1329,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-condensed-nearest-neighbor-rule-(Corresp.)-Hart",
            "title": {
                "fragments": [],
                "text": "The condensed nearest neighbor rule (Corresp.)"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 265
                            }
                        ],
                        "text": "4 Classi cation with the Probabilistic Classi er An advantage of using a classi er which provides accurate estimates of P (Cjw) is that, under certain assumptions, decision theory gives an optimal rule for deciding whether an example should be assigned to class C ([27], p."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern Classi cation and Scene"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 191
                            }
                        ],
                        "text": "The form of the estimate is: P (Cjx) = exp(a + b1x1 + :::+ bmxm) 1 + exp(a+ b1x1 + :::+ bmxm) (5) A number of approaches to using logistic regression in text classi cation have been proposed [23, 24, 25]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical problems in the application of probabilistic models to infor mation retrieval. Report 5739"
            },
            "venue": {
                "fragments": [],
                "text": "British Library,"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 183
                            }
                        ],
                        "text": "A single classi er approach to uncertainty sampling has several theoretical failings, including underestimation of true uncertainty, and biases caused by nonrepresentative classi ers [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 137
                            }
                        ],
                        "text": "Recently, several algorithms for learning via queries have been proposed that lter existing examples rather than creating arti cial ones [9, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving generalization with self-directed learning, 1992. To  appear in Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 140
                            }
                        ],
                        "text": "Recently, several algorithms for learning via queries have been proposed that filter existing examples rather than creating artificial ones [9, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 185
                            }
                        ],
                        "text": "A single classifier approach to uncertainty sampling haa several theoretical failings, including underestimation of true uncertainty, and biases caused by nonrepresentative classifiers [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving generalization with self-directed learning, 1992. To appear in Machine Learnzng"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 246
                            }
                        ],
                        "text": "2 Training The initial classi er required by the uncertainty sampling algorithm (Figure 3) could be produced from a set of words suggested by a teacher, just as classi ers are constructed from the texts of user requests in text retrieval systems [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using probabilistic models of document retrieval without relevance feedback"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Documentation"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text-Based Intelligent Systems: Current Research tn Ted Analyszs, Infor- mation Extraction, and Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Text-Based Intelligent Systems: Current Research tn Ted Analyszs, Infor- mation Extraction, and Retrieval"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "1 Random sampling [3] will usually not be effective."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Samplzng Techniques"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 183
                            }
                        ],
                        "text": "A single classi er approach to uncertainty sampling has several theoretical failings, including underestimation of true uncertainty, and biases caused by nonrepresentative classi ers [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 137
                            }
                        ],
                        "text": "Recently, several algorithms for learning via queries have been proposed that lter existing examples rather than creating arti cial ones [9, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving generalization with self-directed learning"
            },
            "venue": {
                "fragments": [],
                "text": "Improving generalization with self-directed learning"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "Relevance sampling is a sequential approach to sampling, since the labeling of earlier examples in uences the selection of later ones [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A brief history of sequential analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Handbook of Sequential Analysis 1{19. Marcel Dekker"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 37,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/A-sequential-algorithm-for-training-text-Lewis-Gale/5194b668c67aa83c037e71599a087f63c98eb713?sort=total-citations"
}