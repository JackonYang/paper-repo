{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2038285"
                        ],
                        "name": "Alessandro Lenci",
                        "slug": "Alessandro-Lenci",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Lenci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Lenci"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5584134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "553fb89d5858826c02f26e94262e8958debc777e",
            "isKey": false,
            "numCitedBy": 619,
            "numCiting": 148,
            "paperAbstract": {
                "fragments": [],
                "text": "Research into corpus-based semantics has focused on the development of ad hoc models that treat single tasks, or sets of closely related tasks, as unrelated challenges to be tackled by extracting different kinds of distributional information from the corpus. As an alternative to this \u201cone task, one model\u201d approach, the Distributional Memory framework extracts distributional information once and for all from the corpus, in the form of a set of weighted word-link-word tuples arranged into a third-order tensor. Different matrices are then generated from the tensor, and their rows and columns constitute natural spaces to deal with different semantic problems. In this way, the same distributional information can be shared across tasks such as modeling word similarity judgments, discovering synonyms, concept categorization, predicting selectional preferences of verbs, solving analogy problems, classifying relations between word pairs, harvesting qualia structures with patterns or example pairs, predicting the typical properties of concepts, and classifying verbs into alternation classes. Extensive empirical testing in all these domains shows that a Distributional Memory implementation performs competitively against task-specific algorithms recently reported in the literature for the same tasks, and against our implementations of several state-of-the-art methods. The Distributional Memory approach is thus shown to be tenable despite the constraints imposed by its multi-purpose nature."
            },
            "slug": "Distributional-Memory:-A-General-Framework-for-Baroni-Lenci",
            "title": {
                "fragments": [],
                "text": "Distributional Memory: A General Framework for Corpus-Based Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Distributional Memory approach is shown to be tenable despite the constraints imposed by its multi-purpose nature, and performs competitively against task-specific algorithms recently reported in the literature for the same tasks, and against several state-of-the-art methods."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2432655"
                        ],
                        "name": "J. Reisinger",
                        "slug": "J.-Reisinger",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Reisinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Reisinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8602751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e0dabfbbe823b8bdf54ecf2875c9c1341363ab1",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce tiered clustering, a mixture model capable of accounting for varying degrees of shared (context-independent) feature structure, and demonstrate its applicability to inferring distributed representations of word meaning. Common tasks in lexical semantics such as word relatedness or selectional preference can benefit from modeling such structure: Polysemous word usage is often governed by some common background metaphoric usage (e.g. the senses of line or run), and likewise modeling the selectional preference of verbs relies on identifying commonalities shared by their typical arguments. Tiered clustering can also be viewed as a form of soft feature selection, where features that do not contribute meaningfully to the clustering can be excluded. We demonstrate the applicability of tiered clustering, highlighting particular cases where modeling shared structure is beneficial and where it can be detrimental."
            },
            "slug": "A-Mixture-Model-with-Sharing-for-Lexical-Semantics-Reisinger-Mooney",
            "title": {
                "fragments": [],
                "text": "A Mixture Model with Sharing for Lexical Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "Tiered clustering is introduced, a mixture model capable of accounting for varying degrees of shared (context-independent) feature structure, and its applicability to inferring distributed representations of word meaning is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34955837"
                        ],
                        "name": "Gabriel Recchia",
                        "slug": "Gabriel-Recchia",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Recchia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriel Recchia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111327888"
                        ],
                        "name": "Michael N. Jones",
                        "slug": "Michael-N.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael N. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33871974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61c53f8d4728e811c53120ed46b8aa60090678f2",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational models of lexical semantics, such as latent semantic analysis, can automatically generate semantic similarity measures between words from statistical redundancies in text. These measures are useful for experimental stimulus selection and for evaluating a model\u2019s cognitive plausibility as a mechanism that people might use to organize meaning in memory. Although humans are exposed to enormous quantities of speech, practical constraints limit the amount of data that many current computational models can learn from. We follow up on previous work evaluating a simple metric of pointwise mutual information. Controlling for confounds in previous work, we demonstrate that this metric benefits from training on extremely large amounts of data and correlates more closely with human semantic similarity ratings than do publicly available implementations of several more complex models. We also present a simple tool for building simple and scalable models from large corpora quickly and efficiently."
            },
            "slug": "More-data-trumps-smarter-algorithms:-Comparing-with-Recchia-Jones",
            "title": {
                "fragments": [],
                "text": "More data trumps smarter algorithms: Comparing pointwise mutual information with latent semantic analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work evaluates a simple metric of pointwise mutual information and demonstrates that this metric benefits from training on extremely large amounts of data and correlates more closely with human semantic similarity ratings than do publicly available implementations of several more complex models."
            },
            "venue": {
                "fragments": [],
                "text": "Behavior research methods"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095398"
                        ],
                        "name": "Alexander Budanitsky",
                        "slug": "Alexander-Budanitsky",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Budanitsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Budanitsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145036961"
                        ],
                        "name": "Graeme Hirst",
                        "slug": "Graeme-Hirst",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Hirst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graeme Hirst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 838777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a32b3d027064798fb31ce42894fec31e834f7db",
            "isKey": false,
            "numCitedBy": 1554,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "The quantification of lexical semantic relatedness has many applications in NLP, and many different measures have been proposed. We evaluate five of these measures, all of which use WordNet as their central resource, by comparing their performance in detecting and correcting real-word spelling errors. An information-content-based measure proposed by Jiang and Conrath is found superior to those proposed by Hirst and St-Onge, Leacock and Chodorow, Lin, and Resnik. In addition, we explain why distributional similarity is not an adequate proxy for lexical semantic relatedness."
            },
            "slug": "Evaluating-WordNet-based-Measures-of-Lexical-Budanitsky-Hirst",
            "title": {
                "fragments": [],
                "text": "Evaluating WordNet-based Measures of Lexical Semantic Relatedness"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An information-content-based measure proposed by Jiang and Conrath is found superior to those proposed by Hirst and St-Onge, Leacock and Chodorow, Lin, and Resnik, and why distributional similarity is not an adequate proxy for lexical semantic relatedness."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46973696"
                        ],
                        "name": "D. Nelson",
                        "slug": "D.-Nelson",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Nelson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2327242"
                        ],
                        "name": "C. McEvoy",
                        "slug": "C.-McEvoy",
                        "structuredName": {
                            "firstName": "Cathy",
                            "lastName": "McEvoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. McEvoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2853950"
                        ],
                        "name": "T. A. Schreiber",
                        "slug": "T.-A.-Schreiber",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Schreiber",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. A. Schreiber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 125
                            }
                        ],
                        "text": "To estimate association, we extracted ratings directly from the University of South Florida Free Association Database (USF) (Nelson et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 183
                            }
                        ],
                        "text": "Separating similarity from association To create a test of the ability of models to capture similarity as opposed to association, we started with the \u2248 72, 000 pairs of concepts in the USF dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Table 1 lists the USF noun pairs with the lowest similarity scores overall, and also those with the largest additive discrepancy between association strength and similarity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "However, in line with the intuitive ubiquity of pairs such as car and petrol, of the USF pairs (all of which are associated to a greater or lesser degree) over 10% had a WupSim score of less than 0.25."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "By measuring WupSim between all pairs in the USF dataset, we observed, as expected, a high correlation between similarity and association strength across all USF pairs (Spearman \u03c1 = 0.65, p   0.001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "One benefit of sampling pairs for SimLex-999 from the USF dataset is that most items have been rated according to concreteness on a scale of 1-7 by at least 10 human subjects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "From the remaining pairs, we accepted only those in which both concepts had been subject to the USF norming procedure, ensuring that these non-USF pairs were indeed unassociated rather than simply not normed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "8According to the USF concreteness ratings, 72% of noun or verb types in the British National Corpus are more abstract than the concept war, a concept many would already consider quite abstract."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "This may be a consequence of the fact that many pairs in SimLex-999 were selected (from USF) to have a degree of association."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "(according to the USF free association scores)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "From these random parings, we excluded those that coincidentally occurred elsewhere in USF (and therefore had a degree of association)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "Final sampling From the associated (USF) cohort of potential pairs we selected 600 noun pairs, 200 verb pairs and 100 adjective pairs, and from the unassociated (non-USF) cohort, we sampled 66 nouns pairs, 22 verb pairs and 11 adjective pairs."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8890546,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "78466285abd953288db4a9832e4616e1249dba19",
            "isKey": true,
            "numCitedBy": 1983,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Preexisting word knowledge is accessed in many cognitive tasks, and this article offers a means for indexing this knowledge so that it can be manipulated or controlled. We offer free association data for 72,000 word pairs, along with over a million entries of related data, such as forward and backward strength, number of competing associates, and printed frequency. A separate file contains the 5,019 normed words, their statistics, and thousands of independently normed rhyme, stem, and fragment cues. Other files providen \u00d7 n associative networks for more than 4,000 words and a list of idiosyncratic responses for each normed word. The database will be useful for investigators interested in cuing, priming, recognition, network theory, linguistics, and implicit testing applications. They also will be useful for evaluating the predictive value of free association probabilities as compared with other measures, such as similarity ratings and co-occurrence norms. Of several procedures for measuring preexisting strength between two words, the best remains to be determined. The norms may be downloaded fromwww.psychonomic.org/archive/."
            },
            "slug": "The-University-of-South-Florida-free-association,-Nelson-McEvoy",
            "title": {
                "fragments": [],
                "text": "The University of South Florida free association, rhyme, and word fragment norms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The database will be useful for investigators interested in cuing, priming, recognition, network theory, linguistics, and implicit testing applications, and for evaluating the predictive value of free association probabilities as compared with other measures, such as similarity ratings and co-occurrence norms."
            },
            "venue": {
                "fragments": [],
                "text": "Behavior research methods, instruments, & computers : a journal of the Psychonomic Society, Inc"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689647"
                        ],
                        "name": "Peter D. Turney",
                        "slug": "Peter-D.-Turney",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Turney",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter D. Turney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 280
                            }
                        ],
                        "text": "\u2026literature refers to the conceptual relationship between these concepts as association, although it has been given a range of names including relatedness (Budanitsky and Hirst, 2006; Agirre et al., 2009), topical similarity (Hatzivassiloglou et al., 2001) and domain similarity (Turney, 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 148
                            }
                        ],
                        "text": "\u2026association and similarity in a principled way (see e.g. (Huang et al., 2012; Reisinger and Mooney, 2010b; Luong et al., 2013)).3 One exception is Turney (2012), who constructs two distributional models with different features and parameter settings, designed explicitly to capture either\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 455112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbb3b9c94129fe7a29cfdbd97f0ad5b5224ae246",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 100,
            "paperAbstract": {
                "fragments": [],
                "text": "Given appropriate representations of the semantic relations between carpenter and wood and between mason and stone (for example, vectors in a vector space model), a suitable algorithm should be able to recognize that these relations are highly similar (carpenter is to wood as mason is to stone; the relations are analogous). Likewise, with representations of dog, house, and kennel, an algorithm should be able to recognize that the semantic composition of dog and house, dog house, is highly similar to kennel (dog house and kennel are synonymous). It seems that these two tasks, recognizing relations and compositions, are closely connected. However, up to now, the best models for relations are significantly different from the best models for compositions. In this paper, we introduce a dual-space model that unifies these two tasks. This model matches the performance of the best previous models for relations and compositions. The dual-space model consists of a space for measuring domain similarity and a space for measuring function similarity. Carpenter and wood share the same domain, the domain of carpentry. Mason and stone share the same domain, the domain of masonry. Carpenter and mason share the same function, the function of artisans. Wood and stone share the same function, the function of materials. In the composition dog house, kennel has some domain overlap with both dog and house (the domains of pets and buildings). The function of kennel is similar to the function of house (the function of shelters). By combining domain and function similarities in various ways, we can model relations, compositions, and other aspects of semantics."
            },
            "slug": "Domain-and-Function:-A-Dual-Space-Model-of-Semantic-Turney",
            "title": {
                "fragments": [],
                "text": "Domain and Function: A Dual-Space Model of Semantic Relations and Compositions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A dual-space model is introduced that matches the performance of the best previous models for relations and compositions and can model relations, compositions, and other aspects of semantics."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2552871"
                        ],
                        "name": "Elia Bruni",
                        "slug": "Elia-Bruni",
                        "structuredName": {
                            "firstName": "Elia",
                            "lastName": "Bruni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elia Bruni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807810"
                        ],
                        "name": "Gemma Boleda",
                        "slug": "Gemma-Boleda",
                        "structuredName": {
                            "firstName": "Gemma",
                            "lastName": "Boleda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gemma Boleda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39903329"
                        ],
                        "name": "N. Tran",
                        "slug": "N.-Tran",
                        "structuredName": {
                            "firstName": "Nam",
                            "lastName": "Tran",
                            "middleNames": [
                                "Khanh"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Tran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In both cases, the sampling was stratified such that, in each POS subset, each of the four concreteness classes C1 \u2212 C4 was equally represented."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 75
                            }
                        ],
                        "text": "Such anomalies also exist in other gold standards such as the MEN dataset (Bruni et al., 2012a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 200
                            }
                        ],
                        "text": "Further,\n7http://clic.cimec.unitn.it/ elia.bruni/MEN.html\nthere is a strong bias towards concrete concepts in MEN because the concepts were originally selected from those identified in an image-bank (Bruni et al., 2012a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 99
                            }
                        ],
                        "text": "The design of the MEN rating system precludes a conventional calculation of inter-rater agreement (Bruni et al., 2012b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 47
                            }
                        ],
                        "text": "The MEN Test Collection A larger dataset, MEN (Bruni et al., 2012a), is used in a handful of recent studies (Bruni et al., 2012b; Bernardi et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8712237,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "917fbd64a435cb33e0e5b4cd73fe830db7b166db",
            "isKey": true,
            "numCitedBy": 357,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Our research aims at building computational models of word meaning that are perceptually grounded. Using computer vision techniques, we build visual and multimodal distributional models and compare them to standard textual models. Our results show that, while visual models with state-of-the-art computer vision techniques perform worse than textual models in general tasks (accounting for semantic relatedness), they are as good or better models of the meaning of words with visual correlates such as color terms, even in a nontrivial task that involves nonliteral uses of such words. Moreover, we show that visual and textual information are tapping on different aspects of meaning, and indeed combining them in multimodal models often improves performance."
            },
            "slug": "Distributional-Semantics-in-Technicolor-Bruni-Boleda",
            "title": {
                "fragments": [],
                "text": "Distributional Semantics in Technicolor"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "While visual models with state-of-the-art computer vision techniques perform worse than textual models in general tasks, they are as good or better models of the meaning of words with visual correlates such as color terms, even in a nontrivial task that involves nonliteral uses of such words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1144461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "isKey": false,
            "numCitedBy": 5789,
            "numCiting": 210,
            "paperAbstract": {
                "fragments": [],
                "text": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched."
            },
            "slug": "A-Solution-to-Plato's-Problem:-The-Latent-Semantic-Landauer-Dumais",
            "title": {
                "fragments": [],
                "text": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040726"
                        ],
                        "name": "R. Bernardi",
                        "slug": "R.-Bernardi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bernardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145505048"
                        ],
                        "name": "Georgiana Dinu",
                        "slug": "Georgiana-Dinu",
                        "structuredName": {
                            "firstName": "Georgiana",
                            "lastName": "Dinu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georgiana Dinu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48188880"
                        ],
                        "name": "M. Marelli",
                        "slug": "M.-Marelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Marelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2012a), is used in a handful of recent studies (Bruni et al., 2012b; Bernardi et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 130
                            }
                        ],
                        "text": "The MEN Test Collection A larger dataset, MEN (Bruni et al., 2012a), is used in a handful of recent studies (Bruni et al., 2012b; Bernardi et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9727714,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc888933dd2373adeca86923fee72150d6f0de1c",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Distributional models of semantics capture word meaning very effectively, and they have been recently extended to account for compositionally-obtained representations of phrases made of content words. We explore whether compositional distributional semantic models can also handle a construction in which grammatical terms play a crucial role, namely determiner phrases (DPs). We introduce a new publicly available dataset to test distributional representations of DPs, and we evaluate state-of-the-art models on this set."
            },
            "slug": "A-relatedness-benchmark-to-test-the-role-of-in-Bernardi-Dinu",
            "title": {
                "fragments": [],
                "text": "A relatedness benchmark to test the role of determiners in compositional distributional semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work explores whether compositional distributional semantic models can also handle a construction in which grammatical terms play a crucial role, namely determiner phrases (DPs)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727837"
                        ],
                        "name": "Enrique Alfonseca",
                        "slug": "Enrique-Alfonseca",
                        "structuredName": {
                            "firstName": "Enrique",
                            "lastName": "Alfonseca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrique Alfonseca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32580243"
                        ],
                        "name": "Keith B. Hall",
                        "slug": "Keith-B.-Hall",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Hall",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keith B. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3228765"
                        ],
                        "name": "Jana Kravalova",
                        "slug": "Jana-Kravalova",
                        "structuredName": {
                            "firstName": "Jana",
                            "lastName": "Kravalova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jana Kravalova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724629"
                        ],
                        "name": "Marius Pasca",
                        "slug": "Marius-Pasca",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Pasca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marius Pasca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078619062"
                        ],
                        "name": "Aitor Soroa Etxabe",
                        "slug": "Aitor-Soroa-Etxabe",
                        "structuredName": {
                            "firstName": "Aitor",
                            "lastName": "Etxabe",
                            "middleNames": [
                                "Soroa"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aitor Soroa Etxabe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5944731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5079c42cb329f70a4f2b94fd429ea8d35a043f56",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents and compares WordNet-based and distributional similarity approaches. The strengths and weaknesses of each approach regarding similarity and relatedness tasks are discussed, and a combination is presented. Each of our methods independently provide the best results in their class on the RG and WordSim353 datasets, and a supervised combination of them yields the best published results on all datasets. Finally, we pioneer cross-lingual similarity, showing that our methods are easily adapted for a cross-lingual task with minor losses."
            },
            "slug": "A-Study-on-Similarity-and-Relatedness-Using-and-Agirre-Alfonseca",
            "title": {
                "fragments": [],
                "text": "A Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents and compares WordNet-based and distributional similarity approaches, and pioneer cross-lingual similarity, showing that the methods are easily adapted for a cross-lingsual task with minor losses."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689647"
                        ],
                        "name": "Peter D. Turney",
                        "slug": "Peter-D.-Turney",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Turney",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter D. Turney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990190"
                        ],
                        "name": "P. Pantel",
                        "slug": "P.-Pantel",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Pantel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pantel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 164
                            }
                        ],
                        "text": "More generally, in opposition to the fuzzy, statistical approaches to meaning predominant in both cognitive psychology (Griffiths et al., 2007) and NLP (Turney and Pantel, 2010), they do not require similarity to be measured on a continuous scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 221
                            }
                        ],
                        "text": "\u2026well known neuroprobabilistic language models (NLMs) of Huang et al. (2012), Collobert and Weston (2008) and Mikolov et al. (2013a), which we compare with traditional vector-space co-occurrence models (VSMs) (Turney and Pantel, 2010) and latent semantic analysis (LSA) (Landauer and Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1500900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a0e788268fafb23ab20da0e98bb578b06830f7d",
            "isKey": false,
            "numCitedBy": 2724,
            "numCiting": 208,
            "paperAbstract": {
                "fragments": [],
                "text": "Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field."
            },
            "slug": "From-Frequency-to-Meaning:-Vector-Space-Models-of-Turney-Pantel",
            "title": {
                "fragments": [],
                "text": "From Frequency to Meaning: Vector Space Models of Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs, and to provide pointers into the literature for those who are less familiar with the field."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145505048"
                        ],
                        "name": "Georgiana Dinu",
                        "slug": "Georgiana-Dinu",
                        "structuredName": {
                            "firstName": "Georgiana",
                            "lastName": "Dinu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georgiana Dinu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067996"
                        ],
                        "name": "Germ\u00e1n Kruszewski",
                        "slug": "Germ\u00e1n-Kruszewski",
                        "structuredName": {
                            "firstName": "Germ\u00e1n",
                            "lastName": "Kruszewski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Germ\u00e1n Kruszewski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": "The models were selected to cover the main classes of representation learning architectures (Baroni et al., 2014): Vector space cooccurrence (counting) models and neural language models (NLM)s (Bengio et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 102
                            }
                        ],
                        "text": "LSA models.16 In contrast to recent results that emphasize the superiority of NLMs over alternatives (Baroni et al., 2014), we observed no clear advantage for the NLM over the VSM or LSA when considering the association-based gold standards WS-353 and MEN together."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 85205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cfbb77e5a0e24772cfdb2eb3d4f35dead54b118",
            "isKey": false,
            "numCitedBy": 1307,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Context-predicting models (more commonly known as embeddings or neural language models) are the new kids on the distributional semantics block. Despite the buzz surrounding these models, the literature is still lacking a systematic comparison of the predictive models with classic, count-vector-based distributional semantic approaches. In this paper, we perform such an extensive evaluation, on a wide range of lexical semantics tasks and across many parameter settings. The results, to our own surprise, show that the buzz is fully justified, as the context-predicting models obtain a thorough and resounding victory against their count-based counterparts."
            },
            "slug": "Don\u2019t-count,-predict!-A-systematic-comparison-of-Baroni-Dinu",
            "title": {
                "fragments": [],
                "text": "Don\u2019t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An extensive evaluation of context-predicting models with classic, count-vector-based distributional semantic approaches, on a wide range of lexical semantics tasks and across many parameter settings shows that the buzz around these models is fully justified."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748977"
                        ],
                        "name": "P. Cimiano",
                        "slug": "P.-Cimiano",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Cimiano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cimiano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792623"
                        ],
                        "name": "A. Hotho",
                        "slug": "A.-Hotho",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Hotho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hotho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752093"
                        ],
                        "name": "Steffen Staab",
                        "slug": "Steffen-Staab",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Staab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Staab"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6168648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb81fd17c7522b595af228e50a57dd618ea9b188",
            "isKey": false,
            "numCitedBy": 611,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to the automatic acquisition of taxonomies or concept hierarchies from a text corpus. The approach is based on Formal Concept Analysis (FCA), a method mainly used for the analysis of data, i.e. for investigating and processing explicitly given information. We follow Harris' distributional hypothesis and model the context of a certain term as a vector representing syntactic dependencies which are automatically acquired from the text corpus with a linguistic parser. On the basis of this context information, FCA produces a lattice that we convert into a special kind of partial order constituting a concept hierarchy. The approach is evaluated by comparing the resulting concept hierarchies with hand-crafted taxonomies for two domains: tourism and finance. We also directly compare our approach with hierarchical agglomerative clustering as well as with Bi-Section-KMeans as an instance of a divisive clustering algorithm. Furthermore, we investigate the impact of using different measures weighting the contribution of each attribute as well as of applying a particular smoothing technique to cope with data sparseness."
            },
            "slug": "Learning-Concept-Hierarchies-from-Text-Corpora-Cimiano-Hotho",
            "title": {
                "fragments": [],
                "text": "Learning Concept Hierarchies from Text Corpora using Formal Concept Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A novel approach to the automatic acquisition of taxonomies or concept hierarchies from a text corpus based on Formal Concept Analysis, which model the context of a certain term as a vector representing syntactic dependencies which are automatically acquired from the text corpus with a linguistic parser."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711215"
                        ],
                        "name": "U. Pad\u00f3",
                        "slug": "U.-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708114"
                        ],
                        "name": "Katrin Erk",
                        "slug": "Katrin-Erk",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Erk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Erk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10375802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fc56fac2ab7ac0554d2d1e2569e48bf3b259442",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we consider the computational modelling of human plausibility judgements for verb-relation-argument triples, a task equivalent to the computation of selectional preferences. Such models have applications both in psycholinguistics and in computational linguistics. By extending a recent model, we obtain a completely corpus-driven model for this task which achieves significant correlations with human judgements. It rivals or exceeds deeper, resource-driven models while exhibiting higher coverage. Moreover, we show that our model can be combined with deeper models to obtain better predictions than from either model alone."
            },
            "slug": "Flexible,-Corpus-Based-Modelling-of-Human-Pad\u00f3-Pad\u00f3",
            "title": {
                "fragments": [],
                "text": "Flexible, Corpus-Based Modelling of Human Plausibility Judgements"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A completely corpus-driven model is obtained for this task which rivals or exceeds deeper, resource-driven models while exhibiting higher coverage and can be combined with deeper models to obtain better predictions than from either model alone."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3216372"
                        ],
                        "name": "Chung Yong Lim",
                        "slug": "Chung-Yong-Lim",
                        "structuredName": {
                            "firstName": "Chung",
                            "lastName": "Lim",
                            "middleNames": [
                                "Yong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung Yong Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2435259"
                        ],
                        "name": "S. K. Foo",
                        "slug": "S.-K.-Foo",
                        "structuredName": {
                            "firstName": "Shou",
                            "lastName": "Foo",
                            "middleNames": [
                                "King"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Foo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3141663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac20da2a10ef8b07679c8dc951ed342b704a72fd",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a general concern within the field of word sense dusamb~guatmn about the rater-annotator agreement between human annota tors . In thus paper, we examine th~s msue by comparing the agreement rate on a large corpus of more than 30,000 sense-tagged instances Thin corpus us the mtersectmn of the WORDNET Semcor corpus and the DSO corpus, which has been independently tagged by two separate groups of human annotators The contribution of this paper us two-fold First , ~t presents a greedy search algori thm tha t can automatical ly derive coarser sense classes based on the sense tags assigned by two human annotators The resulting derived coarse sense classes achmve a h~gher agreement rate but we s t f l !mamtam as many of the original sense classes as posmble Second, the coarse sense grouping derived by the algorithm, upon verification by human, can potent ial ly serve as a better sense inventory for evaluating automated word sense d~samb~guatmn algori thms Moreover, we examined the derived coarse sense classes and found some interesting groupings of word senses that correspond to human mtmtlve judgment of sense granularity 1 I n t r o d u c t i o n . It us widely acknowledged that word sense d~samblguatmn (WSD) us a central problem m natural language processing In order for computers to be able to understand and process natural language beyond simple keyword matching, the problem of d~samblguatmg word sense, or dlscermng the meamng of a word m context, must be effectively dealt with Advances in WSD v, ill have slgmficant Impact on apphcatlons hke information retrieval and machine translation For natural language subtasks hke part-of-speech tagging or s)ntactm parsing, there are relatlvely well defined and agreed-upon cnterm of what it means to have the \"correct\" part of speech or syntactic structure assigned to a word or sentence For instance, the Penn Treebank corpus (Marcus et a l , 1993) pro~ide~ ,t large repo.~tory of texts annotated w~th partof-speech and s}ntactm structure mformatlon Tv.o independent human annotators can achieve a high rate of agreement on assigning part-of-speech tags to words m a g~ven sentence Unfortunately, th~s us not the case for word sense assignment F~rstly, it is rarely the case that any two dictionaries will have the same set of sense defimtmns for a g~ven word Different d~ctlonanes tend to carve up the \"semantic space\" m a different way, so to speak Secondly, the hst of senses for a word m a typical dmtmnar~ tend to be rather refined and comprehensive This is especmlly so for the commonly used words which have a large number of senses The sense dustmctmn between the different senses for a commonly used word m a d~ctmnary hke WoRDNET (Miller, 1990) tend to be rather fine Hence, two human annotators may genuinely dusagree m their sense assignment to a word m context The agreement rate between human annotators on word sense assignment us an Important concern for the evaluatmn of WSD algorithms One would prefer to define a dusamblguatlon task for which there us reasonably hlgh agreement between human annotators The agreement rate between human annotators will then form the upper ceiling against whmh to compare the performance of WSD algorithms For instance, the SENSEVAL exerclse has performed a detaded s tudy to find out the raterannotator agreement among ~ts lexicographers taggrog the word senses (Kllgamff, 1998c, Kllgarnff, 1998a, Kflgarrlff, 1998b) 2 A C a s e S t u d y In th i s -paper , we examine the ~ssue of raterannotator agreement by comparing the agreement rate of human annotators on a large sense-tagged corpus of more than 30,000 instances of the most frequently occurring nouns and verbs of Enghsh This corpus is the intersection of the WORDNET Semcor corpus (Miller et a l , 1993) and the DSO corpus (Ng and Lee, 1996, Ng, 1997), which has been independently tagged wlth the refined senses of WORDNET by two separate groups of human annotators The Semcor corpus us a subset of the Brown corpus tagged with ~VoRDNET senses, and consists of more than 670,000 words from 352 text files Sense taggmg was done on the content words (nouns, ~erbs, adjectives and adverbs) m this subset The DSO corpus consists of sentences drawn from the Brown corpus and the Wall Street Journal For each word w from a hst of 191 frequently occurring words of Enghsh (121 nouns and 70 verbs), sentences containing w (m singular or plural form, and m its various reflectional verb form) are selected and each word occurrence w ~s tagged w~th a sense from WoRDNET There ~s a total of about 192,800 sentences in the DSO corpus m which one word occurrence has been sense-tagged m each sentence The intersection of the Semcor corpus and the DSO corpus thus consists of Brown corpus sentences m which a word occurrence w is sense-tagged m each sentence, where w Is one of.the 191 frequently oc,currmg English nouns or verbs Since this common pomon has been sense-tagged by two independent groups of human annotators, ~t serves as our data set for investigating inter-annotator agreement in this paper"
            },
            "slug": "A-Case-Study-on-Inter-Annotator-Agreement-for-Word-Ng-Lim",
            "title": {
                "fragments": [],
                "text": "A Case Study on Inter-Annotator Agreement for Word Sense Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper examines th~s msue by comparing the agreement rate on a large corpus of more than 30,000 sense-tagged instances of the WORDNET Semcor corpus and the DSO corpus, which has been independently tagged by two separate groups of human annotators."
            },
            "venue": {
                "fragments": [],
                "text": "SIGLEX Workshop On Standardizing Lexical Resources"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821711"
                        ],
                        "name": "Thang Luong",
                        "slug": "Thang-Luong",
                        "structuredName": {
                            "firstName": "Thang",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thang Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14276764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53ab89807caead278d3deb7b6a4180b277d3cb77",
            "isKey": false,
            "numCitedBy": 794,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector-space word representations have been very successful in recent years at improving performance across a variety of NLP tasks. However, common to most existing work, words are regarded as independent entities without any explicit relationship among morphologically related words being modeled. As a result, rare and complex words are often poorly estimated, and all unknown words are represented in a rather crude way using only one or a few vectors. This paper addresses this shortcoming by proposing a novel model that is capable of building representations for morphologically complex words from their morphemes. We combine recursive neural networks (RNNs), where each morpheme is a basic unit, with neural language models (NLMs) to consider contextual information in learning morphologicallyaware word representations. Our learned models outperform existing word representations by a good margin on word similarity tasks across many datasets, including a new dataset we introduce focused on rare words to complement existing ones in an interesting way."
            },
            "slug": "Better-Word-Representations-with-Recursive-Neural-Luong-Socher",
            "title": {
                "fragments": [],
                "text": "Better Word Representations with Recursive Neural Networks for Morphology"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper combines recursive neural networks, where each morpheme is a basic unit, with neural language models to consider contextual information in learning morphologicallyaware word representations and proposes a novel model capable of building representations for morphologically complex words from their morphemes."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064181"
                        ],
                        "name": "A. Tversky",
                        "slug": "A.-Tversky",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Tversky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tversky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "Association contrasts with similarity, the relation connecting cup and mug (Tversky, 1977)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9173202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f718309706172d6fb1e89f583927274f9a4cdf4f",
            "isKey": false,
            "numCitedBy": 7350,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "The metric and dimensional assumptions that underlie the geometric representation of similarity are questioned on both theoretical and empirical grounds. A new set-theoretical approach to similarity is developed in which objects are represented as collections of features, and similarity is described as a feature-matching process. Specifically, a set of qualitative assumptions is shown to imply the contrast model, which expresses the similarity between objects as a linear combination of the measures of their common and distinctive features. Several predictions of the contrast model are tested in studies of similarity with both semantic and perceptual stimuli. The model is used to uncover, analyze, and explain a variety of empirical phenomena such as the role of common and distinctive features, the relations between judgments of similarity and difference, the presence of asymmetric similarities, and the effects of context on judgments of similarity. The contrast model generalizes standard representations of similarity data in terms of clusters and trees. It is also used to analyze the relations of prototypicality and family resemblance"
            },
            "slug": "Features-of-Similarity-Tversky",
            "title": {
                "fragments": [],
                "text": "Features of Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The metric and dimensional assumptions that underlie the geometric representation of similarity are questioned on both theoretical and empirical grounds and a set of qualitative assumptions are shown to imply the contrast model, which expresses the similarity between objects as a linear combination of the measures of their common and distinctive features."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16447573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "isKey": false,
            "numCitedBy": 26066,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. \n \nAn inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
            },
            "slug": "Distributed-Representations-of-Words-and-Phrases-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Words and Phrases and their Compositionality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method for finding phrases in text, and shows that learning good vector representations for millions of phrases is possible and describes a simple alternative to the hierarchical softmax called negative sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2044056"
                        ],
                        "name": "Olena Medelyan",
                        "slug": "Olena-Medelyan",
                        "structuredName": {
                            "firstName": "Olena",
                            "lastName": "Medelyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olena Medelyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39737797"
                        ],
                        "name": "C. Legg",
                        "slug": "C.-Legg",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Legg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Legg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1972431"
                        ],
                        "name": "David N. Milne",
                        "slug": "David-N.-Milne",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Milne",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David N. Milne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9419406"
                        ],
                        "name": "I. Witten",
                        "slug": "I.-Witten",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Witten",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Witten"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1828098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a67be688df763918a060240ceceeffd042c9aaf0",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 236,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mining-Meaning-from-Wikipedia-Medelyan-Legg",
            "title": {
                "fragments": [],
                "text": "Mining Meaning from Wikipedia"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Hum. Comput. Stud."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 182
                            }
                        ],
                        "text": "Adjectives exhibit various aspects of lexical semantics that have proved challenging for computational models, including antonymy, polarity (Williams and Anand, 2009) and sentiment (Wiebe, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14170522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5581992944c66522dd1b11f8a6150aeef2d95b7a",
            "isKey": false,
            "numCitedBy": 598,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Subjectivity tagging is distinguishing sentences used to present opinions and evaluations from sentences used to objectively present factual information. There are numerous applications for which subjectivity tagging is relevant, including information extraction and information retrieval. This paper identifies strong clues of subjectivity using the results of a method for clustering words according to distributional similarity (Lin 1998), seeded by a small amount of detailed manual annotation. These features are then further refined with the addition of lexical semantic features of adjectives, specifically polarity and gradability (Hatzivassiloglou & McKeown 1997), which can be automatically learned from corpora. In 10-fold cross validation experiments, features based on both similarity clusters and the lexical semantic features are shown to have higher precision than features based on each alone."
            },
            "slug": "Learning-Subjective-Adjectives-from-Corpora-Wiebe",
            "title": {
                "fragments": [],
                "text": "Learning Subjective Adjectives from Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper identifies strong clues of subjectivity using the results of a method for clustering words according to distributional similarity (Lin 1998), seeded by a small amount of detailed manual annotation."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783676"
                        ],
                        "name": "Felix Hill",
                        "slug": "Felix-Hill",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Felix Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762757"
                        ],
                        "name": "Roi Reichart",
                        "slug": "Roi-Reichart",
                        "structuredName": {
                            "firstName": "Roi",
                            "lastName": "Reichart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roi Reichart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145762466"
                        ],
                        "name": "A. Korhonen",
                        "slug": "A.-Korhonen",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Korhonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Korhonen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14526181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5002a020c0aa0d7838bb51c1ab24b23d2385e9d9",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-modal models that learn semantic representations from both linguistic and perceptual input outperform language-only models on a range of evaluations, and better reflect human concept acquisition. Most perceptual input to such models corresponds to concrete noun concepts and the superiority of the multi-modal approach has only been established when evaluating on such concepts. We therefore investigate which concepts can be effectively learned by multi-modal models. We show that concreteness determines both which linguistic features are most informative and the impact of perceptual input in such models. We then introduce ridge regression as a means of propagating perceptual information from concrete nouns to more abstract concepts that is more robust than previous approaches. Finally, we present weighted gram matrix combination, a means of combining representations from distinct modalities that outperforms alternatives when both modalities are sufficiently rich."
            },
            "slug": "Multi-Modal-Models-for-Concrete-and-Abstract-Hill-Reichart",
            "title": {
                "fragments": [],
                "text": "Multi-Modal Models for Concrete and Abstract Concept Meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that concreteness determines both which linguistic features are most informative and the impact of perceptual input in multi-modal models, and weighted gram matrix combination is presented, a means of combining representations from distinct modalities that outperforms alternatives when both modalities are sufficiently rich."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145811519"
                        ],
                        "name": "K. McRae",
                        "slug": "K.-McRae",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "McRae",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McRae"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21287124"
                        ],
                        "name": "Saman Khalkhali",
                        "slug": "Saman-Khalkhali",
                        "structuredName": {
                            "firstName": "Saman",
                            "lastName": "Khalkhali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saman Khalkhali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31683897"
                        ],
                        "name": "M. Hare",
                        "slug": "M.-Hare",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hare",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hare"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 76
                            }
                        ],
                        "text": "Since the essence of association is co-occurrence (linguistic or otherwise (McRae et al., 2012)), such pairs can seem, at least intuitively, to be similar but not strongly associated."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 179
                            }
                        ],
                        "text": "In contrast, car and petrol are associated because they frequently occur together in space and language, in this case as a result of a clear functional relationship (Plaut, 1995; McRae et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54043775,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "fcac4eaa309640026b5cdcbb48842c133c93c645",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "The constructs of semantic and associative relatedness have played a prominent role in research on semantic memory because researchers have historically drawn on the distinction between these two types of relations when formulating theories, creating experimental conditions, and explaining empirical results. We argue that the binary distinction between semantics and association is rooted in a fundamental problem in how the two are defined and contrasted. Whereas semantic relatedness has typically been limited to category coordinates, associative relatedness has most often been operationalized using the word association task. We show that meaningful semantic relations between words/concepts certainly extend beyond category coordinates, that word association is driven primarily by meaningful semantic relations between cue and response words, and that non-meaningful, purely associative relations between words generally are not retained in memory. To illustrate these points, we discuss research on semantic priming, picture naming, and the Deese-Roediger-McDermott false memory paradigm. Furthermore, we describe how research on the development of mnemonic skills in adolescents supports our view. That is, adolescents do not learn arbitrary associations between words, but develop elaborative strategies for linking words by drawing on their rich knowledge of events and situations. In other words, adolescents use existing memories of meaningful relations to ground their memories for novel word pairs, even in an associative learning paradigm. The term \u201csemantic memory\u201d is used to refer to people\u2019s memory for concepts and word meanings. An important aspect of understanding semantic memory concerns delineating the ways in which knowledge of word meaning is organized, and as such, a great deal of research has been aimed at providing insight into this issue. A key goal in this regard is to uncover the relations among concepts that are encoded in semantic memory. To this end, the constructs of semantic and associative relations have been central components of theories of the organization of semantic memory, and research comparing the two has provided a substantial amount of informative data that have furthered both theory development and empirical work. However, critical issues remain with regard to how semantic and associative relations have been defined and studied in semantic memory research, and how they might best be defined and studied in future research. In an influential paper on the organization of human memory, Tulving (1972) noted an increased interest among some of his contemporaries in the kind of memory that underlies the seemingly effortless execution of skills such as language processing and memory access. Tulving\u2019s definition of semantic memory still nicely captures some commonly held views: Semantic memory is the memory necessary for the use of language. It is a mental thesaurus, organized knowledge a person possesses about words and other verbal symbols, their meaning and referents, about relations among them, and about rules, formulas, and algorithms for the manipulation of these symbols, concepts, and relations. (p. 386) Tulving also stated that \u201cthe relations among items in semantic memory are of much greater variety\u201d (p. 388) than the relations among the contents of episodic memories, which he believed to be organized chiefly along spatio-temporal dimensions. Since that time, a large number of theories and studies have focused on the contrast between semantic and associative relations because they are considered to be the two principle and distinguishable components of conceptual organization (Crutch & Warrington, 2010; Fischler, 1977; Hutchison, 2002; Shelton & Martin, 1992; Thompson-Schill, Kurtz, & Gabrielli, 1998; Yee, Overton, & Thompson-Schill, 2009). It has been a common working hypothesis in semantic memory research that these components are defined on orthogonal dimensions. Associative relatedness is defined typically in terms of stimulus-response combinations in a word association task (e.g., agony-pain; Nelson, McEvoy, & Schreiber, 1998). In fact, Nelson et al.\u2019s word association norms, although not the Semantic & Associative Relations 3 sole source of word association norms in the literature, have been the most often used operationalization of association in memory research for at least the past decade. In contrast, semantic relatedness has typically been defined either as membership in the same superordinate category (e.g., horse-dog; Lupker, 1984), or as the degree to which the semantic features of two concepts overlap (horse-cow; Frenck-Mestre & Beuno, 1999). Often these two measures are treated as essentially the same, and indeed both are based on closeness in a representational structure, although featural overlap is more of a continuous dimension than is shared category. In this chapter, we outline our position concerning the relationship between association and meaning. Association in its general sense spatial and temporal co-occurrence in the world and language is an important driving force in learning, and this includes the formation of semantic representations. Furthermore, word association norms are an interesting and rich source of data. However, word associations on their own provide little if any insight into the relations that are encoded in semantic memory. Performance on word association norms is driven by meaningful semantic relations, and these relations are identifiable, and in many cases, quantifiable. We also argue that is not fruitful to attempt to understand semantic memory using a binary distinction between semantic similarity and word association (or even between semantic relatedness, broadly defined, vs. word association). On the one hand, the scope of semantic relations is much broader than similarity alone, and on the other hand, word associations are driven almost exclusively by semantic relations. Finally, a fruitful research strategy is to work toward understanding the relative importance or centrality of various types of semantic relations for various types of concepts. This approach, we believe, is the best path forward for understanding concepts and semantic memory. To provide evidence for these ideas, and to couch our arguments, we focus on four areas of research in which the semantics-word association dichotomy has played a major role. Section 4.1 deals with experiments regarding picture-word facilitation and interference. Section 4.2 concerns the DeeseRoediger-McDermott false memory paradigm. Section 4.3 focuses on semantic priming. Finally, Section 4.4 describes research concerning how the ability to learn word pairs develops across adolescence, and how this development crucially hinges on semantic knowledge, and the ability to employ that knowledge to make associations meaningful."
            },
            "slug": "Semantic-and-associative-relations-in-adolescents-a-McRae-Khalkhali",
            "title": {
                "fragments": [],
                "text": "Semantic and associative relations in adolescents and young adults: Examining a tenuous dichotomy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1752785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "265be00bf112c6cb2fa3e8176bff8394a114dbde",
            "isKey": false,
            "numCitedBy": 3890,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66)."
            },
            "slug": "Using-Information-Content-to-Evaluate-Semantic-in-a-Resnik",
            "title": {
                "fragments": [],
                "text": "Using Information Content to Evaluate Semantic Similarity in a Taxonomy"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content, which performs encouragingly well and is significantly better than the traditional edge counting approach."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31565315"
                        ],
                        "name": "Chris Biemann",
                        "slug": "Chris-Biemann",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Biemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Biemann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11285499,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29f7d170f3381281537a3f75c038d3b9a30d6577",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "After the vision of the Semantic Web was broadcasted at the turn of the millennium, ontology became a synonym for the solution to many problems concerning the fact that computers do not understand human language: if there were an ontology and every document were marked up with it and we had agents that would understand the markup, then computers would finally be able to process our queries in a really sophisticated way. Some years later, the success of Google shows us that the vision has not come true, being hampered by the incredible amount of extra work required for the intellectual encoding of semantic mark-up \u2013 as compared to simply uploading an HTML page. To alleviate this acquisition bottleneck, the field of ontology learning has since emerged as an important sub-field of ontology engineering. It is widely accepted that ontologies can facilitate text understanding and automatic processing of textual resources. Moving from words to concepts not only mitigates data sparseness issues, but also promises appealing solutions to polysemy and homonymy by finding non-ambiguous concepts that may map to various realizations in \u2013 possibly ambiguous \u2013 words. Numerous applications using lexical-semantic databases like WordNet (Miller, 1990) and its non-English counterparts, e.g. EuroWordNet (Vossen, 1997) or CoreNet (Choi and Bae, 2004) demonstrate the utility of semantic resources for natural language processing. Learning semantic resources from text instead of manually creating them might be dangerous in terms of correctness, but has undeniable advantages: Creating resources for text processing from the texts to be processed will fit the semantic component neatly and directly to them, which will never be possible with general-purpose resources. Further, the cost per entry is greatly reduced, giving rise to much larger resources than an advocate of a manual approach could ever afford. On the other hand, none of the methods used today are good enough for creating semantic resources of any kind in a completely unsupervised fashion, albeit automatic methods can facilitate manual construction to a large extent. The term ontology is understood in a variety of ways and has been used in philosophy for many centuries. In contrast, the notion of ontology in the field of computer science is younger \u2013 but almost used as inconsistently, when it comes to the details of the definition. The intention of this essay is to give an overview of different methods that learn ontologies or ontology-like structures from unstructured text. Ontology learning from other sources, issues in description languages, ontology editors, ontology merging and ontology evolving transcend the scope of this article. Surveys on ontology learning from text and other sources can be found in Ding and Foo (2002) and Gomez-Perez"
            },
            "slug": "Ontology-Learning-from-Text:-A-Survey-of-Methods-Biemann",
            "title": {
                "fragments": [],
                "text": "Ontology Learning from Text: A Survey of Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The intention of this essay is to give an overview of different methods that learn ontologies or ontology-like structures from unstructured text."
            },
            "venue": {
                "fragments": [],
                "text": "LDV Forum"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145317727"
                        ],
                        "name": "Yulia Tsvetkov",
                        "slug": "Yulia-Tsvetkov",
                        "structuredName": {
                            "firstName": "Yulia",
                            "lastName": "Tsvetkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yulia Tsvetkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308561"
                        ],
                        "name": "Leonid Boytsov",
                        "slug": "Leonid-Boytsov",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Boytsov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leonid Boytsov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145001267"
                        ],
                        "name": "A. Gershman",
                        "slug": "A.-Gershman",
                        "structuredName": {
                            "firstName": "Anatole",
                            "lastName": "Gershman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gershman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144287919"
                        ],
                        "name": "Eric Nyberg",
                        "slug": "Eric-Nyberg",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Nyberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Nyberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 83
                            }
                        ],
                        "text": "To complement this cohort with entirely unassociated pairs, we paired up the concepts from the 900 associated pairs at random."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 950358,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ef1d93b03c20b2f488b66e8e2c24fceb2105d58f",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that it is possible to reliably discriminate whether a syntactic construction is meant literally or metaphorically using lexical semantic features of the words that participate in the construction. Our model is constructed using English resources, and we obtain state-of-the-art performance relative to previous work in this language. Using a model transfer approach by pivoting through a bilingual dictionary, we show our model can identify metaphoric expressions in other languages. We provide results on three new test sets in Spanish, Farsi, and Russian. The results support the hypothesis that metaphors are conceptual, rather than lexical, in nature."
            },
            "slug": "Metaphor-Detection-with-Cross-Lingual-Model-Tsvetkov-Boytsov",
            "title": {
                "fragments": [],
                "text": "Metaphor Detection with Cross-Lingual Model Transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is shown that it is possible to reliably discriminate whether a syntactic construction is meant literally or metaphorically using lexical semantic features of the words that participate in the construction."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143981449"
                        ],
                        "name": "Mark Andrews",
                        "slug": "Mark-Andrews",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Andrews",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Andrews"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2517462"
                        ],
                        "name": "G. Vigliocco",
                        "slug": "G.-Vigliocco",
                        "structuredName": {
                            "firstName": "Gabriella",
                            "lastName": "Vigliocco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Vigliocco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15109128"
                        ],
                        "name": "D. Vinson",
                        "slug": "D.-Vinson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Vinson",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Vinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17542062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b3616e10fc5f810243f20b84ffc72acbf773cc3",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors identify 2 major types of statistical data from which semantic representations can be learned. These are denoted as experiential data and distributional data. Experiential data are derived by way of experience with the physical world and comprise the sensory-motor data obtained through sense receptors. Distributional data, by contrast, describe the statistical distribution of words across spoken and written language. The authors claim that experiential and distributional data represent distinct data types and that each is a nontrivial source of semantic information. Their theoretical proposal is that human semantic representations are derived from an optimal statistical combination of these 2 data types. Using a Bayesian probabilistic model, they demonstrate how word meanings can be learned by treating experiential and distributional data as a single joint distribution and learning the statistical structure that underlies it. The semantic representations that are learned in this manner are measurably more realistic-as verified by comparison to a set of human-based measures of semantic representation-than those available from either data type individually or from both sources independently. This is not a result of merely using quantitatively more data, but rather it is because experiential and distributional data are qualitatively distinct, yet intercorrelated, types of data. The semantic representations that are learned are based on statistical structures that exist both within and between the experiential and distributional data types."
            },
            "slug": "Integrating-experiential-and-distributional-data-to-Andrews-Vigliocco",
            "title": {
                "fragments": [],
                "text": "Integrating experiential and distributional data to learn semantic representations."
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Using a Bayesian probabilistic model, the authors demonstrate how word meanings can be learned by treating experiential and distributional data as a single joint distribution and learning the statistical structure that underlies it."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733928"
                        ],
                        "name": "R. Navigli",
                        "slug": "R.-Navigli",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Navigli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Navigli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 461624,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "c1e48526eddd68b5bf98739a578ab69a009f570d",
            "isKey": false,
            "numCitedBy": 1919,
            "numCiting": 325,
            "paperAbstract": {
                "fragments": [],
                "text": "Word sense disambiguation (WSD) is the ability to identify the meaning of words in context in a computational manner. WSD is considered an AI-complete problem, that is, a task whose solution is at least as hard as the most difficult problems in artificial intelligence. We introduce the reader to the motivations for solving the ambiguity of words and provide a description of the task. We overview supervised, unsupervised, and knowledge-based approaches. The assessment of WSD systems is discussed in the context of the Senseval/Semeval campaigns, aiming at the objective evaluation of systems participating in several different disambiguation tasks. Finally, applications, open problems, and future directions are discussed."
            },
            "slug": "Word-sense-disambiguation:-A-survey-Navigli",
            "title": {
                "fragments": [],
                "text": "Word sense disambiguation: A survey"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces the reader to the motivations for solving the ambiguity of words and provides a description of the task, and overviews supervised, unsupervised, and knowledge-based approaches."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5715561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "509a2ca90a85c62d66a16b37e0de28715dd4e89f",
            "isKey": false,
            "numCitedBy": 1015,
            "numCiting": 140,
            "paperAbstract": {
                "fragments": [],
                "text": "Processing language requires the retrieval of concepts from memory in response to an ongoing stream of information. This retrieval is facilitated if one can infer the gist of a sentence, conversation, or document and use that gist to predict related concepts and disambiguate words. This article analyzes the abstract computational problem underlying the extraction and use of gist, formulating this problem as a rational statistical inference. This leads to a novel approach to semantic representation in which word meanings are represented in terms of a set of probabilistic topics. The topic model performs well in predicting word association and the effects of semantic association and ambiguity on a variety of language-processing and memory tasks. It also provides a foundation for developing more richly structured statistical models of language, as the generative process assumed in the topic model can easily be extended to incorporate other kinds of semantic and syntactic structure."
            },
            "slug": "Topics-in-semantic-representation.-Griffiths-Steyvers",
            "title": {
                "fragments": [],
                "text": "Topics in semantic representation."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This article analyzes the abstract computational problem underlying the extraction and use of gist, formulating this problem as a rational statistical inference that leads to a novel approach to semantic representation in which word meanings are represented in terms of a set of probabilistic topics."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2001885"
                        ],
                        "name": "Ted Pedersen",
                        "slug": "Ted-Pedersen",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Pedersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984521"
                        ],
                        "name": "Siddharth Patwardhan",
                        "slug": "Siddharth-Patwardhan",
                        "structuredName": {
                            "firstName": "Siddharth",
                            "lastName": "Patwardhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siddharth Patwardhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3075310"
                        ],
                        "name": "Jason Michelizzi",
                        "slug": "Jason-Michelizzi",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Michelizzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Michelizzi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 149
                            }
                        ],
                        "text": "\u2026model the similarity between concepts c1 and c2 as the minimum of all pairwise distances between the senses of c1 and the senses of c2 (Resnik, 1995; Pedersen et al., 2004).\nble systematic differences between annotators and tranches, which could be detected by variation on the consistency set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1499545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "495f3405da229b903797472c64d09d83659fdb34",
            "isKey": false,
            "numCitedBy": 1783,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets). It provides six measures of similarity, and three measures of relatedness, all of which are based on the lexical database WordNet. These measures are implemented as Perl modules which take as input two concepts, and return a numeric value that represents the degree to which they are similar or related."
            },
            "slug": "WordNet::Similarity-Measuring-the-Relatedness-of-Pedersen-Patwardhan",
            "title": {
                "fragments": [],
                "text": "WordNet::Similarity - Measuring the Relatedness of Concepts"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets)."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146254443"
                        ],
                        "name": "Zhibiao Wu",
                        "slug": "Zhibiao-Wu",
                        "structuredName": {
                            "firstName": "Zhibiao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhibiao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 100
                            }
                        ],
                        "text": "WupSim has been shown to correlate well with human judgements on the similarity-focused RG dataset (Wu and Palmer, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": "Specifically, we applied the\nmeasure of Wu and Palmer (1994) (henceforth WupSim), which approximates similarity on a [0,1] scale reflecting the minimum distance between any two synsets of two given concepts in WordNet."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12009057,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0e3e3c3d8ae5cb7c4636870d69967c197484d3bb",
            "isKey": false,
            "numCitedBy": 3703,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT). Two groups of English and Chinese verbs are examined to show that lexical selection must be based on interpretation of the sentences as well as selection restrictions placed on the verb arguments. A novel representation scheme is suggested, and is compared to representations with selection restrictions used in transfer-based MT. We see our approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems. Examples and experimental results will show that, using this scheme, inexact matches can achieve correct lexical selection."
            },
            "slug": "Verb-Semantics-and-Lexical-Selection-Wu-Palmer",
            "title": {
                "fragments": [],
                "text": "Verb Semantics and Lexical Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT), and sees the approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110887762"
                        ],
                        "name": "Lin Sun",
                        "slug": "Lin-Sun",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145762466"
                        ],
                        "name": "A. Korhonen",
                        "slug": "A.-Korhonen",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Korhonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Korhonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2349412"
                        ],
                        "name": "Yuval Krymolowski",
                        "slug": "Yuval-Krymolowski",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Krymolowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Krymolowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 527256,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "fa0135b3afea139a80870e944915c9eb0e2d2cd6",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous research has shown that syntactic features are the most informative features in automatic verb classification. We investigate their optimal characteristics by comparing a range of feature sets extracted from data where the proportion of verbal arguments and adjuncts is controlled. The data are obtained from different versions of VALEX [1] - a large SCF lexicon for English which was acquired automatically from several corpora and theWeb.We evaluate the feature sets thoroughly using four supervised classifiers and one unsupervised method. The best performing feature set includes rich syntactic information about both arguments and adjuncts of verbs. When combined with our best performing classifier (a novel Gaussian classifier), it yields the promising accuracy of 64.2% in classifying 204 verbs to 17 Levin (1993) classes. We discuss the impact of our results on the state-or-art and propose avenues for future work."
            },
            "slug": "Verb-Class-Discovery-from-Rich-Syntactic-Data-Sun-Korhonen",
            "title": {
                "fragments": [],
                "text": "Verb Class Discovery from Rich Syntactic Data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The best performing feature set includes rich syntactic information about both arguments and adjuncts of verbs, which yields the promising accuracy of 64.2% in classifying 204 verbs to 17 Levin (1993) classes."
            },
            "venue": {
                "fragments": [],
                "text": "CICLing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40150953"
                        ],
                        "name": "E. Huang",
                        "slug": "E.-Huang",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Huang",
                            "middleNames": [
                                "Hsin-Chun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 136
                            }
                        ],
                        "text": "Much recent research in distributional semantics does not distinguish between association and similarity in a principled way (see e.g. (Huang et al., 2012; Reisinger and Mooney, 2010b; Luong et al., 2013)).3 One exception is Turney (2012), who constructs two distributional models with different\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 74
                            }
                        ],
                        "text": "These include the well known neuroprobabilistic language models (NLMs) of Huang et al. (2012), Collobert and Weston (2008) and Mikolov et al. (2013a), which we compare with traditional vector-space co-occurrence models (VSMs) (Turney and Pantel, 2010) and latent semantic analysis (LSA) (Landauer\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 29
                            }
                        ],
                        "text": "17Training times reported by Huang et al. (2012), and for Col-\nwell below the inter-annotator agreement of 0.67."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "The Huang et al. (2012) model performs well on WS-35315, but is not very robust to changes in evaluation gold standard, and performs worst of all the models on SimLex-999."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 176
                            }
                        ],
                        "text": "\u2026an arguably more serious third limitation of WS-353 is low inter-annotor agreement, and the fact that state-of-the-art models such as those of Collobert and Weston (2008) and Huang et al. (2012) reach, or even surpass, the interannotator agreement ceiling in estimating the WS353 scores."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 79
                            }
                        ],
                        "text": "We downloaded the embeddings directly from the authors\u2019 webpage.12\nHuang et al. Huang et al. (2012) present a NLM that learns word embeddings to maximise the likelihood of predicting the last word in a sentence s based on (i) the previous words in that sentence (local context - as with Collobert\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 0
                            }
                        ],
                        "text": "(Huang et al., 2012; Bansal et al., 2014) (5)This fact is also noted by the dataset authors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 66
                            }
                        ],
                        "text": "We downloaded the embeddings directly from the authors\u2019 webpage.12\nHuang et al. Huang et al. (2012) present a NLM that learns word embeddings to maximise the likelihood of predicting the last word in a sentence s based on (i) the previous words in that sentence (local context - as with Collobert and Weston (2008)) and (ii) the document d in which that word occurs (global context)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 98
                            }
                        ],
                        "text": "It could be argued that a different comparison is more appropriate: Since the model is\n4See e.g. (Huang et al., 2012; Bansal et al., 2014) 5This fact is also noted by the dataset authors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 58
                            }
                        ],
                        "text": "The Collobert and Weston (2008) model was better than the Huang et al. (2012) model at estimating similarity in the face of high association."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 205
                            }
                        ],
                        "text": "As noted in the Introduction, an arguably more serious third limitation of WS-353 is low inter-annotor agreement, and the fact that state-of-the-art models such as those of Collobert and Weston (2008) and Huang et al. (2012) reach, or even surpass, the interannotator agreement ceiling in estimating the WS353 scores."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 60
                            }
                        ],
                        "text": "However, the true explanation may be less simple, since the Huang et al. (2012) model performs weakly on the association-based MEN dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 136
                            }
                        ],
                        "text": "Much recent research in distributional semantics does not distinguish between association and similarity in a principled way (see e.g. (Huang et al., 2012; Reisinger and Mooney, 2010b; Luong et al., 2013)).3 One exception is Turney (2012), who constructs two distributional models with different features and parameter settings, designed explicitly to capture either similarity or association."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 205
                            }
                        ],
                        "text": "Figure 7 compares the best performing NLM model (Mikolov et al., 2013a) with the VSM and\n15This score, based on embeddings downloaded from the authors\u2019 webpage, is notably lower than the score reported in (Huang et al., 2012) mentioned in Section 5.1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 74
                            }
                        ],
                        "text": "These include the well known neuroprobabilistic language models (NLMs) of Huang et al. (2012), Collobert and Weston (2008) and Mikolov et al. (2013a), which we compare with traditional vector-space co-occurrence models (VSMs) (Turney and Pantel, 2010) and latent semantic analysis (LSA) (Landauer and Dumais, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 52
                            }
                        ],
                        "text": "Thus, unlike in the small evaluation constructed by Huang et al. (2012), words are not rated in a phrasal or sentential context."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 15
                            }
                        ],
                        "text": "1For instance, Huang et al. (2012, pages 1,4,10) and Reisinger and Mooney (2010b, page 4) refer to MEN and/or WS-353 as \u2018similarity datasets\u2019."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 128
                            }
                        ],
                        "text": "Given the focus of the WS-353 ratings, it is tempting to explain this by concluding that the global context objective leads the Huang et al. (2012) model to focus on association rather than similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Huang et al. (2012) report a Spearman correlation of \u03c1 = 0.713 between their model output and WS-353."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 81
                            }
                        ],
                        "text": "When learning from 990m words of\n12http://ml.nec-labs.com/senna/\nwikipedia text, Huang et al. report a Spearman correlation of \u03c1 = 71.3 between the cosine similarity of their model embeddings and the WS-353 scores, which constitutes state-of-the-art performance for a NLM model on that dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 114
                            }
                        ],
                        "text": "This score, based on embeddings downloaded from the authors\u2019 webpage, is notably lower than the score reported in (Huang et al., 2012) mentioned in Section 5."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 372093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b669398c4cf2ebe04375c8b1beae20f4ac802fa",
            "isKey": true,
            "numCitedBy": 1184,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised word representations are very useful in NLP tasks both as inputs to learning algorithms and as extra word features in NLP systems. However, most of these models are built with only local context and one representation per word. This is problematic because words are often polysemous and global context can also provide useful information for learning word meanings. We present a new neural network architecture which 1) learns word embeddings that better capture the semantics of words by incorporating both local and global document context, and 2) accounts for homonymy and polysemy by learning multiple embeddings per word. We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outperforms competitive baselines and other neural language models."
            },
            "slug": "Improving-Word-Representations-via-Global-Context-Huang-Socher",
            "title": {
                "fragments": [],
                "text": "Improving Word Representations via Global Context and Multiple Word Prototypes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new neural network architecture is presented which learns word embeddings that better capture the semantics of words by incorporating both local and global document context, and accounts for homonymy and polysemy by learning multiple embedDings per word."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32440409"
                        ],
                        "name": "T. Rose",
                        "slug": "T.-Rose",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Rose",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146329150"
                        ],
                        "name": "Fan Li",
                        "slug": "Fan-Li",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fan Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11027141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2abe6b9ea1b13653b7384e9c8ef14b0d87e20cfc",
            "isKey": false,
            "numCitedBy": 2684,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters documentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illustrating the collection's properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices."
            },
            "slug": "RCV1:-A-New-Benchmark-Collection-for-Text-Research-Lewis-Yang",
            "title": {
                "fragments": [],
                "text": "RCV1: A New Benchmark Collection for Text Categorization Research"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2552871"
                        ],
                        "name": "Elia Bruni",
                        "slug": "Elia-Bruni",
                        "structuredName": {
                            "firstName": "Elia",
                            "lastName": "Bruni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elia Bruni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1823362"
                        ],
                        "name": "J. Uijlings",
                        "slug": "J.-Uijlings",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Uijlings",
                            "middleNames": [
                                "R.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Uijlings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In both cases, the sampling was stratified such that, in each POS subset, each of the four concreteness classes C1 \u2212 C4 was equally represented."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 75
                            }
                        ],
                        "text": "Such anomalies also exist in other gold standards such as the MEN dataset (Bruni et al., 2012a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 200
                            }
                        ],
                        "text": "Further,\n7http://clic.cimec.unitn.it/ elia.bruni/MEN.html\nthere is a strong bias towards concrete concepts in MEN because the concepts were originally selected from those identified in an image-bank (Bruni et al., 2012a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 99
                            }
                        ],
                        "text": "The design of the MEN rating system precludes a conventional calculation of inter-rater agreement (Bruni et al., 2012b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 40
                            }
                        ],
                        "text": "Training involves updating the parameters of the function f and the entries of the vector representations vw such that f(s) is larger than f(sw) for any w in V , other than the correct final word of s."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 47
                            }
                        ],
                        "text": "The MEN Test Collection A larger dataset, MEN (Bruni et al., 2012a), is used in a handful of recent studies (Bruni et al., 2012b; Bernardi et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6345436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a615793f07d1dcfcd853573bbe7a1dc29b77c90b",
            "isKey": true,
            "numCitedBy": 46,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "The current trend in image analysis and multimedia is to use information extracted from text and text processing techniques to help vision-related tasks, such as automated image annotation and generating semantically rich descriptions of images. In this work, we claim that image analysis techniques can \"return the favor\" to the text processing community and be successfully used for a general-purpose representation of word meaning. We provide evidence that simple low-level visual features can enrich the semantic representation of word meaning with information that cannot be extracted from text alone, leading to improvement in the core task of estimating degrees of semantic relatedness between words, as well as providing a new, perceptually-enhanced angle on word semantics. Additionally, we show how distinguishing between a concept and its context in images can improve the quality of the word meaning representations extracted from images."
            },
            "slug": "Distributional-semantics-with-eyes:-using-image-to-Bruni-Uijlings",
            "title": {
                "fragments": [],
                "text": "Distributional semantics with eyes: using image analysis to improve computational representations of word meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work claims that image analysis techniques can \"return the favor\" to the text processing community and be successfully used for a general-purpose representation of word meaning and shows how distinguishing between a concept and its context in images can improve the quality of the word meaning representations extracted from images."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783676"
                        ],
                        "name": "Felix Hill",
                        "slug": "Felix-Hill",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Felix Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145762466"
                        ],
                        "name": "A. Korhonen",
                        "slug": "A.-Korhonen",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Korhonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Korhonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255675"
                        ],
                        "name": "C. Bentz",
                        "slug": "C.-Bentz",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bentz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bentz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 36
                            }
                        ],
                        "text": "This ensures that the data reflect a meaningful cognitive or semantic phenomenon, and also enables the dataset to be scaled up or transferred to other languages at minimal cost and effort."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9524682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "014d2893273384a80daedc323d8080b10bcce357",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "This study presents original evidence that abstract and concrete concepts are organized and represented differently in the mind, based on analyses of thousands of concepts in publicly available data sets and computational resources. First, we show that abstract and concrete concepts have differing patterns of association with other concepts. Second, we test recent hypotheses that abstract concepts are organized according to association, whereas concrete concepts are organized according to (semantic) similarity. Third, we present evidence suggesting that concrete representations are more strongly feature-based than abstract concepts. We argue that degree of feature-based structure may fundamentally determine concreteness, and we discuss implications for cognitive and computational models of meaning."
            },
            "slug": "A-Quantitative-Empirical-Analysis-of-the-Hill-Korhonen",
            "title": {
                "fragments": [],
                "text": "A Quantitative Empirical Analysis of the Abstract/Concrete Distinction"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "Original evidence that abstract and concrete concepts are organized and represented differently in the mind is presented, based on analyses of thousands of concepts in publicly available data sets and computational resources."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920653"
                        ],
                        "name": "Samer Hassan",
                        "slug": "Samer-Hassan",
                        "structuredName": {
                            "firstName": "Samer",
                            "lastName": "Hassan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samer Hassan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8041824,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e9c459390caef1eb116c1f2fcbe7e79717f2964",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a novel method for measuring semantic relatedness using semantic profiles constructed from salient encyclopedic features. The model is built on the notion that the meaning of a word can be characterized by the salient concepts found in its immediate context. In addition to being computationally efficient, the new model has superior performance and remarkable consistency when compared to both knowledge-based and corpus-based state-of-the-art semantic relatedness models."
            },
            "slug": "Semantic-Relatedness-Using-Salient-Semantic-Hassan-Mihalcea",
            "title": {
                "fragments": [],
                "text": "Semantic Relatedness Using Salient Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A novel method for measuring semantic relatedness using semantic profiles constructed from salient encyclopedic features built on the notion that the meaning of a word can be characterized by the salient concepts found in its immediate context is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2194679"
                        ],
                        "name": "Steffen Remus",
                        "slug": "Steffen-Remus",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Remus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Remus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31565315"
                        ],
                        "name": "Chris Biemann",
                        "slug": "Chris-Biemann",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Biemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Biemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 747342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51c49cc4654dbce3c3de2919800da1e7477d88b3",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Distributional representations of words have been recently used in supervised settings for recognizing lexical inference relations between word pairs, such as hypernymy and entailment. We investigate a collection of these state-of-the-art methods, and show that they do not actually learn a relation between two words. Instead, they learn an independent property of a single word in the pair: whether that word is a \u201cprototypical hypernym\u201d."
            },
            "slug": "Do-Supervised-Distributional-Methods-Really-Learn-Levy-Remus",
            "title": {
                "fragments": [],
                "text": "Do Supervised Distributional Methods Really Learn Lexical Inference Relations?"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work investigates a collection of distributional representations of words used in supervised settings for recognizing lexical inference relations between word pairs, and shows that they do not actually learn a relation between two words, but an independent property of a single word in the pair."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977268"
                        ],
                        "name": "Mohit Bansal",
                        "slug": "Mohit-Bansal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Bansal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2924113"
                        ],
                        "name": "Karen Livescu",
                        "slug": "Karen-Livescu",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Livescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Livescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 0
                            }
                        ],
                        "text": "(Huang et al., 2012; Bansal et al., 2014) (5)This fact is also noted by the dataset authors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 118
                            }
                        ],
                        "text": "It could be argued that a different comparison is more appropriate: Since the model is\n4See e.g. (Huang et al., 2012; Bansal et al., 2014) 5This fact is also noted by the dataset authors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7803700,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f91e7bac46b13444eddeb2438b01089e73b786",
            "isKey": false,
            "numCitedBy": 295,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Word representations have proven useful for many NLP tasks, e.g., Brown clusters as features in dependency parsing (Koo et al., 2008). In this paper, we investigate the use of continuous word representations as features for dependency parsing. We compare several popular embeddings to Brown clusters, via multiple types of features, in both news and web domains. We find that all embeddings yield significant parsing gains, including some recent ones that can be trained in a fraction of the time of others. Explicitly tailoring the representations for the task leads to further improvements. Moreover, an ensemble of all representations achieves the best results, suggesting their complementarity."
            },
            "slug": "Tailoring-Continuous-Word-Representations-for-Bansal-Gimpel",
            "title": {
                "fragments": [],
                "text": "Tailoring Continuous Word Representations for Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is found that all embeddings yield significant parsing gains, including some recent ones that can be trained in a fraction of the time of others, suggesting their complementarity."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3081370"
                        ],
                        "name": "Yuval Marton",
                        "slug": "Yuval-Marton",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Marton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Marton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 201
                            }
                        ],
                        "text": "Gentner (2006) showed that children find verb concepts harder to learn than noun concepts, and Markman and Wisniewski (1997) present evidence that different cognitive operations are employed when com-\nparing two nouns or two verbs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 211
                            }
                        ],
                        "text": "C\nL ]\n1 5\nA ug\ntion systems, which aim to define mappings between fragments of different languages whose meaning is similar, but not necessarily associated, are another established application (He et al., 2008; Marton et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 188
                            }
                        ],
                        "text": "Models of similarity are particularly applicable to various NLP tasks, such as lexical resource building, semantic parsing and machine translation (He et al., 2008; Haghighi et al., 2008; Marton et al., 2009; Beltagy et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2695216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e127e8d56bf179e5e311bcc933ae764308b3d417",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Untranslated words still constitute a major problem for Statistical Machine Translation (SMT), and current SMT systems are limited by the quantity of parallel training texts. Augmenting the training data with paraphrases generated by pivoting through other languages alleviates this problem, especially for the so-called \"low density\" languages. But pivoting requires additional parallel texts. We address this problem by deriving paraphrases monolingually, using distributional semantic similarity measures, thus providing access to larger training resources, such as comparable and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting."
            },
            "slug": "Improved-Statistical-Machine-Translation-Using-Marton-Callison-Burch",
            "title": {
                "fragments": [],
                "text": "Improved Statistical Machine Translation Using Monolingually-Derived Paraphrases"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents what is to their knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783676"
                        ],
                        "name": "Felix Hill",
                        "slug": "Felix-Hill",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Felix Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743722"
                        ],
                        "name": "Douwe Kiela",
                        "slug": "Douwe-Kiela",
                        "structuredName": {
                            "firstName": "Douwe",
                            "lastName": "Kiela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douwe Kiela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145762466"
                        ],
                        "name": "A. Korhonen",
                        "slug": "A.-Korhonen",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Korhonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Korhonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 157
                            }
                        ],
                        "text": "This finding supports the growing evidence for systematic differences in representation and/or similarity operations between abstract and concrete concepts (Hill et al., 2013a), and suggests that at least part these concreteness effects are independent of POS."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 190
                            }
                        ],
                        "text": "The choice of evaluation pairs in SimLex-999 was motivated by empirical evidence that humans represent concepts of distinct part-of-speech (POS) (Gentner, 1978) and conceptual concreteness (Hill et al., 2013b) differently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 97
                            }
                        ],
                        "text": "Concreteness has also been associated with differential performance in computational text-based (Hill et al., 2013a) and multimodal semantic models (Kiela et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 86
                            }
                        ],
                        "text": "From these random parings, we excluded those that coincidentally occurred elsewhere in USF (and therefore had a degree of association)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 124
                            }
                        ],
                        "text": "On the cognitive side, these \u2018concreteness effects\u2019 are well established, even if the causes are still debated (Paivio, 1991; Hill et al., 2013b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61471537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aec4a0833f1ef7ac8b75946deba3d62fb8796591",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An increasing body of empirical evidence suggests that concreteness is a fundamental dimension of semantic representation. By implementing both a vector space model and a Latent Dirichlet Allocation (LDA) Model, we explore the extent to which concreteness is reflected in the distributional patterns in corpora. In one experiment, we show that that vector space models can be tailored to better model semantic domains of particular degrees of concreteness. In a second experiment, we show that the quality of the representations of"
            },
            "slug": "Concreteness-and-Corpora:-A-Theoretical-and-Hill-Kiela",
            "title": {
                "fragments": [],
                "text": "Concreteness and Corpora: A Theoretical and Practical Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work implements both a vector space model and a Latent Dirichlet Allocation Model to explore the extent to which concreteness is reflected in the distributional patterns in corpora."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743722"
                        ],
                        "name": "Douwe Kiela",
                        "slug": "Douwe-Kiela",
                        "structuredName": {
                            "firstName": "Douwe",
                            "lastName": "Kiela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douwe Kiela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 228
                            }
                        ],
                        "text": "Concreteness Although a clear majority of pairs in gold standards such as MEN and RG contain concrete items, perhaps surprisingly, the vast majority of adjective, noun and verb concepts in everyday language are in fact abstract (Hill et al., 2014; Kiela et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": ", 2013a) and multimodal semantic models (Kiela et al., 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 147
                            }
                        ],
                        "text": "\u2026items, perhaps surprisingly, the vast majority of adjective, noun and verb concepts in everyday language are in fact abstract (Hill et al., 2014; Kiela et al., 2014).8 To facilitate the evaluation of models for both concrete and abstract concept meaning, and in light of the cognitive and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 149
                            }
                        ],
                        "text": "Concreteness has also been associated with differential performance in computational text-based (Hill et al., 2013a) and multimodal semantic models (Kiela et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 129092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52d199be8845bf2529aaf3d0931e103d9ef01ade",
            "isKey": true,
            "numCitedBy": 120,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a systematic study of parameters used in the construction of semantic vector space models. Evaluation is carried out on a variety of similarity tasks, including a compositionality dataset, using several source corpora. In addition to recommendations for optimal parameters, we present some novel findings, including a similarity metric that outperforms the alternatives on all tasks considered."
            },
            "slug": "A-Systematic-Study-of-Semantic-Vector-Space-Model-Kiela-Clark",
            "title": {
                "fragments": [],
                "text": "A Systematic Study of Semantic Vector Space Model Parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A systematic study of parameters used in the construction of semantic vector space models finds some novel findings, including a similarity metric that outperforms the alternatives on all tasks considered."
            },
            "venue": {
                "fragments": [],
                "text": "CVSC@EACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153160559"
                        ],
                        "name": "Joseph P. Turian",
                        "slug": "Joseph-P.-Turian",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Turian",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph P. Turian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2335225"
                        ],
                        "name": "Lev-Arie Ratinov",
                        "slug": "Lev-Arie-Ratinov",
                        "structuredName": {
                            "firstName": "Lev-Arie",
                            "lastName": "Ratinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lev-Arie Ratinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 170
                            }
                        ],
                        "text": "The relatively low-dimension, dense (vector) representations learned by this model and the other NLMs introduced in this section are sometimes referred to as embeddings (Turian et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 629094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dac72f2c509aee67524d3321f77e97e8eff51de6",
            "isKey": false,
            "numCitedBy": 2163,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/"
            },
            "slug": "Word-Representations:-A-Simple-and-General-Method-Turian-Ratinov",
            "title": {
                "fragments": [],
                "text": "Word Representations: A Simple and General Method for Semi-Supervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work evaluates Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeds of words on both NER and chunking, and finds that each of the three word representations improves the accuracy of these baselines."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 127
                            }
                        ],
                        "text": "These include the well known neuroprobabilistic language models (NLMs) of Huang et al. (2012), Collobert and Weston (2008) and Mikolov et al. (2013a), which we compare with traditional vector-space co-occurrence models (VSMs) (Turney and Pantel, 2010) and latent semantic analysis (LSA) (Landauer\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 160
                            }
                        ],
                        "text": "Despite this simplification, the embeddings achieve state-of-the-art performance on several semantic tasks including sentence completion and analogy modelling (Mikolov et al., 2013a; Mikolov et al., 2013b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 82
                            }
                        ],
                        "text": "As shown in Fig-\nure 9, there is a negligible improvement in the performance of the Mikolov et al. (2013a) model when the window size is reduced from 10 to 2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 74
                            }
                        ],
                        "text": "We downloaded these embeddings from the authors\u2019 webpage.13\nMikolov et al. Mikolov et al. (2013a) present an architecture that learns word embeddings similar to those of standard NLMs but with no non-linear hidden layer (resulting in a simpler scoring function)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2, we evaluated the Mikolov et al. (2013a), VSM, and SVD models on the subsets of SimLex-999 containing adjective, noun, and verb concept pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 67
                            }
                        ],
                        "text": "T = 1\nN N\u2211 n=1 \u2211 \u2212t(n)\u2264j\u2264t(n),j 6=0 log(p(wn+j |wn))\nAs with other NLMs, Mikolov et al.\u2019s model captures conceptual semantics by exploting the fact that words appearing in similar linguistic contexts are likely to have similar meanings."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 163
                            }
                        ],
                        "text": "Learning concepts of different POS Given the theoretical likelihood of variation in model performance across POS categories noted in Section 2.2, we evaluated the Mikolov et al. (2013a), VSM and LSA models on the subsets of SimLex-999 containing adjective, noun and verb concept pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 124
                            }
                        ],
                        "text": "The Collobert and Weston (2008) model is more robust across WS-353 and MEN, but still does not match the performance of the Mikolov et al. (2013a) model on SimLex-999."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 105
                            }
                        ],
                        "text": "We tested the first hypothesis using the embeddings of Levy and Goldberg (2014), whose model extends the Mikolov et al. (2013a) model so that target-context training instances are extracted based on dependency-parsed rather than simple running text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The two models on the right-hand side also demonstrate the effect of training an NLM (the Mikolov et al. [2013a] model) on running-text (Mikolov et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To better understand the linguistic information exploited by models when acquiring concepts of different POS, we also computed performance on the POS subsets of SimLex-999 of the dependency-based model of Levy and Goldberg (2014) and the standard skipgram model, in which linguistic contexts are encoded as simple bagsof-words (BOW) (Mikolov et al. (2013a) [trained on the same Wikipedia text])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "Figure 7 compares the best performing NLM model (Mikolov et al., 2013a) with the VSM and\n15This score, based on embeddings downloaded from the authors\u2019 webpage, is notably lower than the score reported in (Huang et al., 2012) mentioned in Section 5.1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 127
                            }
                        ],
                        "text": "These include the well known neuroprobabilistic language models (NLMs) of Huang et al. (2012), Collobert and Weston (2008) and Mikolov et al. (2013a), which we compare with traditional vector-space co-occurrence models (VSMs) (Turney and Pantel, 2010) and latent semantic analysis (LSA) (Landauer and Dumais, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 4
                            }
                        ],
                        "text": "The Mikolov et al. model, however, performed notably better than both other NLMs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Figure 8 compares the best performing NLM model (Mikolov et al. 2013a) with the VSM and SVD models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 24
                            }
                        ],
                        "text": "Specifically, while the Mikolov et al. model was the highest performer on all POS categories, its performance was worse than both the simple VSM and LSA models (of window size 10) on the most concrete concept pairs."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5959482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "330da625c15427c6e42ccfa3b747fb29e5835bf0",
            "isKey": true,
            "numCitedBy": 21906,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose two novel model architectures for computing continuous vector\nrepresentations of words from very large data sets. The quality of these\nrepresentations is measured in a word similarity task, and the results are\ncompared to the previously best performing techniques based on different types\nof neural networks. We observe large improvements in accuracy at much lower\ncomputational cost, i.e. it takes less than a day to learn high quality word\nvectors from a 1.6 billion words data set. Furthermore, we show that these\nvectors provide state-of-the-art performance on our test set for measuring\nsyntactic and semantic word similarities."
            },
            "slug": "Efficient-Estimation-of-Word-Representations-in-Mikolov-Chen",
            "title": {
                "fragments": [],
                "text": "Efficient Estimation of Word Representations in Vector Space"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Two novel model architectures for computing continuous vector representations of words from very large data sets are proposed and it is shown that these vectors provide state-of-the-art performance on the authors' test set for measuring syntactic and semantic word similarities."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704065"
                        ],
                        "name": "D. Gentner",
                        "slug": "D.-Gentner",
                        "structuredName": {
                            "firstName": "Dedre",
                            "lastName": "Gentner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gentner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Gentner (2006) showed that children find verb concepts harder to learn than noun concepts, and Markman and Wisniewski (1997) present evidence that different cognitive operations are employed when com-\nparing two nouns or two verbs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1447469,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "d66dc53cd279e5749344b648af321e9c56910351",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "Words do not all connect to the world in the same way. Some words basically point and refer to things in the world, while others organize the world into semantic systems and name according to the system. According to the natural partitions hypothesis, the noun class has the privilege of naming the highly cohesive bits of the world, whereas verbs and prepositions have the job of partitioning the leftovers-a diffuse set of largely relational components (Gentner, 1981, 1982; Gentner & Boroditsky, 2001). The contrast between concrete nouns and verbs is in part the contrast between local individuation and individuation as part of a semantic system. As Gentner (1982, p. 324) argued,"
            },
            "slug": "Why-verbs-are-hard-to-learn-Gentner",
            "title": {
                "fragments": [],
                "text": "Why verbs are hard to learn"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2432655"
                        ],
                        "name": "J. Reisinger",
                        "slug": "J.-Reisinger",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Reisinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Reisinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 24
                            }
                        ],
                        "text": "On the cognitive side, these \u2018concreteness effects\u2019 are well established, even if the causes are still debated (Paivio, 1991; Hill et al., 2013b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 145
                            }
                        ],
                        "text": "\u2026research in distributional semantics does not distinguish between association and similarity in a principled way (see e.g. (Huang et al., 2012; Reisinger and Mooney, 2010b; Luong et al., 2013)).3 One exception is Turney (2012), who constructs two distributional models with different features\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 197
                            }
                        ],
                        "text": "This is ten percentage points higher than inter-annotator agreement (\u03c1 = 0.611) when defined as the average pairwise correlation between two annotators, as is common in NLP work (Pado\u0301 et al., 2007; Reisinger and Mooney, 2010a; Silberer and Lapata, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 93
                            }
                        ],
                        "text": "As in previous annotation or data collection for computational semantics (Pado\u0301 et al., 2007; Reisinger and Mooney, 2010a; Silberer and Lapata, 2014) we computed the inter-rater agreement as the average of pairwise Spearman \u03c1 correlations between the ratings of all respondents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2156506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c62450a13bb6692385490dd4b371de9857761374",
            "isKey": true,
            "numCitedBy": 396,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Current vector-space models of lexical semantics create a single \"prototype\" vector to represent the meaning of a word. However, due to lexical ambiguity, encoding word meaning with a single vector is problematic. This paper presents a method that uses clustering to produce multiple \"sense-specific\" vectors for each word. This approach provides a context-dependent vector representation of word meaning that naturally accommodates homonymy and polysemy. Experimental comparisons to human judgements of semantic similarity for both isolated words as well as words in sentential contexts demonstrate the superiority of this approach over both prototype and exemplar based vector-space models."
            },
            "slug": "Multi-Prototype-Vector-Space-Models-of-Word-Meaning-Reisinger-Mooney",
            "title": {
                "fragments": [],
                "text": "Multi-Prototype Vector-Space Models of Word Meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental comparisons to human judgements of semantic similarity for both isolated words as well as words in sentential contexts demonstrate the superiority of this approach over both prototype and exemplar based vector-space models."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112143809"
                        ],
                        "name": "Mu Li",
                        "slug": "Mu-Li",
                        "structuredName": {
                            "firstName": "Mu",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mu Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145490067"
                        ],
                        "name": "Muhua Zhu",
                        "slug": "Muhua-Zhu",
                        "structuredName": {
                            "firstName": "Muhua",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Muhua Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145955194"
                        ],
                        "name": "Yang Zhang",
                        "slug": "Yang-Zhang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143849609"
                        ],
                        "name": "M. Zhou",
                        "slug": "M.-Zhou",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 157
                            }
                        ],
                        "text": "Such models are used for the automatic generation of dictionaries, thesauri, ontologies and language correction tools (Cimiano et al., 2005; Biemann, 2005; Li et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 409423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d79be6f0fee88c0aa1aaf1b21c259776069b440e",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A query speller is crucial to search engine in improving web search relevance. This paper describes novel methods for use of distributional similarity estimated from query logs in learning improved query spelling correction models. The key to our methods is the property of distributional similarity between two terms: it is high between a frequently occurring misspelling and its correction, and low between two irrelevant terms only with similar spellings. We present two models that are able to take advantage of this property. Experimental results demonstrate that the distributional similarity based models can significantly outperform their baseline systems in the web query spelling correction task."
            },
            "slug": "Exploring-Distributional-Similarity-Based-Models-Li-Zhu",
            "title": {
                "fragments": [],
                "text": "Exploring Distributional Similarity Based Models for Query Spelling Correction"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "Novel methods for use of distributional similarity estimated from query logs in learning improved query spelling correction models are described, which can significantly outperform their baseline systems in the web query spelling Correction task."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761739"
                        ],
                        "name": "Judith L. Klavans",
                        "slug": "Judith-L.-Klavans",
                        "structuredName": {
                            "firstName": "Judith",
                            "lastName": "Klavans",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judith L. Klavans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69977144"
                        ],
                        "name": "Melissa L. Holcombe",
                        "slug": "Melissa-L.-Holcombe",
                        "structuredName": {
                            "firstName": "Melissa",
                            "lastName": "Holcombe",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Melissa L. Holcombe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37596605"
                        ],
                        "name": "Min-Yen Kan",
                        "slug": "Min-Yen-Kan",
                        "structuredName": {
                            "firstName": "Min-Yen",
                            "lastName": "Kan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Yen Kan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 54085695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0af651764f9b3af12596a55d036498da13d0937e",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : We present a statistical similarity measuring and clustering tool, SIMFINDER, that organizes small pieces of text from one or multiple documents into tight clusters. By placing highly related text units in the same cluster, SIMFINDER enables a subsequent content selection/generation component to reduce each cluster to a single sentence, either by extraction or by reformulation. We report on improvements in the similarity and clustering components of SIMFINDER, including a quantitative evaluation, and establish the generality of the approach by interfacing SIMFINDER to two very different summarization systems."
            },
            "slug": "SIMFINDER:-A-Flexible-Clustering-Tool-for-Hatzivassiloglou-Klavans",
            "title": {
                "fragments": [],
                "text": "SIMFINDER: A Flexible Clustering Tool for Summarization"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Improvements in the similarity and clustering components of SIMFINDER are reported, including a quantitative evaluation, and the generality of the approach is established by interfacing SIMF INDER to two very different summarization systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47709773"
                        ],
                        "name": "H. Rubenstein",
                        "slug": "H.-Rubenstein",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Rubenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rubenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1898344"
                        ],
                        "name": "J. Goodenough",
                        "slug": "J.-Goodenough",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Goodenough",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goodenough"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18309234,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7ef3ac14cdb484aaa2b039850093febd5cf73a21",
            "isKey": false,
            "numCitedBy": 1460,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Experimentol corroboration was obtained for the hypothesis that the proportion of words common to the contexts of word A and to the contexts of word B is a function of the degree to which A and B are similar in meaning. The tests were carried out for variously defined contexts. The shapes of the functions, however, indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "slug": "Contextual-correlates-of-synonymy-Rubenstein-Goodenough",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of synonymy"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The shapes of the functions indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143998726"
                        ],
                        "name": "G. Leech",
                        "slug": "G.-Leech",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Leech",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Leech"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153733790"
                        ],
                        "name": "R. Garside",
                        "slug": "R.-Garside",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Garside",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garside"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40639594"
                        ],
                        "name": "M. Bryant",
                        "slug": "M.-Bryant",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bryant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bryant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 135
                            }
                        ],
                        "text": "Such meaning-in-context evaluations are motivated by a desire to disambiguate words that otherwise might be considered to have multiple senses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16137021,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3cc8d65946052ef661e1b6b4c7b5d8322ab37f35",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to describe the CLAWS4 general-purpose grammatical tagger, used for the tagging of the 100-million-word British National Corpus, of which c.70 million words have been tagged at the time of writing (April 1994)) We will emphasise the goals of (a) gener~d-purpose adaptability, (b) incorporation of linguistic knowledge to improve quality ,and consistency, and (c) accuracy, measured consistently and in a linguistically informed way. The British National Corpus (BNC) consists of c.100 million words of English written texts and spoken transcriptions, sampled from a comprehensive range of text types. The BNC includes 10 million words of spoken h'mguage, c.45% of which is impromptu conversation (see Crowdy, forthcoming). It also includes ,an immense variety of written texts, including unpublished materials. The gr,'unmatical tagging of the corpus has therefore required the 'super-robustness' of a tagger which can adapt well to virtually all kinds of text. The tagger also has had to be versatile in dealing with different tagsets (sets of grammatical category labels-see 3 below) and accepting text in varied input formats. For the purposes of the BNC, l, he tagger has been requircd both to accept and to output text in a corpus-oriented TEl-confonnant mark-up definition known as CDIF (Corpus Document Interchange Format), but within this format many variant fornaats (affecting, for example, segmentation into words and sentences) can be readily accepted. In addition, CLAWS al-"
            },
            "slug": "CLAWS4:-The-Tagging-of-the-British-National-Corpus-Leech-Garside",
            "title": {
                "fragments": [],
                "text": "CLAWS4: The Tagging of the British National Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The main purpose of this paper is to describe the CLAWS4 general-purpose grammatical tagger, used for the tagging of the 100-million-word British National Corpus, and emphasise the goals of adaptability, incorporation of linguistic knowledge to improve quality, consistency, and accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153013450"
                        ],
                        "name": "Gbolahan K. Williams",
                        "slug": "Gbolahan-K.-Williams",
                        "structuredName": {
                            "firstName": "Gbolahan",
                            "lastName": "Williams",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gbolahan K. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795891"
                        ],
                        "name": "S. Anand",
                        "slug": "S.-Anand",
                        "structuredName": {
                            "firstName": "Sarabjot",
                            "lastName": "Anand",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Anand"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16962688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22a487f06e1eb604ece58301054fb9237b2f4a10",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A key element of any sentiment analysis system is the ability to assign a polarity strength value to words appearing within the documents. In this paper we present a novel approach to polarity strength assignment. The approach is knowledge based in that it uses WordNet to build an adjective graph which is used to measure semantic distance between words of known polarity (reference or seed words) and the target word, which is then used to assign a polarity to the target word. We extend previous work in this area by using a small training data set to learn an optimal predictor of polarity strength and to dampen polarity assigned to non-polar adjectives. We also extend the coverage of previous approaches by exploring additional lexical relations not studied previously. The method has been evaluated on a validation set and shows excellent potential in reducing the assignment of spurious polarity and accurately predicting polarity values for polar adjectives."
            },
            "slug": "Predicting-the-Polarity-Strength-of-Adjectives-Williams-Anand",
            "title": {
                "fragments": [],
                "text": "Predicting the Polarity Strength of Adjectives Using WordNet"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper uses a small training data set to learn an optimal predictor of polarity strength and to dampen polarity assigned to non-polar adjectives and extends the coverage of previous approaches by exploring additional lexical relations not studied previously."
            },
            "venue": {
                "fragments": [],
                "text": "ICWSM"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743722"
                        ],
                        "name": "Douwe Kiela",
                        "slug": "Douwe-Kiela",
                        "structuredName": {
                            "firstName": "Douwe",
                            "lastName": "Kiela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douwe Kiela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783676"
                        ],
                        "name": "Felix Hill",
                        "slug": "Felix-Hill",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Felix Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145762466"
                        ],
                        "name": "A. Korhonen",
                        "slug": "A.-Korhonen",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Korhonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Korhonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17451961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0463b1fe889f4924da30a739f5faa61b70e08629",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Models that learn semantic representations from both linguistic and perceptual input outperform text-only models in many contexts and better reflect human concept acquisition. However, experiments suggest that while the inclusion of perceptual input improves representations of certain concepts, it degrades the representations of others. We propose an unsupervised method to determine whether to include perceptual input for a concept, and show that it significantly improves the ability of multi-modal models to learn and represent word meanings. The method relies solely on image data, and can be applied to a variety of other NLP tasks."
            },
            "slug": "Improving-Multi-Modal-Representations-Using-Image-Kiela-Hill",
            "title": {
                "fragments": [],
                "text": "Improving Multi-Modal Representations Using Image Dispersion: Why Less is Sometimes More"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An unsupervised method to determine whether to include perceptual input for a concept is proposed, and it is shown that it significantly improves the ability of multi-modal models to learn and represent word meanings."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490430"
                        ],
                        "name": "Carina Silberer",
                        "slug": "Carina-Silberer",
                        "structuredName": {
                            "firstName": "Carina",
                            "lastName": "Silberer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carina Silberer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 5
                            }
                        ],
                        "text": "Concreteness Although a clear majority of pairs in gold standards such as MEN and RG contain concrete items, perhaps surprisingly, the vast majority of adjective, noun and verb concepts in everyday language are in fact abstract (Hill et al., 2014; Kiela et al., 2014).8 To facilitate the evaluation\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 122
                            }
                        ],
                        "text": "Collobert & Weston Collobert and Weston (2008) apply the architecture of an NLM to learn a word representations vw for each word w in some corpus vocabulary V ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1866991,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3540081f3aa95646171d875f8ede7d93f45cf9b",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of grounding distributional representations of lexical meaning. We introduce a new model which uses stacked autoencoders to learn higher-level embeddings from textual and visual input. The two modalities are encoded as vectors of attributes and are obtained automatically from text and images, respectively. We evaluate our model on its ability to simulate similarity judgments and concept categorization. On both tasks, our approach outperforms baselines and related models."
            },
            "slug": "Learning-Grounded-Meaning-Representations-with-Silberer-Lapata",
            "title": {
                "fragments": [],
                "text": "Learning Grounded Meaning Representations with Autoencoders"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A new model is introduced which uses stacked autoencoders to learn higher-level embeddings from textual and visual input and which outperforms baselines and related models on similarity judgments and concept categorization."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727837"
                        ],
                        "name": "Enrique Alfonseca",
                        "slug": "Enrique-Alfonseca",
                        "structuredName": {
                            "firstName": "Enrique",
                            "lastName": "Alfonseca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrique Alfonseca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756438"
                        ],
                        "name": "S. Manandhar",
                        "slug": "S.-Manandhar",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Manandhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Manandhar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 260
                            }
                        ],
                        "text": "At the same time, however, state-of-the-art distributional models are clearly not perfect representation-learning or even similarity estimation engines, as evidenced by the fact they cannot yet be applied, for instance, to generate flawless lexical resources (Alfonseca and Manandhar, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16547881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bc729d14845f8dba21ea00c418014a5ff5bd246",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Ontologies are a tool for Knowledge Representation that is now widely used, but the effort employed to build an ontology is high. We describe here a procedure to automatically extend an ontology such as WordNet with domain-specific knowledge. The main advantage of our approach is that it is completely unsupervised, so it can be applied to different languages and domains. Our experiments, in which several domain-specific concepts from a book have been introduced, with no human supervision, into WordNet, have been successful."
            },
            "slug": "Extending-a-Lexical-Ontology-by-a-Combination-of-Alfonseca-Manandhar",
            "title": {
                "fragments": [],
                "text": "Extending a Lexical Ontology by a Combination of Distributional Semantics Signatures"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work describes a procedure to automatically extend an ontology such as WordNet with domain-specific knowledge, which is completely unsupervised, so it can be applied to different languages and domains."
            },
            "venue": {
                "fragments": [],
                "text": "EKAW"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081664301"
                        ],
                        "name": "Dcdre Centner",
                        "slug": "Dcdre-Centner",
                        "structuredName": {
                            "firstName": "Dcdre",
                            "lastName": "Centner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dcdre Centner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 146
                            }
                        ],
                        "text": "The choice of evaluation pairs in SimLex-999 was motivated by empirical evidence that humans represent concepts of distinct part-of-speech (POS) (Gentner, 1978) and conceptual concreteness (Hill et al., 2013b) differently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 145
                            }
                        ],
                        "text": "The choice of evaluation pairs in SimLex-999 was motivated by empirical evidence that humans represent concepts of distinct part-of-speech (POS) (Gentner, 1978) and conceptual concreteness (Hill et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7539638,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "5c1a0cd25d76342eb5061c1b20bfe672e5f48142",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "words Cru.-rp.xn, Dents:. On Relational Meaning: The Acquisition of Verb Meanin;. CnrLi DevlaoPxtcrT, 1978 . 49, 9SS-99S . The acquisition of verb meaning is very different from the acquisition of simple noun meaning . (\"Simple nouns\" comprise concrete nouns and proper nouns .) Verbs are slower to be acquired than simple nouns . Verbs are used by children and adults with greater breadth of application than simple nouns . Finall%, a componential account of meaning appears to fit the acquisition of verb meaning somewhat better than it does that of simple nouns . These differences reflect an im ortant difference in the kind of meaning conveyed by verbs and simple nouns. Simple nouns reler to real-world entities, and verbs convey relationships among entities ."
            },
            "slug": "On-Relational-Meaning-:-The-Acquisition-of-Verb-Centner",
            "title": {
                "fragments": [],
                "text": "On Relational Meaning : The Acquisition of Verb Meaning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111076629"
                        ],
                        "name": "Mei Yang",
                        "slug": "Mei-Yang",
                        "structuredName": {
                            "firstName": "Mei",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mei Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14902530"
                        ],
                        "name": "P. Nguyen",
                        "slug": "P.-Nguyen",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143767423"
                        ],
                        "name": "Robert C. Moore",
                        "slug": "Robert-C.-Moore",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Moore",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert C. Moore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2822831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d83f76f5f66cae1829c6377e1fc4899eeef5298e",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new hypothesis alignment method for combining outputs of multiple machine translation (MT) systems. An indirect hidden Markov model (IHMM) is proposed to address the synonym matching and word ordering issues in hypothesis alignment. Unlike traditional HMMs whose parameters are trained via maximum likelihood estimation (MLE), the parameters of the IHMM are estimated indirectly from a variety of sources including word semantic similarity, word surface similarity, and a distance-based distortion penalty. The IHMM-based method significantly outperforms the state-of-the-art TER-based alignment model in our experiments on NIST benchmark datasets. Our combined SMT system using the proposed method achieved the best Chinese-to-English translation result in the constrained training track of the 2008 NIST Open MT Evaluation."
            },
            "slug": "Indirect-HMM-based-Hypothesis-Alignment-for-Outputs-He-Yang",
            "title": {
                "fragments": [],
                "text": "Indirect-HMM-based Hypothesis Alignment for Combining Outputs from Machine Translation Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "The proposed indirect hidden Markov model (IHMM) is proposed to address the synonym matching and word ordering issues in hypothesis alignment and achieved the best Chinese-to-English translation result in the constrained training track of the 2008 NIST Open MT Evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36037226"
                        ],
                        "name": "R\u00e9jean Ducharme",
                        "slug": "R\u00e9jean-Ducharme",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Ducharme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9jean Ducharme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909943744"
                        ],
                        "name": "Christian Janvin",
                        "slug": "Christian-Janvin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Janvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Janvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 221275765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c2b28f9354f667cd5bd07afc0471d8334430da7",
            "isKey": false,
            "numCitedBy": 6014,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts."
            },
            "slug": "A-Neural-Probabilistic-Language-Model-Bengio-Ducharme",
            "title": {
                "fragments": [],
                "text": "A Neural Probabilistic Language Model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2348067"
                        ],
                        "name": "Changliang Li",
                        "slug": "Changliang-Li",
                        "structuredName": {
                            "firstName": "Changliang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changliang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109511511"
                        ],
                        "name": "Bo Xu",
                        "slug": "Bo-Xu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2236258"
                        ],
                        "name": "Gao-wei Wu",
                        "slug": "Gao-wei-Wu",
                        "structuredName": {
                            "firstName": "Gao-wei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gao-wei Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118418666"
                        ],
                        "name": "Xiuying Wang",
                        "slug": "Xiuying-Wang",
                        "structuredName": {
                            "firstName": "Xiuying",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiuying Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054600543"
                        ],
                        "name": "Wendong Ge",
                        "slug": "Wendong-Ge",
                        "structuredName": {
                            "firstName": "Wendong",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wendong Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152887035"
                        ],
                        "name": "Yan Li",
                        "slug": "Yan-Li",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44904085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "667b91410fc33ef214bc2f13c85c4ae9ac68adce",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector space word representations have gained big success recently at improving performance across various NLP tasks. However, existing word embeddings learning methods only utilize homo-lingual corpus. Inspired by transfer learning, we propose a novel language transfer method to obtain word embeddings via language transfer. Under this method, in order to obtain word embeddings of one language target language, we train models on corpus of another different language source language instead. And then we use the obtained source language word embeddings to represent target language word embeddings. We evaluate the word embeddings obtained by the proposed method on word similarity tasks across several benchmark datasets. And the results show that our method is surprisingly effective, outperforming competitive baselines by a large margin. Another benefit of our method is that the process of collecting new corpus might be skipped."
            },
            "slug": "Obtaining-Better-Word-Representations-via-Language-Li-Xu",
            "title": {
                "fragments": [],
                "text": "Obtaining Better Word Representations via Language Transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a novel language transfer method to obtain word embeddings via language transfer, and shows that the method is surprisingly effective, outperforming competitive baselines by a large margin."
            },
            "venue": {
                "fragments": [],
                "text": "CICLing"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46181066"
                        ],
                        "name": "Iz Beltagy",
                        "slug": "Iz-Beltagy",
                        "structuredName": {
                            "firstName": "Iz",
                            "lastName": "Beltagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iz Beltagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708114"
                        ],
                        "name": "Katrin Erk",
                        "slug": "Katrin-Erk",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Erk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Erk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2361649,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "d0918cdd60bda2a9c3b01cce8f05fe9e0a2111c2",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new approach to semantic parsing that is not constrained by a fixed formal ontology and purely logical inference. Instead, we use distributional semantics to generate only the relevant part of an on-the-fly ontology. Sentences and the on-the-fly ontology are represented in probabilistic logic. For inference, we use probabilistic logic frameworks like Markov Logic Networks (MLN) and Probabilistic Soft Logic (PSL). This semantic parsing approach is evaluated on two tasks, Textual Entitlement (RTE) and Textual Similarity (STS), both accomplished using inference in probabilistic logic. Experiments show the potential of the approach."
            },
            "slug": "Semantic-Parsing-using-Distributional-Semantics-and-Beltagy-Erk",
            "title": {
                "fragments": [],
                "text": "Semantic Parsing using Distributional Semantics and Probabilistic Logic"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This work proposes a new approach to semantic parsing that is not constrained by a fixed formal ontology and purely logical inference, and uses distributional semantics to generate only the relevant part of an on-the-fly ontology."
            },
            "venue": {
                "fragments": [],
                "text": "ACL 2014"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153154477"
                        ],
                        "name": "David Smith",
                        "slug": "David-Smith",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145043214"
                        ],
                        "name": "Jason Eisner",
                        "slug": "Jason-Eisner",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Eisner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Eisner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20977299,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "eb1cc1a15764746bf26e03b0ffd3112c1cbe268b",
            "isKey": false,
            "numCitedBy": 1111,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "Lexical semantics is concerned with inherent aspects of word meaning and the semantic relations between words, as well as the ways in which word meaning is related to syntactic structure. This chapter provides an introduction to some of the main themes in lexical semantic research, including the nature of the mental lexicon, lexical relations, and the decomposition of words into grammatically relevant semantic features. The mapping between the semantics of verbs and their associated syntax is discussed in terms of thematic roles, semantic structure theory, and feature selection. A review of some of the most influential findings in second language research involving both open-class and closed-class lexical items reveals important implications for classroom pedagogy and syllabus design in the domain of vocabulary instruction."
            },
            "slug": "Lexical-Semantics-Smith-Eisner",
            "title": {
                "fragments": [],
                "text": "Lexical Semantics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 Models with larger context windows may learn representations that better capture association, whereas models with narrower windows better reflect similarity (Agirre et al., 2009; Kiela and Clark, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We finish by reviewing existing gold standards, and show that none enables a satisfactory evaluation of the capability of models to capture similarity (2.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2107337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0183b3e9d84c15c7048e6c2149ed86257ccdc6cb",
            "isKey": true,
            "numCitedBy": 834,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "While continuous word embeddings are gaining popularity, current models are based solely on linear contexts. In this work, we generalize the skip-gram model with negative sampling introduced by Mikolov et al. to include arbitrary contexts. In particular, we perform experiments with dependency-based contexts, and show that they produce markedly different embeddings. The dependencybased embeddings are less topical and exhibit more functional similarity than the original skip-gram embeddings."
            },
            "slug": "Dependency-Based-Word-Embeddings-Levy-Goldberg",
            "title": {
                "fragments": [],
                "text": "Dependency-Based Word Embeddings"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The skip-gram model with negative sampling introduced by Mikolov et al. is generalized to include arbitrary contexts, and experiments with dependency-based contexts are performed, showing that they produce markedly different embeddings."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50064811"
                        ],
                        "name": "L. Finkelstein",
                        "slug": "L.-Finkelstein",
                        "structuredName": {
                            "firstName": "Lev",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718798"
                        ],
                        "name": "E. Gabrilovich",
                        "slug": "E.-Gabrilovich",
                        "structuredName": {
                            "firstName": "Evgeniy",
                            "lastName": "Gabrilovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gabrilovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745572"
                        ],
                        "name": "Y. Matias",
                        "slug": "Y.-Matias",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Matias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Matias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747801"
                        ],
                        "name": "E. Rivlin",
                        "slug": "E.-Rivlin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Rivlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rivlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3316511"
                        ],
                        "name": "Zach Solan",
                        "slug": "Zach-Solan",
                        "structuredName": {
                            "firstName": "Zach",
                            "lastName": "Solan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zach Solan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073936"
                        ],
                        "name": "G. Wolfman",
                        "slug": "G.-Wolfman",
                        "structuredName": {
                            "firstName": "Gadi",
                            "lastName": "Wolfman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wolfman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779370"
                        ],
                        "name": "E. Ruppin",
                        "slug": "E.-Ruppin",
                        "structuredName": {
                            "firstName": "Eytan",
                            "lastName": "Ruppin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ruppin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12956853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0c01df98a6b633b25c96c1a99b713ac96f1c5be",
            "isKey": false,
            "numCitedBy": 1725,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Keyword-based search engines are in widespread use today as a popular means for Web-based information retrieval. Although such systems seem deceptively simple, a considerable amount of skill is required in order to satisfy non-trivial information needs. This paper presents a new conceptual paradigm for performing search in context, that largely automates the search process, providing even non-professional users with highly relevant results. This paradigm is implemented in practice in the IntelliZap system, where search is initiated from a text query marked by the user in a document she views, and is guided by the text surrounding the marked query in that document (\"the context\"). The context-driven information retrieval process involves semantic keyword extraction and clustering to automatically generate new, augmented queries. The latter are submitted to a host of general and domain-specific search engines. Search results are then semantically reranked, using context. Experimental results testify that using context to guide search, effectively offers even inexperienced users an advanced search tool on the Web."
            },
            "slug": "Placing-search-in-context:-the-concept-revisited-Finkelstein-Gabrilovich",
            "title": {
                "fragments": [],
                "text": "Placing search in context: the concept revisited"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new conceptual paradigm for performing search in context is presented, that largely automates the search process, providing even non-professional users with highly relevant results."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": false,
            "numCitedBy": 5025,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761880"
                        ],
                        "name": "A. Haghighi",
                        "slug": "A.-Haghighi",
                        "structuredName": {
                            "firstName": "Aria",
                            "lastName": "Haghighi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Haghighi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075292388"
                        ],
                        "name": "P. Liang",
                        "slug": "P.-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400419309"
                        ],
                        "name": "Taylor Berg-Kirkpatrick",
                        "slug": "Taylor-Berg-Kirkpatrick",
                        "structuredName": {
                            "firstName": "Taylor",
                            "lastName": "Berg-Kirkpatrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taylor Berg-Kirkpatrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Models of similarity are particularly applicable to various NLP tasks, such as lexical resource building, semantic parsing, and machine translation (Haghighi et al. 2008; He et al. 2008; Marton, Callison-Burch, and Resnik 2009; Beltagy, Erk, and Mooney 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 165
                            }
                        ],
                        "text": "Models of similarity are particularly applicable to various NLP tasks, such as lexical resource building, semantic parsing and machine translation (He et al., 2008; Haghighi et al., 2008; Marton et al., 2009; Beltagy et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7185434,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3709b6cb2ed14c04b60e38d5f75e89c41317e93d",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for learning bilingual translation lexicons from monolingual corpora. Word types in each language are characterized by purely monolingual features, such as context counts and orthographic substrings. Translations are induced using a generative model based on canonical correlation analysis, which explains the monolingual lexicons in terms of latent matchings. We show that high-precision lexicons can be learned in a variety of language pairs and from a range of corpus types."
            },
            "slug": "Learning-Bilingual-Lexicons-from-Monolingual-Haghighi-Liang",
            "title": {
                "fragments": [],
                "text": "Learning Bilingual Lexicons from Monolingual Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that high-precision lexicons can be learned in a variety of language pairs and from a range of corpus types."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32440409"
                        ],
                        "name": "T. Rose",
                        "slug": "T.-Rose",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Rose",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144795097"
                        ],
                        "name": "Mark Stevenson",
                        "slug": "Mark-Stevenson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Stevenson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Stevenson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068521476"
                        ],
                        "name": "Miles Whitehead",
                        "slug": "Miles-Whitehead",
                        "structuredName": {
                            "firstName": "Miles",
                            "lastName": "Whitehead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miles Whitehead"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9239414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "590cfa38094122f42412d747350229f79b7e6412",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Reuters, the global information, news and technology group, has for the first time made available free of charge, large quantities of archived Reuters news stories for use by research communities around the world. The Reuters Corpus Volume 1 (RCV1) includes over 800,000 news stories typical of the annual English language news output of Reuters. This paper describes the origins of RCV1, the motivations behind its creation, and how it differs from previous corpora. In addition we discuss the system of category coding, whereby each story is annotated for topic, region and industry sector. We also discuss the process by which these codes were applied, and examine the issues involved in maintaining quality and consistency of coding in an operational, commercial environment."
            },
            "slug": "The-Reuters-Corpus-Volume-1-from-Yesterday\u2019s-News-Rose-Stevenson",
            "title": {
                "fragments": [],
                "text": "The Reuters Corpus Volume 1 -from Yesterday\u2019s News to Tomorrow\u2019s Language Resources"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The origins of RCV1, the motivations behind its creation, and how it differs from previous corpora are described, and the system of category coding, whereby each story is annotated for topic, region and industry sector is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762910"
                        ],
                        "name": "X. Phan",
                        "slug": "X.-Phan",
                        "structuredName": {
                            "firstName": "Xuan",
                            "lastName": "Phan",
                            "middleNames": [
                                "Hieu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Phan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789308"
                        ],
                        "name": "Minh Le Nguyen",
                        "slug": "Minh-Le-Nguyen",
                        "structuredName": {
                            "firstName": "Minh",
                            "lastName": "Nguyen",
                            "middleNames": [
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minh Le Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060737928"
                        ],
                        "name": "S. Horiguchi",
                        "slug": "S.-Horiguchi",
                        "structuredName": {
                            "firstName": "Susumu",
                            "lastName": "Horiguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Horiguchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16198890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8907ed38d6f9c56aa406704c7354afd2472d364e",
            "isKey": false,
            "numCitedBy": 769,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general framework for building classifiers that deal with short and sparse text & Web segments by making the most of hidden topics discovered from large-scale data collections. The main motivation of this work is that many classification tasks working with short segments of text & Web, such as search snippets, forum & chat messages, blog & news feeds, product reviews, and book & movie summaries, fail to achieve high accuracy due to the data sparseness. We, therefore, come up with an idea of gaining external knowledge to make the data more related as well as expand the coverage of classifiers to handle future data better. The underlying idea of the framework is that for each classification task, we collect a large-scale external data collection called \"universal dataset\", and then build a classifier on both a (small) set of labeled training data and a rich set of hidden topics discovered from that data collection. The framework is general enough to be applied to different data domains and genres ranging from Web search results to medical text. We did a careful evaluation on several hundred megabytes of Wikipedia (30M words) and MEDLINE (18M words) with two tasks: \"Web search domain disambiguation\" and \"disease categorization for medical text\", and achieved significant quality enhancement."
            },
            "slug": "Learning-to-classify-short-and-sparse-text-&-web-Phan-Nguyen",
            "title": {
                "fragments": [],
                "text": "Learning to classify short and sparse text & web with hidden topics from large-scale data collections"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A general framework for building classifiers that deal with short and sparse text & Web segments by making the most of hidden topics discovered from large-scale data collections that is general enough to be applied to different data domains and genres ranging from Web search results to medical text."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2471378"
                        ],
                        "name": "L. Barsalou",
                        "slug": "L.-Barsalou",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Barsalou",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Barsalou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145632326"
                        ],
                        "name": "W. K. Simmons",
                        "slug": "W.-K.-Simmons",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Simmons",
                            "middleNames": [
                                "Kyle"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. K. Simmons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2896717"
                        ],
                        "name": "A. Barbey",
                        "slug": "A.-Barbey",
                        "structuredName": {
                            "firstName": "Aron",
                            "lastName": "Barbey",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barbey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48515412"
                        ],
                        "name": "Christine D. Wilson",
                        "slug": "Christine-D.-Wilson",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Wilson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christine D. Wilson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 805674,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3f5e922ce20efe7da64c115e5346481cfc618b79",
            "isKey": false,
            "numCitedBy": 1068,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Grounding-conceptual-knowledge-in-modality-specific-Barsalou-Simmons",
            "title": {
                "fragments": [],
                "text": "Grounding conceptual knowledge in modality-specific systems"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Cognitive Sciences"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2546518"
                        ],
                        "name": "D. Plaut",
                        "slug": "D.-Plaut",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Plaut",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Plaut"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 166
                            }
                        ],
                        "text": "In contrast, car and petrol are associated because they frequently occur together in space and language, in this case as a result of a clear functional relationship (Plaut, 1995; McRae et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15573558,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d859f0d4c78bc772b350854cae30e72e5610ce71",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "A distributed attractor network is trained on an abstract version of the task of deriving the meanings of written words. When processing a word, the network starts from the final activity pattern of the previous word. Two words are semantically related if they overlap in their semantic features, whereas they are associatively related if one word follows the other frequently during training. After training, the network exhibits two empirical effects that have posed problems for distributed network theories: much stronger associative priming than semantic priming, and significantassociative priming across an intervening unrelated item. It also reproduces the empirical findingsof greater priming for low-frequency targets, degraded targets, and high-dominance category exemplars."
            },
            "slug": "Semantic-and-Associative-Priming-in-a-Distributed-Plaut",
            "title": {
                "fragments": [],
                "text": "Semantic and Associative Priming in a Distributed Attractor Network"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A distributed attractor network is trained on an abstract version of the task of deriving the meanings of written words and exhibits two empirical effects that have posed problems for distributed network theories: much stronger associative priming than semantic priming, and significant association priming across an intervening unrelated item."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404468069"
                        ],
                        "name": "K. Hirsh-Pasek",
                        "slug": "K.-Hirsh-Pasek",
                        "structuredName": {
                            "firstName": "Kathy",
                            "lastName": "Hirsh-Pasek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hirsh-Pasek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2962767"
                        ],
                        "name": "R. Golinkoff",
                        "slug": "R.-Golinkoff",
                        "structuredName": {
                            "firstName": "Roberta",
                            "lastName": "Golinkoff",
                            "middleNames": [
                                "Michnick"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Golinkoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Gentner (2006) showed that children find verb concepts harder to learn than noun concepts, and Markman and Wisniewski (1997) present evidence that different cognitive operations are employed when com-\nparing two nouns or two verbs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60868956,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "65f271327ac13aa4a945202dfbf9ec37eca82f28",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction: Progress on the Verb Learning Front PART I PREREQUISITES TO VERB LEARNING: FINDING THE VERB 1. Finding the Verbs: Distributional Cues Available to Young Learners 2. Finding Verb Dorms Within the Continuous Speech Stream 3. Discovering Verbs Through Multiple-Cue Integration PART II PREREQUISITES TO VERB LEARNING: FINDING ACTIONS IN EVENTS 4. Actions Organize the Infant's World 5. Conceptual Foundations for Verb Learning: Celebrating the Event 6. Precursors to Verb Learning: Infants' Understanding of Motion Events 7. Preverbal Spatial Cognition and Language-Specific Input: Categories of Containment and Support 8. The Roots of Verbs in Prelinguistic Action Knowledge 9. When Is a Grasp a Grasp? Characterizing Some Basic Components of Human Action Processing 10. Word, Intention, and Action: A Two-Tiered Model of Action Word Learning 11. Verbs, Actions, and Intentions PART III WHEN ACTION MEETS WORD: CHILDREN LEARN THEIR FIRST VERBS 12. Are Nouns Easier to Learn Than Verbs? Three Experimental Studies 13. Verbs at the Very Beginning: Parallels Between Comprehension and Input 14. A Unified Theory of Word Learning: Putting Verb Acquisition in Context 15. Who's the Subject? Sentence Structure and Verb Meaning PART VI HOW LANGUAGE INFLUENCES VERB LEARNING: CROSS-LINGUISTIC EVIDENCE 16. Verb Learning as a Probe Into Children's Grammars 17. Revisiting the Noun-Verb Debate: A Cross-Linguistic Comparison of Novel Noun and Verb Learning in English-, Japanese- and Chinese-Speaking Children 18. But Are They Really Verbs?: Chinese Words for Action 19. Influences of Object Knowledge on the Acquisition of Verbs in English and Japanese 20. East and West: A Role for Culture in the Acquisition of Nouns and Verbs 21. Why Verbs are Hard to Learn"
            },
            "slug": "Action-Meets-Word:-How-Children-Learn-Verbs-Hirsh-Pasek-Golinkoff",
            "title": {
                "fragments": [],
                "text": "Action Meets Word: How Children Learn Verbs"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This chapter discusses Verb Learning as a Probe Into Children's Grammars, a Cross-Linguistic Comparison of Novel Noun and Verb Learning in English-, Japanese- and Chinese-Speaking Children, and Influences of Object Knowledge on the Acquisition of Verbs in English and Japanese."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145435830"
                        ],
                        "name": "H. Cunningham",
                        "slug": "H.-Cunningham",
                        "structuredName": {
                            "firstName": "Hamish",
                            "lastName": "Cunningham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Cunningham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 160
                            }
                        ],
                        "text": "\u2026which is still only marginally better than the best automatic method.6\nThus, at least according to the established wisdom in NLP evaluation (Yong and Foo, 1999; Cunningham, 2005; Resnik and Lin, 2010), the strength of the conclusions that can be inferred from improvements on WS-353 is limited."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 180
                            }
                        ],
                        "text": "It is common practice in NLP to define the upper limit for automated performance on an evaluation as the average human performance or interannotator agreement (Yong and Foo, 1999; Cunningham, 2005; Resnik and Lin, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 71
                            }
                        ],
                        "text": "6 Thus, at least according to the established wisdom in NLP evaluation (Yong and Foo, 1999; Cunningham, 2005; Resnik and Lin, 2010), the strength of the conclusions that can be inferred from improvements on WS-353 is limited."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14977169,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76739f77dd4c58801aecdf74fb718de7ddb87a5c",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-Extraction,-Automatic-Cunningham",
            "title": {
                "fragments": [],
                "text": "Information Extraction, Automatic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2436806"
                        ],
                        "name": "V. Reyna",
                        "slug": "V.-Reyna",
                        "structuredName": {
                            "firstName": "Valerie",
                            "lastName": "Reyna",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Reyna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145070590"
                        ],
                        "name": "S. Chapman",
                        "slug": "S.-Chapman",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "Chapman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chapman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145551351"
                        ],
                        "name": "M. Dougherty",
                        "slug": "M.-Dougherty",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Dougherty",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dougherty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968320"
                        ],
                        "name": "J. Confrey",
                        "slug": "J.-Confrey",
                        "structuredName": {
                            "firstName": "Jere",
                            "lastName": "Confrey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Confrey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141597691,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "db5113ad2da0609d0ad7dee4cd26c94519086c8f",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This multi-authored volume deals with brain development and higher-order cognition in adolescents. The book is a recent release from APA Books, a subsidiary of APA Publications, which is owned and operated by the American Psychological Association (APA). Releases from APA Books span a broad range of topics in psychology and related fields. The vast majority of the books are independent works that do not necessarily represent APA views or policies. Members and affiliates of the organization receive discounts when purchasing books and other publications through the APA. This volume grew out of the Workshop on Higher Cognition in Adolescents and Young Adults: Social, Behavioral, and Biological Influences on Learning, sponsored by the National Science Foundation and held at Cornell University on September 28-30, 2008. The workshop brought together top scholars and scientists with the goal of encouraging interdisciplinary collaboration and inspiring new research initiatives in the field. The timely undertaking drew upon the past 30 years\u2019 increasingly active research in developmental neuroscience. Building on the success of the workshop, and going beyond it, the editors of this book set out to combine the work of basic or foundational scientists and applied researchers to promote an integrated, cutting-edge understanding of adolescent brain development and cognition. The purpose was to advance knowledge of groundbreaking basic science discoveries while relating them to real-life problems and developmental tasks important in the lives of adolescents and young adults. Applications range from issues in practical everyday decision making to the requirements to prepare for and compete in an increasingly complex society and economy that depend on advanced cognitive skills. The book consists of an Introduction and 14 chapters organized into 5 sections. Section I, \u201cFoundations,\u201d has a single chapter focusing on anatomic brain development in normal children and adolescents. The nicely presented material draws from an ongoing longitudinal assessment of brain development conducted at the National Institute of Mental Health since 1989. The >2000 participants, aged 3 to 30 years, have been studied with magnetic resonance imaging, genetic analysis, and neuropsychological testing. This chapter focuses on findings reported on roughly half of the participants who were developing normally. One of the authors\u2019 conclusions is that the massive pruning of gray matter during normal adolescence, coupled with the extensive growth of neural connectivity in the brain, disproves the idea that this is a relatively inactive period of brain development. The next 3 sections present the main body of the book. Section II, \u201cMemory, Meaning, and Representation,\u201d covers semantic and associative relations, the representation and transfer of abstract mathematical concepts, the complementary roles of concrete and symbolic instructional materials, and higher-order strategic gist reasoning. Section III, \u201cLearning, Reasoning, and Problem Solving,\u201d extends the application of developmental neuroscience to learning trajectories, differences in reasoning between mathematical and nonmathematical domains, the continuing plasticity in the adolescent brain allowing experience (including adaptive cognitive training) to promote neural changes, and the beneficial versus disruptive effects of emotion, motivation, and other noncognitive influences on higher cognition. Sections II and III emphasize factors affecting mathematical learning, reasoning, and performance. The editors felt that mathematics was an appropriate subject of emphasis, both because of the relative neglect of math in the general literature on learning and learning disabilities and because of the critical importance of the mastery of math skills in a world increasingly dependent on science and technology. Section IV, \u201cJudgment and Decision Making,\u201d is the one that I liked best. It examines factors influencing judgment and decision making during a developmental period that can have a disproportionate impact on a person\u2019s future health and productivity. This is a time of unprecedented risks but also one of great promise and positive change. The chapters in this section address the roles of different brain regions in processing risks and rewards in decision making, mediated especially by frontostriatal circuitry. The topics covered consider not only adolescents\u2019 judgment about common risks such as drinking and smoking, but also factors that can affect adolescents\u2019 judgment about positive behavior patterns that can promote health and prevent disease. Also considered is a distinction that many parents and educators are all too aware of, namely, that intelligence and rationality are not one and the same. While many of an adolescent\u2019s cognitive skills may be peaking, a myriad of other factors influence the rationality of that adolescent\u2019s decisions. Throughout this section, the authors highlight different theoretical models of adolescent decision making. One of these, the imbalance model, posits the asymmetrical interplay between dual processes: the prefrontal cognitive system, which develops slowly through early adulthood, versus the subcortical reward system, which develops more quickly during adolescence. The imbalance, which can be modified by experience or context, can explain why reward-driven decisions often win out over cognition-based decisions. The book\u2019s closing section is an Epilogue that further highlights The reviewer declares no conflicts of interest. BOOK REVIEW"
            },
            "slug": "The-Adolescent-Brain:-Learning,-Reasoning,-and-Reyna-Chapman",
            "title": {
                "fragments": [],
                "text": "The Adolescent Brain: Learning, Reasoning, and Decision Making"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21308992"
                        ],
                        "name": "Steven Bird",
                        "slug": "Steven-Bird",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Bird",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Bird"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1438450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01a660ec8aa995a88a00bfb41cb86c022047a9db",
            "isKey": false,
            "numCitedBy": 3449,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "NLTK, the Natural Language Toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware. NLTK covers symbolic and statistical natural language processing, and is interfaced to annotated corpora. Students augment and replace existing components, learn structured programming by example, and manipulate sophisticated models from the outset."
            },
            "slug": "NLTK:-The-Natural-Language-Toolkit-Bird",
            "title": {
                "fragments": [],
                "text": "NLTK: The Natural Language Toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "NLTK, the Natural Language Toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware that covers symbolic and statistical natural language processing."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409522235"
                        ],
                        "name": "B.",
                        "slug": "B.",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "B.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B."
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18585288,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2090720f0bd72166dab52fb70c751cc82ad1829a",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "ion and (b) subordinates are similar to other categories at the same level. Thus, it should be difficult to find contrasts for both superordinate and basic-level contrast categories, but easy to find contrasts for subordinate targets."
            },
            "slug": "Similar-and-Different-:-The-Differentiation-of-B.",
            "title": {
                "fragments": [],
                "text": "Similar and Different : The Differentiation of Basic-Level Categories"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145580839"
                        ],
                        "name": "Jimmy J. Lin",
                        "slug": "Jimmy-J.-Lin",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Lin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy J. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 178
                            }
                        ],
                        "text": "\u2026which is still only marginally better than the best automatic method.6\nThus, at least according to the established wisdom in NLP evaluation (Yong and Foo, 1999; Cunningham, 2005; Resnik and Lin, 2010), the strength of the conclusions that can be inferred from improvements on WS-353 is limited."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 198
                            }
                        ],
                        "text": "It is common practice in NLP to define the upper limit for automated performance on an evaluation as the average human performance or interannotator agreement (Yong and Foo, 1999; Cunningham, 2005; Resnik and Lin, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10838676,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "2d0596075f55312568e8b7f69501c517877b826c",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "\u2022 (YDOXDWLRQ LV LWVHOI D ILUVW FODVV UHVHDUFK DFWLYLW\\ FUHDWLRQ RI HIIHFWLYH HYDOXDWLRQ PHWKRGV GULYHV PRUH UDSLG SURJUHVV DQG EHWWHU FRPPXQLFDWLRQ ZLWKLQ D UHVHDUFK FRPPXQLW\\ (Hirschman, 1998:302f) \u2022 >%HIRUH@ WKHUH ZHUH QR FRPPRQ PHDVXUHV DQG QR VKDUHG GDWD $V D FRQVHTXHQFH V\\VWHPV DQG DSSURDFKHV FRXOG QRW EH SUHFLVHO\\ FRPSDUHG DQG UHVXOWV FRXOG QRW EH UHSOLFDWHG (Gaizauskas, 1998:249) Lack of evaluation history"
            },
            "slug": "Evaluation-of-NLP-Systems-Resnik-Lin",
            "title": {
                "fragments": [],
                "text": "Evaluation of NLP Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712211"
                        ],
                        "name": "G. Golub",
                        "slug": "G.-Golub",
                        "structuredName": {
                            "firstName": "Gene",
                            "lastName": "Golub",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Golub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91937307"
                        ],
                        "name": "C. Reinsch",
                        "slug": "C.-Reinsch",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Reinsch",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Reinsch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123532178,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8ae0cbae42a5fb9b340adaed9ed39569eb96b42d",
            "isKey": false,
            "numCitedBy": 2090,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Let A be a real m\u00d7n matrix with m\u2267n. It is well known (cf. [4]) that \n \n$$A = U\\sum {V^T}$$ \n \n(1) \n \nwhere \n \n$${U^T}U = {V^T}V = V{V^T} = {I_n}{\\text{ and }}\\sum {\\text{ = diag(}}{\\sigma _{\\text{1}}}{\\text{,}} \\ldots {\\text{,}}{\\sigma _n}{\\text{)}}{\\text{.}}$$ \n \nThe matrix U consists of n orthonormalized eigenvectors associated with the n largest eigenvalues of AA T , and the matrix V consists of the orthonormalized eigenvectors of A T A. The diagonal elements of \u2211 are the non-negative square roots of the eigenvalues of A T A; they are called singular values. We shall assume that \n \n$${\\sigma _1} \\geqq {\\sigma _2} \\geqq \\cdots \\geqq {\\sigma _n} \\geqq 0.$$ \n \nThus if rank(A)=r, \u03c3 r+1 = \u03c3 r+2=\u22ef=\u03c3 n = 0. The decomposition (1) is called the singular value decomposition (SVD)."
            },
            "slug": "Singular-value-decomposition-and-least-squares-Golub-Reinsch",
            "title": {
                "fragments": [],
                "text": "Singular value decomposition and least squares solutions"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "The decomposition of A is called the singular value decomposition (SVD) and the diagonal elements of \u2211 are the non-negative square roots of the eigenvalues of A T A; they are called singular values."
            },
            "venue": {
                "fragments": [],
                "text": "Milestones in Matrix Computation"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50064811"
                        ],
                        "name": "L. Finkelstein",
                        "slug": "L.-Finkelstein",
                        "structuredName": {
                            "firstName": "Lev",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718798"
                        ],
                        "name": "E. Gabrilovich",
                        "slug": "E.-Gabrilovich",
                        "structuredName": {
                            "firstName": "Evgeniy",
                            "lastName": "Gabrilovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gabrilovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745572"
                        ],
                        "name": "Y. Matias",
                        "slug": "Y.-Matias",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Matias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Matias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747801"
                        ],
                        "name": "E. Rivlin",
                        "slug": "E.-Rivlin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Rivlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rivlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3316511"
                        ],
                        "name": "Zach Solan",
                        "slug": "Zach-Solan",
                        "structuredName": {
                            "firstName": "Zach",
                            "lastName": "Solan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zach Solan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073936"
                        ],
                        "name": "G. Wolfman",
                        "slug": "G.-Wolfman",
                        "structuredName": {
                            "firstName": "Gadi",
                            "lastName": "Wolfman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wolfman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779370"
                        ],
                        "name": "E. Ruppin",
                        "slug": "E.-Ruppin",
                        "structuredName": {
                            "firstName": "Eytan",
                            "lastName": "Ruppin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ruppin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 118
                            }
                        ],
                        "text": "Nevertheless, in what is currently the most popular evaluation gold standard for semantic similarity, WordSim(WS)-353 (Finkelstein et al. 2001), coffee and"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 7
                            }
                        ],
                        "text": "WS-353 (Finkelstein et al. 2001) is perhaps the most commonly used evaluation gold standard for semantic models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 20
                            }
                        ],
                        "text": "WordSim-353 WS-353 (Finkelstein et al., 2001) is perhaps the most commonly-used evaluation gold standard for semantic models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 119
                            }
                        ],
                        "text": "Nevertheless, in what is currently the most popular evaluation gold standard for semantic similarity, WordSim(WS)-353 (Finkelstein et al., 2001), coffee and cup are rated as more \u2018similar\u2019 than pairs such as car and train, which share numerous common properties (function, material, dynamic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52098500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1abbf4914589252348d6e8f1e41e7bbc7b96d476",
            "isKey": true,
            "numCitedBy": 219,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Keyword-based search engines are in widespread use today as a popular means for Web-based information retrieval. Although such systems seem deceptively simple, a considerable amount of skill is required in order to satisfy non-trivial information needs. This paper presents a new conceptual paradigm for performing search in context, that largely automates the search process, providing even non-professional users with highly relevant results. This paradigm is implemented in practice in the IntelliZap system, where search is initiated from a text query marked by the user in a document she views, and is guided by the text surrounding the marked query in that document (\u201cthe context\u201d). The context-driven information retrieval process involves semantic keyword extraction and clustering to automatically generate new, augmented queries. The latter are submitted to a host of general and domain-specific search engines. Search results are then semantically reranked, using context. Experimental results testify that using context to guide search, effectively offers even inexperienced users an advanced search tool on the Web."
            },
            "slug": "Placing-search-in-context:-the-concept-revisited-Finkelstein-Gabrilovich",
            "title": {
                "fragments": [],
                "text": "Placing search in context: the concept revisited"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new conceptual paradigm for performing search in context is presented, that largely automates the search process, providing even non-professional users with highly relevant results."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '01"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 160
                            }
                        ],
                        "text": "\u2026which is still only marginally better than the best automatic method.6\nThus, at least according to the established wisdom in NLP evaluation (Yong and Foo, 1999; Cunningham, 2005; Resnik and Lin, 2010), the strength of the conclusions that can be inferred from improvements on WS-353 is limited."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 180
                            }
                        ],
                        "text": "It is common practice in NLP to define the upper limit for automated performance on an evaluation as the average human performance or interannotator agreement (Yong and Foo, 1999; Cunningham, 2005; Resnik and Lin, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We finish by reviewing existing gold standards, and show that none enables a satisfactory evaluation of the capability of models to capture similarity (2.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information extraction, automatic. Encyclopedia of language and linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Information extraction, automatic. Encyclopedia of language and linguistics"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 178
                            }
                        ],
                        "text": "\u2026which is still only marginally better than the best automatic method.6\nThus, at least according to the established wisdom in NLP evaluation (Yong and Foo, 1999; Cunningham, 2005; Resnik and Lin, 2010), the strength of the conclusions that can be inferred from improvements on WS-353 is limited."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 198
                            }
                        ],
                        "text": "It is common practice in NLP to define the upper limit for automated performance on an evaluation as the average human performance or interannotator agreement (Yong and Foo, 1999; Cunningham, 2005; Resnik and Lin, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We finish by reviewing existing gold standards, and show that none enables a satisfactory evaluation of the capability of models to capture similarity (2.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "11 evaluations of NLP systems. The handbook of computational linguistics and natural language processing"
            },
            "venue": {
                "fragments": [],
                "text": "11 evaluations of NLP systems. The handbook of computational linguistics and natural language processing"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5737624"
                        ],
                        "name": "E. Rosch",
                        "slug": "E.-Rosch",
                        "structuredName": {
                            "firstName": "Eleanor",
                            "lastName": "Rosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rosch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30488219"
                        ],
                        "name": "C. Simpson",
                        "slug": "C.-Simpson",
                        "structuredName": {
                            "firstName": "Carolyn",
                            "lastName": "Simpson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Simpson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144370935"
                        ],
                        "name": "R. S. Miller",
                        "slug": "R.-S.-Miller",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "Miller",
                            "middleNames": [
                                "S"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. S. Miller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 145675134,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "64a5379e98ea882ac189c8a77837d1a4b1274ba3",
            "isKey": false,
            "numCitedBy": 503,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Structural-bases-of-typicality-effects.-Rosch-Simpson",
            "title": {
                "fragments": [],
                "text": "Structural bases of typicality effects."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2473524"
                        ],
                        "name": "A. Paivio",
                        "slug": "A.-Paivio",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Paivio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Paivio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 75
                            }
                        ],
                        "text": "Contrary to what might be expected given established concreteness effects (Paivio, 1991), we observed not only higher inter-rater agreement but also less per-pair variability for abstract rather than concrete concepts11."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 110
                            }
                        ],
                        "text": "On the cognitive side, these \u2018concreteness effects\u2019 are well established, even if the causes are still debated (Paivio, 1991; Hill et al., 2013b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 144200338,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ab64f003fe2fe641a3c8a0c1187d36c04a4718bd",
            "isKey": false,
            "numCitedBy": 1644,
            "numCiting": 107,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Dual-coding-theory:-Retrospect-and-current-status.-Paivio",
            "title": {
                "fragments": [],
                "text": "Dual coding theory: Retrospect and current status."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144191879"
                        ],
                        "name": "J. Firth",
                        "slug": "J.-Firth",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Firth",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Firth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 92
                            }
                        ],
                        "text": "Distributional semantics aims to infer the meaning of words based on the company they keep (Firth, 1957)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Distributional semantics aims to infer the meaning of words based on the company they keep (Firth 1957)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62680330,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "f681847f5b72360f098906261fffd935a04a36ea",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Papers-in-linguistics,-1934-1951-Firth",
            "title": {
                "fragments": [],
                "text": "Papers in linguistics, 1934-1951"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144191879"
                        ],
                        "name": "J. Firth",
                        "slug": "J.-Firth",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Firth",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Firth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 57487592,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "a2fcad1243b6b6dcb4ccff71db50d52fa42fbfae",
            "isKey": false,
            "numCitedBy": 424,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Papers-in-linguistics-Firth",
            "title": {
                "fragments": [],
                "text": "Papers in linguistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1958
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Philipp Cimiano, Andreas Hotho, and Steffen Staab Learning concept hierarchies from text corpora using formal concept analysis"
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif . Intell. Res.(JAIR)"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WordNet"
            },
            "venue": {
                "fragments": [],
                "text": "Wiley Online Library."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 92
                            }
                        ],
                        "text": "Distributional semantics aims to infer the meaning of words based on the company they keep (Firth, 1957)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Papers in Linguistics 19341951"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Predicting the polarity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "11 evaluations of NLP systems"
            },
            "venue": {
                "fragments": [],
                "text": "The handbook of computational linguistics and natural language processing, 57:271."
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 194
                            }
                        ],
                        "text": "C\nL ]\n1 5\nA ug\ntion systems, which aim to define mappings between fragments of different languages whose meaning is similar, but not necessarily associated, are another established application (He et al., 2008; Marton et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "Models of similarity are particularly applicable to various NLP tasks, such as lexical resource building, semantic parsing and machine translation (He et al., 2008; Haghighi et al., 2008; Marton et al., 2009; Beltagy et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 178
                            }
                        ],
                        "text": "tion systems, which aim to define mappings between fragments of different languages whose meaning is similar, but not necessarily associated, are another established application (He et al., 2008; Marton et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Indirecthmm-based hypothesis alignment for combining outputs from machine translation systems"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the Conference on Empirical Methods in Nat-"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 185
                            }
                        ],
                        "text": "To classify potential pairs according to POS, we counted the frequency with which the items in each pair occurred with the three possible tags in the POS-tagged British National Copus (Leech et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Omer and Yoav Goldberg. 2014. Dependency-based word embeddings"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of COLING"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "11 evaluation of nlp systems. The handbook of computational linguistics and natural language processing"
            },
            "venue": {
                "fragments": [],
                "text": "11 evaluation of nlp systems. The handbook of computational linguistics and natural language processing"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 76
                            }
                        ],
                        "text": "Since the essence of association is co-occurrence (linguistic or otherwise (McRae et al., 2012)), such pairs can seem, at least intuitively, to be similar but not strongly associated."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 179
                            }
                        ],
                        "text": "In contrast, car and petrol are associated because they frequently occur together in space and language, in this case as a result of a clear functional relationship (Plaut, 1995; McRae et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantic and associative relations in adolescents and young 693 Downloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00237 by guest on"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "11 evaluation of nlp systems. The handbook of computational linguistics and natural language processing, 57:271"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Witten . 2009 . Mining meaning from Wikipedia"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Human - Computer Studies"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Marius PasPas\u00b8ca, and Aitor Soroa. 2009. A study on similarity and relatedness using distributional and wordnet-based approaches Association for Computational Linguis- tics"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "Association contrasts with similarity, the relation connecting cup and mug (Tversky, 1977)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Features of similarity Learning subjective adjectives from corpora"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1977
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 37,
            "methodology": 19,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 94,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/SimLex-999:-Evaluating-Semantic-Models-With-Hill-Reichart/7a96765c147c9c814803c8c9de28a1dd069271da?sort=total-citations"
}