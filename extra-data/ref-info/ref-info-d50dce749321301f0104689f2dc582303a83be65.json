{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114709889"
                        ],
                        "name": "I. Poujaud",
                        "slug": "I.-Poujaud",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Poujaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Poujaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3078169"
                        ],
                        "name": "L. Personnaz",
                        "slug": "L.-Personnaz",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Personnaz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Personnaz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097910"
                        ],
                        "name": "G. Dreyfus",
                        "slug": "G.-Dreyfus",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Dreyfus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Dreyfus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116525682"
                        ],
                        "name": "Y. Le Cun",
                        "slug": "Y.-Le-Cun",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Le Cun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Le Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 90
                            }
                        ],
                        "text": "Pairwise Linear Classi er: A simple improvement of the basic linear classi er was tested (Guyon et al. 89)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2093637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "590bd948e06e9d07e305fe175c2a86d751ccac2d",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An evaluation is made of several neural network classifiers, comparing their performance on a typical problem, namely handwritten digit recognition. For this purpose, the authors use a database of handwritten digits, with relatively uniform handwriting styles. The authors propose a novel way of organizing the network architectures by training several small networks so as to deal separately with subsets of the problem, and then combining the results. This approach works in conjunction with various techniques including: layered networks with one or several layers of adaptive connections, fully connected recursive networks, ad hoc networks with no adaptive connections, and architectures with second-degree polynomial decision surfaces.<<ETX>>"
            },
            "slug": "Comparing-different-neural-network-architectures-Guyon-Poujaud",
            "title": {
                "fragments": [],
                "text": "Comparing different neural network architectures for classifying handwritten digits"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The authors propose a novel way of organizing the network architectures by training several small networks so as to deal separately with subsets of the problem, and then combining the results."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 67
                            }
                        ],
                        "text": "These considerations lead us to the idea of convolutional network (LeCun et al. 90)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2542741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86ab4cae682fbd49c5a5bedb630e5a40fa7529f6",
            "isKey": false,
            "numCitedBy": 2930,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "slug": "Handwritten-Digit-Recognition-with-a-Network-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Handwritten Digit Recognition with a Back-Propagation Network"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task, and has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 206
                            }
                        ],
                        "text": "Tangent Distance Classi er (TDC): The Tangent Distance classi er (TDC) is a nearest-neighbor method where the distance function is made insensitive to small distortions and translations of the input image (Simard et al. 93)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11382731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8314dda1ec43ce57ff877f8f02ed89acb68ca035",
            "isKey": false,
            "numCitedBy": 581,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Memory-based classification algorithms such as radial basis functions or K-nearest neighbors typically rely on simple distances (Euclidean, dot product...), which are not particularly meaningful on pattern vectors. More complex, better suited distance measures are often expensive and rather ad-hoc (elastic matching, deformable templates). We propose a new distance measure which (a) can be made locally invariant to any set of transformations of the input and (b) can be computed efficiently. We tested the method on large handwritten character databases provided by the Post Office and the NIST. Using invariances with respect to translation, rotation, scaling, shearing and line thickness, the method consistently outperformed all other systems tested on the same databases."
            },
            "slug": "Efficient-Pattern-Recognition-Using-a-New-Distance-Simard-LeCun",
            "title": {
                "fragments": [],
                "text": "Efficient Pattern Recognition Using a New Transformation Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new distance measure which can be made locally invariant to any set of transformations of the input and can be computed efficiently is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050470845"
                        ],
                        "name": "H. Drucker",
                        "slug": "H.-Drucker",
                        "structuredName": {
                            "firstName": "Harris",
                            "lastName": "Drucker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 76
                            }
                        ],
                        "text": "Boosted LeNet 4: Following theoretical work by R. Schapire, Drucker et al. (Drucker et al 93) developed the \\boosting\" method for combining multiple classi ers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33515643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "843ffb9898cedf899ddcdb9c4bdd10881c122429",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A boosting algorithm, based on the probably approximately correct (PAC) learning model is used to construct an ensemble of neural networks that significantly improves performance (compared to a single network) in optical character recognition (OCR) problems. The effect of boosting is reported on four handwritten image databases consisting of 12000 digits from segmented ZIP Codes from the United States Postal Service and the following from the National Institute of Standards and Technology: 220000 digits, 45000 upper case letters, and 45000 lower case letters. We use two performance measures: the raw error rate (no rejects) and the reject rate required to achieve a 1% error rate on the patterns not rejected. Boosting improved performance significantly, and, in some cases, dramatically."
            },
            "slug": "Boosting-Performance-in-Neural-Networks-Drucker-Schapire",
            "title": {
                "fragments": [],
                "text": "Boosting Performance in Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The boosting algorithm is used to construct an ensemble of neural networks that significantly improves performance (compared to a single network) in optical character recognition (OCR) problems and improved performance significantly, and, in some cases, dramatically."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97914531"
                        ],
                        "name": "E. Sackinger",
                        "slug": "E.-Sackinger",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Sackinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sackinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775043"
                        ],
                        "name": "H. Graf",
                        "slug": "H.-Graf",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Graf",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Graf"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 952197,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2235a16dd55b44213961dba94f26fd7c3250efbd",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A mixed analog/digital chip (ANNA) for fast 2-d convolution and matrix-vector multiplication has been developed (peak speed 20,000 MOPS). Two of these chips have been integrated on a 6U VME board, to serve as a high-speed platform for a wide variety of algorithms used in neural-network applications as well as in image analysis. The system has been tested for such tasks as character recognition, noise removal, and text location as well as for emulating cellular neural networks (CNN). A sustained speed of up to 2 billion connections per second (GC/s) and a recognition speed of 1000 characters per second with a sophisticated neural network has been measured."
            },
            "slug": "A-system-for-high-speed-pattern-recognition-and-Sackinger-Graf",
            "title": {
                "fragments": [],
                "text": "A system for high-speed pattern recognition and image analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A mixed analog/digital chip (ANNA) for fast 2-d convolution and matrix-vector multiplication has been developed and integrated on a 6U VME board, to serve as a high-speed platform for a wide variety of algorithms used in neural-network applications as well as in image analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Microelectronics for Neural Networks and Fuzzy Systems"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 26
                            }
                        ],
                        "text": "Boser, Guyon, and Vapnik (Boser et al. 92) realized that any polynomial of degree k in this \\maximummargin\" set can be computed by rst computing the dot product of the input image with a subset of the training samples (called the \\support vectors\"), elevating the result to the k-th power, and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 75
                            }
                        ],
                        "text": "Using a version of the procedure, known as Soft Margin Classi er (Cortes & Vapnik 95) that is well suited for noisy problems, with a 4-th degree decision surface, a test error of 1.1% was reached."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Boser, Guyon, and Vapnik (Boser et al. 92) realized that any polynomial of degree k in this \\maximummargin\" set can be computed by rst computing the dot product of the input image with a subset of the training samples (called the \\support vectors\"), elevating the result to the k-th power, and linearly combining the numbers thereby obtained."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 133
                            }
                        ],
                        "text": "We replaced the last layer of LeNet4 with a Euclidean Nearest Neighbor classi er, and with the \\local learning\" method of Bottou and Vapnik, in which a local linear classi er is retrained each time a new test pattern is shown."
                    },
                    "intents": []
                }
            ],
            "corpusId": 207165665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2599131a4bc2fa957338732a37c744cfe3e17b24",
            "isKey": true,
            "numCitedBy": 10839,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms."
            },
            "slug": "A-training-algorithm-for-optimal-margin-classifiers-Boser-Guyon",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented, applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122946816"
                        ],
                        "name": "Schurmann",
                        "slug": "Schurmann",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Schurmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Schurmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 70
                            }
                        ],
                        "text": "Principal Component Analysis and Polynomial Classi er: Following (Sch urmann 78), a preprocessing stage was constructed which computes the projection of the input pattern on the 40 principal components of the set of training vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11270671,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46b3764436e54ec10fdf14f31c544599456385d9",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the basic design principles of a multifont word recognition system developed for postal address reading. Of the three main subsystems, image preprocessing, single character recognition, and contextual postprocessing, the last two will be considered in detail. A multiple-channel/multiple-choice approach is taken in designing the overall system. The character images produced by the image preprocessing subsystem are fed into three parallel single character recognition (SCR) channels. Each channel classifies the raster image according to one of the three character types: capital letter, small letter, or numeral. A second degree polynomial classifier is required in order to satisfy the multifont requirements of address reading. Each SCR channel outputs a rank-ordered list of potential character meanings for the character type being processed and a channel-specific figure of confidence. This figure of confidence serves a twofold purpose. First, it is used to determine the number of alternatives in the rank-ordered list, and secondly, it is used by the subsequent contextual postprocessor in calculating a word-specific discriminant function designed to discriminate between four different kinds of words: numeric, all upper case, all lower case, and lower case with upper case initial. Based on this discriminant function for every character position, only one channel output is passed on to-the word recognition system. From the list of alternatives for each character position, a set of alternative words can be constructed which, with a high probability, contains the correct word."
            },
            "slug": "A-Multifont-Word-Recognition-System-for-Postal-Schurmann",
            "title": {
                "fragments": [],
                "text": "A Multifont Word Recognition System for Postal Address Reading"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The basic design principles of a multifont word recognition system developed for postal address reading are described, with a multiple-channel/multiple-choice approach taken in designing the overall system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 61
                            }
                        ],
                        "text": "The de ciencies of the linear classi er are well documented (Duda\n& Hart 73) and it is included here simply to form a basis of comparison for more sophisticated classi ers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16926,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 26
                            }
                        ],
                        "text": "Boser, Guyon, and Vapnik (Boser et al. 92) realized that any polynomial of degree k in this \\maximummargin\" set can be computed by rst computing the dot product of the input image with a subset of the training samples (called the \\support vectors\"), elevating the result to the k-th power, and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 75
                            }
                        ],
                        "text": "Using a version of the procedure, known as Soft Margin Classi er (Cortes & Vapnik 95) that is well suited for noisy problems, with a 4-th degree decision surface, a test error of 1.1% was reached."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Boser, Guyon, and Vapnik (Boser et al. 92) realized that any polynomial of degree k in this \\maximummargin\" set can be computed by rst computing the dot product of the input image with a subset of the training samples (called the \\support vectors\"), elevating the result to the k-th power, and linearly combining the numbers thereby obtained."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 133
                            }
                        ],
                        "text": "We replaced the last layer of LeNet4 with a Euclidean Nearest Neighbor classi er, and with the \\local learning\" method of Bottou and Vapnik, in which a local linear classi er is retrained each time a new test pattern is shown."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A T r aining Algorithm for Optimal Margin Classiers"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fifth Annual Workshop on Computational Learning Theory"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 66
                            }
                        ],
                        "text": "Using a version of the procedure, known as Soft Margin Classi er (Cortes & Vapnik 95) that is well suited for noisy problems, with a 4-th degree decision surface, a test error of 1.1% was reached."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Soft Margin Classier"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 66
                            }
                        ],
                        "text": "Using a version of the procedure, known as Soft Margin Classi er (Cortes & Vapnik 95) that is well suited for noisy problems, with a 4-th degree decision surface, a test error of 1.1% was reached."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Soft Margin Classiier"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 67
                            }
                        ],
                        "text": "These considerations lead us to the idea of convolutional network (LeCun et al. 90)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten digit recognition with a back-propagation network, in D"
            },
            "venue": {
                "fragments": [],
                "text": "Touretzky (ed), Advances in Neural Information Processing Systems"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparing Di erent Neural Net Architectures for Classifying HandwrittenDigits"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local Learning Algorithms Neural Computation"
            },
            "venue": {
                "fragments": [],
                "text": "Local Learning Algorithms Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 76
                            }
                        ],
                        "text": "Boosted LeNet 4: Following theoretical work by R. Schapire, Drucker et al. (Drucker et al 93) developed the \\boosting\" method for combining multiple classi ers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boosting Performance in Neural Networks, International"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Pattern Recognition and Arti cial Intelligence"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten digit recognition with a backpropagationnetwork"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information ProcessingSystems"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 42
                            }
                        ],
                        "text": "Radial Basis Function Network: Following (Lee 91), an RBF network was constructed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten Digit Recognition using K-Nearest Neighbor, RadialBasis Functions, and Backpropagation"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks, Neural Computation,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 42
                            }
                        ],
                        "text": "Radial Basis Function Network: Following (Lee 91), an RBF network was constructed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten Digit Recognition using K-Nearest Neighbor, Radial-Basis Functions, and Backpropagation Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Comparison-of-learning-algorithms-for-handwritten-LeCun-Jackel/d50dce749321301f0104689f2dc582303a83be65?sort=total-citations"
}