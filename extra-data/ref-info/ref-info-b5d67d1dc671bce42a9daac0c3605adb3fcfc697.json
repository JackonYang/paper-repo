{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 70
                            }
                        ],
                        "text": "Smolensky (1990) proposed the use of tensor products as a means of binding one vector to another."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 34
                            }
                        ],
                        "text": "We refer the interested reader to Pad\u0301o and Lapata (2007) for a comprehensive overview.\ntion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7747235,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "7441116c5b5a745708a9d7c5aa0ecf04e0c76c93",
            "isKey": false,
            "numCitedBy": 695,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, vector-based semantic space models use word co-occurrence counts from large corpora to represent lexical meaning. In this article we present a novel framework for constructing semantic spaces that takes syntactic relations into account. We introduce a formalization for this class of models, which allows linguistic knowledge to guide the construction process. We evaluate our framework on a range of tasks relevant for cognitive science and natural language processing: semantic priming, synonymy detection, and word sense disambiguation. In all cases, our framework obtains results that are comparable or superior to the state of the art."
            },
            "slug": "Dependency-Based-Construction-of-Semantic-Space-Pad\u00f3-Lapata",
            "title": {
                "fragments": [],
                "text": "Dependency-Based Construction of Semantic Space Models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This article presents a novel framework for constructing semantic spaces that takes syntactic relations into account, and introduces a formalization for this class of models, which allows linguistic knowledge to guide the construction process."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18542790,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d23485f88032bf5db0c0360f1f8c1060c00126af",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The way we model semantic similarity is closely tied to our understanding of linguistic representations. We present several models of semantic similarity, based on differing rep- resentational assumptions, and investigate their properties via comparison with human ratings of verb similarity. The results offer insight into the bases for human similarity judgments and provide a testbed for further investigation of the interactions among syntactic properties, semantic structure, and semantic content."
            },
            "slug": "Measuring-Verb-Similarity-Resnik-Diab",
            "title": {
                "fragments": [],
                "text": "Measuring Verb Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Several models of semantic similarity are presented, based on differing rep- resentational assumptions, and their properties are investigated via comparison with human ratings of verb similarity to offer insight into the bases for human similarity judgments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145465286"
                        ],
                        "name": "Timothy Baldwin",
                        "slug": "Timothy-Baldwin",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Baldwin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Baldwin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47473549"
                        ],
                        "name": "Colin Bannard",
                        "slug": "Colin-Bannard",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Bannard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Colin Bannard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49125917"
                        ],
                        "name": "Takaaki Tanaka",
                        "slug": "Takaaki-Tanaka",
                        "structuredName": {
                            "firstName": "Takaaki",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takaaki Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802811"
                        ],
                        "name": "D. Widdows",
                        "slug": "D.-Widdows",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Widdows",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Widdows"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 125
                            }
                        ],
                        "text": "Such an approach may be better suited to modeling non-compositional structures that are lexicalized and frequently occurring (Baldwin et al., 2003; Bannard et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1695436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0756f5cb5ae444d153734edf68d1ce9b95a96d1a",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a construction-inspecific model of multiword expression decomposability based on latent semantic analysis. We use latent semantic analysis to determine the similarity between a multiword expression and its constituent words, and claim that higher similarities indicate greater decomposability. We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet. Based on mean hyponymy over partitions of data ranked on similarity, we furnish evidence for the calculated similarities being correlated with the semantic relational content of WordNet."
            },
            "slug": "An-Empirical-Model-of-Multiword-Expression-Baldwin-Bannard",
            "title": {
                "fragments": [],
                "text": "An Empirical Model of Multiword Expression Decomposability"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A construction-inspecific model of multiword expression decomposability based on latent semantic analysis is presented, and evidence is furnished for the calculated similarities being correlated with the semantic relational content of WordNet."
            },
            "venue": {
                "fragments": [],
                "text": "ACL 2003"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 182
                            }
                        ],
                        "text": "The technique is a special case of n-fold cross-validation (Weiss & Kulikowski, 1991) and has been previously used for measuring how well humans agree on judging semantic similarity (Resnik & Diab, 2000; Resnik, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7872315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e89ac6de1ed1c63f26168b1afea9b64e0c766f4",
            "isKey": false,
            "numCitedBy": 2273,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a measure of semantic similarity in an IS-A taxonomy based on the notion of shared information content. Experimental evaluation against a benchmark set of human similarity judgments demonstrates that the measure performs better than the traditional edge-counting approach. The article presents algorithms that take advantage of taxonomic similarity in resolving syntactic and semantic ambiguity, along with experimental results demonstrating their effectiveness."
            },
            "slug": "Semantic-Similarity-in-a-Taxonomy:-An-Measure-and-Resnik",
            "title": {
                "fragments": [],
                "text": "Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This article presents a measure of semantic similarity in an IS-A taxonomy based on the notion of shared information content that performs better than the traditional edge-counting approach."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50419262"
                        ],
                        "name": "S. Pulman",
                        "slug": "S.-Pulman",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pulman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pulman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2280191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73e897104540642698321c106cc9c35af369fe12",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The are two main approaches to the representation of meaning in Computational Linguistics: a symbolic approach and a distributional approach. This paper considers the fundamental question of how these approaches might be combined. The proposal is to adapt a method from the Cognitive Science literature, in which symbolic and connectionist representations are combined using tensor products. Possible applications of this method for language processing are described. Finally, a potentially fruitful link between Quantum Mechanics, Computational Linguistics, and other related areas such as Information Retrieval and Machine Learning, is proposed."
            },
            "slug": "Combining-Symbolic-and-Distributional-Models-of-Clark-Pulman",
            "title": {
                "fragments": [],
                "text": "Combining Symbolic and Distributional Models of Meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method is to be adapted from the Cognitive Science literature, in which symbolic and connectionist representations are combined using tensor products, to adapt a method for language processing."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI Spring Symposium: Quantum Interaction"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326718"
                        ],
                        "name": "B. Coecke",
                        "slug": "B.-Coecke",
                        "structuredName": {
                            "firstName": "Bob",
                            "lastName": "Coecke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Coecke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80045331"
                        ],
                        "name": "Mehrnoosh",
                        "slug": "Mehrnoosh",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Mehrnoosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mehrnoosh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 70
                            }
                        ],
                        "text": "So, if we assume that only theith components ofu andv contribute to theith component ofp, that these components are not dependent oni, and that the function is symmetric with regard to the interchange ofu\nandv, we obtain a simpler instantiation of an additive model:\npi = ui +vi (5)\nAnalogously,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Under this framework, we introduce novel composition models which we compare empirically against previous work using a rigorous evaluation methodology."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 66
                            }
                        ],
                        "text": "Figure 3 shows the distribution of estimated similarities under the multiplicative model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15293885,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f86ef3e7b856d61ade62e643d87d288fef8827dd",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a mathematical framework for a unification of the distributional theory of meaning in terms of vector space models, and a compositional theory for grammatical types, namely Lambek\u2019s pregroup semantics. A key observation is that the monoidal category of (finite dimensional) vector spaces, linear maps and the tensor product, as well as any pregroup, are examples of compact closed categories. Since, by definition, a pregroup is a compact closed category with trivial morphisms, its compositional content is reflected within the compositional structure of any non-degenerate compact closed category. The (slightly refined) category of vector spaces enables us to compute the meaning of a compound well-typed sentence from the meaning of its constituents, by \u2018lifting\u2019 the type reduction mechanisms of pregroup semantics to the whole category. These sentence meanings live in a single space, independent of the grammatical structure of the sentence. Hence we can use the inner-product to compare meanings of arbitrary sentences. A variation of this procedure which involves constraining the scalars of the vector spaces to the semiring of Booleans results in the well-known Montague semantics."
            },
            "slug": "A-Compositional-Distributional-Model-of-Meaning-Clark-Coecke",
            "title": {
                "fragments": [],
                "text": "A Compositional Distributional Model of Meaning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40591835"
                        ],
                        "name": "K. Lund",
                        "slug": "K.-Lund",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50611682"
                        ],
                        "name": "C. Burgess",
                        "slug": "C.-Burgess",
                        "structuredName": {
                            "firstName": "Curt",
                            "lastName": "Burgess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burgess"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 93
                            }
                        ],
                        "text": "In cognitive science vector-based models have been successful in simulating semantic priming (Lund and Burgess, 1996; Landauer and Dumais, 1997) and text comprehension (Landauer and Dumais, 1997; Foltz et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 37
                            }
                        ],
                        "text": "Vector-based models of word meaning (Lund and Burgess, 1996; Landauer and Dumais, 1997) have become increasingly popular in natural language processing (NLP) and cognitive science."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 94
                            }
                        ],
                        "text": "In cognitive science vector-based models have been successful in simulating semantic priming (Lund and Burgess, 1996; Landauer and Dumais, 1997) and text comprehension (Landauer and Dumais, 1997; Foltz et al.,\n1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61090106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7093913b4daa0f34d9d58a41ceb0475cc3cc9f4",
            "isKey": false,
            "numCitedBy": 1721,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A procedure that processes a corpus of text and produces numeric vectors containing information about its meanings for each word is presented. This procedure is applied to a large corpus of natural language text taken from Usenet, and the resulting vectors are examined to determine what information is contained within them. These vectors provide the coordinates in a high-dimensional space in which word relationships can be analyzed. Analyses of both vector similarity and multidimensional scaling demonstrate that there is significant semantic information carried in the vectors. A comparison of vector similarity with human reaction times in a single-word priming experiment is presented. These vectors provide the basis for a representational model of semantic memory, hyperspace analogue to language (HAL)."
            },
            "slug": "Producing-high-dimensional-semantic-spaces-from-Lund-Burgess",
            "title": {
                "fragments": [],
                "text": "Producing high-dimensional semantic spaces from lexical co-occurrence"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A procedure that processes a corpus of text and produces numeric vectors containing information about its meanings for each word, which provide the basis for a representational model of semantic memory, hyperspace analogue to language (HAL)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095398"
                        ],
                        "name": "Alexander Budanitsky",
                        "slug": "Alexander-Budanitsky",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Budanitsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Budanitsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145036961"
                        ],
                        "name": "Graeme Hirst",
                        "slug": "Graeme-Hirst",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Hirst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graeme Hirst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40770371"
                        ],
                        "name": "K. Alcock",
                        "slug": "K.-Alcock",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Alcock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Alcock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072593976"
                        ],
                        "name": "Jiang\u2014 Conrath",
                        "slug": "Jiang\u2014-Conrath",
                        "structuredName": {
                            "firstName": "Jiang\u2014",
                            "lastName": "Conrath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiang\u2014 Conrath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 132
                            }
                        ],
                        "text": "We selected Jiang and Conrath\u2019s measure since it has been shown to perform consistently well across several cognitive and NLP tasks (Budanitsky and Hirst, 2001).\nglowed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We selected Jiang and Conrath\u2019s measure since it has been shown to perform consistently well across several cognitive and NLP tasks (Budanitsky and Hirst, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14764558,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6db4e86e6377cd703aaaf3a3b471b62e033757ae",
            "isKey": false,
            "numCitedBy": 916,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Five different proposed measures of similarity or semantic distance in WordNet were experimentally compared by examining their performance in a real-word spelling correction system. It was found that Jiang and Conrath\u2019s measure gave the best results overall. That of Hirst and St-Onge seriously over-related, that of Resnik seriously under-related, and those of Lin and of Leacock and Chodorow fell in between."
            },
            "slug": "Semantic-distance-in-WordNet:-An-experimental,-of-Budanitsky-Hirst",
            "title": {
                "fragments": [],
                "text": "Semantic distance in WordNet: An experimental, application-oriented evaluation of five measures"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Five different proposed measures of similarity or semantic distance in WordNet were experimentally compared by examining their performance in a real-word spelling correction system and found that Jiang and Conrath\u2019s measure gave the best results overall."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145632116"
                        ],
                        "name": "N. Coccaro",
                        "slug": "N.-Coccaro",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Coccaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Coccaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 127
                            }
                        ],
                        "text": "NLP tasks that could benefit from composition models include paraphrase identification and context-dependent language modeling (Coccaro and Jurafsky, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13185450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b888cae7e6e288b108f9d119fc23b84b4d447029",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a number of techniques designed to help integrate semantic knowledge with N-gram language models for automatic speech recognition. Our techniques allow us to integrate Latent Semantic Analysis (LSA), a word-similarity algorithm based on word co-occurrence information, with N-gram models. While LSA is good at predicting content words which are coherent with the rest of a text, it is a bad predictor of frequent words, has a low dynamic range, and is inaccurate when combined linearly with N-grams. We show that modifying the dynamic range, applying a per-word con \ufb01 dence metric, and using geometric rather than linear combinations with N-grams produces a more robust language model which has a lower perplexity on a Wall Street Journal test-set than a baseline N-gram model."
            },
            "slug": "Towards-better-integration-of-semantic-predictors-Coccaro-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Towards better integration of semantic predictors in statistical language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that modifying the dynamic range, applying a per-word con \ufb01 dence metric, and using geometric rather than linear combinations with N-grams produces a more robust language model which has a lower perplexity on a Wall Street Journal test-set than a baseline N- gram model."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802811"
                        ],
                        "name": "D. Widdows",
                        "slug": "D.-Widdows",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Widdows",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Widdows"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12044606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c69a90236f1c57348de858918c554a9420f1521",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic vector models have proven their worth in a number of natural language applications whose goals can be accomplished by modelling individual semantic concepts and measuring similarities between them. By comparison, the area of semantic compositionality in these models has so far remained underdeveloped. This will be a crucial hurdle for semantic vector models: in order to play a fuller part in the modelling of human language, these models will need some way of modelling the way in which single concepts are put together to form more complex conceptual structures. This paper explores some of the opportunities for using vector product operations to model compositional phenomena in natural language. These vector operations are all well-known and used in mathematics and physics, particularly in quantum mechanics. Instead of designing new vector composition operators, this paper gathers a list of existing operators, and a list of typical composition operations in natural language, and describes two small experiments that begin to investigate the use of certain vector operators to model certain"
            },
            "slug": "Semantic-Vector-Products:-Some-Initial-Widdows",
            "title": {
                "fragments": [],
                "text": "Semantic Vector Products: Some Initial Investigations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper gathers a list of existing operators, an list of typical composition operations in natural language, and describes two small experiments that begin to investigate the use of certain vector operators to model certain compositional phenomena innatural language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708425"
                        ],
                        "name": "Jay J. Jiang",
                        "slug": "Jay-J.-Jiang",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Jiang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jay J. Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075147"
                        ],
                        "name": "D. Conrath",
                        "slug": "D.-Conrath",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Conrath",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Conrath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Specifically, they belonged to different synsets and were maximally dissimilar as measured by the  Jiang and Conrath (1997)  measure.3"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1359050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b64e068a8face2540fc436af40dbcd2b0912bbf",
            "isKey": false,
            "numCitedBy": 3339,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach for measuring semantic similarity/distance between words and concepts. It combines a lexical taxonomy structure with corpus statistical information so that the semantic distance between nodes in the semantic space constructed by the taxonomy can be better quantified with the computational evidence derived from a distributional analysis of corpus data. Specifically, the proposed measure is a combined approach that inherits the edge-based approach of the edge counting scheme, which is then enhanced by the node-based approach of the information content calculation. When tested on a common data set of word pair similarity ratings, the proposed approach outperforms other computational models. It gives the highest correlation value (r = 0.828) with a benchmark based on human similarity judgements, whereas an upper bound (r = 0.885) is observed when human subjects replicate the same task."
            },
            "slug": "Semantic-Similarity-Based-on-Corpus-Statistics-and-Jiang-Conrath",
            "title": {
                "fragments": [],
                "text": "Semantic Similarity Based on Corpus Statistics and Lexical Taxonomy"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper presents a new approach for measuring semantic similarity/distance between words and concepts that combines a lexical taxonomy structure with corpus statistical information so that the semantic distance between nodes in the semantic space constructed by the taxonomy can be better quantified with the computational evidence derived from a distributional analysis of corpus data."
            },
            "venue": {
                "fragments": [],
                "text": "ROCLING/IJCLCLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Under this framework, we introduce novel composition models which we compare empirically against previous work using a rigorous evaluation methodology."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15698938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd1901f34cc3673072264104885d70555b1a4cdc",
            "isKey": false,
            "numCitedBy": 1928,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Bootstrapping semantics from text is one of the greatest challenges in natural language learning. We first define a word similarity measure based on the distributional pattern of words. The similarity measure allows us to construct a thesaurus using a parsed corpus. We then present a new evaluation methodology for the automatically constructed thesaurus. The evaluation results show that the thesaurus is significantly closer to WordNet than Roget Thesaurus is."
            },
            "slug": "Automatic-Retrieval-and-Clustering-of-Similar-Words-Lin",
            "title": {
                "fragments": [],
                "text": "Automatic Retrieval and Clustering of Similar Words"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A word similarity measure based on the distributional pattern of words allows the automatically constructed thesaurus to be significantly closer to WordNet than Roget Thesaurus is."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47473549"
                        ],
                        "name": "Colin Bannard",
                        "slug": "Colin-Bannard",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Bannard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Colin Bannard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145465286"
                        ],
                        "name": "Timothy Baldwin",
                        "slug": "Timothy-Baldwin",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Baldwin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Baldwin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1876168"
                        ],
                        "name": "A. Lascarides",
                        "slug": "A.-Lascarides",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Lascarides",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lascarides"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 125
                            }
                        ],
                        "text": "Such an approach may be better suited to modeling non-compositional structures that are lexicalized and frequently occurring (Baldwin et al., 2003; Bannard et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2356182,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "7feb6ba5666a5b106c5c141c4356587164d15614",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a distributional approach to the semantics of verb-particle constructions (e.g. put up, make off). We report first on a framework for implementing and evaluating such models. We then go on to report on the implementation of some techniques for using statistical models acquired from corpus data to infer the meaning of verb-particle constructions."
            },
            "slug": "A-Statistical-Approach-to-the-Semantics-of-Bannard-Baldwin",
            "title": {
                "fragments": [],
                "text": "A Statistical Approach to the Semantics of Verb-Particles"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A distributional approach to the semantics of verb-particle constructions (e.g. put up, make off) is described and some techniques for using statistical models acquired from corpus data to infer the meaning of verbs are reported on."
            },
            "venue": {
                "fragments": [],
                "text": "ACL 2003"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5715561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "509a2ca90a85c62d66a16b37e0de28715dd4e89f",
            "isKey": false,
            "numCitedBy": 1014,
            "numCiting": 140,
            "paperAbstract": {
                "fragments": [],
                "text": "Processing language requires the retrieval of concepts from memory in response to an ongoing stream of information. This retrieval is facilitated if one can infer the gist of a sentence, conversation, or document and use that gist to predict related concepts and disambiguate words. This article analyzes the abstract computational problem underlying the extraction and use of gist, formulating this problem as a rational statistical inference. This leads to a novel approach to semantic representation in which word meanings are represented in terms of a set of probabilistic topics. The topic model performs well in predicting word association and the effects of semantic association and ambiguity on a variety of language-processing and memory tasks. It also provides a foundation for developing more richly structured statistical models of language, as the generative process assumed in the topic model can easily be extended to incorporate other kinds of semantic and syntactic structure."
            },
            "slug": "Topics-in-semantic-representation.-Griffiths-Steyvers",
            "title": {
                "fragments": [],
                "text": "Topics in semantic representation."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This article analyzes the abstract computational problem underlying the extraction and use of gist, formulating this problem as a rational statistical inference that leads to a novel approach to semantic representation in which word meanings are represented in terms of a set of probabilistic topics."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 45
                            }
                        ],
                        "text": "In the following we describe our data collection procedure and give details on how our composition models were constructed and evaluated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15246663,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "289d3a9562f57d0182d1aae9376b0e3793d80272",
            "isKey": false,
            "numCitedBy": 3132,
            "numCiting": 105,
            "paperAbstract": {
                "fragments": [],
                "text": "Publisher Summary This chapter discusses data concerning the time course of word identification in a discourse context. A simulation of arithmetic word-problem understanding provides a plausible account for some well-known phenomena. The current theories use representations with several mutually constraining layers. There is typically a linguistic level of representation, conceptual levels to represent both the local and global meaning and structure of a text, and a level at which the text itself has lost its individuality and its information content. Knowledge provides part of the context within which a discourse interpreted. The integration phase is the price the model pays for the necessary flexibility in the construction process."
            },
            "slug": "The-role-of-knowledge-in-discourse-comprehension:-a-Kintsch",
            "title": {
                "fragments": [],
                "text": "The role of knowledge in discourse comprehension: a construction-integration model."
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This chapter discusses data concerning the time course of word identification in a discourse context and a simulation of arithmetic word-problem understanding provides a plausible account for some well-known phenomena."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1876168"
                        ],
                        "name": "A. Lascarides",
                        "slug": "A.-Lascarides",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Lascarides",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lascarides"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5653822,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "f932caac89709a716a7d3e6632caf9f34d709518",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article we investigate logical metonymy, that is, constructions in which the argument of a word in syntax appears to be different from that argument in logical form (e.g., enjoy the book means enjoy reading the book, and easy problem means a problem that is easy to solve). The systematic variation in the interpretation of such constructions suggests a rich and complex theory of composition on the syntax/semantics interface. Linguistic accounts of logical metonymy typically fail to describe exhaustively all the possible interpretations, or they don't rank those interpretations in terms of their likelihood. In view of this, we acquire the meanings of metonymic verbs and adjectives from a large corpus and propose a probabilistic model that provides a ranking on the set of possible interpretations. We identify the interpretations automatically by exploiting the consistent correspondences between surface syntactic cues and meaning. We evaluate our results against paraphrase judgments elicited experimentally from humans and show that the model's ranking of meanings correlates reliably with human intuitions."
            },
            "slug": "A-Probabilistic-Account-of-Logical-Metonymy-Lapata-Lascarides",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Account of Logical Metonymy"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This article acquires the meanings of metonymic verbs and adjectives from a large corpus and proposes a probabilistic model that provides a ranking on the set of possible interpretations and identifies the interpretations automatically by exploiting the consistent correspondences between surface syntactic cues and meaning."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686074"
                        ],
                        "name": "Patrick Schone",
                        "slug": "Patrick-Schone",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Schone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick Schone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 172
                            }
                        ],
                        "text": "\u2026include automatic thesaurus extraction (Grefenstette, 1994), word sense discrimination (Schu\u0308tze, 1998) and disambiguation (McCarthy et al., 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al., 2001) , and notably information retrieval (Salton et al., 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 32
                            }
                        ],
                        "text": ", 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17089673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ea1a0e87169f9ac95293d77eb0bbcd79506bd09",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We seek a knowledge-free method for inducing multiword units from text corpora for use as machine-readable dictionary headwords. We provide two major evaluations of nine existing collocation-finders and illustrate the continuing need for improvement. We use Latent Semantic Analysis to make modest gains in performance, but we show the significant challenges encountered in trying this approach."
            },
            "slug": "Is-Knowledge-Free-Induction-of-Multiword-Unit-a-Schone-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Is Knowledge-Free Induction of Multiword Unit Dictionary Headwords a Solved Problem?"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work seeks a knowledge-free method for inducing multiword units from text corpora for use as machine-readable dictionary headwords and uses Latent Semantic Analysis to make modest gains in performance, but shows the significant challenges encountered."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2036336"
                        ],
                        "name": "P. Foltz",
                        "slug": "P.-Foltz",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Foltz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Foltz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62729021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4732c036d0b00d435bcd41ae904a9e936e4f683",
            "isKey": false,
            "numCitedBy": 792,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent Semantic Analysis (LSA) is used as a technique for measuring the coherence of texts. By comparing the vectors for 2 adjoining segments of text in a high\u2010dimensional semantic space, the method provides a characterization of the degree of semantic relatedness between the segments. We illustrate the approach for predicting coherence through reanalyzing sets of texts from 2 studies that manipulated the coherence of texts and assessed readers\u2019 comprehension. The results indicate that the method is able to predict the effect of text coherence on comprehension and is more effective than simple term\u2010term overlap measures. In this manner, LSA can be applied as an automated method that produces coherence predictions similar to propositional modeling. We describe additional studies investigating the application of LSA to analyzing discourse structure and examine the potential of LSA as a psychological model of coherence effects in text comprehension."
            },
            "slug": "The-Measurement-of-Textual-Coherence-with-Latent-Foltz-Kintsch",
            "title": {
                "fragments": [],
                "text": "The Measurement of Textual Coherence with Latent Semantic Analysis."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The approach for predicting coherence through reanalyzing sets of texts from 2 studies that manipulated the coherence of texts and assessed readers\u2019 comprehension indicates that the method is able to predict the effect of text coherence on comprehension and is more effective than simple term\u2010term overlap measures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2001885"
                        ],
                        "name": "Ted Pedersen",
                        "slug": "Ted-Pedersen",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Pedersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984521"
                        ],
                        "name": "Siddharth Patwardhan",
                        "slug": "Siddharth-Patwardhan",
                        "structuredName": {
                            "firstName": "Siddharth",
                            "lastName": "Patwardhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siddharth Patwardhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3075310"
                        ],
                        "name": "Jason Michelizzi",
                        "slug": "Jason-Michelizzi",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Michelizzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Michelizzi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 147
                            }
                        ],
                        "text": "The opposite is the case for the referenceThe face\n3We assessed a wide range of semantic similarity measures using the WordNet similarity package (Pedersen et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1499545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "495f3405da229b903797472c64d09d83659fdb34",
            "isKey": false,
            "numCitedBy": 1783,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets). It provides six measures of similarity, and three measures of relatedness, all of which are based on the lexical database WordNet. These measures are implemented as Perl modules which take as input two concepts, and return a numeric value that represents the degree to which they are similar or related."
            },
            "slug": "WordNet::Similarity-Measuring-the-Relatedness-of-Pedersen-Patwardhan",
            "title": {
                "fragments": [],
                "text": "WordNet::Similarity - Measuring the Relatedness of Concepts"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets)."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760616"
                        ],
                        "name": "F. J. Pelletier",
                        "slug": "F.-J.-Pelletier",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Pelletier",
                            "middleNames": [
                                "Jeffry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. J. Pelletier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our results show that the multiplicative models are superior and correlate significantly with behavioral data."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 58761668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "975b9c246611a35a41474ddf7403828b437551e8",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This book introduces fundamental techniques for computing semantic representations for fragments of natural language and performing inference with the result. The prinary tools used are first-order logic and lambda calculus. All the techniques introduced are implemented in Prolog. The book also shown how to use theorem provers and model builders in parallel to deal with natrual language inference."
            },
            "slug": "Representation-and-Inference-for-Natural-Language:-Pelletier",
            "title": {
                "fragments": [],
                "text": "Representation and Inference for Natural Language: A First Course in Computational Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This book introduces fundamental techniques for computing semantic representations for fragments of natural language and performing inference with the result by using first-order logic and lambda calculus."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47002621"
                        ],
                        "name": "Yuhua Li",
                        "slug": "Yuhua-Li",
                        "structuredName": {
                            "firstName": "Yuhua",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhua Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144960578"
                        ],
                        "name": "D. Mclean",
                        "slug": "D.-Mclean",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mclean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mclean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829501"
                        ],
                        "name": "Z. Bandar",
                        "slug": "Z.-Bandar",
                        "structuredName": {
                            "firstName": "Zuhair",
                            "lastName": "Bandar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Bandar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410239467"
                        ],
                        "name": "J. O'Shea",
                        "slug": "J.-O'Shea",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "O'Shea",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Shea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2627074"
                        ],
                        "name": "Keeley A. Crockett",
                        "slug": "Keeley-A.-Crockett",
                        "structuredName": {
                            "firstName": "Keeley",
                            "lastName": "Crockett",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keeley A. Crockett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12007882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58331d76610488c64ce104fbc361e30d8f0f8704",
            "isKey": false,
            "numCitedBy": 841,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Sentence similarity measures play an increasingly important role in text-related research and applications in areas such as text mining, Web page retrieval, and dialogue systems. Existing methods for computing sentence similarity have been adopted from approaches used for long text documents. These methods process sentences in a very high-dimensional space and are consequently inefficient, require human input, and are not adaptable to some application domains. This paper focuses directly on computing the similarity between very short texts of sentence length. It presents an algorithm that takes account of semantic information and word order information implied in the sentences. The semantic similarity of two sentences is calculated using information from a structured lexical database and from corpus statistics. The use of a lexical database enables our method to model human common sense knowledge and the incorporation of corpus statistics allows our method to be adaptable to different domains. The proposed method can be used in a variety of applications that involve text knowledge representation and discovery. Experiments on two sets of selected sentence pairs demonstrate that the proposed method provides a similarity measure that shows a significant correlation to human intuition"
            },
            "slug": "Sentence-similarity-based-on-semantic-nets-and-Li-Mclean",
            "title": {
                "fragments": [],
                "text": "Sentence similarity based on semantic nets and corpus statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experiments demonstrate that the proposed method provides a similarity measure that shows a significant correlation to human intuition and can be used in a variety of applications that involve text knowledge representation and discovery."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6387310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10b8f21e57b3392ce623c374c2c039f811ce5f69",
            "isKey": false,
            "numCitedBy": 523,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the text-to-text generation problem of sentence-level paraphrasing --- a phenomenon distinct from and more difficult than word- or phrase-level paraphrasing. Our approach applies multiple-sequence alignment to sentences gathered from unannotated comparable corpora: it learns a set of paraphrasing patterns represented by word lattice pairs and automatically determines how to apply these patterns to rewrite new sentences. The results of our evaluation experiments show that the system derives accurate paraphrases, outperforming baseline systems."
            },
            "slug": "Learning-to-Paraphrase:-An-Unsupervised-Approach-Barzilay-Lee",
            "title": {
                "fragments": [],
                "text": "Learning to Paraphrase: An Unsupervised Approach Using Multiple-Sequence Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work applies multiple-sequence alignment to sentences gathered from unannotated comparable corpora: it learns a set of paraphrasing patterns represented by word lattice pairs and automatically determines how to apply these patterns to rewrite new sentences."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 103
                            }
                        ],
                        "text": "We observe a similar pattern for the non compositional baseline model, the weighted additive model and Kintsch (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Kintsch (2001) proposes a variation on the vector addition theme in an attempt to model how the meaning of a predicate (e.g.,run) varies depending on the arguments it operates upon (e.g,the horse ran vs. the color ran)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 45
                            }
                        ],
                        "text": "When modeling predicate-argument structures, Kintsch (2001) proposes including one or more distributional neighbors,n, of the predicate:\np = u+v+\u2211n (10)\nNote that considerable latitude is allowed in selecting the appropriate neighbors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Kintsch (2001) considers only themmost similar neighbors to the predicate, from which he subsequently selectsk, those most similar to its argument."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 99
                            }
                        ],
                        "text": "We evaluated the models presented in Section 3 on a sentence similarity task initially proposed by Kintsch (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 15
                            }
                        ],
                        "text": "Unfortunately, Kintsch (2001) demonstrates how his own composition algorithm works intuitively on a few hand selected examples but does not provide a comprehensive test set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 97
                            }
                        ],
                        "text": "The weighted additive model (\u03c1 = 0.09) is not significantly different from the baseline either or Kintsch (2001) (\u03c1 = 0.09)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 219322170,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "040a6d4542111c1b6161533aa0818c0b025505a0",
            "isKey": true,
            "numCitedBy": 562,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Predication-Kintsch",
            "title": {
                "fragments": [],
                "text": "Predication"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3022217"
                        ],
                        "name": "J. Spenader",
                        "slug": "J.-Spenader",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Spenader",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Spenader"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2038941"
                        ],
                        "name": "Reinhard Blutner",
                        "slug": "Reinhard-Blutner",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Blutner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reinhard Blutner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10457370,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "abb83e7b45bfe3bc48cc504667c2da8fdf49c53d",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "A feasible model of natural language semantics should also account for the systematicity displayed by language understanding. The idea that compositionality alone is sufficient to guarantee systematic reasoning within a semantic system is rejected. An analysis of systematic inferences involving adjective\u2013noun combinations with intersective adjectives illustrates that more than a compositional semantics is required for their understanding, and that even simple concepts involve hidden structures. It is argued that the same processes used in determining context-dependent meaning are at work in understanding complex concepts where world-knowledge plays a key role. In the latter cases however accumulated experience with the given concept is argued to serve as a contrast set against which complex concepts are interpreted. 1 What is systematicity? The term \u2018systematicity\u2019 was first introduced in Fodor and Pylyshyn (1988) as a cognitive capacity on par with productivity which a compositional linguistic system is guaranteed to support. Fodor and Pylyshyn refer to systematicity as \u2018a feature of cognition, inferential coherence\u2019. In the following quote they describe what they mean (Fodor and Pylyshyn, 1988, p. 37): The ability to produce/understand some sentences is intrinsically connected to the ability to produce/understand certain others. However, Fodor and Pylyshyn give no formal definition (see van Gelder, 1990, for an attempt to work out the concept formally), instead choosing to illustrate the concept with examples. Here are examples of what types of systematic inferences we can make with language. When an agent understands the sentence \u2018John loves the girl\u2019, she understands the sentence \u2018The girl loves John\u2019 as well (Fodor and Pylyshyn, 1988, pp. 42, 48\u201349). (1) When an agent understands the expressions \u2018brown triangle\u2019 and \u2018black square\u2019, she understands the expressions \u2018brown square\u2019 and \u2018black triangle\u2019 as well. (Based on examples given in Fodor and Pylyshyn, 1988.) (2) Cognitive Foundations of Interpretation. Royal Netherlands Academy of Arts and Sciences, 2007 163 Initially, these two \u2018systematicity clauses\u2019 seem intuitively to be true. Surely understanding \u2018brown triangle\u2019 and \u2018black square\u2019 means that you will be able to infer what \u2018brown square\u2019 means. Systematicity is argued to follow from compositionality because understanding a complex concept like \u2018brown triangle\u2019 is achieved through an understanding of \u2018brown\u2019 and \u2018triangle\u2019, and therefore an agent must be able to use these lexical items in novel combinations. It is true that we understand all the above expressions, but how do we do it and what type of linguistic model will support these inferences? The ability to predict and confirm systematic inferences like these would seem to be a prerequisite for any language model that claims to model natural language understanding. Does understanding the results of the modification of one concept really insure the understanding of the same modification when applied to another concept? We will argue that the answer is not as simple as it first looks, not only for complex cases, but even for so-called simple compounds. Additionally, we will argue that the compositionality of a semantic theory is not sufficient to insure that the semantics predicts systematicity in language understanding. In Section 2 we examine several systematicity inferences that range from those requiring some reasoning to those that lead to compounds that seem only interpretable as idiomatic expressions, or even seem uninterpretable. Section 3 looks at simple adjective\u2013noun compounds involving intersective adjectives. The classic compositional approach is argued to be insufficient for correctly producing even the simplest systematicity clauses. Complex expressions with intersective adjectives are examined in more detail in Section 4. It is first shown that even the simplest concepts have hidden structures that are relevant to their interpretation. Second, it is shown that context affects both how adjective\u2013noun phrases are produced and how they are interpreted. We then argue that the mechanisms at work in cases where context-sets play a role in the meaning of adjective\u2013noun compounds, are the same mechanisms that were at work in determining in what way modification applies to a given object relative to other instances of that object in the world. Finally, Section 5 summarizes what implications this work has for other work in lexical semantics and natural language understanding. 2 Concepts do not relate systematically Lexical items evoke or refer to concepts, but these concepts don\u2019t necessarily relate in predictable ways. Consider the following examples of systematicity clauses where determining the actual meaning of each complex expression is not straightforwardly computable. An agent who understands \u2018good writer\u2019 and \u2018bad teacher\u2019 also understands \u2018bad writer\u2019 and \u2018good teacher\u2019. (3) An agent who understands \u2018within an hour\u2019 and \u2018without a watch\u2019 also understands \u2018without an hour\u2019 and \u2018within a watch\u2019. (4) An agent who understands \u2018Mom drives me to kindergarten\u2019 also understands \u2018I drive mom to kindergarten\u2019. (5) 164 Compositionality and systematicity Consider example (3). Do all who understand \u2018good writer\u2019 and \u2018bad teacher\u2019 also understand \u2018bad writer\u2019 and \u2018good teacher\u2019? The answer seems to be yes. However, determining the meaning of the new complex is a more involved process. For most of us, a writer is good or bad based on characteristics that are different from those under which a teacher is considered good or bad. Both characteristics can be identified from understanding the first two compound expressions. In order to understand the second two we seem to switch from the one end of the scale to the other. Example (4) seems unlikely. Do all who understand \u2018within an hour\u2019 and \u2018without a watch\u2019 also understand \u2018within a watch\u2019 and \u2018without an hour\u2019? (Szab\u00f3, 2000.) An interpretation requires some creativity, given that \u2018within a watch\u2019 does not seem to have any type of conventional meaning, and even if it did, it would not be part of combination of the meaning of the words \u2018within\u2019 and \u2018watch\u2019. On hearing it, listeners are more likely to assume that it has some sort of idiosyncratic, noncompositional meaning that they are unaware of. Finally, example (5) illustrates a case where the problem is conceptual. Would a child who understands \u2018Mom drives me to kindergarten\u2019 also be understand \u2018I drive mom to kindergarten\u2019? Here we are dealing with another type of example where there is a problem of conceptualization and likelihood. A child of kindergarten age may not even initially be able to conceive that he or she could drive the car. All three of these examples illustrate that systematic inferences seem to be heavily dependent on world knowledge, and not just linguistic knowledge. This raises the question what is actually involved in systematicity. If the systematicity that we sometimes find is a feature of language, entailed by virtue of language being a compositional system, then it should be in some ways independent of world knowledge. If however, systematic inferences are in part possible because of the way the world is, and are not really a reflection of linguistic structures, then whether or not your semantic system is compositional would seem to be beside the point. Consider what Clark (1993, p. 148) says: Instead of treating [systematicity] as a property to be directly induced by a canny choice of basic architecture, it may be fruitful to try to treat it as intrinsic to the knowledge we want a"
            },
            "slug": "Compositionality-and-Systematicity-Spenader-Blutner",
            "title": {
                "fragments": [],
                "text": "Compositionality and Systematicity"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An analysis of systematic inferences involving adjective\u2013noun combinations with intersective adjectives illustrates that more than a compositional semantics is required for their understanding, and that even simple concepts involve hidden structures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145948254"
                        ],
                        "name": "J. Bullinaria",
                        "slug": "J.-Bullinaria",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bullinaria",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bullinaria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144053576"
                        ],
                        "name": "J. Levy",
                        "slug": "J.-Levy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Levy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1025306,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f76807536e7f6542a72609929a9630de802a597f",
            "isKey": false,
            "numCitedBy": 673,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "The idea that at least some aspects of word meaning can be induced from patterns of word co-occurrence is becoming increasingly popular. However, there is less agreement about the precise computations involved, and the appropriate tests to distinguish between the various possibilities. It is important that the effect of the relevant design choices and parameter values are understood if psychological models using these methods are to be reliably evaluated and compared. In this article, we present a systematic exploration of the principal computational possibilities for formulating and validating representations of word meanings from word co-occurrence statistics. We find that, once we have identified the best procedures, a very simple approach is surprisingly successful and robust over a range of psychologically relevant evaluation measures."
            },
            "slug": "Extracting-semantic-representations-from-word-A-Bullinaria-Levy",
            "title": {
                "fragments": [],
                "text": "Extracting semantic representations from word co-occurrence statistics: A computational study"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article presents a systematic exploration of the principal computational possibilities for formulating and validating representations of word meanings from word co-occurrence statistics and finds that, once the best procedures are identified, a very simple approach is surprisingly successful and robust over a range of psychologically relevant evaluation measures."
            },
            "venue": {
                "fragments": [],
                "text": "Behavior research methods"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Under this framework, we introduce novel composition models which we compare empirically against previous work using a rigorous evaluation methodology."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7605995,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6dd83b2aa34c806596fc619ff3fbccf5f9830ab",
            "isKey": false,
            "numCitedBy": 2499,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel statistical method for factor analysis of binary and count data which is closely related to a technique known as Latent Semantic Analysis. In contrast to the latter method which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed technique uses a generative latent class model to perform a probabilistic mixture decomposition. This results in a more principled approach with a solid foundation in statistical inference. More precisely, we propose to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice. Probabilistic Latent Semantic Analysis has many applications, most prominently in information retrieval, natural language processing, machine learning from text, and in related areas. The paper presents perplexity results for different types of text and linguistic data collections and discusses an application in automated document indexing. The experiments indicate substantial and consistent improvements of the probabilistic method over standard Latent Semantic Analysis."
            },
            "slug": "Unsupervised-Learning-by-Probabilistic-Latent-Hofmann",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning by Probabilistic Latent Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice, and results in a more principled approach with a solid foundation in statistical inference."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144514944"
                        ],
                        "name": "W. Lowe",
                        "slug": "W.-Lowe",
                        "structuredName": {
                            "firstName": "Will",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2260968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e43f8a9a1ff712bdb3192d6e66b04effaf56597f",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "McDonald and Lowe [15] showed that cosines in a semantic space of several hundred dimensions reflect human priming results for a wide range of semantic and associatively related words [16, Exp.2]. Previously, Lowe [II, 10] argued that the intrinsic dimensionality of semantic space is much lower, and that high-dimensional structure can be effectively captured in just two dimensions as the surface of a neural map. This paper provides a replication of McDonald and Lowe\u2019s results in two dimensions using the Generative Topographic Mapping [2], a statistically motivated neural network architecture for topographic maps."
            },
            "slug": "What-is-the-Dimensionality-of-Human-Semantic-Space-Lowe",
            "title": {
                "fragments": [],
                "text": "What is the Dimensionality of Human Semantic Space?"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper provides a replication of McDonald and Lowe\u2019s results in two dimensions using the Generative Topographic Mapping [2], a statistically motivated neural network architecture for topographic maps."
            },
            "venue": {
                "fragments": [],
                "text": "NCPW"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2404363"
                        ],
                        "name": "S. Sloman",
                        "slug": "S.-Sloman",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Sloman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sloman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1969651"
                        ],
                        "name": "L. Rips",
                        "slug": "L.-Rips",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Rips",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39852555,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1e6b9a32b5f57e23b8f2f61df8d1e802db5d9c68",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Similarity-as-an-explanatory-construct-Sloman-Rips",
            "title": {
                "fragments": [],
                "text": "Similarity as an explanatory construct"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47709773"
                        ],
                        "name": "H. Rubenstein",
                        "slug": "H.-Rubenstein",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Rubenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rubenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1898344"
                        ],
                        "name": "J. Goodenough",
                        "slug": "J.-Goodenough",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Goodenough",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goodenough"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18309234,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7ef3ac14cdb484aaa2b039850093febd5cf73a21",
            "isKey": false,
            "numCitedBy": 1460,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Experimentol corroboration was obtained for the hypothesis that the proportion of words common to the contexts of word A and to the contexts of word B is a function of the degree to which A and B are similar in meaning. The tests were carried out for variously defined contexts. The shapes of the functions, however, indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "slug": "Contextual-correlates-of-synonymy-Rubenstein-Goodenough",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of synonymy"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The shapes of the functions indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2444937"
                        ],
                        "name": "Darrell Laham",
                        "slug": "Darrell-Laham",
                        "structuredName": {
                            "firstName": "Darrell",
                            "lastName": "Laham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Darrell Laham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2197285"
                        ],
                        "name": "B. Rehder",
                        "slug": "B.-Rehder",
                        "structuredName": {
                            "firstName": "Bob",
                            "lastName": "Rehder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rehder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144029655"
                        ],
                        "name": "M. E. Schreiner",
                        "slug": "M.-E.-Schreiner",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Schreiner",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. E. Schreiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 25
                            }
                        ],
                        "text": ", 1990) or essay grading (Landauer et al., 1997) were more concerned with modeling the gist of a document rather than the meaning of its sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 106
                            }
                        ],
                        "text": "Previous applications of vector addition to document indexing (Deerwester et al., 1990) or essay grading (Landauer et al., 1997) were more concerned with modeling the gist of a document rather than the meaning of its sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 52
                            }
                        ],
                        "text": "This is illustrated in the example below taken from Landauer et al. (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14911179,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0c074681e891ecd764bb844666011fa41cf7c8f1",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "How much of the meaning of a naturally occurring English passage is derivable from its combination of words without considering their order? An exploratory approach to this question was provided by asking humans to judge the quality and quantity of knowledge conveyed by short student essays on scientific topics and comparing the interrater reliability and predictive accuracy of their estimates with the performance of a corpus-based statistical model that takes no account of word order within an essay. There was surprisingly little difference between the human judges and the model. In the studies reported here, experts were asked to read short student essays about scientific topics with the goal of determining how much knowledge was accurately reflected in a given essay. We measured the readers\u2019 success by how well their ratings agreed with each other and how well they predicted scores on an objective test on the same subject. All current accounts of human discourse understanding"
            },
            "slug": "How-Well-Can-Passage-Meaning-be-Derived-without-A-Landauer-Laham",
            "title": {
                "fragments": [],
                "text": "How Well Can Passage Meaning be Derived without Using Word Order? A Comparison of Latent Semantic Analysis and Humans"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "An exploratory approach was provided by asking humans to judge the quality and quantity of knowledge conveyed by short student essays on scientific topics and comparing the interrater reliability and predictive accuracy of their estimates with the performance of a corpus-based statistical model that takes no account of word order within an essay."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33696979"
                        ],
                        "name": "G. Murphy",
                        "slug": "G.-Murphy",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Murphy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023259"
                        ],
                        "name": "D. Medin",
                        "slug": "D.-Medin",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Medin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Medin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14525617,
            "fieldsOfStudy": [
                "Philosophy",
                "Psychology"
            ],
            "id": "4336c33f0ab03e8722712792d25e46922eed73ed",
            "isKey": false,
            "numCitedBy": 2555,
            "numCiting": 147,
            "paperAbstract": {
                "fragments": [],
                "text": "The question of what makes a concept coherent (what makes its members form a comprehensible class) has received a variety of answers. In this article we review accounts based on similarity, feature correlations, and various theories of categorization. We find that each theory provides an inadequate account of conceptual coherence (or no account at all) because none provides enough constraints on possible concepts. We propose that concepts are coherent to the extent that they fit people's background knowledge or naive theories about the world. These theories help to relate the concepts in a domain and to structure the attributes that are internal to a concept. Evidence of the influence of theories on various conceptual tasks is presented, and the possible importance of theories in cognitive development is discussed."
            },
            "slug": "The-role-of-theories-in-conceptual-coherence.-Murphy-Medin",
            "title": {
                "fragments": [],
                "text": "The role of theories in conceptual coherence."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proposed that concepts are coherent to the extent that they fit people's background knowledge or naive theories about the world and to structure the attributes that are internal to a concept."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 36
                            }
                        ],
                        "text": "Vector-based models of word meaning (Lund and Burgess, 1996; Landauer and Dumais, 1997) have become increasingly popular in natural language processing (NLP) and cognitive science."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 168
                            }
                        ],
                        "text": "In cognitive science vector-based models have been successful in simulating semantic priming (Lund and Burgess, 1996; Landauer and Dumais, 1997) and text comprehension (Landauer and Dumais, 1997; Foltz et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 93
                            }
                        ],
                        "text": "In cognitive science vector-based models have been successful in simulating semantic priming (Lund and Burgess, 1996; Landauer and Dumais, 1997) and text comprehension (Landauer and Dumais, 1997; Foltz et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 84
                            }
                        ],
                        "text": "While vector addition has been effective in some applications such as essay grading (Landauer and Dumais, 1997) and coherence assessment (Foltz et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 134
                            }
                        ],
                        "text": "For example, assuming that individual words are represented by vectors, we can compute the meaning of a sentence by taking their mean (Foltz et al., 1998; Landauer and Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1144461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "isKey": true,
            "numCitedBy": 5788,
            "numCiting": 210,
            "paperAbstract": {
                "fragments": [],
                "text": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched."
            },
            "slug": "A-Solution-to-Plato's-Problem:-The-Latent-Semantic-Landauer-Dumais",
            "title": {
                "fragments": [],
                "text": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388342831"
                        ],
                        "name": "Stefan L. Frank",
                        "slug": "Stefan-L.-Frank",
                        "structuredName": {
                            "firstName": "Stefan L.",
                            "lastName": "Frank",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan L. Frank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34647275"
                        ],
                        "name": "M. Koppen",
                        "slug": "M.-Koppen",
                        "structuredName": {
                            "firstName": "Mathieu",
                            "lastName": "Koppen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Koppen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145395855"
                        ],
                        "name": "Leo G. M. Noordman",
                        "slug": "Leo-G.-M.-Noordman",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Noordman",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leo G. M. Noordman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145699990"
                        ],
                        "name": "W. Vonk",
                        "slug": "W.-Vonk",
                        "structuredName": {
                            "firstName": "Wietske",
                            "lastName": "Vonk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vonk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our results show that the multiplicative models are superior and correlate significantly with behavioral data."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 158
                            }
                        ],
                        "text": "The merits of different approaches are illustrated with a few hand picked examples and parameter values and large scale evaluations are uniformly absent (see Frank et al. (2007) for a criticism of Kintsch\u2019s (2001) evaluation standards)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 54753366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6797b320c62999eb6fac3ed2874e9e7ef44d6cb7",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Because higher level cognitive processes generally involve the use of world knowledge, computational models of these processes require the implementation of a knowledge base. This article identifies and discusses 4 strategies for dealing with world knowledge in computational models: disregarding world knowledge, ad hoc selection, extraction from text corpora, and implementation of all knowledge about a simplified microworld. Each of these strategies is illustrated by a detailed discussion of a model of discourse comprehension. It is argued that seemingly successful modeling results are uninformative if knowledge is implemented ad hoc or not at all, that knowledge extracted from large text corpora is not appropriate for discourse comprehension, and that a suitable implementation can be obtained by applying the microworld strategy."
            },
            "slug": "World-Knowledge-in-Computational-Models-of-Frank-Koppen",
            "title": {
                "fragments": [],
                "text": "World Knowledge in Computational Models of Discourse Comprehension"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that seemingly successful modeling results are uninformative if knowledge is implemented ad hoc or not at all, that knowledge extracted from large text corpora is not appropriate for discourse comprehension, and that a suitable implementation can be obtained by applying the microworld strategy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3177797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f198043a866e9187925a8d8db9a55e3bfdd47f2c",
            "isKey": false,
            "numCitedBy": 30947,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Latent-Dirichlet-Allocation-Blei-Ng",
            "title": {
                "fragments": [],
                "text": "Latent Dirichlet Allocation"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111327888"
                        ],
                        "name": "Michael N. Jones",
                        "slug": "Michael-N.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael N. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821878"
                        ],
                        "name": "D. Mewhort",
                        "slug": "D.-Mewhort",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Mewhort",
                            "middleNames": [
                                "J.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mewhort"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7819391,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d3cf28ab36ff7f7601a55c1e832736b2473a07f0",
            "isKey": false,
            "numCitedBy": 576,
            "numCiting": 164,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a computational model that builds a holographic lexicon representing both word meaning and word order from unsupervised experience with natural language. The model uses simple convolution and superposition mechanisms (cf. B. B. Murdock, 1982) to learn distributed holographic representations for words. The structure of the resulting lexicon can account for empirical data from classic experiments studying semantic typicality, categorization, priming, and semantic constraint in sentence completions. Furthermore, order information can be retrieved from the holographic representations, allowing the model to account for limited word transitions without the need for built-in transition rules. The model demonstrates that a broad range of psychological data can be accounted for directly from the structure of lexical representations learned in this way, without the need for complexity to be built into either the processing mechanisms or the representations. The holographic representations are an appropriate knowledge representation to be used by higher order models of language comprehension, relieving the complexity required at the higher level."
            },
            "slug": "Representing-word-meaning-and-order-information-in-Jones-Mewhort",
            "title": {
                "fragments": [],
                "text": "Representing word meaning and order information in a composite holographic lexicon."
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A computational model that builds a holographic lexicon representing both word meaning and word order from unsupervised experience with natural language demonstrates that a broad range of psychological data can be accounted for directly from the structure of lexical representations learned in this way, without the need for complexity to be built into either the processing mechanisms or the representations."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 49
                            }
                        ],
                        "text": "Examples include automatic thesaurus extraction (Grefenstette, 1994), word sense discrimination (Schu\u0308tze, 1998) and disambiguation (McCarthy et al., 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al., 2001) , and notably information retrieval (Salton et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59167516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4471e3117cdac2fae74d305d54b237bb3addd749",
            "isKey": false,
            "numCitedBy": 873,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. 1. Introduction. 2. Semantic Extraction. 3. Sextant. 4. Evaluation. 5. Applications. 6. Conclusion. 1: Preprocesors. 2. Webster Stopword List. 3: Similarity List. 4: Semantic Clustering. 5: Automatic Thesaurus Generation. 6. Corpora Treated. Index."
            },
            "slug": "Explorations-in-automatic-thesaurus-discovery-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Explorations in automatic thesaurus discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The aim of this monograph is to provide a catalog of words and phrases used in ThesaurusGeneration, as well as some examples of other writers' work, which have been used in similar contexts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153592298"
                        ],
                        "name": "S. McDonald",
                        "slug": "S.-McDonald",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "McDonald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. McDonald"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30529950,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6d8018bd8b288baca0c55522877efd1b49258747",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 172,
            "paperAbstract": {
                "fragments": [],
                "text": "A central concern of psycholinguistic research is explaining the relative ease or difficulty involved in processing words. In this thesis, we explore the connection between lexical processing effort and measurable properties of the linguistic environment. Distributional information (information about a word\u2019s contexts of use) is easily extracted from large language corpora in the form of co-occurrence statistics. We claim that such simple distributional statistics can form the basis of a parsimonious model of lexical processing effort. Adopting the purposive style of explanation advocated by the recent rational analysis approach to understanding cognition, we propose that the primary function of the human language processor is to recover meaning from an utterance. We assume that for this task to be efficient, a useful processing strategy is to use prior knowledge in order to build expectations about the meaning of upcoming words. Processing effort can then be seen as reflecting the difference between \u2018expected\u2019 meaning and \u2018actual\u2019 meaning. Applying the tools of information theory to lexical representations constructed from simple distributional statistics, we show how this quantity can be estimated as the amount of information conveyed by a word about its contexts of use. The hypothesis that properties of the linguistic environment are relevant to lexical processing effort is evaluated against a wide range of empirical data, including both new experimental studies and computational reanalyses of published behavioural data. Phenomena accounted for using the current approach include: both singleword and multiple-word lexical priming, isolated word recognition, the effect of contextual constraint on eye movements during reading, sentence and \u2018feature\u2019 priming, and picture naming performance by Alzheimer\u2019s patients. Besides explaining a broad range of empirical findings, our model provides an integrated account of both context-dependent and context-independent processing behaviour, offers an objective alternative to the influential spreading activation model of contextual facilitation, and invites reinterpretation of a number of controversial issues in the literature, such as the word frequency effect and the need for distinct mechanisms to explain semantic and associative priming. We conclude by emphasising the important role of distributional information in explanations of lexical processing effort, and suggest that environmental factors in general should given a more prominent place in theories of human language processing."
            },
            "slug": "Environmental-Determinants-of-Lexical-Processing-McDonald",
            "title": {
                "fragments": [],
                "text": "Environmental Determinants of Lexical Processing Effort"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This model provides an integrated account of both context-dependent and context-independent processing behaviour, offers an objective alternative to the influential spreading activation model of contextual facilitation, and invites reinterpretation of a number of controversial issues in the literature."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804885"
                        ],
                        "name": "M. Steyvers",
                        "slug": "M.-Steyvers",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steyvers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steyvers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6000627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "498a304a452fa4c3fb7ab91da7485bf0a405feac",
            "isKey": false,
            "numCitedBy": 1171,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "We present statistical analyses of the large-scale structure of 3 types of semantic networks: word associations, WordNet, and Roget's Thesaurus. We show that they have a small-world structure, characterized by sparse connectivity, short average path lengths between words, and strong local clustering. In addition, the distributions of the number of connections follow power laws that indicate a scale-free pattern of connectivity, with most nodes having relatively few connections joined together through a small number of hubs with many connections. These regularities have also been found in certain other complex natural networks, such as the World Wide Web, but they are not consistent with many conventional models of semantic organization, based on inheritance hierarchies, arbitrarily structured networks, or high-dimensional vector spaces. We propose that these structures reflect the mechanisms by which semantic networks grow. We describe a simple model for semantic growth, in which each new word or concept is connected to an existing network by differentiating the connectivity pattern of an existing node. This model generates appropriate small-world statistics and power-law connectivity distributions, and it also suggests one possible mechanistic basis for the effects of learning history variables (age of acquisition, usage frequency) on behavioral performance in semantic processing tasks."
            },
            "slug": "The-Large-Scale-Structure-of-Semantic-Networks:-and-Steyvers-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "The Large-Scale Structure of Semantic Networks: Statistical Analyses and a Model of Semantic Growth"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple model for semantic growth is described, in which each new word or concept is connected to an existing network by differentiating the connectivity pattern of an existing node, which generates appropriate small-world statistics and power-law connectivity distributions."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689109"
                        ],
                        "name": "Magnus Sahlgren",
                        "slug": "Magnus-Sahlgren",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Sahlgren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Magnus Sahlgren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078819344"
                        ],
                        "name": "Anders Holst",
                        "slug": "Anders-Holst",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Holst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anders Holst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298207"
                        ],
                        "name": "P. Kanerva",
                        "slug": "P.-Kanerva",
                        "structuredName": {
                            "firstName": "Pentti",
                            "lastName": "Kanerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanerva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17182082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "673b15746dd4ba0e70f038cf52f56dae1faeb744",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that sequence information can be encoded into high-dimensional fixed-width vectors using permutations of coordinates. Computational models of language often represent words with high-dimensional semantic vectors compiled from word-use statistics. A word's semantic vector usually encodes the contexts in which the word appears in a large body of text but ignores word order. However, word order often signals a word's grammatical role in a sentence and thus tells of the word's meaning. Jones and Mewhort (2007) show that word order can be included in the semantic vectors using holographic reduced representation and convolution. We show here that the order information can be captured also by permuting of vector coordinates, thus providing a general and computationally light alternative to convolution."
            },
            "slug": "Permutations-as-a-means-to-encode-order-in-word-Sahlgren-Holst",
            "title": {
                "fragments": [],
                "text": "Permutations as a means to encode order in word space"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "It is shown that sequence information can be encoded into high-dimensional fixed-width vectors using permutations of coordinates, thus providing a general and computationally light alternative to convolution."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365155"
                        ],
                        "name": "S. Deerwester",
                        "slug": "S.-Deerwester",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Deerwester",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Deerwester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737579"
                        ],
                        "name": "G. Furnas",
                        "slug": "G.-Furnas",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Furnas",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Furnas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154682"
                        ],
                        "name": "R. Harshman",
                        "slug": "R.-Harshman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Harshman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Harshman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 63
                            }
                        ],
                        "text": "Previous applications of vector addition to document indexing (Deerwester et al., 1990) or essay grading (Landauer et al., 1997) were more concerned with modeling the gist of a document rather than the meaning of its sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3252915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20a80a7356859daa4170fb4da6b87b84adbb547f",
            "isKey": false,
            "numCitedBy": 7019,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising."
            },
            "slug": "Indexing-by-Latent-Semantic-Analysis-Deerwester-Dumais",
            "title": {
                "fragments": [],
                "text": "Indexing by Latent Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new method for automatic indexing and retrieval to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 97
                            }
                        ],
                        "text": "Examples include automatic thesaurus extraction (Grefenstette, 1994), word sense discrimination (Schu\u0308tze, 1998) and disambiguation (McCarthy et al., 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al., 2001) , and notably information retrieval (Salton et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Examples include automatic thesaurus extraction (Grefenstette, 1994), word sense discrimination (Sch\u00fctze, 1998) and disambiguation (McCarthy et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8754851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cd9fd8a36c8feb74bb20ae25817edb9c6a0518c",
            "isKey": false,
            "numCitedBy": 1401,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words."
            },
            "slug": "Automatic-Word-Sense-Discrimination-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Automatic Word Sense Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering that demonstrates good performance of context- group discrimination for a sample of natural and artificial ambiguous words."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298207"
                        ],
                        "name": "P. Kanerva",
                        "slug": "P.-Kanerva",
                        "structuredName": {
                            "firstName": "Pentti",
                            "lastName": "Kanerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanerva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2532711"
                        ],
                        "name": "Jan Kristoferson",
                        "slug": "Jan-Kristoferson",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Kristoferson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Kristoferson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078819344"
                        ],
                        "name": "Anders Holst",
                        "slug": "Anders-Holst",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Holst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anders Holst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60571601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "932c8b99ef910bedd0f49d889230aba308004e0a",
            "isKey": false,
            "numCitedBy": 492,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Random Indexing of Text Samples for Latent Semantic Analysis Pentti Kanerva Jan Kristoferson Anders Holst kanerva@sics.se, janke@sics.se, aho@sics.se RWCP Theoretical Foundation SICS Laboratory Swedish Institute of Computer Science, Box 1263, SE-16429 Kista, Sweden Latent Semantic Analysis is a method of computing vectors|and it has several randomly placed ; 1s and high-dimensional semantic vectors, or context vectors, 1s, with the rest 0s (e.g., four each of ; 1 and 1, or for words from their co-occurrence statistics. An exper- eight non-0s in 1,800, instead of one non-0 in 30,000 iment by Landauer & Dumais (1997) covers a vocabu- as above). Thus, we would accumulate the same data lary of 60,000 words (unique letter strings delimited by into a 60,000 1,800 words-by-contexts matrix instead word-space characters) in 30,000 contexts (text samples of 60,000 30,000. or \\documents of about 150 words each). The data are Our method has been veried with dierent data, a rst collected into a 60,000 30,000 words-by-contexts ten-million-word \\TASA corpus consisting of a 79,000- co-occurrence matrix, with each row representing a word word vocabulary (when words are truncated after the 8th and each column representing a text sample so that each character) in 37,600 text samples. The data were accu- entry gives the frequency of a given word in a given mulated into a 79,000 1,800 words-by-contexts matrix, text sample. The frequencies are normalized, and the which was normalized by thresholding into a matrix of normalized matrix is transformed with Singular-Value ; 1s, 0s, and 1s. The unnormalized 1,800-dimensional Decomposition (SVD) reducing its original 30,000 doc- context vectors gave 35{44% correct in the TOEFL test ument dimensions into a much smaller number of latent and the normalized ones gave 48{51% correct, which cor- dimensions, 300 proving to be optimal. Thus words are respond to Landauer & Dumais' 36% for their normal- represented by 300-dimensional semantic vectors. ized 30,000-dimensional vectors before SVD, for a dier- The point in all of this is that the vectors capture ent corpus (see above). Our words-by-contexts matrix meaning. Landauer and Dumais demonstrate it with a can be transformed further, for example with SVD as in synonym test called TOEFL (for \\Test Of English as a LSA, except that the matrix is much smaller. Mathematically, the 30,000- or 37,600-dimensional in- Foreign Language ). For each test word, four alterna- dex vectors are orthogonal, whereas the 1,800-dimen- tives are given, and the \\contestant is asked to nd the one that's the most synonymous. Choosing at random sional ones are only nearly orthogonal. They seem to would yield 25% correct. However, when the seman- work just as well, in addition to which they are more tic vector for the test word is compared to the seman- \\brainlike and less aected by the number of text sam- tic vectors for the four alternatives, it correlates most ples (1,800-dimensional index vectors can cover a wide- highly with the correct alternative in 64% of the cases. ranging number of text samples). We have used such However, when the same test is based on the 30,000- vectors also to index words in narrow context windows, dimensional vectors before SVD, the result is not nearly getting 62{70% correct, and conclude that random in- as good: only 36% correct. The authors conclude that dexing deserves to be studied and understood more fully. Acknowledgments. This research is supported by the reorganization of information by SVD somehow cor- Japan's Ministry of International Trade and Industry responds to human psychology. under the Real World Computing Partnership We have studied high-dimensional random distributed (MITI) (RWCP) The TASA corpus and 80 TOEFL representations, as models of brainlike representation of test items program. were made available to us by courtesy of Pro- information (Kanerva, 1994; Kanerva & Sj\u007fodin, 1999). fessor Thomas Landauer, University of Colorado. In this poster we report on the use of such a repre- sentation to reduce the dimensionality of the original words-by-contexts matrix. The method can be explained Kanerva, P. (1994). References The Spatter Code for encoding by looking at the 60,000 30,000 matrix of frequencies concepts at many levels. In M. Marinaro and P. G. above. Assume that each text sample is represented by a Morasso (eds.), ICANN '94, Proc. Int'l Conference 30,000-bit vector with a single 1 marking the place of the on Articial Neural Networks (Sorrento, Italy), vol. 1, sample in a list of all samples, and call it the sample's pp. 226{229. London: Springer-Verlag. index vector (i.e., the n th bit of the index vector for the Kanerva, P., and Sj\u007fodin, G. (1999). Stochastic Pattern n th text sample is 1|the representation is unitary or lo- Computing. Proc. 2000 Real World Computing Sym- cal). Then the words-by-contexts matrix of frequencies bosium (Report TR-99-002, pp. 271{276). Tsukuba- can be gotten by the following procedure: every time city, Japan: Real World Computing Partnership. that the word w occurs in the n th text sample, the n th index vector is added to the row for the word w . Landauer, T. K., and Dumais, S. T. (1997). A solution We use the same procedure for accumulating a words- to Plato's problem: The Latent Semantic Analysis by-contexts matrix, except that the index vectors are theory of the acquisition, induction, and representa- not unitary. A text-sample's index vector is \\small tion of knowledge. Psychological Review 104 (2):211{ by comparison|we have used 1,800-dimensional index"
            },
            "slug": "Random-indexing-of-text-samples-for-latent-semantic-Kanerva-Kristoferson",
            "title": {
                "fragments": [],
                "text": "Random indexing of text samples for latent semantic analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "Random Indexing of Text Samples for Latent Semantic Analysis Pentti Kanerva Jan Kristoferson Anders Holst kanerva@sics.se, aho@sic.se RWCP Theoretical Foundation SICS Laboratory Swedish Institute of Computer Science, Box 1263, SE-16429 Kista, Sweden LatentSemantic Analysis is a method of computing vectors that captures ent corpus and the vectors capture words-by-contexts matrix meaning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5277263"
                        ],
                        "name": "J. Pynte",
                        "slug": "J.-Pynte",
                        "structuredName": {
                            "firstName": "Jo\u00ebl",
                            "lastName": "Pynte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pynte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145235075"
                        ],
                        "name": "Boris New",
                        "slug": "Boris-New",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "New",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris New"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46526669"
                        ],
                        "name": "A. Kennedy",
                        "slug": "A.-Kennedy",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Kennedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kennedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 148177835,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "f16b0e0a7bd562d4734a0190a779f813fb0bc5ac",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic and syntactic influences during reading normal text were examined in a series of multiple regression analyses conducted on a large-scale corpus of eyemovement data. Two measures of contextual constraints, based on the syntactic descriptions provided by Abeille, Clement et Toussenel (2003) and one measure on semantic constraint, based on Latent Semantic Analysis, were included in the regression equation, together with a set of properties (length, frequency, etc.), known to affect inspection times. Both syntactic and semantic constraints were found to exert a significant influence, with less time spent inspecting highly constrained target words, relative to weakly constrained ones. Semantic and syntactic properties apparently exerted their influence independently from each other, as suggested by the lack of interaction."
            },
            "slug": "A-multiple-regression-analysis-of-syntactic-and-in-Pynte-New",
            "title": {
                "fragments": [],
                "text": "A multiple regression analysis of syntactic and semantic influences in reading normal text"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Both syntactic and semantic constraints were found to exert a significant influence, with less time spent inspecting highly constrained target words, relative to weakly constrained ones."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Smolensky (1990) proposed the use of tensor products as a means of binding one vector to another."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 6
                            }
                        ],
                        "text": "Despite their widespread use, vector-based models are typically directed at representing words in isolation and methods for constructing representations for phrases or sentences have received little attention in the literature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 125580247,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9438172bfbb74a6a4ea4242b180d4335bb1f18b7",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: 1. Introduction, 2. Connectionist Representation and Tensor Product Binding: Definition and Examples, 3. Tensor Product Representation: Properties, 4. Conclusion"
            },
            "slug": "Tensor-Product-Variable-Binding-and-the-of-Symbolic-Hinton",
            "title": {
                "fragments": [],
                "text": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This chapter contains sections titled connectionist Representation and Tensor Product Binding: Definition and Examples, and tensor Product Representation: Properties."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143981449"
                        ],
                        "name": "Mark Andrews",
                        "slug": "Mark-Andrews",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Andrews",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Andrews"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2517462"
                        ],
                        "name": "G. Vigliocco",
                        "slug": "G.-Vigliocco",
                        "structuredName": {
                            "firstName": "Gabriella",
                            "lastName": "Vigliocco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Vigliocco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15109128"
                        ],
                        "name": "D. Vinson",
                        "slug": "D.-Vinson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Vinson",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Vinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17542062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b3616e10fc5f810243f20b84ffc72acbf773cc3",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors identify 2 major types of statistical data from which semantic representations can be learned. These are denoted as experiential data and distributional data. Experiential data are derived by way of experience with the physical world and comprise the sensory-motor data obtained through sense receptors. Distributional data, by contrast, describe the statistical distribution of words across spoken and written language. The authors claim that experiential and distributional data represent distinct data types and that each is a nontrivial source of semantic information. Their theoretical proposal is that human semantic representations are derived from an optimal statistical combination of these 2 data types. Using a Bayesian probabilistic model, they demonstrate how word meanings can be learned by treating experiential and distributional data as a single joint distribution and learning the statistical structure that underlies it. The semantic representations that are learned in this manner are measurably more realistic-as verified by comparison to a set of human-based measures of semantic representation-than those available from either data type individually or from both sources independently. This is not a result of merely using quantitatively more data, but rather it is because experiential and distributional data are qualitatively distinct, yet intercorrelated, types of data. The semantic representations that are learned are based on statistical structures that exist both within and between the experiential and distributional data types."
            },
            "slug": "Integrating-experiential-and-distributional-data-to-Andrews-Vigliocco",
            "title": {
                "fragments": [],
                "text": "Integrating experiential and distributional data to learn semantic representations."
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Using a Bayesian probabilistic model, the authors demonstrate how word meanings can be learned by treating experiential and distributional data as a single joint distribution and learning the statistical structure that underlies it."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29874772"
                        ],
                        "name": "E. Kako",
                        "slug": "E.-Kako",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Kako",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kako"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our results show that the multiplicative models are superior and correlate significantly with behavioral data."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 144448562,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "e5b09259b4047481c277de3225753696e5ab495f",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Which properties of syntax are uniquely human, and which can be acquired by other animals? Relevant evidence is provided by work with three language-trained animals: the African gray parrot Alex, who can produce and comprehend a small fragment of English; the bottle-nosed dolphins Ake and Phoenix, who can comprehend a gestural and an acoustic language, respectively; and the bonobo Kanzi, who can produce combinations of lexigrams and comprehend a significant fragment of English. The systems of these animals are examined for evidence of four core properties of syntax: discrete combinatorics, category-based rules, argument structure, and closed-class items. Additional studies that explore further what these animals can learn about these core properties are suggested."
            },
            "slug": "Elements-of-syntax-in-the-systems-of-three-animals-Kako",
            "title": {
                "fragments": [],
                "text": "Elements of syntax in the systems of three language-trained animals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31533192"
                        ],
                        "name": "A. Collins",
                        "slug": "A.-Collins",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Collins",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69960817"
                        ],
                        "name": "M. R. Quillian",
                        "slug": "M.-R.-Quillian",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Quillian",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. R. Quillian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60922154,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06cb835bda3420186e2c6f6fa2dbc1613a9b2d75",
            "isKey": false,
            "numCitedBy": 2946,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Retrieval-time-from-semantic-memory-Collins-Quillian",
            "title": {
                "fragments": [],
                "text": "Retrieval time from semantic memory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2496651"
                        ],
                        "name": "G. Denhi\u00e8re",
                        "slug": "G.-Denhi\u00e8re",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Denhi\u00e8re",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Denhi\u00e8re"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144996667"
                        ],
                        "name": "Beno\u00eet Lemaire",
                        "slug": "Beno\u00eet-Lemaire",
                        "structuredName": {
                            "firstName": "Beno\u00eet",
                            "lastName": "Lemaire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beno\u00eet Lemaire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 182
                            }
                        ],
                        "text": "Moreover, the vector similarities within such semantic spaces have been shown to substantially correlate with human similarity judgments (McDonald, 2000) and word association norms (Denhire and Lemaire, 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9548665,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "aaf611a06273a3f6bb1183cc81381009f6b6910d",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "A computational model of children's semantic memory is built from the Latent Semantic Analysis (LSA) of a multisource child corpus. Three tests of the model are described, simulating a vocabulary test, an association test and a recall task. For each one, results from experiments with children are presented and compared to the model data. Adequacy is correct, which means that this simulation of children's semantic memory can be used to simulate a variety of children's cognitive processes."
            },
            "slug": "A-Computational-Model-of-Children's-Semantic-Memory-Denhi\u00e8re-Lemaire",
            "title": {
                "fragments": [],
                "text": "A Computational Model of Children's Semantic Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A computational model of children's semantic memory is built from the Latent Semantic Analysis (LSA) of a multisource child corpus, simulating a vocabulary test, an association test and a recall task."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859277"
                        ],
                        "name": "T. Plate",
                        "slug": "T.-Plate",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Plate",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Plate"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 110015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9091aa773f1b31b4ff6d15a676321fc781b7e8c9",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Holographic reduced representations (HRRs) are a method for encoding nested relational structures in fixed\u2010width vector representations. HRRs encode relational structures as vector representations in such a way that the superficial similarity of the vectors reflects both superficial and structural similarity of the relational structures. HRRs also support a number of operations that could be very useful in psychological models of human analogy processing: fast estimation of superficial and structural similarity via a vector dot\u2010product; finding corresponding objects in two structures; and chunking of vector representations. Although similarity assessment and discovery of corresponding objects both theoretically take exponential time to perform fully and accurately, with HRRs one can obtain approximate solutions in constant time. The accuracy of these operations with HRRs mirrors patterns of human performance on analog retrieval and processing tasks."
            },
            "slug": "Analogy-retrieval-and-processing-with-distributed-Plate",
            "title": {
                "fragments": [],
                "text": "Analogy retrieval and processing with distributed vector representations"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Holographic reduced representations are a method for encoding nested relational structures in fixed\u2010width vector representations that support a number of operations that could be very useful in psychological models of human analogy processing."
            },
            "venue": {
                "fragments": [],
                "text": "Expert Syst. J. Knowl. Eng."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5823614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8fe99b6dc76dc342fe9fb47740fee40381fa13d",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a robust accurate domain-independent approach to statistical parsing incorporated into the new release of the ANLT toolkit, and publicly available as a research tool. The system has been used to parse many well known corpora in order to produce data for lexical acquisition efforts; it has also been used as a component in an open-domain question answering project. The performance of the system is competitive with that of statistical parsers using highly lexicalised parse selection models. However, we plan to extend the system to improve parse coverage, depth and accuracy."
            },
            "slug": "Robust-Accurate-Statistical-Annotation-of-General-Briscoe-Carroll",
            "title": {
                "fragments": [],
                "text": "Robust Accurate Statistical Annotation of General Text"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A robust accurate domain-independent approach to statistical parsing incorporated into the new release of the ANLT toolkit, and publicly available as a research tool."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36855520"
                        ],
                        "name": "R. F. West",
                        "slug": "R.-F.-West",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "West",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. F. West"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4248890"
                        ],
                        "name": "K. Stanovich",
                        "slug": "K.-Stanovich",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Stanovich",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Stanovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 38513808,
            "fieldsOfStudy": [
                "Psychology",
                "Linguistics"
            ],
            "id": "60bd96f3aa44485f1fe5dbe65d83d16e56334711",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "A series of experiments explored the effect of the syntactic structure of a sentence fragment on the processing of a subsequent target word. In both a naming and a lexical decision task, modal verb contexts followed by main verb targets and preposition contexts followed by noun targets produced faster response times than did the opposite pairings (i.e., modal/noun and preposition/ verb). This syntactic context effect occurred across several different variations in the method of context presentation. Also, unlike some previous findings on syntactic priming, the present effects did not disappear when a naming task was employed. The magnitude of the syntactic priming effect was similar in the naming and lexical decision tasks when the response times were slow, but was larger in the lexical decision task when the response times were faster. The implications of these results for recent discussions of the relationship between task structure and the locus of observed contextual effects are discussed."
            },
            "slug": "Robust-effects-of-syntactic-structure-on-visual-West-Stanovich",
            "title": {
                "fragments": [],
                "text": "Robust effects of syntactic structure on visual word processing"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The magnitude of the syntactic priming effect was similar in the naming and lexical decision tasks when the response times were slow, but was larger in the Lexical decision task when theresponse times were faster."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47277215"
                        ],
                        "name": "S. Duffy",
                        "slug": "S.-Duffy",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Duffy",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Duffy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33070393"
                        ],
                        "name": "R. Morris",
                        "slug": "R.-Morris",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Morris",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Morris"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1199849,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d55b04a65608f549c9637e78bc6e194f362f3c5c",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "In three experiments we investigated the effect of a sentence context on naming time for a target word. Contexts were presented by using a rapid serial visual presentation; subjects named the last word of the sentence. In the first two experiments, facilitation was observed for a fully congruent context containing a subject and verb that were weakly related to the target word. No facilitation was observed when either the subject or verb was replaced with a more neutral word. In the third experiment, the fully congruent contexts were modified either to preserve or to disrupt the original relation between the subject and verb. Facilitation was observed in both conditions. The full pattern of results suggests that a combination of lexical items can prime a target word in the absence of priming by any of the lexical items individually. This combination priming is not dependent upon the overall meaning of the sentence."
            },
            "slug": "Semantic-facilitation-of-lexical-access-during-Duffy-Henderson",
            "title": {
                "fragments": [],
                "text": "Semantic facilitation of lexical access during sentence processing."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The full pattern of results suggests that a combination of lexical items can prime a target word in the absence of priming by any of the lexicalItems individually."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Learning, memory, and cognition"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690396"
                        ],
                        "name": "C. Eliasmith",
                        "slug": "C.-Eliasmith",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Eliasmith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Eliasmith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756123"
                        ],
                        "name": "P. Thagard",
                        "slug": "P.-Thagard",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Thagard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thagard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123203339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90cfc9fa6c26b65b661f0329c80aae212af42c2f",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Integrating-structure-and-meaning:-a-distributed-of-Eliasmith-Thagard",
            "title": {
                "fragments": [],
                "text": "Integrating structure and meaning: a distributed model of analogical mapping"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120600938"
                        ],
                        "name": "G. Simpson",
                        "slug": "G.-Simpson",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Simpson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Simpson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152782175"
                        ],
                        "name": "R. R. Peterson",
                        "slug": "R.-R.-Peterson",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "Peterson",
                            "middleNames": [
                                "R"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. R. Peterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5645275"
                        ],
                        "name": "M. A. Casteel",
                        "slug": "M.-A.-Casteel",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Casteel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Casteel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50611682"
                        ],
                        "name": "C. Burgess",
                        "slug": "C.-Burgess",
                        "structuredName": {
                            "firstName": "Curt",
                            "lastName": "Burgess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burgess"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 144044038,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "44656a2e344549fffc3203580fe6e31085688716",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Three experiments examined lexical and sentence-level contributions to contextual facilitation effects in word recognition. Subjects named target words preceded by normal or scrambled sentence contexts that contained lexical associates of the target. In Experiment 1, normal sentences showed facilitation for related targets and inhibition for unrelated targets. Experiment 2 eliminated syntactically anomalous targets among unrelated items and showed only facilitation for related targets. In neither experiment was there any effect of relatedness for scrambled stimuli. Experiment 3 included syntactically normal but semantically anomalous sentences to test whether the failure of scrambled sentences to show priming was due to their syntactic incoherence. Normal sentences again showed contextual facilitation, but neither scrambled nor anomalous sentences showed such effects. The results indicate that there are sentence-context effects that do not arise solely from intralexical spreading activation and suggest that context facilitates the identification of a lexical candidate."
            },
            "slug": "Lexical-and-Sentence-Context-Effects-in-Word-Simpson-Peterson",
            "title": {
                "fragments": [],
                "text": "Lexical and Sentence Context Effects in Word Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145539951"
                        ],
                        "name": "J. Pollack",
                        "slug": "J.-Pollack",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Pollack",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 770011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a835df43fdc2f79126319f6fa033bb42147c6f6",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-Distributed-Representations-Pollack",
            "title": {
                "fragments": [],
                "text": "Recursive Distributed Representations"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13574,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1969651"
                        ],
                        "name": "L. Rips",
                        "slug": "L.-Rips",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Rips",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 52
                            }
                        ],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143831277,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ed6780677cc5d7128f0619327aa995a305cf839a",
            "isKey": false,
            "numCitedBy": 448,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Inductive-judgments-about-natural-categories.-Rips",
            "title": {
                "fragments": [],
                "text": "Inductive judgments about natural categories."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2869436"
                        ],
                        "name": "V. Demberg",
                        "slug": "V.-Demberg",
                        "structuredName": {
                            "firstName": "Vera",
                            "lastName": "Demberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Demberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143694777"
                        ],
                        "name": "Frank Keller",
                        "slug": "Frank-Keller",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Keller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Keller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1444973,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "41215599674d8a81e7420f2a40320868f3dbc2f1",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Data-from-eye-tracking-corpora-as-evidence-for-of-Demberg-Keller",
            "title": {
                "fragments": [],
                "text": "Data from eye-tracking corpora as evidence for theories of syntactic processing complexity"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153873834"
                        ],
                        "name": "A. Wong",
                        "slug": "A.-Wong",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40498308"
                        ],
                        "name": "Chung-Shu Yang",
                        "slug": "Chung-Shu-Yang",
                        "structuredName": {
                            "firstName": "Chung-Shu",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-Shu Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 275
                            }
                        ],
                        "text": "\u2026include automatic thesaurus extraction (Grefenstette, 1994), word sense discrimination (Schu\u0308tze, 1998) and disambiguation (McCarthy et al., 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al., 2001) , and notably information retrieval (Salton et al., 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 44
                            }
                        ],
                        "text": ", 2001) , and notably information retrieval (Salton et al., 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6473756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5f169880e30e1f76827d72f862555d00b01bed9",
            "isKey": false,
            "numCitedBy": 7617,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of the model."
            },
            "slug": "A-vector-space-model-for-automatic-indexing-Salton-Wong",
            "title": {
                "fragments": [],
                "text": "A vector space model for automatic indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents, demonstating the usefulness of the model."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2770201"
                        ],
                        "name": "G. Pullum",
                        "slug": "G.-Pullum",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Pullum",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pullum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2917207"
                        ],
                        "name": "Barbara C. Scholz",
                        "slug": "Barbara-C.-Scholz",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Scholz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barbara C. Scholz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our results show that the multiplicative models are superior and correlate significantly with behavioral data."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 169556235,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0e1a3b216c99c39506500013a5514748f8e2408d",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "A lengthy debate in the philosophy of the cognitive sciences has turned on whether the phenomenon known as 'systematicity' of language and thought shows that connectionist explanatory aspirations are misguided. We investigate the issue of just which phenomenon 'systematicity' is supposed to be. The much-rehearsed examples always suggest that being systematic has something to do with ways in which some parts of expressions in natural languages (and, more conjecturally, some parts of thoughts) can be substituted for others without altering well-formedness. We show that under one construal this yields a grossly weak claim that is not just compatible with a narrow version of associationist psychology but essentially coincides with a formalization of its descriptive power. Under another construal we get a claim (apparently unintended) that requires natural languages to fall within the context-free class, a claim that most linguists regard as too strong. Looking more closely at this proposed reconstruction of systematicity leads us to endorse, with further illustrations, the suggestion of Johnson (2004) that systematicity as a matter of substitutability of co-categorial constituents for one another does not appear to hold of natural languages at all. The appeal of the ill-delineated notion of systematicity may lie in the fact that within certain subclasses of lexical items mutual intersubstitutability does seem to hold, and the explanation for that lies in a limitation on human memory: we simply cannot learn separate privileges of syntactic distribution for all of the huge number of words and phrases that we know."
            },
            "slug": "Systematicity-and-Natural-Language-Syntax-Pullum-Scholz",
            "title": {
                "fragments": [],
                "text": "Systematicity and Natural Language Syntax"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47473549"
                        ],
                        "name": "Colin Bannard",
                        "slug": "Colin-Bannard",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Bannard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Colin Bannard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15728911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36e8b8b35e51e5b39fcafdb5c2bc763796d0672e",
            "isKey": false,
            "numCitedBy": 620,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work has used monolingual parallel corpora to extract and generate paraphrases. We show that this task can be done using bilingual parallel corpora, a much more commonly available resource. Using alignment techniques from phrase-based statistical machine translation, we show how paraphrases in one language can be identified using a phrase in another language as a pivot. We define a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities, and show how it can be refined to take contextual information into account. We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments, and contrast the quality with paraphrases extracted from automatic alignments."
            },
            "slug": "Paraphrasing-with-Bilingual-Parallel-Corpora-Bannard-Callison-Burch",
            "title": {
                "fragments": [],
                "text": "Paraphrasing with Bilingual Parallel Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work defines a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities, and shows how it can be refined to take contextual information into account."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704065"
                        ],
                        "name": "D. Gentner",
                        "slug": "D.-Gentner",
                        "structuredName": {
                            "firstName": "Dedre",
                            "lastName": "Gentner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gentner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 104
                            }
                        ],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16400609,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41935319686770077dac8d53d44ddf5d1bdad26b",
            "isKey": false,
            "numCitedBy": 1136,
            "numCiting": 130,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : It is widely agreed that similarity and analogy are important in transfer of learning. Recent research suggests that different kinds of similarity enter into different parts of the transfer process. For example, access to long-term memory is more influenced by surface similarity than is analogical inference once an analogy is present. In this paper I decompose similarity-based transfer into separate subprocesses and compare how different kinds of similarity affect each of these processes. Keywords: Similarity, Transfer, Analogical mapping, Analogical soundness, Access."
            },
            "slug": "Mechanisms-of-Analogical-Learning.-Gentner",
            "title": {
                "fragments": [],
                "text": "Mechanisms of Analogical Learning."
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper decomposes similarity-based transfer into separate subprocesses and compares how different kinds of similarity affect each of these processes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50672236"
                        ],
                        "name": "D. J. Foss",
                        "slug": "D.-J.-Foss",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Foss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. J. Foss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 105
                            }
                        ],
                        "text": "Changes in the temporal order of words in a sentence decrease the strength of the related priming effect (Foss, 1982; Masson, 1986; O\u2019Seaghdha, 1989; Simpson, Peterson, Casteel, & Brugges, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42931448,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3b2809a14caf764ebe1f86f9a38be90b1033e28e",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-discourse-on-semantic-priming-Foss",
            "title": {
                "fragments": [],
                "text": "A discourse on semantic priming"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2896203"
                        ],
                        "name": "L. Doumas",
                        "slug": "L.-Doumas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Doumas",
                            "middleNames": [
                                "A.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Doumas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725887"
                        ],
                        "name": "J. Hummel",
                        "slug": "J.-Hummel",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hummel",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hummel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570618"
                        ],
                        "name": "C. Sandhofer",
                        "slug": "C.-Sandhofer",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Sandhofer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sandhofer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1989372,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d4b9807973730f1af4b3e6af171d283328af99d8",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 175,
            "paperAbstract": {
                "fragments": [],
                "text": "Relational thinking plays a central role in human cognition. However, it is not known how children and adults acquire relational concepts and come to represent them in a form that is useful for the purposes of relational thinking (i.e., as structures that can be dynamically bound to arguments). The authors present a theory of how a psychologically and neurally plausible cognitive architecture can discover relational concepts from examples and represent them as explicit structures (predicates) that can take arguments (i.e., predicate them). The theory is instantiated as a computer program called DORA (Discovery Of Relations by Analogy). DORA is used to simulate the discovery of novel properties and relations, as well as a body of empirical phenomena from the domain of relational learning and the development of relational representations in children and adults."
            },
            "slug": "A-theory-of-the-discovery-and-predication-of-Doumas-Hummel",
            "title": {
                "fragments": [],
                "text": "A theory of the discovery and predication of relational concepts."
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The authors present a theory of how a psychologically and neurally plausible cognitive architecture can discover relational concepts from examples and represent them as explicit structures (predicates) that can take arguments (i.e., predicate them)."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33070393"
                        ],
                        "name": "R. Morris",
                        "slug": "R.-Morris",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Morris",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Morris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23331798,
            "fieldsOfStudy": [
                "Psychology",
                "Linguistics"
            ],
            "id": "c8a3f203278da35f444923a5e2c79612c266b471",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Readers' eye movements were recorded as they read an unambiguous noun in a sentence context. In Experiment 1, fixation durations on a target noun were shorter when it was embedded in context containing a subject noun and a verb that were weakly related to the target than when either content word was replaced with a more neutral word. These results were not affected by changes in the syntactic relations between the content words. In Experiment 2, the semantic relations between the message-level representation of the sentence and the target word were altered whereas the lexical content was held constant. Fixation time on the target word was shorter when the context was semantically related to the target word than when it was unrelated. Intralexical priming effects between the subject noun and the verb were also observed. The results suggest that both lexical and message-level representations can influence the access of an individual lexical item in a sentence context."
            },
            "slug": "Lexical-and-message-level-sentence-context-effects-Morris",
            "title": {
                "fragments": [],
                "text": "Lexical and message-level sentence context effects on fixation times in reading."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The results suggest that both lexical and message-level representations can influence the access of an individual lexical item in a sentence context."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Learning, memory, and cognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50064811"
                        ],
                        "name": "L. Finkelstein",
                        "slug": "L.-Finkelstein",
                        "structuredName": {
                            "firstName": "Lev",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718798"
                        ],
                        "name": "E. Gabrilovich",
                        "slug": "E.-Gabrilovich",
                        "structuredName": {
                            "firstName": "Evgeniy",
                            "lastName": "Gabrilovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gabrilovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745572"
                        ],
                        "name": "Y. Matias",
                        "slug": "Y.-Matias",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Matias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Matias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747801"
                        ],
                        "name": "E. Rivlin",
                        "slug": "E.-Rivlin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Rivlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rivlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3316511"
                        ],
                        "name": "Zach Solan",
                        "slug": "Zach-Solan",
                        "structuredName": {
                            "firstName": "Zach",
                            "lastName": "Solan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zach Solan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073936"
                        ],
                        "name": "G. Wolfman",
                        "slug": "G.-Wolfman",
                        "structuredName": {
                            "firstName": "Gadi",
                            "lastName": "Wolfman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wolfman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779370"
                        ],
                        "name": "E. Ruppin",
                        "slug": "E.-Ruppin",
                        "structuredName": {
                            "firstName": "Eytan",
                            "lastName": "Ruppin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ruppin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 41
                            }
                        ],
                        "text": "We used WordSim353, a benchmark dataset (Finkelstein et al., 2002), consisting of relatedness judgments (on a scale of 0 to 10) for 353 word pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12956853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0c01df98a6b633b25c96c1a99b713ac96f1c5be",
            "isKey": false,
            "numCitedBy": 1725,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Keyword-based search engines are in widespread use today as a popular means for Web-based information retrieval. Although such systems seem deceptively simple, a considerable amount of skill is required in order to satisfy non-trivial information needs. This paper presents a new conceptual paradigm for performing search in context, that largely automates the search process, providing even non-professional users with highly relevant results. This paradigm is implemented in practice in the IntelliZap system, where search is initiated from a text query marked by the user in a document she views, and is guided by the text surrounding the marked query in that document (\"the context\"). The context-driven information retrieval process involves semantic keyword extraction and clustering to automatically generate new, augmented queries. The latter are submitted to a host of general and domain-specific search engines. Search results are then semantically reranked, using context. Experimental results testify that using context to guide search, effectively offers even inexperienced users an advanced search tool on the Web."
            },
            "slug": "Placing-search-in-context:-the-concept-revisited-Finkelstein-Gabrilovich",
            "title": {
                "fragments": [],
                "text": "Placing search in context: the concept revisited"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new conceptual paradigm for performing search in context is presented, that largely automates the search process, providing even non-professional users with highly relevant results."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51966268"
                        ],
                        "name": "W. Estes",
                        "slug": "W.-Estes",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Estes",
                            "middleNames": [
                                "Kaye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Estes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 78
                            }
                        ],
                        "text": "Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61051459,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "61e79a9d4865dfd80a73eaaaa24386c594a819c1",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction and Basic Concepts 2. Category Structures and Categorization 3. Models for Category Learning 4. Categorization and Memory Processing 5. On the Storage and Retrieval of Categorical Information 6. Extensions and New Applications of the Exemplar-Similarity Model"
            },
            "slug": "Classification-and-cognition-Estes",
            "title": {
                "fragments": [],
                "text": "Classification and cognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper presents a meta-modelling framework for category learning called the Exemplar-Similarity Model, which automates the very labor-intensive and therefore time-heavy and expensive process of category classification and classification-based learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1831395"
                        ],
                        "name": "H. Wallach",
                        "slug": "H.-Wallach",
                        "structuredName": {
                            "firstName": "Hanna",
                            "lastName": "Wallach",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wallach"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7335851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52951eefe0e5c69d6e14840e2d2b30f62a09a28b",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis introduces new methods for statistically modelling text using topic models. Topic models have seen many successes in recent years, and are used in a variety of applications, including analysis of news articles, topic-based search interfaces and navigation tools for digital libraries. Despite these recent successes, the field of topic modelling is still relatively new and there remains much to be explored. One noticeable absence from most of the previous work on topic modelling is consideration of language and document structure\u2014from low-level structures, including word order and syntax, to higher-level structures, such as relationships between documents. The focus of this thesis is therefore structured topic models\u2014models that combine latent topics with information about document structure, ranging from local sentence structure to inter-document relationships. These models draw on techniques from Bayesian statistics, including hierarchical Dirichlet distributions and processes, Pitman-Yor processes, and Markov chain Monte Carlo methods. Several methods for estimating the parameters of Dirichlet-multinomial distributions are also compared. The main contribution of this thesis is the introduction of three structured topic models. The first is a topic-based language model. This model captures both word order and latent topics by extending a Bayesian topic model to incorporate n-gram statistics. A bigram version of the new model does better at predicting future words than either a topic model or a trigram language model. It also provides interpretable topics. The second model arises from a Bayesian reinterpretation of a classic generative dependency parsing model. The new model demonstrates that parsing performance can be substantially improved by a careful choice of prior and by sampling hyperparameters. Additionally, the generative nature of the model facilitates the inclusion of latent state variables, which act as specialised part-of-speech tags or \u201csyntactic topics\u201d. The third is a model that captures high-level relationships between documents. This model uses nonparametric Bayesian priors and Markov chain Monte Carlo methods to infer topic-based document clusters. The model assigns a higher probability to unseen test documents than either a clustering model without topics or a Bayesian topic model without document clusters. The model can be extended to incorporate author information, resulting in finer-grained clusters and better predictive performance."
            },
            "slug": "Structured-Topic-Models-for-Language-Wallach",
            "title": {
                "fragments": [],
                "text": "Structured Topic Models for Language"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This thesis introduces new methods for statistically modelling text using topic models that combine latent topics with information about document structure, ranging from local sentence structure to inter-document relationships."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859277"
                        ],
                        "name": "T. Plate",
                        "slug": "T.-Plate",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Plate",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Plate"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1197280,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a7a9eeb64ec4511ed1415baa4716da15e2897641",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A solution to the problem of representing compo-sitional structure using distributed representations is described. The method uses circular convolution to associate items, which are represented by v ec-tors. Arbitrary variable bindings, short sequences of various lengths, frames, and reduced representations can be compressed into a xed width vector. These representations are items in their own right, and can be used in constructing compositional structures. The noisy reconstructions given by convolution memories can be cleaned up by using a separate associative memory that has good recon-structive properties."
            },
            "slug": "Holographic-Reduced-Representations:-Convolution-Plate",
            "title": {
                "fragments": [],
                "text": "Holographic Reduced Representations: Convolution Algebra for Compositional Distributed Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A solution to the problem of representing compo-sitional structure using distributed representations is described, which uses circular convolution to associate items, which are represented by v ec-tors."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144553330"
                        ],
                        "name": "H. Neville",
                        "slug": "H.-Neville",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Neville",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Neville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39151594"
                        ],
                        "name": "J. Nicol",
                        "slug": "J.-Nicol",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Nicol",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nicol"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6060298"
                        ],
                        "name": "A. Barss",
                        "slug": "A.-Barss",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4750592"
                        ],
                        "name": "K. Forster",
                        "slug": "K.-Forster",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Forster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Forster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39997409"
                        ],
                        "name": "M. Garrett",
                        "slug": "M.-Garrett",
                        "structuredName": {
                            "firstName": "Merrill",
                            "lastName": "Garrett",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garrett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5090452,
            "fieldsOfStudy": [
                "Psychology",
                "Linguistics"
            ],
            "id": "21ace5a76dd71cefee73863d724eca1d0856bce9",
            "isKey": false,
            "numCitedBy": 839,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Theoretical considerations and diverse empirical data from clinical, psycholinguistic, and developmental studies suggest that language comprehension processes are decomposable into separate subsystems, including distinct systems for semantic and grammatical processing. Here we report that event-related potentials (ERPs) to syntactically well-formed but semantically anomalous sentences produced a pattern of brain activity that is distinct in timing and distribution from the patterns elicited by syntactically deviant sentences, and further, that different types of syntactic deviance produced distinct ERP patterns. Forty right-handed young adults read sentences presented at 2 words/sec while ERPs were recorded from over several positions between and within the hemispheres. Half of the sentences were semantically and grammatically acceptable and were controls for the remainder, which contained sentence medial words that violated (1) semantic expectations, (2) phrase structure rules, or (3) WH-movement constraints on Specificity and (4) Subjacency. As in prior research, the semantic anomalies produced a negative potential, N400, that was bilaterally distributed and was largest over posterior regions. The phrase structure violations enhanced the N125 response over anterior regions of the left hemisphere, and elicited a negative response (300-500 msec) over temporal and parietal regions of the left hemisphere. Violations of Specificity constraints produced a slow negative potential, evident by 125 msec, that was also largest over anterior regions of the left hemisphere. Violations of Subjacency constraints elicited a broadly and symmetrically distributed positivity that onset around 200 msec. The distinct timing and distribution of these effects provide biological support for theories that distinguish between these types of grammatical rules and constraints and more generally for the proposal that semantic and grammatical processes are distinct subsystems within the language faculty."
            },
            "slug": "Syntactically-Based-Sentence-Processing-Classes:-Neville-Nicol",
            "title": {
                "fragments": [],
                "text": "Syntactically Based Sentence Processing Classes: Evidence from Event-Related Brain Potentials"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The distinct timing and distribution of these effects provide biological support for theories that distinguish between these types of grammatical rules and constraints and more generally for the proposal that semantic and grammatical processes are distinct subsystems within the language faculty."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298207"
                        ],
                        "name": "P. Kanerva",
                        "slug": "P.-Kanerva",
                        "structuredName": {
                            "firstName": "Pentti",
                            "lastName": "Kanerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanerva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 733980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "425931e434f6b370cc6cdd2db58873843def7d7f",
            "isKey": false,
            "numCitedBy": 515,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "The 1990s saw the emergence of cognitive models that depend on very high dimensionality and randomness. They include Holographic Reduced Representations, Spatter Code, Semantic Vectors, Latent Semantic Analysis, Context-Dependent Thinning, and Vector-Symbolic Architecture. They represent things in high-dimensional vectors that are manipulated by operations that produce new high-dimensional vectors in the style of traditional computing, in what is called here hyperdimensional computing on account of the very high dimensionality. The paper presents the main ideas behind these models, written as a tutorial essay in hopes of making the ideas accessible and even provocative. A sketch of how we have arrived at these models, with references and pointers to further reading, is given at the end. The thesis of the paper is that hyperdimensional representation has much to offer to students of cognitive science, theoretical neuroscience, computer science and engineering, and mathematics."
            },
            "slug": "Hyperdimensional-Computing:-An-Introduction-to-in-Kanerva",
            "title": {
                "fragments": [],
                "text": "Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The thesis of the paper is that hyperdimensional representation has much to offer to students of cognitive science, theoretical neuroscience, computer science and engineering, and mathematics."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Computation"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38663378"
                        ],
                        "name": "J. Fodor",
                        "slug": "J.-Fodor",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Fodor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fodor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194015"
                        ],
                        "name": "Z. Pylyshyn",
                        "slug": "Z.-Pylyshyn",
                        "structuredName": {
                            "firstName": "Zenon",
                            "lastName": "Pylyshyn",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Pylyshyn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 212
                            }
                        ],
                        "text": "The problem of vector composition has received some attention in the connectionist literature, particularly in response to criticisms of the ability of connectionist representations to handle complex structures (Fodor and Pylyshyn, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29043627,
            "fieldsOfStudy": [
                "Philosophy",
                "Psychology"
            ],
            "id": "56cbfcbfffd8c54bd8477d10b6e0e17e097b97c7",
            "isKey": false,
            "numCitedBy": 3540,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectionism-and-cognitive-architecture:-A-Fodor-Pylyshyn",
            "title": {
                "fragments": [],
                "text": "Connectionism and cognitive architecture: A critical analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2326474"
                        ],
                        "name": "E. Heit",
                        "slug": "E.-Heit",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Heit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Heit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069432298"
                        ],
                        "name": "J. Rubinstein",
                        "slug": "J.-Rubinstein",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Rubinstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rubinstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 143
                            }
                        ],
                        "text": "We intend to assess the potential of our composition models on context sensitive semantic priming (Till et al., 1988) and inductive inference (Heit and Rubinstein, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9806284,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "fa4153addc25d8a1319066c628d3d750f36ca2fa",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Three experiments investigated the proposal that inductive inferences about different properties depend on different measures of similarity. In Experiments 1 and 2, Ss were given the premise that a category of animals has some property and judged the probability that another category of animals also has that property. Ss made the strongest inferences when the kind of property (anatomical or behavioral) corresponded to the kind of similarity between the animal categories (anatomical or behavioral). These results cannot be explained in terms of a single measure of similarity underlying induction. In Experiment 3, Ss rated the similarity of animal pairs with respect to anatomy or behavior. Regression analyses showed that both behavioral and anatomical similarity influenced behavioral inferences, but only anatomical similarity influenced anatomical inferences."
            },
            "slug": "Similarity-and-property-effects-in-inductive-Heit-Rubinstein",
            "title": {
                "fragments": [],
                "text": "Similarity and property effects in inductive reasoning."
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Three experiments investigated the proposal that inductive inferences about different properties depend on different measures of similarity, and found that Ss made the strongest inferences when the kind of property corresponded to theKind of similarity between the animal categories (anatomical or behavioral)."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Learning, memory, and cognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40756494"
                        ],
                        "name": "J. Metcalfe",
                        "slug": "J.-Metcalfe",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Metcalfe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Metcalfe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 138
                            }
                        ],
                        "text": "representations (RAAMS, Pollack, 1990), spatter codes (Kanerva, 1988), holographic reduced representations (Plate, 1995), and convolution (Metcalfe, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41426049,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "08703471946563df9b9682999b4a04d2d1ec4142",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, a highly interactive model of association formation, storage, and retrieval is described. Items, represented as sets of features, are associated by the operation of convolution. The associations are stored by being superimposed in a composite memory trace. Retrieval occurs when a cue item is correlated with the composite trace. The retrieved items are intrinsically noisy, may be ambiguous, and may under certain conditions be systematically distorted from their encoded form. A discrete response is selected by matching the retrieved item to all of the items in semantic memory. The model yields several new predictions about errors in single-trial cued recall that depend on similarity relations among the to-be-remembered items, and also about the efficacy of extralist cues. Experiments are presented that test these predictions against human recall. The model is then applied to several well-known results: prototype abstraction, the A-B A-D paradigm\u2014including the independence of the B and D responses\u2014 and the Osgood transfer surface."
            },
            "slug": "A-composite-holographic-associative-recall-model-Metcalfe",
            "title": {
                "fragments": [],
                "text": "A composite holographic associative recall model"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A highly interactive model of association formation, storage, and retrieval that is applied to several well-known results, yielding several new predictions about errors in single-trial cued recall that depend on similarity relations among the to-be-remembered items, and also about the efficacy of extralist cues."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35400286"
                        ],
                        "name": "Z. Harris",
                        "slug": "Z.-Harris",
                        "structuredName": {
                            "firstName": "Zellig",
                            "lastName": "Harris",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 38
                            }
                        ],
                        "text": "Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 205
                            }
                        ],
                        "text": "The appeal of these models lies in their ability to represent meaning simply by using distributional information under the assumption that words occurring within similar contexts are semantically similar (Harris, 1968)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32164517,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "99eadd5e29a85f30cafef7f2c915f384715e3b89",
            "isKey": false,
            "numCitedBy": 986,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We may not be able to make you love reading, but mathematical structures of language will lead you to love reading starting from now. Book is the window to open the new world. The world that you want is in the better stage and level. World will always guide you to even the prestige stage of the life. You know, this is some of how reading will give you the kindness. In this case, more books you read more knowledge you know, but it can mean also the bore is full."
            },
            "slug": "Mathematical-structures-of-language-Harris",
            "title": {
                "fragments": [],
                "text": "Mathematical structures of language"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors may not be able to make you love reading, but mathematical structures of language will lead you to love reading starting from now."
            },
            "venue": {
                "fragments": [],
                "text": "Interscience tracts in pure and applied mathematics"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776987"
                        ],
                        "name": "S. Vosniadou",
                        "slug": "S.-Vosniadou",
                        "structuredName": {
                            "firstName": "Stella",
                            "lastName": "Vosniadou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vosniadou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802934"
                        ],
                        "name": "A. Ortony",
                        "slug": "A.-Ortony",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Ortony",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ortony"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 221998343,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "5e98cace2c063e3eff6c317277121fa60ee13284",
            "isKey": false,
            "numCitedBy": 1210,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface Similarity and analogical reasoning: a synthesis Stella Vosniadou and Andrew Ortony Part I. Similarity and the Structure of Concepts: 1. Similarity, typicality, and categorization Lance J. Rips 2. Similarity and decision making Edward E. Smith and Daniel N. Osherson 3. Intraconcept similarity and its implications for interconcept similarity Lawrence W. Barsalou 4. Two-tiered concept meaning, inferential matching, and conceptual cohesiveness Ryszard S. Michalski 5. From global similarities to kinds of similarities: the construction of dimensions in development Linda B. Smith 6. Comments on Part I. Psychological essentialism Douglas Medin and Andrew Ortony Part II. Analogical Reasoning: 7. The mechanisms of analogical learning Dedre Genter 8. A computational model of analogical problem solving Keith J. Holyoak and Paul R. Thagard 9. Use of analogy in production system architecture John R. Anderson and Ross Thompson 10. Toward a microstructural account of human reasoning David E. Rumelhart 11. Analogy and the exercise of creativity Philip N. Johnson-Laird 12. Comments on Part II. Levels of description in information-processing theories of analogy Stephen E. Palmer 13. Comments on Part II. The role of explanation in analogy or, the curse of an alluring name Gerald Dejong Part III. Similarity and Analogy in Development, Learning and Instruction: 14. Analogical learning and transfer: what develops? Ann L. Brown 15. Analogical reasoning as a mechanism in knowledge acquisition: a developmental perspective Stella Vosniadou 16. Remindings in learning and instruction Brian H. Ross 17. New approaches to instruction: because wisdom can't be told John D. Bransford, Jeffery J. Franks, Nancy J. Vye and Robert Sherwood 18. Multiple analogies for complex concepts: antidotes for analogy-induced misconception in advanced knowledge acquisition Rand J. Spiro, Paul J. Feltovich, Richard L. Coulson and Daniel K. Anderson 19. Comments on Part III. The activation and acquisition of knowledge William F. Brewer Afterword Allan Collins and Mark Burstein Name index Subject index."
            },
            "slug": "Similarity-and-Analogical-Reasoning-Vosniadou-Ortony",
            "title": {
                "fragments": [],
                "text": "Similarity and Analogical Reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This book discusses Similarity and analogical reasoning as a mechanism in knowledge acquisition: a developmental perspective Stella Vosniadou and Andrew Ortony, and the mechanisms of analogical learning in development, learning and instruction."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1958983"
                        ],
                        "name": "D. Eakin",
                        "slug": "D.-Eakin",
                        "structuredName": {
                            "firstName": "Deborah",
                            "lastName": "Eakin",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eakin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8065473,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "cf7c27cb86c6112a9df8aee1ebc44a1a64c47ed6",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Various areas of research (e.g., memory, metamemory, visual word recognition, associative priming) rely on the careful construction of reliable word lists. ListChecker Pro 1.2 is a computer program that accesses the University of South Florida word association norms (Nelson, McEvoy, & Schreiber, 1998, 2004) to report characteristics of words (e.g., frequency, concreteness), as well as direct and indirect associative relationships (e.g., shared associates, mediators). The present article presents the input requirements, menu options, and output obtained by ListChecker Pro 1.2. In addition, a randomly selected list of words from the associative versus semantic priming literature was submitted to ListChecker Pro 1.2 to demonstrate how seemingly unrelated words can be associated. The zipped file containing the program and database can be downloaded from www .eakinmemorylab.psychology.msstate.edu."
            },
            "slug": "ListChecker-Pro-1.2:-A-program-designed-to-creating-Eakin",
            "title": {
                "fragments": [],
                "text": "ListChecker Pro 1.2: A program designed to facilitate creating word lists using the University of South Florida word association norms"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present article presents the input requirements, menu options, and output obtained by ListChecker Pro 1.2 and presents a randomly selected list of words from the associative versus semantic priming literature to demonstrate how seemingly unrelated words can be associated."
            },
            "venue": {
                "fragments": [],
                "text": "Behavior research methods"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2653356"
                        ],
                        "name": "R. E. Till",
                        "slug": "R.-E.-Till",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Till",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. E. Till"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3831099"
                        ],
                        "name": "E. F. Mross",
                        "slug": "E.-F.-Mross",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Mross",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. F. Mross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 42653521,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c7e8f3b6f78a770b3e2e51d58421b311452ab2fe",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The construction of word meanings in a discourse context was conceptualized as a process of sense activation, sense selection, and sense elaboration. In three experiments, subjects read texts presented by a rapid serial visual procedure and performed a lexical decision on visually presented targets that followed ambiguous prime words. When the target was a word, it was either an associate of the prime word, a probable inference suggested by the discourse, or an unrelated word. For associates, lexical decisions that related to either the appropriate or the inappropriate sense of the ambiguous word were generally facilitated at short (200-400 msec) prime-target stimulus onset asynchronies (SOAs). At longer SOAs, responses were faster to appropriate than to inappropriate associates. For the thematic inferences, there was no difference between these (appropriate) inferences and (inappropriate) control words at short SOAs. At long SOAs (1,000 and 1,500 msec), however, inference words were facilitated. The results are interpreted as consistent with a model of lexical processing in which sense activation functions independently of context. Discourse context effects, whether on sense selection (suppression of inappropriate associates) or on sense elaboration (creation of inferences), are seen as postlexical."
            },
            "slug": "Time-course-of-priming-for-associate-and-inference-Till-Mross",
            "title": {
                "fragments": [],
                "text": "Time course of priming for associate and inference words in a discourse context"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The construction of word meanings in a discourse context was conceptualized as a process of sense activation, sense selection, and sense elaboration and the results are interpreted as consistent with a model of lexical processing in which sense activation functions independently of context."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142223"
                        ],
                        "name": "M. Lesk",
                        "slug": "M.-Lesk",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lesk",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lesk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11892605,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "76e4e034c20bea86edcc6e71bbaddb47fafeecbc",
            "isKey": false,
            "numCitedBy": 2124,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The meaning of an English word can vary widely depending on which sense is intended. Does a fireman feed fires or put them out? It depends on whether or not he is on a steam locomotive. I am trying to decide automatically which sense of a word is intended (in written English) by using machine readable dictionaries, and looking for words in the sense definitions that overlap words in the definition of nearby words. The problem of deciding which sense of a word was intended by the writer is an important problem in information retrieval systems. At present most retrieval systems rely on manual indexing; if this is to be replaced with automatic text processing, it would be very desirable to recognize the correct sense of each word as often as possible. Previous work has generally either suggested (a) detailed frames describing the particular word senses,t*\u2019 or (b) global statistics about the word occurrences.3 The first has not yet been made available in any real application, and the second may give the wrong answer in specific local instances. This procedure uses available dictionaries, so that it will process any text; and uses solely the immediate context. To consider the example in the title, look at the definition of pine in the Oxford Advanced Learner\u2019s Dictionary of Current English: there are, of course, two major senses. \u201ckind of evergreen tree with needle-shaped leaves.. .\u201d and \u201cwaste away through sorrow or illness...\u201d And cone has three separate definitions: \u201csolid body which narrows to a\u2019 point . . . . *\u2019 \u201csomething of this shape w-hether solid or hollow...,\u201d and \u201cfruit of certain evergreen trees...\u201d Note that both evergreen and tree are common to two of the sense definitions: thus a program could guess that if the two words pine cone appear together, the likely senses are those of the tree and its fruit"
            },
            "slug": "Automatic-sense-disambiguation-using-machine-how-to-Lesk",
            "title": {
                "fragments": [],
                "text": "Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This procedure uses available dictionaries, so that it will process any text; and uses solely the immediate context to decide which sense of a word is intended (in written English)."
            },
            "venue": {
                "fragments": [],
                "text": "SIGDOC '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2009767"
                        ],
                        "name": "K. Holyoak",
                        "slug": "K.-Holyoak",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Holyoak",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Holyoak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725887"
                        ],
                        "name": "J. Hummel",
                        "slug": "J.-Hummel",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hummel",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hummel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our results show that the multiplicative models are superior and correlate significantly with behavioral data."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 15033838,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "8e975728daddfc0e6cfc2cb9495cb60559dbaba1",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "A foundational principle of modern cognitive science is the Physical Symbol System hypothesis, which states simply that human cognition is the product of a physical symbol system (PSS). A symbol is a pattern that denotes something else; a symbol system is a set of symbols that can be composed into more complex structures by a set of relations. The term \" physical \" conveys that a symbol system can and must be realized in some physical way in order to create intelligence. The physical basis may be the circuits of an electronic computer, the neural substrate of a thinking biological organism, or in principle anything else that could implement a Turing machine-like computing device. The PSS hypothesis, which implies that structured mental representations are central to human intelligence, was for some time uncontroversial, accepted by most cognitive scientists as an axiom of the field scarcely in need of either theoretical analysis or direct empirical support. In the mid-1980s, however, the hypothesis came under sharp attack from some proponents of connectionist models of cognition, particularly the advocates of models in the style of \" parallel many others; see Marcus, 1997, for a review). The representations used in such models are often described as \" subsymbolic \" because the elementary units correspond to (relatively) low-level features, over which meaningful concepts are represented in a distributed fashion. In so far as models based on \"subsymbolic\" representations are actually non-symbolic, yet adequate as accounts of human intelligence, the need for symbol systems would be eliminated; hence models of this general class constitute \"eliminative\" connectionism (Pinker & Prince, 1988). Eliminative connectionism offers a direct challenge to the PSS hypothesis, thereby transforming the latter from an axiom of cognitive science into a controversial theoretical position, which has been vigorously Regardless of whether models based on distributed representations provide genuine alternatives to physical symbol systems, it is apparent that they have attractive properties as possible algorithmic accounts of cognition. Discrete symbols represent entities in an \"all-or-none\" fashion, thereby violating the principle of least commitment (e.g., using the presence or absence of the symbol \"dog\" to represent the presence or absence of a dog affords no direct basis for expressing inconclusive evidence that there may be a dog). Discrete symbols also fail to express the semantic content of the represented entities (e.g., the symbols \"dog\" and \"cat\" do not signify what dogs and"
            },
            "slug": "The-Proper-Treatment-of-Symbols-in-a-Connectionist-Holyoak-Hummel",
            "title": {
                "fragments": [],
                "text": "The Proper Treatment of Symbols in a Connectionist Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Ezinative connectionism offers a direct challenge to the PSS hypothesis, thereby transforming the latter from an axiom of cognitive science into a controversial theoretical position, which has been vigorously Regardless of whether models based on distributed representations provide genuine alternatives to physical symbol systems, it is apparent that they have attractive properties as possible algorithmic accounts of cognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36568337"
                        ],
                        "name": "B. Ross",
                        "slug": "B.-Ross",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ross"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 21
                            }
                        ],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 144823696,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2acac0a804c04b16c5940f978efaccfb4aa477e5",
            "isKey": false,
            "numCitedBy": 648,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Novices attempting to solve a problem often are reminded of an earlier problem that illustrated a principle. Two experiments examined how these earlier problems are used and how this use is related to these remindings. Subjects studied four probability principles with related word problems. Test problems varied in their similarity to the study problems on story lines, objects, and correspondence of objects (variable roles). Experiment 1 tested whether remindings cue the principle or serve as the sources of detailed analogies. When the appropriate formula was provided with each test, the similarity of story lines had no effect, but object correspondences had a large effect. These results support an analogical account in which mapping is affected by the similarity of objects between study and test problems. Experiment 2 began to separate the aspects of similarity affecting the access and use of earlier problems by showing that, with confusable principles, similar story lines increased the access, but did not affect the use. The access appears to be sensitive to the relative similarity of examples because with distinctive principles, similar story lines had little effect. Discussion focuses on the further specification of the processes of noticing and analogical use of earlier problems."
            },
            "slug": "This-is-like-that:-The-use-of-earlier-problems-and-Ross",
            "title": {
                "fragments": [],
                "text": "This is like that: The use of earlier problems and the separation of similarity effects."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2009767"
                        ],
                        "name": "K. Holyoak",
                        "slug": "K.-Holyoak",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Holyoak",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Holyoak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46371477"
                        ],
                        "name": "K. Koh",
                        "slug": "K.-Koh",
                        "structuredName": {
                            "firstName": "Kyunghee",
                            "lastName": "Koh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Koh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13553955,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d44a35794785eba1164bc1bd2117f909112e4398",
            "isKey": false,
            "numCitedBy": 866,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Two experiments investigated factors that influence the retrieval and use of analogies in problem solving, Experiment 1 demonstrated substantial spontaneous analogical transfer with a delay of several days between presentation of the source and target analogues. Experiment 2 examined the influence of different types of similarity between the analogues. A mechanism for retrieval of source analogues is proposed, based on summation of activation from features shared with a target problem. The results of Experiment 2 indicated that both structural features, which play a causal role in determining possible problem solutions, and salient surface features, which do not have a causal role, influence spontaneous selection of an analogue. Structural features, however, have a greater impact than do surface features on a problem solver\u2019s ability to use an analogue once its relevance has been pointed out."
            },
            "slug": "Surface-and-structural-similarity-in-analogical-Holyoak-Koh",
            "title": {
                "fragments": [],
                "text": "Surface and structural similarity in analogical transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results of Experiment 2 indicated that both structural features and salient surface features influence spontaneous selection of an analogue, however, structural features have a greater impact than do surface features on a problem solver\u2019s ability to use an analogue once its relevance has been pointed out."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143902101"
                        ],
                        "name": "M. Masson",
                        "slug": "M.-Masson",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Masson",
                            "middleNames": [
                                "E",
                                "J"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Masson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 105
                            }
                        ],
                        "text": "Changes in the temporal order of words in a sentence decrease the strength of the related priming effect (Foss, 1982; Masson, 1986; O\u2019Seaghdha, 1989; Simpson, Peterson, Casteel, & Brugges, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143939538,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "31a9416d2eb177b536aafa3eeca819dc2df455f7",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Comprehension-of-rapidly-presented-sentences:-The-Masson",
            "title": {
                "fragments": [],
                "text": "Comprehension of rapidly presented sentences: The mind is quicker than the eye"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8167983"
                        ],
                        "name": "J. Raaijmakers",
                        "slug": "J.-Raaijmakers",
                        "structuredName": {
                            "firstName": "Jeroen",
                            "lastName": "Raaijmakers",
                            "middleNames": [
                                "G.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Raaijmakers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2355175"
                        ],
                        "name": "R. Shiffrin",
                        "slug": "R.-Shiffrin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Shiffrin",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shiffrin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 31
                            }
                        ],
                        "text": "Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 199929697,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "062d5eecccf8cc93eb781b85da130ec675da018d",
            "isKey": false,
            "numCitedBy": 1562,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes search of associative memory (SAM), a general theory of retrieval from long-term memory that combines features of associative network models and random search models. It posits cue-dependent probabilistic sampling and recovery from an associative network, but the network is specified as a retrieval structure rather than a storage structure. A quantitative computer simulation of SAM was developed and applied to the part-list cuing paradigm. When free recall of a list of words was cued by a random subset of words from that list, the probability of recalling one of the remaining words was less than if no cues were provided at all. SAM predicted this effect in all its variations by making extensive use of interword associations in retrieval, a process that previous theorizing has dismissed. (55 ref)"
            },
            "slug": "Search-of-associative-memory.-Raaijmakers-Shiffrin",
            "title": {
                "fragments": [],
                "text": "Search of associative memory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15291527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff2c2e3e83d1e8828695484728393c76ee07a101",
            "isKey": false,
            "numCitedBy": 15710,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The fundamental principles, basic mechanisms, and formal analyses involved in the development of parallel distributed processing (PDP) systems are presented in individual chapters contributed by leading experts. Topics examined include distributed representations, PDP models and general issues in cognitive science, feature discovery by competitive learning, the foundations of harmony theory, learning and relearning in Boltzmann machines, and learning internal representations by error propagation. Consideration is given to linear algebra in PDP, the logic of additive functions, resource requirements of standard and programmable nets, and the P3 parallel-network simulating system."
            },
            "slug": "Parallel-distributed-processing:-explorations-in-of-Rumelhart-McClelland",
            "title": {
                "fragments": [],
                "text": "Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767844"
                        ],
                        "name": "Diederik Aerts",
                        "slug": "Diederik-Aerts",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Aerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik Aerts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3278816"
                        ],
                        "name": "M. Czachor",
                        "slug": "M.-Czachor",
                        "structuredName": {
                            "firstName": "Marek",
                            "lastName": "Czachor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Czachor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Under this framework, we introduce novel composition models which we compare empirically against previous work using a rigorous evaluation methodology."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16701954,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "ec013e75fb6486994455db8c31d2feef71bb63a6",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A zipper tooth has a body portion with an opening at one end for connection to a tape to form a zipper stringer of a slide fastener. At the other end of the body portion is an engaging head. Just behind the engaging head are a pair of grooves, one on each side of the body portion. The grooves are contoured to accommodate portions of the engaging heads of other similar zipper teeth. At each end of each of the grooves are outwardly extending tapered projections. The projections are rolled over to provide endwalls for the grooves so that a cavity is formed for locking accepting portions of engaging heads of other zipper teeth."
            },
            "slug": "LETTER-TO-THE-EDITOR:-Quantum-aspects-of-semantic-Aerts-Czachor",
            "title": {
                "fragments": [],
                "text": "LETTER TO THE EDITOR: Quantum aspects of semantic analysis and symbolic artificial intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A zipper tooth has a body portion with an opening at one end for connection to a tape to form a zipper stringer of a slide fastener to accommodate portions of the engaging heads of other similar zipper teeth."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2693903"
                        ],
                        "name": "S. Pinker",
                        "slug": "S.-Pinker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Pinker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pinker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143780834,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8a99ddac28e5695589789609b1258958c2a6c70a",
            "isKey": false,
            "numCitedBy": 1277,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this classic, the world's expert on language and mind lucidly explains everything you always wanted to know about language: how it works, how children learn it, how it changes, how the brain computes it, and how it evolved. With deft use of examples of humor and wordplay, Steven Pinker weaves our vast knowledge of language into a compelling story: language is a human instinct, wired into our brains by evolution. The Language Instinct received the William James Book Prize from the American Psychological Association and the Public Interest Award from the Linguistics Society of America. This edition includes an update on advances in the science of language since The Language Instinct was first published."
            },
            "slug": "The-language-instinct-:-how-the-mind-creates-Pinker",
            "title": {
                "fragments": [],
                "text": "The language instinct : how the mind creates language"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2009767"
                        ],
                        "name": "K. Holyoak",
                        "slug": "K.-Holyoak",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Holyoak",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Holyoak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144729281"
                        ],
                        "name": "B. Morrison",
                        "slug": "B.-Morrison",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Morrison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Morrison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our results show that the multiplicative models are superior and correlate significantly with behavioral data."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 162009578,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "33b1b26482683129b9923f331873eb065c603dfd",
            "isKey": false,
            "numCitedBy": 1304,
            "numCiting": 294,
            "paperAbstract": {
                "fragments": [],
                "text": "The Cambridge Handbook of Thinking and Reasoning is the first comprehensive and authoritative handbook covering all the core topics of the field of thinking and reasoning. Written by the foremost experts from cognitive psychology, cognitive science, and cognitive neuroscience, individual chapters summarize basic concepts and findings for a major topic, sketch its history, and give a sense of the directions in which research is currently heading. The volume also includeswork related to developmental, social and clinical psychology, philosophy, economics, artificial intelligence, linguistics, education, law, and medicine. Scholars and students in all these fields and others will find this to be a valuable collection."
            },
            "slug": "The-Cambridge-handbook-of-thinking-and-reasoning-Holyoak-Morrison",
            "title": {
                "fragments": [],
                "text": "The Cambridge handbook of thinking and reasoning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298207"
                        ],
                        "name": "P. Kanerva",
                        "slug": "P.-Kanerva",
                        "structuredName": {
                            "firstName": "Pentti",
                            "lastName": "Kanerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanerva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 54
                            }
                        ],
                        "text": "Kintsch (2001) proposes a variation on the vector addition theme in an attempt to model how the meaning of a predicate (e.g.,run) varies depending on the arguments it operates upon (e.g,the horse ran vs. the color ran)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57931704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcdb9bd64e3d7885c10938291153257b94f3df91",
            "isKey": false,
            "numCitedBy": 1008,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nMotivated by the remarkable fluidity of memory the way in which items are pulled spontaneously and effortlessly from our memory by vague similarities to what is currently occupying our attention Sparse Distributed Memory presents a mathematically elegant theory of human long term memory. \nThe book, which is self contained, begins with background material from mathematics, computers, and neurophysiology; this is followed by a step by step development of the memory model. The concluding chapter describes an autonomous system that builds from experience an internal model of the world and bases its operation on that internal model. Close attention is paid to the engineering of the memory, including comparisons to ordinary computer memories. \nSparse Distributed Memory provides an overall perspective on neural systems. The model it describes can aid in understanding human memory and learning, and a system based on it sheds light on outstanding problems in philosophy and artificial intelligence. Applications of the memory are expected to be found in the creation of adaptive systems for signal processing, speech, vision, motor control, and (in general) robots. Perhaps the most exciting aspect of the memory, in its implications for research in neural networks, is that its realization with neuronlike components resembles the cortex of the cerebellum. \nPentti Kanerva is a scientist at the Research Institute for Advanced Computer Science at the NASA Ames Research Center and a visiting scholar at the Stanford Center for the Study of Language and Information. A Bradford Book."
            },
            "slug": "Sparse-Distributed-Memory-Kanerva",
            "title": {
                "fragments": [],
                "text": "Sparse Distributed Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Pentti Kanerva's Sparse Distributed Memory presents a mathematically elegant theory of human long term memory that resembles the cortex of the cerebellum, and provides an overall perspective on neural systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36568337"
                        ],
                        "name": "B. Ross",
                        "slug": "B.-Ross",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ross"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 119
                            }
                        ],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45244660,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ea126c28da4aa7f9635ebb79dba11eb4f68c6625",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Remindings-and-their-effects-in-learning-a-skill-Ross",
            "title": {
                "fragments": [],
                "text": "Remindings and their effects in learning a cognitive skill"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46831169"
                        ],
                        "name": "G. Hinton",
                        "slug": "G.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144323951"
                        ],
                        "name": "T. Shallice",
                        "slug": "T.-Shallice",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Shallice",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shallice"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 202927997,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e4250448b8b2511246a9eae881ca7397747d4750",
            "isKey": false,
            "numCitedBy": 479,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "A recurrent connectionist network was trained to output semantic feature vectors when presented with letter strings. When damaged, the network exhibited characteristics that resembled several of the phenomena found in deep dyslexia and semantic-access dyslexia. Damaged networks sometimes settled to the semantic vectors for semantically similar but visually dissimilar words. With severe damage, a forced-choice decision between categories was possible even when the choice of the particular semantic vector within the category was not possible. The damaged networks typically exhibited many mixed visual and semantic errors in which the output corresponded to a word that was both visually and semantically similar. Surprisingly, damage near the output sometimes caused pure visual errors. Indeed, the characteristic error pattern of deep dyslexia occurred with damage to virtually any part of the network."
            },
            "slug": "Lesioning-an-attractor-network:-investigations-of-Hinton-Shallice",
            "title": {
                "fragments": [],
                "text": "Lesioning an attractor network: investigations of acquired dyslexia"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144999249"
                        ],
                        "name": "G. Kane",
                        "slug": "G.-Kane",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Kane",
                            "middleNames": [
                                "Stanley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kane"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 71267845,
            "fieldsOfStudy": [
                "Computer Science",
                "History"
            ],
            "id": "78f6f0ac3d501cb0073a7d94edde5267044a59ae",
            "isKey": false,
            "numCitedBy": 2758,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural Computing: Theory and Practice , by Philip Wasserman, 230 pp, $41.95, with illus, ISBN 0-442-20743-3, New York, NY, Van Nostrand Reinhold, 1989. Neural Networks: A Tutorial , by Michael Chester, 182 pp, $38, with illus, ISBN 0-13-368903-4, Englewood Cliffs, NJ, Prentice Hall, 1993. Neural Networks: Algorithms, Applications, and Programming Techniques , by James Freeman and David Skapura, 401 pp, $50.50, with illus, ISBN 0-201-51376-5, Reading, Mass, Addison-Wesley, 1991. Understanding Neural Networks: Computer Explorations , vol 1: Basic Networks , vol 2: Advanced Networks , 309, 367 pp, by Maureen Caudill and Charles Butler, paper, with illus, spiral-bound, with 1 diskette/vol, $39.95/vol, vol 1: ISBN0-262-53102-X (Macintosh), 0-262-53099-6 (IBM), vol 2: ISBN 0-262-53103-8 (Macintosh), 0-262-53100-3 (IBM), Cambridge, Mass, The MIT Press, 1992. Artificial neural network research began in the early 1940s, advancing in fits and starts, until the late 1960s when Minsky and Papert published Perceptrons , in which they proved that neural networks, as then conceived, can"
            },
            "slug": "Parallel-Distributed-Processing:-Explorations-in-of-Kane",
            "title": {
                "fragments": [],
                "text": "Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vol 1: Foundations, vol 2: Psychological and Biological Models"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Artificial neural network research began in the early 1940s, advancing in fits and starts, until the late 1960s when Minsky and Papert published Perceptrons, in which they proved that neural networks, as then conceived, can be proved."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143694777"
                        ],
                        "name": "Frank Keller",
                        "slug": "Frank-Keller",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Keller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Keller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3613636"
                        ],
                        "name": "S. Gunasekharan",
                        "slug": "S.-Gunasekharan",
                        "structuredName": {
                            "firstName": "Subahshini",
                            "lastName": "Gunasekharan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gunasekharan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32498452"
                        ],
                        "name": "N. Mayo",
                        "slug": "N.-Mayo",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Mayo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Mayo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996123"
                        ],
                        "name": "M. Corley",
                        "slug": "M.-Corley",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Corley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Corley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17047232,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8db3dc5390a0fc7bd4e605aa493eaf5e42abaea6",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Although Internet-based experiments are gaining in popularity, most studies rely on directly evaluating participants\u2019 responses rather than response times. In the present article, we present two experiments that demonstrate the feasibility of collecting response latency data over the World-Wide Web using WebExp\u2014a software package designed to run psychological experiments over the Internet. Experiment 1 uses WebExp to collect measurements for known time intervals (generated using keyboard repetition). The resulting measurements are found to be accurate across platforms and load conditions. In Experiment 2, we use WebExp to replicate a lab-based self-paced reading study from the psycholinguistic literature. The data of the Web-based replication correlate significantly with those of the original study and show the same main effects and interactions. We conclude that WebExp can be used to obtain reliable response time data, at least for the self-paced reading paradigm."
            },
            "slug": "Timing-accuracy-of-Web-experiments:-A-case-study-Keller-Gunasekharan",
            "title": {
                "fragments": [],
                "text": "Timing accuracy of Web experiments: A case study using the WebExp software package"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Two experiments demonstrate the feasibility of collecting response latency data over the World-Wide Web using WebExp\u2014a software package designed to run psychological experiments over the Internet and conclude that WebExp can be used to obtain reliable response time data, at least for the self-paced reading paradigm."
            },
            "venue": {
                "fragments": [],
                "text": "Behavior research methods"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285789"
                        ],
                        "name": "C. Kulikowski",
                        "slug": "C.-Kulikowski",
                        "structuredName": {
                            "firstName": "Casimir",
                            "lastName": "Kulikowski",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kulikowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 38
                            }
                        ],
                        "text": "We employed leave-one-out resampling (Weiss and Kulikowski, 1991), by correlating the data obtained from each participant with the ratings obtained from all other participants."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12484204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "664b701a39371c5356754dc72cea1349233c8506",
            "isKey": false,
            "numCitedBy": 1046,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1 Overview of Learning Systems 1.1 What is a Learning System? 1.2 Motivation for Building Learning Systems 1.3 Types of Practical Empirical Learning Systems 1.3.1 Common Theme: The Classification Model 1.3.2 Let the Data Speak 1.4 What's New in Learning Methods 1.4.1 The Impact of New Technology 1.5 Outline of the Book 1.6 Bibliographical and Historical Remarks 2 How to Estimate the True Performance of a Learning System 2.1 The Importance of Unbiased Error Rate Estimation 2.2. What is an Error? 2.2.1 Costs and Risks 2.3 Apparent Error Rate Estimates 2.4 Too Good to Be True: Overspecialization 2.5 True Error Rate Estimation 2.5.1 The Idealized Model for Unlimited Samples 2.5.2 Train-and Test Error Rate Estimation 2.5.3 Resampling Techniques 2.5.4 Finding the Right Complexity Fit 2.6 Getting the Most Out of the Data 2.7 Classifier Complexity and Feature Dimensionality 2.7.1 Expected Patterns of Classifier Behavior 2.8 What Can Go Wrong? 2.8.1 Poor Features, Data Errors, and Mislabeled Classes 2.8.2 Unrepresentative Samples 2.9 How Close to the Truth? 2.10 Common Mistakes in Performance Analysis 2.11 Bibliographical and Historical Remarks 3 Statistical Pattern Recognition 3.1 Introduction and Overview 3.2 A Few Sample Applications 3.3 Bayesian Classifiers 3.3.1 Direct Application of the Bayes Rule 3.4 Linear Discriminants 3.4.1 The Normality Assumption and Discriminant Functions 3.4.2 Logistic Regression 3.5 Nearest Neighbor Methods 3.6 Feature Selection 3.7 Error Rate Analysis 3.8 Bibliographical and Historical Remarks 4 Neural Nets 4.1 Introduction and Overview 4.2 Perceptrons 4.2.1 Least Mean Square Learning Systems 4.2.2 How Good Is a Linear Separation Network? 4.3 Multilayer Neural Networks 4.3.1 Back-Propagation 4.3.2 The Practical Application of Back-Propagation 4.4 Error Rate and Complexity Fit Estimation 4.5 Improving on Standard Back-Propagation 4.6 Bibliographical and Historical Remarks 5 Machine Learning: Easily Understood Decision Rules 5.1 Introduction and Overview 5.2 Decision Trees 5.2.1 Finding the Perfect Tree 5.2.2 The Incredible Shrinking Tree 5.2.3 Limitations of Tree Induction Methods 5.3 Rule Induction 5.3.1 Predictive Value Maximization 5.4 Bibliographical and Historical Remarks 6 Which Technique is Best? 6.1 What's Important in Choosing a Classifier? 6.1.1 Prediction Accuracy 6.1.2 Speed of Learning and Classification 6.1.3 Explanation and Insight 6.2 So, How Do I Choose a Learning System? 6.3 Variations on the Standard Problem 6.3.1 Missing Data 6.3.2 Incremental Learning 6.4 Future Prospects for Improved Learning Methods 6.5 Bibliographical and Historical Remarks 7 Expert Systems 7.1 Introduction and Overview 7.1.1 Why Build Expert Systems? New vs. Old Knowledge 7.2 Estimating Error Rates for Expert Systems 7.3 Complexity of Knowledge Bases 7.3.1 How Many Rules Are Too Many? 7.4 Knowledge Base Example 7.5 Empirical Analysis of Knowledge Bases 7.6 Future: Combined Learning and Expert Systems 7.7 Bibliographical and Historical Remarks References Author Index Subject Index"
            },
            "slug": "Computer-Systems-That-Learn:-Classification-and-and-Weiss-Kulikowski",
            "title": {
                "fragments": [],
                "text": "Computer Systems That Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning and Expert Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This book discusses how to Estimate the True Performance of a Learning System, and the Importance of Unbiased Error Rate Estimation, and Machine Learning: Easily Understood Decision Rules."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670758"
                        ],
                        "name": "Jacob Cohen",
                        "slug": "Jacob-Cohen",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054136717"
                        ],
                        "name": "P. Cohen",
                        "slug": "P.-Cohen",
                        "structuredName": {
                            "firstName": "Patricia",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31291341"
                        ],
                        "name": "S. West",
                        "slug": "S.-West",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "West",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. West"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4246971"
                        ],
                        "name": "L. Aiken",
                        "slug": "L.-Aiken",
                        "structuredName": {
                            "firstName": "Leona",
                            "lastName": "Aiken",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Aiken"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "In order to establish which ones fit our data better, we examined whether the correlation coefficients achieved differ significantly using at-test (Cohen and Cohen, 1983)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121953269,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e2f4f64a17a05379e45f713d10d7c546bda7734a",
            "isKey": false,
            "numCitedBy": 30480,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Contents: Preface. Introduction. Bivariate Correlation and Regression. Multiple Regression/Correlation With Two or More Independent Variables. Data Visualization, Exploration, and Assumption Checking: Diagnosing and Solving Regression Problems I. Data-Analytic Strategies Using Multiple Regression/Correlation. Quantitative Scales, Curvilinear Relationships, and Transformations. Interactions Among Continuous Variables. Categorical or Nominal Independent Variables. Interactions With Categorical Variables. Outliers and Multicollinearity: Diagnosing and Solving Regression Problems II. Missing Data. Multiple Regression/Correlation and Causal Models. Alternative Regression Models: Logistic, Poisson Regression, and the Generalized Linear Model. Random Coefficient Regression and Multilevel Models. Longitudinal Regression Methods. Multiple Dependent Variables: Set Correlation. Appendices: The Mathematical Basis for Multiple Regression/Correlation and Identification of the Inverse Matrix Elements. Determination of the Inverse Matrix and Applications Thereof."
            },
            "slug": "Applied-multiple-regression/correlation-analysis-Cohen-Cohen",
            "title": {
                "fragments": [],
                "text": "Applied multiple regression/correlation analysis for the behavioral sciences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 76
                            }
                        ],
                        "text": "Computational models of semantics which use symbolic logic representations (Montague, 1974) can account naturally for the meaning of phrases or sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 60
                            }
                        ],
                        "text": "The simple additive model fails to distinguish between High and Low Similarity items."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "Here,burn is a high similarity landmark (High) for the referenceThe fire glowed, whereasbeam is a low similarity landmark (Low)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Model High Low \u03c1 NonComp 0.27 0.26 0.08**\nAdd 0.59 0.59 0.04* WeightAdd 0.35 0.34 0.09** Kintsch 0.47 0.45 0.09** Multiply 0.42 0.28 0.17** Combined 0.38 0.28 0.19** UpperBound 4.94 3.25 0.40**\naddition (equation (11), Combined)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our results show that the multiplicative models are superior and correlate significantly with behavioral data."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "More evidence that this is not an easy task comes from Figure 2 where we observe some overlap in the ratings for High and Low similarity items."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Table 2 shows the average model ratings for High\nnd Low similarity items."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "The difference between High and Low similarity values estimated by these models are statistically significant (p   0.01 using the Wilcoxon rank sum test)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "English as a formal language Formal philosophy"
            },
            "venue": {
                "fragments": [],
                "text": "English as a formal language Formal philosophy"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 103
                            }
                        ],
                        "text": "We observe a similar pattern for the non compositional baseline model, the weighted additive model and Kintsch (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Kintsch (2001) proposes a variation on the vector addition theme in an attempt to model how the meaning of a predicate (e.g.,run) varies depending on the arguments it operates upon (e.g,the horse ran vs. the color ran)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 48
                            }
                        ],
                        "text": "The downside of this approach is that differences in meaning are qualitative rather than quantitative, and degrees of similarity cannot be expressed easily."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 45
                            }
                        ],
                        "text": "When modeling predicate-argument structures, Kintsch (2001) proposes including one or more distributional neighbors,n, of the predicate:\np = u+v+\u2211n (10)\nNote that considerable latitude is allowed in selecting the appropriate neighbors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Kintsch (2001) considers only themmost similar neighbors to the predicate, from which he subsequently selectsk, those most similar to its argument."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 41
                            }
                        ],
                        "text": "In his study, Kintsch builds a model of how a verb\u2019s meaning is modified in the context of its subject."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 99
                            }
                        ],
                        "text": "We evaluated the models presented in Section 3 on a sentence similarity task initially proposed by Kintsch (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 15
                            }
                        ],
                        "text": "Unfortunately, Kintsch (2001) demonstrates how his own composition algorithm works intuitively on a few hand selected examples but does not provide a comprehensive test set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 97
                            }
                        ],
                        "text": "The weighted additive model (\u03c1 = 0.09) is not significantly different from the baseline either or Kintsch (2001) (\u03c1 = 0.09)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Predication. Cognitive Science"
            },
            "venue": {
                "fragments": [],
                "text": "Predication. Cognitive Science"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 35
                            }
                        ],
                        "text": "Landmarks were taken from WordNet (Fellbaum, 1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 170
                            }
                        ],
                        "text": "In order to reduce the set of items to a more manageable size and more importantly to guarantee that the phrases were indeed semantically similar, we resorted to WordNet (Fellbaum, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 119
                            }
                        ],
                        "text": "The opposite is the case for the referenceThe face\n3We assessed a wide range of semantic similarity measures using the WordNet similarity package (Pedersen et al., 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 108
                            }
                        ],
                        "text": "While background knowledge undoubtedly contributes to the compositional process, and resources like WordNet (Fellbaum, 1998) may be used to provide this information, from a methodological perspective it is preferable to understand the fundamental processes of how representations are composed before trying to understand the interaction between existing representations and those under construction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wordnet: An electronic lexical database (language, speech, and communication)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39340971"
                        ],
                        "name": "B. Partee",
                        "slug": "B.-Partee",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Partee",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Partee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116976482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07d2993d7b5cce0058c29010d5f85d4f2dc02067",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lexical-semantics-and-compositionality.-Partee",
            "title": {
                "fragments": [],
                "text": "Lexical semantics and compositionality."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102157754"
                        ],
                        "name": "G. Frege",
                        "slug": "G.-Frege",
                        "structuredName": {
                            "firstName": "Gottlob",
                            "lastName": "Frege",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Frege"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 169330149,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c746ff3fe16f15a5d7503f0554d2784a733b886e",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Die-Grundlagen-der-Arithmetik-Frege",
            "title": {
                "fragments": [],
                "text": "Die Grundlagen der Arithmetik"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40642524"
                        ],
                        "name": "A. Doumas",
                        "slug": "A.-Doumas",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Doumas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doumas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725887"
                        ],
                        "name": "J. Hummel",
                        "slug": "J.-Hummel",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hummel",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hummel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 164972488,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3d45455b8c06ff7598f590bb1b98acda70d4b567",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modeling-Human-Mental-Representations:-What-Works,-Doumas-Hummel",
            "title": {
                "fragments": [],
                "text": "Modeling Human Mental Representations: What Works, What doesn't and Why?"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117488877"
                        ],
                        "name": "Nolan Miller",
                        "slug": "Nolan-Miller",
                        "structuredName": {
                            "firstName": "Nolan",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nolan Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89117352"
                        ],
                        "name": "G. Oldham",
                        "slug": "G.-Oldham",
                        "structuredName": {
                            "firstName": "Gerda",
                            "lastName": "Oldham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Oldham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2693903"
                        ],
                        "name": "S. Pinker",
                        "slug": "S.-Pinker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Pinker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pinker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 164152624,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "63458be2006a89c4b1469e49f1bed09e45929a94",
            "isKey": false,
            "numCitedBy": 1161,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Language-Instinct:-How-the-Mind-Creates-Miller-Oldham",
            "title": {
                "fragments": [],
                "text": "The Language Instinct: How the Mind Creates Language"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221897174,
            "fieldsOfStudy": [],
            "id": "5ef85c2768adaf728295324869e26c638f553706",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the nature and scope of featural representations of word meaning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35031308"
                        ],
                        "name": "C. Osgood",
                        "slug": "C.-Osgood",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Osgood",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Osgood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4462273"
                        ],
                        "name": "G. Suci",
                        "slug": "G.-Suci",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Suci",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Suci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1937895"
                        ],
                        "name": "P. Tannenbaum",
                        "slug": "P.-Tannenbaum",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Tannenbaum",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tannenbaum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 144731157,
            "fieldsOfStudy": [
                "Psychology",
                "Sociology"
            ],
            "id": "08617e3249989e8f35cb093185883b6cb169652d",
            "isKey": false,
            "numCitedBy": 7158,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Measurement-of-Meaning-Osgood-Suci",
            "title": {
                "fragments": [],
                "text": "The Measurement of Meaning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144541931"
                        ],
                        "name": "Edward E. Smith",
                        "slug": "Edward-E.-Smith",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Smith",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward E. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023259"
                        ],
                        "name": "D. Medin",
                        "slug": "D.-Medin",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Medin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Medin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 144952337,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "f9f79457703ec65a8c21b2017365bd9e176be800",
            "isKey": false,
            "numCitedBy": 1740,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Categories-and-concepts-Smith-Medin",
            "title": {
                "fragments": [],
                "text": "Categories and concepts"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36568337"
                        ],
                        "name": "B. Ross",
                        "slug": "B.-Ross",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ross"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 144801745,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "85d9466e4dce5f59330396905c563b4829298a02",
            "isKey": false,
            "numCitedBy": 470,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Distinguishing-Types-of-Superficial-Similarities:-Ross",
            "title": {
                "fragments": [],
                "text": "Distinguishing Types of Superficial Similarities: Different Effects on the Access and Use of Earlier Problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 91
                            }
                        ],
                        "text": "Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 222292355,
            "fieldsOfStudy": [],
            "id": "a6fb18698a57122ffb7b5ccb04b513ac6f055dcf",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Choice, similarity, and the context theory of classification."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39340971"
                        ],
                        "name": "B. Partee",
                        "slug": "B.-Partee",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Partee",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Partee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124676946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfe99696be15b4edc86650f19b478a32ba48d344",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Compositionality-in-Formal-Semantics-Partee",
            "title": {
                "fragments": [],
                "text": "Compositionality in Formal Semantics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3679969"
                        ],
                        "name": "O. Spies",
                        "slug": "O.-Spies",
                        "structuredName": {
                            "firstName": "Otto",
                            "lastName": "Spies",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Spies"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119008519,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e4c25e5db186835944660b11196dfe66bd6608a0",
            "isKey": false,
            "numCitedBy": 311,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Die-grundlagen-der-arithmetik:-by-G.-Frege.-English-Spies",
            "title": {
                "fragments": [],
                "text": "Die grundlagen der arithmetik: by G. Frege. English translation by J. L. Austin. 119 pages, 14 \u00d7 22 cm. Breslau, Verlag von Wilhelm Koebner, 1884, and New York, Philosophical Library, 1950. Price, $4.75"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331233"
                        ],
                        "name": "A. Markman",
                        "slug": "A.-Markman",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Markman",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Markman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 65466606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c94d84bf230b6eaa1af83cafd4de2046af3394b",
            "isKey": false,
            "numCitedBy": 943,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Knowledge-Representation-Markman",
            "title": {
                "fragments": [],
                "text": "Knowledge Representation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48959839"
                        ],
                        "name": "R. Montague",
                        "slug": "R.-Montague",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Montague",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Montague"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 75
                            }
                        ],
                        "text": "Computational models of semantics which use symbolic logic representations (Montague, 1974) can account naturally for the meaning of phrases or sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60562957,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "1b5ad278a01a2c91f35c4c86fbbffc09d6fe2d72",
            "isKey": false,
            "numCitedBy": 699,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ENGLISH-AS-A-FORMAL-LANGUAGE-Montague",
            "title": {
                "fragments": [],
                "text": "ENGLISH AS A FORMAL LANGUAGE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144263847"
                        ],
                        "name": "J. Deese",
                        "slug": "J.-Deese",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Deese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Deese"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 18
                            }
                        ],
                        "text": "Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30259120,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "id": "03894f9f549972bd77963172ccecc4e8144a72f4",
            "isKey": false,
            "numCitedBy": 1884,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-prediction-of-occurrence-of-particular-in-Deese",
            "title": {
                "fragments": [],
                "text": "On the prediction of occurrence of particular verbal intrusions in immediate recall."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology"
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2500077"
                        ],
                        "name": "Julie Weeds",
                        "slug": "Julie-Weeds",
                        "structuredName": {
                            "firstName": "Julie",
                            "lastName": "Weeds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julie Weeds"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 22521075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb8b0c56bad2d3952ad1a71ed479b1679e0963eb",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 217,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Measures-and-applications-of-lexical-distributional-Weeds",
            "title": {
                "fragments": [],
                "text": "Measures and applications of lexical distributional similarity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428338"
                        ],
                        "name": "Freddy Y. Y. Choi",
                        "slug": "Freddy-Y.-Y.-Choi",
                        "structuredName": {
                            "firstName": "Freddy",
                            "lastName": "Choi",
                            "middleNames": [
                                "Y.",
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Freddy Y. Y. Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400286782"
                        ],
                        "name": "P. Wiemer-Hastings",
                        "slug": "P.-Wiemer-Hastings",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Wiemer-Hastings",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Wiemer-Hastings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47147237"
                        ],
                        "name": "Johanna D. Moore",
                        "slug": "Johanna-D.-Moore",
                        "structuredName": {
                            "firstName": "Johanna",
                            "lastName": "Moore",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johanna D. Moore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 79
                            }
                        ],
                        "text": ", 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al., 2001) , and notably information retrieval (Salton et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 219
                            }
                        ],
                        "text": "\u2026include automatic thesaurus extraction (Grefenstette, 1994), word sense discrimination (Schu\u0308tze, 1998) and disambiguation (McCarthy et al., 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al., 2001) , and notably information retrieval (Salton et al., 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39184340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "405297d1cf45a2375a6a20294a5f28b5a4633cd0",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Latent-Semantic-Analysis-for-Text-Segmentation-Choi-Wiemer-Hastings",
            "title": {
                "fragments": [],
                "text": "Latent Semantic Analysis for Text Segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Features: sentence vectors concatenated (con), subtracted (sub), encoding of words in sentence (enc), sentence vector similarity, unigram overlap, sentence lengths Model Acc"
            },
            "venue": {
                "fragments": [],
                "text": "Features: sentence vectors concatenated (con), subtracted (sub), encoding of words in sentence (enc), sentence vector similarity, unigram overlap, sentence lengths Model Acc"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Under this framework, we introduce novel composition models which we compare empirically against previous work using a rigorous evaluation methodology."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introducing word order in an lsa framework Latent semantic analysis: A road to meaning"
            },
            "venue": {
                "fragments": [],
                "text": "Introducing word order in an lsa framework Latent semantic analysis: A road to meaning"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lexical and context effects in word recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Experimental Psychology: Learning, Memory and Cognition,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Features: sentence vectors concatenated (con), subtracted (sub), encoding of words in sentence (enc), sentence vector similarity, unigram overlap, sentence lengths Model Acc"
            },
            "venue": {
                "fragments": [],
                "text": "Features: sentence vectors concatenated (con), subtracted (sub), encoding of words in sentence (enc), sentence vector similarity, unigram overlap, sentence lengths Model Acc"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rethinking innateness: A connectionist perspective"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Linguistic gestalts"
            },
            "venue": {
                "fragments": [],
                "text": "W. Beach, S. Fox, & S. Philosoph (Eds.), Papers from the 13th Regional Meeting, Chicago Linguistic Society (pp. 236\u2013287). Chicago, Illinois: Chicago Linguistic Society."
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 91
                            }
                        ],
                        "text": "All occurrences of these verbs with a subject noun were next extracted from a RASP parsed (Briscoe and Carroll, 2002) version of the British National Corpus (BNC)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust accurate statistical"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Idioms. Language"
            },
            "venue": {
                "fragments": [],
                "text": "Idioms. Language"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Microsoft Research Paraphrase Corpus"
            },
            "venue": {
                "fragments": [],
                "text": "Microsoft Research Paraphrase Corpus"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 38
                            }
                        ],
                        "text": "We employed leave-one-out resampling (Weiss and Kulikowski, 1991), by correlating the data obtained from each participant with the ratings obtained from all other participants."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1991.Computer Systems that Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning, and Expert Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 114
                            }
                        ],
                        "text": ", 2007), discourse comprehension (Landauer & Dumais, 1997; Foltz, Kintsch, & Landauer, 1998), word categorization (Laham, 2000), judgments of essay quality (Landauer, Laham, Rehder, & Schreiner, 1997a), synonymy tests (Landauer & Dumais, 1997; Griffiths et al."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automated content assessment of text using latent semantic analysis to simulate human cognition"
            },
            "venue": {
                "fragments": [],
                "text": "Unpublished doctoral dissertation, University of Colorado at Boulder."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WordNet: An Electronic Database"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our results show that the multiplicative models are superior and correlate significantly with behavioral data."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Compositionality and systematicity Amsterdam: KNAW publications"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive foundations of interpretation"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Paraphrasing with bilingual parallel corpora. In Proceedings of the 43rd annual meeting of the association for computational linguistics (pp. 597\u2013604)"
            },
            "venue": {
                "fragments": [],
                "text": "Ann Arbor"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Under this framework, we introduce novel composition models which we compare empirically against previous work using a rigorous evaluation methodology."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Holographic reduced representations [Paper]"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector-based models of semantic composition"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of acl-08: Hlt (pp. 236\u2013244)"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 243
                            }
                        ],
                        "text": "For example, by defining context in terms of syntactic dependencies (Grefenstette, 1994; Lin, 1998; Pad\u00f3 & Lapata, 2007) or by taking into account relational information about how roles and fillers combine to create specific factual knowledge (Dennis, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introducing word order in an lsa framework"
            },
            "venue": {
                "fragments": [],
                "text": "P. Press (Ed.), Latent semantic analysis: A road to meaning (pp. 449\u2013464). Thomas K. Landauer and Danielle S. McNamara and Simon Dennis and Walter Kintsch."
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lexical semantics and compositionality Invitation to cognitive science part i: Language (pp"
            },
            "venue": {
                "fragments": [],
                "text": "Lexical semantics and compositionality Invitation to cognitive science part i: Language (pp"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 132
                            }
                        ],
                        "text": "Examples include automatic thesaurus extraction (Grefenstette, 1994), word sense discrimination (Schu\u0308tze, 1998) and disambiguation (McCarthy et al., 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al., 2001) , and notably information retrieval (Salton et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 132
                            }
                        ],
                        "text": "Examples include automatic thesaurus extraction (Grefenstette, 1994), word sense discrimination (Sch \u00fctze, 1998) and disambiguation (McCarthy et al., 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Finding predominant senses in untagged text"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 99
                            }
                        ],
                        "text": "We intend to assess the potential of our composition models on context sensitive semantic priming (Till et al., 1988) and inductive inference (Heit and Rubinstein, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 86
                            }
                        ],
                        "text": ", 1991; West and Stanovich, 1986) and modulate cognitive behavior in sentence priming (Till et al., 1988) and inference tasks (Heit and"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 225
                            }
                        ],
                        "text": "\u2026empirical evidence that syntactic relations across and within sentences are crucial for sentence and discourse processing (Neville et al., 1991; West and Stanovich, 1986) and modulate cognitive behavior in sentence priming (Till et al., 1988) and inference tasks (Heit and\n236\nRubinstein, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Time course of priming for associate and inference words in discourse context.Memory and Cognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Richard Socher (http://www.socher.org/) University of Trento, COMPOSES (http://clic.cimec.unitn.it/composes/) Universities of Oxford and Cambridge"
            },
            "venue": {
                "fragments": [],
                "text": "Brian Murphy) Workshop at ACL-2013: Continuous Vector Space Models and their Compositionality"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 40,
            "methodology": 26,
            "result": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 135,
        "totalPages": 14
    },
    "page_url": "https://www.semanticscholar.org/paper/Vector-based-Models-of-Semantic-Composition-Mitchell-Lapata/b5d67d1dc671bce42a9daac0c3605adb3fcfc697?sort=total-citations"
}