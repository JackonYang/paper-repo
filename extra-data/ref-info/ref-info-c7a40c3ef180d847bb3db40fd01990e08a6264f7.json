{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 221
                            }
                        ],
                        "text": "Recent work has addressed this problem by learning semantic parsers given sentences paired with logical meaning representations (Thompson & Mooney, 2002; Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 0
                            }
                        ],
                        "text": "Zettlemoyer & Collins (2005, 2007) developed CCG grammar induction techniques where lexical items are proposed according to a set of hand-engineered lexical templates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1223\u20131233, MIT, Massachusetts, USA, 9-11 October 2010. c\u00a92010 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 166
                            }
                        ],
                        "text": "The full Geo880 dataset contains 880 (Englishsentence, logical-form) pairs, which we split into a development set of 600 pairs and a test set of 280 pairs, following Zettlemoyer & Collins (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 97
                            }
                        ],
                        "text": "We also compare performance to previous methods (Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008), which are designed with either language- or representation- specific constraints that limit generalization, as discussed in more detail in Section 6."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 258
                            }
                        ],
                        "text": "\u2026discriminates between analyses using a log-linear CCG parsing model, similar to those used in previous work (Clark & Curran, 2003, 2007), but differing in that the syntactic parses are treated as a hidden variable during training, following the approach of Zettlemoyer & Collins (2005, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 449252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74fe7ec751cd50295b15cfd46389a8fefb37c414",
            "isKey": false,
            "numCitedBy": 874,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of mapping natural language sentences to lambda\u2013calculus encodings of their meaning. We describe a learning algorithm that takes as input a training set of sentences labeled with expressions in the lambda calculus. The algorithm induces a grammar for the problem, along with a log-linear model that represents a distribution over syntactic and semantic analyses conditioned on the input sentence. We apply the method to the task of learning natural language interfaces to databases and show that the learned parsers outperform previous methods in two benchmark database domains."
            },
            "slug": "Learning-to-Map-Sentences-to-Logical-Form:-with-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A learning algorithm is described that takes as input a training set of sentences labeled with expressions in the lambda calculus and induces a grammar for the problem, along with a log-linear model that represents a distribution over syntactic and semantic analyses conditioned on the input sentence."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 0
                            }
                        ],
                        "text": "Zettlemoyer & Collins (2005, 2007) developed CCG grammar induction techniques where lexical items are proposed according to a set of hand-engineered lexical templates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 258
                            }
                        ],
                        "text": "\u2026discriminates between analyses using a log-linear CCG parsing model, similar to those used in previous work (Clark & Curran, 2003, 2007), but differing in that the syntactic parses are treated as a hidden variable during training, following the approach of Zettlemoyer & Collins (2005, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 221
                            }
                        ],
                        "text": "Recent work has addressed this problem by learning semantic parsers given sentences paired with logical meaning representations (Thompson & Mooney, 2002; Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 97
                            }
                        ],
                        "text": "We also compare performance to previous methods (Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008), which are designed with either language- or representation- specific constraints that limit generalization, as discussed in more detail in Section 6."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 12728987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "774113732db34ce0b797fc3dcceded811fb6edbc",
            "isKey": false,
            "numCitedBy": 448,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning to parse sentences to lambda-calculus representations of their underlying semantics and present an algorithm that learns a weighted combinatory categorial grammar (CCG). A key idea is to introduce non-standard CCG combinators that relax certain parts of the grammar\u2014for example allowing flexible word order, or insertion of lexical items\u2014 with learned costs. We also present a new, online algorithm for inducing a weighted CCG. Results for the approach on ATIS data show 86% F-measure in recovering fully correct semantic analyses and 95.9% F-measure by a partial-match criterion, a more than 5% improvement over the 90.3% partial-match figure reported by He and Young (2006)."
            },
            "slug": "Online-Learning-of-Relaxed-CCG-Grammars-for-Parsing-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Online Learning of Relaxed CCG Grammars for Parsing to Logical Form"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A key idea is to introduce non-standard CCG combinators that relax certain parts of the grammar\u2014for example allowing flexible word order, or insertion of lexical items\u2014 with learned costs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143844110"
                        ],
                        "name": "Wei Lu",
                        "slug": "Wei-Lu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740222"
                        ],
                        "name": "Wee Sun Lee",
                        "slug": "Wee-Sun-Lee",
                        "structuredName": {
                            "firstName": "Wee",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wee Sun Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Lu et al. (2008) (Lu08) developed a generative model that builds a single hybrid tree of words, syntax and meaning representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 256
                            }
                        ],
                        "text": "Recent work has addressed this problem by learning semantic parsers given sentences paired with logical meaning representations (Thompson & Mooney, 2002; Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 56
                            }
                        ],
                        "text": "We use the same folds as Wong & Mooney (2006, 2007) and Lu et al. (2008), allowing a direct comparison."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 280
                            }
                        ],
                        "text": "\u2026eyaletin texas ye siniri vardir Meaning: answer(state(borders(tex)))\nwhere the sentence is in Turkish and the meaning representation is a variable-free logical expression of the type that has been used in recent work (Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 132
                            }
                        ],
                        "text": "We also compare performance to previous methods (Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008), which are designed with either language- or representation- specific constraints that limit generalization, as discussed in more detail in Section 6."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 148
                            }
                        ],
                        "text": "where the sentence is in Turkish and the meaning representation is a variable-free logical expression of the type that has been used in recent work (Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8045822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d39d39a6246c13928bbd66d122f3e61e67b584ef",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an algorithm for learning a generative model of natural language sentences together with their formal meaning representations with hierarchical structures. The model is applied to the task of mapping sentences to hierarchical representations of their underlying meaning. We introduce dynamic programming techniques for efficient training and decoding. In experiments, we demonstrate that the model, when coupled with a discriminative reranking technique, achieves state-of-the-art performance when tested on two publicly available corpora. The generative model degrades robustly when presented with instances that are different from those seen in training. This allows a notable improvement in recall compared to previous models."
            },
            "slug": "A-Generative-Model-for-Parsing-Natural-Language-to-Lu-Ng",
            "title": {
                "fragments": [],
                "text": "A Generative Model for Parsing Natural Language to Meaning Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The generative model is applied to the task of mapping sentences to hierarchical representations of their underlying meaning and achieves state-of-the-art performance when tested on two publicly available corpora."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641"
                        ],
                        "name": "Rohit J. Kate",
                        "slug": "Rohit-J.-Kate",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Kate",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rohit J. Kate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 219
                            }
                        ],
                        "text": "\u2026eyaletin texas ye siniri vardir Meaning: answer(state(borders(tex)))\nwhere the sentence is in Turkish and the meaning representation is a variable-free logical expression of the type that has been used in recent work (Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 148
                            }
                        ],
                        "text": "where the sentence is in Turkish and the meaning representation is a variable-free logical expression of the type that has been used in recent work (Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 154
                            }
                        ],
                        "text": "Recent work has addressed this problem by learning semantic parsers given sentences paired with logical meaning representations (Thompson & Mooney, 2002; Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7396224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dd9fd6a45afd266d48255c398429e01ea4fd6db",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language. The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non-terminal symbols in this grammar. The learned transformation rules incrementally map a natural-language sentence or its syntactic parse tree into a parse-tree for the target formal language. Experimental results are presented for two corpora. one which maps English instructions into an existing formal coaching language for simulated RoboCup soccer agents, and another which maps English U.S.-geography questions into a database query language. We show that our method performs overall better and faster than previous approaches in both domains."
            },
            "slug": "Learning-to-Transform-Natural-to-Formal-Languages-Kate-Wong",
            "title": {
                "fragments": [],
                "text": "Learning to Transform Natural to Formal Languages"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language and shows that this method performs overall better and faster than previous approaches in both domains."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 13
                            }
                        ],
                        "text": "WASP system (Wong & Mooney, 2006) uses statistical machine translation techniques to learn synchronous context free grammars containing both words and logic."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 194
                            }
                        ],
                        "text": "Recent work has addressed this problem by learning semantic parsers given sentences paired with logical meaning representations (Thompson & Mooney, 2002; Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 25
                            }
                        ],
                        "text": "We use the same folds as Wong & Mooney (2006, 2007) and Lu et al. (2008), allowing a direct comparison."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 259
                            }
                        ],
                        "text": "\u2026eyaletin texas ye siniri vardir Meaning: answer(state(borders(tex)))\nwhere the sentence is in Turkish and the meaning representation is a variable-free logical expression of the type that has been used in recent work (Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1223\u20131233, MIT, Massachusetts, USA, 9-11 October 2010. c\u00a92010 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 70
                            }
                        ],
                        "text": "We also compare performance to previous methods (Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008), which are designed with either language- or representation- specific constraints that limit generalization, as discussed in more detail in Section 6."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 7785983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "687dce9ac01f5996601655035c34b449c27c3b6a",
            "isKey": true,
            "numCitedBy": 293,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel statistical approach to semantic parsing, WASP, for constructing a complete, formal meaning representation of a sentence. A semantic parser is learned given a set of sentences annotated with their correct meaning representations. The main innovation of WASP is its use of state-of-the-art statistical machine translation techniques. A word alignment model is used for lexical acquisition, and the parsing model itself can be seen as a syntax-based translation model. We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision, and shows better robustness to variations in task complexity and word order."
            },
            "slug": "Learning-for-Semantic-Parsing-with-Statistical-Wong-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning for Semantic Parsing with Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision, and shows better robustness to variations in task complexity and word order."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 150
                            }
                        ],
                        "text": "We\nare also interested in developing similar grammar induction techniques for context-dependent understanding problems, such as the one considered by Zettlemoyer & Collins (2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1950452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07216ee1119f61b351b69e94b2e7c3698d96b026",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning context-dependent mappings from sentences to logical form. The training examples are sequences of sentences annotated with lambda-calculus meaning representations. We develop an algorithm that maintains explicit, lambda-calculus representations of salient discourse entities and uses a context-dependent analysis pipeline to recover logical forms. The method uses a hidden-variable variant of the perception algorithm to learn a linear model used to select the best analysis. Experiments on context-dependent utterances from the ATIS corpus show that the method recovers fully correct logical forms with 83.7% accuracy."
            },
            "slug": "Learning-Context-Dependent-Mappings-from-Sentences-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Learning Context-Dependent Mappings from Sentences to Logical Form"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm is developed that maintains explicit, lambda-calculus representations of salient discourse entities and uses a context-dependent analysis pipeline to recover logical forms and a hidden-variable variant of the perception algorithm to learn a linear model used to select the best analysis."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 25
                            }
                        ],
                        "text": "We use the same folds as Wong & Mooney (2006, 2007) and Lu et al. (2008), allowing a direct comparison."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 194
                            }
                        ],
                        "text": "Recent work has addressed this problem by learning semantic parsers given sentences paired with logical meaning representations (Thompson & Mooney, 2002; Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 13
                            }
                        ],
                        "text": "For example, Wong & Mooney (2007) developed a variant of WASP (\u03bb-WASP) specifically designed for this alternate representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 70
                            }
                        ],
                        "text": "We also compare performance to previous methods (Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008), which are designed with either language- or representation- specific constraints that limit generalization, as discussed in more detail in Section 6."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 9337134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2ecc66c0e5f976b0e0d95c64ed2d1e283a2625d",
            "isKey": true,
            "numCitedBy": 354,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the first empirical results to our knowledge on learning synchronous grammars that generate logical forms. Using statistical machine translation techniques, a semantic parser based on a synchronous context-free grammar augmented with \ufffdoperators is learned given a set of training sentences and their correct logical forms. The resulting parser is shown to be the bestperforming system so far in a database query domain."
            },
            "slug": "Learning-Synchronous-Grammars-for-Semantic-Parsing-Wong-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A semantic parser based on a synchronous context-free grammar augmented with \ufffdoperators is learned given a set of training sentences and their correct logical forms, and is shown to be the bestperforming system so far in a database query domain."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255957"
                        ],
                        "name": "Cynthia A. Thompson",
                        "slug": "Cynthia-A.-Thompson",
                        "structuredName": {
                            "firstName": "Cynthia",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cynthia A. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1223\u20131233, MIT, Massachusetts, USA, 9-11 October 2010. c\u00a92010 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 129
                            }
                        ],
                        "text": "Recent work has addressed this problem by learning semantic parsers given sentences paired with logical meaning representations (Thompson & Mooney, 2002; Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 805082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbd3bb68861808eadd8c0ef2734fd0cd666305d9",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on a system, WOLFIE (WOrd Learning From Interpreted Examples), that acquires a semantic lexicon from a corpus of sentences paired with semantic representations. The lexicon learned consists of phrases paired with meaning representations. WOLFIE is part of an integrated system that learns to transform sentences into representations such as logical database queries. \n \nExperimental results are presented demonstrating WOLFIE's ability to learn useful lexicons for a database interface in four different natural languages. The usefulness of the lexicons learned by WOLFIE are compared to those acquired by a similar system, with results favorable to WOLFIE. A second set of experiments demonstrates WOLFIE's ability to scale to larger and more difficult, albeit artificially generated, corpora. \n \nIn natural language acquisition, it is difficult to gather the annotated data needed for supervised learning; however, unannotated data is fairly plentiful. Active learning methods attempt to select for annotation and training only the most informative examples, and therefore are potentially very useful in natural language applications. However, most results to date for active learning have only considered standard classification tasks. To reduce annotation effort while maintaining accuracy, we apply active learning to semantic lexicons. We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance."
            },
            "slug": "Acquiring-Word-Meaning-Mappings-for-Natural-Thompson-Mooney",
            "title": {
                "fragments": [],
                "text": "Acquiring Word-Meaning Mappings for Natural Language Interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance, and is applied to semantic lexicons."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733593"
                        ],
                        "name": "J. Curran",
                        "slug": "J.-Curran",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Curran",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Curran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8701528,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d45f21c9deb17987a6be71b3c9a2758791540a2",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes a number of log-linear parsing models for an automatically extracted lexicalized grammar. The models are full parsing models in the sense that probabilities are defined for complete parses, rather than for independent events derived by decomposing the parse tree. Discriminative training is used to estimate the models, which requires incorrect parses for each sentence in the training data as well as the correct parse. The lexicalized grammar formalism used is Combinatory Categorial Grammar (CCG), and the grammar is automatically extracted from CCGbank, a CCG version of the Penn Treebank. The combination of discriminative training and an automatically extracted grammar leads to a significant memory requirement (up to 25 GB), which is satisfied using a parallel implementation of the BFGS optimization algorithm running on a Beowulf cluster. Dynamic programming over a packed chart, in combination with the parallel implementation, allows us to solve one of the largest-scale estimation problems in the statistical parsing literature in under three hours. A key component of the parsing system, for both training and testing, is a Maximum Entropy supertagger which assigns CCG lexical categories to words in a sentence. The supertagger makes the discriminative training feasible, and also leads to a highly efficient parser. Surprisingly, given CCG's spurious ambiguity, the parsing speeds are significantly higher than those reported for comparable parsers in the literature. We also extend the existing parsing techniques for CCG by developing a new model and efficient parsing algorithm which exploits all derivations, including CCG's nonstandard derivations. This model and parsing algorithm, when combined with normal-form constraints, give state-of-the-art accuracy for the recovery of predicate-argument dependencies from CCGbank. The parser is also evaluated on DepBank and compared against the RASP parser, outperforming RASP overall and on the majority of relation types. The evaluation on DepBank raises a number of issues regarding parser evaluation. This article provides a comprehensive blueprint for building a wide-coverage CCG parser. We demonstrate that both accurate and highly efficient parsing is possible with CCG."
            },
            "slug": "Wide-Coverage-Efficient-Statistical-Parsing-with-Clark-Curran",
            "title": {
                "fragments": [],
                "text": "Wide-Coverage Efficient Statistical Parsing with CCG and Log-Linear Models"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This article describes a number of log-linear parsing models for an automatically extracted lexicalized grammar and develops a new model and efficient parsing algorithm which exploits all derivations, including CCG's nonstandard derivations."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641"
                        ],
                        "name": "Rohit J. Kate",
                        "slug": "Rohit-J.-Kate",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Kate",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rohit J. Kate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 13
                            }
                        ],
                        "text": "For example, Kate & Mooney (2006) present a method (KRISP) that extends an existing SVM learning algorithm to recover logical representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 173
                            }
                        ],
                        "text": "Recent work has addressed this problem by learning semantic parsers given sentences paired with logical meaning representations (Thompson & Mooney, 2002; Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 238
                            }
                        ],
                        "text": "\u2026eyaletin texas ye siniri vardir Meaning: answer(state(borders(tex)))\nwhere the sentence is in Turkish and the meaning representation is a variable-free logical expression of the type that has been used in recent work (Kate et al., 2005; Kate & Mooney, 2006; Wong & Mooney, 2006; Lu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1223\u20131233, MIT, Massachusetts, USA, 9-11 October 2010. c\u00a92010 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 49
                            }
                        ],
                        "text": "We also compare performance to previous methods (Kate & Mooney, 2006; Wong & Mooney, 2006, 2007; Zettlemoyer & Collins, 2005, 2007; Lu et al., 2008), which are designed with either language- or representation- specific constraints that limit generalization, as discussed in more detail in Section 6."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 245587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64a6439ed59e3c1dd54e778450f4758a59a2b0e0",
            "isKey": true,
            "numCitedBy": 270,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for mapping natural language sentences to their formal meaning representations using string-kernel-based classifiers. Our system learns these classifiers for every production in the formal language grammar. Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers. Our experiments on two real-world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise."
            },
            "slug": "Using-String-Kernels-for-Learning-Semantic-Parsers-Kate-Mooney",
            "title": {
                "fragments": [],
                "text": "Using String-Kernels for Learning Semantic Parsers"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work presents a new approach for mapping natural language sentences to their formal meaning representations using string-kernel-based classifiers, which compares favorably to other existing systems and is particularly robust to noise."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787006"
                        ],
                        "name": "Ruifang Ge",
                        "slug": "Ruifang-Ge",
                        "structuredName": {
                            "firstName": "Ruifang",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruifang Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 179
                            }
                        ],
                        "text": "Examples include an early statistical method for learning to fill slot-value representations (Miller et al., 1996) and a more recent approach for recovering semantic parse trees (Ge & Mooney, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 2
                            }
                        ],
                        "text": "When the parser fails to return an analysis for a test sentence due to novel words or usage, we reparse the sentence and allow the parser to skip words, with a fixed cost."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9271185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4736635da3d32f8ff18ddc62552e180e303f47b6",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic parsing is the task of mapping natural language sentences to complete formal meaning representations. The performance of semantic parsing can be potentially improved by using discriminative reranking, which explores arbitrary global features. In this paper, we investigate discriminative reranking upon a baseline semantic parser, SCISSOR, where the composition of meaning representations is guided by syntax. We examine if features used for syntactic parsing can be adapted for semantic parsing by creating similar semantic features based on the mapping between syntax and semantics. We report experimental results on two real applications, an interpreter for coaching instructions in robotic soccer and a natural-language database interface. The results show that reranking can improve the performance on the coaching interpreter, but not on the database interface."
            },
            "slug": "Discriminative-Reranking-for-Semantic-Parsing-Ge-Mooney",
            "title": {
                "fragments": [],
                "text": "Discriminative Reranking for Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper investigates discriminative reranking upon a baseline semantic parser, SCISSOR, where the composition of meaning representations is guided by syntax, and finds that reranking can improve the performance on the coaching interpreter, but not on the database interface."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710450"
                        ],
                        "name": "J. Zelle",
                        "slug": "J.-Zelle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zelle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 112
                            }
                        ],
                        "text": "We evaluate the approach on benchmark datasets from a natural language interface to a database of US Geography (Zelle & Mooney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1223\u20131233, MIT, Massachusetts, USA, 9-11 October 2010. c\u00a92010 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 263135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c0e47f8b768258b7d536c21b218e6c46ab8791",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "slug": "Learning-to-Parse-Database-Queries-Using-Inductive-Zelle-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning to Parse Database Queries Using Inductive Logic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart, and provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145585242"
                        ],
                        "name": "Aline Villavicencio",
                        "slug": "Aline-Villavicencio",
                        "structuredName": {
                            "firstName": "Aline",
                            "lastName": "Villavicencio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aline Villavicencio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "For example, Buszkowski & Penn (1990) describe a unification-based approach for grammar discovery from bracketed natural language sentences and Villavicencio (2002) developed an approach for modeling child language acquisition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115610730,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "85ecf448f41dd408ef053fb2e2331a6e621f55b6",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this work is to investigate the process of grammatical acquisition from data. In order to do that, a computational learning system is used, composed of a Universal Grammar with associated parameters, and a learning algorithm, following the Principles and Parameters Theory. The Universal Grammar is implemented as a Unification-Based Generalised Categorial Grammar, embedded in a default inheritance network of lexical types. The learning algorithm receives input from a corpus of spontaneous child-directed transcribed speech annotated with logical forms and sets the parameters based on this input. This framework is used as a basis to investigate several aspects of language acquisition. In this thesis I concentrate on the acquisition of subcategorisation frames and word order information, from data. The data to which the learner is exposed can be noisy and ambiguous, and I investigate how these factors affect the learning process. The results obtained show a robust learner converging towards the target grammar given the input data available. They also show how the amount of noise present in the input data affects the speed of convergence of the learner towards the target grammar. Future work is suggested for investigating the developmental stages of language acquisition as predicted by the learning model, with a thorough comparison with the developmental stages of a child. This is primarily a cognitive computational model of language learning that can be used to investigate and gain a better understanding of human language acquisition, and can potentially be relevant to the development of more adaptive NLP technology."
            },
            "slug": "The-acquisition-of-a-unification-based-generalised-Villavicencio",
            "title": {
                "fragments": [],
                "text": "The acquisition of a unification-based generalised categorial grammar"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733593"
                        ],
                        "name": "J. Curran",
                        "slug": "J.-Curran",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Curran",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Curran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1223\u20131233, MIT, Massachusetts, USA, 9-11 October 2010. c\u00a92010 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 122
                            }
                        ],
                        "text": "Our approach discriminates between analyses using a log-linear CCG parsing model, similar to those used in previous work (Clark & Curran, 2003, 2007), but differing in that the syntactic parses are treated as a hidden variable during training, following the approach of Zettlemoyer & Collins (2005,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7895723,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19da3a7bc4fd32b697bab29fdbc6fe27bf3b33fb",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes log-linear parsing models for Combinatory Categorial Grammar (CCG). Log-linear models can easily encode the long-range dependencies inherent in coordination and extraction phenomena, which CCG was designed to handle. Log-linear models have previously been applied to statistical parsing, under the assumption that all possible parses for a sentence can be enumerated. Enumerating all parses is infeasible for large grammars; however, dynamic programming over a packed chart can be used to efficiently estimate the model parameters. We describe a parellelised implementation which runs on a Beowulf cluster and allows the complete WSJ Penn Treebank to be used for estimation."
            },
            "slug": "Log-Linear-Models-for-Wide-Coverage-CCG-Parsing-Clark-Curran",
            "title": {
                "fragments": [],
                "text": "Log-Linear Models for Wide-Coverage CCG Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This paper describes log-linear parsing models for Combinatory Categorial Grammar and describes a parellelised implementation which runs on a Beowulf cluster and allows the complete WSJ Penn Treebank to be used for estimation."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7939855"
                        ],
                        "name": "W. Buszkowski",
                        "slug": "W.-Buszkowski",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Buszkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Buszkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145047294"
                        ],
                        "name": "Gerald Penn",
                        "slug": "Gerald-Penn",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Penn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerald Penn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 13
                            }
                        ],
                        "text": "For example, Buszkowski & Penn (1990) describe a unification-based approach for grammar discovery from bracketed natural language sentences and Villavicencio (2002) developed an approach for modeling child language acquisition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 115
                            }
                        ],
                        "text": "Skipping words can potentially increase recall, if the ignored word is an unknown function word that does not contribute semantic content."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29665519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a61bd30edeb10d8db8bca27413e60689937dbb6",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide an algorithm for determining a categorial grammar from linguistic data that essentially uses unification of type-schemes assigned to atoms. The algorithm presented here extends an earlier one restricted to rigid categorial grammars, introduced in [4] and [5], by admitting non-rigid outputs. The key innovation is the notion of an optimal unifier, a natural generalization of that of a most general unifier."
            },
            "slug": "Categorial-grammars-determined-from-linguistic-data-Buszkowski-Penn",
            "title": {
                "fragments": [],
                "text": "Categorial grammars determined from linguistic data by unification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The algorithm presented here extends an earlier one restricted to rigid categorial grammars, introduced in [4] and [5], by admitting non-rigid outputs, and introduces the notion of an optimal unifier, a natural generalization of that of a most general unifier."
            },
            "venue": {
                "fragments": [],
                "text": "Stud Logica"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 71
                            }
                        ],
                        "text": "Our approach works by inducing a combinatory categorial grammar (CCG) (Steedman, 1996, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1223\u20131233, MIT, Massachusetts, USA, 9-11 October 2010. c\u00a92010 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12352908,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ded3f3aaaef970030dffd2326be77024b48bac77",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Combinatory Categorial Grammar (CCG) offers a new approach to the theory of natural language grammar. Coordination, relativization, and related prosodic phenomena have been analyzed in CCG in terms of a radically revised notion of surface structure. CCG surface structures do not exhibit traditional notions of syntactic dominance and command, and do not constitute an autonomous level of representation. Instead, they reflect the computations by which a sentence may be realized or analyzed, to synchronously define a predicate-argument structure, or logical form. Surface Structure and Interpretation shows that binding and control can be captured at this level, preserving the advantages of CCG as an account of coordination and unbounded dependency.The core of the book is a detailed treatment of extraction, a focus of syntactic research since the early work of Chomsky and Ross. The topics addressed include the sources of subject-object asymmetries and phenomena attributed to the Empty Category Principle (ECP), asymmetric islands, parasitic gaps, and the relation of coordination and extraction, including their interactions with binding theory. In his conclusion, the author relates CCG to other categorial and type-driven approaches and to proposals for minimalism in linguistic theory.Linguistic Inquiry Monograph No. 30"
            },
            "slug": "Surface-structure-and-interpretation-Steedman",
            "title": {
                "fragments": [],
                "text": "Surface structure and interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The core of the book is a detailed treatment of extraction, a focus of syntactic research since the early work of Chomsky and Ross, and relates CCG to other categorial and type-driven approaches and to proposals for minimalism in linguistic theory."
            },
            "venue": {
                "fragments": [],
                "text": "Linguistic inquiry"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746013"
                        ],
                        "name": "R. Muskens",
                        "slug": "R.-Muskens",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Muskens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Muskens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 51
                            }
                        ],
                        "text": "We use a version of the typed lambda calculus (cf. Carpenter (1997)), in which the basic types include e, for entities; t, for truth values; and i for numbers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37254056,
            "fieldsOfStudy": [
                "Philosophy",
                "Linguistics"
            ],
            "id": "81e982e91ab1c307e001301948caeda47cad43e0",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Type-logical semantics studies linguistic meaning with the help of the theory of types. The latter originated with Russell as an answer to the paradoxes, but has the additional virtue that it is very close to ordinary language. In fact, type theory is so much more similar to language than predicate logic is, that adopting it as a vehicle of representation can overcome the mismatches between grammatical form and predicate logical form that were observed by Frege and Russell. The grammatical forms of ordinary language sentences consequently may be taken to be much less misleading than logicians in the first half of the 20th century often thought them to be. This was realized by Richard Montague, who used the theory of types to translate fragments of ordinary language into a logical language. Semantics is commonly divided into lexical semantics, which studies the meaning of words, and compositional semantics, which studies the way in which complex phrases obtain a meaning from their constituents. The strength of type-logical semantics lies with the latter, but type-logical theories can be combined with many competing hypotheses about lexical meaning, provided these hypotheses are expressed using the language of type theory."
            },
            "slug": "Type-logical-semantics-Muskens",
            "title": {
                "fragments": [],
                "text": "Type-logical semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Type-logical semantics studies linguistic meaning with the help of the theory of types, which has the additional virtue that it is very close to ordinary language, and can be combined with many competing hypotheses about lexical meaning, provided these hypotheses are expressed using the language of type theory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3461596"
                        ],
                        "name": "Johan Bos",
                        "slug": "Johan-Bos",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Bos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johan Bos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733593"
                        ],
                        "name": "J. Curran",
                        "slug": "J.-Curran",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Curran",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Curran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 14
                            }
                        ],
                        "text": "Additionally, Bos et al. (2004) consider the challenging problem of constructing broad-coverage semantic representations with CCG, but do not learn the lexicon."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Skipping words can potentially increase recall, if the ignored word is an unknown function word that does not contribute semantic content."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9317139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c7a1d0b183d0db47a438299d023684491461eac",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how to construct semantic representations from the derivations produced by a wide-coverage CCG parser. Unlike the dependency structures returned by the parser itself, these can be used directly for semantic interpretation. We demonstrate that well-formed semantic representations can be produced for over 97% of the sentences in unseen WSJ text. We believe this is a major step towards widecoverage semantic interpretation, one of the key objectives of the field of NLP."
            },
            "slug": "Wide-Coverage-Semantic-Representations-from-a-CCG-Bos-Clark",
            "title": {
                "fragments": [],
                "text": "Wide-Coverage Semantic Representations from a CCG Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated that well-formed semantic representations can be produced for over 97% of the sentences in unseen WSJ text, a major step towards widecoverage semantic interpretation, one of the key objectives of the field of NLP."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281709"
                        ],
                        "name": "M. Dalrymple",
                        "slug": "M.-Dalrymple",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Dalrymple",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dalrymple"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692491"
                        ],
                        "name": "S. Shieber",
                        "slug": "S.-Shieber",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Shieber",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shieber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705097"
                        ],
                        "name": "F. Pereira",
                        "slug": "F.-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "Carlos",
                                "Neves"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 140
                            }
                        ],
                        "text": "Such an approach would complement ideas for using high-order unification to model a wider range of language phenomena, such as VP ellipsis (Dalrymple et al., 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 122
                            }
                        ],
                        "text": "would complement ideas for using high-order unification to model a wider range of language phenomena, such as VP ellipsis (Dalrymple et al., 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 215747076,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "a21e2560414e98339df5301da5fbb66ec4b80e05",
            "isKey": false,
            "numCitedBy": 507,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for characterizing the interpretive possibilities generated by elliptical constructions in natural language. Unlike previous analyses, which postulate ambiguity of interpretation or derivation in the full clause source of the ellipsis, our analysis requires no such hidden ambiguity. Further, the analysis follows relatively directly from an abstract statement of the ellipsis interpretation problem. It predicts correctly a wide range of interactions between ellipsis and other semantic phenomena such as quantifier scope and bound anaphora. Finally, although the analysis itself is stated nonprocedurally, it admits of a direct computational method for generating interpretations."
            },
            "slug": "Ellipsis-and-higher-order-unification-Dalrymple-Shieber",
            "title": {
                "fragments": [],
                "text": "Ellipsis and higher-order unification"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new method for characterizing the interpretive possibilities generated by elliptical constructions in natural language, which predicts correctly a wide range of interactions between ellipsis and other semantic phenomena such as quantifier scope and bound anaphora."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 71
                            }
                        ],
                        "text": "Our approach works by inducing a combinatory categorial grammar (CCG) (Steedman, 1996, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 5
                            }
                        ],
                        "text": "CCG (Steedman, 2000) is a linguistic formalism that tightly couples syntax and semantics, and can be used to model a wide range of language phenomena."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58106824,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ce8cca19455e8d3055c57a9bafe882984c95a201",
            "isKey": false,
            "numCitedBy": 911,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In computational linguistics, which began in the 1950's with machine translation, systems that are based mainly on the lexicon have a longer t r a d i t i o n than anything e l se f o r these purposes, twenty f i ve years must be allowed to count as a tradition. The bulk of many of the early translation systems was made up by a d ic t ionary whose ent r ies consisted of a rb i t ra ry ins t ruc t ions In machine language. In the early 60's, computational llnsulsts---at least those with theoretical pretentlons---abandoned this way of doing business for at least three related reasons:"
            },
            "slug": "Syntactic-Process-Kay",
            "title": {
                "fragments": [],
                "text": "Syntactic Process"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "In computational linguistics, which began in the 1950's with machine translation, systems that are based mainly on the lexicon have a longer lifespan than anything else, so twenty years must be allowed to count as a tradition."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "The weights for the lexical features are initialized according to coocurrance statistics estimated with the Giza++ (Och & Ney, 2003) implementation of IBM Model 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 71
                            }
                        ],
                        "text": "The approach uses higher-order unification to define the space of possible grammars in a language- and representation-independent manner, paired with an algorithm that learns a probabilistic parsing model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5219389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de2df29b0a0312de7270c3f5a0af6af5645cf91a",
            "isKey": false,
            "numCitedBy": 4470,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present and compare various methods for computing word alignments using statistical or heuristic models. We consider the five alignment models presented in Brown, Della Pietra, Della Pietra, and Mercer (1993), the hidden Markov alignment model, smoothing techniques, and refinements. These statistical models are compared with two heuristic models based on the Dice coefficient. We present different methods for combining word alignments to perform a symmetrization of directed statistical alignment models. As evaluation criterion, we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We evaluate the models on the German-English Verbmobil task and the French-English Hansards task. We perform a detailed analysis of various design decisions of our statistical alignment system and evaluate these on training corpora of various sizes. An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models. In the Appendix, we present an efficient training algorithm for the alignment models presented."
            },
            "slug": "A-Systematic-Comparison-of-Various-Statistical-Och-Ney",
            "title": {
                "fragments": [],
                "text": "A Systematic Comparison of Various Statistical Alignment Models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110271578"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145482266"
                        ],
                        "name": "D. Stallard",
                        "slug": "D.-Stallard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stallard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stallard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189985"
                        ],
                        "name": "R. Bobrow",
                        "slug": "R.-Bobrow",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bobrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 94
                            }
                        ],
                        "text": "Examples include an early statistical method for learning to fill slot-value representations (Miller et al., 1996) and a more recent approach for recovering semantic parse trees (Ge & Mooney, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10983275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9c1f510bcf5933d3cf8ec8108a04a9ba601a843",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a natural language interface system which is based entirely on trained statistical models. The system consists of three stages of processing: parsing, semantic interpretation, and discourse. Each of these stages is modeled as a statistical process. The models are fully integrated, resulting in an end-to-end system that maps input utterances into meaning representation frames."
            },
            "slug": "A-Fully-Statistical-Approach-to-Natural-Language-Miller-Stallard",
            "title": {
                "fragments": [],
                "text": "A Fully Statistical Approach to Natural Language Interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work presents a natural language interface system which is based entirely on trained statistical models, resulting in an end-to-end system that maps input utterances into meaning representation frames."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741947"
                        ],
                        "name": "G. Huet",
                        "slug": "G.-Huet",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Huet",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Huet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 38
                            }
                        ],
                        "text": "The higher-order unification problem (Huet, 1975) involves finding a substitution for the free variables in a pair of lambda-calculus expressions that, when applied, makes the expressions equal each other."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 92
                            }
                        ],
                        "text": "These entries are iteratively refined with a restricted higher-order unification procedure (Huet, 1975) that defines all possible ways to subdivide them, consistent with the requirement that each training sentence can still be parsed to yield its labeled meaning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12226962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32b1b03b5450ac1f286933f44939e71e5068e8d3",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Unification-Algorithm-for-Typed-lambda-Calculus-Huet",
            "title": {
                "fragments": [],
                "text": "A Unification Algorithm for Typed lambda-Calculus"
            },
            "venue": {
                "fragments": [],
                "text": "Theor. Comput. Sci."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741947"
                        ],
                        "name": "G. Huet",
                        "slug": "G.-Huet",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Huet",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Huet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 63
                            }
                        ],
                        "text": "This problem is notoriously complex; in the unrestricted form (Huet, 1973), it is undecidable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205884267,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "83927e8274409303561620a269f3975be7f09691",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Undecidability-of-Unification-in-Third-Order-Huet",
            "title": {
                "fragments": [],
                "text": "The Undecidability of Unification in Third Order Logic"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 75
                            }
                        ],
                        "text": "To estimate the parameters themselves, we use stochastic gradient updates (LeCun et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35270,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116621073"
                        ],
                        "name": "S. Schein",
                        "slug": "S.-Schein",
                        "structuredName": {
                            "firstName": "Seth",
                            "lastName": "Schein",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 191048544,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "9a40a8a16d920447258894dccb1c3b7b5c89e324",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The Iliad is organized according to two complementary, structural principles, one related to its narrative action and traditional mythological content, the other to its traditional style and the artistic norms of the eighth century B.C. Generally speaking, the narrative of the Iliad consists of three parts or stages: Books 1-7, Books 8-17 (perhaps excluding Book 10, the Doloneia), and Books 18 24. Trojans, followed by the death of Patroclus, raises moral and intellectual issues that go beyond anything in Books 1-7, and perhaps beyond anything in the poetic tradition; this stage is distinctively Iliadic. Achilles' aristeia in the final stage of the poem, culminating in the killing of Hector and mutilation of his corpse, is even more dislocated and untraditional than that of Patroclus, and in comparison with Diomedes, Achilles stands out as a deadly and daemonic force of destruction barely acknowledging his human limits.Keywords: Achilles; aristeia; Doloneia; Iliad; Patroclus; Trojans"
            },
            "slug": "The-Iliad:-Structure-and-Interpretation-Schein",
            "title": {
                "fragments": [],
                "text": "The Iliad: Structure and Interpretation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 140
                            }
                        ],
                        "text": "Such an approach would complement ideas for using high-order unification to model a wider range of language phenomena, such as VP ellipsis (Dalrymple et al., 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ellipsis and higher-order unification. Linguistics and Philosophy"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 38
                            }
                        ],
                        "text": "The higher-order unification problem (Huet, 1975) involves finding a substitution for the free variables in a pair of lambda-calculus expressions that, when applied, makes the expressions equal each other."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 92
                            }
                        ],
                        "text": "These entries are iteratively refined with a restricted higher-order unification procedure (Huet, 1975) that defines all possible ways to subdivide them, consistent with the requirement that each training sentence can still be parsed to yield its labeled meaning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A unification algorithm for typed \u03bbcalculus"
            },
            "venue": {
                "fragments": [],
                "text": "Theoretical Computer Science,"
            },
            "year": 1975
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 19,
            "methodology": 18,
            "result": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 28,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Inducing-Probabilistic-CCG-Grammars-from-Logical-Kwiatkowski-Zettlemoyer/c7a40c3ef180d847bb3db40fd01990e08a6264f7?sort=total-citations"
}