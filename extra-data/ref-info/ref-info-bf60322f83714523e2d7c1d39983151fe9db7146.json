{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144621026"
                        ],
                        "name": "R. Snow",
                        "slug": "R.-Snow",
                        "structuredName": {
                            "firstName": "Rion",
                            "lastName": "Snow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Snow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401020033"
                        ],
                        "name": "Brendan T. O'Connor",
                        "slug": "Brendan-T.-O'Connor",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "O'Connor",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brendan T. O'Connor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 128
                            }
                        ],
                        "text": "Related work MTurk has been used for many different NLP and vision tasks (Tietze et al., 2009; Zaidan and Callison-Burch, 2009; Snow et al., 2008; Sorokin and Forsyth, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7008675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0165568bcc1a819c18564567f2ec15d859be2519",
            "isKey": false,
            "numCitedBy": 2129,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Human linguistic annotation is crucial for many natural language processing tasks but can be expensive and time-consuming. We explore the use of Amazon's Mechanical Turk system, a significantly cheaper and faster method for collecting annotations from a broad base of paid non-expert contributors over the Web. We investigate five tasks: affect recognition, word similarity, recognizing textual entailment, event temporal ordering, and word sense disambiguation. For all five, we show high agreement between Mechanical Turk non-expert annotations and existing gold standard labels provided by expert labelers. For the task of affect recognition, we also show that using non-expert labels for training machine learning algorithms can be as effective as using gold standard annotations from experts. We propose a technique for bias correction that significantly improves annotation quality on two tasks. We conclude that many large labeling tasks can be effectively designed and carried out in this method at a fraction of the usual expense."
            },
            "slug": "Cheap-and-Fast-\u2013-But-is-it-Good-Evaluating-for-Snow-O'Connor",
            "title": {
                "fragments": [],
                "text": "Cheap and Fast \u2013 But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work explores the use of Amazon's Mechanical Turk system, a significantly cheaper and faster method for collecting annotations from a broad base of paid non-expert contributors over the Web, and proposes a technique for bias correction that significantly improves annotation quality on two tasks."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 115
                            }
                        ],
                        "text": "Related work MTurk has been used for many different NLP and vision tasks (Tietze et al., 2009; Zaidan and Callison-Burch, 2009; Snow et al., 2008; Sorokin and Forsyth, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 9
                            }
                        ],
                        "text": "Callison-Burch (2009) asks Turkers to produce translations when given reference sentences in other languages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16019656,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "146582d4f49ea5dc39782a7dc1403a05a4a579c7",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Manual evaluation of translation quality is generally thought to be excessively time consuming and expensive. We explore a fast and inexpensive way of doing it using Amazon's Mechanical Turk to pay small sums to a large number of non-expert annotators. For $10 we redundantly recreate judgments from a WMT08 translation task. We find that when combined non-expert judgments have a high-level of agreement with the existing gold-standard judgments of machine translation quality, and correlate more strongly with expert judgments than Bleu does. We go on to show that Mechanical Turk can be used to calculate human-mediated translation edit rate (HTER), to conduct reading comprehension experiments with machine translation, and to create high quality reference translations."
            },
            "slug": "Fast,-Cheap,-and-Creative:-Evaluating-Translation-Callison-Burch",
            "title": {
                "fragments": [],
                "text": "Fast, Cheap, and Creative: Evaluating Translation Quality Using Amazon\u2019s Mechanical Turk"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is found that when combined non-expert judgments have a high-level of agreement with the existing gold-standard judgments of machine translation quality, and correlate more strongly with expert judgments than Bleu does, Mechanical Turk can be used to calculate human-mediated translation edit rate (HTER), to conduct reading comprehension experiments with machine translation, and to create high quality reference translations."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2569283"
                        ],
                        "name": "Michael Kaisser",
                        "slug": "Michael-Kaisser",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kaisser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Kaisser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406118956"
                        ],
                        "name": "J. Lowe",
                        "slug": "J.-Lowe",
                        "structuredName": {
                            "firstName": "John B.",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Kaisser and Lowe (2008)\n7Our final data set consists of 1482 pictures from action photography, 1904 from dogs, 776 from flickr-social, 916 from outdoor, 1257 from strangers and 1773 from wild-child."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7656873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f28a63d18c6500f37e7c67d4246e6c32e6f7a9e3",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Each year NIST releases a set of question, document id, answer-triples for the factoid questions used in the TREC Question Answering track. While this resource is widely used and proved itself useful for many purposes, it also is too coarse a grain-size for a lot of other purposes. In this paper we describe how we have used Amazon\u0092s Mechanical Turk to have multiple subjects read the documents and identify the sentences themselves which contain the answer. For most of the 1911 questions in the test sets from 2002 to 2006 and each of the documents said to contain an answer, the Question-Answer Sentence Pairs (QASP) corpus introduced in this paper contains the identified answer sentences. We believe that this corpus, which we will make available to the public, can further stimulate research in QA, especially linguistically motivated research, where matching the question to the answer sentence by either syntactic or semantic means is a central concern."
            },
            "slug": "Creating-a-Research-Collection-of-Question-Answer-Kaisser-Lowe",
            "title": {
                "fragments": [],
                "text": "Creating a Research Collection of Question Answer Sentence Pairs with Amazon's Mechanical Turk"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The Question-Answer Sentence Pairs (QASP) corpus is introduced and it is believed that this corpus can further stimulate research in QA, especially linguistically motivated research, where matching the question to the answer sentence by either syntactic or semantic means is a central concern."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48155668"
                        ],
                        "name": "Greg Little",
                        "slug": "Greg-Little",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Little"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 20
                            }
                        ],
                        "text": "The TurKit toolkit (Little et al., 2009) provides another approach to improving the quality of MTurk annotations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6449475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3ed842935f30c18ff85d68a22be7db4e0d4bbbd",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Mechanical Turk (MTurk) is an increasingly popular web service for paying people small rewards to do human computation tasks. Current uses of MTurk typically post independent parallel tasks. I am exploring an alternative iterative paradigm, in which workers build on or evaluate each other's work. Part of my proposal is a toolkit called TurKit which facilitates deployment of iterative tasks on MTurk. I want to explore using this technology as a new form of end-user programming, where end-users are writing \u201cprograms\u201d that are really instructions executed by humans on MTurk."
            },
            "slug": "TurKit:-Tools-for-iterative-tasks-on-mechanical-Little",
            "title": {
                "fragments": [],
                "text": "TurKit: Tools for iterative tasks on mechanical turk"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Part of the proposal is a toolkit called TurKit which facilitates deployment of iterative tasks on MTurk, an alternative iterative paradigm, in which workers build on or evaluate each other's work."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144080148"
                        ],
                        "name": "A. Sorokin",
                        "slug": "A.-Sorokin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Sorokin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sorokin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 147
                            }
                        ],
                        "text": "Related work MTurk has been used for many different NLP and vision tasks (Tietze et al., 2009; Zaidan and Callison-Burch, 2009; Snow et al., 2008; Sorokin and Forsyth, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1206581,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d513d8b6470c7cbbeca8563505de8711325a3179",
            "isKey": false,
            "numCitedBy": 645,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how to outsource data annotation to Amazon Mechanical Turk. Doing so has produced annotations in quite large numbers relatively cheaply. The quality is good, and can be checked and controlled. Annotations are produced quickly. We describe results for several different annotation problems. We describe some strategies for determining when the task is well specified and properly priced."
            },
            "slug": "Utility-data-annotation-with-Amazon-Mechanical-Turk-Sorokin-Forsyth",
            "title": {
                "fragments": [],
                "text": "Utility data annotation with Amazon Mechanical Turk"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work shows how to outsource data annotation to Amazon Mechanical Turk, and describes results for several different annotation problems, including some strategies for determining when the task is well specified and properly priced."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145234497"
                        ],
                        "name": "A. Kittur",
                        "slug": "A.-Kittur",
                        "structuredName": {
                            "firstName": "Aniket",
                            "lastName": "Kittur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kittur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2226805"
                        ],
                        "name": "Ed H. Chi",
                        "slug": "Ed-H.-Chi",
                        "structuredName": {
                            "firstName": "Ed",
                            "lastName": "Chi",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ed H. Chi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3994427"
                        ],
                        "name": "B. Suh",
                        "slug": "B.-Suh",
                        "structuredName": {
                            "firstName": "Bongwon",
                            "lastName": "Suh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Suh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Kittur et al. (2008) solicit ratings about different aspects of Wikipedia articles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1442595,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2de9b67cabf99432a4d4a7b278a98afdb42c3d6d",
            "isKey": false,
            "numCitedBy": 1981,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "User studies are important for many aspects of the design process and involve techniques ranging from informal surveys to rigorous laboratory studies. However, the costs involved in engaging users often requires practitioners to trade off between sample size, time requirements, and monetary costs. Micro-task markets, such as Amazon's Mechanical Turk, offer a potential paradigm for engaging a large number of users for low time and monetary costs. Here we investigate the utility of a micro-task market for collecting user measurements, and discuss design considerations for developing remote micro user evaluation tasks. Although micro-task markets have great potential for rapidly collecting user measurements at low costs, we found that special care is needed in formulating tasks in order to harness the capabilities of the approach."
            },
            "slug": "Crowdsourcing-user-studies-with-Mechanical-Turk-Kittur-Chi",
            "title": {
                "fragments": [],
                "text": "Crowdsourcing user studies with Mechanical Turk"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Although micro-task markets have great potential for rapidly collecting user measurements at low costs, it is found that special care is needed in formulating tasks in order to harness the capabilities of the approach."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1936277"
                        ],
                        "name": "Omar Zaidan",
                        "slug": "Omar-Zaidan",
                        "structuredName": {
                            "firstName": "Omar",
                            "lastName": "Zaidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omar Zaidan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8431414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99367f21cafc843feb2c43def13c2e3f249f9acc",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Minimum error rate training (MERT) involves choosing parameter values for a machine translation (MT) system that maximize performance on a tuning set as measured by an automatic evaluation metric, such as Bleu. The method is best when the system will eventually be evaluated using the same metric, but in reality, most MT evaluations have a human-based component. Although performing MERT with a human-based metric seems like a daunting task, we describe a new metric, Rypt, which takes human judgments into account, but only requires human input to build a database that can be reused over and over again, hence eliminating the need for human input at tuning time. In this investigative study, we analyze the diversity (or lack thereof) of the candidates produced during MERT, we describe how this redundancy can be used to our advantage, and show that Rypt is a better predictor of translation quality than Bleu."
            },
            "slug": "Feasibility-of-Human-in-the-loop-Minimum-Error-Rate-Zaidan-Callison-Burch",
            "title": {
                "fragments": [],
                "text": "Feasibility of Human-in-the-loop Minimum Error Rate Training"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This investigative study analyzes the diversity (or lack thereof) of the candidates produced during MERT, describes a new metric, Rypt, which takes human judgments into account, but only requires human input to build a database that can be reused over and over again, hence eliminating the need for human input at tuning time."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723976"
                        ],
                        "name": "C. Strapparava",
                        "slug": "C.-Strapparava",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Strapparava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Strapparava"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 0
                            }
                        ],
                        "text": "Mihalcea and Strapparava (2009) ask Turkers to produce 4-5 sentence opinion paragraphs about the death penalty, about abortion and describing a friend."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10186140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50d6a8834013b29927c708c556baee06ce94337b",
            "isKey": false,
            "numCitedBy": 306,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present initial experiments in the recognition of deceptive language. We introduce three data sets of true and lying texts collected for this purpose, and we show that automatic classification is a viable technique to distinguish between truth and falsehood as expressed in language. We also introduce a method for class-based feature analysis, which sheds some light on the features that are characteristic for deceptive text."
            },
            "slug": "The-Lie-Detector:-Explorations-in-the-Automatic-of-Mihalcea-Strapparava",
            "title": {
                "fragments": [],
                "text": "The Lie Detector: Explorations in the Automatic Recognition of Deceptive Language"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that automatic classification is a viable technique to distinguish between truth and falsehood as expressed in language and a method for class-based feature analysis is introduced, which sheds some light on the features that are characteristic for deceptive text."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 168
                            }
                        ],
                        "text": "The PASCAL Data Set Every year, the Pattern Analysis, Statistical Modeling, and Computational Learning (PASCAL) organization hosts the Visual Object Classes Challenge (Everingham et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 200
                            }
                        ],
                        "text": "Although many generic NLP applications can be developed by using existing corpora or text collections as test and training data, there are many areas where NLP could be useful if there was a suitable corpus available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61615905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2ed19ac684022aa3186887cd4893484ab8f80c",
            "isKey": false,
            "numCitedBy": 2169,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006). Details of the challenge, data, and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change."
            },
            "slug": "The-PASCAL-visual-object-classes-challenge-2006-Everingham-Zisserman",
            "title": {
                "fragments": [],
                "text": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2750542"
                        ],
                        "name": "Martin I. Tietze",
                        "slug": "Martin-I.-Tietze",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Tietze",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin I. Tietze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2147464"
                        ],
                        "name": "A. Winterboer",
                        "slug": "A.-Winterboer",
                        "structuredName": {
                            "firstName": "Andi",
                            "lastName": "Winterboer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Winterboer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47147237"
                        ],
                        "name": "Johanna D. Moore",
                        "slug": "Johanna-D.-Moore",
                        "structuredName": {
                            "firstName": "Johanna",
                            "lastName": "Moore",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johanna D. Moore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61315936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29c516b67e6de9d0e6b630d4ed8ed5d42e35fa38",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we examine the effect of linguistic devices on recall and comprehension in information presentation using both recall and eye-tracking data. In addition, the results were validated via an experiment using Amazon's Mechanical Turk micro-task environment."
            },
            "slug": "The-effect-of-linguistic-devices-in-information-on-Tietze-Winterboer",
            "title": {
                "fragments": [],
                "text": "The effect of linguistic devices in information presentation messages on comprehension and recall"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "The effect of linguistic devices on recall and comprehension in information presentation using both recall and eye-tracking data was examined and validated via an experiment using Amazon's Mechanical Turk micro-task environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 10,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Collecting-Image-Annotations-Using-Amazon\u2019s-Turk-Rashtchian-Young/bf60322f83714523e2d7c1d39983151fe9db7146?sort=total-citations"
}