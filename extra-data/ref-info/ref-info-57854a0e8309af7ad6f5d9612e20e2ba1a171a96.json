{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2637837"
                        ],
                        "name": "Zen Chen",
                        "slug": "Zen-Chen",
                        "structuredName": {
                            "firstName": "Zen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721539"
                        ],
                        "name": "Hsi-Jian Lee",
                        "slug": "Hsi-Jian-Lee",
                        "structuredName": {
                            "firstName": "Hsi-Jian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsi-Jian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 39569986,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8879d4878bb7edcc9c1aaf3b800e4f99de55f472",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer vision method is presented to determine the 3-D spatial locations of joints or feature points of human body from a film recording the human motion during walking. The proposed method first applies the geometric projection theory to obtain a set of feasible postures from a single image, then it makes use of the given dimensions of the human stick figure, physiological and motion-specific knowledge to constrain the feasible postures in both the single-frame analysis and the multi-frame analysis. Finally a unique gait interpretation is selected by an optimization algorithm. Computer simulations are used to illustrate the ideas presented. >"
            },
            "slug": "Knowledge-guided-visual-perception-of-3-D-human-a-Chen-Lee",
            "title": {
                "fragments": [],
                "text": "Knowledge-guided visual perception of 3-D human gait from a single image sequence"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A computer vision method is presented to determine the 3-D spatial locations of joints or feature points of human body from a film recording the human motion during walking with a unique gait interpretation selected by an optimization algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717217"
                        ],
                        "name": "R. J. Qian",
                        "slug": "R.-J.-Qian",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Qian",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J. Qian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 165
                            }
                        ],
                        "text": "Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a di erent goal [7, 8, 16, 18, 17, 14, 5, 6, 15, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61282481,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "3ebba0031dc072867381dfc9ac66769ad5c1254d",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Studying the visual motion of human ambulatory patterns is of great importance for both vision research and applications. The authors first present three new algorithms for the recovery of three-dimensional structures from the motion of certain types of joints of articulated objects assuming perspective projection. Then based on the assumption that a human body can be considered as an articulated object and each part of the articulated object is rigid, they apply these algorithms to motion analysis of human ambulatory patterns in a combined way. The proposed algorithms have been tested in terms of the uniqueness of real solution and the speed of convergence using the synthesized data.<<ETX>>"
            },
            "slug": "Motion-analysis-of-human-ambulatory-patterns-Qian-Huang",
            "title": {
                "fragments": [],
                "text": "Motion analysis of human ambulatory patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The authors present three new algorithms for the recovery of three-dimensional structures from the motion of certain types of joints of articulated objects assuming perspective projection for motion analysis of human ambulatory patterns."
            },
            "venue": {
                "fragments": [],
                "text": "[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15268662,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "86086a48021d34c1e36cc9e0d1fa532d3a3efb1e",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach that uses a volume model consisting of cylinders for model-based recognition of pedestrians in real-world images is presented. The human body is represented by a volume model, and medical motion data are used for simulating the movement of walking. This knowledge is exploited to determine the 3-D position, as well as the posture of an observed person. By applying a Kalman filter, the model parameters in consecutive images are incrementally estimated. The approach is tested on real image data.<<ETX>>"
            },
            "slug": "Incremental-recognition-of-pedestrians-from-image-Rohr",
            "title": {
                "fragments": [],
                "text": "Incremental recognition of pedestrians from image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An approach that uses a volume model consisting of cylinders for model-based recognition of pedestrians in real-world images is presented, and medical motion data are used for simulating the movement of walking."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890438"
                        ],
                        "name": "M. Leung",
                        "slug": "M.-Leung",
                        "structuredName": {
                            "firstName": "Maylor",
                            "lastName": "Leung",
                            "middleNames": [
                                "Karhang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35964920"
                        ],
                        "name": "Yee-Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee-Hong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Hong Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 165
                            }
                        ],
                        "text": "Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a di erent goal [7, 8, 16, 18, 17, 14, 5, 6, 15, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 262
                            }
                        ],
                        "text": "One reason for this approach is that standard optical ow algorithms fail in regions where there are multiple motions, occlusion, and non-rigidly moving areas; many other human body tracking e orts use a change detection operation as well to bypass these problems[18, 7, 17, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5757451,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a33fe92d9114446faed461e87d29cca129f82f67",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-body-motion-segmentation-in-a-complex-scene-Leung-Yang",
            "title": {
                "fragments": [],
                "text": "Human body motion segmentation in a complex scene"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7265948"
                        ],
                        "name": "L. Kozlowski",
                        "slug": "L.-Kozlowski",
                        "structuredName": {
                            "firstName": "Lynn",
                            "lastName": "Kozlowski",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kozlowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2345416"
                        ],
                        "name": "J. Cutting",
                        "slug": "J.-Cutting",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cutting",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cutting"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 123
                            }
                        ],
                        "text": "It is known that humans can detect and recognize gait with reduce spatiotemporal sequences (such as moving light displays) [3, 10], and we would like to give similar capabilities to machines."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143941887,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1c25a91fdb4e8da680eb19cb20d0f2ffbb1ea34f",
            "isKey": false,
            "numCitedBy": 853,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The sex of human walkers can be recognized without familiarity cues from displays of pointlight sources mounted on major joints. Static versions of these abstract displays do not permit accurate recognition of sex. Variation in the degree of armswing or in walking speed generally interferes with recognition, except that faster speeds are associated somewhat with improved recognition of females. Lights on upper-body joints permit more accurate guesses than do Lights on lower-body joints, but identification is possible even from minimal displays, with lights placed only on the ankles. No feedback was given to observers. Confidence judgments of sex relate to the accuracy of responses in a manner that suggests that viewers know what they are doing."
            },
            "slug": "Recognizing-the-sex-of-a-walker-from-a-dynamic-Kozlowski-Cutting",
            "title": {
                "fragments": [],
                "text": "Recognizing the sex of a walker from a dynamic point-light display"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9394419"
                        ],
                        "name": "T. Tsukiyama",
                        "slug": "T.-Tsukiyama",
                        "structuredName": {
                            "firstName": "Toshifumi",
                            "lastName": "Tsukiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tsukiyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700379"
                        ],
                        "name": "Y. Shirai",
                        "slug": "Y.-Shirai",
                        "structuredName": {
                            "firstName": "Yoshiaki",
                            "lastName": "Shirai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shirai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 41410208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34cc9ec982f052302b9ee32160b2bf30a88010b7",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Detection-of-the-movements-of-persons-from-a-sparse-Tsukiyama-Shirai",
            "title": {
                "fragments": [],
                "text": "Detection of the movements of persons from a sparse sequence of TV images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074973893"
                        ],
                        "name": "N. Goddard",
                        "slug": "N.-Goddard",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Goddard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Goddard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 87
                            }
                        ],
                        "text": "Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58777057,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "e9ce1fea1e38e330b2715124dec49ac7f0530888",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognition of motion sequences is a crucial ability for biological and robot vision systems. We present an architecture for the higher-level processes involved in recognition of complex structured motion. The work is focused on modeling human recognition of Moving Light Displays. MLDs are image sequences that contain only motion information at a small number of locations. Despite the extreme paucity of information in these displays, humans can recognize MLDs generated from a variety of common human movements. This dissertation explores the high-level representations and computational processes required for the recognition task. The structures and algorithms are articulated in the language of structured connectionist models. The implemented network can discriminate three human gaits from data generated by several actors. .pp Recognition of any motion involves indexing into stored models of movement. We present a representation for such models, called scenarios, based on coordinated sequences of discrete motion events. A method for indexing into this representation is described. We develop a parallel model of spatial and conceptual attention that is essential for disambiguating the spatially and temporally diffuse MLD data. The major computational problems addressed are: (1) representation of time-varying visual models; (2) integration of visual stimuli over time; (3) gestalt formation in and between spatially-localized feature maps and central movement representations; (4) contextual feedback to lower levels; and (5) the use of attention to focus processing on particular spatial locations and particular high-level representations. Several novel connectionist mechanisms are developed and used in the implementation. .pp In particular, we present advances in connectionist representation of temporal sequences and in using high-level knowledge to control an attentional mechanism. We show that recognition of gait can be achieved directly from motion features, without complex shape information, and that the motion information need not be finely quantized. We show how the \"what\" and \"where\" processes in vision can be tightly coupled in a synergistic fashion. These results indicate the value of the structured connectionist paradigm in modeling perceptual processes: no previous computational model has accounted for MLD recognition and we do not know how it would be approached in any other paradigm."
            },
            "slug": "The-Perception-of-Articulated-Motion:-Recognizing-Goddard",
            "title": {
                "fragments": [],
                "text": "The Perception of Articulated Motion: Recognizing Moving Light Displays"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that recognition of gait can be achieved directly from motion features, without complex shape information, and that the motion information need not be finely quantized, which indicates the value of the structured connectionist paradigm in modeling perceptual processes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2345416"
                        ],
                        "name": "J. Cutting",
                        "slug": "J.-Cutting",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cutting",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cutting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7265948"
                        ],
                        "name": "L. Kozlowski",
                        "slug": "L.-Kozlowski",
                        "structuredName": {
                            "firstName": "Lynn",
                            "lastName": "Kozlowski",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kozlowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 143687558,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a6f0aa2485265e2f714708570a495cf0469ca717",
            "isKey": false,
            "numCitedBy": 1058,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Viewers can recognize themselves and others in an abstract display of their movements. Light sources mounted on joints prominent during the act of walking are sufficient cues for identification. No other information, no feedback, and little practice with such a display are needed. This procedure, developed by Johansson, holds promise for inquiry into the dimensions and features of event perception: It is both naturalistic and experimentally manageable."
            },
            "slug": "Recognizing-friends-by-their-walk:-Gait-perception-Cutting-Kozlowski",
            "title": {
                "fragments": [],
                "text": "Recognizing friends by their walk: Gait perception without familiarity cues"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890438"
                        ],
                        "name": "M. Leung",
                        "slug": "M.-Leung",
                        "structuredName": {
                            "firstName": "Maylor",
                            "lastName": "Leung",
                            "middleNames": [
                                "Karhang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35964920"
                        ],
                        "name": "Yee-Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee-Hong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Hong Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 165
                            }
                        ],
                        "text": "Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a di erent goal [7, 8, 16, 18, 17, 14, 5, 6, 15, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15456598,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5c3a93b395dc197670db5797c7494337b6833ec3",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-region-based-approach-for-human-body-motion-Leung-Yang",
            "title": {
                "fragments": [],
                "text": "A region based approach for human body motion analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 165
                            }
                        ],
                        "text": "Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a di erent goal [7, 8, 16, 18, 17, 14, 5, 6, 15, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detecting activ-  ities"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2-7,"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2652428"
                        ],
                        "name": "R. Polana",
                        "slug": "R.-Polana",
                        "structuredName": {
                            "firstName": "Ramprasad",
                            "lastName": "Polana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Polana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31614700"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Nelson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7521679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f17b48014c3f3e861fcd8f5827d13ab2b5a25d1",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of activity detection is described. This technique uses a periodicity measure on gray-level signals extracted along spatio-temporal reference curves. The technique is illustrated using real-world examples of activities. It is shown that the technique robustly detects complex periodic activities, while excluding nonperiodic motion. A technique to recognize these activities using the detection scheme described is proposed. It is not clear how much the periodicity alone is useful for recognition, but the authors believe that the phase information is valuable for activity recognition.<<ETX>>"
            },
            "slug": "Detecting-activities-Polana-Nelson",
            "title": {
                "fragments": [],
                "text": "Detecting activities"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the technique robustly detects complex periodic activities, while excluding nonperiodic motion, and the authors believe that the phase information is valuable for activity recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052391642"
                        ],
                        "name": "J. O'Rourke",
                        "slug": "J.-O'Rourke",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "O'Rourke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Rourke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699200"
                        ],
                        "name": "N. Badler",
                        "slug": "N.-Badler",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Badler",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Badler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15680007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9df0428c30b8aab4f7e6f367e70126efdfb8fc45",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "A system capable of analyzing image sequences of human motion is described. The system is structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level. The domain of human motion lends itself to a model-driven analysis, and the system includes a detailed model of the human body. All information extracted from the image is interpreted through a constraint network based on the structure of the human model. A constraint propagation operator is defined and its theoretical properties outlined. An implementation of this operator is described, and results of the analysis system for short image sequences are presented."
            },
            "slug": "Model-based-image-analysis-of-human-motion-using-O'Rourke-Badler",
            "title": {
                "fragments": [],
                "text": "Model-based image analysis of human motion using constraint propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A system capable of analyzing image sequences of human motion is described, structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47579815"
                        ],
                        "name": "Masanobu Yamamoto",
                        "slug": "Masanobu-Yamamoto",
                        "structuredName": {
                            "firstName": "Masanobu",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masanobu Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2638101"
                        ],
                        "name": "K. Koshikawa",
                        "slug": "K.-Koshikawa",
                        "structuredName": {
                            "firstName": "Kazutada",
                            "lastName": "Koshikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Koshikawa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35103895,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "4ff071ca1e5207975ca8cd146f5c33eddfdb2d98",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A model-based method for analyzing a human body motion is presented. The method is based on a robot arm model which represents a human body motion. Combining the model and the gradient scheme, the movement of the configuration of the model (Human) can be directly estimated from an image sequence.<<ETX>>"
            },
            "slug": "Human-motion-analysis-based-on-a-robot-arm-model-Yamamoto-Koshikawa",
            "title": {
                "fragments": [],
                "text": "Human motion analysis based on a robot arm model"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A model-based method based on a robot arm model which represents a human body motion and the movement of the configuration of the model can be directly estimated from an image sequence."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2019875"
                        ],
                        "name": "A. Shio",
                        "slug": "A.-Shio",
                        "structuredName": {
                            "firstName": "Akio",
                            "lastName": "Shio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765522"
                        ],
                        "name": "J. Sklansky",
                        "slug": "J.-Sklansky",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Sklansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sklansky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 165
                            }
                        ],
                        "text": "Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a di erent goal [7, 8, 16, 18, 17, 14, 5, 6, 15, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 262
                            }
                        ],
                        "text": "One reason for this approach is that standard optical ow algorithms fail in regions where there are multiple motions, occlusion, and non-rigidly moving areas; many other human body tracking e orts use a change detection operation as well to bypass these problems[18, 7, 17, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 129637437,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "833063952e8a337db7970e81a70b134d25d12675",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for segmenting monocular images of people in motion from a cinematic sequence of frames is described. This method is based on image intensities, motion, and an object model-i.e., a model of the image of a person in motion. Though each part of a person may move in different directions at any instant, the time averaged motion of all parts must converge to a global average value over a few seconds. People in an image may be occluded by other people, and usually it is not easy to detect their boundaries. These boundaries can be detected with motion information if they move in different directions, even if there are almost no apparent differences among object intensities or colors. Each image of a person in a scene usually can be divided into several parts, each with distinct intensities or colors. The parts of a person can be merged into a single group by an iterative merging algorithm based on the object model and the motion information because the parts move coherently. This merging is analogous to the property of perceptual grouping in human visual perception of motion. Experiments based on a sequence of complex real scenes produced results that are supportive of the authors approach to the segmentation of people in motion.<<ETX>>"
            },
            "slug": "Segmentation-of-people-in-motion-Shio-Sklansky",
            "title": {
                "fragments": [],
                "text": "Segmentation of people in motion"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Workshop on Visual Motion"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3267020"
                        ],
                        "name": "S. Kurakake",
                        "slug": "S.-Kurakake",
                        "structuredName": {
                            "firstName": "Shoji",
                            "lastName": "Kurakake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kurakake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12454684,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c155df6c101f219c469bfd73be639aff4d90c3d",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the problem of deriving a description for an articulated object from images taken in the real environment. Sometimes with the articulated object, the detection of the articulation is difficult depending on the deformation or the direction of the view line. Also, the false articulation is detected due to the disconnection of the object contour derived from the image or due to the noise. \n \n \n \nTo cope with such difficulties, a method is proposed for the moving articulated object, where the articulation is detected with a high reliability, and the description as well as the segmentation of the articulated object are derived by processing a series of images containing different outblocks and deformations of the object. In this method, the ribbon, which is the two-dimensional version of the generalized cylinder, is used as the basic representation for the part. The initial description is derived from each frame image, and the initial descriptions of various frames are compared by ribbon matching to detect the articulation position with a high reliability. Based on the detected positions, the initial descriptions are integrated selectively and the final description is obtained. As a by-product of the ribbon matching, the tracking of parts also is realized. By an experiment using a human walking scene, the usefulness of the proposed method is demonstrated."
            },
            "slug": "Description-and-tracking-of-moving-articulated-Kurakake-Nevatia",
            "title": {
                "fragments": [],
                "text": "Description and tracking of moving articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A method to obtain reliable shape description of articulated objects by integrating initial descriptions computed from different view images by using ribbon, which is a 2-D analog of a generalized cone, as the basic shape representation scheme."
            },
            "venue": {
                "fragments": [],
                "text": "Systems and Computers in Japan"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153281777"
                        ],
                        "name": "D. Marr",
                        "slug": "D.-Marr",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Marr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144901036"
                        ],
                        "name": "H. Nishihara",
                        "slug": "H.-Nishihara",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Nishihara",
                            "middleNames": [
                                "Keith"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nishihara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43759520,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdf9b8f4de001f5f37bc844efbce1210d581d599",
            "isKey": false,
            "numCitedBy": 2323,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual process can be studied by examining the computational problems associated with deriving useful information from retinal images. In this paper, we apply this approach to the problem of representing three-dimensional shapes for the purpose of recognition. 1. Three criteria, accessibility, scope and uniqueness, and stability and sensitivity, are presented for judging the usefulness of a representation for shape recognition. 2. Three aspects of a representation\u2019s design are considered, (i) the representation\u2019s coordinate system, (ii) its primitives, which are the primary units of shape information used in the representation, and (iii) the organization the representation imposes on the information in its descriptions. 3. In terms of these design issues and the criteria presented, a shape representation for recognition should: (i) use an object-centred coordinate system, (ii) include volumetric primitives of varied sizes, and (iii) have a modular organization. A representation based on a shape\u2019s natural axes (for example the axes identified by a stick figure) follows directly from these choices. 4. The basic process for deriving a shape description in this representation must involve: (i) a means for identifying the natural axes of a shape in its image and (ii) a mechanism for transforming viewer-centred axis specifications to specifications in an object-centred coordinate system. 5. Shape recognition involves: (i) a collection of stored shape descriptions, and (ii) various indexes into the collection that allow a newly derived description to be associated with an appropriate stored description. The most important of these indexes allows shape recognition to proceed conservatively from the general to the specific based on the specificity of the information available from the image. 6. New constraints supplied by a conservative recognition process can be used to extract more information from the image. A relaxation process for carrying out this constraint analysis is described."
            },
            "slug": "Representation-and-recognition-of-the-spatial-of-Marr-Nishihara",
            "title": {
                "fragments": [],
                "text": "Representation and recognition of the spatial organization of three-dimensional shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The human visual process can be studied by examining the computational problems associated with deriving useful information from retinal images by applying the approach to the problem of representing three-dimensional shapes for the purpose of recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B. Biological Sciences"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116077"
                        ],
                        "name": "R. Rashid",
                        "slug": "R.-Rashid",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rashid",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rashid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 87
                            }
                        ],
                        "text": "Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10033309,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c3f88c3fa31d21d37df5cd181954c3c1256e4d9e",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Lights is a system for the interpretation of simple moving light displays (MLD) of jointed objects against a stationary background. The displays studied differ from those examined by previous researchers in that 1) objects are represented by a relatively small number of points, 2) objects are not rigid, and 3) the viewing geometry is such that highly varying degrees of perspective distortion occur. An algorithm is presented which segments the points of an MLD of a wire-frame man into body parts. The relationship of this algorithm to previous theories of MLD perception and actual human performance is discussed."
            },
            "slug": "Towards-a-system-for-the-interpretation-of-moving-Rashid",
            "title": {
                "fragments": [],
                "text": "Towards a system for the interpretation of moving light displays"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An algorithm is presented which segments the points of an MLD of a wire-frame man into body parts, and the relationship of this algorithm to previous theories of MLD perception and actual human performance is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145787720"
                        ],
                        "name": "J. Webb",
                        "slug": "J.-Webb",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Webb",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Webb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 87
                            }
                        ],
                        "text": "Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8129680,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "9ea315676e07e7c3d678efc9de30f84aef86cd47",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Structure-from-Motion-of-Rigid-and-Jointed-Objects-Webb-Aggarwal",
            "title": {
                "fragments": [],
                "text": "Structure from Motion of Rigid and Jointed Objects"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 165
                            }
                        ],
                        "text": "Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a di erent goal [7, 8, 16, 18, 17, 14, 5, 6, 15, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detecting activ-  ities"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2-7,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 165
                            }
                        ],
                        "text": "Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a di erent goal [7, 8, 16, 18, 17, 14, 5, 6, 15, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 262
                            }
                        ],
                        "text": "One reason for this approach is that standard optical ow algorithms fail in regions where there are multiple motions, occlusion, and non-rigidly moving areas; many other human body tracking e orts use a change detection operation as well to bypass these problems[18, 7, 17, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detection of  the movements of persons from a sparse se-  quence of TV images. Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "M.I.T. Media Lab Vision and Modeling\nGroup Technical Report No. 223\nAnalyzing and Recognizing Walking\nFigures in XYT\nSourabh A. Niyogi and Edward H. Adelson\nsourabh@media.mit.edu and adelson@media.mit.edu\nPerceptual Computing Section MIT Media Laboratory\n20 Ames St., Cambridge, MA 02139"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing the sex of a walker from a dynamic pointlight display. Perception and Psychophysics"
            },
            "venue": {
                "fragments": [],
                "text": "Recognizing the sex of a walker from a dynamic pointlight display. Perception and Psychophysics"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 165
                            }
                        ],
                        "text": "Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a di erent goal [7, 8, 16, 18, 17, 14, 5, 6, 15, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "man motion analysis based on a robot arm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u201c Analyzing and recognizing walking figures in XYT , \u201d MIT Media Lab Perceptual Computing Technical Report 221 , November 1993"
            },
            "venue": {
                "fragments": [],
                "text": "Intern . J . Computer Vision"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analyzing and recognizing walking figures"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 165
                            }
                        ],
                        "text": "Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a di erent goal [7, 8, 16, 18, 17, 14, 5, 6, 15, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 262
                            }
                        ],
                        "text": "One reason for this approach is that standard optical ow algorithms fail in regions where there are multiple motions, occlusion, and non-rigidly moving areas; many other human body tracking e orts use a change detection operation as well to bypass these problems[18, 7, 17, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Incremental recognition of pedes-  trians from image sequences"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR pp"
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Analyzing-and-recognizing-walking-figures-in-XYT-Niyogi-Adelson/57854a0e8309af7ad6f5d9612e20e2ba1a171a96?sort=total-citations"
}