{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49693392"
                        ],
                        "name": "A. Kojima",
                        "slug": "A.-Kojima",
                        "structuredName": {
                            "firstName": "Atsuhiro",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kojima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2023734"
                        ],
                        "name": "M. Izumi",
                        "slug": "M.-Izumi",
                        "structuredName": {
                            "firstName": "Masao",
                            "lastName": "Izumi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Izumi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114145871"
                        ],
                        "name": "Takeshi Tamura",
                        "slug": "Takeshi-Tamura",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Tamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takeshi Tamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950023"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Kunio",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 160
                            }
                        ],
                        "text": "In our previous paper, we present a method for generating textual descriptions from position and orientation of human head representing the whole body posture (Kojima et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27525133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e62d7dd5ffb078e4244fef096a4a868462eb6d5e",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In visual surveillance applications, it is becoming popular to perceive video images and to interpret them using natural language concepts. We propose an approach to generating a natural language description of human behavior appearing in real video images. First, a head region of a human, on behalf of the whole body, is extracted from each frame. Using a model based method, three dimensional pose and position of the head are estimated. Next, the trajectory of these parameters is divided into segments of monotonous motions. For each segment, we evaluate conceptual features such as degree of change of pose and position and that of relative distance to some objects in the surroundings, and so on. By calculating the product of these feature values, a most suitable verb is selected and other syntactic elements are supplied. Finally natural language text is generated using a technique of machine translation."
            },
            "slug": "Generating-natural-language-description-of-human-Kojima-Izumi",
            "title": {
                "fragments": [],
                "text": "Generating natural language description of human behavior from video images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes an approach to generating a natural language description of human behavior appearing in real video images using a model based method and a technique of machine translation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145379616"
                        ],
                        "name": "Douglas Ayers",
                        "slug": "Douglas-Ayers",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Ayers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douglas Ayers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 43
                            }
                        ],
                        "text": "For human activities in real video images, Ayers and Shah (2001) propose a method for generating textual description of human behavior in video images using state transition models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 60
                            }
                        ],
                        "text": "As a related work on textual description of human behavior, Ayers and Shah (2001) should be mentioned."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As a related work on textual description of human behavior,  Ayers and Shah (2001)  should be mentioned."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10222347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ac8fe1ca09e994a1fdc244c66ecbf0a2b8d5148",
            "isKey": true,
            "numCitedBy": 174,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Monitoring-human-behavior-from-video-taken-in-an-Ayers-Shah",
            "title": {
                "fragments": [],
                "text": "Monitoring human behavior from video taken in an office environment"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: natural language generation, concept hierarchy, semantic primitive, position/posture estimation of human, case frame"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30734553,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8f98e2f0d43e82cf8801cd6081d5907e557e0c32",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This contribution is based on two previously published approaches one of which automatically extracts vehicle trajectories from image sequences of traffic scenes and associates these trajectories with motion verbs. The second approach exploits machine vision in order to maneuver autonomous road vehicles. The combination of these two approaches provides a link from the evaluation of video signals via an abstract representation at the level of natural language concepts to actuator devices in automatic closed loop control of road vehicles. Building on implemented representations for elementary motion verbs and for elementary road vehicle maneuvers, a grammar to represent a nontrivial subset of more complex driving activities on a highway is formulated. Driving on a highway can thereby be investigated not only at the level of control algorithms, but simultaneously at the level of natural language descriptions."
            },
            "slug": "A-vision-of-\u2018vision-and-language\u2019-comprises-action:-Nagel",
            "title": {
                "fragments": [],
                "text": "A vision of \u2018vision and language\u2019 comprises action: An example from road traffic"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A grammar to represent a nontrivial subset of more complex driving activities on a highway is formulated and can be investigated not only at thelevel of control algorithms, but simultaneously at the level of natural language descriptions."
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence Review"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153007197"
                        ],
                        "name": "G. Herzog",
                        "slug": "G.-Herzog",
                        "structuredName": {
                            "firstName": "Gerd",
                            "lastName": "Herzog",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Herzog"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3471215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c2552010b5a9d45761bc49b5ca2f36c4f751da",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "The integration of vision and natural language processing increasingly attracts attention in different areas of AI research. Up to now, however, there have only been a few attempts at connecting vision systems with natural language access systems. Within the SFB 314, special collaborative program on AI and knowledge-based systems, the automatic natural language description of real world image sequences constitutes a major research goal, which has been pursued during the last ten years. The aim of our approach is to obtain an incremental evaluation and simultaneous description of the perceived time-varying scenes. In this contribution we will report on new results of our joint efforts at combining the natural language access system Vitra with a vision system. We have investigated the problem of describing the movements of articulated bodies in image sequences within an integrated natural language and computer vision system. The paper will focus on our model-based approach for the recognition of pedestrians and on the further evaluation and language production in Vitra."
            },
            "slug": "Integrating-Vision-and-Language:-Towards-Automatic-Herzog-Rohr",
            "title": {
                "fragments": [],
                "text": "Integrating Vision and Language: Towards Automatic Description of Human Movements"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model-based approach for the recognition of pedestrians and on the further evaluation and language production in Vitra are reported on, which aims to obtain an incremental evaluation and simultaneous description of the perceived time-varying scenes."
            },
            "venue": {
                "fragments": [],
                "text": "KI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2590676"
                        ],
                        "name": "H. Kollnig",
                        "slug": "H.-Kollnig",
                        "structuredName": {
                            "firstName": "Henner",
                            "lastName": "Kollnig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kollnig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055354"
                        ],
                        "name": "M. Otte",
                        "slug": "M.-Otte",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Otte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Otte"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 167
                            }
                        ],
                        "text": "Traffic surveillance system, for instance, represents moving vehicles by series of verbs or short sentences in place of numerical expressions of the objects\u2019 location (Kollnig et al., 1994; Nagel, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40895626,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2adb6bb86633a5d3581c781ce5b5dd18c6c69c84",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This contribution addresses the problem of detection and tracking of moving vehicles in image sequences from traffic scenes recorded by a stationary camera. By replacing the low level vision system component for the estimation of displacement vectors by an optical flow estimation module we are able to detect all moving vehicles in our test image sequence. By replacing the edge detector and by doubling the sampling rate we improve the model-based object tracking system significantly compared to an earlier system. The trajectories of vehicles are characterized by motion verbs and verb phrases. Results from various experiments with real world traffic scenes are presented."
            },
            "slug": "Association-of-Motion-Verbs-with-Vehicle-Movements-Kollnig-Nagel",
            "title": {
                "fragments": [],
                "text": "Association of Motion Verbs with Vehicle Movements Extracted from Dense Optical Flow Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This contribution addresses the problem of detection and tracking of moving vehicles in image sequences from traffic scenes recorded by a stationary camera by replacing the low level vision system component for the estimation of displacement vectors by an optical flow estimation module."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414870"
                        ],
                        "name": "N. Okada",
                        "slug": "N.-Okada",
                        "structuredName": {
                            "firstName": "Naoyuki",
                            "lastName": "Okada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Okada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Okada (1980, 1996), as a\npioneer, demonstrates textual explanation of activities of entities in a series of line drawings through simulated mind model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24425127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9828be632f1b44a440119b3befc784052b7dec1",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a taxonomy of \"matter concepts\" or concepts of verbs that play roles of governors in understanding natural language and picture patterns. For this taxonomy we associate natural language with real world picture patterns and analyze the meanings common to them. The analysis shows that matter concepts are divided into two large classes:\"simple matter concepts\" and \"non-simple matter concepts.\" Furthermore, the latter is divided into \"complex concepts\" and \"derivative concepts.\" About 4,700 matter concepts used in daily Japanese were actually classified according to the analysis. As a result of the classification about 1,200 basic matter concepts which cover the concepts of real world matter at a minimum were obtained. This classification was applied to a translation of picture pattern sequences into natural language."
            },
            "slug": "Conceptual-Taxonomy-of-Japanese-Verbs-for-Natural-Okada",
            "title": {
                "fragments": [],
                "text": "Conceptual Taxonomy of Japanese Verbs for Uderstanding Natural Language and Picture Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A taxonomy of \"matter concepts\" or concepts of verbs that play roles of governors in understanding natural language and picture patterns and the meanings common to them was applied to a translation of picture pattern sequences into natural language."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103200794"
                        ],
                        "name": "NetworksStephen",
                        "slug": "NetworksStephen",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "NetworksStephen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "NetworksStephen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2035278947"
                        ],
                        "name": "Intille",
                        "slug": "Intille",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Intille",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Intille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071624500"
                        ],
                        "name": "Aaron",
                        "slug": "Aaron",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Aaron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080412006"
                        ],
                        "name": "BobickPerceptual",
                        "slug": "BobickPerceptual",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "BobickPerceptual",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "BobickPerceptual"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 175
                            }
                        ],
                        "text": "Similarly, in an automatic annotation system for a sport scene, each formation of players is represented by belief networks based on visual evidence and temporal constraints (Intille and Bobick, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8696740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "494c83e408ddb4c31cd5ba60206b713310cd8269",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic framework for representing and visually recognizing complex multi-agent action is presented. Motivated by work in model-based object recognition and designed for the recognition of action from visual evidence, the representation has three components: (1) temporal structure descriptions representing the logical and temporal relationships between agent goals, (2) belief networks for probabilistically representing and recognizing individual agent goals from visual evidence, and (3) belief networks automatically generated from the temporal structure descriptions that support the recognition of the complex action. We describe our current work on recognizing American football plays from noisy trajectory data."
            },
            "slug": "Representation-and-Visual-Recognition-of-Complex-,-NetworksStephen-Intille",
            "title": {
                "fragments": [],
                "text": "Representation and Visual Recognition of Complex , Multi-agent Actions using Belief"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The current work on recognizing American football plays from noisy trajectory data is described, and a probabilistic framework for representing and visually recognizing complex multi-agent action is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760079"
                        ],
                        "name": "T. Kitahashi",
                        "slug": "T.-Kitahashi",
                        "structuredName": {
                            "firstName": "Tadahiro",
                            "lastName": "Kitahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kitahashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068061815"
                        ],
                        "name": "Muneki Ohya",
                        "slug": "Muneki-Ohya",
                        "structuredName": {
                            "firstName": "Muneki",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Muneki Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2488986"
                        ],
                        "name": "K. Kakusho",
                        "slug": "K.-Kakusho",
                        "structuredName": {
                            "firstName": "Koh",
                            "lastName": "Kakusho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kakusho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727647"
                        ],
                        "name": "N. Babaguchi",
                        "slug": "N.-Babaguchi",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Babaguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Babaguchi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: natural language generation, concept hierarchy, semantic primitive, position/posture estimation of human, case frame"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Kitahashi et al. (1997) and Babaguchi et al. (1996) present schemes for integrating pattern information and natural language notions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46333062,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "01097e6a8181c2337faefed49b507ad45f78d772",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors view a document as a multi-modal media in the sense that it presents information by using figures and/or images as well as text. By showing examples of media conversion and media integration, the authors discuss the essential processing techniques of media information, especially document media information. First, media conversion is briefly addressed by an example of converting a graph diagram in a document to either an alternative graph diagram or a table. The main topic is the generation of a manual of a mechanical parts assembly as an example of media integration in a document. Thereby, necessary input information is presented for generating the manual."
            },
            "slug": "Media-information-processing-in-of-manuals-of-parts-Kitahashi-Ohya",
            "title": {
                "fragments": [],
                "text": "Media information processing in documents-generation of manuals of mechanical parts assembling"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The main topic is the generation of a manual of a mechanical parts assembly as an example of media integration in a document and the essential processing techniques of media information, especially document media information."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414870"
                        ],
                        "name": "N. Okada",
                        "slug": "N.-Okada",
                        "structuredName": {
                            "firstName": "Naoyuki",
                            "lastName": "Okada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Okada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46743934"
                        ],
                        "name": "Aiko Miura",
                        "slug": "Aiko-Miura",
                        "structuredName": {
                            "firstName": "Aiko",
                            "lastName": "Miura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aiko Miura"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Okada (1980, 1996) , as a 172 Kojima, Tamura and Fukunaga"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1573022,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "26bb1c4a66355385277258ad0988025d45b91120",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "S O to state S 1 as shown in Fig. 14 Adjective concepts are considered to be c a p t u r e d as the \" d i f f e r e n c e \" between o b j e c t s O O and 0 I. Ylg.2 shows how the difference in vertical length between 00 and 01 b r i n g s about the concept of \" h i gh\" . Not ice t h a t s u r f a c e s t r u c t u r e s o f t e n l ack the e x p r e s s i o n of 00 l i k e \"yama-ga t a k a i ( the m o u n t a i n i s h i g h ) \" . S ince the meaning of \"h igh\" cannot be expressed on ly by O 1, deep s t r u c t u r e s need O 0 as an object for comparison."
            },
            "slug": "Conceptual-Taxonomy-of-Japanese-Adjectives-for-and-Okada-Miura",
            "title": {
                "fragments": [],
                "text": "Conceptual Taxonomy of Japanese Adjectives for Understanding Natural Language and Picture Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "S O to state S 1 as shown in Fig. 2 shows how the difference in vertical length between 00 and 01 b r i n g s about the concept of \" h i gh\" shows how deep s t r u c t u r e s need O 0 as an object for comparison."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414870"
                        ],
                        "name": "N. Okada",
                        "slug": "N.-Okada",
                        "structuredName": {
                            "firstName": "Naoyuki",
                            "lastName": "Okada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Okada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Okada (1980, 1996), as a\npioneer, demonstrates textual explanation of activities of entities in a series of line drawings through simulated mind model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30067207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc26494fc802de7514ddce3d5f4e213c8ecc299b",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an integrated comprehension and generation system for vision, motion and language. First, a computer model of mind proposed previously is reviewed as the basis of the integration. It consists of nine domains according to the contents of mental activities and five levels along the process of concept formation.Then, vision and motion are discussed based on the model. Real world objects are divided into four categories: substance, event, attribute and others. The first three are named as noun, verb and adjective, respectively. The comprehension process of the named objects and the generation process of the named motion are shown along the five levels. Furthermore, vision and motion are connected and controlled by planning.Next, language is considered to \u201cdescribe any data or processing in mind\u201d in our model. From this are derived three functions: surveying any mental object, organizing high-level thought, and communicating with others. The realization of these functions is discussed from the point of generation.Next, an integrated system for vision, motion, and language is implemented on workstations. The system, or an intellectual and emotional agent, simulates the protagonist or fox of an Aesop fable. Its mental and physical behavior is shown by graphic displays, a voice generator, and a music generator which expresses its emotional states.In conclusion, this system could be expected to provide a good framework for integrated comprehension and generation systems from the technological point of view."
            },
            "slug": "Integrating-vision,-motion-and-language-through-Okada",
            "title": {
                "fragments": [],
                "text": "Integrating vision, motion and language through mind"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "An integrated comprehension and generation system for vision, motion and language that simulates the protagonist or fox of an Aesop fable and could be expected to provide a good framework for integrated absorption and generation systems from the technological point of view."
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence Review"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727647"
                        ],
                        "name": "N. Babaguchi",
                        "slug": "N.-Babaguchi",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Babaguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Babaguchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3234879"
                        ],
                        "name": "Seiichiro Dan",
                        "slug": "Seiichiro-Dan",
                        "structuredName": {
                            "firstName": "Seiichiro",
                            "lastName": "Dan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seiichiro Dan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760079"
                        ],
                        "name": "T. Kitahashi",
                        "slug": "T.-Kitahashi",
                        "structuredName": {
                            "firstName": "Tadahiro",
                            "lastName": "Kitahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kitahashi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: natural language generation, concept hierarchy, semantic primitive, position/posture estimation of human, case frame"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 28
                            }
                        ],
                        "text": "Kitahashi et al. (1997) and Babaguchi et al. (1996) present schemes for integrating pattern information and natural language notions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41230124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f2b9adc0600d8d4ae9233be93b43990f69fa148",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a method of generating a sketch map drawing and its instructions in order to support the route understanding of a human. Both are given from a structured data, called the road network, which is a graph augmented by the attributes of roads and crossings. In generating a sketch map drawing, the pictorial information about the shape and the direction of roads is modified. The sketch map drawing can be generated at any simplification level by controlling a parameter called simpleness. The instructions corresponding to the sketch map are produced by assigning appropriate terms into sentence templates. We verified that favorable results are obtained by this method."
            },
            "slug": "Generation-of-sketch-map-image-and-its-instructions-Babaguchi-Dan",
            "title": {
                "fragments": [],
                "text": "Generation of sketch map image and its instructions to support the understanding of geographical information"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper proposed a method of generating a sketch map drawing and its instructions from a structured data, called the road network, which is a graph augmented by the attributes of roads and crossings."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909761"
                        ],
                        "name": "F. Nishida",
                        "slug": "F.-Nishida",
                        "structuredName": {
                            "firstName": "Fujio",
                            "lastName": "Nishida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Nishida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143882780"
                        ],
                        "name": "S. Takamatsu",
                        "slug": "S.-Takamatsu",
                        "structuredName": {
                            "firstName": "Shinobu",
                            "lastName": "Takamatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Takamatsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 99
                            }
                        ],
                        "text": "A case frame is translated into natural language sentence using case structures and verb patterns (Nishida and Takamatsu, 1982; Nishida et al., 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 738216,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "fc256fe2138812d11dc1f944d4caa28a44558ddc",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an approach to Japanese-English translation through internal expressions which are similar to those used in our recent approach to English-Japanese translation [2]. Attention is focused on construction of the internal expressions of Japanese sentences based on case structures of predicates and also conversion of the Japanese internal expressions to the English ones for generating good English sentences in conventional use. Finally, associated with translation, extraction of specified translated information from Japanese patent claim sentences is described briefly."
            },
            "slug": "Japanese-English-Translation-Through-Internal-Nishida-Takamatsu",
            "title": {
                "fragments": [],
                "text": "Japanese-English Translation Through Internal Expressions"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This paper describes an approach to Japanese-English translation through internal expressions which are similar to those used in the recent approach to English-Japanese translation, focused on construction of the internal expressions of Japanese sentences based on case structures of predicates."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 45
                            }
                        ],
                        "text": "An electronic thesaurus, especially WordNet (Fellbaum, 1998), is useful because it has links to super- and sub-concept of a word."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13575,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72523686"
                        ],
                        "name": "Katsunori Asanuma",
                        "slug": "Katsunori-Asanuma",
                        "structuredName": {
                            "firstName": "Katsunori",
                            "lastName": "Asanuma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katsunori Asanuma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703823"
                        ],
                        "name": "M. Onishi",
                        "slug": "M.-Onishi",
                        "structuredName": {
                            "firstName": "Masaki",
                            "lastName": "Onishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Onishi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49693392"
                        ],
                        "name": "A. Kojima",
                        "slug": "A.-Kojima",
                        "structuredName": {
                            "firstName": "Atsuhiro",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kojima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950023"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Kunio",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 55
                            }
                        ],
                        "text": "In this paper, we use a method we proposed previously (Asanuma et al., 1999), in which human skin regions can be robustly tracked under complex backgrounds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64166259,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abf20ca689bfdc723314a0f40909379bd9a82c0a",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a method of extracting and tracking regions of human face and hands appeared on sequential images considering fusion of color information and tracking region. Conventionally, it has been hard to extract the skin regions of human in the case when a background reflects skin color objects like corrugated cardboards, or including moving picture such as TV screen. Coping with such kind of difficult situation to extract skin regions, we firstly obtain three kinds of information based on background color, skin color and its tracking skin regions, then apply Dempster-Shafer's combination rule to the three kinds of information. This approach using the fused information becomes a robust extraction method, because other information can extract the regions even if one of the information lacks. The effectiveness of our approach is examined by the experiments."
            },
            "slug": "Extracting-Regions-of-Human-Face-and-Hands-of-Color-Asanuma-Onishi",
            "title": {
                "fragments": [],
                "text": "Extracting Regions of Human Face and Hands considering Information of Color and Region Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper proposes a method of extracting and tracking regions of human face and hands appeared on sequential images considering fusion of color information and tracking region, and obtains three kinds of information based on background color, skin color and its tracking skin regions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909761"
                        ],
                        "name": "F. Nishida",
                        "slug": "F.-Nishida",
                        "structuredName": {
                            "firstName": "Fujio",
                            "lastName": "Nishida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Nishida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143882780"
                        ],
                        "name": "S. Takamatsu",
                        "slug": "S.-Takamatsu",
                        "structuredName": {
                            "firstName": "Shinobu",
                            "lastName": "Takamatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Takamatsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072677453"
                        ],
                        "name": "Tadaaki Tani",
                        "slug": "Tadaaki-Tani",
                        "structuredName": {
                            "firstName": "Tadaaki",
                            "lastName": "Tani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tadaaki Tani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152670469"
                        ],
                        "name": "Tsunehisa Doi",
                        "slug": "Tsunehisa-Doi",
                        "structuredName": {
                            "firstName": "Tsunehisa",
                            "lastName": "Doi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsunehisa Doi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 128
                            }
                        ],
                        "text": "A case frame is translated into natural language sentence using case structures and verb patterns (Nishida and Takamatsu, 1982; Nishida et al., 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18455650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b08b905c31c2c5d0457d6150261be7548bfa6a99",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an attempt to construct a feedback system PECOF which improves a Japanese-English Machine Translation system by feedback of correcting information given by posteditors. PECOF analyzes the error-correcting information by using an English-Japanese Machine Translation system which works in the reverse direction to the original MT system, compares the intermediate expressions of the corrected patterns with those of the erroneous parts of the original MT output at every transfer stage and identifies the responsible parts of the original Japanese-English MT system. Then PECOF corrects the irrelevant parts of the database or adds error correcting patterns to a document of postediting to ask users for further examinations for corrections."
            },
            "slug": "Feedback-of-Correcting-Information-in-Postediting-a-Nishida-Takamatsu",
            "title": {
                "fragments": [],
                "text": "Feedback of Correcting Information in Postediting to a Machine Translation System"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents an attempt to construct a feedback system PECOF which improves a Japanese-English Machine Translation system by feedback of correcting information given by posteditors."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 30
                            }
                        ],
                        "text": "Using Dempster-Shafer theory (Shafer, 1976), these three kinds of probabilities are integrated into one probability that the pixel belongs to a skin region of the human."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27862354,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4cd91c51098783ec972f6a0ab430cacdd634a5b2",
            "isKey": false,
            "numCitedBy": 14561,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Both in science and in practical affairs we reason by combining facts only inconclusively supported by evidence. Building on an abstract understanding of this process of combination, this book constructs a new theory of epistemic probability. The theory draws on the work of A. P. Dempster but diverges from Depster's viewpoint by identifying his \"lower probabilities\" as epistemic probabilities and taking his rule for combining \"upper and lower probabilities\" as fundamental. The book opens with a critique of the well-known Bayesian theory of epistemic probability. It then proceeds to develop an alternative to the additive set functions and the rule of conditioning of the Bayesian theory: set functions that need only be what Choquet called \"monotone of order of infinity.\" and Dempster's rule for combining such set functions. This rule, together with the idea of \"weights of evidence,\" leads to both an extensive new theory and a better understanding of the Bayesian theory. The book concludes with a brief treatment of statistical inference and a discussion of the limitations of epistemic probability. Appendices contain mathematical proofs, which are relatively elementary and seldom depend on mathematics more advanced that the binomial theorem."
            },
            "slug": "A-Mathematical-Theory-of-Evidence-Shafer",
            "title": {
                "fragments": [],
                "text": "A Mathematical Theory of Evidence"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This book develops an alternative to the additive set functions and the rule of conditioning of the Bayesian theory: set functions that need only be what Choquet called \"monotone of order of infinity.\" and Dempster's rule for combining such set functions."
            },
            "venue": {
                "fragments": [],
                "text": "A Mathematical Theory of Evidence"
            },
            "year": 2020
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 160
                            }
                        ],
                        "text": "In our previous paper, we present a method for generating textual descriptions from position and orientation of human head representing the whole body posture (Kojima et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 0
                            }
                        ],
                        "text": "Okada(1980)demonstratetextual explanationof activitiesof entitiesin a seriesof line drawingsthroughsimulatedmind modelin theirpioneeringworks(Okada,1996). Kitahashiet al. (1997)andBabaguchi et al. (1996)presentschemesfor integrating patterninformationandnatural languagenotions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 165
                            }
                        ],
                        "text": "For humanactivitiesonrealvideoimages,wehave proposedamethodof generatingtextual descriptions from position andorientati on of humanhead in behalfof whole bodyposture(Kojima et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Okada(1980)demonstratetextual explanationof activitiesof entitiesin a seriesof line drawingsthroughsimulatedmind modelin theirpioneeringworks(Okada,1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "andFukunaga,K.: \u2018GeneratingNaturalLanguageDescription of HumanBehavior from VideoImages"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc.of ICPR2000Vol.4,"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69878945"
                        ],
                        "name": "A. Hornby",
                        "slug": "A.-Hornby",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Hornby",
                            "middleNames": [
                                "Sydney"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hornby"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "verb patterns classified by Hornby (1975). For example, the intransitive verb \u2018walk\u2019 (VP2) is necessarily accompanied with only an agentive case, while goal and/or source case is optional: Ex."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 81
                            }
                        ],
                        "text": "In English, the order of phrases is dominated by the verb patterns classified by Hornby (1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60616875,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "96135ea3bb8eb7616f88f5f5617e03f2ddc9f4c0",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Guide-to-Patterns-and-Usage-in-English-Hornby",
            "title": {
                "fragments": [],
                "text": "Guide to Patterns and Usage in English"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1954
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 32
                            }
                        ],
                        "text": "In a visual surveillance system (Thonnat and Rota, 1999), human behavior is represented by scenarios, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 33
                            }
                        ],
                        "text": "In a visual surveillance system (Thonnat and Rota, 1999), human behavior is represented by scenarios, i.e. predefined sequences of events."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image understanding for visual surveillance applications"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of 3rd Int. Workshop on Cooperative Distributed Vision, pp. 51\u201382."
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IntegratingVisionandLanguage:TowardsAutomaticDescription of HumanMovements"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. 19th Annual German Conf. on Artificial Intelligence,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 81
                            }
                        ],
                        "text": "In English, the order of phrases is dominated by the verb patterns classified by Hornby (1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 25
                            }
                        ],
                        "text": "verbpatternsclassifiedby Hornby(1975).For example,theintransi tiveverb \u2018walk\u2019 (VP2) is necessarilyaccompaniedwith only an agenti ve case,while goal and/orsourcecaseis optional: Ex."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Guideto PatternsandUsagein English, OxfordUniv"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Kitahashi et al. (1997) and Babaguchi et al. (1996) present schemes for integrating pattern information and natural language notions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Media InformationProcesingin Documents\u2013 Generationof Manualsof Mechanical PartsAssembling \u2013"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc.of 4th Int. Conf. onDocumentAnalysisandRecognition, Ulm, Germany,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Osaka Prefecture University 1-1 Gakuen-cho, Sakai, Osaka 599-8531, JAPAN E-mail: ark@center.osakafu-u.ac"
            },
            "venue": {
                "fragments": [],
                "text": "Osaka Prefecture University 1-1 Gakuen-cho, Sakai, Osaka 599-8531, JAPAN E-mail: ark@center.osakafu-u.ac"
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Natural-Language-Description-of-Human-Activities-on-Kojima-Tamura/d53a97a3dd7760b193c0d9a5293b60feff239059?sort=total-citations"
}