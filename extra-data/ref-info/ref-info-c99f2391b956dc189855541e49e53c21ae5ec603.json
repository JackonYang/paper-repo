{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 74
                            }
                        ],
                        "text": "As suggested in Torralba and Oliva (1999), Oliva and Torralba (2001), and Torralba and Sinha (2001) the scene/context can be considered a single entity that can be recognized by means of a scene-centered representation bypassing the identification of the constituent objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 116
                            }
                        ],
                        "text": "An alternative view of context relies on using the entire scene information holistically\n(Oliva and Torralba, 2001; Torralba and Sinha, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 171
                            }
                        ],
                        "text": "Our goal here is to use such a scheme for including context information in object representations and to demonstrate its role in facilitating individual object detection (Torralba and Sinha, 2001; Torralba, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9982531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6a48c0dbff6e7fa752fdcf8ef34f8cba8202b41",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. However the issue of how to formalize centextual influences is still largely open. Here we introduce a simple probabilistic framework for modeling the relationship between context and object properties. We represent global context information in terms of the spatial layout of spectral components. The resulting scheme serves as an effective procedure for context driven focus of attention and scale-selection on real-world scenes. Based on a simple holistic analysis of an image, the scheme is able to accurately predict object locations and sizes."
            },
            "slug": "Statistical-context-priming-for-object-detection-Torralba-Sinha",
            "title": {
                "fragments": [],
                "text": "Statistical Context Priming for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple probabilistic framework for modeling the relationship between context and object properties is introduced, representing global context information in terms of the spatial layout of spectral components and serving as an effective procedure for context driven focus of attention and scale-selection on real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156786341"
                        ],
                        "name": "tephen E. Palmer",
                        "slug": "tephen-E.-Palmer",
                        "structuredName": {
                            "firstName": "tephen",
                            "lastName": "Palmer",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "tephen E. Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "Experiments in scene perception and visual search (Palmer, 1975; Biederman et al., 1982;"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, object recognition, focus of attention, automatic scale selection, object priming"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20646799,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "cc9057f0fc18874314a3c1049d93a6749dc36f73",
            "isKey": false,
            "numCitedBy": 631,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This experiment demonstrates the influence of the prior presentation of visual scenes on the identification of briefly presented drawings of real-world objects. Different pairings of objects and scenes were used to produce three main contextual conditions: appropriate, inappropriate, and no context. Correct responses and confusions with visually similar objects depended strongly on both the contextual condition and the particular target object presented. The probability of being correct was highest in the appropriate context condition and lowest in the inappropriate context condition. Confidence ratings of responses were a function of the perceptual similarity between the stimulus object and the named object; they were not strongly affected by contextual conditions. Morton\u2019s (1970) \u201clogogen\u201d model provided a good quantitative fit to the response probability data."
            },
            "slug": "The-effects-of-contextual-scenes-on-the-of-objects-Palmer",
            "title": {
                "fragments": [],
                "text": "The effects of contextual scenes on the identification of objects"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This experiment demonstrates the influence of the prior presentation of visual scenes on the identification of briefly presented drawings of real-world objects using Morton\u2019s (1970) \u201clogogen\u201d model."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4611739"
                        ],
                        "name": "P. de Graef",
                        "slug": "P.-de-Graef",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "de Graef",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. de Graef"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081692601"
                        ],
                        "name": "Dominie Christiaens",
                        "slug": "Dominie-Christiaens",
                        "structuredName": {
                            "firstName": "Dominie",
                            "lastName": "Christiaens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dominie Christiaens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398239168"
                        ],
                        "name": "G. d'Ydewalle",
                        "slug": "G.-d'Ydewalle",
                        "structuredName": {
                            "firstName": "G\u00e9ry",
                            "lastName": "d'Ydewalle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. d'Ydewalle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 9
                            }
                        ],
                        "text": "Figures 15(c) and (d) correspond to the contextual\npriming provided by the objects already recognized for the detection of the remaining objects of the same category in the scene: P(x | o, O1, O2, . . .)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, object recognition, focus of attention, automatic scale selection, object priming"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 193
                            }
                        ],
                        "text": "When considering real world-scenes, it is very likely that visual search strategies and the computation of saliency maps are modulated by global high-level information related to the scene (De Graef et al., 1990; Henderson and Holligworth, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1281770,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6d4b0e1e0692d4d92ac03b70aa42f20c288172df",
            "isKey": false,
            "numCitedBy": 311,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryIn a number of studies the context provided by a real-world scene has been claimed to have a mandatory, perceptual effect on the identification of individual objects in such a scene. This claim has provided a basis for challenging widely accepted data-driven models of visual perception in order to advocate alternative models with an outspoken top-down character. The present paper offers a review of the evidence to demonstrate that the observed scene-context effects may be the product of post-perceptual and task-dependent guessing strategies. A new research paradigm providing an on-line measure of genuine perceptual effects of context on object identification is proposed. First-fixation durations for objects incidentally fixated during the free exploration of real-world scenes are shown to increase when the objects are improbable in the scene or violate certain aspects of their typical spatial appearance in it. These effects of contextual violations are shown to emerge only at later stages of scene exploration, contrary to the notion of schema-driven scene perception effective from the very first scene fixation. In addition, evidence is reported in support of the existence of a facilitatory component in scene-context effects. This is taken to indicate that the context directly affects the ease of perceptual object processing and does not merely serve as a framework for checking the plausibility of the output of perceptual processes. Finally, our findings are situated against other contrasting results. Some future research questions are highlighted."
            },
            "slug": "Perceptual-effects-of-scene-context-on-object-Graef-Christiaens",
            "title": {
                "fragments": [],
                "text": "Perceptual effects of scene context on object identification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A review of the evidence is offered to demonstrate that the observed scene-context effects may be the product of post-perceptual and task-dependent guessing strategies, and to indicate that the context directly affects the ease of perceptual object processing."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological research"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153014854"
                        ],
                        "name": "R. J. Mezzanotte",
                        "slug": "R.-J.-Mezzanotte",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mezzanotte",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J. Mezzanotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117606629"
                        ],
                        "name": "J. C. Rabinowitz",
                        "slug": "J.-C.-Rabinowitz",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Rabinowitz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. Rabinowitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 94
                            }
                        ],
                        "text": "Although these kinds of context priming have been shown to be important in human vision (e.g. Biederman et al., 1982), computational models of object detection typically ignore the information available from the context."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 65
                            }
                        ],
                        "text": "Experiments in scene perception and visual search (Palmer, 1975; Biederman et al., 1982;"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 50
                            }
                        ],
                        "text": "Experiments in scene perception and visual search (Palmer, 1975; Biederman et al., 1982; De Graef et al., 1990; Henderson and Hollingworth, 1999; Chun and Jiang, 1998) have shown that the human visual system makes extensive use of these relationships for facilitating object detection and recognition suggesting that the visual system first processes context information in order to index object properties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16232587,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a5b309957c0113d45458268f2324b36c52ae3f73",
            "isKey": false,
            "numCitedBy": 982,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scene-perception:-Detecting-and-judging-objects-Biederman-Mezzanotte",
            "title": {
                "fragments": [],
                "text": "Scene perception: Detecting and judging objects undergoing relational violations"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 145641722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf85123feb2cf0ec42930ce324501fd2cd9c049c",
            "isKey": false,
            "numCitedBy": 720,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In very fast recognition tasks, scenes are identified as fast as isolated objects How can this efficiency be achieved, considering the large number of component objects and interfering factors, such as cast shadows and occlusions? Scene categories tend to have distinct and typical spatial organizations of their major components If human perceptual structures were tuned to extract this information early in processing, a coarse-to-fine process could account for efficient scene recognition A coarse description of the input scene (oriented \u201cblobs\u201d in a particular spatial organization) would initiate recognition before the identity of the objects is processed We report two experiments that contrast the respective roles of coarse and fine information in fast identification of natural scenes The first experiment investigated whether coarse and fine information were used at different stages of processing The second experiment tested whether coarse-to-fine processing accounts for fast scene categorization The data suggest that recognition occurs at both coarse and fine spatial scales By attending first to the coarse scale, the visual system can get a quick and rough estimate of the input to activate scene schemas in memory, attending to fine information allows refinement, or refutation, of the raw estimate"
            },
            "slug": "From-Blobs-to-Boundary-Edges:-Evidence-for-Time-and-Schyns-Oliva",
            "title": {
                "fragments": [],
                "text": "From Blobs to Boundary Edges: Evidence for Time- and Spatial-Scale-Dependent Scene Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The data suggest that recognition occurs at both coarse and fine spatial scales, and that attending first to the coarse scale can get a quick and rough estimate of the input to activate scene schemas in memory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3662180"
                        ],
                        "name": "G. Gelade",
                        "slug": "G.-Gelade",
                        "structuredName": {
                            "firstName": "Garry",
                            "lastName": "Gelade",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gelade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 169
                            }
                        ],
                        "text": "The most popular ones are based on low-level saliency maps (without any high-level information relative to the task or context, e.g. Itti et al., 1998; Lindeberg, 1993; Treisman and Gelade, 1980; Wolfe, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 353246,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "76361a44e145732a39dbc68d9418871038c83be2",
            "isKey": false,
            "numCitedBy": 11415,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-feature-integration-theory-of-attention-Treisman-Gelade",
            "title": {
                "fragments": [],
                "text": "A feature-integration theory of attention"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3286262"
                        ],
                        "name": "M. Chun",
                        "slug": "M.-Chun",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Chun",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144648366"
                        ],
                        "name": "Yuhong V. Jiang",
                        "slug": "Yuhong-V.-Jiang",
                        "structuredName": {
                            "firstName": "Yuhong",
                            "lastName": "Jiang",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhong V. Jiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the real world, there exists a strong relationship between the environment and the objects that can be found within it. Experiments in scene perception and visual search (Palmer, 1975; Biederman et al., 1982; De Graef et al., 1990; Henderson and Hollingworth, 1999;  Chun and Jiang, 1998 ) have shown that the human visual system makes extensive use of these relationships for facilitating object detection and recognition suggesting that the ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 6
                            }
                        ],
                        "text": "1999; Chun and Jiang, 1998) have shown that the human visual system makes extensive use of these relationships for facilitating object detection and recognition suggesting that the visual system first processes context information in order to index object properties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1955059,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "ff1c9b87dfd0663aef303e4ecf1734a6495bb488",
            "isKey": false,
            "numCitedBy": 1748,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "Global context plays an important, but poorly understood, role in visual tasks. This study demonstrates that a robust memory for visual context exists to guide spatial attention. Global context was operationalized as the spatial layout of objects in visual search displays. Half of the configurations were repeated across blocks throughout the entire session, and targets appeared within consistent locations in these arrays. Targets appearing in learned configurations were detected more quickly. This newly discovered form of search facilitation is termed contextual cueing. Contextual cueing is driven by incidentally learned associations between spatial configurations (context) and target locations. This benefit was obtained despite chance performance for recognizing the configurations, suggesting that the memory for context was implicit. The results show how implicit learning and memory of visual context can guide spatial attention towards task-relevant aspects of a scene."
            },
            "slug": "Contextual-Cueing:-Implicit-Learning-and-Memory-of-Chun-Jiang",
            "title": {
                "fragments": [],
                "text": "Contextual Cueing: Implicit Learning and Memory of Visual Context Guides Spatial Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results show how implicit learning and memory of visual context can guide spatial attention towards task-relevant aspects of a scene."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4910863"
                        ],
                        "name": "A. Hollingworth",
                        "slug": "A.-Hollingworth",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hollingworth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hollingworth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 50
                            }
                        ],
                        "text": "Experiments in scene perception and visual search (Palmer, 1975; Biederman et al., 1982; De Graef et al., 1990; Henderson and Hollingworth, 1999; Chun and Jiang, 1998) have shown that the human visual system makes extensive use of these relationships for facilitating object detection and recognition suggesting that the visual system first processes context information in order to index object properties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 920100,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "12684438f2a34d96ed02f96a0be460b83c4f1e52",
            "isKey": false,
            "numCitedBy": 929,
            "numCiting": 151,
            "paperAbstract": {
                "fragments": [],
                "text": "Three areas of high-level scene perception research are reviewed. The first concerns the role of eye movements in scene perception, focusing on the influence of ongoing cognitive processing on the position and duration of fixations in a scene. The second concerns the nature of the scene representation that is retained across a saccade and other brief time intervals during ongoing scene perception. Finally, we review research on the relationship between scene and object identification, focusing particularly on whether the meaning of a scene influences the identification of constituent objects."
            },
            "slug": "High-level-scene-perception.-Henderson-Hollingworth",
            "title": {
                "fragments": [],
                "text": "High-level scene perception."
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Three areas of high-level scene perception research are reviewed, focusing on the role of eye movements in scene perception and the influence of ongoing cognitive processing on the position and duration of fixations in a scene."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of psychology"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 117
                            }
                        ],
                        "text": "In the case of human heads, changes in pose due to horizontal rotations are unconstrained by contextual information (Torralba, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 197
                            }
                        ],
                        "text": "Our goal here is to use such a scheme for including context information in object representations and to demonstrate its role in facilitating individual object detection (Torralba and Sinha, 2001; Torralba, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16610199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f05f91c03fc7497162f754fdbfcddc5fcf4179fb",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The most popular algorithms for object detection require the use of exhaustive spatial and scale search procedures. In such approaches, an object is defined by means of local features. In this paper we show that including contextual information in object detection procedures provides an efficient way of cutting down the need for exhaustive search. We present results with real images showing that the proposed scheme is able to accurately predict likely object classes, locations and sizes."
            },
            "slug": "Contextual-Modulation-of-Target-Saliency-Torralba",
            "title": {
                "fragments": [],
                "text": "Contextual Modulation of Target Saliency"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper shows that including contextual information in object detection procedures provides an efficient way of cutting down the need for exhaustive search."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45203429,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6",
            "isKey": false,
            "numCitedBy": 3957,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Psychophysical and physiological evidence indicates that the visual system of primates and humans has evolved a specialized processing focus moving across the visual scene. This study addresses the question of how simple networks of neuron-like elements can account for a variety of phenomena associated with this shift of selective visual attention. Specifically, we propose the following: (1) A number of elementary features, such as color, orientation, direction of movement, disparity etc. are represented in parallel in different topographical maps, called the early representation. (2) There exists a selective mapping from the early topographic representation into a more central non-topographic representation, such that at any instant the central representation contains the properties of only a single location in the visual scene, the selected location. We suggest that this mapping is the principal expression of early selective visual attention. One function of selective attention is to fuse information from different maps into one coherent whole. (3) Certain selection rules determine which locations will be mapped into the central representation. The major rule, using the conspicuity of locations in the early representation, is implemented using a so-called Winner-Take-All network. Inhibiting the selected location in this network causes an automatic shift towards the next most conspicious location. Additional rules are proximity and similarity preferences. We discuss how these rules can be implemented in neuron-like networks and suggest a possible role for the extensive back-projection from the visual cortex to the LGN."
            },
            "slug": "Shifts-in-selective-visual-attention:-towards-the-Koch-Ullman",
            "title": {
                "fragments": [],
                "text": "Shifts in selective visual attention: towards the underlying neural circuitry."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This study addresses the question of how simple networks of neuron-like elements can account for a variety of phenomena associated with this shift of selective visual attention and suggests a possible role for the extensive back-projection from the visual cortex to the LGN."
            },
            "venue": {
                "fragments": [],
                "text": "Human neurobiology"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 175
                            }
                        ],
                        "text": "In essence, {an}n=1,D is a holistic representation as all the regions of the image contribute to all the coefficients, and objects are not encoded individually (see Oliva and Torralba, 2001, for a detailed description\nof the holistic representation)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 127
                            }
                        ],
                        "text": "As we will show here, a holistic scene analysis allows representing the context in a very low dimensional space (see Oliva and Torralba, 2001 for a detailed description)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 127
                            }
                        ],
                        "text": "Low-level features statistics differ when considering real world images corresponding to different scene categories (Oliva and Torralba, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 101
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 53
                            }
                        ],
                        "text": "As suggested in Torralba and Oliva (1999), Oliva and Torralba (2001), and Torralba and Sinha (2001) the scene/context can be considered a single entity that can be recognized by means of a scene-centered representation bypassing the identification of the constituent objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 26
                            }
                        ],
                        "text": "As discussed in Oliva and Torralba (2001), the second order statistics of natural images (encoded in the Fourier spectra) are correlated with simple scene attributes (e.g. depth) and, therefore, strongly differ between distinct environmental categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 26
                            }
                        ],
                        "text": "As suggested in Oliva and Torralba (2001) it is possible to build a representation of the scene that bypasses object identities, in which the scene is represented as a single entity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 108
                            }
                        ],
                        "text": "Computational studies too (Gorkani and Picard, 1994; Schiele and Crowley, 2000; Rao et al., 1996; Oliva and Torralba, 2001) have found this choice of features useful for several object and scene recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 100
                            }
                        ],
                        "text": "An alternative view of context relies on using the entire scene information holistically\n(Oliva and Torralba, 2001; Torralba and Sinha, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11664336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "869171b2f56cfeaa9b81b2626cb4956fea590a57",
            "isKey": false,
            "numCitedBy": 6522,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "slug": "Modeling-the-Shape-of-the-Scene:-A-Holistic-of-the-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717172"
                        ],
                        "name": "J. Wolfe",
                        "slug": "J.-Wolfe",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wolfe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 196
                            }
                        ],
                        "text": "The most popular ones are based on low-level saliency maps (without any high-level information relative to the task or context, e.g. Itti et al., 1998; Lindeberg, 1993; Treisman and Gelade, 1980; Wolfe, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16901865,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a52b81b322087ce82e4ec4124b3a47cbb391a0eb",
            "isKey": false,
            "numCitedBy": 3424,
            "numCiting": 347,
            "paperAbstract": {
                "fragments": [],
                "text": "An important component of routine visual behavior is the ability to find one item in a visual world filled with other, distracting items. This ability to performvisual search has been the subject of a large body of research in the past 15 years. This paper reviews the visual search literature and presents a model of human search behavior. Built upon the work of Neisser, Treisman, Julesz, and others, the model distinguishes between a preattentive, massively parallel stage that processes information about basic visual features (color, motion, various depth cues, etc.) across large portions of the visual field and a subsequent limited-capacity stage that performs other, more complex operations (e.g., face recognition, reading, object identification) over a limited portion of the visual field. The spatial deployment of the limited-capacity process is under attentional control. The heart of the guided search model is the idea that attentional deployment of limited resources isguided by the output of the earlier parallel processes. Guided Search 2.0 (GS2) is a revision of the model in which virtually all aspects of the model have been made more explicit and/or revised in light of new data. The paper is organized into four parts: Part 1 presents the model and the details of its computer simulation. Part 2 reviews the visual search literature on preattentive processing of basic features and shows how the GS2 simulation reproduces those results. Part 3 reviews the literature on the attentional deployment of limited-capacity processes in conjunction and serial searches and shows how the simulation handles those conditions. Finally, Part 4 deals with shortcomings of the model and unresolved issues."
            },
            "slug": "Guided-Search-2.0-A-revised-model-of-visual-search-Wolfe",
            "title": {
                "fragments": [],
                "text": "Guided Search 2.0 A revised model of visual search"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper reviews the visual search literature and presents a model of human search behavior, a revision of the guided search 2.0 model in which virtually all aspects of the model have been made more explicit and/or revised in light of new data."
            },
            "venue": {
                "fragments": [],
                "text": "Psychonomic bulletin & review"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48717175"
                        ],
                        "name": "D. Chernyak",
                        "slug": "D.-Chernyak",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Chernyak",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Chernyak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144145222"
                        ],
                        "name": "L. Stark",
                        "slug": "L.-Stark",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Stark",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Stark"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 119
                            }
                        ],
                        "text": "In a similar vein, some models of visual search and attention include the use of context (e.g., Noton and Stark, 1971; Chernyak and Stark, 2001) to guide eye movements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 134
                            }
                        ],
                        "text": "Some previous models of top-down attention guidance incorporate context information to direct attention (e.g., Noton and Stark, 1971; Chernyak and Stark, 2001; Tsotsos et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8016126,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a06e49457e87e3632c2107bcadaf2d992f62395c",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Eye movements (EMs) are an important aspect of human visual behavior. The temporal and space-variant nature of sampling a visual scene requires frequent attentional gaze shifts (saccades) to fixate onto different parts of an image. Fixations are often directed toward the most informative regions in the visual scene. We introduce a model and its simulation that can select such regions based on prior knowledge of similar scenes. Having representations of scenes as a probabilistic combination of regions with certain properties, it is possible to assess the likely contribution of each region in the successive recognition process. Using Bayesian conditional probabilities for each region given the scene category, the model can then predict the informative value of that region and initiate a spatial information-gathering algorithm analogous to an EM saccade to a new fixation."
            },
            "slug": "Top-down-guided-eye-movements-Chernyak-Stark",
            "title": {
                "fragments": [],
                "text": "Top-down guided eye movements"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model and its simulation is introduced that can select regions based on prior knowledge of similar scenes as a probabilistic combination of regions with certain properties and initiate a spatial information-gathering algorithm analogous to an EM saccade to a new fixation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern. Part B"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2653462"
                        ],
                        "name": "Ronald A. Rensink",
                        "slug": "Ronald-A.-Rensink",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rensink",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald A. Rensink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398984373"
                        ],
                        "name": "J. O'Regan",
                        "slug": "J.-O'Regan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "O'Regan",
                            "middleNames": [
                                "Kevin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Regan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47125588"
                        ],
                        "name": "James J. Clark",
                        "slug": "James-J.-Clark",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Clark",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James J. Clark"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 257
                            }
                        ],
                        "text": "In particular, scene recognition experiments suggest that information about scene identity may be available before performing a more detailed analysis of the individual objects (Potter, 1975; Biederman, 1987; Schyns and Oliva, 1994; Oliva and Schyns, 1997; Rensink et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, object recognition, focus of attention, automatic scale selection, object priming"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1945079,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "644145f29d1463647821378536994e03f4fe4964",
            "isKey": false,
            "numCitedBy": 2252,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "When looking at a scene, observers feel that they see its entire structure in great detail and can immediately notice any changes in it. However, when brief blank fields are placed between alternating displays of an original and a modified scene, a striking failure of perception is induced: Identification of changes becomes extremely difficult, even when changes are large and made repeatedly. Identification is much faster when a verbal cue is provided, showing that poor visibility is not the cause of this difficulty. Identification is also faster for objects considered to be important in the scene. These results support the idea that observers never form a complete, detailed representation of their surroundings. In addition, the results indicate that attention is required to perceive change, and that in the absence of localized motion signals, attention is guided on the basis of high-level interest."
            },
            "slug": "TO-SEE-OR-NOT-TO-SEE:-The-Need-for-Attention-to-in-Rensink-O'Regan",
            "title": {
                "fragments": [],
                "text": "TO SEE OR NOT TO SEE: The Need for Attention to Perceive Changes in Scenes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 97
                            }
                        ],
                        "text": "Coarse color distributions have also been shown to be relevant for scene perception by subjects (Oliva and Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Coarse color distributions have also been shown to be relevant for scene perception by subjects ( Oliva and Schyns, 2000 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17043497,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f24db70b4283b56f43a94edd48d1d35e20935ef4",
            "isKey": false,
            "numCitedBy": 412,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "In this research, we aim to ground scene recognition on information other than the identity of component objects. Specifically we seek to understand the structure of color cues that allows the express recognition of scene gists. Using the L*a*b* color space we examined the conditions under which chromatic cues concur with brightness to allow a viewer to recognize scenes at a glance. Using different methods, Experiments 1 and 2 tested the hypothesis that colors do contribute when they are diagnostic (i.e., predictive) of a scene category. Experiment 3 examined the structure of colored cues at different spatial scales that are responsible for the effects of color diagnosticity reported in Experiments 1 and 2. Together, the results suggest that colored blobs at a coarse spatial scale concur with luminance cues to form the relevant spatial layout that mediates express scene recognition."
            },
            "slug": "Diagnostic-Colors-Mediate-Scene-Recognition-Oliva-Schyns",
            "title": {
                "fragments": [],
                "text": "Diagnostic Colors Mediate Scene Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results suggest that colored blobs at a coarse spatial scale concur with luminance cues to form the relevant spatial layout that mediates express scene recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 192
                            }
                        ],
                        "text": "In particular, scene recognition experiments suggest that information about scene identity may be available before performing a more detailed analysis of the individual objects (Potter, 1975; Biederman, 1987; Schyns and Oliva, 1994; Oliva and Schyns, 1997; Rensink et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8054340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b37258659bcdbc380b1e6c4e22cce9ea06397a1",
            "isKey": false,
            "numCitedBy": 5632,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons (N \u00a3 36), can be derived from contrasts of five readily detectable properties of edges in a two-dimensiona l image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position an$ image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. Representational power derives from an allowance of free combinations of the geons. A Principle of Componential Recovery can account for the major phenomena of object recognition: If an arrangement of two or three geons can be recovered from the input, objects can be quickly recognized even when they are occluded, novel, rotated in depth, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory. Any single object can project an infinity of image configurations to the retina. The orientation of the object to the viewer can vary continuously, each giving rise to a different two-dimensional projection. The object can be occluded by other objects or texture fields, as when viewed behind foliage. The object need not be presented as a full-colored textured image but instead can be a simplified line drawing. Moreover, the object can even be missing some of its parts or be a novel exemplar of its particular category. But it is only with rare exceptions that an image fails to be rapidly and readily classified, either as an instance of a familiar object category or as an instance that cannot be so classified (itself a form of classification)."
            },
            "slug": "Recognition-by-components:-a-theory-of-human-image-Biederman",
            "title": {
                "fragments": [],
                "text": "Recognition-by-components: a theory of human image understanding."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recognition-by-components (RBC) provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 169
                            }
                        ],
                        "text": "Furthermore, the human visual system is able to analyze scenes even under degraded conditions that obscure the identities of individual objects (Schyns and Oliva, 1994; Oliva and Schyns, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 233
                            }
                        ],
                        "text": "In particular, scene recognition experiments suggest that information about scene identity may be available before performing a more detailed analysis of the individual objects (Potter, 1975; Biederman, 1987; Schyns and Oliva, 1994; Oliva and Schyns, 1997; Rensink et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "X k+1 i;n =< ~x ~a i;n A k+1 i;n T ~v T ~x ~a i;n A k+1 i;n T ~v >i (24)"
                    },
                    "intents": []
                }
            ],
            "corpusId": 2644477,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "48f0d6211dc70a56202c1a0c95124c65a51f721f",
            "isKey": false,
            "numCitedBy": 437,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient categorizations of complex visual stimuli require effective encodings of their distinctive properties. However, the question remains of how processes of object and scene categorization use the information associated with different perceptual spatial scales. The psychophysics of scale perception suggests that recognition uses coarse blobs before fine scale edges, because the former is perceptually available before the latter. Although possible, this perceptually determined scenario neglects the nature of the task the recognition system must solve. If different spatial scales transmit different information about the input, an identical scene might be flexibly encoded and perceived at the scale that optimizes information for the considered task-i.e., the diagnostic scale. This paper tests the hypothesis that scale diagnosticity can determine scale selection for recognition. Experiment 1 tested whether coarse and fine spatial scales were both available at the onset of scene categorization. The second experiment tested that the selection of one scale could change depending on the diagnostic information present at this scale. The third and fourth experiments investigated whether scale-specific cues were independently processed, or whether they perceptually cooperated in the recognition of the input scene. Results suggest that a mandatory low-level registration of multiple spatial scales promotes flexible scene encodings, perceptions, and categorizations."
            },
            "slug": "Coarse-Blobs-or-Fine-Edges-Evidence-That-Changes-of-Oliva-Schyns",
            "title": {
                "fragments": [],
                "text": "Coarse Blobs or Fine Edges? Evidence That Information Diagnosticity Changes the Perception of Complex Visual Stimuli"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper tests the hypothesis that scale diagnosticity can determine scale selection for recognition and suggests that a mandatory low-level registration of multiple spatial scales promotes flexible scene encodings, perceptions, and categorizations."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705903"
                        ],
                        "name": "S. Intille",
                        "slug": "S.-Intille",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Intille",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Intille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16501860,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13dc9145cd6de73a31bc051ad004367ec6dec2b9",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A new approach to tracking weakly modeled objects in a semantically rich domain is presented. We define a closed-world as a space-time region of an image sequence in which the complete taxonomy of objects is known, and in which each pixel should be explained as belonging to one of those objects. Given contextual object information, context-specific features can be dynamically selected as the basis for tracking. A context-specific feature is one that has been chosen based upon the context to maximize the chance of successful tracking between frames. Our work is motivated by the goal of video annotation-the semi-automatic generation of symbolic descriptions of action taking place in a contextually-rich dynamic scene. We describe how contextual knowledge in the \"football domain\" can be applied to closed-world football player tracking and present the details of our implementation. We include tracking results based on hundreds of images that demonstrate the wide range of tracking situations the algorithm successfully handles as well as a few examples of where the algorithm fails.<<ETX>>"
            },
            "slug": "Closed-world-tracking-Intille-Bobick",
            "title": {
                "fragments": [],
                "text": "Closed-world tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work describes how contextual knowledge in the \"football domain\" can be applied to closed-world football player tracking and presents the details of the implementation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31913541"
                        ],
                        "name": "W. Richards",
                        "slug": "W.-Richards",
                        "structuredName": {
                            "firstName": "Whitman",
                            "lastName": "Richards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Richards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061773"
                        ],
                        "name": "D. Knill",
                        "slug": "D.-Knill",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Knill",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Knill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 94
                            }
                        ],
                        "text": "(3) in that now all the probabilities are conditional with respect to contextual information (Jepson et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 35
                            }
                        ],
                        "text": "The image patches that do not satisfy the similarity criteria are discarded and modeled as noise with particular statistical properties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 37
                            }
                        ],
                        "text": "Only the pictures that contain people with a given scale are averaged."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 242
                            }
                        ],
                        "text": "\u2026factor, the PDF P(O | vC ), provides context-based priors on object class, location and scale and it is of capital importance for insuring reliable inferences in situations where the image measurements produce ambiguous interpretations (see Jepson et al., 1996, for a discussion on this topic)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 168
                            }
                        ],
                        "text": "From a computational point of view, context priming reduces the set of possible objects and therefore the number of features needed for discriminating between objects (Jepson et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18237419,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "4e1d816d66305f68d1e96260ccc4bbddc87497b3",
            "isKey": true,
            "numCitedBy": 37,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The world we live in is a very structured place Matter does not it about in space and time in a completely unorganized fashion but rather is organized by the physical forces biological processes social interactions and so on which exist in our world McMahon Thompson It is this structure or regularity which makes it possible for us to make reliable inferences about our surroundings from the signals taken in from various senses Marr Witkin and Tenenbaum In other words regularities in the world make sense data reliably informative about the world we move around in But what is the nature of these regularities and how can they be used for the purposes of perception"
            },
            "slug": "Model-structure-and-reliable-inference-Jepson-Richards",
            "title": {
                "fragments": [],
                "text": "Model structure and reliable inference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 16
                            }
                        ],
                        "text": "As suggested in Torralba and Oliva (1999), Oliva and Torralba (2001), and Torralba and Sinha (2001) the scene/context can be considered a single entity that can be recognized by means of a scene-centered representation bypassing the identification of the constituent objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16037331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85ff07142de17d55a240f9120686aa3cb529f70a",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a procedure for organizing real world scenes along semantic axes. The approach is based on the output energies of linear discriminant filters that take into account, or not, spatial information. We introduce three semantic axes along which pictures are ordered. The main semantic axis computes the degree of naturalness of a scene. Then, urban pictures are evaluated according to their degree of verticalness and natural scenes, according to their degree of openness. We observe the emergence of typical scene categories such as beach, mountain, skyscrapers, city center etc., along the axes."
            },
            "slug": "Semantic-organization-of-scenes-using-discriminant-Torralba-Oliva",
            "title": {
                "fragments": [],
                "text": "Semantic organization of scenes using discriminant structural templates"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper introduces three semantic axes along which pictures are ordered and observes the emergence of typical scene categories such as beach, mountain, skyscrapers, city center etc., along the axes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2866369"
                        ],
                        "name": "T. Strat",
                        "slug": "T.-Strat",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Strat",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 50
                            }
                        ],
                        "text": "Built on a similar philosophy, the CONDOR system (Strat and Fischler, 1991) uses contextual information for object recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15374748,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06c908a5dea82fdbffa8285beae1c3d60b028902",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Results from an ongoing project concerned with recognizing objects in complex scene domains, especially in the domain that includes the natural outdoor world, are described. Traditional machine recognition paradigms assume either that all objects of interest are definable by a relatively small number of explicit shape models or that all objects of interest have characteristic, locally measurable features. The failure of both assumptions has a dramatic impact on the form of an acceptable architecture for an object recognition system. In this work, the use of the contextual information is a central issue, and a system is explicitly designed to identify and use context as an integral part of recognition that eliminates the traditional dependence on stored geometric models and universal image partitioning algorithms. This paradigm combines the results of many simple procedures that analyze monochrome, color, stereo, or 3D range images. Interpreting the results along with relevant contextual knowledge makes it possible to achieve a reliable recognition result, even when using imperfect visual procedures. Initial experimentation with the system on ground-level outdoor imagery has demonstrated competence beyond what is attainable with other vision systems. >"
            },
            "slug": "Context-Based-Vision:-Recognizing-Objects-Using-2D-Strat-Fischler",
            "title": {
                "fragments": [],
                "text": "Context-Based Vision: Recognizing Objects Using Information from Both 2D and 3D Imagery"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "In this work, a system is explicitly designed to identify and use context as an integral part of recognition that eliminates the traditional dependence on stored geometric models and universal image partitioning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727853"
                        ],
                        "name": "John K. Tsotsos",
                        "slug": "John-K.-Tsotsos",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tsotsos",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John K. Tsotsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2888197"
                        ],
                        "name": "Sean M. Culhane",
                        "slug": "Sean-M.-Culhane",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Culhane",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean M. Culhane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676061"
                        ],
                        "name": "W. Y. Wai",
                        "slug": "W.-Y.-Wai",
                        "structuredName": {
                            "firstName": "Winky",
                            "lastName": "Wai",
                            "middleNames": [
                                "Yan",
                                "Kei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Y. Wai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399956386"
                        ],
                        "name": "Yuzhong Lai",
                        "slug": "Yuzhong-Lai",
                        "structuredName": {
                            "firstName": "Yuzhong",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuzhong Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070037776"
                        ],
                        "name": "Neal Davis",
                        "slug": "Neal-Davis",
                        "structuredName": {
                            "firstName": "Neal",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neal Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397804046"
                        ],
                        "name": "Fernando Nuflo",
                        "slug": "Fernando-Nuflo",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Nuflo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Nuflo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 160
                            }
                        ],
                        "text": "Some previous models of top-down attention guidance incorporate context information to direct attention (e.g., Noton and Stark, 1971; Chernyak and Stark, 2001; Tsotsos et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32094988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8930f62a4b5eb1cbabf224cf84aa009ea798cfee",
            "isKey": false,
            "numCitedBy": 1211,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modeling-Visual-Attention-via-Selective-Tuning-Tsotsos-Culhane",
            "title": {
                "fragments": [],
                "text": "Modeling Visual Attention via Selective Tuning"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123706"
                        ],
                        "name": "P. Lipson",
                        "slug": "P.-Lipson",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Lipson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lipson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "A k+1 i;n = V k+1 i;n 1 < (~v ~v i;n )~x T >i (22)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 70
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 206589454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8cf3f0ea76961eca50bf26ab31e677037cab622",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene classification is a major open challenge in machine vision. Most solutions proposed so far such as those based on color histograms and local texture statistics cannot capture a scene's global configuration, which is critical in perceptual judgments of scene similarity. We present a novel approach, \"configural recognition\", for encoding scene class structure. The approach's main feature is its use of qualitative spatial and photometric relationships within and across regions in low resolution images. The emphasis on qualitative measures leads to enhanced generalization abilities and the use of low-resolution images renders the scheme computationally efficient. We present results on a large database of natural scenes. We also describe how qualitative scene concepts may be learned from examples."
            },
            "slug": "Configuration-based-scene-classification-and-image-Lipson-Grimson",
            "title": {
                "fragments": [],
                "text": "Configuration based scene classification and image indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel approach, \"configural recognition\", for encoding scene class structure using qualitative spatial and photometric relationships within and across regions in low resolution images and how qualitative scene concepts may be learned from examples is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 14
                            }
                        ],
                        "text": "For instance, Lindeberg (1993) proposed a method for scale selection for the detection of low-level features such as edges, junctions, ridges and blobs when no a priori information about the nature of the picture is available."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 87
                            }
                        ],
                        "text": "Previous studies in automatic scale selection are based on bottom-up approaches (e.g., Lindeberg, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 152
                            }
                        ],
                        "text": "The most popular ones are based on low-level saliency maps (without any high-level information relative to the task or context, e.g. Itti et al., 1998; Lindeberg, 1993; Treisman and Gelade, 1980; Wolfe, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11998035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8385d733a5d41f79ec6cc34be147ec39f592de56",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents: (i) a multiscale representation of grey-level shape called the scale-space primal sketch, which makes explicit both features in scale-space and the relations between structures at different scales, (ii) a methodology for extracting significant blob-like image structures from this representation, and (iii) applications to edge detection, histogram analysis, and junction classification demonstrating how the proposed method can be used for guiding later-stage visual processes.The representation gives a qualitative description of image structure, which allows for detection of stable scales and associated regions of interest in a solely bottom-up data-driven way. In other words, it generates coarse segmentation cues, and can hence be seen as preceding further processing, which can then be properly tuned. It is argued that once such information is available, many other processing tasks can become much simpler. Experiments on real imagery demonstrate that the proposed theory gives intuitive results."
            },
            "slug": "Detecting-salient-blob-like-image-structures-and-a-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A multiscale representation of grey-level shape called the scale-space primal sketch is presented, which gives a qualitative description of image structure, which allows for detection of stable scales and associated regions of interest in a solely bottom-up data-driven way."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "P ( j on; ~vC) = PM i=1 biG( ; i;Si)G(~vC ;~vi;Vi) PM i=1 biG(~vC ;~vi;Vi) (28)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 182
                            }
                        ],
                        "text": "Objectcentered representations use exclusively object intrinsic features for performing object detection and recognition tasks (e.g. Burl et al., 1998; Moghaddam and Pentland, 1997; Papageorgiou and Poggio, 2000; Rao et al., 1996; Rowley et al., 1998; Schiele and Crowley, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13308232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c20ed0c3f375f403ab5d750a6e9699d5c3af6a",
            "isKey": false,
            "numCitedBy": 1404,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general, trainable system for object detection in unconstrained, cluttered scenes. The system derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform. This example-based learning approach implicitly derives a model of an object class by training a support vector machine classifier using a large set of positive and negative examples. We present results on face, people, and car detection tasks using the same architecture. In addition, we quantify how the representation affects detection performance by considering several alternate representations including pixels and principal components. We also describe a real-time application of our person detection system as part of a driver assistance system."
            },
            "slug": "A-Trainable-System-for-Object-Detection-Papageorgiou-Poggio",
            "title": {
                "fragments": [],
                "text": "A Trainable System for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A general, trainable system for object detection in unconstrained, cluttered scenes that derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2551159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd232cf2ab28cc0ba06942875f14206f04ebbae0",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 109,
            "paperAbstract": {
                "fragments": [],
                "text": "The appearance of an object is composed of local structure. This local structure can be described and characterized by a vector of local features measured by local operators such as Gaussian derivatives or Gabor filters. This article presents a technique where appearances of objects are represented by the joint statistics of such local neighborhood operators. As such, this represents a new class of appearance based techniques for computer vision. Based on joint statistics, the paper develops techniques for the identification of multiple objects at arbitrary positions and orientations in a cluttered scene. Experiments show that these techniques can identify over 100 objects in the presence of major occlusions. Most remarkably, the techniques have low complexity and therefore run in real-time."
            },
            "slug": "Recognition-without-Correspondence-using-Receptive-Schiele-Crowley",
            "title": {
                "fragments": [],
                "text": "Recognition without Correspondence using Multidimensional Receptive Field Histograms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article presents a technique where appearances of objects are represented by the joint statistics of such local neighborhood operators, which represents a new class of appearance based techniques for computer vision."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143615848"
                        ],
                        "name": "Rajesh P. N. Rao",
                        "slug": "Rajesh-P.-N.-Rao",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Rao",
                            "middleNames": [
                                "P.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajesh P. N. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696991"
                        ],
                        "name": "G. Zelinsky",
                        "slug": "G.-Zelinsky",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Zelinsky",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zelinsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2848854"
                        ],
                        "name": "M. Hayhoe",
                        "slug": "M.-Hayhoe",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hayhoe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hayhoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 114
                            }
                        ],
                        "text": "Other algorithms propose to include models of the target in order to account for task dependent constraints (e.g. Rao et al., 1996; Moghaddam and Pentland, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 80
                            }
                        ],
                        "text": "Computational studies too (Gorkani and Picard, 1994; Schiele and Crowley, 2000; Rao et al., 1996; Oliva and Torralba, 2001) have found this choice of features useful for several object and scene recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "(30) provides a con dence measurement for the scale priming and can be used for reducing the range of possible scales to explore for high con dence contexts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 213
                            }
                        ],
                        "text": "Objectcentered representations use exclusively object intrinsic features for performing object detection and recognition tasks (e.g. Burl et al., 1998; Moghaddam and Pentland, 1997; Papageorgiou and Poggio, 2000; Rao et al., 1996; Rowley et al., 1998; Schiele and Crowley, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1200246,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "e1e5cf2d7c7758de35db4d4d5901563feab21805",
            "isKey": true,
            "numCitedBy": 60,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual cognition depends critically on the ability to make rapid eye movements known as saccades that orient the fovea over targets of interest in a visual scene. Saccades are known to be ballistic: the pattern of muscle activation for foveating a prespecified target location is computed prior to the movement and visual feedback is precluded. Despite these distinctive properties, there has been no general model of the saccadic targeting strategy employed by the human visual system during visual search in natural scenes. This paper proposes a model for saccadic targeting that uses iconic scene representations derived from oriented spatial filters at multiple scales. Visual search proceeds in a coarse-to-fine fashion with the largest scale filter responses being compared first. The model was empirically tested by comparing its performance with actual eye movement data from human subjects in a natural visual search task; preliminary results indicate substantial agreement between eye movements predicted by the model and those recorded from human subjects."
            },
            "slug": "Modeling-Saccadic-Targeting-in-Visual-Search-Rao-Zelinsky",
            "title": {
                "fragments": [],
                "text": "Modeling Saccadic Targeting in Visual Search"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A model for saccadic targeting that uses iconic scene representations derived from oriented spatial filters at multiple scales is proposed and preliminary results indicate substantial agreement between eye movements predicted by the model and those recorded from human subjects."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32713089"
                        ],
                        "name": "Darnell J. Moore",
                        "slug": "Darnell-J.-Moore",
                        "structuredName": {
                            "firstName": "Darnell",
                            "lastName": "Moore",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Darnell J. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21472040"
                        ],
                        "name": "Irfan Essa",
                        "slug": "Irfan-Essa",
                        "structuredName": {
                            "firstName": "Irfan",
                            "lastName": "Essa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irfan Essa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144449603"
                        ],
                        "name": "M. Hayes",
                        "slug": "M.-Hayes",
                        "structuredName": {
                            "firstName": "Monson",
                            "lastName": "Hayes",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hayes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In Moore et al. (1999), a prior model of a particular fixed scene and the identification of human motion constitute the context used for the recognition of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15378359,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f090df944fceaf52cda458ed6116802cd36ca08e",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Our goal is to exploit human motion and object context to perform action recognition and object classification. Towards this end, we introduce a framework for recognizing actions and objects by measuring image-, object- and action-based information from video. Hidden Markov models are combined with object context to classify hand actions, which are aggregated by a Bayesian classifier to summarize activities. We also use Bayesian methods to differentiate the class of unknown objects by evaluating detected actions along with low-level, extracted object features. Our approach is appropriate for locating and classifying objects under a variety of conditions including full occlusion. We show experiments where both familiar and previously unseen objects are recognized using action and context information."
            },
            "slug": "Exploiting-human-actions-and-object-context-for-Moore-Essa",
            "title": {
                "fragments": [],
                "text": "Exploiting human actions and object context for recognition tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This work introduces a framework for recognizing actions and objects by measuring image-, object- and action-based information from video, which is appropriate for locating and classifying objects under a variety of conditions including full occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, object recognition, focus of attention, automatic scale selection, object priming"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 133
                            }
                        ],
                        "text": "Objectcentered representations use exclusively object intrinsic features for performing object detection and recognition tasks (e.g. Burl et al., 1998; Moghaddam and Pentland, 1997; Papageorgiou and Poggio, 2000; Rao et al., 1996; Rowley et al., 1998; Schiele and Crowley, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11023003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "102cf35af78c14019edfe28c8cd624da7d5b3fac",
            "isKey": false,
            "numCitedBy": 334,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Many object classes, including human faces, can be modeled as a set of characteristic parts arranged in a variable spatial configuration. We introduce a simplified model of a deformable object class and derive the optimal detector for this model. However, the optimal detector is not realizable except under special circumstances (independent part positions). A cousin of the optimal detector is developed which uses \u201csoft\u201d part detectors with a probabilistic description of the spatial arrangement of the parts. Spatial arrangements are modeled probabilistically using shape statistics to achieve invariance to translation, rotation, and scaling. Improved recognition performance over methods based on \u201chard\u201d part detectors is demonstrated for the problem of face detection in cluttered scenes."
            },
            "slug": "A-Probabilistic-Approach-to-Object-Recognition-and-Burl-Weber",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Approach to Object Recognition Using Local Photometry and Global Geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simplified model of a deformable object class is introduced and the optimal detector for this model is derived, which is not realizable except under special circumstances (independent part positions)."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766240"
                        ],
                        "name": "Claudio S. Pinhanez",
                        "slug": "Claudio-S.-Pinhanez",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Pinhanez",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claudio S. Pinhanez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 3
                            }
                        ],
                        "text": "In Bobick and Pinhanez (1995) context is used to validate and select vision routines."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16807559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "093c7404280d84c30997d8bd07a2e30035760343",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Most computer vision algorithms are based on strong assumptions about the objects and the actions depicted in the image. To safely apply those algorithms in real world image sequences, it is necessary to verify that their assumptions are satissed in the context of the visual process. We propose the use of approximate world models { coarse descriptions of objects and actions in the world | as the appropriate representation for contextual information. The approximate world models are employed to verify the applicability of a vision routine in a given situation. Under these conditions, a task module can reliably use the outputs of the contextually-safe vision routines, without having to refer to an accurate reconstruction of the world. We are using approximate world models in a project to control cameras in a TV studio. In our Intelligent Studio automatic cameras respond to verbal requests for shots from the TV director. Contextual information is obtained from the script of the TV show and from the imagery provided by wide-angle, low-resolution cameras monitoring the studio. Some examples of the cameras' responses to diierent requests are shown in the domain of a cooking show."
            },
            "slug": "Using-approximate-models-as-source-of-contextual-Bobick-Pinhanez",
            "title": {
                "fragments": [],
                "text": "Using approximate models as source of contextual information for vision processing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes the use of approximate world models { coarse descriptions of objects and actions in the world | as the appropriate representation for contextual information in a project to control cameras in a TV studio."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 94
                            }
                        ],
                        "text": "The use of such regularities in the statistics finds applications in models of neural coding (Field, 1987), lightness and reflectance perception (Weiss, 2001; Dror, 2001), and camera distortion removal (Farid, 2001) among many other applications."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1600874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aeb37769d72999bcbfb0582b73607fd8d23f4545",
            "isKey": false,
            "numCitedBy": 3273,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "The relative efficiency of any particular image-coding scheme should be defined only in relation to the class of images that the code is likely to encounter. To understand the representation of images by the mammalian visual system, it might therefore be useful to consider the statistics of images from the natural environment (i.e., images with trees, rocks, bushes, etc). In this study, various coding schemes are compared in relation to how they represent the information in such natural images. The coefficients of such codes are represented by arrays of mechanisms that respond to local regions of space, spatial frequency, and orientation (Gabor-like transforms). For many classes of image, such codes will not be an efficient means of representing information. However, the results obtained with six natural images suggest that the orientation and the spatial-frequency tuning of mammalian simple cells are well suited for coding the information in such images if the goal of the code is to convert higher-order redundancy (e.g., correlation between the intensities of neighboring pixels) into first-order redundancy (i.e., the response distribution of the coefficients). Such coding produces a relatively high signal-to-noise ratio and permits information to be transmitted with only a subset of the total number of cells. These results support Barlow's theory that the goal of natural vision is to represent the information in the natural environment with minimal redundancy."
            },
            "slug": "Relations-between-the-statistics-of-natural-images-Field",
            "title": {
                "fragments": [],
                "text": "Relations between the statistics of natural images and the response properties of cortical cells."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results obtained with six natural images suggest that the orientation and the spatial-frequency tuning of mammalian simple cells are well suited for coding the information in such images if the goal of the code is to convert higher-order redundancy into first- order redundancy."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 132
                            }
                        ],
                        "text": "Other algorithms propose to include models of the target in order to account for task dependent constraints (e.g. Rao et al., 1996; Moghaddam and Pentland, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 65
                            }
                        ],
                        "text": "The EM algorithm is an iterative procedure composed of two steps (e.g. Dempster et al., 1977; Jordan and Jacobs, 1994; Moghaddam and Pentland, 1997; Gershnfeld, 1999):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 119
                            }
                        ],
                        "text": "The EM algorithm is an iterative procedure composed of two steps (e.g. Dempster et al., 1977; Jordan and Jacobs, 1994; Moghaddam and Pentland, 1997; Gershnfeld, 1999):\n\u2022 E-step: Computes the posterior probabilities of the clusters hi (t) given the observed data vt ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 100
                            }
                        ],
                        "text": "Therefore, the PDF that is actually used by statistical approaches for object recognition is (e.g., Moghaddam and Pentland, 1997; Schiele and Crowley, 2000):\nP(O | v) P(O | vL ) = P(vL | O) P(vL ) P(O) (3)\nThis function is the object-centered object likelihood. vL = vB(x, ) is a set of local image\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 152
                            }
                        ],
                        "text": "Objectcentered representations use exclusively object intrinsic features for performing object detection and recognition tasks (e.g. Burl et al., 1998; Moghaddam and Pentland, 1997; Papageorgiou and Poggio, 2000; Rao et al., 1996; Rowley et al., 1998; Schiele and Crowley, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": true,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 83
                            }
                        ],
                        "text": "The organization is correlated with the size of the space that the scene subtends (Torralba and Oliva, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 143
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 17
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be relevant for discrimination between different scenes are:"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 7138552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acf0b6745708457a53d5327eea345c0bcf466e97",
            "isKey": false,
            "numCitedBy": 333,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "In the absence of cues for absolute depth measurements as binocular disparity, motion, or defocus, the absolute distance between the observer and a scene cannot be measured. The interpretation of shading, edges, and junctions may provide a 3D model of the scene but it will not provide information about the actual \"scale\" of the space. One possible source of information for absolute depth estimation is the image size of known objects. However, object recognition, under unconstrained conditions, remains difficult and unreliable for current computational approaches. We propose a source of information for absolute depth estimation based on the whole scene structure that does not rely on specific objects. We demonstrate that, by recognizing the properties of the structures present in the image, we can infer the scale of the scene and, therefore, its absolute mean depth. We illustrate the interest in computing the mean depth of the scene with application to scene recognition and object detection."
            },
            "slug": "Depth-Estimation-from-Image-Structure-Torralba-Oliva",
            "title": {
                "fragments": [],
                "text": "Depth Estimation from Image Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is demonstrated that, by recognizing the properties of the structures present in the image, one can infer the scale of the scene and, therefore, its absolute mean depth."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944906"
                        ],
                        "name": "M. Potter",
                        "slug": "M.-Potter",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Potter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Potter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 178
                            }
                        ],
                        "text": "In particular, scene recognition experiments suggest that information about scene identity may be available before performing a more detailed analysis of the individual objects (Potter, 1975; Biederman, 1987; Schyns and Oliva, 1994; Oliva and Schyns, 1997; Rensink et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, object recognition, focus of attention, automatic scale selection, object priming"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35385513,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "29c5af8f630bb688ad627e6f750ba5c10fc8b86c",
            "isKey": false,
            "numCitedBy": 584,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Viewers briefly glimpsed pictures presented in a sequence at rates up to eight per second. They recognized a target picture as accurately and almost as rapidly when they knew only its meaning given by a name (for example, a boat) as when they had seen the picture itself in advance."
            },
            "slug": "Meaning-in-visual-search.-Potter",
            "title": {
                "fragments": [],
                "text": "Meaning in visual search."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Viewers briefly glimpsed pictures presented in a sequence at rates up to eight per second and recognized a target picture as accurately and almost as rapidly when they knew only its meaning given by a name."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722325"
                        ],
                        "name": "J. Bonet",
                        "slug": "J.-Bonet",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Bonet",
                            "middleNames": [
                                "S.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bonet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "\u2026Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be relevant for discrimination between\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "P (On j~v) = P (On; ~v) P (~v) = P (~vL jOn; ~vC) P (~vL j~vC) P (On j~vC) (6)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "The di erence in the complexities of local and contextual features justi es the choice of the form of equation (6) in which contextual features are used to simplify the distribution of the local features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11876914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0565714cadd26a4e46f55b7f47c9e4394163df1b",
            "isKey": true,
            "numCitedBy": 64,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A new algorithm is presented which approximates the perceived visual similarity between images. The images are initially transformed into a feature space which captures visual structure, texture and color using a tree of filters. Similarity is the inverse of the distance in this perceptual feature space. Using this algorithm we have constructed an image database system which can perform example based retrieval on large image databases. Using carefully constructed target sets, which limit variation to only a single visual characteristic, retrieval rates are quantitatively compared to those of standard methods."
            },
            "slug": "Structure-Driven-Image-Database-Retrieval-Bonet-Viola",
            "title": {
                "fragments": [],
                "text": "Structure Driven Image Database Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An image database system which can perform example based retrieval on large image databases is constructed, using carefully constructed target sets, which limit variation to only a single visual characteristic."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087139"
                        ],
                        "name": "M. Gorkani",
                        "slug": "M.-Gorkani",
                        "structuredName": {
                            "firstName": "Monika",
                            "lastName": "Gorkani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gorkani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 27
                            }
                        ],
                        "text": "Computational studies too (Gorkani and Picard, 1994; Schiele and Crowley, 2000; Rao et al., 1996; Oliva and Torralba, 2001) have found this choice of features useful for several object and scene recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 23
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 18920889,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c21738e116aeabca1e523f612610605718ae00ff",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Investigates a measure of \"dominant perceived orientation\" that has been developed to match the output of a human study involving 40 subjects. The results of this measure are compared with humans analyzing seven \"teaser\" images to test its effectiveness for finding perceptually dominant orientations. The use of low-level orientation is then applied to a \"quick search\" problem important in image database applications. Since both pigeons and humans are able to perform coarse classification of certain kinds of scenes, e.g., city from country, without taking time or brain-power to solve the image understanding problem, the authors conjecture that the collective behavior of low-level textural features such as orientation may be doing most of the work. The authors demonstrate a simple test of global multiscale orientation for quickly searching a database of vacation photos for likely \"city/suburb\" shots. The orientation features achieve agreement with human classification in 91 out of 98 of the scenes."
            },
            "slug": "Texture-orientation-for-sorting-photos-\"at-a-Gorkani-Picard",
            "title": {
                "fragments": [],
                "text": "Texture orientation for sorting photos \"at a glance\""
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The authors demonstrate a simple test of global multiscale orientation for quickly searching a database of vacation photos for likely \"city/suburb\" shots and find the orientation features achieve agreement with human classification in 91 out of 98 of the scenes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120499"
                        ],
                        "name": "N. Campbell",
                        "slug": "N.-Campbell",
                        "structuredName": {
                            "firstName": "Neill",
                            "lastName": "Campbell",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Campbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2779611"
                        ],
                        "name": "William P. J. Mackeown",
                        "slug": "William-P.-J.-Mackeown",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Mackeown",
                            "middleNames": [
                                "P.",
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William P. J. Mackeown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3306363"
                        ],
                        "name": "B. Thomas",
                        "slug": "B.-Thomas",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Thomas",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4997851"
                        ],
                        "name": "T. Troscianko",
                        "slug": "T.-Troscianko",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Troscianko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Troscianko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 3
                            }
                        ],
                        "text": "In Campbell et al. (1997), they define the contextual features of an image region as the probabilities assigned to each of the possible labels of the surrounding regions in the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 113
                            }
                        ],
                        "text": "Under such high quality viewing conditions, the object recognition mechanisms could rely exclusively on intrinsic object features ignoring the background."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11218901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "588f849b4577700398ed728aa46c4d9b2217e233",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Interpreting-image-databases-by-region-Campbell-Mackeown",
            "title": {
                "fragments": [],
                "text": "Interpreting image databases by region classification"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2969789"
                        ],
                        "name": "C. Carson",
                        "slug": "C.-Carson",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Carson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Carson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Gorkani and Picard, 1994;  Carson et al., 1997;  Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be relevant for discrimination between different scenes are:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 49
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 7047950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "913beb8d70383bacaf7f0133d9a88ca592542af7",
            "isKey": false,
            "numCitedBy": 323,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. In this paper, we present a new image representation which provides a transformation from the raw pixel data to a small set of localized coherent regions in color and texture space. This so-called &ldquo;blobworld&rdquo; representation is based on segmentation using the expectation-maximization algorithm on combined color and texture features. The texture features we use for the segmentation arise from a new approach to texture description and scale selection. We describe a system that uses the blobworld representation to retrieve images. An important and unique aspect of the system is that, in the context of similarity-based querying, the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, the outcome of many queries on these systems can be quite inexplicable, despite the availability of knobs for adjusting the similarity metric"
            },
            "slug": "Region-based-image-querying-Carson-Belongie",
            "title": {
                "fragments": [],
                "text": "Region-based image querying"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new image representation is presented which provides a transformation from the raw pixel data to a small set of localized coherent regions in color and texture space based on segmentation using the expectation-maximization algorithm on combined color andtexture features."
            },
            "venue": {
                "fragments": [],
                "text": "1997 Proceedings IEEE Workshop on Content-Based Access of Image and Video Libraries"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12568146"
                        ],
                        "name": "D. Noton",
                        "slug": "D.-Noton",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Noton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Noton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144145223"
                        ],
                        "name": "L. Stark",
                        "slug": "L.-Stark",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Stark",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Stark"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 96
                            }
                        ],
                        "text": "In a similar vein, some models of visual search and attention include the use of context (e.g., Noton and Stark, 1971; Chernyak and Stark, 2001) to guide eye movements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 111
                            }
                        ],
                        "text": "Some previous models of top-down attention guidance incorporate context information to direct attention (e.g., Noton and Stark, 1971; Chernyak and Stark, 2001; Tsotsos et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": "By adjusting the threshold th we change the size of the search region from 100% of the image size, th = 0, to a small image region, th 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20018885,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "dbbabc2af3deb36ed7790cc473cef133c3876554",
            "isKey": false,
            "numCitedBy": 618,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Subjects learned and recognized patterns which were marginally visible, requiring them to fixate directly each feature to which they wished to attend. Fixed \"scanpaths,\" specific to subject and pattern, appeared in their saccadic eye movements, both intermittently during learning and in initial eye movements during recognition. A proposed theory of pattern perception explains these results."
            },
            "slug": "Scanpaths-in-Eye-Movements-during-Pattern-Noton-Stark",
            "title": {
                "fragments": [],
                "text": "Scanpaths in Eye Movements during Pattern Perception"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Subjects learned and recognized patterns which were marginally visible, requiring them to fixate directly each feature to which they wished to attend, and fixed \"scanpaths,\" specific to subject and pattern appeared in their saccadic eye movements."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 982857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a62d0cca2fabf1d6f6ee15e4c14cef415b657d1",
            "isKey": false,
            "numCitedBy": 2592,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented for the representation of (pictures of) faces. Within a specified framework the representation is ideal. This results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector. The method is illustrated in detail by the use of an ensemble of pictures taken for this purpose."
            },
            "slug": "Low-dimensional-procedure-for-the-characterization-Sirovich-Kirby",
            "title": {
                "fragments": [],
                "text": "Low-dimensional procedure for the characterization of human faces."
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A method is presented for the representation of faces that results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 22
                            }
                        ],
                        "text": "Experimental studies (Hubel and Wiesel, 1968) have provided evidence for the use of oriented band-pass filters (such as Gabors) in the early stages of the visual pathway."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "A k+1 i;n = PNt t=1 h k i;n(t) ~(~vt ~a k+1 i;n )(~vt ~a k+1 i;n ) T PNt t=1 h k i;n(t) (15)"
                    },
                    "intents": []
                }
            ],
            "corpusId": 7136759,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c5f5311fa1f34159ab3a0a1d58da51cd0340a640",
            "isKey": false,
            "numCitedBy": 6319,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light. Most cells can be categorized as simple, complex, or hypercomplex, with response properties very similar to those previously described in the cat. On the average, however, receptive fields are smaller, and there is a greater sensitivity to changes in stimulus orientation. A small proportion of the cells are colour coded."
            },
            "slug": "Receptive-fields-and-functional-architecture-of-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Receptive fields and functional architecture of monkey striate cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light, with response properties very similar to those previously described in the cat."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 146
                            }
                        ],
                        "text": "The use of such regularities in the statistics finds applications in models of neural coding (Field, 1987), lightness and reflectance perception (Weiss, 2001; Dror, 2001), and camera distortion removal (Farid, 2001) among many other applications."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2164492,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bd7d18aee6f43baeda78eea356d2a6497c07c8f7",
            "isKey": false,
            "numCitedBy": 658,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Intrinsic images are a useful midlevel description of scenes proposed by H.G. Barrow and J.M. Tenenbaum (1978). An image is de-composed into two images: a reflectance image and an illumination image. Finding such a decomposition remains a difficult problem in computer vision. We focus on a slightly, easier problem: given a sequence of T images where the reflectance is constant and the illumination changes, can we recover T illumination images and a single reflectance image? We show that this problem is still imposed and suggest approaching it as a maximum-likelihood estimation problem. Following recent work on the statistics of natural images, we use a prior that assumes that illumination images will give rise to sparse filter outputs. We show that this leads to a simple, novel algorithm for recovering reflectance images. We illustrate the algorithm's performance on real and synthetic image sequences."
            },
            "slug": "Deriving-intrinsic-images-from-image-sequences-Weiss",
            "title": {
                "fragments": [],
                "text": "Deriving intrinsic images from image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Following recent work on the statistics of natural images, a prior is used that assumes that illumination images will give rise to sparse filter outputs and this leads to a simple, novel algorithm for recovering reflectance images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38502616"
                        ],
                        "name": "Daniel D. Fu",
                        "slug": "Daniel-D.-Fu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Fu",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel D. Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2263239"
                        ],
                        "name": "K. Hammond",
                        "slug": "K.-Hammond",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Hammond",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hammond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 3
                            }
                        ],
                        "text": "In Fu et al. (1994) context consists of prior knowledge about regularities of a reduced world in which the\nsystem has to operate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15116687,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "b3acf94be93aa9934534bb60d333f8798c717a45",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "People are often able to act eeciently in places like grocery stores, libraries, and other man-made domains even if they haven't been to those particular places before: They are exercising useful knowledge about how these environments are organized in order to facilitate their tasks. In this paper we show that everyday environments exhibit useful regularities an autonomous agent can use in order to accomplish tasks eeciently. In particular, we identify useful regularities of grocery stores, and show how they're used in the design of an agent. We discuss how our planning system, Shopper , uses these regularities to nd items in Grocery-World, a simulated grocery store. Suppose I stop to buy Kellogg's Raisin Bran at an unfamiliar grocery store on the way home. How should my task proceed? A slow, but sure way is to systematically walk through the store slowly moving down aisles while looking at anything, careful not to miss the Raisin Bran. However, I can use information of how grocery stores are organized to speed up my search, for example I know: Most stores provide signs outlining an aisle's contents. Signs are placed at the ends of aisles. Cereals are clustered together. Raisin Bran is a cereal. In coming up with a method for nding Raisin Bran, we can use this knowledge as a basis for a strategy: Move across aisles and stop at a \\cereals\" sign. Enter the aisle under the sign. Find any kind of cereal. Look for Raisin Bran among the cereals. This strategy is eeective for many items in a grocery store. It works because it relies on speciic features of the environment. These features are ensured to exist so as to make shopping easier for people. Thus this strategy should be easily extensible to all medium-sized grocery stores (in the United States). Shopper For a robot operating in an existing man-made domain , knowledge of organization and strategies can prove useful for accomplishing tasks like this. With the Shopper project, we are examining the types of functional knowledge needed for an agent to work in a man-made domain as well as the sensing and control mechanisms needed to use this knowledge. In this paper , we describe the Shopper system: an integrated system incorporating planning and vision techniques for the task of grocery store shopping. Grocery store shopping is a common task everyone does at least occasionally. Since everybody is able to \u2026"
            },
            "slug": "Vision-and-navigation-in-man-made-environments:-for-Fu-Hammond",
            "title": {
                "fragments": [],
                "text": "Vision and navigation in man-made environments: looking for syrup in all the right places"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Shopper system is described: an integrated system incorporating planning and vision techniques for the task of grocery store shopping, examining the types of functional knowledge needed for an agent to work in a man-made domain as well as the sensing and control mechanisms needed to use this knowledge."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 147
                            }
                        ],
                        "text": "\u2026Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be relevant for\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15065442,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "c411f93539714f512e437c45a7a9d0a6d5a7675e",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-image-classification:-city-images-vs.-landscapes-Vailaya-Jain",
            "title": {
                "fragments": [],
                "text": "On image classification: city images vs. landscapes"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 231
                            }
                        ],
                        "text": "Objectcentered representations use exclusively object intrinsic features for performing object detection and recognition tasks (e.g. Burl et al., 1998; Moghaddam and Pentland, 1997; Papageorgiou and Poggio, 2000; Rao et al., 1996; Rowley et al., 1998; Schiele and Crowley, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Burl et al., 1998; Moghaddam and Pentland, 1997; Papageorgiou and Poggio, 2000; Rao et al., 1996;  Rowley et al., 1998;  Schiele and Crowley, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2561280"
                        ],
                        "name": "R. Dror",
                        "slug": "R.-Dror",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Dror",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dror"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "(8), provides some robustness with respect to objects arrangements that are compatible with the same scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6708128,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1e22f1b63015eac460e4a10fd80ad5d76d25c0e6",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans recognize optical reflectance properties of surfaces such as metal, plastic, or paper from a single image without knowledge of illumination. We develop a machine vision system to perform similar recognition tasks automatically. Reflectance estimation under unknown, arbitrary illumination proves highly underconstrained due to the variety of potential illumination distributions and surface reflectance properties. We have found that the spatial structure of real-world illumination possesses some of the statistical regularities observed in the natural image statistics literature. A human or computer vision system may be able to exploit this prior information to determine the most likely surface reflectance given an observed image. We develop an algorithm for reflectance classification under unknown real-world illumination, which learns relationships between surface reflectance and certain features (statistics) computed from a single observed image. We also develop an automatic feature selection method."
            },
            "slug": "Surface-Reflectance-Estimation-and-Natural-Dror-Adelson",
            "title": {
                "fragments": [],
                "text": "Surface Reflectance Estimation and Natural Illumination Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An algorithm for reflectance classification under unknown real-world illumination is developed, which learns relationships between surface reflectance and certain features (statistics) computed from a single observed image, and an automatic feature selection method is developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 166
                            }
                        ],
                        "text": "M-step: Computes the most likely cluster parameters by maximization of the join likelihood of the training data: b i;n = PNt t=1 h k i;n(t) PL i=1 PNt t=1 h k i;n(t) (13)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 135
                            }
                        ],
                        "text": "Other approaches use a statistical approach in order to learn the joint distribution of N objects O1, . . . , ON within a scene (e.g., Haralick, 1983; Song et al., 2000) given a set of local measurements v1, . . . , vN corresponding to image regions:\nP(O1, . . . , ON , v1, . . . , vN )\n[\nN\u220f i\nP(vi\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3332651,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8566d8dcf52f59dd157803283971f0145f832614",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "From a Bayesian decision theoretic framework, we show that the reason why the usual statistical approaches do not take context into account is because of the assumptions made on the joint prior probability function and because of the simplistic loss function chosen. We illustrate how the constraints sometimes employed by artificial intelligence researchers constitute a different kind of assumption on the joint prior probability function. We discuss a couple of loss functions which do take context into account and when combined with the joint prior probability constraint create a decision problem requiring a combinatorial state space search. We also give a theory for how probabilistic relaxation works from a Bayesian point of view."
            },
            "slug": "Decision-Making-in-Context-Haralick",
            "title": {
                "fragments": [],
                "text": "Decision Making in Context"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "From a Bayesian decision theoretic framework, it is shown that the reason why the usual statistical approaches do not take context into account is because of the assumptions made on the joint prior probability function andBecause of the simplistic loss function chosen."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17585310"
                        ],
                        "name": "M. I. Jordan",
                        "slug": "M.-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144215175"
                        ],
                        "name": "R. Jacobs",
                        "slug": "R.-Jacobs",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 65
                            }
                        ],
                        "text": "The EM algorithm is an iterative procedure composed of two steps (e.g. Dempster et al., 1977; Jordan and Jacobs, 1994; Moghaddam and Pentland, 1997; Gershnfeld, 1999):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "The EM algorithm is an iterative procedure composed of two steps (e.g. Dempster et al., 1977; Jordan and Jacobs, 1994; Moghaddam and Pentland, 1997; Gershnfeld, 1999):\n\u2022 E-step: Computes the posterior probabilities of the clusters hi (t) given the observed data vt ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 67000854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6d8a7fc2e2d53923832f9404376512068ca2a57",
            "isKey": false,
            "numCitedBy": 2136,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a tree-structured architecture for supervised learning. The statistical model underlying the architecture is a hierarchical mixture model in which both the mixture coefficients and the mixture components are generalized linear models (GLIM's). Learning is treated as a maximum likelihood problem; in particular, we present an Expectation-Maximization (EM) algorithm for adjusting the parameters of the architecture. We also develop an on-line learning algorithm in which the parameters are updated incrementally. Comparative simulation results are presented in the robot dynamics domain."
            },
            "slug": "Hierarchical-Mixtures-of-Experts-and-the-EM-Jordan-Jacobs",
            "title": {
                "fragments": [],
                "text": "Hierarchical mixtures of experts and the EM algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "An Expectation-Maximization (EM) algorithm for adjusting the parameters of the tree-structured architecture for supervised learning and an on-line learning algorithm in which the parameters are updated incrementally."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3210944"
                        ],
                        "name": "Xubo B. Song",
                        "slug": "Xubo-B.-Song",
                        "structuredName": {
                            "firstName": "Xubo",
                            "lastName": "Song",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xubo B. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2524190"
                        ],
                        "name": "J. Sill",
                        "slug": "J.-Sill",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Sill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46704575"
                        ],
                        "name": "H. Kasdan",
                        "slug": "H.-Kasdan",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Kasdan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kasdan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18671151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96dab60fce923c70a9d3309dc032d4306f54c102",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new and efficient technique for incorporating contextual information into object classification. Most of the current techniques face the problem of exponential computation cost. In this paper, we propose a new general framework that incorporates partial context at a linear cost. This technique is applied to microscopic urinalysis image recognition, resulting in a significant improvement of recognition rate over the context free approach. This gain would have been impossible using conventional context incorporation techniques."
            },
            "slug": "Image-Recognition-in-Context:-Application-to-Song-Sill",
            "title": {
                "fragments": [],
                "text": "Image Recognition in Context: Application to Microscopic Urinalysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new general framework that incorporates partial context at a linear cost is proposed that is applied to microscopic urinalysis image recognition, resulting in a significant improvement of recognition rate over the context free approach."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778989"
                        ],
                        "name": "M. Szummer",
                        "slug": "M.-Szummer",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Szummer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szummer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 117
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 14254507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f45a46dedadf599c12874b22645d596205ed8d5",
            "isKey": false,
            "numCitedBy": 774,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how high-level scene properties can be inferred from classification of low-level image features, specifically for the indoor-outdoor scene retrieval problem. We systematically studied the features of: histograms in the Ohta color space; multiresolution, simultaneous autoregressive model parameters; and coefficients of a shift-invariant DCT. We demonstrate that performance is improved by computing features on subblocks, classifying these subblocks, and then combining these results in a way reminiscent of stacking. State of the art single-feature methods are shown to result in about 75-86% performance, while the new method results in 90.3% correct classification, when evaluated on a diverse database of over 1300 consumer images provided by Kodak."
            },
            "slug": "Indoor-outdoor-image-classification-Szummer-Picard",
            "title": {
                "fragments": [],
                "text": "Indoor-outdoor image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work systematically studied the features of: histograms in the Ohta color space; multiresolution, simultaneous autoregressive model parameters; and coefficients of a shift-invariant DCT to show how high-level scene properties can be inferred from classification of low-level image features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1998 IEEE International Workshop on Content-Based Access of Image and Video Database"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122942"
                        ],
                        "name": "B. Ripley",
                        "slug": "B.-Ripley",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ripley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ripley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10536649,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c26bbfda107188d5c1bcbcbc93d93dd1c133116",
            "isKey": false,
            "numCitedBy": 2848,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nPattern recognition has long been studied in relation to many different (and mainly unrelated) applications, such as remote sensing, computer vision, space research, and medical imaging. In this book Professor Ripley brings together two crucial ideas in pattern recognition; statistical methods and machine learning via neural networks. Unifying principles are brought to the fore, and the author gives an overview of the state of the subject. Many examples are included to illustrate real problems in pattern recognition and how to overcome them.This is a self-contained account, ideal both as an introduction for non-specialists readers, and also as a handbook for the more expert reader."
            },
            "slug": "Pattern-Recognition-and-Neural-Networks-Ripley",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Professor Ripley brings together two crucial ideas in pattern recognition; statistical methods and machine learning via neural networks in this self-contained account."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4153758"
                        ],
                        "name": "H. Farid",
                        "slug": "H.-Farid",
                        "structuredName": {
                            "firstName": "Hany",
                            "lastName": "Farid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Farid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 203
                            }
                        ],
                        "text": "The use of such regularities in the statistics finds applications in models of neural coding (Field, 1987), lightness and reflectance perception (Weiss, 2001; Dror, 2001), and camera distortion removal (Farid, 2001) among many other applications."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1771654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6152d79bebb6ae7d671c8e7846a53901a6e4134f",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The luminance nonlinearity introduced by many imaging devices can often be described by a simple point-wise operation (gamma correction). This paper presents a technique for blindly estimating the amount of gamma correction in the absence of any calibration information or knowledge of the imaging device. The basic approach exploits the fact that gamma correction introduces specific higher-order correlations in the frequency domain. These correlations can be detected using tools from polyspectral analysis. The amount of gamma correction is then estimated by minimizing these correlations."
            },
            "slug": "Blind-inverse-gamma-correction-Farid",
            "title": {
                "fragments": [],
                "text": "Blind inverse gamma correction"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper presents a technique for blindly estimating the amount of gamma correction in the absence of any calibration information or knowledge of the imaging device by exploiting the fact that gamma correction introduces specific higher-order correlations in the frequency domain."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688083"
                        ],
                        "name": "N. Gershenfeld",
                        "slug": "N.-Gershenfeld",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Gershenfeld",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gershenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122800093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41d6913177e0078d914da200f0eca65c10f35c22",
            "isKey": false,
            "numCitedBy": 494,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Introduction Part I. Analytical Models: 2. Ordinary differential and difference equations 3. Partial differential equations 4. Variational principles 5. Random systems Part II. Numerical Models: 6. Finite differences: ordinary difference equations 7. Finite differences: partial differential equations 8. Finite elements 9. Cellular automata and lattice gases Part III. Observational Models: 10. Function fitting 11. Transforms 12. Architectures 13. Optimization and search 14. Clustering and density estimation 15. Filtering and state estimation 16. Linear and nonlinear time series Appendix 1. Graphical and mathematical software Appendix 2. Network programming Appendix 3. Benchmarking Appendix 4. Problem solutions Bibliography."
            },
            "slug": "The-nature-of-mathematical-modeling-Gershenfeld",
            "title": {
                "fragments": [],
                "text": "The nature of mathematical modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The purpose of this monograph is to discuss models for optimization and search, as well as some of the principles used in computer programming, which have been used in the design of search engines and mobile devices."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Dempster et al., 1977;  Jordan and Jacobs, 1994; Moghaddam and Pentland, 1997; Gershnfeld, 1999):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "The EM algorithm is an iterative procedure composed of two steps (e.g. Dempster et al., 1977; Jordan and Jacobs, 1994; Moghaddam and Pentland, 1997; Gershnfeld, 1999):\n\u2022 E-step: Computes the posterior probabilities of the clusters hi (t) given the observed data vt ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48399,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39853279"
                        ],
                        "name": "W. R. Howard",
                        "slug": "W.-R.-Howard",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Howard",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. R. Howard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 52
                            }
                        ],
                        "text": "For modeling the PDF we use a mixture of gaussians (Gershnfeld, 1999):\nP(x, vC | o) = M\u2211\ni=1 bi G(x; xi , Xi ) G(vC ; vi , Vi ) (17)\nThe join PDF is modeled as a sum of gaussian clusters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 29
                            }
                        ],
                        "text": "The EM algorithm is now (see Gershnfeld, 1999 for a description of the learning equations):\n\u2022 E-step: Computes the posterior probabilities of the clusters hi (t) given the observed data vt and xt ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 51
                            }
                        ],
                        "text": "For modeling the PDF we use a mixture of gaussians (Gershnfeld, 1999):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 65
                            }
                        ],
                        "text": "The EM algorithm is an iterative procedure composed of two steps (e.g. Dempster et al., 1977; Jordan and Jacobs, 1994; Moghaddam and Pentland, 1997; Gershnfeld, 1999):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 149
                            }
                        ],
                        "text": "The EM algorithm is an iterative procedure composed of two steps (e.g. Dempster et al., 1977; Jordan and Jacobs, 1994; Moghaddam and Pentland, 1997; Gershnfeld, 1999):\n\u2022 E-step: Computes the posterior probabilities of the clusters hi (t) given the observed data vt ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58450342,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "a1daaebda73c8bb3a0b6673745aef4a479a37aaf",
            "isKey": true,
            "numCitedBy": 203,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Nature-of-Mathematical-Modeling-Howard",
            "title": {
                "fragments": [],
                "text": "The Nature of Mathematical Modeling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "We apply the Bayes rule successively in order to split the PDF P (On j~vC) in three factors that model three kinds of context priming: P (On j~vC) = P ( j ~x; on; ~vC)P (~x j on; ~vC)P (on j~vC) (7)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "(7) and to showing the ability of the holistic context features to predict object properties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "(7), P (on j~vC), gives the probability of presence of the object class on given contextual information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 193
                            }
                        ],
                        "text": "When considering real world-scenes, it is very likely that visual search strategies and the computation of saliency maps are modulated by global high-level information related to the scene (De Graef et al., 1990; Henderson and Holligworth, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perceptual e ects of scene context on object identi cation"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological research,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 93
                            }
                        ],
                        "text": "Therefore, the PDF that is actually used by statistical approaches for object recognition is (e.g., Moghaddam and Pentland, 1997; Schiele and Crowley, 2000):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 130
                            }
                        ],
                        "text": "Therefore, the PDF that is actually used by statistical approaches for object recognition is (e.g., Moghaddam and Pentland, 1997; Schiele and Crowley, 2000):\nP(O | v) P(O | vL ) = P(vL | O) P(vL ) P(O) (3)\nThis function is the object-centered object likelihood. vL = vB(x, ) is a set of local image\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 53
                            }
                        ],
                        "text": "Computational studies too (Gorkani and Picard, 1994; Schiele and Crowley, 2000; Rao et al., 1996; Oliva and Torralba, 2001) have found this choice of features useful for several object and scene recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 252
                            }
                        ],
                        "text": "Objectcentered representations use exclusively object intrinsic features for performing object detection and recognition tasks (e.g. Burl et al., 1998; Moghaddam and Pentland, 1997; Papageorgiou and Poggio, 2000; Rao et al., 1996; Rowley et al., 1998; Schiele and Crowley, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition without correspon"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Intelligence,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 165
                            }
                        ],
                        "text": "In essence, {an}n=1,D is a holistic representation as all the regions of the image contribute to all the coefficients, and objects are not encoded individually (see Oliva and Torralba, 2001, for a detailed description\nof the holistic representation)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 17
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be relevant for discrimination between different scenes are:"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 117
                            }
                        ],
                        "text": "As we will show here, a holistic scene analysis allows representing the context in a very low dimensional space (see Oliva and Torralba, 2001 for a detailed description)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 117
                            }
                        ],
                        "text": "Low-level features statistics differ when considering real world images corresponding to different scene categories (Oliva and Torralba, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 91
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 43
                            }
                        ],
                        "text": "As suggested in Torralba and Oliva (1999), Oliva and Torralba (2001), and Torralba and Sinha (2001) the scene/context can be considered a single entity that can be recognized by means of a scene-centered representation bypassing the identification of the constituent objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 16
                            }
                        ],
                        "text": "As discussed in Oliva and Torralba (2001), the second order statistics of natural images (encoded in the Fourier spectra) are correlated with simple scene attributes (e.g. depth) and, therefore, strongly differ between distinct environmental categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 16
                            }
                        ],
                        "text": "As suggested in Oliva and Torralba (2001) it is possible to build a representation of the scene that bypasses object identities, in which the scene is represented as a single entity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 98
                            }
                        ],
                        "text": "Computational studies too (Gorkani and Picard, 1994; Schiele and Crowley, 2000; Rao et al., 1996; Oliva and Torralba, 2001) have found this choice of features useful for several object and scene recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 90
                            }
                        ],
                        "text": "An alternative view of context relies on using the entire scene information holistically\n(Oliva and Torralba, 2001; Torralba and Sinha, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextual Priming for Object Detection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, object recognition, focus of attention, automatic scale selection, object priming"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 231
                            }
                        ],
                        "text": "Objectcentered representations use exclusively object intrinsic features for performing object detection and recognition tasks (e.g. Burl et al., 1998; Moghaddam and Pentland, 1997; Papageorgiou and Poggio, 2000; Rao et al., 1996; Rowley et al., 1998; Schiele and Crowley, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural networkbased face detetcion"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 192
                            }
                        ],
                        "text": "In particular, scene recognition experiments suggest that information about scene identity may be available before performing a more detailed analysis of the individual objects (Potter, 1975; Biederman, 1987; Schyns and Oliva, 1994; Oliva and Schyns, 1997; Rensink et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition-by-components: A theory of human image interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological Review,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 49
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 17
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be relevant for discrimination between different scenes are:"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Regionbased image querying"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. IEEE W. on Content-Based Access of Image and Video Libraries,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Depth perception from familiar structure"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 97
                            }
                        ],
                        "text": "Coarse color distributions have also been shown to be relevant for scene perception by subjects (Oliva and Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Diagnostic color blobs mediate scene recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Low-dimensional procedure for"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological Science,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "VISIONS: A computer system for interpreting scenes"
            },
            "venue": {
                "fragments": [],
                "text": "In Computer Vision Systems,"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "Experiments in scene perception and visual search (Palmer, 1975; Biederman et al., 1982;"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The e ects of contextual scenes on the identi cation of objects"
            },
            "venue": {
                "fragments": [],
                "text": "Memory and Cognition"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 166
                            }
                        ],
                        "text": "M-step: Computes the most likely cluster parameters by maximization of the join likelihood of the training data: b i;n = PNt t=1 h k i;n(t) PL i=1 PNt t=1 h k i;n(t) (19)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shifts in visual attention: Towards the underlying circuitry"
            },
            "venue": {
                "fragments": [],
                "text": "Human Neurobiology,"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "The EM algorithm is an iterative procedure composed of two steps (e.g. Dempster et al., 1977; Jordan and Jacobs, 1994; Moghaddam and Pentland, 1997; Gershnfeld, 1999):\n\u2022 E-step: Computes the posterior probabilities of the clusters hi (t) given the observed data vt ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximumlikelihood from incomplete data via the EM algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "J. Royal Statist. Soc. Ser. B.,"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 145
                            }
                        ],
                        "text": "Furthermore, the human visual system is able to analyze scenes even under degraded conditions that obscure the identities of individual objects (Schyns and Oliva, 1994; Oliva and Schyns, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 209
                            }
                        ],
                        "text": "In particular, scene recognition experiments suggest that information about scene identity may be available before performing a more detailed analysis of the individual objects (Potter, 1975; Biederman, 1987; Schyns and Oliva, 1994; Oliva and Schyns, 1997; Rensink et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From blobs to boundary edges"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 242
                            }
                        ],
                        "text": "\u2026factor, the PDF P(O | vC ), provides context-based priors on object class, location and scale and it is of capital importance for insuring reliable inferences in situations where the image measurements produce ambiguous interpretations (see Jepson et al., 1996, for a discussion on this topic)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 94
                            }
                        ],
                        "text": "(3) in that now all the probabilities are conditional with respect to contextual information (Jepson et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 168
                            }
                        ],
                        "text": "From a computational point of view, context priming reduces the set of possible objects and therefore the number of features needed for discriminating between objects (Jepson et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modal structures and reliable inference. In Perception as Bayesian Inference, D"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be relevant for discrimination between different scenes are:\n\u2022 The\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 17
                            }
                        ],
                        "text": "Previous studies (e.g. Gorkani and Picard, 1994; Carson et al., 1997; Lipson et al., 1997; Oliva and Torralba, 2001; Szummer and Picard, 1998; Torralba and Oliva, 2002; Vailaya et al., 1998; De Bonet and Viola, 1997; Clarkson and Pentland, 2000) have shown that some of the features that seem to be relevant for discrimination between different scenes are:"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Framing through peripheral vision"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. IEEE International Conference on Image Processing,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "Experiments in scene perception and visual search (Palmer, 1975; Biederman et al., 1982;"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The e ects of contextual scenes on the identi cation of objects. Memory and Cognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 16
                            }
                        ],
                        "text": "As suggested in Torralba and Oliva (1999), Oliva and Torralba (2001), and Torralba and Sinha (2001) the scene/context can be considered a single entity that can be recognized by means of a scene-centered representation bypassing the identification of the constituent objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scene organization using discriminant structural templates"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Proc. of Int. Conf. in Comp"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network - based face detetcion"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 231
                            }
                        ],
                        "text": "Objectcentered representations use exclusively object intrinsic features for performing object detection and recognition tasks (e.g. Burl et al., 1998; Moghaddam and Pentland, 1997; Papageorgiou and Poggio, 2000; Rao et al., 1996; Rowley et al., 1998; Schiele and Crowley, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network - based face detetcion"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 47,
            "methodology": 24,
            "result": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 75,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Contextual-Priming-for-Object-Detection-Torralba/c99f2391b956dc189855541e49e53c21ae5ec603?sort=total-citations"
}