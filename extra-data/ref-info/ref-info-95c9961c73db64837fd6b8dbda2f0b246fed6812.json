{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46286291"
                        ],
                        "name": "Yingchen Yang",
                        "slug": "Yingchen-Yang",
                        "structuredName": {
                            "firstName": "Yingchen",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yingchen Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40150531"
                        ],
                        "name": "W. Luk",
                        "slug": "W.-Luk",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Luk",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Luk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10390140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d41a54ad8820082004bda2a5f7202b08e5642640",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Web table mining is about information extraction from tables published inside web pages as HTML texts. Most previous work on this subject makes use of the tags to discover components of the table. Our work treats web as a distinct publication media, in two ways. We argue that new types of table format have been developed specially for the web. We also argue that the visual cues embedded within the HTML text, are utilized by the authors to direct the viewer on how to read the contents contained a web table properly. We develop a framework for comprehensively analyzing the structural aspects of a web table, within which rules are devised to process and extract attribute-value pairs from the table. This approach to web table mining is validated by good experimental results."
            },
            "slug": "A-framework-for-web-table-mining-Yang-Luk",
            "title": {
                "fragments": [],
                "text": "A framework for web table mining"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work develops a framework for comprehensively analyzing the structural aspects of a web table, within which rules are devised to process and extract attribute-value pairs from the table."
            },
            "venue": {
                "fragments": [],
                "text": "WIDM '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2990683"
                        ],
                        "name": "Ashwin Tengli",
                        "slug": "Ashwin-Tengli",
                        "structuredName": {
                            "firstName": "Ashwin",
                            "lastName": "Tengli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashwin Tengli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2027866"
                        ],
                        "name": "Nianli Ma",
                        "slug": "Nianli-Ma",
                        "structuredName": {
                            "firstName": "Nianli",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nianli Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[29] present an algorithm that extracts tables and differentiates between label and data cells."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9595306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ab39aa2e9ef711b6e35026b3270401dc1f6cc24",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction from tables in web pages is a challenging problem due to the diverse nature of table formats and the vocabulary variants in attribute names. This paper presents a new approach to automated table extraction that exploits formatting cues in semi-structured HTML tables, learns lexical variants from training examples and uses a vector space model to deal with non-exact matches among labels. We conducted experiments with this method on a set of tables collected from 157 university web sites, and obtained the information extraction performance of 91.4% in the Fl-measure, showing the effectiveness of the combined use of structural table parsing and example-based label learning."
            },
            "slug": "Learning-Table-Extraction-from-Examples-Tengli-Yang",
            "title": {
                "fragments": [],
                "text": "Learning Table Extraction from Examples"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new approach to automated table extraction that exploits formatting cues in semi-structured HTML tables, learns lexical variants from training examples and uses a vector space model to deal with non-exact matches among labels is presented."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782658"
                        ],
                        "name": "Kristina Lerman",
                        "slug": "Kristina-Lerman",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Lerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Lerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746034"
                        ],
                        "name": "L. Getoor",
                        "slug": "L.-Getoor",
                        "structuredName": {
                            "firstName": "Lise",
                            "lastName": "Getoor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Getoor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26602711"
                        ],
                        "name": "Steven N. Minton",
                        "slug": "Steven-N.-Minton",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Minton",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven N. Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[22] mention that just a fraction of tables are actually created with <table> tags."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6642452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb52373f7266e19efa28043812c9dae96ecd26d1",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Many Web sites, especially those that dynamically generate HTML pages to display the results of a user's query, present information in the form of list or tables. Current tools that allow applications to programmatically extract this information rely heavily on user input, often in the form of labeled extracted records. The sheer size and rate of growth of the Web make any solution that relies primarily on user input is infeasible in the long term. Fortunately, many Web sites contain much explicit and implicit structure, both in layout and content, that we can exploit for the purpose of information extraction. This paper describes an approach to automatic extraction and segmentation of records from Web tables. Automatic methods do not require any user input, but rely solely on the layout and content of the Web source. Our approach relies on the common structure of many Web sites, which present information as a list or a table, with a link in each entry leading to a detail page containing additional information about that item. We describe two algorithms that use redundancies in the content of table and detail pages to aid in information extraction. The first algorithm encodes additional information provided by detail pages as constraints and finds the segmentation by solving a constraint satisfaction problem. The second algorithm uses probabilistic inference to find the record segmentation. We show how each approach can exploit the web site structure in a general, domain-independent manner, and we demonstrate the effectiveness of each algorithm on a set of twelve Web sites."
            },
            "slug": "Using-the-structure-of-Web-sites-for-automatic-of-Lerman-Getoor",
            "title": {
                "fragments": [],
                "text": "Using the structure of Web sites for automatic segmentation of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper describes an approach to automatic extraction and segmentation of records from Web tables, which relies on the common structure of many Web sites, and describes two algorithms that use redundancies in the content of table and detail pages to aid in information extraction."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000882"
                        ],
                        "name": "Wolfgang Gatterbauer",
                        "slug": "Wolfgang-Gatterbauer",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Gatterbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Gatterbauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308385"
                        ],
                        "name": "Paul Bohunsky",
                        "slug": "Paul-Bohunsky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Bohunsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Bohunsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [15], we describe a method that works on both word and element node bounding boxes, and that is able to locate concepts of a predefined seed knowledge in web tables."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "The data structure Xe is a minimum double topological grid [15] superimposed on all VENs and, as such, defined by Xe = {\u3008x1, y1, x2, y2\u3009 |x1\u2208X1, y1\u2208Y1, x2\u2208X2, y2\u2208Y2, x1<x2, y1<y2} with X1 = {x | (\u2203e\u2208Ve |x1 =x)} and analogous Y1, X2 and Y2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "It builds upon the expansion algorithm Expand(direction, frame) from our previous work (Algorithm 1 from [15]) but works without any prior semantic word knowledge by expanding from all VENs except Table 1: Twelve most important extraction rules and heuristics of VENTex."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6474907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c506ce95dcdd45831eb4785c638b4767e1e995e",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables on web pages contain a huge amount of semantically explicit information, which makes them a worthwhile target for automatic information extraction and knowledge acquisition from the Web. However, the task of table extraction from web pages is difficult, because of HTML's design purpose to convey visual instead of semantic information. In this paper, we propose a robust technique for table extraction from arbitrary web pages. This technique relies upon the positional information of visualized DOM element nodes in a browser and, hereby, separates the intricacies of code implementation from the actual intended visual appearance. The novel aspect of the proposed web table extraction technique is the effective use of spatial reasoning on the CSS2 visual box model, which shows a high level of robustness even without any form of learning (F-measure \u2248 90%). We describe the ideas behind our approach, the tabular pattern recognition algorithm operating on a double topographical grid structure and allowing for effective and robust extraction, and general observations on web tables that should be borne in mind by any automatic web table extraction mechanism."
            },
            "slug": "Table-Extraction-Using-Spatial-Reasoning-on-the-Box-Gatterbauer-Bohunsky",
            "title": {
                "fragments": [],
                "text": "Table Extraction Using Spatial Reasoning on the CSS2 Visual Box Model"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a robust technique for table extraction from arbitrary web pages that relies upon the positional information of visualized DOM element nodes in a browser and separates the intricacies of code implementation from the actual intended visual appearance."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738409"
                        ],
                        "name": "Bernhard Kr\u00fcpl",
                        "slug": "Bernhard-Kr\u00fcpl",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Kr\u00fcpl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard Kr\u00fcpl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153481005"
                        ],
                        "name": "M. Herzog",
                        "slug": "M.-Herzog",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Herzog",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Herzog"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000882"
                        ],
                        "name": "Wolfgang Gatterbauer",
                        "slug": "Wolfgang-Gatterbauer",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Gatterbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Gatterbauer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "We add the idea of treating individual words as rendered on the screen as separate entities [21] and call them visualized words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "In contrast, in our previous work [21] we describe a top-down web table location mechanism working exclusively on visual information obtained from the Mozilla web browser."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6574692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38c3a2248eee100437388e4d9f881c5396208d8c",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method to extract tabular data from web pages. Rather than just analyzing the DOM tree, we also exploit visual cues in the rendered version of the document to extract data from tables which are not explicitly marked with an HTML table element. To detect tables, we rely on a variant of the well-known X-Y cut algorithm as used in the OCR community. We implemented the system by directly accessing Mozilla's box model that contains the positional data for all HTML elements of a given web page."
            },
            "slug": "Using-visual-cues-for-extraction-of-tabular-data-Kr\u00fcpl-Herzog",
            "title": {
                "fragments": [],
                "text": "Using visual cues for extraction of tabular data from arbitrary HTML documents"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A method to extract tabular data from web pages by exploiting visual cues in the rendered version of the document to extract data from tables which are not explicitly marked with an HTML table element is described."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50452701"
                        ],
                        "name": "M. Broadhead",
                        "slug": "M.-Broadhead",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Broadhead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Broadhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 171
                            }
                        ],
                        "text": "As a domain-independent and automatic information extraction system should ideally make a single pass over its corpus guaranteeing scalability with the size of the corpus [4], such a content-specific and irrevocable decision is, in our opinion, better left to a later probabilistic information integration step."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 183
                            }
                        ],
                        "text": "One principal idea is that an extraction system makes a single data-driven pass over its entire corpus and extracts a large set of relational tuples without requiring any human input [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207169186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "498bb0efad6ec15dd09d941fb309aa18d6df9f5f",
            "isKey": false,
            "numCitedBy": 2290,
            "numCiting": 148,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, Information Extraction (IE) has focused on satisfying precise, narrow, pre-specified requests from small homogeneous corpora (e.g., extract the location and time of seminars from a set of announcements). Shifting to a new domain requires the user to name the target relations and to manually create new extraction rules or hand-tag new training examples. This manual labor scales linearly with the number of target relations. This paper introduces Open IE (OIE), a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiring any human input. The paper also introduces TEXTRUNNER, a fully implemented, highly scalable OIE system where the tuples are assigned a probability and indexed to support efficient extraction and exploration via user queries. We report on experiments over a 9,000,000 Web page corpus that compare TEXTRUNNER with KNOWITALL, a state-of-the-art Web IE system. TEXTRUNNER achieves an error reduction of 33% on a comparable set of extractions. Furthermore, in the amount of time it takes KNOWITALL to perform extraction for a handful of pre-specified relations, TEXTRUNNER extracts a far broader set of facts reflecting orders of magnitude more relations, discovered on the fly. We report statistics on TEXTRUNNER\u2019s 11,000,000 highest probability tuples, and show that they contain over 1,000,000 concrete facts and over 6,500,000more abstract assertions."
            },
            "slug": "Open-Information-Extraction-from-the-Web-Banko-Cafarella",
            "title": {
                "fragments": [],
                "text": "Open Information Extraction from the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Open IE (OIE), a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiring any human input, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724421"
                        ],
                        "name": "Deng Cai",
                        "slug": "Deng-Cai",
                        "structuredName": {
                            "firstName": "Deng",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deng Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1911562"
                        ],
                        "name": "Shipeng Yu",
                        "slug": "Shipeng-Yu",
                        "structuredName": {
                            "firstName": "Shipeng",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shipeng Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259699"
                        ],
                        "name": "Ji-Rong Wen",
                        "slug": "Ji-Rong-Wen",
                        "structuredName": {
                            "firstName": "Ji-Rong",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji-Rong Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] describe a web page segmentation process that uses visual information from Internet Explorer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13007604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84372852886ddcb49e9adf9c5facf53e1bde9696",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A new web content structure based on visual representation is proposed in this paper. Many web applications such as information retrieval, information extraction and automatic page adaptation can benefit from this structure. This paper presents an automatic top-down, tag-tree independent approach to detect web content structure. It simulates how a user understands web layout structure based on his visual perception. Comparing to other existing techniques, our approach is independent to underlying documentation representation such as HTML and works well even when the HTML structure is far different from layout structure. Experiments show satisfactory results."
            },
            "slug": "Extracting-Content-Structure-for-Web-Pages-Based-on-Cai-Yu",
            "title": {
                "fragments": [],
                "text": "Extracting Content Structure for Web Pages Based on Visual Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents an automatic top-down, tag-tree independent approach to detect web content structure that simulates how a user understands web layout structure based on his visual perception."
            },
            "venue": {
                "fragments": [],
                "text": "APWeb"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145329865"
                        ],
                        "name": "Minoru Yoshida",
                        "slug": "Minoru-Yoshida",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Yoshida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minoru Yoshida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768754"
                        ],
                        "name": "Kentaro Torisawa",
                        "slug": "Kentaro-Torisawa",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Torisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kentaro Torisawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737901"
                        ],
                        "name": "Junichi Tsujii",
                        "slug": "Junichi-Tsujii",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Tsujii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junichi Tsujii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 179
                            }
                        ],
                        "text": "We currently solve the issue of assigning a given table the according n-tupel relations by having first defined a number of most commonly found table types on the Web (similar to [38]) and then a number of discriminating heuristics which make heavy use of the style information contained in the attribute vector of the extended VENs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[38] base their work on a general knowledge ontology and employ an expectation maximization algorithm to distinguish between attribute and value cells."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15867784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2985934cf5161c1fb6cecc8728dbd155cb6d278a",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web (WWW) allows a person to access a great amount of data provided by a wide variety of entities. However, the content varies widely in expression. This makes it difficult to browse many pages effectively, even if the contents of the pages are quite similar. This study is the first step toward the reduction of such variety of WWW contents. The method proposed in this paper enables us to easily obtain information about similar objects scattered over the WWW. We focus on the tables contained in the WWW pages and propose a method to integrate them according to the category of objects presented in each table. The table integrated in a uniform format enables us to easily compare the objects of different locations and styles of expressions."
            },
            "slug": "A-method-to-integrate-tables-of-the-World-Wide-Web-Yoshida-Torisawa",
            "title": {
                "fragments": [],
                "text": "A method to integrate tables of the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This study focuses on the tables contained in the WWW pages and proposes a method to integrate them according to the category of objects presented in each table, which enables us to easily compare the objects of different locations and styles of expressions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40343421"
                        ],
                        "name": "Yanhong Zhai",
                        "slug": "Yanhong-Zhai",
                        "structuredName": {
                            "firstName": "Yanhong",
                            "lastName": "Zhai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanhong Zhai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145321667"
                        ],
                        "name": "B. Liu",
                        "slug": "B.-Liu",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12750207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f49e35b6a85b8d81d2c9d9e26e8bf19dd94fad3a",
            "isKey": false,
            "numCitedBy": 600,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies the problem of extracting data from a Web page that contains several structured data records. The objective is to segment these data records, extract data items/fields from them and put the data in a database table. This problem has been studied by several researchers. However, existing methods still have some serious limitations. The first class of methods is based on machine learning, which requires human labeling of many examples from each Web site that one is interested in extracting data from. The process is time consuming due to the large number of sites and pages on the Web. The second class of algorithms is based on automatic pattern discovery. These methods are either inaccurate or make many assumptions. This paper proposes a new method to perform the task automatically. It consists of two steps, (1) identifying individual data records in a page, and (2) aligning and extracting data items from the identified data records. For step 1, we propose a method based on visual information to segment data records, which is more accurate than existing methods. For step 2, we propose a novel partial alignment technique based on tree matching. Partial alignment means that we align only those data fields in a pair of data records that can be aligned (or matched) with certainty, and make no commitment on the rest of the data fields. This approach enables very accurate alignment of multiple data records. Experimental results using a large number of Web pages from diverse domains show that the proposed two-step technique is able to segment data records, align and extract data from them very accurately."
            },
            "slug": "Web-data-extraction-based-on-partial-tree-alignment-Zhai-Liu",
            "title": {
                "fragments": [],
                "text": "Web data extraction based on partial tree alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Experimental results using a large number of Web pages from diverse domains show that the proposed two-step technique is able to segment data records, align and extract data from them very accurately."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34361707"
                        ],
                        "name": "Kai Simon",
                        "slug": "Kai-Simon",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Simon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Simon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809410"
                        ],
                        "name": "G. Lausen",
                        "slug": "G.-Lausen",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Lausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 21
                            }
                        ],
                        "text": "[28] K. Simon \nand G. Lausen."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Simon and Lausen [28] describe different approaches for detecting repetitive patterns on web pages, which are predominantly source-code based and enhanced with visual cues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 40
                            }
                        ],
                        "text": "Zhao et al. [41], Zhai and Liu [40] and Simon and Lausen [28] describe di.erent approaches \nfor de\u00adtecting repetitive patterns on web pages, which are predom\u00adinantly source-code based and enhanced \nwith visual cues."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7329393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eca8d0c78af7917cd774bbe1b56e62d61bd74cc0",
            "isKey": true,
            "numCitedBy": 252,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of unsupervised Web data extraction. We show that unsupervised Web data extraction becomes feasible when supposing pages that are made up of repetitive patterns, as it is the case, e.g., for search engine result pages. Hereby the extraction rules are generated automatically without any training or human interaction, by means of operating on the DOM tree respectively the flat tag token sequence of a single page.Our contribution to automatic data extraction through this paper is twofold. First, we identify and rank potential repetitive patterns with respect to the user's visual perception of the Web page, well aware that location and size of matching elements within a Web page constitute important criteria for defining relevance. Second, matching sub-sequences of the pattern with the highest weightiness are aligned with global multiple sequence alignment techniques. Experimental results show that our system is able to achieve high accuracy in distilling and aligning regularly structured objects inside complex Web pages."
            },
            "slug": "ViPER:-augmenting-automatic-information-extraction-Simon-Lausen",
            "title": {
                "fragments": [],
                "text": "ViPER: augmenting automatic information extraction with visual perceptions"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The unsupervised Web data extraction becomes feasible when supposing pages that are made up of repetitive patterns, as it is the case, e.g., for search engine result pages, by means of operating on the DOM tree respectively the flat tag token sequence of a single page."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145612610"
                        ],
                        "name": "Doug Downey",
                        "slug": "Doug-Downey",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Downey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doug Downey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3296031"
                        ],
                        "name": "Tal Shaked",
                        "slug": "Tal-Shaked",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Shaked",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tal Shaked"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321874"
                        ],
                        "name": "A. Yates",
                        "slug": "A.-Yates",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yates"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7156466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "400cf0a4a689f65681a4c618471387ea61598283",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Our KNOWITALL system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an autonomous, domain-independent, and scalable manner. In its first major run, KNOWITALL extracted over 50,000 facts with high precision, but suggested a challenge: How can we improve KNOWITALL's recall and extraction rate without sacrificing precision? \n \nThis paper presents three distinct ways to address this challenge and evaluates their performance. Rule Learning learns domain-specific extraction rules. Subclass Extraction automatically identifies sub-classes in order to boost recall. List Extraction locates lists of class instances, learns a \"wrapper\" for each list, and extracts elements of each list. Since each method bootstraps from KNOWITALL's domain-independent methods, no hand-labeled training examples are required. Experiments show the relative coverage of each method and demonstrate their synergy. In concert, our methods gave KNOWITALL a 4-fold to 19-fold increase in recall, while maintaining high precision, and discovered 10,300 cities missing from the Tipster Gazetteer."
            },
            "slug": "Methods-for-Domain-Independent-Information-from-the-Etzioni-Cafarella",
            "title": {
                "fragments": [],
                "text": "Methods for Domain-Independent Information Extraction from the Web: An Experimental Comparison"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Three distinct ways to improve KNOWITALL's recall and extraction rate without sacrificing precision are presented and evaluated and their performance is evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2825868"
                        ],
                        "name": "M. Cosulschi",
                        "slug": "M.-Cosulschi",
                        "structuredName": {
                            "firstName": "Mirel",
                            "lastName": "Cosulschi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cosulschi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145208011"
                        ],
                        "name": "N. Constantinescu",
                        "slug": "N.-Constantinescu",
                        "structuredName": {
                            "firstName": "Nicolae",
                            "lastName": "Constantinescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Constantinescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2185102"
                        ],
                        "name": "M. Gabroveanu",
                        "slug": "M.-Gabroveanu",
                        "structuredName": {
                            "firstName": "Mihai",
                            "lastName": "Gabroveanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gabroveanu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] describe an approach that uses positional information of DOM tree elements to calculate block correspondence between web pages."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58000821,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13f6d867d5e04161af395be5cf59b56a45157c50",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is closely related to the web structure analysis based on visual representation direction, a new and promising one, from which many web application such as information retrieval, information extraction can take advantage of. Page segmentation can be used to improve the query process in information retrieval, to simplify the work of automatic wrappers and to eliminate irrelevant data such as navigational bar and advertisement. Simple DOM based segmentation did not show satisfactory results, but the combination of DOM features with visual characteristics lead to a better partitioning. 2000 Mathematics Subject Classi cation. 68P20,68U99."
            },
            "slug": "Classifcation-and-comparison-of-information-from-a-Cosulschi-Constantinescu",
            "title": {
                "fragments": [],
                "text": "Classifcation and comparison of information structures from a web page"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Page segmentation can be used to improve the query process in information retrieval, to simplify the work of automatic wrappers and to eliminate irrelevant data such as navigational bar and advertisement."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36806626"
                        ],
                        "name": "B. Pollak",
                        "slug": "B.-Pollak",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Pollak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pollak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000882"
                        ],
                        "name": "Wolfgang Gatterbauer",
                        "slug": "Wolfgang-Gatterbauer",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Gatterbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Gatterbauer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "One such obstacle is that it is not easy to create a permanent copy of available web pages as we explain in detail in [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6193974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0adeeea67b00686b456468fb0addba434e9f8d5e",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In the research area of automatic web information extraction, there is a need for permanent and annotated web page collections enabling objective performance evaluation of different algorithms. Currently, researchers are suffering from the absence of such representative and contemporary test collections, especially on web tables. At the same time, creating your own sharable web page collections is not trivial nowadays because of the dynamic and diverse nature of modern web technologies employed to create often shortlived online content. In this paper, we cover the problem of creating static representations of web pages in order to build sharable ground truth test sets. We explain the principal difficulties of the problem, discuss possible approaches and introduce our solution: WebPageDump, a Firefox extension capable of saving web pages exactly as they are rendered online. Finally, we benchmark our system with current alternatives using an innovative automatic method based on image snapshots."
            },
            "slug": "Creating-Permanent-Test-Collections-of-Web-Pages-Pollak-Gatterbauer",
            "title": {
                "fragments": [],
                "text": "Creating Permanent Test Collections of Web Pages for Information Extraction Research"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The problem of creating static representations of web pages in order to build sharable ground truth test sets is covered and the solution: WebPageDump, a Firefox extension capable of saving web pages exactly as they are rendered online is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "SOFSEM"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7476856"
                        ],
                        "name": "M. Kovacevic",
                        "slug": "M.-Kovacevic",
                        "structuredName": {
                            "firstName": "Milos",
                            "lastName": "Kovacevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kovacevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767359"
                        ],
                        "name": "Michelangelo Diligenti",
                        "slug": "Michelangelo-Diligenti",
                        "structuredName": {
                            "firstName": "Michelangelo",
                            "lastName": "Diligenti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michelangelo Diligenti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700423"
                        ],
                        "name": "V. Milutinovic",
                        "slug": "V.-Milutinovic",
                        "structuredName": {
                            "firstName": "Veljko",
                            "lastName": "Milutinovic",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Milutinovic"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 273998,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0fe1c8dd553964e0292f9a463108a36fcc7a79e",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Extracting and processing information from Web pages is an important task in many areas like constructing search engines, information retrieval, and data mining from the Web. A common approach in the extraction process is to represent a page as a \"bag of words\" and then to perform additional processing on such a flat representation. We propose a new, hierarchical representation that includes browser screen coordinates for every HTML object in a page. Using visual information one is able to define heuristics for the recognition of common page areas such as header, left and right menu, footer and center of a page. We show in initial experiments that using our heuristics defined objects are recognized properly in 73% of cases. Finally, we show that a Naive Bayes classifier, taking into account the proposed representation, clearly outperforms the same classifier using only information about the content of documents."
            },
            "slug": "Recognition-of-common-areas-in-a-Web-page-using-a-a-Kovacevic-Diligenti",
            "title": {
                "fragments": [],
                "text": "Recognition of common areas in a Web page using visual information: a possible application in a page classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new, hierarchical representation that includes browser screen coordinates for every HTML object in a page is proposed that shows that a Naive Bayes classifier clearly outperforms the same classifier using only information about the content of documents."
            },
            "venue": {
                "fragments": [],
                "text": "2002 IEEE International Conference on Data Mining, 2002. Proceedings."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47019405"
                        ],
                        "name": "Xiaodong Gu",
                        "slug": "Xiaodong-Gu",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108284694"
                        ],
                        "name": "Jinlin Chen",
                        "slug": "Jinlin-Chen",
                        "structuredName": {
                            "firstName": "Jinlin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinlin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737338"
                        ],
                        "name": "Guoliang Chen",
                        "slug": "Guoliang-Chen",
                        "structuredName": {
                            "firstName": "Guoliang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guoliang Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] describe a top-down approach to segment a web page and detect its content structure by dividing and merging blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15010651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b946360e383fb2dbcc0028856231bb7840e641d7",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Web content structure is proposed to facilitate automatic web page adaptation in this paper. By identifying the logic relationship of web content based on layout information, web content structure effectively represents authors' presentation intention. An automatic top-down, tag-tree independent approach to detect web content structure is presented. It simulates how a user understands web layout structure based on his vision. Comparing to other content analysis techniques, our approach is independent to physical realization and works well even when the physical structure is far different from layout structure. Besides, our approach is an O(n)-time process which is much more efficient comparing to other approaches with O(n2)-time complexity. Furthermore, our approach is tag tree independent, which means it can be applied to web contents of arbitrary physical realization formats. Experiments show satisfactory results."
            },
            "slug": "Visual-Based-Content-Understanding-towards-Web-Gu-Chen",
            "title": {
                "fragments": [],
                "text": "Visual Based Content Understanding towards Web Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An automatic top-down, tag-tree independent approach to detect web content structure is presented that can be applied to web contents of arbitrary physical realization formats and works well even when the physical structure is far different from layout structure."
            },
            "venue": {
                "fragments": [],
                "text": "AH"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 8
                            }
                        ],
                        "text": "[18] M. Hurst."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Hurst breaks \ndown the task of table under\u00adstanding into the following subtasks: (1) table location, the process of \nspotting tables in documents; (2) table recogni\u00adtion, the task of segmenting the original description \nof the table into a relative spatial description; (3) functional and (4) structural analysis; and .nally \n(5) table interpretation, the extraction of meaningful and unambiguously structured information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 22
                            }
                        ],
                        "text": "[12] D. W. Embley, M. Hurst, D. P. Lopresti, and G. Nagy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "We basically follow the naming and process description given by Hurst [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 20
                            }
                        ],
                        "text": "[8] W. W. Cohen, M. Hurst, and L. S. Jensen."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7205594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f52409df167cfe6bafdebac63dfcf8710a56c92",
            "isKey": true,
            "numCitedBy": 90,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we consider the table understanding task and present a catalogue of particular issues that arise when the tables are those found on the web. In addition, we consider what happens when processes commonly associated with web pages are applied to those bearing tables. 1 Table Understanding and the Web The ubiquity of tables, and their ability to describe relational information in a compact and immediate manner make them attractive targets for automated understanding. Recent research into the automatic location, recognition and understanding of tables has demonstrated the viability of integrating automated table processing systems into larger knowledge management applications ([8]). However, table understanding is still a relatively novel research area, one whose definition and terminology are still not fixed. It is useful to break the task down into some subtasks, and to consider them in turn with respect to the understanding of tables delivered on the web. Generally, table processing can be conceptualized as consisting of table location; table recognition; functional and structural analysis; and finally interpretation the extraction of meaningful and unambiguously structured information ([4]). We concentrate on the first two tasks in the following. location table location is the processes of spotting tables in documents. Traditionally, this task comes in two basic forms document image sourced tables ([7], [3]) and electronic text sourced tables including HTML ([1]). The problem is extended to include the spotting of tables in other document encodings such as postscript, pdf, rtf, word, etc. In general, when considering tables on the web, the appropriate HTML tags are exploited (TABLE, TH, TD, etc.). However, this is where we come to the first two distinguishing points. the presence of the TABLE tag in an HTML document does not necessarily indicate the presence of a table ([1] suggest less than 30 % of HTML TABLEs are real tables in one particular domain). there are many other ways in which tables may be presented in web delivered documents plain text (PRE), images, mixtures of table specific tags (TABLE, etc.) and tags used within the table for their functionality in terms of placing text spatially (PRE, LI, etc.) see Figure 1 for an example of such complexities. The first point requires the creation of accurate classification technology. Given any TABLE node in the HTML, the classifier must accept or reject it. Such a classifier may be built either via hand crafted rules ([1]) or using a machine learning approach. Experiments suggest that a machine learning approach using a naive bayse classifier ([9]) based on a feature set describing the set of tags below the potential TABLE node in the document tree produces adequate results. Locating tables encoded in other formats requires technology from other areas. For example, images of tables may be processed by techniques from the document image field ([2]), pre-formatted tables (using the PRE) tag may be processed using plain text table methods ([5]). However, the classification problem extends to these cases and individual classifiers must be constructed to make decisions about document elements of each type. The remaining outstanding issues relate to the mixture of encoding types (e.g. tables built out of TABLE nodes and pre-formatted elements), as well as the mixture of encoding purposes (e.g. the use of the HTML TABLE to encode surrounding text as well as an embedded table). Figure 1. A web page using a mixture of HTML tables (on the left) and images of tables (on the right). recognition table recognition is the task of segmenting the original description of the table into a relative spatial description. In general this task is required when the input is low-level, such as a document image or an electronic text. Clearly, if such tables are found on a web page, the same process is required. Again, given certain assumptions, we can take the marked up tables in a web page to be the logical spatial table. However, there are certain issues that need to be understood in order to account for certain variations: internal cell structure though tags like TH and TD may be assumed to delimit a single cell in the table, there are cases where other non-table tags are used to provide internal structure in such a way as to associate the cell\u2019s contents with those of other cells. A solution would be required to apply a certain amount of recursive processing working into the structure and building a unified abstract table. split cells in order to gain more control over the distribution of the text in a cell, authors occasionally split the text and place it in two or more adjacent cells. This problem may be accommodated by exploiting linguistic process as described in [6] where the content of the cell can be used to indicate continuity, if any, to other cells. errors spanning errors occur when the COLSPAN or ROWSPAN values are not correctly calculated. There are two cases. In the first the cell spans beyond the border of the intended table giving the cell incorrect coordinates. In the second, the span of the cell does not communicate the correct meaning of the cell. For example, a cell that is intended to span three cells below it spans only one leading to ambiguity. The first type of problem may be repaired by some form of normalization, whereas the second requires intelligent processing in order to distinguish the following two cases:"
            },
            "slug": "Layout-and-Language:-Challenges-for-Table-on-the-Hurst",
            "title": {
                "fragments": [],
                "text": "Layout and Language: Challenges for Table Understanding on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The table understanding task is considered and a catalogue of particular issues that arise when the tables are those found on the web are presented and what happens when processes commonly associated with web pages are applied to those bearing tables is considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "The work of Wang and Hu [33], which we have already referenced several times, reports an approximate F-measure of 96% for table location after training a classifier on discriminating features from the source code of web pages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "As explained in the section on related work, Yalin Wang and Hu [33] used a machine-learning based approach using features deduced from the HTML code to discern genuine from non-genuine tables."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Yalin Wang and Hu [33] train a classifier on content features of individual cells and non-text layout features from the HTML source to perform the same task of table location."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "ing these parameters into a machine-learning framework [33] which explicitly uses the visual features available in a 2-D topological problem formulation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2061833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d89945f77470b6a1dabd1f224f10b7d096fd9435",
            "isKey": true,
            "numCitedBy": 227,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a commonly used presentation scheme, especially for describing relational information. However, table understanding remains an open problem. In this paper, we consider the problem of table detection in web documents. Its potential applications include web mining, knowledge management, and web content summarization and delivery to narrow-bandwidth devices. We describe a machine learning based approach to classify each given table entity as either genuine or non-genuine. Various features reflecting the layout as well as content characteristics of tables are studied.In order to facilitate the training and evaluation of our table classifier, we designed a novel web document table ground truthing protocol and used it to build a large table ground truth database. The database consists of 1,393 HTML files collected from hundreds of different web sites and contains 11,477 leaf TABLE elements, out of which 1,740 are genuine tables. Experiments were conducted using the cross validation method and an F-measure of 95.89% was achieved."
            },
            "slug": "A-machine-learning-based-approach-for-table-on-the-Wang-Hu",
            "title": {
                "fragments": [],
                "text": "A machine learning based approach for table detection on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A machine learning based approach to classify each given table entity as either genuine or non-genuine, and designed a novel web document table ground truthing protocol and used it to build a large table ground truth database."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "(2) How can the transition from the table topology into the model be automatized? Recent literature [13] suggests that"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2454221,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1d9629cd4fdfba3211f1ebdf8582c60ddf23584",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The shift of interest to web tables in HTML and PDF files, coupled with the incorporation of table analysis and conversion routines in commercial desktop document processing software, are likely to turn table recognition into more of a systems than an algorithmic issue. We illustrate the transition by some actual examples of web table conversion. We then suggest that the appropriate target format for table analysis, whether performed by conventional customized programs or by off-the-shelf software, is a representation based on the abstract table introduced by X. Wang in 1996. We show that the Wang model is adequate for some useful tasks that prove elusive for less explicit representations, and outline our plans to develop a semi-automated table processing system to demonstrate this approach. Screen-snaphots of a prototype tool to allow table mark-up in the style of Wang are also presented."
            },
            "slug": "Notes-on-Contemporary-Table-Recognition-Embley-Lopresti",
            "title": {
                "fragments": [],
                "text": "Notes on Contemporary Table Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is suggested that the appropriate target format for table analysis, whether performed by conventional customized programs or by off-the-shelf software, is a representation based on the abstract table introduced by X. Wang in 1996."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090792"
                        ],
                        "name": "Y. Aumann",
                        "slug": "Y.-Aumann",
                        "structuredName": {
                            "firstName": "Yonatan",
                            "lastName": "Aumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Aumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145864794"
                        ],
                        "name": "Ronen Feldman",
                        "slug": "Ronen-Feldman",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronen Feldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2659434"
                        ],
                        "name": "Yair Liberzon",
                        "slug": "Yair-Liberzon",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Liberzon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Liberzon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47861681"
                        ],
                        "name": "Binyamin Rosenfeld",
                        "slug": "Binyamin-Rosenfeld",
                        "structuredName": {
                            "firstName": "Binyamin",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Binyamin Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2012715"
                        ],
                        "name": "Jonathan Schler",
                        "slug": "Jonathan-Schler",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Schler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Schler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] describe a system that works only on a hierarchical structure of the visual representation (experiments are performed with PDF documents) and learns to recognize text fields such as author or title from manually tagged training sets of documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9846921,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37b5296d40fd7ad553a87932e2cc088b3970cce2",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Typographic and visual information is an integral part of textual documents. Most information extraction (IE) systems ignore most of this visual information, processing the text as a linear sequence of words. Thus, much valuable information is lost. In this paper, we show how to make use of this visual information for IE. We present an algorithm that allows to automatically extract specific fields of the document (such as the title, author, etc.) based exclusively on the visual formatting of the document, without any reference to the semantic content. The algorithm employs a machine learning approach, whereby the system is first provided with a set of training documents in which the target fields are manually tagged and automatically learns how to extract these fields in future documents. We implemented the algorithm in a system for automatic analysis of documents in PDF format. We present experimental results of applying the system on a set of financial documents, extracting nine different target fields. Overall, the system achieved a 90% accuracy."
            },
            "slug": "Visual-information-extraction-Aumann-Feldman",
            "title": {
                "fragments": [],
                "text": "Visual information extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An algorithm is presented that allows to automatically extract specific fields of a document based exclusively on the visual formatting of the document, without any reference to the semantic content, based on a machine learning approach."
            },
            "venue": {
                "fragments": [],
                "text": "Knowledge and Information Systems"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2662719"
                        ],
                        "name": "Hongkun Zhao",
                        "slug": "Hongkun-Zhao",
                        "structuredName": {
                            "firstName": "Hongkun",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongkun Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38699354"
                        ],
                        "name": "W. Meng",
                        "slug": "W.-Meng",
                        "structuredName": {
                            "firstName": "Weiyi",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109556899"
                        ],
                        "name": "Zonghuan Wu",
                        "slug": "Zonghuan-Wu",
                        "structuredName": {
                            "firstName": "Zonghuan",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zonghuan Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714283"
                        ],
                        "name": "Vijay V. Raghavan",
                        "slug": "Vijay-V.-Raghavan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Raghavan",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay V. Raghavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642131"
                        ],
                        "name": "Clement T. Yu",
                        "slug": "Clement-T.-Yu",
                        "structuredName": {
                            "firstName": "Clement",
                            "lastName": "Yu",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clement T. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": ", comparative shopping [5], and meta-search [41]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6149544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7eb6b3c556755146897fb06524e66af3da8af572",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "When a query is submitted to a search engine, the search engine returns a dynamically generated result page containing the result records, each of which usually consists of a link to and/or snippet of a retrieved Web page. In addition, such a result page often also contains information irrelevant to the query, such as information related to the hosting site of the search engine and advertisements. In this paper, we present a technique for automatically producing wrappers that can be used to extract search result records from dynamically generated result pages returned by search engines. Automatic search result record extraction is very important for many applications that need to interact with search engines such as automatic construction and maintenance of metasearch engines and deep Web crawling. The novel aspect of the proposed technique is that it utilizes both the visual content features on the result page as displayed on a browser and the HTML tag structures of the HTML source file of the result page. Experimental results indicate that this technique can achieve very high extraction accuracy."
            },
            "slug": "Fully-automatic-wrapper-generation-for-search-Zhao-Meng",
            "title": {
                "fragments": [],
                "text": "Fully automatic wrapper generation for search engines"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A technique for automatically producing wrappers that can be used to extract search result records from dynamically generated result pages returned by search engines, and experimental results indicate that this technique can achieve very high extraction accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47655430"
                        ],
                        "name": "Bing Liu",
                        "slug": "Bing-Liu",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143922493"
                        ],
                        "name": "K. Chang",
                        "slug": "K.-Chang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Chang",
                            "middleNames": [
                                "Chen-Chuan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "Web information extraction, building upon structural features of the data on web pages, is probably the most intense studied research topic of web content mining [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207156058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02b465f012f7e1649d48f1cc59058006f1354887",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "With the phenomenal growth of the Web, there is an everincreasing volume of data and information published in numerous Web pages. The research in Web mining aims to develop new techniques to effectively extract and mine useful knowledge or information from these Web pages [8]. Due to the heterogeneity and lack of structure of Web data, automated discovery of targeted or unexpected knowledge/information is a challenging task. It calls for novel methods that draw from a wide range of fields spanning data mining, machine learning, natural language processing, statistics, databases, and information retrieval. In the past few years, there was a rapid expansion of activities in the Web mining field, which consists of Web usage mining, Web structure mining, and Web content mining. Web usage mining refers to the discovery of user access patterns from Web usage logs. Web structure mining tries to discover useful knowledge from the structure of hyperlinks. Web content mining aims to extract/mine useful information or knowledge from Web page contents. For this special issue, we focus on Web content mining."
            },
            "slug": "Editorial:-special-issue-on-web-content-mining-Liu-Chang",
            "title": {
                "fragments": [],
                "text": "Editorial: special issue on web content mining"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This special issue focuses on Web content mining, which consists of Web usage mining, Web structure mining, and Web contentmining, which aims to extract/mine useful information or knowledge from Web page contents."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1839745"
                        ],
                        "name": "Y. Tijerino",
                        "slug": "Y.-Tijerino",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Tijerino",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tijerino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730612"
                        ],
                        "name": "Deryle W. Lonsdale",
                        "slug": "Deryle-W.-Lonsdale",
                        "structuredName": {
                            "firstName": "Deryle",
                            "lastName": "Lonsdale",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deryle W. Lonsdale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645191"
                        ],
                        "name": "Yihong Ding",
                        "slug": "Yihong-Ding",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Ding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30] describe the automatic generation of ontologies from normalized tables, which is a structure they get after normalizing table-equivalent data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11682816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "288673018a6f48a8aa20936833bcd3ef8661508b",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "At the heart of today's information-explosion problems are issues involving semantics, mutual understanding, concept matching, and interoperability. Ontologies and the Semantic Web are offered as a potential solution, but creating ontologies for real-world knowledge is nontrivial. If we could automate the process, we could significantly improve our chances of making the Semantic Web a reality. While understanding natural language is difficult, tables and other structured information make it easier to interpret new items and relations. In this paper we introduce an approach to generating ontologies based on table analysis. We thus call our approach TANGO (Table ANalysis for Generating Ontologies). Based on conceptual modeling extraction techniques, TANGO attempts to (i) understand a table's structure and conceptual content; (ii) discover the constraints that hold between concepts extracted from the table; (iii) match the recognized concepts with ones from a more general specification of related concepts; and (iv) merge the resulting structure with other similar knowledge representations. TANGO is thus a formalized method of processing the format and content of tables that can serve to incrementally build a relevant reusable conceptual ontology."
            },
            "slug": "Towards-Ontology-Generation-from-Tables-Tijerino-Embley",
            "title": {
                "fragments": [],
                "text": "Towards Ontology Generation from Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper introduces an approach to generating ontologies based on table analysis called TANGO (Table ANalysis for Generating Ontologies), a formalized method of processing the format and content of tables that can serve to incrementally build a relevant reusable conceptual ontology."
            },
            "venue": {
                "fragments": [],
                "text": "World Wide Web"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122689890"
                        ],
                        "name": "Lee S. Jensen",
                        "slug": "Lee-S.-Jensen",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Jensen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lee S. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2313483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0909fee90833e20913adb553bf6667c9a3b854b0",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A program that makes an existing website look like a database is called a wrapper. Wrapper learning is the problem of learning website wrappers from examples. We present a wrapper-learning system called WL2 that can exploit several different representations of a document. Examples of such different representations include DOM-level and token-level representations, as well as two-dimensional geometric views of the rendered page (for tabular data) and representations of the visual appearance of text asm it will be rendered. Additionally, the learning system is modular, and can be easily adapted to new domains and tasks. The learning system described is part of an \"industrial-strength\" wrapper management system that is in active use at WhizBang Labs. Controlled experiments show that the learner has broader coverage and a faster learning rate than earlier wrapper-learning systems."
            },
            "slug": "A-flexible-learning-system-for-wrapping-tables-and-Cohen-Hurst",
            "title": {
                "fragments": [],
                "text": "A flexible learning system for wrapping tables and lists in HTML documents"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A wrapper-learning system called WL2 that can exploit several different representations of a document, including DOM-level and token-level representations, as well as two-dimensional geometric views of the rendered page and representations of the visual appearance of text asm it will be rendered."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153924342"
                        ],
                        "name": "Hsin-Hsi Chen",
                        "slug": "Hsin-Hsi-Chen",
                        "structuredName": {
                            "firstName": "Hsin-Hsi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsin-Hsi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072526610"
                        ],
                        "name": "Shih-Chung Tsai",
                        "slug": "Shih-Chung-Tsai",
                        "structuredName": {
                            "firstName": "Shih-Chung",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Chung Tsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949513"
                        ],
                        "name": "Jin-He Tsai",
                        "slug": "Jin-He-Tsai",
                        "structuredName": {
                            "firstName": "Jin-He",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin-He Tsai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] employ heuristic rules to filter out non-genuine tables from their test set and make assumptions about cell content similarity for table recognition and interpretation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6844025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "578c63514136ac5b9af0144bcfe06efcfdd3099c",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a very common presentation scheme, but few papers touch on table extraction in text data mining. This paper focuses on mining tables from large-scale HTML texts. Table filtering, recognition, interpretation, and presentation are discussed. Heuristic rules and cell similarities are employed to identify tables. The F-measure of table recognition is 86.50%. We also propose an algorithm to capture attribute-value relationships among table cells. Finally, more structured data is extracted and presented."
            },
            "slug": "Mining-Tables-from-Large-Scale-HTML-Texts-Chen-Tsai",
            "title": {
                "fragments": [],
                "text": "Mining Tables from Large Scale HTML Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper focuses on mining tables from large-scale HTML texts by using heuristic rules and cell similarities to identify tables and proposes an algorithm to capture attribute-value relationships among table cells."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10215983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8eb9090db385fd6fa77f02736f48d7c98a8d6a5",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 110,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are a ubiquitous form of communication. While everyone seems to know what a table is, a precise, analytical definition of \u201ctabularity\u201d remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Most past research has addressed the extraction of low-level geometric information from raster images of tables scanned from printed documents, although there is growing interest in the processing of tables in electronic form as well. Recent research on table composition and table analysis has improved our understanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. This review, which is structured in terms of generalized paradigms for table processing, indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "slug": "Table-processing-paradigms:-a-research-survey-Embley-Hurst",
            "title": {
                "fragments": [],
                "text": "Table-processing paradigms: a research survey"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This review, which is structured in terms of generalized paradigms for table processing, indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738409"
                        ],
                        "name": "Bernhard Kr\u00fcpl",
                        "slug": "Bernhard-Kr\u00fcpl",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Kr\u00fcpl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard Kr\u00fcpl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153481005"
                        ],
                        "name": "M. Herzog",
                        "slug": "M.-Herzog",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Herzog",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Herzog"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "This approach is later adapted in [20] to a bottom-up clustering algorithm starting with word bounding boxes as well."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14752962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b998e35eb78ddc9f9539860b92817d97876a6ece",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "In the AllRight project, we are developing an algorithm for unsupervised table detection and segmentation that uses the visual rendition of a Web page rather than the HTML code. Our algorithm works bottom-up by grouping word bounding boxes into larger groups and uses a set of heuristics. It has already been implemented and a preliminary evaluation on about 6000 Web documents has been carried out."
            },
            "slug": "Visually-guided-bottom-up-table-detection-and-in-Kr\u00fcpl-Herzog",
            "title": {
                "fragments": [],
                "text": "Visually guided bottom-up table detection and segmentation in web documents"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An algorithm for unsupervised table detection and segmentation that uses the visual rendition of a Web page rather than the HTML code and uses a set of heuristics."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685296"
                        ],
                        "name": "Eugene Agichtein",
                        "slug": "Eugene-Agichtein",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Agichtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Agichtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684012"
                        ],
                        "name": "L. Gravano",
                        "slug": "L.-Gravano",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Gravano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gravano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 209
                            }
                        ],
                        "text": "In contrast, the goal of automatic information extraction is to discover relations between data items of interest and similar data items on a large scale and independently of their domain without any training [2, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7579604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cee045e890270abae65455667b292db355d53728",
            "isKey": false,
            "numCitedBy": 1365,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Text documents often contain valuable structured data that is hidden Yin regular English sentences. This data is best exploited infavailable as arelational table that we could use for answering precise queries or running data mining tasks.We explore a technique for extracting such tables from document collections that requires only a handful of training examples from users. These examples are used to generate extraction patterns, that in turn result in new tuples being extracted from the document collection.We build on this idea and present our Snowball system. Snowball introduces novel strategies for generating patterns and extracting tuples from plain-text documents.At each iteration of the extraction process, Snowball evaluates the quality of these patterns and tuples without human intervention,and keeps only the most reliable ones for the next iteration. In this paper we also develop a scalable evaluation methodology and metrics for our task, and present a thorough experimental evaluation of Snowball and comparable techniques over a collection of more than 300,000 newspaper documents."
            },
            "slug": "Snowball:-extracting-relations-from-large-Agichtein-Gravano",
            "title": {
                "fragments": [],
                "text": "Snowball: extracting relations from large plain-text collections"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper develops a scalable evaluation methodology and metrics for the task, and presents a thorough experimental evaluation of Snowball and comparable techniques over a collection of more than 300,000 newspaper documents."
            },
            "venue": {
                "fragments": [],
                "text": "DL '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020400"
                        ],
                        "name": "A. Pivk",
                        "slug": "A.-Pivk",
                        "structuredName": {
                            "firstName": "Aleksander",
                            "lastName": "Pivk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pivk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748977"
                        ],
                        "name": "P. Cimiano",
                        "slug": "P.-Cimiano",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Cimiano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cimiano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401813995"
                        ],
                        "name": "York Sure-Vetter",
                        "slug": "York-Sure-Vetter",
                        "structuredName": {
                            "firstName": "York",
                            "lastName": "Sure-Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "York Sure-Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[26] focus on understanding table-like structures only due to their structural dimension and transforming the most relevant table types into F-logic frames."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 664903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d60d4937b034c74872d4dec70723c5a20169e70",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Turning the current Web into a Semantic Web requires automatic approaches for annotation of existing data since manual approaches will not scale in general. We here present an approach for automatic generation of F-Logic frames out of tables which subsequently supports the automatic population of ontologies from table-like structures. The approach consists of a methodology, an accompanying implementation and a thorough evaluation. It is based on a grounded cognitive table model which is stepwise instantiated by our methodology."
            },
            "slug": "From-Tables-to-Frames-Pivk-Cimiano",
            "title": {
                "fragments": [],
                "text": "From Tables to Frames"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An approach for automatic generation of F-Logic frames out of tables which subsequently supports the automatic population of ontologies from table-like structures is presented."
            },
            "venue": {
                "fragments": [],
                "text": "SEMWEB"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48441706"
                        ],
                        "name": "H. W. Lie",
                        "slug": "H.-W.-Lie",
                        "structuredName": {
                            "firstName": "H\u00e5kon",
                            "lastName": "Lie",
                            "middleNames": [
                                "Wium"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. W. Lie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143830707"
                        ],
                        "name": "B. Bos",
                        "slug": "B.-Bos",
                        "structuredName": {
                            "firstName": "Bert",
                            "lastName": "Bos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "model and the CSS2 visual formatting model [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207930915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a11c4b42f98078d57f816a8b50e9a0caee6d267b",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "The topic of this thesis is style sheet languages for structured documents on the web. Due to characteristics of the web \u2013 including a screen-centric publishing model, a multitude of output devices, uncertain delivery, strong user preferences, and the possibility for later binding between content and style \u2013 the hypothesis is that the web calls for different style sheet languages than does traditional electronic publishing. Style sheet languages that were developed and used prior to the web are analyzed and compared with style sheet proposals for the web between 1993-1996. The dissertation describes the design of a web-centric style sheet language known as Cascading Style Sheets (CSS). CSS has several notable features including: cascading, pseudo-classes and pseudo-elements, forward-compatible parsing rules, support for different media types, and a strong emphasis on selectors. Problems in CSS are analyzed, and recommended future research is described."
            },
            "slug": "Cascading-style-sheets-Lie-Bos",
            "title": {
                "fragments": [],
                "text": "Cascading style sheets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The dissertation describes the design of a web-centric style sheet language known as Cascading Style Sheets (CSS), which has several notable features including: cascading, pseudo-classes and pseudo-elements, forward-compatible parsing rules, support for different media types, and a strong emphasis on selectors."
            },
            "venue": {
                "fragments": [],
                "text": "World Wide Web J."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741453"
                        ],
                        "name": "A. Culotta",
                        "slug": "A.-Culotta",
                        "structuredName": {
                            "firstName": "Aron",
                            "lastName": "Culotta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Culotta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38765847"
                        ],
                        "name": "Jonathan Betz",
                        "slug": "Jonathan-Betz",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Betz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Betz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "Traditionally, such domain-independent information extraction systems aim to find relations in unstructured plain text by applying natural language processing techniques [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 311673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92d520c905ba682734e0d1f4999e19428b27eb3e",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In order for relation extraction systems to obtain human-level performance, they must be able to incorporate relational patterns inherent in the data (for example, that one's sister is likely one's mother's daughter, or that children are likely to attend the same college as their parents). Hand-coding such knowledge can be time-consuming and inadequate. Additionally, there may exist many interesting, unknown relational patterns that both improve extraction performance and provide insight into text. We describe a probabilistic extraction model that provides mutual benefits to both \"top-down\" relational pattern discovery and \"bottom-up\" relation extraction."
            },
            "slug": "Integrating-Probabilistic-Extraction-Models-and-to-Culotta-McCallum",
            "title": {
                "fragments": [],
                "text": "Integrating Probabilistic Extraction Models and Data Mining to Discover Relations and Patterns in Text"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A probabilistic extraction model is described that provides mutual benefits to both \"top-down\" relational pattern discovery and \"bottom-up\" relation extraction."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47695762"
                        ],
                        "name": "M. Bilenko",
                        "slug": "M.-Bilenko",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Bilenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bilenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40632403"
                        ],
                        "name": "Sugato Basu",
                        "slug": "Sugato-Basu",
                        "structuredName": {
                            "firstName": "Sugato",
                            "lastName": "Basu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sugato Basu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": ", comparative shopping [5], and meta-search [41]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1800721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c412d3f82cc2baeba302c0b1201bab558c652ba7",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of record linkage focuses on determining whether two object descriptions refer to the same underlying entity. Addressing this problem effectively has many practical applications, e.g., elimination of duplicate records in databases and citation matching for scholarly articles. In this paper, we consider a new domain where the record linkage problem is manifested: Internet comparison shopping. We address the resulting linkage setting that requires learning a similarity function between record pairs from streaming data. The learned similarity function is subsequently used in clustering to determine which records are co-referent and should be linked. We present an online machine learning method for addressing this problem, where a composite similarity function based on a linear combination of basis functions is learned incrementally. We illustrate the efficacy of this approach on several real-world datasets from an Internet comparison shopping site, and show that our method is able to effectively learn various distance functions for product data with differing characteristics. We also provide experimental results that show the importance of considering multiple performance measures in record linkage evaluation."
            },
            "slug": "Adaptive-product-normalization:-using-online-for-in-Bilenko-Basu",
            "title": {
                "fragments": [],
                "text": "Adaptive product normalization: using online learning for record linkage in comparison shopping"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents an online machine learning method for addressing the resulting linkage setting that requires learning a similarity function between record pairs from streaming data, and illustrates the efficacy of this approach on several real-world datasets from an Internet comparison shopping site."
            },
            "venue": {
                "fragments": [],
                "text": "Fifth IEEE International Conference on Data Mining (ICDM'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720331"
                        ],
                        "name": "B. Parsia",
                        "slug": "B.-Parsia",
                        "structuredName": {
                            "firstName": "Bijan",
                            "lastName": "Parsia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Parsia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73652210"
                        ],
                        "name": "P. Patel-Schneider",
                        "slug": "P.-Patel-Schneider",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Patel-Schneider",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Patel-Schneider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 206
                            }
                        ],
                        "text": "Another approach to structured information extraction, which we suggest in this paper, is to focus on the 2-D visual representation of web pages as intended by authors for readers in the current Visual Web [24], instead of the tree-based representation used to encode such information (Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Visual Web Table Extraction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 87
                            }
                        ],
                        "text": "D visual representation \nof web pages as intended by authors for read\u00aders in the current Visual Web [24], instead of the tree-based \nrepresentation used to encode such information (Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 152
                            }
                        ],
                        "text": "Figure 1: Information extraction (IE) from rendered web pages emulates the process by which internet \nusers encode and decode information in the current Visual Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Visual Web Page Analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 238
                            }
                        ],
                        "text": "Bernhard Kr \u00a8 { ABSTRACT Traditionally, information extraction from based on assumptions about the \nuse of <table> tags. make these approaches di.cult to scale. topological and style information allows \nknowledge acquisition from the current Visual Web."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8223287,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "94100ad73eed07ff67aa34b2287ba2ca0b1ae6f2",
            "isKey": true,
            "numCitedBy": 21,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The meaning of names (URI references) is a contentious issue in the Semantic Web. Numerous proposals have been given for how to provide meaning for names in the Semantic Web, ranging from a strict localized model-theoretic semantics to proposals for a unified single meaning. We argue that a slight expansion of the standard model-theoretic semantics for names is sufficient for the present, and can easily be augmented where necessary to allow communities of interest to strengthen this spartan theory of meaning."
            },
            "slug": "Meaning-and-the-semantic-web-Parsia-Patel-Schneider",
            "title": {
                "fragments": [],
                "text": "Meaning and the semantic web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that a slight expansion of the standard model-theoretic semantics for names is sufficient for the present, and can easily be augmented where necessary to allow communities of interest to strengthen this spartan theory of meaning."
            },
            "venue": {
                "fragments": [],
                "text": "WWW Alt. '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923209"
                        ],
                        "name": "Nilesh N. Dalvi",
                        "slug": "Nilesh-N.-Dalvi",
                        "structuredName": {
                            "firstName": "Nilesh",
                            "lastName": "Dalvi",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nilesh N. Dalvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144823759"
                        ],
                        "name": "Dan Suciu",
                        "slug": "Dan-Suciu",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Suciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Suciu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 40
                            }
                        ],
                        "text": "Our thinking is inspired by the work of Dalvi and Suciu [11] who propose to extend probabilis\u00adtic databases \nby adding statistics on the global schema and probabilities to the view, thus allowing to compute proba\u00adbilistic \nanswers to queries instead of commonly used deter\u00administic answers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "of Dalvi and Suciu [11] who propose to extend probabilistic databases by adding statistics on the global schema and probabilities to the view, thus allowing to compute probabilistic answers to queries instead of commonly used deterministic answers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "[11] N. N. Dalvi and D. Suciu."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3405432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf2b61de3622b739039de7b6f53588d45074a302",
            "isKey": true,
            "numCitedBy": 73,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Systems integrating dozens of databases, in the scientific domain or in a large corporation, need to cope with a wide variety of imprecisions, such as: different representations of the same object in different sources; imperfect and noisy schema alignments; contradictory information across sources; constraint violations; or insufficient evidence to answer a given query. If standard query semantics were applied to such data, all but the most trivial queries will return an empty answer."
            },
            "slug": "Answering-Queries-from-Statistics-and-Probabilistic-Dalvi-Suciu",
            "title": {
                "fragments": [],
                "text": "Answering Queries from Statistics and Probabilistic Views"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Systems integrating dozens of databases, in the scientific domain or in a large corporation, need to cope with a wide variety of imprecisions, such as: different representations of the same object in different sources; imperfect and noisy schema alignments; contradictory information across sources; constraint violations; or insufficient evidence to answer a given query."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108023096"
                        ],
                        "name": "Xinxin Wang",
                        "slug": "Xinxin-Wang",
                        "structuredName": {
                            "firstName": "Xinxin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinxin Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16895319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb8327c5b091ea26e42ed924e25a02c564998f19",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools. A generic model is designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables. The model separates table's logical structure from its layout structure, which consists of tabular topology and typographic style. The notion of an abstract table, which describes the logical relationships among tabular items, is formally defined and a set of logical operations is proposed to manipulate tables based on these logical relationships. An abstract table can be visualized through a layout structure specified by a set of topological rules, which determine the relative placement of tabular items in two dimensions, and a set of style rules, which determine the final appearance of different items. The absolute placement of a concrete table can be automatically generated by applying a layout specification to an abstract line. An NP-complete problem arises in the formatting process that uses automatic line breaking and determines the physical dimension of a table to satisfy user-specified size constraints. An algorithm has been designed to solve the formatting problem in polynomial time for typical tables. Based on the tabular model, a prototype tabular composition system has been implemented in a UNIX, X Windows environment. This prototype provides an interactive interface to edit the logical structure, the topology and the styles of tables. It allows us to manipulate tables based on the logical relationships tabular items, regardless of where the items are placed in the layout structure, and capable of presenting a table in different topologies and styles so that we can select a high-quality layout structure."
            },
            "slug": "Tabular-Abstraction,-Editing,-and-Formatting-Wang",
            "title": {
                "fragments": [],
                "text": "Tabular Abstraction, Editing, and Formatting"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools using a generic model designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793699"
                        ],
                        "name": "R. Zanibbi",
                        "slug": "R.-Zanibbi",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zanibbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zanibbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683822"
                        ],
                        "name": "J. Cordy",
                        "slug": "J.-Cordy",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cordy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cordy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[39], which cover a broad range of table processing literature and illustrate the general challenges of information extraction from tables despite their primary focus on non-HTML documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42236309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c92be1e0a4ecb0c0ee28aa7da9ec0a39611e5bc",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.Table characteristics vary widely. Consequently, a great variety of computational approaches have been applied to table recognition. In this survey, the table recognition literature is presented as an interaction of table models, observations, transformations, and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup, transformations alter or restructure data, and inferences generate and test hypotheses. This presentation clarifies both the decisions made by a table recognizer and the assumptions and inferencing techniques that underlie these decisions."
            },
            "slug": "A-survey-of-table-recognition-Zanibbi-Blostein",
            "title": {
                "fragments": [],
                "text": "A survey of table recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This presentation clarifies both the decisions made by a table recognizer and the assumptions and inferencing techniques that underlie these decisions."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis and Recognition"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145047294"
                        ],
                        "name": "Gerald Penn",
                        "slug": "Gerald-Penn",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Penn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerald Penn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110416089"
                        ],
                        "name": "Hengbin Luo",
                        "slug": "Hengbin-Luo",
                        "structuredName": {
                            "firstName": "Hengbin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hengbin Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957226"
                        ],
                        "name": "Ryan T. McDonald",
                        "slug": "Ryan-T.-McDonald",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "McDonald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan T. McDonald"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[25] define genuine uses of HTML tables as document entities where the 2-D grid is semantically significant and describe a couple of heuristics to distinguish genuine from non-genuine leaf <table> tables on web pages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 242
                            }
                        ],
                        "text": "The task of extracting web tables can be formulated as the the task of (1) finding all frames for a given web page; (2) discerning those which adhere to the definition of tables from section 3 and where a 2-D grid is semantically significant [25] from lists and other frames intended for nonrelational layout purposes; (3) transfering the content into a topological grid description in which logical cells are flush with neighboring cells and their spatial relations are explicit."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1214535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb72ee8307eeeafeb93031d8625440b9e6415159",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a set of baseline heuristics for identifying genuinely tabular information and news links in HTML documents. A prototype implementation of these heuristics is described for delivering content from news providers' home pages to a narrow-bandwidth device such as a portable digital assistant or cellular phone display. Its evaluation on 75 Web sites is provided, along with a discussion of topics for future research."
            },
            "slug": "Flexible-Web-document-analysis-for-delivery-to-Penn-Hu",
            "title": {
                "fragments": [],
                "text": "Flexible Web document analysis for delivery to narrow-bandwidth devices"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A prototype implementation of a set of baseline heuristics for identifying genuinely tabular information and news links in HTML documents for delivering content from news providers' home pages to a narrow-bandwidth device such as a portable digital assistant or cellular phone display is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69026873"
                        ],
                        "name": "S. Abiteboul",
                        "slug": "S.-Abiteboul",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Abiteboul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Abiteboul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144837668"
                        ],
                        "name": "R. Hull",
                        "slug": "R.-Hull",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hull",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765187"
                        ],
                        "name": "V. Vianu",
                        "slug": "V.-Vianu",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Vianu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vianu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "as n-tuples in terms of the relational model of relational databases [1], but rather tuples whose relation between individual tuples and entries can be specified a posteriori of the extraction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5513123,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a96d7a5c82dd0096b8a8813bf2235f573d84057",
            "isKey": false,
            "numCitedBy": 4292,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A. ANTECHAMBER. Database Systems. The Main Principles. Functionalities. Complexity and Diversity. Past and Future. Ties with This Book. Bibliographic Notes. Theoretical Background. Some Basics. Languages, Computability, and Complexity. Basics from Logic. The Relational Model. The Structure of the Relational Model. Named versus Unnamed Perspectives. Notation. Bibliographic Notes. B. BASICS: RELATIONAL QUERY LANGUAGES. Conjunctive Queries. Getting Started. Logic-Based Perspectives. Query Composition and Views. Algebraic Perspectives. Adding Union. Bibliographic Notes. Exercises. Adding Negation: Algebra and Calculus. The Relational Algebras. Nonrecursive Datalog with Negation. The Relational Calculus. Syntactic Restrictions for Domain Independence. Aggregate Functions. Digression: Finite Representations of Infinite Databases. Bibliographic Notes. Exercises. Static Analysis and Optimization. Issues in Practical Query Optimization. Global Optimization. Static Analysis of the Relational Calculus. Computers with Acyclic Joins. Bibliographic Notes. Exercises. Notes on Practical Languages. SQL: The Structured Query Language. Query-by-Example and Microsoft Access. Confronting the Real World. Bibliographic Notes. Exercises. C. CONSTRAINTS. Functional and Join Dependency. Motivation. Functional and Key Dependencies. join and Multivalued Dependencies. The Chase. Bibliographic Notes. Exercises. Inclusion Dependency. Inclusion Dependency in Isolation. Finite versus Infinite Implication. Nonaxiomatizability of fd's + ind's. Restricted Kinds of Inclusion Dependency. Bibliographic Notes. Exercises. A Larger Perspective. A Unifying Framework. The Chase revisited. Axiomatization. An Algebraic Perspective. Bibliographic Notes. Exercises. Design and Dependencies. Semantic Data Models. Normal Forms. Universal Relation Assumption. Bibliographic Notes. Exercises. D. DATALOG AND RECURSION. Datalog. Syntax of Datalog. Model-Theoretic Semantics. Fixpoint Semantics. Proof-Theoretic Approach. Static Program Analysis. Bibliographic Notes. Exercises. Evaluation of Datalog. Seminaive Evaluation. Top-Down Techniques. Magic. Two Improvements. Bibliographic Notes. Exercises. Recursion and Negation. Algebra + While. Calculus + Fixpoint. Datalog with Negation. Equivalence. Recursion in Practical Language. Bibliographic Notes. Exercises. Negation in Datalog. The Basic Problem. Stratified Semantics. Well-Founded Semantics. Expressive Power. Negation as Failure of Brief. Bibliographic Notes. Exercises. E. EXPRESSIVENESS AND COMPLEXITY. Sizing up Languages. Queries. Complexity of Queries. Languages and Complexity. Bibliographic Notes. Exercises. First Order, Fixpoint and While. Complexity of First-Order Queries. Expressiveness of First-Order Queries. Fixpoint and While Queries. The Impact of Order. Bibliographic Notes. Exercises. Highly Expressive Languages. While(N)-while with Arithmetic. While(new)-while with New Values. While(uty)-An Untyped Extension of while. Bibliographic Notes. Exercises. F. FINALE. Incomplete Information. Warm-Up. Weak Representation Systems. Conditional Tables. The Complexity of Nulls. Other Approaches. Bibliographic Notes. Exercises. Complex Values. Complex Value Databases. The Algebra. The Caculas. Examples. Equivalence Theorems. Fixpoint and Deduction. Expressive Power and Complexity. A Practicle Query Language for Complex Values. Bibliographic Notes. Exercises. Object Databases. Informal Presentation. Formal Definition of an OODB Model. Languages for OODB Queries. Languages for Methods. Further Issues for OODB's. Bibliographic Notes. Exercises. Dynamic Aspects. Updated Languages. Transactional Schemas. Updating Views and Deductive Databases. Active Databases. Temporal Databases and Constraints. Bibliographic Notes. Exercises. Bibliography. Symbol Index. Index. 0201537710T04062001"
            },
            "slug": "Foundations-of-Databases-Abiteboul-Hull",
            "title": {
                "fragments": [],
                "text": "Foundations of Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book discusses Languages, Computability, and Complexity, and the Relational Model, which aims to clarify the role of Semantic Data Models in the development of Query Language Design."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "Now, while existing literature agrees that the ground truthing of interpreted tables in general is difficult because of several \u201ctruths\u201d that might exist about what a table is and how it is interpreted [17], we also came across several problems in the steps prior to table interpretation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16106027,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "9e16dcd290d9ab780107270c666d71c00e569b22",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The principle that for every document analysis task there exists a mechanism for creating well-defined ground-truth is a widely held tenet. Past experience with standard datasets providing ground-truth for character recognition and page segmentation tasks supports this belief. In the process of attempting to evaluate several table recognition algorithms we have been developing, however, we have uncovered a number of serious hurdles connected with the ground-truthing of tables. This problem may, in fact, be much more difficult than it appears. We present a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "slug": "Why-table-ground-truthing-is-hard-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Why table ground-truthing is hard"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "The end result of this extraction is an XML representation, which is heavily inspired by the work of Wohlberg [35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 8
                            }
                        ],
                        "text": "[35] T. Wohlberg."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 336,
                                "start": 332
                            }
                        ],
                        "text": "Our system analyzes any given web page for the existence of tabular data, recognizes relations as implied by their spatial arrangement, extracts a number of n-tuples together with hierarchical information about relations between their entries and saves them in an XML data format which is heavily influenced by the work of Wohlberg [35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 330,
                                "start": 322
                            }
                        ],
                        "text": "Our \nsystem analyzes any given web page for the existence of tabular data, rec\u00adognizes relations as implied \nby their spatial arrangement, extracts a number of n-tuples together with hierarchical in\u00adformation about \nrelations between their entries and saves them in an XML data format which is heavily in.uenced by the \nwork of Wohlberg [35]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hypertables: Development of a structure description language for tables in XML"
            },
            "venue": {
                "fragments": [],
                "text": "Master thesis, University of Hamburg, Germany"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 50
                            }
                        ],
                        "text": "We consider the description of tables as given by Vanoirbeek [31] a very useful \nde.nition of tables on the Web despite its original focus on printed docu\u00adments: In a global way, a table \nmay be de.ned as a two-dimensional presentation of logical relationships between groups of data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 44
                            }
                        ],
                        "text": "This table model is similar to the model of \nVanoirbeek [31] in the sense that it is a multi-dimensional model of a table, separating the logical \nstructure from the layout of a table."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "This table model is similar to the model of Vanoirbeek [31] in the sense that it is a multi-dimensional model of a table, separating the logical structure from the layout of a table."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 8
                            }
                        ],
                        "text": "[31] C. Vanoirbeek."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "We consider the description of tables as given by Vanoirbeek [31] a very useful definition of tables on the Web despite its original focus on printed documents: \u201cIn a global way, a table may be defined as a two-dimensional presentation of logical relationships between groups of data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Formatting structured tables"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. of Electronic Publishing\u201992,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Creating permanent test sets of web pages for information extraction research ViPER : augmenting automatic information extraction with visual perceptions Learning table extraction from examples"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classification and comparison of information structures from a web page. The Annals of the University of Craiova"
            },
            "venue": {
                "fragments": [],
                "text": "Classification and comparison of information structures from a web page. The Annals of the University of Craiova"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Track: Data Mining Session: Identifying Structure in Web Pages"
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "the appropriate target format for table analysis is a representation based on the abstract table proposed by Xinxin Wang [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 146
                            }
                        ],
                        "text": "Recent literature [13] suggests that the appropriate target format for table analysis is a represen\u00adtation \nbased on the abstract table proposed by Xinxin Wang [32]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tabular abstraction"
            },
            "venue": {
                "fragments": [],
                "text": "editing, and formatting. Ph.D. thesis, University of Waterloo"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 23,
            "methodology": 13
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 44,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Towards-domain-independent-information-extraction-Gatterbauer-Bohunsky/95c9961c73db64837fd6b8dbda2f0b246fed6812?sort=total-citations"
}