{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700597"
                        ],
                        "name": "Jyrki Kivinen",
                        "slug": "Jyrki-Kivinen",
                        "structuredName": {
                            "firstName": "Jyrki",
                            "lastName": "Kivinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyrki Kivinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9426152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14658bf6b693af9f30920c70fad14563f6b0cc10",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider on-line algorithms for predicting binary or continuous-valued outcomes, when the algorithm has available the predictions made by N experts. For a sequence of trials, we compute total losses for both the algorithm and the experts under a loss function. At the end of the trial sequence, we compare the total loss of the algorithm to the total loss of the best expert, i.e., the expert with the least loss on the particular trial sequence. We show that for a large class of loss functions, with binary outcomes the total loss of the algorithm proposed by Vovk exceeds the total loss of the best expert at most by the amount c ln N, where c is a constant determined by the loss function. This upper bound does not depend on any assumptions on how the experts'' predictions or the outcomes are generated, and the trial sequence can be arbitrarily long. We give a straightforward method for finding the correct value c and show by a lower bound that for this value of c, the upper bound is asymptotically tight. The lower bound is based on a probabilistic adversary argument. The class of loss functions for which the c ln N upper bound holds includes the square loss, the logarithmic loss, and the Hellinger loss. We also consider another class of loss functions, including the absolute loss, for which we have an Omega((l log N)^(1/2)) lower bound, where l is the number of trials. We show that for the square and logarithmic loss functions, Vovk''s algorithm achieves the same worst-case upper bounds with continuous-valued outcomes as with binary outcomes. For the absolute loss, we show how bounds earlier achieved for binary outcomes can be achieved with continuous-valued outcomes using a slightly more complicated algorithm."
            },
            "slug": "Tight-worst-case-loss-bounds-for-predicting-with-Haussler-Kivinen",
            "title": {
                "fragments": [],
                "text": "Tight worst-case loss bounds for predicting with expert advice"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work considers on-line algorithms for predicting binary or continuous-valued outcomes, when the algorithm has available the predictions made by N experts, and shows that for a large class of loss functions, with binary outcomes the total loss of the algorithm proposed by Vovk exceeds the total losses of the best expert at most by the amount c ln N, where c is a constant determined by the loss function."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722848"
                        ],
                        "name": "A. D. Santis",
                        "slug": "A.-D.-Santis",
                        "structuredName": {
                            "firstName": "Alfredo",
                            "lastName": "Santis",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. D. Santis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1896180"
                        ],
                        "name": "G. Markowsky",
                        "slug": "G.-Markowsky",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Markowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Markowsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36114502"
                        ],
                        "name": "M. Wegman",
                        "slug": "M.-Wegman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Wegman",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6921021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "952f74df2f23cf5f72f26a58a6bb29b6ac210996",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The question of how to learn rules, when those rules make probabilistic statements about the future, is considered. Issues are discussed that arise when attempting to determine what a good prediction function is, when those prediction functions make probabilistic assumptions. Learning has at least two purposes: to enable the learner to make predictions in the future and to satisfy intellectual curiosity as to the underlying cause of a process. Two results related to these distinct goals are given. In both cases, the inputs are a countable collection of functions which make probabilistic statements about a sequence of events. One of the results shows how to find one of the functions, which generated the sequence, the other result allows to do as well in terms of predicting events as the best of the collection. In both cases the results are obtained by evaluating a function based on a tradeoff between its simplicity and the accuracy of its predictions.<<ETX>>"
            },
            "slug": "Learning-probabilistic-prediction-functions-Santis-Markowsky",
            "title": {
                "fragments": [],
                "text": "Learning probabilistic prediction functions"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "The question of how to learn rules, when those rules make probabilistic statements about the future, is considered and two results related to these distinct goals are given."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1988] 29th Annual Symposium on Foundations of Computer Science"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12843330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35582a30685083c62dca992553eec44123be9d07",
            "isKey": false,
            "numCitedBy": 1675,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The construction of prediction algorithms in a situation in which a learner faces a sequence of trials, with a prediction to be made in each, and the goal of the learner is to make few mistakes is studied. It is assumed that the learner has reason to believe that one of some pool of known algorithms will perform well but does not know which one. A simple and effective method, based on weighted voting, is introduced for constructing a compound algorithm in such a circumstance. It is called the weighted majority algorithm and is shown to be robust with respect to errors in the data. Various versions of the weighted majority algorithm are discussed, and error bounds for them that are closely related to the error bounds of the best algorithms of the pool are proved.<<ETX>>"
            },
            "slug": "The-weighted-majority-algorithm-Littlestone-Warmuth",
            "title": {
                "fragments": [],
                "text": "The Weighted Majority Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A simple and effective method, based on weighted voting, is introduced for constructing a compound algorithm in a situation in which a learner faces a sequence of trials, and the goal of the learner is to make few mistakes."
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34755863"
                        ],
                        "name": "K. Yamanishi",
                        "slug": "K.-Yamanishi",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamanishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yamanishi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10939898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "977a156cb5ec9e1668c1844ac19fc75018b21b4c",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In this paper, we consider the problem of on-line prediction in which at each time an unlabeled instance is given and then a prediction algorithm outputs a probability distribution over the set of labels rather than {0, 1}-values before it sees the correct label. For this setting, we propose a weighted-average-type on-line stochastic prediction algorithm WA, which can be regarded as a hybrid of the Bayes algorithm and a sequential real-valued parameter estimation method. We derive upper bounds on the instantaneous logarithmic loss and cumulative logarithmic loss for WA in both the example-dependent form and the expected form (the expectation is taken with respect to the fixed target distribution of sequences). Specifically, under some specific parametric assumptions for target rules, we prove that WA is optimal in the sense that the upper bound on the expected cumulative logarithmic loss for WA asymptotically matches Rissanen\u2032s coding-theoretic lower bound. Further, we derive an upper bound on the expected cumulative quadratic loss by making use of relationships between the quadratic loss and the logarithmic loss. Throughout the paper, we relate computational learning theory to information theory, most specifically, Rissanen\u2032s predictive minimum description length principle, by giving noiseless coding theoretic interpretations to the loss bounds."
            },
            "slug": "A-Loss-Bound-Model-for-On-Line-Stochastic-Yamanishi",
            "title": {
                "fragments": [],
                "text": "A Loss Bound Model for On-Line Stochastic Prediction Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that WA is optimal in the sense that the upper bound on the expected cumulative logarithmic loss for WA asymptotically matches Rissanen\u2032s coding-theoretic lower bound."
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51106511"
                        ],
                        "name": "A. Barron",
                        "slug": "A.-Barron",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Barron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11662842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a2a4c30ca15e5c06b3d81aa02c8cf39450d9ee5",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We look at sequential classification and regression problems in which {+- 1}-labeled instances are given on-line, one at a time, and for each new instance, before seeing the label, the learning system must either predict the label, or estimate the probability that the label is +1. We look at the performance of Bayes method for this task, as measured by the total number of mistakes for the classification problem, and by the total log loss (or information gain) for the regression problem. Our results are given by comparing the performance of Bayes method to the performance of a hypothetical \"omniscient scientist\" who is able to use extra information about the labeling process that would not be available in the standard learning protocol. The results show that Bayes methods perform only slightly worse than the omniscient scientist in many cases. These results generalize previous results of Haussler, Kearns and Schapire, and Opper and Haussler."
            },
            "slug": "HOW-WELL-DO-BAYES-METHODS-WORK-FOR-ON-LINE-OF-{+-1}-Haussler-Barron",
            "title": {
                "fragments": [],
                "text": "HOW WELL DO BAYES METHODS WORK FOR ON-LINE PREDICTION OF {+- 1} VALUES?"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This work looks at sequential classification and regression problems in which {+- 1}-labeled instances are given on-line, one at a time, and for each new instance, before seeing the label, the learning system must either predict thelabel, or estimate the probability that the label is +1."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144519810"
                        ],
                        "name": "M. Feder",
                        "slug": "M.-Feder",
                        "structuredName": {
                            "firstName": "Meir",
                            "lastName": "Feder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Feder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734871"
                        ],
                        "name": "N. Merhav",
                        "slug": "N.-Merhav",
                        "structuredName": {
                            "firstName": "Neri",
                            "lastName": "Merhav",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Merhav"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145215487"
                        ],
                        "name": "M. Gutman",
                        "slug": "M.-Gutman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Gutman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gutman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 240855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce9251f7594f0cb1e043452403475b1611f99e51",
            "isKey": false,
            "numCitedBy": 366,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of sequentially determining the next, future, outcome of a specific binary individual sequence, based on its observed past, using a finite state predictor is considered. The authors define the finite state predictability of the (infinite) sequence x/sub 1/ . . . z/sub n/ . . . as the minimum fraction of prediction errors that can be made by any such predictor, and prove that this can be achieved, upto an arbitrary small prescribed distance, for each individual sequence, by fully sequential guessing schemes. The rate at which the sequential guessing schemes approach the predictability is calculated. An efficient guessing procedure is based on the incremental parsing algorithm used in Lempel-Ziv data compression, and its fraction of errors also approaches the predictability of the sequence. Some relations between compressibility and predictability are discussed and use of the predictability as an additional measure for the complexity, or randomness, of the sequence is suggested.<<ETX>>"
            },
            "slug": "Universal-prediction-of-individual-sequences-Feder-Merhav",
            "title": {
                "fragments": [],
                "text": "Universal prediction of individual sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The authors define the finite state predictability of the (infinite) sequence x/sub 1/ . . . z/sub n/ ."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772099"
                        ],
                        "name": "D. Helmbold",
                        "slug": "D.-Helmbold",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Helmbold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmbold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16694241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c58afc1b7fd284351d6897f315617084087d4340",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is a weak learning algorithm if with some small probability it outputs a hypothesis with error slightly below 50%. This paper presents relationships between weak learning, weak prediction (where the probability of being correct is slightly larger than 50%), and consistency oracles (which decide whether or not a given set of examples is consistent with a concept in the class). Our main result is a simple polynomial prediction algorithm which makes only a single query to a consistency oracle and whose predictions have a polynomial edge over random guessing. We compare this prediction algorithm with several of the standard prediction techniques, deriving an improved worst case bound on Gibbs algorithm in the process. We use our algorithm to show that a concept class is polynomially learnable if and only if there is a polynomial probabilistic consistency oracle for the class. Since strong learning algorithms can be built from weak learning algorithms, our results also characterizes strong learnability."
            },
            "slug": "On-Weak-Learning-Helmbold-Warmuth",
            "title": {
                "fragments": [],
                "text": "On Weak Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents relationships between weak learning, weak prediction, and consistency oracles and uses an algorithm to show that a concept class is polynomially learnable if and only if there is a polynomial probabilistic consistency oracle for the class."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 5119145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5609ee7a8c7432c0f502b2a6dcfe9c0039206ab",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We consider the problem of predicting {0, 1}-valued functions on Rn and smaller domains, based on their values on randomly drawn points. Our model is related to Valiant\u2032s PAC learning model, but does not require the hypotheses used for prediction to be represented in any specified form. In our main result we show how to construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions. This result is based on new combinatorial results about classes of functions of finite VC dimension. We also discuss more computationally efficient algorithms for predicting indicator functions of axis-parallel rectangles, more general intersection closed concept classes, and halfspaces in Rn. These are also optimal to within a constant factor. Finally, we compare the general performance of prediction strategies derived by our method to that of those derived from methods in PAC learning theory."
            },
            "slug": "Predicting-{0,1}-functions-on-randomly-drawn-points-Haussler-Littlestone",
            "title": {
                "fragments": [],
                "text": "Predicting {0,1}-functions on randomly drawn points"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This model is related to Valiant\u2032s PAC learning model, but does not require the hypotheses used for prediction to be represented in any specified form and shows how to construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145675281"
                        ],
                        "name": "V. Vovk",
                        "slug": "V.-Vovk",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vovk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vovk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 10690103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8dcb5b79e98dfa06df0abc788257dc8bdd2eaf7",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Universal-Forecasting-Algorithms-Vovk",
            "title": {
                "fragments": [],
                "text": "Universal Forecasting Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50674059"
                        ],
                        "name": "T. H. Chung",
                        "slug": "T.-H.-Chung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Chung",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. H. Chung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2736977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7ed8d24f1d12ffb6dc8bbba3f5831198d965c87",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a game theoretic approach for sequentially choosing decisions by combining the suggestions of a fixed number of experts. Since the optimal decision making strategy is often computationally expensive, we present a methodology for obtaining approximate strategies with provably good performance. These methods are applicable to any decision problem with bounded payoff function, are computationally feasible, and arise naturally as approximations to the exact solution. We illustrate the ideas by applying our results to the problem of predicting a sequence of letters drawn from a finite alphabet with the goal being to minimize the number of mistakes made."
            },
            "slug": "Approximate-methods-for-sequential-decision-making-Chung",
            "title": {
                "fragments": [],
                "text": "Approximate methods for sequential decision making using expert advice"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A game theoretic approach for sequentially choosing decisions by combining the suggestions of a fixed number of experts is considered, applicable to any decision problem with bounded payoff function, and arise naturally as approximations to the exact solution."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34755863"
                        ],
                        "name": "K. Yamanishi",
                        "slug": "K.-Yamanishi",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamanishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yamanishi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37786708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbd8bd853d78cd52b31b208d778a62ec44e9d7c4",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-loss-bound-model-for-on-line-stochastic-Yamanishi",
            "title": {
                "fragments": [],
                "text": "A loss bound model for on-line stochastic prediction strategies"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10ddb646feddc12337b5a755c72e153e37088c02",
            "isKey": false,
            "numCitedBy": 4191,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learnt using it in a reasonable (polynomial) number of steps. We find that inherent algorithmic complexity appears to set serious limits to the range of concepts that can be so learnt. The methodology and results suggest concrete principles for designing realistic learning systems."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '84"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19753387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2606d97cf80839e7d223a0769529e2cc51a95bf",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "From-on-line-to-batch-learning-Littlestone",
            "title": {
                "fragments": [],
                "text": "From on-line to batch learning"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '89"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6298480,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a769ec3a8fb442548beeafa9b5e0d71661b195ac",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we initiate an investigation of generalizations of the Probably Approximately Correct (PAC) learning model that attempt to signi cantly weaken the target function assumptions. The ultimate goal in this direction is informally termed agnostic learning, in which we make virtually no assumptions on the target function. The name derives from the fact that as designers of learning algorithms, we give up the belief that Nature (as represented by the target function) has a simple or succinct explanation. We give a number of positive and negative results that provide an initial outline of the possibilities for agnostic learning. Our results include hardness results for the most obvious generalization of the PAC model to an agnostic setting, an e cient and general agnostic learning method based on dynamic programming, relationships between loss functions for agnostic learning, and an algorithm for a learning problem that involves hidden variables."
            },
            "slug": "Toward-Eecient-Agnostic-Learning-Schapire",
            "title": {
                "fragments": [],
                "text": "Toward Eecient Agnostic Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Results include hardness results for the most obvious generalization of the PAC model to an agnostic setting, an e cient and general agnostic learning method based on dynamic programming, relationships between loss functions for agnosticLearning, and an algorithm for a learning problem that involves hidden variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076815081"
                        ],
                        "name": "Seung",
                        "slug": "Seung",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Seung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30053069"
                        ],
                        "name": "Sompolinsky",
                        "slug": "Sompolinsky",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Sompolinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sompolinsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30093773"
                        ],
                        "name": "Tishby",
                        "slug": "Tishby",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tishby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7394722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2498a4e1755f047accc06a6e0fab0b0eb1b37ae0",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "number of examples P used for training. The theory implies that, for a reduction in eg that remains finite in the large-N limit, P should generally scale as nN, where N is the number of independently adjustable weights in the network. We show that for smooth networks, i.e., those with continuously varying weights and smooth transfer functions, the generalization curve asymptotically obeys an inverse power law. In contrast, for nonsmooth networks other behaviors can appear, depending on the nature of the nonlinearities as well as the realizability of the rule. In particular, a discontinuous learning transition from a state of poor to a state of perfect generalization can occur in nonsmooth networks learning realizable rules. We illustrate both gradual and continuous learning with a detailed analytical and numerical study of several single-layer perceptron models. Comparing with the exact replica theory of perceptron learning, we find that for realizable rules the high-temperature and annealed theories provide very good approximations to the generalization performance. Assuming this to hold for multilayer networks as well, we propose a classification of possible asymptotic forms of learning curves in general realizable models. For unrealizable rules we find that the above approximations fail in general to predict correctly the shapes of the generalization curves. Another indication of the important role of quenched disorder for unrealizable rules is that the generalization error is not necessarily a monotonically increasing function of temperature. Also, unrealizable rules can possess genuine spin-glass phases indicative of degenerate minima separated by high barriers."
            },
            "slug": "Statistical-mechanics-of-learning-from-examples.-Seung-Sompolinsky",
            "title": {
                "fragments": [],
                "text": "Statistical mechanics of learning from examples."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that for smooth networks, i.e., those with continuously varying weights and smooth transfer functions, the generalization curve asymptotically obeys an inverse power law, while for nonsmooth networks other behaviors can appear, depending on the nature of the nonlinearities as well as the realizability of the rule."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review. A, Atomic, molecular, and optical physics"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7165930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e02d1ffa45de336af35ae6fde2e8f6f19d5e50ff",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Equivalence-of-models-for-polynomial-learnability-Haussler-Kearns",
            "title": {
                "fragments": [],
                "text": "Equivalence of models for polynomial learnability"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734871"
                        ],
                        "name": "N. Merhav",
                        "slug": "N.-Merhav",
                        "structuredName": {
                            "firstName": "Neri",
                            "lastName": "Merhav",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Merhav"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144519810"
                        ],
                        "name": "M. Feder",
                        "slug": "M.-Feder",
                        "structuredName": {
                            "firstName": "Meir",
                            "lastName": "Feder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Feder"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15220526,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b7307d1449cded74c7114041fc4fbf059ff7de57",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential learning and decision algorithms are investigated, with various application areas, under a family of additive loss functions for individual data sequences. Simple universal sequential schemes are known, under certain conditions, to approach optimality uniformly as fast as n-1logn, where n is the sample size. For the case of finite-alphabet observations, the class of schemes that can be implemented by finite-state machines (FSM's), is studied. It is shown that Markovian machines with sufficiently long memory exist that are asymptotically nearly as good as any given FSM (deterministic or randomized) for the purpose of sequential decision. For the continuous-valued observation case, a useful class of parametric schemes is discussed with special attention to the recursive least squares (RLS) algorithm."
            },
            "slug": "Universal-sequential-learning-and-decision-from-Merhav-Feder",
            "title": {
                "fragments": [],
                "text": "Universal sequential learning and decision from individual data sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that Markovian machines with sufficiently long memory exist that are asymptotically nearly as good as any given FSM (deterministic or randomized) for the purpose of sequential decision."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1330691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f05520f728a890a5c806ad7f3b27e3144ecc4d6",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we study a Bayesian or average-case model of concept learning with a twofold goal: to provide more precise characterizations of learning curve (sample complexity) behavior that depend on properties of both the prior distribution over concepts and the sequence of instances seen by the learner, and to smoothly unite in a common framework the popular statistical physics and VC dimension theories of learning curves. To achieve this, we undertake a systematic investigation and comparison of two fundamental quantities in learning and information theory: the probability of an incorrect prediction for an optimal learning algorithm, and the Shannon information gain. This study leads to a new understanding of the sample complexity of learning in several existing models."
            },
            "slug": "Bounds-on-the-sample-complexity-of-Bayesian-using-Haussler-Kearns",
            "title": {
                "fragments": [],
                "text": "Bounds on the sample complexity of Bayesian learning using information theory and the VC dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A systematic investigation and comparison of two fundamental quantities in learning and information theory: the probability of an incorrect prediction for an optimal learning algorithm, and the Shannon information gain is undertaken."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49896591"
                        ],
                        "name": "A. Shenhar",
                        "slug": "A.-Shenhar",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Shenhar",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shenhar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22196742,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4aaa6861f93d71d192b38deb99dd69dedd824fce",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential predictors for binary sequences with no assumptions upon the existence of an underlying process are discussed. The rule offered here induces an expected proportion of errors which differs by 0(n-\u00bf) from the Bayes envelope with respect to the observed kth order Markov structure. This extends the compound sequential Bayes work of Robbins, Hannan and Blackwell from sequences with perceived 0th order structure to sequences with perceived kth order structure. The proof follows immediately from applying the 0th order theory to 2k separate subsequences. These results show the essential robustness of procedures which play Bayes with respect to (a perhaps randomized) version of an estimate of the distribution of the past. Such procedures still have asymptotically good properties even when the underlying assumptions for which they were originally developed no longer hold."
            },
            "slug": "Compound-Bayes-Predictors-for-Sequences-with-Markov-Cover-Shenhar",
            "title": {
                "fragments": [],
                "text": "Compound Bayes Predictors for Sequences with Apparent Markov Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results show the essential robustness of procedures which play Bayes with respect to (a perhaps randomized version of an estimate of the distribution of the past) still have asymptotically good properties even when the underlying assumptions for which they were originally developed no longer hold."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30053069"
                        ],
                        "name": "Sompolinsky",
                        "slug": "Sompolinsky",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Sompolinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sompolinsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30093773"
                        ],
                        "name": "Tishby",
                        "slug": "Tishby",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076815081"
                        ],
                        "name": "Seung",
                        "slug": "Seung",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Seung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17664980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c24568e36420c2ffe6a8483100430517a2bbc2b6",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A statistical mechanical theory of learning from examples in layered networks at finite temperature is studied. When the training error is a smooth function of continuously varying weights the generalization error falls off asymptotically as the inverse number of examples. By analytical and numerical studies of single-layer perceptrons we show that when the weights are discrete the generalization error can exhibit a discontinuous transition to perfect generalization. For intermediate sizes of the example set, the state of perfect generalization coexists with a metastable spin-glass state. Understanding how systems can be efficiently trained to perform tasks is of fundamental importance. A central issue in learning theory is the rate of improvement in the processing of novel data as a function of the number of examples presented during training, i.e. , the generalization curve. ' Numerical results on training in layered neural networks indicate that the generalization error improves gradually in some cases, and sharply in others. s In this work we use statistical mechanics to study generalization curves in large layered networks. We will first discuss the general theory and then present results for learning in a single-layer perceptron. The computational function of layered neural networks is described in terms of the input-output relations that they generate. We consider here a multilayer network with M input nodes, whose states are denoted by synaptic weights of the network. The network is trained by adjusting its weights to approximate or reproduce, if possible, a target function cto(S) on the input space."
            },
            "slug": "Learning-from-examples-in-large-neural-networks.-Sompolinsky-Tishby",
            "title": {
                "fragments": [],
                "text": "Learning from examples in large neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Numerical results on training in layered neural networks indicate that the generalization error improves gradually in some cases, and sharply in others, and statistical mechanics is used to study generalization curves in large layered networks."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review letters"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742404"
                        ],
                        "name": "A. Fiat",
                        "slug": "A.-Fiat",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Fiat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fiat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47546648"
                        ],
                        "name": "R. Karp",
                        "slug": "R.-Karp",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Karp",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Karp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145881044"
                        ],
                        "name": "M. Luby",
                        "slug": "M.-Luby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Luby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Luby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2878518"
                        ],
                        "name": "L. A. McGeoch",
                        "slug": "L.-A.-McGeoch",
                        "structuredName": {
                            "firstName": "Lyle",
                            "lastName": "McGeoch",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. A. McGeoch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721040"
                        ],
                        "name": "D. Sleator",
                        "slug": "D.-Sleator",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sleator",
                            "middleNames": [
                                "Dominic"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sleator"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693869"
                        ],
                        "name": "N. Young",
                        "slug": "N.-Young",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3260905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98b96ff1da51efcb16a6eef0cf449bbf62ab12ef",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Competitive-Paging-Algorithms-Fiat-Karp",
            "title": {
                "fragments": [],
                "text": "Competitive Paging Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "J. Algorithms"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734871"
                        ],
                        "name": "N. Merhav",
                        "slug": "N.-Merhav",
                        "structuredName": {
                            "firstName": "Neri",
                            "lastName": "Merhav",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Merhav"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144519810"
                        ],
                        "name": "M. Feder",
                        "slug": "M.-Feder",
                        "structuredName": {
                            "firstName": "Meir",
                            "lastName": "Feder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Feder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16368777,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b80d1ce5de19e3a5a20ded690bbdeb235dc1b87f",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential decision algorithms are investigated for individual data sequences, with various application areas. Simple universal schemes are known to approach optimality as fast as n/sup -1/ log n, where n is the sample size. For the finite-alphabet case, schemes that are implementable by finite-state machines (FSM's), are studied. It is shown that Markovian machines with sufficiently long memory are nearly as good as any randomized FSM. For the continuous-valued case, a useful class of parametric schemes is discussed with application to the recursive least squares (RLS) algorithm."
            },
            "slug": "Universal-Schemes-for-Sequential-Decision-from-Data-Merhav-Feder",
            "title": {
                "fragments": [],
                "text": "Universal schemes for sequential decision from individual data sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that Markovian machines with sufficiently long memory are nearly as good as any randomized FSM, and a useful class of parametric schemes is discussed with application to the recursive least squares algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772099"
                        ],
                        "name": "D. Helmbold",
                        "slug": "D.-Helmbold",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Helmbold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmbold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5141514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2caa093420807f92045a826e4027426ff2dc098a",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is a weak learner if with some small probability itoutputs a hypothesis with error slightly below 50%. This paper presentssufficient conditions for weak learning.\nOur main result requires a \u201cconsistency oracle\u201d for theconcept class <inline-equation><f><ge>F</ge></f></inline-equation> which decides for a given set of examples whetherthere is a concept in <inline-equation><f><ge>F</ge></f></inline-equation> consistent with the examples. We show that such anoracle can be used to construct a computationally efficient weaklearning algorithm for <inline-equation><f><rm><ge>F</ge></rm></f></inline-equation> if<inline-equation><f><ge>F</ge></f><?Pub Caret></inline-equation> is learnable at all. We considerconsistency oracles which are allowed to give wrong answers anddiscusses how the number of incorrect answers effects the oracle's usein computationally efficient weak learning algorihms.\nWe also define \u201cweak Occam algorithms\u201d which, when given a set of <?Pub Fmt italic>m<?Pub Fmt /italic> examples, select aconsistent hypothesis from some class of2<?Pub Fmt italic><supscrpt>m-(1/p(m))</supscrpt><?Pub Fmt /italic>possible hypotheses. We show that these weak Occam algorithms are alsoweak learners. In contrast, we show that an Occam style algorithm whichselects a consistent hypothesis from a class of2<?Pub Fmt italic><supscrpt>m+1</supscrpt><?Pub Fmt /italic>-2hypotheses is not a weak learner."
            },
            "slug": "Some-weak-learning-results-Helmbold-Warmuth",
            "title": {
                "fragments": [],
                "text": "Some weak learning results"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "sufficient conditions for weak learning are presented and consistency oracles which are allowed to give wrong answers are considered and how the number of incorrect answers effects the oracle's use in computationally efficient weak learning algorihms are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516166"
                        ],
                        "name": "J. Rissanen",
                        "slug": "J.-Rissanen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Rissanen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rissanen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3337260"
                        ],
                        "name": "G. Langdon",
                        "slug": "G.-Langdon",
                        "structuredName": {
                            "firstName": "Glen",
                            "lastName": "Langdon",
                            "middleNames": [
                                "G."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Langdon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 28270470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f54bc3a24a1f01808e6e8479a11e5b0244f5523",
            "isKey": false,
            "numCitedBy": 465,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The problems arising in the modeling and coding of strings for compression purposes are discussed. The notion of an information source that simplifies and sharpens the traditional one is axiomatized, and adaptive and nonadaptive models are defined. With a measure of complexity assigned to the models, a fundamental theorem is proved which states that models that use any kind of alphabet extension are inferior to the best models using no alphabet extensions at all. A general class of so-called first-in first-out (FIFO) arithmetic codes is described which require no alphabet extension devices and which therefore can be used in conjunction with the best models. Because the coding parameters are the probabilities that define the model, their design is easy, and the application of the code is straightforward even with adaptively changing source models."
            },
            "slug": "Universal-modeling-and-coding-Rissanen-Langdon",
            "title": {
                "fragments": [],
                "text": "Universal modeling and coding"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A general class of so-called first-in first-out (FIFO) arithmetic codes is described which require no alphabet extension devices and which therefore can be used in conjunction with the best models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145675281"
                        ],
                        "name": "V. Vovk",
                        "slug": "V.-Vovk",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vovk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vovk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124421028,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0f94301a1fbb79f2368796468aa3dba49a6e04b8",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A simple example shows that the classical theory of probability implies more than one can deduce via Kolmogorov's calculus of probability. Developing Dawid's ideas I propose a new calculus of probability which is free from this drawback. This calculus naturally leads to a new interpretation of probability. I argue that attempts to create a general empirical theory of probability should be abandoned and we should content ourselves with the logic of probability establishing relations between probabilistic theories and observations. My approach to the logic of probability is based on a variant of Ville's principle of the excluded gambling strategy"
            },
            "slug": "A-logic-of-probability,-with-application-to-the-of-Vovk",
            "title": {
                "fragments": [],
                "text": "A logic of probability, with application to the foundations of statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144007105"
                        ],
                        "name": "Philip M. Long",
                        "slug": "Philip-M.-Long",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Long",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip M. Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13012680,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ed6f52a5a6ec4f30eecc35035078b5d673748528",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for the on-line learning of linear functions which is optimal to within a constant factor with respect to bounds on the sum of squared errors for a worst case sequence of trials. The bounds are logarithmic in the number of variables. Furthermore, the algorithm is shown to be optimally robust with respect to noise in the data (again to within a constant factor)."
            },
            "slug": "On-line-learning-of-linear-functions-Littlestone-Long",
            "title": {
                "fragments": [],
                "text": "On-line learning of linear functions"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An algorithm for the on-line learning of linear functions which is optimal to within a constant factor with respect to bounds on the sum of squared errors for a worst case sequence of trials is presented."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647026"
                        ],
                        "name": "A. Blumer",
                        "slug": "A.-Blumer",
                        "structuredName": {
                            "firstName": "Anselm",
                            "lastName": "Blumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1138467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0b8fa3496283d4d808fba9ff62d5f024bcf23be",
            "isKey": false,
            "numCitedBy": 1909,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant's learnability model is extended to learning classes of concepts defined by regions in Euclidean space En. The methods in this paper lead to a unified treatment of some of Valiant's results, along with previous results on distribution-free convergence of certain pattern recognition algorithms. It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, the complexity and closure properties of learnable classes are analyzed, and the necessary and sufficient conditions are provided for feasible learnability."
            },
            "slug": "Learnability-and-the-Vapnik-Chervonenkis-dimension-Blumer-Ehrenfeucht",
            "title": {
                "fragments": [],
                "text": "Learnability and the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145924374"
                        ],
                        "name": "L. Birge",
                        "slug": "L.-Birge",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Birge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Birge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3226094"
                        ],
                        "name": "P. Massart",
                        "slug": "P.-Massart",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Massart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Massart"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120362246,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3a69082f5ed81b3183b1404051e181c0d09cc5f4",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryWe shall present here a general study of minimum contrast estimators in a nonparametric setting (although our results are also valid in the classical parametric case) for independent observations. These estimators include many of the most popular estimators in various situations such as maximum likelihood estimators, least squares and other estimators of the regression function, estimators for mixture models or deconvolution... The main theorem relates the rate of convergence of those estimators to the entropy structure of the space of parameters. Optimal rates depending on entropy conditions are already known, at least for some of the models involved, and they agree with what we get for minimum contrast estimators as long as the entropy counts are not too large. But, under some circumstances (\u201clarge\u201d entropies or changes in the entropy structure due to local perturbations), the resulting the rates are only suboptimal. Counterexamples are constructed which show that the phenomenon is real for non-parametric maximum likelihood or regression. This proves that, under purely metric assumptions, our theorem is optimal and that minimum contrast estimators happen to be suboptimal."
            },
            "slug": "Rates-of-convergence-for-minimum-contrast-Birge-Massart",
            "title": {
                "fragments": [],
                "text": "Rates of convergence for minimum contrast estimators"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807137"
                        ],
                        "name": "J. Angus",
                        "slug": "J.-Angus",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Angus",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Angus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 203418927,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "647c2a06ef7a78d5ea99915594bb9afa0b67bc2c",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Asymptotic-Theory-of-Extreme-Order-Statistics-Angus",
            "title": {
                "fragments": [],
                "text": "The Asymptotic Theory of Extreme Order Statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15348764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9642a175637a400b425f0ac0cb6a2b067cc8fe6b",
            "isKey": false,
            "numCitedBy": 639,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning is posed as a problem of function estimation, for which two principles of solution are considered: empirical risk minimization and structural risk minimization. These two principles are applied to two different statements of the function estimation problem: global and local. Systematic improvements in prediction power are illustrated in application to zip-code recognition."
            },
            "slug": "Principles-of-Risk-Minimization-for-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Principles of Risk Minimization for Learning Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Systematic improvements in prediction power and empirical risk minimization are illustrated in application to zip-code recognition."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742404"
                        ],
                        "name": "A. Fiat",
                        "slug": "A.-Fiat",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Fiat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fiat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763352"
                        ],
                        "name": "Y. Rabani",
                        "slug": "Y.-Rabani",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Rabani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rabani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2326410"
                        ],
                        "name": "Yiftach Ravid",
                        "slug": "Yiftach-Ravid",
                        "structuredName": {
                            "firstName": "Yiftach",
                            "lastName": "Ravid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiftach Ravid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12096065,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "df91cfa6fad417ad17079927808e73476851878b",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Deterministic competitive k-server algorithms are given for all k and all metric spaces. This settles the k-server conjecture of M.S. Manasse et al. (1988) up to the competitive ratio. The best previous result for general metric spaces was a three-server randomized competitive algorithm and a nonconstructive proof that a deterministic three-server competitive algorithm exists. The competitive ratio the present authors can prove is exponential in the number of servers. Thus, the question of the minimal competitive ratio for arbitrary metric spaces is still open. The methods set forth here also give competitive algorithms for a natural generalization of the k-server problem, called the k-taxicab problem.<<ETX>>"
            },
            "slug": "Competitive-k-server-algorithms-Fiat-Rabani",
            "title": {
                "fragments": [],
                "text": "Competitive k-Server Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Deterministic competitive k-server algorithms are given for all k and all metric spaces and the competitive ratio can be proved is exponential in the number of servers, settling the k- server conjecture."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742404"
                        ],
                        "name": "A. Fiat",
                        "slug": "A.-Fiat",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Fiat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fiat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145346320"
                        ],
                        "name": "Dean P. Foster",
                        "slug": "Dean-P.-Foster",
                        "structuredName": {
                            "firstName": "Dean",
                            "lastName": "Foster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dean P. Foster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735932"
                        ],
                        "name": "H. Karloff",
                        "slug": "H.-Karloff",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Karloff",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Karloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763352"
                        ],
                        "name": "Y. Rabani",
                        "slug": "Y.-Rabani",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Rabani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rabani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2326410"
                        ],
                        "name": "Yiftach Ravid",
                        "slug": "Yiftach-Ravid",
                        "structuredName": {
                            "firstName": "Yiftach",
                            "lastName": "Ravid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiftach Ravid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713876"
                        ],
                        "name": "S. Vishwanathan",
                        "slug": "S.-Vishwanathan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vishwanathan",
                            "middleNames": [
                                "V.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vishwanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9595979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a305a23d24707408f1223942a191e1797a771c83",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A layered graph is a connected, weighted graph whose vertices are partitioned into sets L/sub 0/=(s), L/sub 1/, L/sub 2/, . . ., and whose edges run between consecutive layers. Its width is max( mod L/sub i/ mod ). In the online layered graph traversal problem, a searcher starts at s in a layered graph of unknown width and tries to reach a target vertex t; however, the vertices in layer i and the edges between layers i-1 and i are only revealed when the searcher reaches layer i-1. The authors give upper and lower bounds on the competitive ratio of layered graph traversal algorithms. They give a deterministic online algorithm that is O(9w)-competitive on width-w graphs and prove that for no w can a deterministic online algorithm have a competitive ratio better than 2w/sup -2/ on width-w graphs. They prove that for all w, w/2 is a lower bound on the competitive ratio of any randomized online layered graph traversal algorithm. For traversing layered graphs consisting of w disjoint paths tied together at a common source, they give a randomized online algorithm with a competitive ratio of O(log w) and prove that this is optimal up to a constant factor.<<ETX>>"
            },
            "slug": "Competitive-algorithms-for-layered-graph-traversal-Fiat-Foster",
            "title": {
                "fragments": [],
                "text": "Competitive algorithms for layered graph traversal"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "For traversing layered graphs consisting of w disjoint paths tied together at a common source, the authors give a randomized online algorithm with a competitive ratio of O(log w) and prove that this is optimal up to a constant factor."
            },
            "venue": {
                "fragments": [],
                "text": "[1991] Proceedings 32nd Annual Symposium of Foundations of Computer Science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516166"
                        ],
                        "name": "J. Rissanen",
                        "slug": "J.-Rissanen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Rissanen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rissanen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30140639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d382b9c11e5c6a8e173fbeb442545e3be8d3e3a5",
            "isKey": false,
            "numCitedBy": 6261,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modeling-By-Shortest-Data-Description*-Rissanen",
            "title": {
                "fragments": [],
                "text": "Modeling By Shortest Data Description*"
            },
            "venue": {
                "fragments": [],
                "text": "Autom."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2168339395"
                        ],
                        "name": "Muang T\u2019ai",
                        "slug": "Muang-T\u2019ai",
                        "structuredName": {
                            "firstName": "Muang",
                            "lastName": "T\u2019ai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Muang T\u2019ai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 249402522,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "505bce3bcdab58be18e6a272f27bba107f71f404",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous to the war 1914-1918, Siam had already realised the usefulness of aircraft. In 1911, the Ministry of War sent three officers of the Royal Engineer to study the art of flying in France. After having obtained their certificates, they returned to Siam in 1913. The Siamese Royal Flying Corps was then established to train pilot and organize Military Aviation. When the Siamese Government declared War on the Central Powers, in 1917, a contingent of pilots and mechanics, together with motor transport and troops, were sent to join the Allies in France. At the end of the War, owing to all the world\u2019s progress in aviation, and owing to the necessity for the development in flying service for military, and above all for civil purposes the Royal Flying Corps was then turned into the Royal Aeronautical Service; with the aim to direct general aviation of the country and to seek the ways and means of using aircraft for public benefit. On October 13, 1919, the Siamese Government signed the International Convention concerning Aerial Navigation. The Royal Aeronautical Service employs many kinds of aeroplanes for different purposes, among which are some of Siamese design."
            },
            "slug": "Siam-T\u2019ai",
            "title": {
                "fragments": [],
                "text": "Siam"
            },
            "venue": {
                "fragments": [],
                "text": "Revue Internationale de la Croix-Rouge et Bulletin international des Societes de la Croix-Rouge"
            },
            "year": 1946
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 203666198,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "b38d9053c44905054ba28824c043df0d5709affc",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Strongly adherent layers of electroless metals on glass or ceramic substrates are obtained by first applying a film of an alkali metal silicate solution containing dissolved therein a catalytically effective amount of nickel, palladium or platinum to the substrate, drying and firing the film onto the substrate and electroless plating the coated substrate."
            },
            "slug": "Efficient-Distribution-free-Learning-of-Concepts-Kearns-Schapire",
            "title": {
                "fragments": [],
                "text": "Efficient Distribution-free Learning of Probabilistic Concepts (Extended Abstract)"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Strongly adherent layers of electroless metals on glass or ceramic substrates are obtained by first applying a film of an alkali metal silicate solution containing dissolved therein a catalytically effective amount of nickel, palladium or platinum to the substrate."
            },
            "venue": {
                "fragments": [],
                "text": "FOCS 1990"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516166"
                        ],
                        "name": "J. Rissanen",
                        "slug": "J.-Rissanen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Rissanen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rissanen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120741100,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7e1ca8d081fc07e6190a3bf5e3156569d8e9c96b",
            "isKey": false,
            "numCitedBy": 1036,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "On demontre un theoreme fondamental qui donne une borne inferieure pour la longueur de code et donc, pour les erreurs de prediction. On definit les notions \u00abd'information a priori\u00bb et \u00abd'information utile\u00bb dans les donnees"
            },
            "slug": "Stochastic-Complexity-and-Modeling-Rissanen",
            "title": {
                "fragments": [],
                "text": "Stochastic Complexity and Modeling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82548657"
                        ],
                        "name": "J. Hannan",
                        "slug": "J.-Hannan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hannan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hannan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123624867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71bf3808d24c9d986fd4a2cf5d93b727479d1e81",
            "isKey": false,
            "numCitedBy": 472,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "4.-APPROXIMATION-TO-RAYES-RISK-IN-REPEATED-PLAY-Hannan",
            "title": {
                "fragments": [],
                "text": "4. APPROXIMATION TO RAYES RISK IN REPEATED PLAY"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 123127517,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ab32d9e0adf7bc2b3920ed6504617cea305cce54",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Prequential-data-analysis-Dawid",
            "title": {
                "fragments": [],
                "text": "Prequential data analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2837737"
                        ],
                        "name": "M. Talagrand",
                        "slug": "M.-Talagrand",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Talagrand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Talagrand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121540156,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "debfa130d31d4fee331519472a305ccb00c303b0",
            "isKey": false,
            "numCitedBy": 517,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sharper-Bounds-for-Gaussian-and-Empirical-Processes-Talagrand",
            "title": {
                "fragments": [],
                "text": "Sharper Bounds for Gaussian and Empirical Processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 115691358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d4f54c22ae2f3c5f9459fb012a9f9ed4c9a89e9",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Behavior-of-sequential-predictors-of-binary-Cover",
            "title": {
                "fragments": [],
                "text": "Behavior of sequential predictors of binary sequences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700597"
                        ],
                        "name": "Jyrki Kivinen",
                        "slug": "Jyrki-Kivinen",
                        "structuredName": {
                            "firstName": "Jyrki",
                            "lastName": "Kivinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyrki Kivinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60798959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78fa2bef9cca6a6b1c11e7bd50631618d0660260",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Using-experts-for-predicting-continuous-outcomes-Kivinen-Warmuth",
            "title": {
                "fragments": [],
                "text": "Using experts for predicting continuous outcomes"
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 52817629,
            "fieldsOfStudy": [],
            "id": "f8a1f40e6b820e5f2fdd543dab32ad8fc74a750c",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient Distribution-Free Learning of Probabilistic Concepts"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145675281"
                        ],
                        "name": "V. Vovk",
                        "slug": "V.-Vovk",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vovk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vovk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5226318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f80ae7531ae8c8e06f53ca78d5ad8a2dfbc8697",
            "isKey": false,
            "numCitedBy": 714,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Aggregating-strategies-Vovk",
            "title": {
                "fragments": [],
                "text": "Aggregating strategies"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '90"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On weak learning EEcient distribution-free learning of probabilistic concepts"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Computer and System Sciences Journal of Computer and System Sciences"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Universal sequential coding of single messages. Problems of Information Transmission"
            },
            "venue": {
                "fragments": [],
                "text": "Universal sequential coding of single messages. Problems of Information Transmission"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prequential analysis, stochastic complexity and Bayesian inference"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian Statistics"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A. Proof of Lemma"
            },
            "venue": {
                "fragments": [],
                "text": "A. Proof of Lemma"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Asymptotic Theo7y o.f EztTeme O'redeT Statwtics"
            },
            "venue": {
                "fragments": [],
                "text": "The Asymptotic Theo7y o.f EztTeme O'redeT Statwtics"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical theory: The prequential approach"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical theory: The prequential approach"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Competitive paging algorithms. Jouma/ of Algo- rithms"
            },
            "venue": {
                "fragments": [],
                "text": "Competitive paging algorithms. Jouma/ of Algo- rithms"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Universal prediction of individual sequences Competitive k-server algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory Journal of Computer and System Sciences"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimation of Dependences"
            },
            "venue": {
                "fragments": [],
                "text": "Based on Empirical Data. Springer-Verlag,"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximation to Bayes risk in repeated play. In Contr-ibutions to the theoTy of games"
            },
            "venue": {
                "fragments": [],
                "text": "Approximation to Bayes risk in repeated play. In Contr-ibutions to the theoTy of games"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Coding of discrete sources with unknown statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Topics in Information Theory"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Networks: a comprehensive foundation HBar] David Haussler and Andrew Barron. How well do Bayes methods work for online prediction of f+1; ?1gvalues?"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedingsof the Third NEC Symposium on Computation and Cognition. SIAM"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Universal sequential coding of single messages"
            },
            "venue": {
                "fragments": [],
                "text": "Prob. Inf. Transm"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prequential analysis, stochastic complexity and Bayesian inference"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian Statistics"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Universal modeling and coding Statistical mechanics of learning from examples Cross-validation: a review"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory Physical Review A Math. Operationforsch. Statist. Ser. Statist"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modeling by shortest data"
            },
            "venue": {
                "fragments": [],
                "text": "description. Automatica,"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Jou'rnai of the Royal Statistical Society, SeTies A"
            },
            "venue": {
                "fragments": [],
                "text": "Jou'rnai of the Royal Statistical Society, SeTies A"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Universal forecasting algorithms. Inf. Comput. 96, 2 (Feb.), 245\u2013277"
            },
            "venue": {
                "fragments": [],
                "text": "VOVK, V. G"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prequential probability theory"
            },
            "venue": {
                "fragments": [],
                "text": "Unpublished manuscript,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Behaviour of sequential predictors of binary sequences. In Transactions of the Fourth Prague Conference on Information Theory, Statistical Decision Functions, Random Processes, pages 263{272"
            },
            "venue": {
                "fragments": [],
                "text": "Publishing House of the Czechoslovak Academy of Sciences,"
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Predicting f0; 1g- functions on randomly drawn points On weak learning"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Computer and System Sciences"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How w ell do Bayes methods work for on-line prediction of f+1; ,1g values"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Third NEC Symposium on Computation and Cognition. SIAM"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic complexity and modeling. The Annals of Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Stochastic complexity and modeling. The Annals of Statistics"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cross-validation: A review"
            },
            "venue": {
                "fragments": [],
                "text": "Math. Operationforsch. Statist. Ser Statist"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Behaviourof sequential predictors of binary sequences In Transactions o.f the Fourth Prague Con.feTence on Information Theory, Statistical Decision Functions, Random PTocesses"
            },
            "venue": {
                "fragments": [],
                "text": "Publishing House of the Czechoslovak Academy of Sciences"
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The weighted majority al- gorithm"
            },
            "venue": {
                "fragments": [],
                "text": "30th Annual IEEE Symposium on Foundations of ComputeT Science"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Universal sequential coding of single messages. Problems of Information Transmission"
            },
            "venue": {
                "fragments": [],
                "text": "Universal sequential coding of single messages. Problems of Information Transmission"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical theory: The prequential approach"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Royal Statistical Society, Series A"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How well do Bayes methods work for on-line prediction of {)1, \"1} values? In Proceedings of the 3rd NEC Symposium on Computation and Cognition"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prequential probability theory. Unpublished manuscript"
            },
            "venue": {
                "fragments": [],
                "text": "Prequential probability theory. Unpublished manuscript"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Toward e cient agnostic learning"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Coding of descrete sources with unknown statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Topics in Information Theory"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic complexity and modeling. The Annals of Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Stochastic complexity and modeling. The Annals of Statistics"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prequential data analysis. Ctiment Issues in Statistical Inference"
            },
            "venue": {
                "fragments": [],
                "text": "Prequential data analysis. Ctiment Issues in Statistical Inference"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical theory: The prequential approach"
            },
            "venue": {
                "fragments": [],
                "text": "J. Roy. Stat. Soc., Series A"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Universal modeling and coding Coding of descrete sources with unknown statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Topics in Information Theory"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cross-validation: a review"
            },
            "venue": {
                "fragments": [],
                "text": "Math. Operationforsch. Statist. Ser. Statist"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cross-validation: a review"
            },
            "venue": {
                "fragments": [],
                "text": "Math. Operationforsch. Statist. Ser. Statist"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximation to Bayes risk in repeated play. I n Contributions to the theory of games, v olume 3, pages 977139"
            },
            "venue": {
                "fragments": [],
                "text": "Hay944 S. Haykin. Neural Networks: a comprehensive foundation. Macmillan"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How well do Bayes methods work for on-line prediction of {11, 21} values? In Proceedings of the 3rd NEC Symposium on Computation and Cognition"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prequential analysis, stochastic complexity and Bayesian inference"
            },
            "venue": {
                "fragments": [],
                "text": "In Bayesian Statistics"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Coding of descrete sources with unknown statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Topics in Information Theory,"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prequential analysis, stochastic complexity and Bayesian inference"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian Statistics"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 86,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/How-to-use-expert-advice-Cesa-Bianchi-Freund/239ae23dc2f934cfa005261ade01023fe7950b82?sort=total-citations"
}