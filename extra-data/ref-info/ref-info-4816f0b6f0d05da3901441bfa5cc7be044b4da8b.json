{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727853"
                        ],
                        "name": "John K. Tsotsos",
                        "slug": "John-K.-Tsotsos",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tsotsos",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John K. Tsotsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2888197"
                        ],
                        "name": "Sean M. Culhane",
                        "slug": "Sean-M.-Culhane",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Culhane",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean M. Culhane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676061"
                        ],
                        "name": "W. Y. Wai",
                        "slug": "W.-Y.-Wai",
                        "structuredName": {
                            "firstName": "Winky",
                            "lastName": "Wai",
                            "middleNames": [
                                "Yan",
                                "Kei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Y. Wai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399956386"
                        ],
                        "name": "Yuzhong Lai",
                        "slug": "Yuzhong-Lai",
                        "structuredName": {
                            "firstName": "Yuzhong",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuzhong Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070037776"
                        ],
                        "name": "Neal Davis",
                        "slug": "Neal-Davis",
                        "structuredName": {
                            "firstName": "Neal",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neal Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397804046"
                        ],
                        "name": "Fernando Nuflo",
                        "slug": "Fernando-Nuflo",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Nuflo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Nuflo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 246
                            }
                        ],
                        "text": "The attended region is selected through dynamic modifications of cortical connectivity or through the establishment of specific temporal patterns of activity, under both top-down (task-dependent) and bottom-up (scene-dependent) control [3], [2], [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "Intermediate and higher visual processes appear to select a subset of the available sensory information before further processing [1], most likely to reduce the complexity of scene analysis [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "Although eye trajectories can differ from attentional trajectories under volitional control [1], visual attention is often thought as a preocculomotor mechanism, strongly influencing free-viewing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "The SM feeds into a biologicallyplausible 2D \u201cwinner-take-all\u201d (WTA) neural network [4], [1] at scale s = 4, in which synaptic interactions among units ensure that only the most active location remains, while all other locations are suppressed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "Although the concept of a saliency map has been widely used in FOA models [1], [3], [7], little detail is usually provided about its construction and dynamics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32094988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8930f62a4b5eb1cbabf224cf84aa009ea798cfee",
            "isKey": true,
            "numCitedBy": 1211,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modeling-Visual-Attention-via-Selective-Tuning-Tsotsos-Culhane",
            "title": {
                "fragments": [],
                "text": "Modeling Visual Attention via Selective Tuning"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "Such strong performance reinforces the idea that a unique saliency map, receiving input from early visual processes, could effectively guide bottom-up attention in primates [4], [10], [5], [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "The SM feeds into a biologicallyplausible 2D \u201cwinner-take-all\u201d (WTA) neural network [4], [1] at scale s = 4, in which synaptic interactions among units ensure that only the most active location remains, while all other locations are suppressed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "1) builds on a second biologicallyplausible architecture, proposed by Koch and Ullman [4] and at the basis of several models [5], [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 263
                            }
                        ],
                        "text": "In order to slightly bias the model to subsequently jump to salient locations spatially close to the currently-attended location, a small excitation is transiently activated in the SM, in a near surround of the FOA (\u201cproximity preference\u201d rule of Koch and Ullman [4])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45203429,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6",
            "isKey": false,
            "numCitedBy": 3958,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Psychophysical and physiological evidence indicates that the visual system of primates and humans has evolved a specialized processing focus moving across the visual scene. This study addresses the question of how simple networks of neuron-like elements can account for a variety of phenomena associated with this shift of selective visual attention. Specifically, we propose the following: (1) A number of elementary features, such as color, orientation, direction of movement, disparity etc. are represented in parallel in different topographical maps, called the early representation. (2) There exists a selective mapping from the early topographic representation into a more central non-topographic representation, such that at any instant the central representation contains the properties of only a single location in the visual scene, the selected location. We suggest that this mapping is the principal expression of early selective visual attention. One function of selective attention is to fuse information from different maps into one coherent whole. (3) Certain selection rules determine which locations will be mapped into the central representation. The major rule, using the conspicuity of locations in the early representation, is implemented using a so-called Winner-Take-All network. Inhibiting the selected location in this network causes an automatic shift towards the next most conspicious location. Additional rules are proximity and similarity preferences. We discuss how these rules can be implemented in neuron-like networks and suggest a possible role for the extensive back-projection from the visual cortex to the LGN."
            },
            "slug": "Shifts-in-selective-visual-attention:-towards-the-Koch-Ullman",
            "title": {
                "fragments": [],
                "text": "Shifts in selective visual attention: towards the underlying neural circuitry."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This study addresses the question of how simple networks of neuron-like elements can account for a variety of phenomena associated with this shift of selective visual attention and suggests a possible role for the extensive back-projection from the visual cortex to the LGN."
            },
            "venue": {
                "fragments": [],
                "text": "Human neurobiology"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3334304"
                        ],
                        "name": "Yiqun Hu",
                        "slug": "Yiqun-Hu",
                        "structuredName": {
                            "firstName": "Yiqun",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiqun Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144076239"
                        ],
                        "name": "Xing Xie",
                        "slug": "Xing-Xie",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144029642"
                        ],
                        "name": "L. Chia",
                        "slug": "L.-Chia",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Chia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145383458"
                        ],
                        "name": "D. Rajan",
                        "slug": "D.-Rajan",
                        "structuredName": {
                            "firstName": "Deepu",
                            "lastName": "Rajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rajan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14073796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "212935413b49076d3d6a5520ac234af41a0c137d",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Detection of salient regions in images is useful for object based image retrieval and browsing applications. This task can be done using methods based on the human visual attention model [1], where feature maps corresponding to color, intensity and orientation capture the corresponding salient regions. In this paper, we propose a strategy for combining the salient regions from the individual feature maps based on a new Composite Saliency Indicator (CSI) which measures the contribution of each feature map to saliency. The method also carries out a dynamic weighting of individual feature maps. The experiment results indicate that this combination strategy reflects the salient regions in an image more accurately."
            },
            "slug": "Salient-Region-Detection-Using-Weighted-Feature-on-Hu-Xie",
            "title": {
                "fragments": [],
                "text": "Salient Region Detection Using Weighted Feature Maps Based on the Human Visual Attention Model"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a strategy for combining the salient regions from the individual feature maps based on a new Composite Saliency Indicator (CSI) which measures the contribution of each feature map to saliency."
            },
            "venue": {
                "fragments": [],
                "text": "PCM"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80317385"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Olshausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143718183"
                        ],
                        "name": "C. Anderson",
                        "slug": "C.-Anderson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Anderson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392063491"
                        ],
                        "name": "D. van Essen",
                        "slug": "D.-van-Essen",
                        "structuredName": {
                            "firstName": "D. C.",
                            "lastName": "van Essen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. van Essen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Although the concept of a saliency map has been widely used in FOA models [1], [3], [7], little detail is usually provided about its construction and dynamics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 236
                            }
                        ],
                        "text": "The attended region is selected through dynamic modifications of cortical connectivity or through the establishment of specific temporal patterns of activity, under both top-down (task-dependent) and bottom-up (scene-dependent) control [3], [2], [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1118263,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "700bbcd3518ca8cb3dac50a89fc69cad3dc1a579",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 146,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a biologically plausible model of an attentional mechanism for forming position- and scale-invariant representations of objects in the visual world. The model relies on a set of control neurons to dynamically modify the synaptic strengths of intracortical connections so that information from a windowed region of primary visual cortex (V1) is selectively routed to higher cortical areas. Local spatial relationships (i.e., topography) within the attentional window are preserved as information is routed through the cortex. This enables attended objects to be represented in higher cortical areas within an object-centered reference frame that is position and scale invariant. We hypothesize that the pulvinar may provide the control signals for routing information through the cortex. The dynamics of the control neurons are governed by simple differential equations that could be realized by neurobiologically plausible circuits. In preattentive mode, the control neurons receive their input from a low-level \u201csaliency map\u201d representing potentially interesting regions of a scene. During the pattern recognition phase, control neurons are driven by the interaction between top-down (memory) and bottom-up (retinal input) sources. The model respects key neurophysiological, neuroanatomical, and psychophysical data relating to attention, and it makes a variety of experimentally testable predictions."
            },
            "slug": "A-neurobiological-model-of-visual-attention-and-on-Olshausen-Anderson",
            "title": {
                "fragments": [],
                "text": "A neurobiological model of visual attention and invariant pattern recognition based on dynamic routing of information"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A biologically plausible model of an attentional mechanism for forming position- and scale-invariant representations of objects in the visual world that respects key neurophysiological, neuroanatomical, and psychophysical data relating to attention, and it makes a variety of experimentally testable predictions."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48855558"
                        ],
                        "name": "D. Pomerleau",
                        "slug": "D.-Pomerleau",
                        "structuredName": {
                            "firstName": "Dean",
                            "lastName": "Pomerleau",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pomerleau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "1) builds on a second biologicallyplausible architecture, proposed by Koch and Ullman [4] and at the basis of several models [5], [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2326351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05efb2d26f594ad966afb62f25acfa8d9bc4c433",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Expectation-based-selective-attention-for-visual-of-Baluja-Pomerleau",
            "title": {
                "fragments": [],
                "text": "Expectation-based selective attention for visual monitoring and control of a robot vehicle"
            },
            "venue": {
                "fragments": [],
                "text": "Robotics Auton. Syst."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1927015"
                        ],
                        "name": "R. Milanese",
                        "slug": "R.-Milanese",
                        "structuredName": {
                            "firstName": "Ruggero",
                            "lastName": "Milanese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Milanese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143820393"
                        ],
                        "name": "S. Gil",
                        "slug": "S.-Gil",
                        "structuredName": {
                            "firstName": "Sylvia",
                            "lastName": "Gil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809085"
                        ],
                        "name": "T. Pun",
                        "slug": "T.-Pun",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Pun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 184
                            }
                        ],
                        "text": "Such strong performance reinforces the idea that a unique saliency map, receiving input from early visual processes, could effectively guide bottom-up attention in primates [4], [10], [5], [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "More than previous models based extensively on relaxation techniques [5], our architecture could easily allow for real-time operation on dedicated hardware."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 141
                            }
                        ],
                        "text": "In addition, at present, our model does not include any magnocellular motion channel, which is known to play a strong role in human saliency [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": ") is faster and simpler than previously-proposed iterative schemes [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 220
                            }
                        ],
                        "text": "Using several scales not only for c but also for d = s - c yields truly multiscale feature extraction, by including different size ratios between the center and surround regions (contrary to previously used fixed ratios [5])."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "1) builds on a second biologicallyplausible architecture, proposed by Koch and Ullman [4] and at the basis of several models [5], [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124575459,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "cd48fdb3a351eb5e0eb5bed5bfd88c0a225b47f6",
            "isKey": true,
            "numCitedBy": 107,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Attention mechanisms extract regions of interest from image data to reduce the amount of information to be analyzed by time-consuming processes such as image transmission, robot navigation, and object recognition. Two such mechanisms are described. The first one is an alerting system that extracts moving objects in a sequence through the use of multiresolution representations. The second one detects regions in still images that are likely to contain objects of interest. Two types of cues are used and integrated to compute the measure of interest. First, bottom-up cues result from the decomposition of the input image into a number of feature and conspicuity maps. The second type of cues is top-down, and is obtained from a priori knowledge about target objects, represented through invariant models. Results are reported for both the alerting and the attention mechanisms using cluttered and noisy scenes."
            },
            "slug": "Attentive-mechanisms-for-dynamic-and-static-scene-Milanese-Gil",
            "title": {
                "fragments": [],
                "text": "Attentive mechanisms for dynamic and static scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An alerting system that extracts moving objects in a sequence through the use of multiresolution representations, and a detection system that detects regions in still images that are likely to contain objects of interest."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3662180"
                        ],
                        "name": "G. Gelade",
                        "slug": "G.-Gelade",
                        "structuredName": {
                            "firstName": "Garry",
                            "lastName": "Gelade",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gelade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "The model was able to reproduce human performance for a number of pop-out tasks [7], using images of the type shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "Both results have been widely observed in humans [7] and are discussed in Section 3."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "It is related to the so-called \u201cfeature integration theory,\u201d explaining human visual search strategies [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "Although the concept of a saliency map has been widely used in FOA models [1], [3], [7], little detail is usually provided about its construction and dynamics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 271
                            }
                        ],
                        "text": "The type of performance which can be expected from this model critically depends on one factor: Only object features explicitly represented in at least one of the feature maps can lead to pop-out, that is, rapid detection independent of the number of distracting objects [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 353246,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "76361a44e145732a39dbc68d9418871038c83be2",
            "isKey": true,
            "numCitedBy": 11415,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-feature-integration-theory-of-attention-Treisman-Gelade",
            "title": {
                "fragments": [],
                "text": "A feature-integration theory of attention"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11563784"
                        ],
                        "name": "J. Gottlieb",
                        "slug": "J.-Gottlieb",
                        "structuredName": {
                            "firstName": "Jacqueline",
                            "lastName": "Gottlieb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gottlieb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7942958"
                        ],
                        "name": "M. Kusunoki",
                        "slug": "M.-Kusunoki",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Kusunoki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kusunoki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144060290"
                        ],
                        "name": "M. Goldberg",
                        "slug": "M.-Goldberg",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goldberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 189
                            }
                        ],
                        "text": "Such strong performance reinforces the idea that a unique saliency map, receiving input from early visual processes, could effectively guide bottom-up attention in primates [4], [10], [5], [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "In primates, such a map is believed to be located in the posterior parietal cortex [8] as well as in the various visual maps in the pulvinar nuclei of the thalamus [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4373687,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "839e0a5e15fec789181285d57c9fad2b26bd0042",
            "isKey": false,
            "numCitedBy": 1084,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "When natural scenes are viewed, a multitude of objects that are stable in their environments are brought in and out of view by eye movements. The posterior parietal cortex is crucial for the analysis of space, visual attention and movement. Neurons in one of its subdivisions, the lateral intraparietal area (LIP), have visual responses to stimuli appearing abruptly at particular retinal locations (their receptive fields). We have tested the responses of LIP neurons to stimuli that entered their receptive field by saccades. Neurons had little or no response to stimuli brought into their receptive field by saccades, unless the stimuli were behaviourally significant. We established behavioural significance in two ways: either by making a stable stimulus task-relevant, or by taking advantage of the attentional attraction of an abruptly appearing stimulus. Our results show that under ordinary circumstances the entire visual world is only weakly represented in LIP. The visual representation in LIP is sparse, with only the mostsalient or behaviourally relevant objects being strongly represented."
            },
            "slug": "The-representation-of-visual-salience-in-monkey-Gottlieb-Kusunoki",
            "title": {
                "fragments": [],
                "text": "The representation of visual salience in monkey parietal cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results show that under ordinary circumstances the entire visual world is only weakly represented in LIP, with only the most salient or behaviourally relevant objects being strongly represented."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717172"
                        ],
                        "name": "J. Wolfe",
                        "slug": "J.-Wolfe",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wolfe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "Such strong performance reinforces the idea that a unique saliency map, receiving input from early visual processes, could effectively guide bottom-up attention in primates [4], [10], [5], [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": ", knowledge about targets to be found) was used to weight the importance of different features [10], such that only those with high weights could reach higher processing levels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16901865,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a52b81b322087ce82e4ec4124b3a47cbb391a0eb",
            "isKey": false,
            "numCitedBy": 3423,
            "numCiting": 347,
            "paperAbstract": {
                "fragments": [],
                "text": "An important component of routine visual behavior is the ability to find one item in a visual world filled with other, distracting items. This ability to performvisual search has been the subject of a large body of research in the past 15 years. This paper reviews the visual search literature and presents a model of human search behavior. Built upon the work of Neisser, Treisman, Julesz, and others, the model distinguishes between a preattentive, massively parallel stage that processes information about basic visual features (color, motion, various depth cues, etc.) across large portions of the visual field and a subsequent limited-capacity stage that performs other, more complex operations (e.g., face recognition, reading, object identification) over a limited portion of the visual field. The spatial deployment of the limited-capacity process is under attentional control. The heart of the guided search model is the idea that attentional deployment of limited resources isguided by the output of the earlier parallel processes. Guided Search 2.0 (GS2) is a revision of the model in which virtually all aspects of the model have been made more explicit and/or revised in light of new data. The paper is organized into four parts: Part 1 presents the model and the details of its computer simulation. Part 2 reviews the visual search literature on preattentive processing of basic features and shows how the GS2 simulation reproduces those results. Part 3 reviews the literature on the attentional deployment of limited-capacity processes in conjunction and serial searches and shows how the simulation handles those conditions. Finally, Part 4 deals with shortcomings of the model and unresolved issues."
            },
            "slug": "Guided-Search-2.0-A-revised-model-of-visual-search-Wolfe",
            "title": {
                "fragments": [],
                "text": "Guided Search 2.0 A revised model of visual search"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper reviews the visual search literature and presents a model of human search behavior, a revision of the guided search 2.0 model in which virtually all aspects of the model have been made more explicit and/or revised in light of new data."
            },
            "venue": {
                "fragments": [],
                "text": "Psychonomic bulletin & review"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230937"
                        ],
                        "name": "D. Robinson",
                        "slug": "D.-Robinson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Robinson",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Robinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1878109"
                        ],
                        "name": "S. Petersen",
                        "slug": "S.-Petersen",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Petersen",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Petersen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 164
                            }
                        ],
                        "text": "In primates, such a map is believed to be located in the posterior parietal cortex [8] as well as in the various visual maps in the pulvinar nuclei of the thalamus [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36549185,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "8b44c60b375d680d94d4a7f59ec62e1f0f6e863a",
            "isKey": false,
            "numCitedBy": 458,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-pulvinar-and-visual-salience-Robinson-Petersen",
            "title": {
                "fragments": [],
                "text": "The pulvinar and visual salience"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Neurosciences"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38821562"
                        ],
                        "name": "M. Cannon",
                        "slug": "M.-Cannon",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Cannon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cannon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4384232"
                        ],
                        "name": "S. Fullenkamp",
                        "slug": "S.-Fullenkamp",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Fullenkamp",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fullenkamp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 177
                            }
                        ],
                        "text": ") is that it coarsely replicates cortical lateral inhibition mechanisms, in which neighboring similar features inhibit each other via specific, anatomically defined connections [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": ") have been observed in the nonclassical receptive field of cells in striate and extrastriate cortex [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17533322,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "bd8aa2f3c9f00415eba725bfcd2bfa903ace6b90",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-model-for-inhibitory-lateral-interaction-effects-Cannon-Fullenkamp",
            "title": {
                "fragments": [],
                "text": "A model for inhibitory lateral interaction effects in perceived contrast"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2332652"
                        ],
                        "name": "S. Engel",
                        "slug": "S.-Engel",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Engel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Engel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108070325"
                        ],
                        "name": "Xuemei M. Zhang",
                        "slug": "Xuemei-M.-Zhang",
                        "structuredName": {
                            "firstName": "Xuemei",
                            "lastName": "Zhang",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuemei M. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022202"
                        ],
                        "name": "B. Wandell",
                        "slug": "B.-Wandell",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Wandell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Wandell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "Such spatial and chromatic opponency exists for the red/green, green/red, blue/yellow, and yellow/blue color pairs in human primary visual cortex [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4333525,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "17feb063229cab01ca65cc9e2b19dc3ed994faa9",
            "isKey": false,
            "numCitedBy": 355,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The primate retina contains three classes of cones, the L, M and S cones, which respond preferentially to long-, middle- and short-wavelength visible light, respectively. Colour appearance results from neural processing of these cone signals within the retina and the brain. Perceptual experiments have identified three types of neural pathways that represent colour: a red\u2013green pathway that signals differences between L- and M-cone responses; a blue\u2013yellow pathway that signals differences between S-cone responses and a sum of L- and M-cone responses; and a luminance pathway that signals a sum of L- and M-cone responses. It might be expected that there are neurons in the primary visual cortex with response properties that resemble these three perceptual pathways, but attempts to find them have led to inconsistent results. We have therefore used functional magnetic resonance imaging (fMRI) to examine responses in the human brain to a large number of colours. In visual cortical areas V1 and V2, the strongest response is to red\u2013green stimuli, and much of this activity is from neurons receiving opposing inputs from L and M cones. A strong response is also seen with blue\u2013yellow stimuli, and this response declines rapidly as the temporal frequency of the stimulus is increased. These responses resemble psychophysical measurements, suggesting that colour signals relevant for perception are encoded in a large population of neurons in areas V1 and V2."
            },
            "slug": "Colour-tuning-in-human-visual-cortex-measured-with-Engel-Zhang",
            "title": {
                "fragments": [],
                "text": "Colour tuning in human visual cortex measured with functional magnetic resonance imaging"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Functional magnetic resonance imaging is used to examine responses in the human brain to a large number of colours, suggesting that colour signals relevant for perception are encoded in a large population of neurons in areas V1 and V2."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393626964"
                        ],
                        "name": "I. Kov\u00e1cs",
                        "slug": "I.-Kov\u00e1cs",
                        "structuredName": {
                            "firstName": "Ilona",
                            "lastName": "Kov\u00e1cs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kov\u00e1cs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326400"
                        ],
                        "name": "B. Julesz",
                        "slug": "B.-Julesz",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Julesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Julesz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 224
                            }
                        ],
                        "text": "For simplicity, we also have not implemented any recurrent mechanism within the feature maps and, hence, cannot reproduce phenomena like contour completion and closure, which are important for certain types of human pop-out [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 189925,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "8f28efa8aefbe0ac8592199e1e9a530f3d7b1f2c",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Detection of fragmented closed contours against a cluttered background occurs much beyond the local coherence distance (maximal separation between segments) of nonclosed contours. This implies that the extent of interaction between locally connected detectors is boosted according to the global stimulus structure. We further show that detection of a target probe is facilitated when the probe is positioned inside a closed circle. To explain the striking contour segregation ability found here, and performance enhancement inside closed boundaries, we propose the existence of a synergetic process in early vision."
            },
            "slug": "A-closed-curve-is-much-more-than-an-incomplete-one:-Kov\u00e1cs-Julesz",
            "title": {
                "fragments": [],
                "text": "A closed curve is much more than an incomplete one: effect of closure in figure-ground segmentation."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The existence of a synergetic process in early vision is proposed, and the striking contour segregation ability found here, and performance enhancement inside closed boundaries are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21484174"
                        ],
                        "name": "A. Leventhal",
                        "slug": "A.-Leventhal",
                        "structuredName": {
                            "firstName": "Audie",
                            "lastName": "Leventhal",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leventhal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "The first set of feature maps is concerned with intensity contrast, which, in mammals, is detected by neurons sensitive either to dark centers on bright surrounds or to bright centers on dark surrounds [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 215
                            }
                        ],
                        "text": "(Gabor filters, which are the product of a cosine grating and a 2D Gaussian envelope, approximate the receptive field sensitivity profile (impulse response) of orientation-selective neurons in primary visual cortex [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 263
                            }
                        ],
                        "text": "Such an architecture, sensitive to local spatial discontinuities, is particularly well-suited to detecting locations which stand out from their surround and is a general computational principle in the retina, lateral geniculate nucleus, and primary visual cortex [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 83426345,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "a6dfb84972c49f6ced0868599fbd81d4fe4e2287",
            "isKey": true,
            "numCitedBy": 460,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Topography of visual cortical area in cats and primates electrophysiological basis of eye movements in primates functional properties of the different classes of retinal ganglion cells receptive field structure of retinal ganglion cells in cats and monkeys electrophysiology of the LGNs in higher mammals inhibitory mechanisms in the visual cortex electrophysiology of the superior colliculus in subprimate species electrophysiolgy of the superior colliculus in subprimate species electrophysiology of the inner nuclear and inner plexiform layers of the retina the accessory optic system electrophysiology of the pulvinar in higher mammals quantitative electrophysiology of visual cortical neurons cat area 17 - laminer organization electrophysiology studies of the columnar organization of the visual cortex in higher mammals electrophysiology of colour vision in the retinogeniculocortical pathways intracellular recordings in visual pathways receptive field properties of extrastriate cortical neurons in subprimate species afferent inputs and receptive field properties of cells in different layers of striate cortex in cat and monkey receptive field structure of cells in visual cortex electrophysiology of vision beyond extrastriate cortex."
            },
            "slug": "The-neural-basis-of-visual-function-Leventhal",
            "title": {
                "fragments": [],
                "text": "The neural basis of visual function"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Electrophysiology of colour vision in the retinogeniculocortical pathways intracellular recordings in visual pathways receptive field properties of extrastriate cortical neurons in subprimate species afferent inputs and receptive field structures of cells in different layers of striate cortex in cat and monkey receptive field structure in visual cortex electrophysiological basis of vision beyond extrastiate cortex."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145135018"
                        ],
                        "name": "R. Goodman",
                        "slug": "R.-Goodman",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Goodman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Goodman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2291646"
                        ],
                        "name": "S. Rakshit",
                        "slug": "S.-Rakshit",
                        "structuredName": {
                            "firstName": "Subrata",
                            "lastName": "Rakshit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rakshit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143718183"
                        ],
                        "name": "C. Anderson",
                        "slug": "C.-Anderson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Anderson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Anderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "Repeat Similar Procedure for Orientation \u25cf Compute Gabor Pyramid \u25cb Gaussian pyramid with additional complex exponential term in low pass filter [4]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8344447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c7349eed0d13a1740286196db7bc83f40a88e85",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A given (overcomplete) discrete oriented pyramid may be converted into a steerable pyramid by interpolation. We present a technique for deriving the optimal interpolation functions (otherwise called 'steering coefficients'). The proposed scheme is demonstrated on a computationally efficient oriented pyramid, which is a variation on the Burt and Adelson (1983) pyramid. We apply the generated steerable pyramid to orientation-invariant texture analysis in order to demonstrate its excellent rotational isotropy. High classification rates and precise rotation identification are demonstrated.<<ETX>>"
            },
            "slug": "Overcomplete-steerable-pyramid-filters-and-rotation-Greenspan-Belongie",
            "title": {
                "fragments": [],
                "text": "Overcomplete steerable pyramid filters and rotation invariance"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A technique for deriving the optimal interpolation functions (otherwise called 'steering coefficients') is presented and the generated steerable pyramid is applied to orientation-invariant texture analysis in order to demonstrate its excellent rotational isotropy."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59751231,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3e47f452e612d354961ac1308210d66a6f4bbc73",
            "isKey": false,
            "numCitedBy": 729,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The membrane equation 2. Linear cable theory 3. Passive dendritic trees 4. Synaptic input 5. Synaptic interactions in a passive dendritic tree 6. The Hodgkin-Huxley model of action-potential generation 7. Phase space analysis of neuronal excitability 8. Ionic channels 9. Beyond Hodgkin and Huxley: calcium, and calcium-dependent potassium currents 10. Linearizing voltage-dependent currents 11. Diffusion, buffering, and binding 12. Dendritic spines 13. Synaptic plasticity 14. Simplified models of individual neurons 15. Stochastic models of single cells 16. Bursting cells 17. Input resistance, time constants, and spike initiation 18. Synaptic input to a passive tree 19. Voltage-dependent events in the dendritic tree 20. Unconventional coupling 21. Computing with neurons - a summary"
            },
            "slug": "Biophysics-of-Computation:-Information-Processing-Koch",
            "title": {
                "fragments": [],
                "text": "Biophysics of Computation: Information Processing in Single Neurons (Computational Neuroscience Series)"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents simplified models of individual neurons, and unconventional coupling, of action-potential generation and phase space analysis of neuronal excitability in response to the Hodgkin-Huxley model."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 11
                            }
                        ],
                        "text": "Similar to Reinagel and Zador\u2019s findings, the SFC at attended locations was significantly higher than the average SFC, by a factor decreasing from 2.5 \u00b1 0.05 at the first attended location to 1.6 \u00b1 0.05\nat the eighth attended location."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Comparison with spatial frequency content models Reinagel and Zador [18] recently used an eye-tracking device to analyze the local spatial frequency distributions along eye scan paths generated by humans while free-viewing grayscale images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 92
                            }
                        ],
                        "text": "It was, hence, interesting to investigate whether our model would reproduce the findings of Reinagel and Zador."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Reinagel and Zador [18] recently used an eye-tracking device to analyze the local spatial frequency distributions along eye scan paths generated by humans while free-viewing gray-scale images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 97
                            }
                        ],
                        "text": "Model predictions were compared to the measure of local SFC, in an experiment similar to that of Reinagel and Zador [18], using natural scenes with salient traffic signs (90 images), a red soda can (104 images), or a vehicle\u2019s emergency triangle symbol (64 images)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Zador, \\The E ect of Gaze on Natural Scene Statis-  tics,\" Neural information and coding workshop"
            },
            "venue": {
                "fragments": [],
                "text": "Snowbird, Utah,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Model predictions were compared to the measure of local SFC, in an experiment similar to that of Reinagel and Zador [18], using natural scenes with salient traffic signs (90 images), a red soda can (104 images), or a vehicle\u2019s emergency triangle symbol (64 images)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 11
                            }
                        ],
                        "text": "Similar to Reinagel and Zador\u2019s findings, the SFC at attended locations was significantly higher than the average SFC, by a factor decreasing from 2.5 \u00b1 0.05 at the first attended location to 1.6 \u00b1 0.05\nat the eighth attended location."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 92
                            }
                        ],
                        "text": "It was, hence, interesting to investigate whether our model would reproduce the findings of Reinagel and Zador."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Reinagel and Zador [18] recently used an eye-tracking device to analyze the local spatial frequency distributions along eye scan paths generated by humans while free-viewing gray-scale images."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Zador, \u201cThe Effect of Gaze on Natural Scene Statistics,"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Information and Coding Workshop, Snowbird, Utah,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Model predictions were compared to the measure of local SFC, in an experiment similar to that of Reinagel and Zador [18], using natural scenes with salient traffic signs (90 images), a red soda can (104 images), or a vehicle\u2019s emergency triangle symbol (64 images)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 11
                            }
                        ],
                        "text": "Similar to Reinagel and Zador\u2019s findings, the SFC at attended locations was significantly higher than the average SFC, by a factor decreasing from 2.5 \u00b1 0.05 at the first attended location to 1.6 \u00b1 0.05\nat the eighth attended location."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 92
                            }
                        ],
                        "text": "It was, hence, interesting to investigate whether our model would reproduce the findings of Reinagel and Zador."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Reinagel and Zador [18] recently used an eye-tracking device to analyze the local spatial frequency distributions along eye scan paths generated by humans while free-viewing gray-scale images."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Effect of Gaze on Natural Scene Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Information and Coding Workshop, Snowbird, Utah, 16-20 Mar. 1997."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2262729"
                        ],
                        "name": "M. Posner",
                        "slug": "M.-Posner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Posner",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Posner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "3), as has been observed psychophysically [16]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "Such an \u201cinhibition of return\u201d has been demonstrated in human visual psychophysics [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 141617398,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "9aeb84ab5af22a63e1881aed2ff21e745100349c",
            "isKey": false,
            "numCitedBy": 2898,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Components-of-visual-orienting-Posner",
            "title": {
                "fragments": [],
                "text": "Components of visual orienting"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6688131"
                        ],
                        "name": "V. Casagrande",
                        "slug": "V.-Casagrande",
                        "structuredName": {
                            "firstName": "Vivien",
                            "lastName": "Casagrande",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Casagrande"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "reached, a prototypical spike is generated, and the capacitive charge is shunted to zero [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57632744,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "cd9450357158ade239316ff5cfa89fe974cef56a",
            "isKey": false,
            "numCitedBy": 1241,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Biophysics-of-Computation:-Information-Processing-Casagrande",
            "title": {
                "fragments": [],
                "text": "Biophysics of Computation: Information Processing in Single Neurons"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Components of Visual Orienting Attention and Performance"
            },
            "venue": {
                "fragments": [],
                "text": "Hilldale, N.J.: Erlbaum"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "Such an \\inhibition of return\" has been demonstrated in human visual psychophysics [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "3), as has been observed psychophysically [16]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Components of visual orienting\", Attention  and Performance X, (H"
            },
            "venue": {
                "fragments": [],
                "text": "Bouma, D.G. Bouwhuis eds), Hilldale, NJ:L. Erl-  baum,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modelling Visual Attention via Selective Tuning Computational Architectures for Attention , \u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modelling Visual Attention via Selective Tuning Computational Architectures for Attention , \u201d R . Parasuraman , ed . , The Attentive Brain , pp . 163 \u2013 186"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Computational architectures for attention The attentive brain"
            },
            "venue": {
                "fragments": [],
                "text": "\\Computational architectures for attention The attentive brain"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The C++ implementation of the model and numerous examples of attentional predictions on natural and synthetic images can be retrieved from http"
            },
            "venue": {
                "fragments": [],
                "text": "The C++ implementation of the model and numerous examples of attentional predictions on natural and synthetic images can be retrieved from http"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Anderson, \\Overcomplete steerable pyramid lters and rotation invariance"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\ A Model for Inhibitory LateralInteraction E ects in Perceived Contrast"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 325,
                                "start": 322
                            }
                        ],
                        "text": "This selection appears to be implemented in the form of a spatially circumscribed region of the visual field, the so-called \u201cfocus of attention,\u201d which scans the scene both in a rapid, bottom-up, saliency-driven, and task-independent manner as well as in a slower, top-down, volition-controlled, and task-dependent manner [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 190
                            }
                        ],
                        "text": "Intermediate and higher visual processes appear to select a subset of the available sensory information before further processing [1], most likely to reduce the complexity of scene analysis [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 241
                            }
                        ],
                        "text": "The attended region is selected through dynamic modifications of cortical connectivity or through the establishment of specific temporal patterns of activity, under both top-down (task-dependent) and bottom-up (scene-dependent) control [3], [2], [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational Architectures for Attention"
            },
            "venue": {
                "fragments": [],
                "text": "R. Parasuraman, ed., The Attentive Brain, pp. 163\u2013186. Cambridge, Mass.: MIT Press, 1998."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nuuo, \\Modelling visual attention via selective tuning"
            },
            "venue": {
                "fragments": [],
                "text": "Artiicial Intelligence"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 226
                            }
                        ],
                        "text": "The biological motivation behind the design of N (:) is that it coarsely replicates cortical lateral inhibition mechanisms, in which neighboring similar features inhibit each other via speci c, anatomically-de ned connections [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fullenkamp, \\A Model for Inhibitory Lateral  Interaction E ects in Perceived Contrast,"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural information and coding workshop"
            },
            "venue": {
                "fragments": [],
                "text": "\\The EEect of Gaze on Natural Scene Statistics"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 8,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 33,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Model-of-Saliency-Based-Visual-Attention-for-Itti-Koch/4816f0b6f0d05da3901441bfa5cc7be044b4da8b?sort=total-citations"
}