{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We show that these are far from being optimal, and derive several algorithms ranging from easy-to-implement to highly-efficient."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25497,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054718690"
                        ],
                        "name": "Joseph Gil",
                        "slug": "Joseph-Gil",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Gil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Gil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27379268"
                        ],
                        "name": "M. Werman",
                        "slug": "M.-Werman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Werman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Werman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "2D Straightforward 1 O(1) O(n(2)) \u223c 1 + 2 ln(n) + ln(2) 2D (n + 1)\u00d7 (n + 1)-Block 1 n(2) O(1) 4\u2212 4 n+1 \u223c 1 + 2 ln(2\u2212 1 n+1 ) < 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "-Case Compl exity per Pixel per Pixel per Pixel 1D Straightforward 1 O(1) O(n) \u223c 1 + ln(n) + ln(2) 1D (n + 1)-Block 1 n+1 O(1) 2\u2212 1 n+1 \u223c 1 + ln(2 \u2212 1 n+1 ) < 1."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206417412,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6da90c6a6d0316aa9b24113ae15d72c44eb4b0a5",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Fast algorithms for computing min, median, max, or any other order statistic filter transforms are described. The algorithms take constant time per pixel to compute min or max filters and polylog time per pixel, in the size of the filter, to compute the median filter. A logarithmic time per pixel lower bound for the computation of the median filter is shown. >"
            },
            "slug": "Computing-2-D-Min,-Median,-and-Max-Filters-Gil-Werman",
            "title": {
                "fragments": [],
                "text": "Computing 2-D Min, Median, and Max Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "Fast algorithms for computing min, median, max, or any other order statistic filter transforms are described and a logarithmic time per pixel lower bound for the computation of the median filter is shown."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We show that these are far from being optimal, and derive several algorithms ranging from easy-to-implement to highly-efficient."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1704741,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8b440596b28dc6683caa2b5f6fbca70963e5909e",
            "isKey": false,
            "numCitedBy": 4161,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching results; the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points."
            },
            "slug": "Scale-&-Affine-Invariant-Interest-Point-Detectors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Scale & Affine Invariant Interest Point Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A comparative evaluation of different detectors is presented and it is shown that the proposed approach for detecting interest points invariant to scale and affine transformations provides better results than existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We show that these are far from being optimal, and derive several algorithms ranging from easy-to-implement to highly-efficient."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5107897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2893662ec4001949b4afcba124492340216dfd7e",
            "isKey": false,
            "numCitedBy": 732,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\u2018Invariant regions\u2019 are self-adaptive image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions can be extracted directly from a single image. They are then described by a set of invariant features, which makes it relatively easy to match them between views, even under wide baseline conditions. In this contribution, two methods to extract invariant regions are presented. The first one starts from corners and uses the nearby edges, while the second one is purely intensity-based. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions. Experiments on images of real-world scenes taken from substantially different viewpoints demonstrate the feasibility of the approach."
            },
            "slug": "Matching-Widely-Separated-Views-Based-on-Affine-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Matching Widely Separated Views Based on Affine Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "To increase the robustness of the system, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric) allow to test the consistency of correspondences and hence to reject falsely matched regions."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "2D Straightforward 1 O(1) O(n(2)) \u223c 1 + 2 ln(n) + ln(2) 2D (n + 1)\u00d7 (n + 1)-Block 1 n(2) O(1) 4\u2212 4 n+1 \u223c 1 + 2 ln(2\u2212 1 n+1 ) < 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "-Case Compl exity per Pixel per Pixel per Pixel 1D Straightforward 1 O(1) O(n) \u223c 1 + ln(n) + ln(2) 1D (n + 1)-Block 1 n+1 O(1) 2\u2212 1 n+1 \u223c 1 + ln(2 \u2212 1 n+1 ) < 1."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distinctive image features from scale-invar  iant keypoints.IJCV"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 5,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Efficient-Non-Maximum-Suppression-Neubeck-Gool/52ca4ed04d1d9dba3e6ae30717898276735e0b79?sort=total-citations"
}