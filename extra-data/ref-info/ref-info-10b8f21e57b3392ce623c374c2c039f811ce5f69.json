{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 246
                            }
                        ],
                        "text": "Our first step is to cluster sentences into groups from which to learn useful patterns; for the multiple-sequence techniques we will use, this means that the sentences within clusters should describe similar events and have similar structure, as in the sentences of Figure 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 21
                            }
                        ],
                        "text": "Jacquemin (1999) and Barzilay and McKeown (2001) identify phraselevel paraphrases, while Lin and Pantel (2001) and Shinyama et al. (2002) acquire structural paraphrases encoded as templates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9842595,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "8d7a692d8763a38283db54e19f1dcc694a34e706",
            "isKey": false,
            "numCitedBy": 538,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "While paraphrasing is critical both for interpretation and generation of natural language, current systems use manual or semi-automatic methods to collect paraphrases. We present an unsupervised learning algorithm for identification of paraphrases from a corpus of multiple English translations of the same source text. Our approach yields phrasal and single word lexical paraphrases as well as syntactic paraphrases."
            },
            "slug": "Extracting-Paraphrases-from-a-Parallel-Corpus-Barzilay-McKeown",
            "title": {
                "fragments": [],
                "text": "Extracting Paraphrases from a Parallel Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents an unsupervised learning algorithm for identification of paraphrases from a corpus of multiple English translations of the same source text that yields phrasal and single word lexical paraphrasing as well as syntactic paraphrase."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2550658"
                        ],
                        "name": "Yusuke Shinyama",
                        "slug": "Yusuke-Shinyama",
                        "structuredName": {
                            "firstName": "Yusuke",
                            "lastName": "Shinyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yusuke Shinyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714612"
                        ],
                        "name": "S. Sekine",
                        "slug": "S.-Sekine",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Sekine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sekine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686185"
                        ],
                        "name": "Kiyoshi Sudo",
                        "slug": "Kiyoshi-Sudo",
                        "structuredName": {
                            "firstName": "Kiyoshi",
                            "lastName": "Sudo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kiyoshi Sudo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12308112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c8b067649f09b9260569d6e398c5c1b16fa2712",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Paraphrases play an important role in the variety and complexity of natural language documents. However, they add to the difficulty of natural language processing. Here we describe a procedure for obtaining paraphrases from news articles. Articles derived from different newspapers can contain paraphrases if they report the same event on the same day. We exploit this feature by using Named Entity recognition. Our approach is based on the assumption that Named Entities are preserved across paraphrases. We applied our method to articles of two domains and obtained notable examples. Although this is our initial attempt at automatically extracting paraphrases from a corpus, the results are promising."
            },
            "slug": "Automatic-paraphrase-acquisition-from-news-articles-Shinyama-Sekine",
            "title": {
                "fragments": [],
                "text": "Automatic paraphrase acquisition from news articles"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This is the initial attempt at automatically extracting paraphrases from a corpus, and the results are promising."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144865353"
                        ],
                        "name": "B. Pang",
                        "slug": "B.-Pang",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Pang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11728052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b48af24cd360d6b0a3dd25424550c28bf97bc1ce",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a syntax-based algorithm that automatically builds Finite State Automata (word lattices) from semantically equivalent translation sets. These FSAs are good representations of paraphrases. They can be used to extract lexical and syntactic paraphrase pairs and to generate new, unseen sentences that express the same meaning as the sentences in the input sets. Our FSAs can also predict the correctness of alternative semantic renderings, which may be used to evaluate the quality of translations."
            },
            "slug": "Syntax-based-Alignment-of-Multiple-Translations:-Pang-Knight",
            "title": {
                "fragments": [],
                "text": "Syntax-based Alignment of Multiple Translations: Extracting Paraphrases and Generating New Sentences"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A syntax-based algorithm that automatically builds Finite State Automata (word lattices) from semantically equivalent translation sets that are good representations of paraphrases and can predict the correctness of alternative semantic renderings, which may be used to evaluate the quality of translations."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2729817"
                        ],
                        "name": "V. Shaked",
                        "slug": "V.-Shaked",
                        "structuredName": {
                            "firstName": "Varda",
                            "lastName": "Shaked",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Shaked"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 249
                            }
                        ],
                        "text": "\u2026level, and so forth.1 Not surprisingly, therefore, paraphrasing has been a focus of gen-\n1Another interesting application, somewhat tangential to generation, would be to expand existing corpora by\neration research for quite some time (McKeown, 1979; Meteer and Shaked, 1988; Dras, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The results of our evaluation experiments show that the system derives accurate paraphrases, outperforming baseline systems."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 5076418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16fcf74245d98ff681c336edbf6f2af5c18664a8",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new dimension to paraphrasing text in which characteristics of the original text motivate strategies for effective paraphrasing. Our system combines two existing robust components: the IRUS-II natural language understanding system and the SPOKESMAN generation system. We describe the architecture of the system and enhancements made to these components to facilitate paraphrasing. We particularly look at how levels of representation in these two systems are used by specialists in the paraphraser which define potential problems and paraphrasing strategies. Finally, we look at the role of paraphrasing in a cooperative dialog system. We will focus here on paraphrasing in the context of natural language interfaces and particularly on how multiple interpretations introduced by various kinds of ambiguity can be conbasted in paraphrases using both sentence structure and highlighting and formating the text itself."
            },
            "slug": "Strategies-for-Effective-Paraphrasing-Meteer-Shaked",
            "title": {
                "fragments": [],
                "text": "Strategies for Effective Paraphrasing"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new dimension to paraphrasing text in which characteristics of the original text motivate strategies for effective paraphrase is presented, which combines two existing robust components: the IRUS-II natural language understanding system and the SPOKESMAN generation system."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 48
                            }
                        ],
                        "text": "See Bangalore, Murdock, and Riccardi (2002) and Barzilay and Lee (2002) for other uses of such data.\ncontrast to previous work using MSA for generation (Barzilay and Lee, 2002), we need neither parallel data nor explicit information about sentence semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 136
                            }
                        ],
                        "text": "Lattices have proven advantageous in a number of NLP contexts (Mangu, Brill, and Stolcke, 2000; Bangalore, Murdock, and Riccardi, 2002; Barzilay and Lee, 2002; Pang, Knight, and Marcu, 2003), but were usually produced from (multi-)parallel data, which may not be readily available for many\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 62
                            }
                        ],
                        "text": "Lattices have proven advantageous in a number of NLP contexts (Mangu et al., 2000; Bangalore et al., 2002; Barzilay and Lee, 2002; Pang et al., 2003), but were usually produced from (multi-)parallel data, which may not be readily available for many applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 163
                            }
                        ],
                        "text": "3Scoring function: aligning two identical words scores 1; inserting a word scores -0.01, and aligning two different words scores -0.5 (parameter values taken from Barzilay and Lee (2002)).\nas those shared by more than 50% of the cluster\u2019s sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7521453,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0666c5355311f7a110157ef5f6ee5f2cc1018b0a",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "An important component of any generation system is the mapping dictionary, a lexicon of elementary semantic expressions and corresponding natural language realizations. Typically, labor-intensive knowledge-based methods are used to construct the dictionary. We instead propose to acquire it automatically via a novel multiple-pass algorithm employing multiple-sequence alignment, a technique commonly used in bioinformatics. Crucially, our method lever-ages latent information contained in multi-parallel corpora --- datasets that supply several verbalizations of the corresponding semantics rather than just one.We used our techniques to generate natural language versions of computer-generated mathematical proofs, with good results on both a per-component and overall-output basis. For example, in evaluations involving a dozen human judges, our system produced output whose readability and faithfulness to the semantic input rivaled that of a traditional generation system."
            },
            "slug": "Bootstrapping-Lexical-Choice-via-Multiple-Sequence-Barzilay-Lee",
            "title": {
                "fragments": [],
                "text": "Bootstrapping Lexical Choice via Multiple-Sequence Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The method lever-ages latent information contained in multi-parallel corpora --- datasets that supply several verbalizations of the corresponding semantics rather than just one to generate natural language versions of computer-generated mathematical proofs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 462954,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d4fa9ef512ac562f5ca081bdf2b62510ff7dc5b",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "The design and implementation of a paraphrase component for a natural language question-answer system (CO-OP) is presented. A major point made is the role of given and new information in formulating a paraphrase that differs in a meaningful way from the user's question. A description is also given of the transformational grammar used by the paraphraser to generate questions."
            },
            "slug": "Paraphrasing-Using-Given-and-New-Information-in-a-McKeown",
            "title": {
                "fragments": [],
                "text": "Paraphrasing Using Given and New Information in a Question-Answer System"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The design and implementation of a paraphrase component for a natural language question-answer system (CO-OP) is presented and a major point made is the role of given and new information in formulating a paraphraser that differs in a meaningful way from the user's question."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9363872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25f51f4132626a645924b3c8b3edcbdcc35c48a3",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "When humans produce summaries of documents, they do not simply extract sentences and concatenate them. Rather, they create new sentences that are grammatical, that cohere with one another, and that capture the most salient pieces of information in the original document. Given that large collections of text/abstract pairs are available online, it is now possible to envision algorithms that are trained to mimic this process. In this paper, we focus on sentence compression, a simpler version of this larger challenge. We aim to achieve two goals simultaneously:our compressions should be grammatical, and they should retain the most important pieces of information. These two goals can conflict. We devise both noisy-channel and decision-tree approaches to the problem, and we evaluate results against manual compressions and a simple baseline."
            },
            "slug": "Statistics-Based-Summarization-Step-One:-Sentence-Knight-Marcu",
            "title": {
                "fragments": [],
                "text": "Statistics-Based Summarization - Step One: Sentence Compression"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper focuses on sentence compression, a simpler version of this larger challenge, and aims to achieve two goals simultaneously: the compressions should be grammatical, and they should retain the most important pieces of information."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1869277"
                        ],
                        "name": "L. Iordanskaja",
                        "slug": "L.-Iordanskaja",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Iordanskaja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Iordanskaja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2840130"
                        ],
                        "name": "R. Kittredge",
                        "slug": "R.-Kittredge",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Kittredge",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kittredge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70801181"
                        ],
                        "name": "A. Polgu\u00e8re",
                        "slug": "A.-Polgu\u00e8re",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Polgu\u00e8re",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Polgu\u00e8re"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The results of our evaluation experiments show that the system derives accurate paraphrases, outperforming baseline systems."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 61102116,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6ea4193bc13b1bdc1afcdbd53b4242f789f8aec5",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a computationally tractable model for language generation based on the Meaning-Text Theory of Mel\u2019cuk et al., in which the lexicon plays a central role. To illustrate the descriptive scope and paraphrase capabilities of the model, we show how the lexicon influences the set of choices at four different points during the multi-stage realization process: (1) semantic net simplification, (2) determination of root lexical node for the deep syntactic dependency tree, (3) possible application of deep paraphrase rules using lexical functions, and (4) surface syntactic realization. We also show some of the ways in which the theme/rheme specifications within the semantic net influence lexical and syntactic choices during realization. Examples are taken primarily from an implemented system which generates paragraph-length reports about the usage of operating systems."
            },
            "slug": "Lexical-Selection-and-Paraphrase-in-a-Meaning-Text-Iordanskaja-Kittredge",
            "title": {
                "fragments": [],
                "text": "Lexical Selection and Paraphrase in a Meaning-Text Generation Model"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A computationally tractable model for language generation based on the Meaning-Text Theory of Mel\u2019cuk et al., in which the lexicon plays a central role is introduced, to illustrate the descriptive scope and paraphrase capabilities of the model."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35893789"
                        ],
                        "name": "R. Chandrasekar",
                        "slug": "R.-Chandrasekar",
                        "structuredName": {
                            "firstName": "Raman",
                            "lastName": "Chandrasekar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chandrasekar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35313721"
                        ],
                        "name": "S. Bangalore",
                        "slug": "S.-Bangalore",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Bangalore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bangalore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 10067966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc37959066f68d1bf9b67a3e309d6da4a3f8acb8",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-induction-of-rules-for-text-Chandrasekar-Bangalore",
            "title": {
                "fragments": [],
                "text": "Automatic induction of rules for text simplification"
            },
            "venue": {
                "fragments": [],
                "text": "Knowl. Based Syst."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145175167"
                        ],
                        "name": "J. Robin",
                        "slug": "J.-Robin",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Robin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Robin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19091184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b947f31028c542bbbc75f64773f5e8488977109",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically summarizing vast amounts of on-line quantitative data with a short natural language paragraph has a wide range of real-world applications. However, this specific task raises a number of difficult issues that are quite distinct from the generic task of language generation: conciseness, complex sentences, floating concepts, historical background, paraphrasing power and implicit content. \nIn this thesis, I address these specific issues by proposing a new generation model in which a first pass builds a draft containing only the essential new facts to report and a second pass incrementally revises this draft to opportunistically add as many background facts as can fit within the space limit. This model requires a new type of linguistic knowledge: revision operations, which specifies the various ways a draft can be transformed in order to concisely accommodate a new piece of information. I present an in-depth corpus analysis of human-written sports summaries that resulted in an extensive set of such revision operations. I also present the implementation, based on functional unification grammars, of the system scSTREAK, which relies on these operations to incrementally generate complex sentences summarizing basketball games. This thesis also contains two quantitative evaluations. The first shows that the new revision-based generation model is far more robust than the one-pass model of previous generators. The second evaluation demonstrates that the revision operations acquired during the corpus analysis and implemented in scSTREAK are, for the most part, portable to at least one other quantitative domain (the stock market). \nscSTREAK is the first report generator that systematically places the facts which it summarizes in their historical perspective. It is more concise than previous systems thanks to its ability to generate more complex sentences and to opportunistically convey facts by adding a few words to carefully chosen draft constituents. The revision operations on which scSTREAK is based constitute the first set of corpus-based linguistic knowledge geared towards incremental generation. The evaluation presented in this thesis is also the first attempt to quantitatively assess the robustness of a new generation model and the portability of a new type of linguistic knowledge."
            },
            "slug": "Revision-based-generation-of-natural-language-and-Robin",
            "title": {
                "fragments": [],
                "text": "Revision-based generation of natural language summaries providing historical background: corpus-based analysis, design, implementation and evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This thesis presents a new generation model in which a first pass builds a draft containing only the essential new facts to report and a second pass incrementally revises this draft to opportunistically add as many background facts as can fit within the space limit."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801071"
                        ],
                        "name": "Frank Smadja",
                        "slug": "Frank-Smadja",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Smadja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Smadja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The results of our evaluation experiments show that the system derives accurate paraphrases, outperforming baseline systems."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 81
                            }
                        ],
                        "text": "For instance, consider the following two sentences (similar to examples found in Smadja and McKeown (1991)):\nAfter the latest Fed rate cut, stocks rose across the board."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62711075,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "fbc5bf11848b0536e79501bd99ad25674e379e22",
            "isKey": true,
            "numCitedBy": 31,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A large number of wording choices naturally occurring in English sentences cannot be accounted for on semantic or syntactic grounds. They represent arbitrary word usages and are termed collocations. In this paper, we show how collocations can enhance the task of lexical selection in language generation. Previous language generation systems were not able to account for collocations for two reasons: they did not have the lexical information in compiled form and the lexicon formalisms available were not able to handle the variations in collocational knowledge. We describe an implemented generator, Cook, which uses a wide range of collocations to produce sentences in the stock market domain. Cook uses a flexible lexicon containing a range of collocations, from idiomatic phrases to word pairs that were compiled automatically from text corpora using a lexicographic tool, Xtract. We show how Cook is able to merge collocations of various types to produce a wide variety of sentences."
            },
            "slug": "Using-collocations-for-language-generation-1-Smadja-McKeown",
            "title": {
                "fragments": [],
                "text": "Using collocations for language generation 1"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An implemented generator, Cook, is described, which uses a flexible lexicon containing a range of collocations, from idiomatic phrases to word pairs that were compiled automatically from text corpora using a lexicographic tool, Xtract."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247319"
                        ],
                        "name": "S. Vogel",
                        "slug": "S.-Vogel",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 250
                            }
                        ],
                        "text": "\u2026the advantages mentioned above, comparable corpora can be easily obtained for many domains, whereas previous approaches to paraphrase acquisition (and the related problem of phrase-based machine translation (Wang, 1998; Och, Tillman, and Ney, 1999; Vogel and Ney, 2000)) required parallel corpora."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "The major goals of our algorithm are to learn:\n\u2022 recurring patterns in the data, such asX (injured/wounded) Y people, Z seriously, where the capital letters represent variables;\n\u2022 pairings between such patterns that represent paraphrases, for example, between the patternX (injured/wounded) Y\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5443564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "085ee1aff80617d2b368bba6bc9584351c0e7cd1",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Translation memories are promising devices for automatic translation. Their main weakness, however, is poor coverage on unseen text. In this paper, the use of a hierarchical translation memory, consisting of a cascade of finite state transducers, is proposed. A number of transducers is applied to convert sentence pairs from a bilingual corpus into translation patterns, which are then used as a translation memory. Preliminary results on the German English VERBMOBIL corpus are given."
            },
            "slug": "Construction-of-a-Hierarchical-Translation-Memory-Vogel-Ney",
            "title": {
                "fragments": [],
                "text": "Construction of a Hierarchical Translation Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A hierarchical translation memory, consisting of a cascade of finite state transducers, is proposed, which is applied to convert sentence pairs from a bilingual corpus into translation patterns, which are then used as a translation memory."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990190"
                        ],
                        "name": "P. Pantel",
                        "slug": "P.-Pantel",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Pantel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pantel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12363172,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4317b8a4490c84301907a61f5b8ebb26ab8828d",
            "isKey": false,
            "numCitedBy": 627,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the main challenges in question-answering is the potential mismatch between the expressions in questions and the expressions in texts. While humans appear to use inference rules such as \u2018X writes Y\u2019 implies \u2018X is the author of Y\u2019 in answering questions, such rules are generally unavailable to question-answering systems due to the inherent difficulty in constructing them. In this paper, we present an unsupervised algorithm for discovering inference rules from text. Our algorithm is based on an extended version of Harris\u2019 Distributional Hypothesis, which states that words that occurred in the same contexts tend to be similar. Instead of using this hypothesis on words, we apply it to paths in the dependency trees of a parsed corpus. Essentially, if two paths tend to link the same set of words, we hypothesize that their meanings are similar. We use examples to show that our system discovers many inference rules easily missed by humans."
            },
            "slug": "Discovery-of-inference-rules-for-question-answering-Lin-Pantel",
            "title": {
                "fragments": [],
                "text": "Discovery of inference rules for question-answering"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents an unsupervised algorithm for discovering inference rules from text based on an extended version of Harris\u2019 Distributional Hypothesis, which states that words that occurred in the same contexts tend to be similar."
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324070"
                        ],
                        "name": "C. Tillmann",
                        "slug": "C.-Tillmann",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Tillmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tillmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6665740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b0495331238da6c0e7be0bfdb9b5453b33c1f98",
            "isKey": false,
            "numCitedBy": 579,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe improved alignment models for statistical machine translation. The statistical translation approach uses two types of information: a translation model and a language model. The language model used is a bigram or general m-gram model. The translation model is decomposed into a lexical and an alignment model. We describe two different approaches for statistical translation and present experimental results. The first approach is based on dependencies between single words, the second approach explicitly takes shallow phrase structures into account, using two different alignment levels: a phrase level alignment between phrases and a word level alignment between single words. We present results using the Verbmobil task (German-English, 6000word vocabulary) which is a limited-domain spoken-language task. The experimental tests were performed on both the text transcription and the speech recognizer output. 1 S t a t i s t i c a l M a c h i n e T r a n s l a t i o n The goal of machine translation is the translation of a text given in some source language into a target language. We are given a source string f / = fl...fj...fJ, which is to be translated into a target string e{ = el...ei...ex. Among all possible target strings, we will choose the string with the highest probability: = argmax {Pr(ezIlflJ)}"
            },
            "slug": "Improved-Alignment-Models-for-Statistical-Machine-Och-Tillmann",
            "title": {
                "fragments": [],
                "text": "Improved Alignment Models for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Improved alignment models for statistical machine translation are described and experimental results are presented using the Verbmobil task (German-English, 6000word vocabulary) which is a limited-domain spoken-language task."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795294"
                        ],
                        "name": "M. Dras",
                        "slug": "M.-Dras",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59702300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fc79ac6d1fbf0ca6752e7e26d4633ecce2942c7",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Paraphrase, as a general concept, is a very mutable thing; at one extreme, paraphrase is the relation between units of text with identical meanings, as under the transformationalgenerative view, and at the other extreme there is the view that no text is interchangeable with any other. Each point in the spectrum ranging between these two views is a valid one, and in order to focus on a speci c point it is necessary to examine paraphrase under a particular context and application. In this thesis, the context is the task of Reluctant Paraphrase (RP). Given an ideal starting text, which expresses exactly what its author intends, it is often necessary to alter the text in some way in order to t it to some externally imposed constraints|length, readability as speci ed by a house style guide, and so on. In this context, paraphrase is a relation between interchangeable units of text; the task is then to choose the best set of such paraphrases that will t the whole text to the constraints, with `best' in this case being the set that changes the text the least. This di ers from other tasks where paraphrase is central: in natural language generation, particularly revision-based generation, where positively correlated constraints have meant there is no need for advanced search strategies to nd the best solution, and where the starting point is a knowledge representation rather than text, with the system consequently being omniscient regarding equivalence of concept realisations into text; and in style checkers and controlled language checkers, where the goal is to correct text, and consequently where the locality of alterations again means that advanced strategies for nding the best solution are unnecessary. The thesis uses the application of paraphrase as a means of exploring properties of the Tree Adjoining Grammar (TAG) formalism. TAG is a mathematical formalism, within which linguistic theories can be expressed, that is constrained in expressive power, which means that formal results about the language can be established, and that a linguistic theory has less work to do in circumscribing the class of acceptable constructions, since the formalism imposes universal constraints. And, as one of a class of mildly context sensitive grammars, it is well suited to describing natural language. Moreover, it is possible to map between TAG grammars using the Synchronous TAG (S-TAG) formalism, which has been used in applications such as machine translation, syntax{semantics mapping and modelling of coordination. However, in these applications the S-TAG formalism is not able to model all the phenomena that occur. Paraphrase is another, di erent application that allows exploration of the formalism from a di erent perspective, one which is particularly structurally complex. This application and the context of RP are closely interrelated. In performing the RP task, a representation of paraphrase is necessary, for which S-TAG provides a formalism. And, in using paraphrase to explore TAG, the RP context provides a focus narrowing down the paraphrases and consequently the requirements of the representation formalism. The thesis then looks at the two related modelling tasks. Firstly, the modelling of the RP task. Integer Programming is shown to be an appropriate framework, allowing a text tting the constraints to be determined, one minimally altered by paraphrasing. A range of model variants is possible, and the thesis investigates which is the best model in terms of search criteria. Secondly, the modelling of paraphrase in S-TAG. The relative structural complexity gives insights into the cause of representational di culties with S-TAG, and leads to generalisations of S-TAG that resolve existing problems in the formalism."
            },
            "slug": "Tree-adjoining-grammar-and-the-reluctant-of-text-Dras",
            "title": {
                "fragments": [],
                "text": "Tree adjoining grammar and the reluctant paraphrasing of text"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The thesis uses the application of paraphrase as a means of exploring properties of the Tree Adjoining Grammar (TAG) formalism as well as other tasks where paraphrase is central, and Integer Programming is shown to be an appropriate framework."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30844359"
                        ],
                        "name": "Ye-Yi Wang",
                        "slug": "Ye-Yi-Wang",
                        "structuredName": {
                            "firstName": "Ye-Yi",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ye-Yi Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 209
                            }
                        ],
                        "text": "\u2026the advantages mentioned above, comparable corpora can be easily obtained for many domains, whereas previous approaches to paraphrase acquisition (and the related problem of phrase-based machine translation (Wang, 1998; Och, Tillman, and Ney, 1999; Vogel and Ney, 2000)) required parallel corpora."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 78
                            }
                        ],
                        "text": "The major goals of our algorithm are to learn:\n\u2022 recurring patterns in the data, such asX (injured/wounded) Y people, Z seriously, where the capital letters represent variables;\n\u2022 pairings between such patterns that represent paraphrases, for example, between the patternX (injured/wounded) Y\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 621484,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb9f9d320ad39febc6246901d47fb40446f2344b",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "NLP researchers face a dilemma: on one side, it is unarguably accepted that languages have internal structure rather than strings of words. On the other side, they nd it very di cult and expensive to write grammars that have good coverage of language structures. Statistical machine translation tries to cope with this problem by ignoring language structures and using a statistical models to depict the translation process. Most of the translation models are word-based. While the approach has achieved surprisingly good performance comparable to the best commercial systems, many questions remain in the machine translation community. Can the statistical word-based translation still perform well on language pairs with radically di erent linguistic structures? How would it function with less training data or with spoken languages? The thesis work investigated these questions. In summary, word-based alignment model is a major cause of errors in German-English statistical spoken language translation. To account for this problem, a structure-based alignment model is introduced. This new model takes advantages of a bilingual grammar inference algorithm, which can automatically acquire shallow phrase structures used by the model. The structure-based model can directly depict the structure di erence between English and German spoken languages. It also results in focused learning of word alignment, therefore it can alleviate the sparse data problem. The structurebased model achieved 11 percent error reduction over the state-of-the-art statistical machine translation models."
            },
            "slug": "Grammar-Inference-and-Statistical-Machine-Wang",
            "title": {
                "fragments": [],
                "text": "Grammar Inference and Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A structure-based alignment model is introduced that can directly depict the structure between English and German spoken languages and results in focused learning of word alignment, therefore it can alleviate the sparse data problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718611"
                        ],
                        "name": "L. Mangu",
                        "slug": "L.-Mangu",
                        "structuredName": {
                            "firstName": "Lidia",
                            "lastName": "Mangu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Mangu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 81
                            }
                        ],
                        "text": "Lattices have proven advantageous in a number of NLP contexts (Mangu, Brill, and Stolcke, 2000; Bangalore, Murdock, and Riccardi, 2002; Barzilay and Lee, 2002; Pang, Knight, and Marcu, 2003), but were usually produced from (multi-)parallel data, which may not be readily available for many\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6135726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7d08c4fdf359f5cf0946a4a86db52d273a59ba4",
            "isKey": false,
            "numCitedBy": 731,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new framework for distilling information from word lattices to improve the accuracy of the speech recognition output and obtain a more perspicuous representation of a set of alternative hypotheses. In the standard MAP decoding approach the recognizer outputs the string of words corresponding to the path with the highest posterior probability given the acoustics and a language model. However, even given optimal models, the MAP decoder does not necessarily minimize the commonly used performance metric, word error rate (WER). We describe a method for explicitly minimizing WER by extracting word hypotheses with the highest posterior probabilities from word lattices. We change the standard problem formulation by replacing global search over a large set of sentence hypotheses with local search over a small set of word candidates. In addition to improving the accuracy of the recognizer, our method produces a new representation of a set of candidate hypotheses that specifies the sequence of word-level confusions in a compact lattice format. We study the properties of confusion networks and examine their use for other tasks, such as lattice compression, word spotting, confidence annotation, and reevaluation of recognition hypotheses using higher-level knowledge sources."
            },
            "slug": "Finding-consensus-in-speech-recognition:-word-error-Mangu-Brill",
            "title": {
                "fragments": [],
                "text": "Finding consensus in speech recognition: word error minimization and other applications of confusion networks"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new framework for distilling information from word lattices is described to improve the accuracy of the speech recognition output and obtain a more perspicuous representation of a set of alternative hypotheses."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717038"
                        ],
                        "name": "C. Jacquemin",
                        "slug": "C.-Jacquemin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Jacquemin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacquemin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6016239,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "a8b9cf25eb63b51f146f89534d18993a215e9e40",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A two-tier model for the description of morphological, syntactic and semantic variations of multi-word terms is presented. It is applied to term normalization of French and English corpora in the medical and agricultural domains. Five differenct sources of morphological and semantic knowledge are exploited (MULTEXT, CELEX, AGROVOC, WordNet1.6, and Microsoft Word97 thesaurus)."
            },
            "slug": "Syntagmatic-and-Paradigmatic-Representations-of-Jacquemin",
            "title": {
                "fragments": [],
                "text": "Syntagmatic and Paradigmatic Representations of Term Variation"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "A two-tier model for the description of morphological, syntactic and semantic variations of multi-word terms is presented and is applied to term normalization of French and English corpora in the medical and agricultural domains."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 123
                            }
                        ],
                        "text": "Learning synonyms via distributional similarity has been well-studied (Pereira, Tishby, and Lee, 1993; Grefenstette, 1994; Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 70
                            }
                        ],
                        "text": "Learning synonyms via distributional similarity has been well-studied (Pereira et al., 1993; Grefenstette, 1994; Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15698938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd1901f34cc3673072264104885d70555b1a4cdc",
            "isKey": false,
            "numCitedBy": 1928,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Bootstrapping semantics from text is one of the greatest challenges in natural language learning. We first define a word similarity measure based on the distributional pattern of words. The similarity measure allows us to construct a thesaurus using a parsed corpus. We then present a new evaluation methodology for the automatically constructed thesaurus. The evaluation results show that the thesaurus is significantly closer to WordNet than Roget Thesaurus is."
            },
            "slug": "Automatic-Retrieval-and-Clustering-of-Similar-Words-Lin",
            "title": {
                "fragments": [],
                "text": "Automatic Retrieval and Clustering of Similar Words"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A word similarity measure based on the distributional pattern of words allows the automatically constructed thesaurus to be significantly closer to WordNet than Roget Thesaurus is."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323275"
                        ],
                        "name": "Kishore Papineni",
                        "slug": "Kishore-Papineni",
                        "structuredName": {
                            "firstName": "Kishore",
                            "lastName": "Papineni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kishore Papineni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144582029"
                        ],
                        "name": "T. Ward",
                        "slug": "T.-Ward",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2587983"
                        ],
                        "name": "Wei-Jing Zhu",
                        "slug": "Wei-Jing-Zhu",
                        "structuredName": {
                            "firstName": "Wei-Jing",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Jing Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11080756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7da009f457917aa381619facfa5ffae9329a6e9",
            "isKey": false,
            "numCitedBy": 16627,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations."
            },
            "slug": "Bleu:-a-Method-for-Automatic-Evaluation-of-Machine-Papineni-Roukos",
            "title": {
                "fragments": [],
                "text": "Bleu: a Method for Automatic Evaluation of Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6713452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eb328cf7e94995199e4c82a1f4d0696430a80b5",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data."
            },
            "slug": "Distributional-Clustering-of-English-Words-Pereira-Tishby",
            "title": {
                "fragments": [],
                "text": "Distributional Clustering of English Words"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deterministic annealing is used to find lowest distortion sets of clusters: as the annealed parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35313721"
                        ],
                        "name": "S. Bangalore",
                        "slug": "S.-Bangalore",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Bangalore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bangalore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684660"
                        ],
                        "name": "Vanessa Murdock",
                        "slug": "Vanessa-Murdock",
                        "structuredName": {
                            "firstName": "Vanessa",
                            "lastName": "Murdock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vanessa Murdock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719162"
                        ],
                        "name": "G. Riccardi",
                        "slug": "G.-Riccardi",
                        "structuredName": {
                            "firstName": "Giuseppe",
                            "lastName": "Riccardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Riccardi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19286820,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcff8cd18fa58c524d37c29feeb2924d498da99c",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the primary issues in training statistical translation models is the paucity of bilingual data. In this paper, we propose techniques to alleviate the bilingual data bottleneck by creating a consensus from translations of monolingual data provided by several off-the-shelf translation engines. We compute the consensus alignment using a multi-sequence alignment algorithm used for DNA sequence alignment. We present an application of this technique to bootstrap bilingual data for the general domain of instant messaging. We train hierarchical statistical translation models on the bootstrapped bilingual data and show that the resulting statistical translation model outperforms each individual off-the-shelf translation system."
            },
            "slug": "Bootstrapping-Bilingual-Data-using-Consensus-for-a-Bangalore-Murdock",
            "title": {
                "fragments": [],
                "text": "Bootstrapping Bilingual Data using Consensus Translation for a Multilingual Instant Messaging System"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper proposes techniques to alleviate the bilingual data bottleneck by creating a consensus from translations of monolingual data provided by several off-the-shelf translation engines, and compute the consensus alignment using a multi-sequence alignment algorithm used for DNA sequence alignment."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 103
                            }
                        ],
                        "text": "Learning synonyms via distributional similarity has been well-studied (Pereira, Tishby, and Lee, 1993; Grefenstette, 1994; Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59167516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4471e3117cdac2fae74d305d54b237bb3addd749",
            "isKey": false,
            "numCitedBy": 873,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. 1. Introduction. 2. Semantic Extraction. 3. Sextant. 4. Evaluation. 5. Applications. 6. Conclusion. 1: Preprocesors. 2. Webster Stopword List. 3: Similarity List. 4: Semantic Clustering. 5: Automatic Thesaurus Generation. 6. Corpora Treated. Index."
            },
            "slug": "Explorations-in-automatic-thesaurus-discovery-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Explorations in automatic thesaurus discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The aim of this monograph is to provide a catalog of words and phrases used in ThesaurusGeneration, as well as some examples of other writers' work, which have been used in similar contexts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1952749"
                        ],
                        "name": "K. Kukich",
                        "slug": "K.-Kukich",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Kukich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kukich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152371197"
                        ],
                        "name": "James Shaw",
                        "slug": "James-Shaw",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Shaw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Shaw"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2283041,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ceef298fc83a92e5b605596828d5da7ffa35edee",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "PLANDoc, a system under joint development by Columbia and Bellcore, documents the activity of planning engineers as they study telephone routes. It takes as input a trace of the engineer's interaction with a network planning tool and produces 1--2 page summary. In this paper, we describe the user needs analysis we performed and how it influenced the development of PLANDoc. In particular, we show how it pinpointed the need for a sublanguage specification, allowing us to identify input messages and to characterize the different sentence paraphrases for realizing them. We focus on the systematic use of conjunction in combination with paraphrase that we developed for PLANDoc, which allows for the generation of summaries that are both concise-avoiding repetition of similar information, and fluent-avoiding repetition of similar phrasing."
            },
            "slug": "Practical-Issues-in-Automatic-Documentation-McKeown-Kukich",
            "title": {
                "fragments": [],
                "text": "Practical Issues in Automatic Documentation Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The user needs analysis performed and how it influenced the development of PLANDoc are described, showing how it pinpointed the need for a sublanguage specification, allowing us to identify input messages and to characterize the different sentence paraphrases for realizing them."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40421149"
                        ],
                        "name": "T. Speed",
                        "slug": "T.-Speed",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Speed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Speed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 165
                            }
                        ],
                        "text": "Pairwise MSA can be extended efficiently to multiple sequences via the iterative pairwise alignment, a polynomial-time method commonly used in computational biology (Durbin et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 150
                            }
                        ],
                        "text": "\u2026be extended efficiently to multiple sequences via the iterative pairwise alignment, a polynomial-time method commonly used in com-\nputational biology (Durbin et al., 1998).3 The results\ncan be represented in an intuitive form via a wordlat-\ntice (see Figure 3), which compactly represents\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2638221,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "ba264396913ed7c8ba03767718ccc01b1a50f111",
            "isKey": false,
            "numCitedBy": 707,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This talk will review a little over a decade's research on applying certain stochastic models to biological sequence analysis. The models themselves have a longer history, going back over 30 years, although many novel variants have arisen since that time. The function of the models in biological sequence analysis is to summarize the information concerning what is known as a motif or a domain in bioinformatics, and to provide a tool for discovering instances of that motif or domain in a separate sequence segment. We will introduce the motif models in stages, beginning from very simple, non-stochastic versions, progressively becoming more complex, until we reach modern profile HMMs for motifs. A second example will come from gene finding using sequence data from one or two species, where generalized HMMs or generalized pair HMMs have proved to be very effective."
            },
            "slug": "Biological-sequence-analysis-Speed",
            "title": {
                "fragments": [],
                "text": "Biological sequence analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This talk will review a little over a decade's research on applying certain stochastic models to biological sequence analysis, and introduce the motif models in stages, beginning from very simple, non-stochastic versions, progressively becoming more complex, until they reach modern profile HMMs for motifs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861837498"
                        ],
                        "name": "G. G. Stokes",
                        "slug": "G.-G.-Stokes",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Stokes",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. G. Stokes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221060727,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "90006064cafcb0a9ad8a30cffeb56efe7e14129b",
            "isKey": false,
            "numCitedBy": 672656,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "however (for it was the literal soul of the life of the Redeemer, John xv. io), is the peculiar token of fellowship with the Redeemer. That love to God (what is meant here is not God\u2019s love to men) is described in such a case as a perfect love (love that has been perfected), involves no difficulty, for the simple reason that the proposition is purely hypothetical. We must, of course, also take the &dquo;keeping&dquo; in all its stringency. John knows right well that the case supposed here ncver becomes full reality. &dquo; Hereb)\u2019,&dquo; i.e. from the actual realization of love to God. &dquo; TIli7i 7e)e are ill Hinz &dquo;"
            },
            "slug": "\"J.\"-Stokes",
            "title": {
                "fragments": [],
                "text": "\"J.\""
            },
            "venue": {
                "fragments": [],
                "text": "The New Yale Book of Quotations"
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145312626"
                        ],
                        "name": "J. R. Landis",
                        "slug": "J.-R.-Landis",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Landis",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Landis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31839425"
                        ],
                        "name": "G. Koch",
                        "slug": "G.-Koch",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Koch",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Koch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11077516,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7e7343a5608fff1c68c5259db0c77b9193f1546d",
            "isKey": false,
            "numCitedBy": 59436,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature."
            },
            "slug": "The-measurement-of-observer-agreement-for-data.-Landis-Koch",
            "title": {
                "fragments": [],
                "text": "The measurement of observer agreement for categorical data."
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies is presented and tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interob server agreement are developed as generalized kappa-type statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Shinyama et al. (2002) also use dependency-tree information to extract templates of a limited form (in their case, determined by the underlying information extraction application)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 15
                            }
                        ],
                        "text": "(The system of Shinyama et al. (2002) was unsuitable for evaluation purposes because their paraphrase extraction component is too tightly coupled to the underlying information extraction system.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 115
                            }
                        ],
                        "text": "Jacquemin (1999) and Barzilay and McKeown (2001) identify phraselevel paraphrases, while Lin and Pantel (2001) and Shinyama et al. (2002) acquire structural paraphrases encoded as templates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 192
                            }
                        ],
                        "text": "Once lattices for each corpus in our comparable-corpus pair are computed, we identify lattice paraphrase pairs, using the idea that paraphrases will tend to take the same values as arguments (Shinyama et al., 2002; Lin and Pantel, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kiyoshi Sudo"
            },
            "venue": {
                "fragments": [],
                "text": "and Ralph Grishman."
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The results of our evaluation experiments show that the system derives accurate paraphrases, outperforming baseline systems."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 81
                            }
                        ],
                        "text": "For instance, consider the following two sentences (similar to examples found in Smadja and McKeown (1991)):\nAfter the latest Fed rate cut, stocks rose across the board."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using collocations for language generation Special issue on natural language generation"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Intelligence"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kevin Knight"
            },
            "venue": {
                "fragments": [],
                "text": "and Daniel Marcu."
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Practical issues in automatic documentation"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the ACL,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Karen Kukich"
            },
            "venue": {
                "fragments": [],
                "text": "and James Shaw."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Naftali Tishby"
            },
            "venue": {
                "fragments": [],
                "text": "and Lillian Lee."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "tributional clustering of English words"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . of the ACL"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syntaxbased alignment of multiple translations: Extracting para"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 58
                            }
                        ],
                        "text": "However, in studies of paraphrases across several domains (Iordanskaja et al., 1991; Robin, 1994; McKeown et al., 1994), this was generally not the case."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 103
                            }
                        ],
                        "text": "However, in studies of paraphrases across several domains (Iordanskaja, Kittredge, and Polguere, 1991; Robin, 1994; McKeown, Kukich, and Shaw, 1994), this was generally not the case."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1994.Revision-Based Generation of Natural Language Summaries Providing Historical Background: Corpus-Based Analysis, Design, Implementation, and Evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. thesis,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syntagmaticand paradigmatic representations of term variations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Explorations in Automatic Thesaurus Discovery, volume 278"
            },
            "venue": {
                "fragments": [],
                "text": "Kluwer. [Iordanskaja, Kittredge, and Polguere1991] Iordanskaja, L"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 103
                            }
                        ],
                        "text": "Learning synonyms via distributional similarity has been well-studied (Pereira, Tishby, and Lee, 1993; Grefenstette, 1994; Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 70
                            }
                        ],
                        "text": "Learning synonyms via distributional similarity has been well-studied (Pereira et al., 1993; Grefenstette, 1994; Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Explorations in Automatic Thesaurus Discovery, volume 278"
            },
            "venue": {
                "fragments": [],
                "text": "Explorations in Automatic Thesaurus Discovery, volume 278"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Strategies for effect"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 3,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 40,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-to-Paraphrase:-An-Unsupervised-Approach-Barzilay-Lee/10b8f21e57b3392ce623c374c2c039f811ce5f69?sort=total-citations"
}