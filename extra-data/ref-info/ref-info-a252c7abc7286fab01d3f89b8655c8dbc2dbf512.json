{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37423160"
                        ],
                        "name": "Suncong Zheng",
                        "slug": "Suncong-Zheng",
                        "structuredName": {
                            "firstName": "Suncong",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suncong Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145756722"
                        ],
                        "name": "Feng Wang",
                        "slug": "Feng-Wang",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2682574"
                        ],
                        "name": "Hongyun Bao",
                        "slug": "Hongyun-Bao",
                        "structuredName": {
                            "firstName": "Hongyun",
                            "lastName": "Bao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongyun Bao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8361912"
                        ],
                        "name": "Yuexing Hao",
                        "slug": "Yuexing-Hao",
                        "structuredName": {
                            "firstName": "Yuexing",
                            "lastName": "Hao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuexing Hao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144032121"
                        ],
                        "name": "P. Zhou",
                        "slug": "P.-Zhou",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109511511"
                        ],
                        "name": "Bo Xu",
                        "slug": "Bo-Xu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11751039,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5d6779073901989f14de984e2236891a801c2bd",
            "isKey": false,
            "numCitedBy": 310,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Joint extraction of entities and relations is an important task in information extraction. To tackle this problem, we firstly propose a novel tagging scheme that can convert the joint extraction task to a tagging problem. Then, based on our tagging scheme, we study different end-to-end models to extract entities and their relations directly, without identifying entities and relations separately. We conduct experiments on a public dataset produced by distant supervision method and the experimental results show that the tagging based methods are better than most of the existing pipelined and joint learning methods. What's more, the end-to-end model proposed in this paper, achieves the best results on the public dataset."
            },
            "slug": "Joint-Extraction-of-Entities-and-Relations-Based-on-Zheng-Wang",
            "title": {
                "fragments": [],
                "text": "Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A novel tagging scheme is proposed that can convert the joint extraction task to a tagging problem, and different end-to-end models are studied to extract entities and their relations directly, without identifying entities and relations separately."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118912383"
                        ],
                        "name": "Qi Li",
                        "slug": "Qi-Li",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016781"
                        ],
                        "name": "Heng Ji",
                        "slug": "Heng-Ji",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Ji"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 55
                            }
                        ],
                        "text": "The joint methods are listed as follows: (4) DS-Joint [Li and Ji, 2014] is a supervised method, which jointly extracts entities and relations using structured perceptron on humanannotated dataset; (5) MultiR [Hoffmann et al., 2011] is a typical distant supervised method based on multi-instance\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 45
                            }
                        ],
                        "text": "The joint methods are listed as follows: (4) DS-Joint [Li and Ji, 2014] is a supervised method, which jointly extracts entities and relations using structured perceptron on humanannotated dataset; (5) MultiR [Hoffmann et al., 2011] is a typical distant supervised method based on multi-instance learning algorithms to combat the noisy training data; (6) CoType [Ren et al., 2017] is a domain independent framework by jointly embedding entity mentions, relation mentions, text features and type labels into meaningful representations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 67
                            }
                        ],
                        "text": "Joint models have been investigated using both statistical methods [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 65
                            }
                        ],
                        "text": "Existing joint methods include feature-based statistical systems [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 54
                            }
                        ],
                        "text": "The joint methods are listed as follows: (4) DS-Joint [Li and Ji, 2014] is a supervised method, which jointly extracts entities and relations using structured perceptron on humanannotated dataset; (5) MultiR [Hoffmann et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 109
                            }
                        ],
                        "text": "Joint models have been investigated using both statistical methods [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al., 2017; Katiyar and Cardie, 2017; Miwa and Bansal, 2016]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Li and Ji, 2014] heavily rely on complicated feature engineering and it is difficult to exploit global features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 107
                            }
                        ],
                        "text": "Existing joint methods include feature-based statistical systems [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b156bdce947783b8c7071f02557b414ab7b5276",
            "isKey": true,
            "numCitedBy": 336,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an incremental joint framework to simultaneously extract entity mentions and relations using structured perceptron with efficient beam-search. A segment-based decoder based on the idea of semi-Markov chain is adopted to the new framework as opposed to traditional token-based tagging. In addition, by virtue of the inexact search, we developed a number of new and effective global features as soft constraints to capture the interdependency among entity mentions and relations. Experiments on Automatic Content Extraction (ACE) 1 corpora demonstrate that our joint model significantly outperforms a strong pipelined baseline, which attains better performance than the best-reported end-to-end system."
            },
            "slug": "Incremental-Joint-Extraction-of-Entity-Mentions-and-Li-Ji",
            "title": {
                "fragments": [],
                "text": "Incremental Joint Extraction of Entity Mentions and Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An incremental joint framework to simultaneously extract entity mentions and relations using structured perceptron with efficient beam-search is presented, which significantly outperforms a strong pipelined baseline, which attains better performance than the best-reported end-to-end system."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731657"
                        ],
                        "name": "Makoto Miwa",
                        "slug": "Makoto-Miwa",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Miwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Makoto Miwa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115075487"
                        ],
                        "name": "Yutaka Sasaki",
                        "slug": "Yutaka-Sasaki",
                        "structuredName": {
                            "firstName": "Yutaka",
                            "lastName": "Sasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yutaka Sasaki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 955518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1845a57621ba2ce9ff3c2d1dcaa1f7f4b04b2186",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a history-based structured learning approach that jointly extracts entities and relations in a sentence. We introduce a novel simple and flexible table representation of entities and relations. We investigate several feature settings, search orders, and learning methods with inexact search on the table. The experimental results demonstrate that a joint learning approach significantly outperforms a pipeline approach by incorporating global features and by selecting appropriate learning methods and search orders."
            },
            "slug": "Modeling-Joint-Entity-and-Relation-Extraction-with-Miwa-Sasaki",
            "title": {
                "fragments": [],
                "text": "Modeling Joint Entity and Relation Extraction with Table Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The experimental results demonstrate that a joint learning approach significantly outperforms a pipeline approach by incorporating global features and by selecting appropriate learning methods and search orders."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145201124"
                        ],
                        "name": "Xiang Ren",
                        "slug": "Xiang-Ren",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiang Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7806955"
                        ],
                        "name": "Zeqiu Wu",
                        "slug": "Zeqiu-Wu",
                        "structuredName": {
                            "firstName": "Zeqiu",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeqiu Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153475859"
                        ],
                        "name": "Wenqi He",
                        "slug": "Wenqi-He",
                        "structuredName": {
                            "firstName": "Wenqi",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenqi He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35955224"
                        ],
                        "name": "Meng Qu",
                        "slug": "Meng-Qu",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Qu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meng Qu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1817166"
                        ],
                        "name": "Clare R. Voss",
                        "slug": "Clare-R.-Voss",
                        "structuredName": {
                            "firstName": "Clare",
                            "lastName": "Voss",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clare R. Voss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016781"
                        ],
                        "name": "Heng Ji",
                        "slug": "Heng-Ji",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730531"
                        ],
                        "name": "T. Abdelzaher",
                        "slug": "T.-Abdelzaher",
                        "structuredName": {
                            "firstName": "Tarek",
                            "lastName": "Abdelzaher",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Abdelzaher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145325584"
                        ],
                        "name": "Jiawei Han",
                        "slug": "Jiawei-Han",
                        "structuredName": {
                            "firstName": "Jiawei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiawei Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 137
                            }
                        ],
                        "text": ", 2011] is a typical distant supervised method based on multi-instance learning algorithms to combat the noisy training data; (6) CoType [Ren et al., 2017] is a domain independent framework by jointly embedding entity mentions, relation mentions, text features and type labels into meaningful representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 360,
                                "start": 354
                            }
                        ],
                        "text": "The joint methods are listed as follows: (4) DS-Joint [Li and Ji, 2014] is a supervised method, which jointly extracts entities and relations using structured perceptron on humanannotated dataset; (5) MultiR [Hoffmann et al., 2011] is a typical distant supervised method based on multi-instance learning algorithms to combat the noisy training data; (6) CoType [Ren et al., 2017] is a domain independent framework by jointly embedding entity mentions, relation mentions, text features and type labels into meaningful representations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 84
                            }
                        ],
                        "text": "For the pipelined\n2The dataset can be downloaded at: https://github.com/shanzhenren/CoType.\nmethods, the NER results are obtained by Ren et al. [2017], then several classical relation classification methods are applied to detect the relations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 149
                            }
                        ],
                        "text": "Dateset To directly compare with Zheng et al. [2017], we use the public dataset NYT2 as our main data set, which is produced by distant supervision [Ren et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 80
                            }
                        ],
                        "text": "The labels of entity types are not considered when computing the final F1score [Ren et al., 2017; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 67
                            }
                        ],
                        "text": "Joint models have been investigated using both statistical methods [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 65
                            }
                        ],
                        "text": "Existing joint methods include feature-based statistical systems [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 60
                            }
                        ],
                        "text": "6 point improvement over the best jointly extracting method [Ren et al., 2017], and 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 145
                            }
                        ],
                        "text": "\u2026et al., 2011] is a typical distant supervised method based on multi-instance learning algorithms to combat the noisy training data; (6) CoType [Ren et al., 2017] is a domain independent framework by jointly embedding entity mentions, relation mentions, text features and type labels into\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 68
                            }
                        ],
                        "text": "Joint models have been investigated using both statistical methods [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al., 2017; Katiyar and Cardie, 2017; Miwa and Bansal, 2016]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 102
                            }
                        ],
                        "text": "[2017], we use the public dataset NYT2 as our main data set, which is produced by distant supervision [Ren et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 90
                            }
                        ],
                        "text": "In particular, it achieves 4.6 point improvement over the best jointly extracting method [Ren et al., 2017], and 1.4 point improvement over the best end-to-end sequence labeling method [Zheng et al., 2017], demonstrating the effectiveness of our model on modeling and predicting entities and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "Existing joint methods include feature-based statistical systems [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1724837,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "060ccf4b9e7c2f4b867ec52c5a5682eb1384e8fb",
            "isKey": true,
            "numCitedBy": 210,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Extracting entities and relations for types of interest from text is important for understanding massive text corpora. Traditionally, systems of entity relation extraction have relied on human-annotated corpora for training and adopted an incremental pipeline. Such systems require additional human expertise to be ported to a new domain, and are vulnerable to errors cascading down the pipeline. In this paper, we investigate joint extraction of typed entities and relations with labeled data heuristically obtained from knowledge bases (i.e., distant supervision). As our algorithm for type labeling via distant supervision is context-agnostic, noisy training data poses unique challenges for the task. We propose a novel domain-independent framework, called CoType, that runs a data-driven text segmentation algorithm to extract entity mentions, and jointly embeds entity mentions, relation mentions, text features and type labels into two low-dimensional spaces (for entity and relation mentions respectively), where, in each space, objects whose types are close will also have similar representations. CoType, then using these learned embeddings, estimates the types of test (unlinkable) mentions. We formulate a joint optimization problem to learn embeddings from text corpora and knowledge bases, adopting a novel partial-label loss function for noisy labeled data and introducing an object \"translation\" function to capture the cross-constraints of entities and relations on each other. Experiments on three public datasets demonstrate the effectiveness of CoType across different domains (e.g., news, biomedical), with an average of 25% improvement in F1 score compared to the next best method."
            },
            "slug": "CoType:-Joint-Extraction-of-Typed-Entities-and-with-Ren-Wu",
            "title": {
                "fragments": [],
                "text": "CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel domain-independent framework that jointly embeds entity mentions, relation mentions, text features and type labels into two low-dimensional spaces, and adopts a novel partial-label loss function for noisy labeled data and introduces an object \"translation\" function to capture the cross-constraints of entities and relations on each other."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2199597"
                        ],
                        "name": "Arzoo Katiyar",
                        "slug": "Arzoo-Katiyar",
                        "structuredName": {
                            "firstName": "Arzoo",
                            "lastName": "Katiyar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arzoo Katiyar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748501"
                        ],
                        "name": "Claire Cardie",
                        "slug": "Claire-Cardie",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Cardie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Cardie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 67
                            }
                        ],
                        "text": ", 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al., 2017; Katiyar and Cardie, 2017; Miwa and Bansal, 2016]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 166
                            }
                        ],
                        "text": "Joint models have been investigated using both statistical methods [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al., 2017; Katiyar and Cardie, 2017; Miwa and Bansal, 2016]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 67
                            }
                        ],
                        "text": ", 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 38
                            }
                        ],
                        "text": "However, most existing neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016] extract entities and relations separately, achieving joint learning only through parameter sharing, but not joint decoding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 144
                            }
                        ],
                        "text": "Existing joint methods include feature-based statistical systems [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 441563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbbd45338fbd85b0bacf23918bb77107f4cfb69e",
            "isKey": true,
            "numCitedBy": 134,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel attention-based recurrent neural network for joint extraction of entity mentions and relations. We show that attention along with long short term memory (LSTM) network can extract semantic relations between entity mentions without having access to dependency trees. Experiments on Automatic Content Extraction (ACE) corpora show that our model significantly outperforms feature-based joint model by Li and Ji (2014). We also compare our model with an end-to-end tree-based LSTM model (SPTree) by Miwa and Bansal (2016) and show that our model performs within 1% on entity mentions and 2% on relations. Our fine-grained analysis also shows that our model performs significantly better on Agent-Artifact relations, while SPTree performs better on Physical and Part-Whole relations."
            },
            "slug": "Going-out-on-a-limb:-Joint-Extraction-of-Entity-and-Katiyar-Cardie",
            "title": {
                "fragments": [],
                "text": "Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "It is shown that attention along with long short term memory (LSTM) network can extract semantic relations between entity mentions without having access to dependency trees."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143740945"
                        ],
                        "name": "Guodong Zhou",
                        "slug": "Guodong-Zhou",
                        "structuredName": {
                            "firstName": "Guodong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guodong Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144538026"
                        ],
                        "name": "J. Su",
                        "slug": "J.-Su",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2159189624"
                        ],
                        "name": "Jie Zhang",
                        "slug": "Jie-Zhang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156053331"
                        ],
                        "name": "Min Zhang",
                        "slug": "Min-Zhang",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3160937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68cd1c7c0651b116a83abab8a7a46a29975d3b5f",
            "isKey": false,
            "numCitedBy": 710,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Extracting semantic relationships between entities is challenging. This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM. Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement. This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking. We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance. Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types."
            },
            "slug": "Exploring-Various-Knowledge-in-Relation-Extraction-Zhou-Su",
            "title": {
                "fragments": [],
                "text": "Exploring Various Knowledge in Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM and illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39798499"
                        ],
                        "name": "Yang Liu",
                        "slug": "Yang-Liu",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49807919"
                        ],
                        "name": "Furu Wei",
                        "slug": "Furu-Wei",
                        "structuredName": {
                            "firstName": "Furu",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Furu Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695451"
                        ],
                        "name": "Sujian Li",
                        "slug": "Sujian-Li",
                        "structuredName": {
                            "firstName": "Sujian",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sujian Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016781"
                        ],
                        "name": "Heng Ji",
                        "slug": "Heng-Ji",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143849609"
                        ],
                        "name": "M. Zhou",
                        "slug": "M.-Zhou",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781885"
                        ],
                        "name": "Houfeng Wang",
                        "slug": "Houfeng-Wang",
                        "structuredName": {
                            "firstName": "Houfeng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Houfeng Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7475429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72b88705083fda3df98e114507ad76094a0465ec",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous research on relation classification has verified the effectiveness of using dependency shortest paths or subtrees. In this paper, we further explore how to make full use of the combination of these dependency information. We first propose a new structure, termed augmented dependency path (ADP), which is composed of the shortest dependency path between two entities and the subtrees attached to the shortest path. To exploit the semantic representation behind the ADP structure, we develop dependency-based neural networks (DepNN): a recursive neural network designed to model the subtrees, and a convolutional neural network to capture the most important features on the shortest path. Experiments on the SemEval-2010 dataset show that our proposed method achieves state-of-art results."
            },
            "slug": "A-Dependency-Based-Neural-Network-for-Relation-Liu-Wei",
            "title": {
                "fragments": [],
                "text": "A Dependency-Based Neural Network for Relation Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new structure, termed augmented dependency path (ADP), is proposed, which is composed of the shortest dependency path between two entities and the subtrees attached to the shortest path, and a dependency-based neural networks (DepNN) are developed to exploit the semantic representation behind the ADP."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2566295"
                        ],
                        "name": "Raphael Hoffmann",
                        "slug": "Raphael-Hoffmann",
                        "structuredName": {
                            "firstName": "Raphael",
                            "lastName": "Hoffmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raphael Hoffmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799338"
                        ],
                        "name": "Congle Zhang",
                        "slug": "Congle-Zhang",
                        "structuredName": {
                            "firstName": "Congle",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Congle Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145787377"
                        ],
                        "name": "Xiao Ling",
                        "slug": "Xiao-Ling",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16483125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d48edf9e81653f4c3da716b037b0b50d54c5b034",
            "isKey": false,
            "numCitedBy": 870,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction (IE) holds the promise of generating a large-scale knowledge base from the Web's natural language text. Knowledge-based weak supervision, using structured data to heuristically label a training corpus, works towards this goal by enabling the automated learning of a potentially unbounded number of relation extractors. Recently, researchers have developed multi-instance learning algorithms to combat the noisy training data that can come from heuristic labeling, but their models assume relations are disjoint --- for example they cannot extract the pair Founded(Jobs, Apple) and CEO-of(Jobs, Apple). \n \nThis paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extraction model with a simple, corpus-level component for aggregating the individual facts. We apply our model to learn extractors for NY Times text using weak supervision from Free-base. Experiments show that the approach runs quickly and yields surprising gains in accuracy, at both the aggregate and sentence level."
            },
            "slug": "Knowledge-Based-Weak-Supervision-for-Information-of-Hoffmann-Zhang",
            "title": {
                "fragments": [],
                "text": "Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel approach for multi-instance learning with overlapping relations that combines a sentence-level extraction model with a simple, corpus-level component for aggregating the individual facts is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2427350"
                        ],
                        "name": "Yankai Lin",
                        "slug": "Yankai-Lin",
                        "structuredName": {
                            "firstName": "Yankai",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yankai Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2589625"
                        ],
                        "name": "Shiqi Shen",
                        "slug": "Shiqi-Shen",
                        "structuredName": {
                            "firstName": "Shiqi",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shiqi Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49293587"
                        ],
                        "name": "Zhiyuan Liu",
                        "slug": "Zhiyuan-Liu",
                        "structuredName": {
                            "firstName": "Zhiyuan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiyuan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371599"
                        ],
                        "name": "Huanbo Luan",
                        "slug": "Huanbo-Luan",
                        "structuredName": {
                            "firstName": "Huanbo",
                            "lastName": "Luan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huanbo Luan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753344"
                        ],
                        "name": "Maosong Sun",
                        "slug": "Maosong-Sun",
                        "structuredName": {
                            "firstName": "Maosong",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maosong Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 397533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "345ef9a7d9af0ac0816d76803ddcf9b6d19404d7",
            "isKey": false,
            "numCitedBy": 746,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Distant supervised relation extraction has been widely used to find novel relational facts from text. However, distant supervision inevitably accompanies with the wrong labelling problem, and these noisy data will substantially hurt the performance of relation extraction. To alleviate this issue, we propose a sentence-level attention-based model for relation extraction. In this model, we employ convolutional neural networks to embed the semantics of sentences. Afterwards, we build sentence-level attention over multiple instances, which is expected to dynamically reduce the weights of those noisy instances. Experimental results on real-world datasets show that, our model can make full use of all informative sentences and effectively reduce the influence of wrong labelled instances. Our model achieves significant and consistent improvements on relation extraction as compared with baselines. The source code of this paper can be obtained from https: //github.com/thunlp/NRE."
            },
            "slug": "Neural-Relation-Extraction-with-Selective-Attention-Lin-Shen",
            "title": {
                "fragments": [],
                "text": "Neural Relation Extraction with Selective Attention over Instances"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A sentence-level attention-based model for relation extraction that employs convolutional neural networks to embed the semantics of sentences and dynamically reduce the weights of those noisy instances."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731657"
                        ],
                        "name": "Makoto Miwa",
                        "slug": "Makoto-Miwa",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Miwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Makoto Miwa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977268"
                        ],
                        "name": "Mohit Bansal",
                        "slug": "Mohit-Bansal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Bansal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 73
                            }
                        ],
                        "text": "However, most existing neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016] extract entities and relations separately, achieving joint learning only through parameter sharing, but not joint decoding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 179
                            }
                        ],
                        "text": "Existing joint methods include feature-based statistical systems [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 201
                            }
                        ],
                        "text": "Joint models have been investigated using both statistical methods [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al., 2017; Katiyar and Cardie, 2017; Miwa and Bansal, 2016]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2476229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3899f87a2031f3434f89beb68c11a1ca6428328a",
            "isKey": false,
            "numCitedBy": 796,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel end-to-end neural model to extract entities and relations between them. Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional tree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows our model to jointly represent both entities and relations with shared parameters in a single model. We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. Our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and ACE2004, respectively. We also show that our LSTM-RNN based model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components."
            },
            "slug": "End-to-End-Relation-Extraction-using-LSTMs-on-and-Miwa-Bansal",
            "title": {
                "fragments": [],
                "text": "End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A novel end-to-end neural model to extract entities and relations between them and compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762110"
                        ],
                        "name": "Matthew R. Gormley",
                        "slug": "Matthew-R.-Gormley",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Gormley",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew R. Gormley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482533"
                        ],
                        "name": "Mo Yu",
                        "slug": "Mo-Yu",
                        "structuredName": {
                            "firstName": "Mo",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mo Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782853"
                        ],
                        "name": "Mark Dredze",
                        "slug": "Mark-Dredze",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dredze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Dredze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 163
                            }
                        ],
                        "text": "\u2026and unsupervised IE features; (2) LINE [Tang et al., 2015] is a network embedding method, which is suitable for arbitrary types of information networks; (3) FCM [Gormley et al., 2015] is a compositional model that combines lexicalized linguistic context and word embeddings for relation extraction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 316,
                                "start": 313
                            }
                        ],
                        "text": "These methods include: (1) DSlogistic [Mintz et al., 2009] is a distant supervised and feature based method, which combines the advantages of supervised IE and unsupervised IE features; (2) LINE [Tang et al., 2015] is a network embedding method, which is suitable for arbitrary types of information networks; (3) FCM [Gormley et al., 2015] is a compositional model that combines lexicalized linguistic context and word embeddings for relation extraction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 110
                            }
                        ],
                        "text": ", 2015] is a network embedding method, which is suitable for arbitrary types of information networks; (3) FCM [Gormley et al., 2015] is a compositional model that combines lexicalized linguistic context and word embeddings for relation extraction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 247735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30f4599c16223237d5622e2150b59211e641032f",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Compositional embedding models build a representation (or embedding) for a linguistic structure based on its component word embeddings. We propose a Feature-rich Compositional Embedding Model (FCM) for relation extraction that is expressive, generalizes to new domains, and is easy-to-implement. The key idea is to combine both (unlexicalized) hand-crafted features with learned word embeddings. The model is able to directly tackle the difficulties met by traditional compositional embeddings models, such as handling arbitrary types of sentence annotations and utilizing global information for composition. We test the proposed model on two relation extraction tasks, and demonstrate that our model outperforms both previous compositional models and traditional feature rich models on the ACE 2005 relation extraction task, and the SemEval 2010 relation classification task. The combination of our model and a log-linear classifier with hand-crafted features gives state-of-the-art results."
            },
            "slug": "Improved-Relation-Extraction-with-Feature-Rich-Gormley-Yu",
            "title": {
                "fragments": [],
                "text": "Improved Relation Extraction with Feature-Rich Compositional Embedding Models"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A Feature-rich Compositional Embedding Model (FCM) for relation extraction that is expressive, generalizes to new domains, and is easy-to-implement that outperforms both previous compositional models and traditional feature rich models."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2262359"
                        ],
                        "name": "Yuxuan Wang",
                        "slug": "Yuxuan-Wang",
                        "structuredName": {
                            "firstName": "Yuxuan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuxuan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256319"
                        ],
                        "name": "Wanxiang Che",
                        "slug": "Wanxiang-Che",
                        "structuredName": {
                            "firstName": "Wanxiang",
                            "lastName": "Che",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wanxiang Che"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144084849"
                        ],
                        "name": "Jiang Guo",
                        "slug": "Jiang-Guo",
                        "structuredName": {
                            "firstName": "Jiang",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiang Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40282288"
                        ],
                        "name": "Ting Liu",
                        "slug": "Ting-Liu",
                        "structuredName": {
                            "firstName": "Ting",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ting Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19118353,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b13fb64c79c7628382b0613e3d22462ddd6385b",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic dependency graph has been recently proposed as an extension of tree-structured syntactic or semantic representation for natural language sentences. It particularly features the structural property of multi-head, which allows nodes to have multiple heads, resulting in a directed acyclic graph (DAG) parsing problem. Yet most statistical parsers focused exclusively on shallow bi-lexical tree structures, DAG parsing remains under-explored. In this paper, we propose a neural transition-based parser, using a variant of list-based arc-eager transition algorithm for dependency graph parsing. Particularly, two non-trivial improvements are proposed for representing the key components of the transition system, to better capture the semantics of segments and internal sub-graph structures. We test our parser on the SemEval-2016 Task 9 dataset (Chinese) and the SemEval-2015 Task 18 dataset (English). On both benchmark datasets, we obtain superior or comparable results to the best performing systems. Our parser can be further improved with a simple ensemble mechanism, resulting in the state-of-the-art performance."
            },
            "slug": "A-Neural-Transition-Based-Approach-for-Semantic-Wang-Che",
            "title": {
                "fragments": [],
                "text": "A Neural Transition-Based Approach for Semantic Dependency Graph Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A neural transition-based parser, using a variant of list-based arc-eager transition algorithm for dependency graph parsing, and two non-trivial improvements are proposed for representing the key components of the transition system, to better capture the semantics of segments and internal sub-graph structures."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145357803"
                        ],
                        "name": "Jian Tang",
                        "slug": "Jian-Tang",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35955224"
                        ],
                        "name": "Meng Qu",
                        "slug": "Meng-Qu",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Qu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meng Qu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108927052"
                        ],
                        "name": "Mingzhe Wang",
                        "slug": "Mingzhe-Wang",
                        "structuredName": {
                            "firstName": "Mingzhe",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingzhe Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47474380"
                        ],
                        "name": "Ming Zhang",
                        "slug": "Ming-Zhang",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112592519"
                        ],
                        "name": "Jun Yan",
                        "slug": "Jun-Yan",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743469"
                        ],
                        "name": "Q. Mei",
                        "slug": "Q.-Mei",
                        "structuredName": {
                            "firstName": "Qiaozhu",
                            "lastName": "Mei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Mei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 144
                            }
                        ],
                        "text": ", 2009] is a distant supervised and feature based method, which combines the advantages of supervised IE and unsupervised IE features; (2) LINE [Tang et al., 2015] is a network embedding method, which is suitable for arbitrary types of information networks; (3) FCM [Gormley et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 149
                            }
                        ],
                        "text": "\u2026al., 2009] is a distant supervised and feature based method, which combines the advantages of supervised IE and unsupervised IE features; (2) LINE [Tang et al., 2015] is a network embedding method, which is suitable for arbitrary types of information networks; (3) FCM [Gormley et al., 2015] is a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "These methods include: (1) DSlogistic [Mintz et al., 2009] is a distant supervised and feature based method, which combines the advantages of supervised IE and unsupervised IE features; (2) LINE [Tang et al., 2015] is a network embedding method, which is suitable for arbitrary types of information networks; (3) FCM [Gormley et al., 2015] is a compositional model that combines lexicalized linguistic context and word embeddings for relation extraction."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8399404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0834e74304b547c9354b6d7da6fa78ef47a48fa8",
            "isKey": false,
            "numCitedBy": 3689,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,'' which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\\footnote{\\url{https://github.com/tangjianpku/LINE}}."
            },
            "slug": "LINE:-Large-scale-Information-Network-Embedding-Tang-Qu",
            "title": {
                "fragments": [],
                "text": "LINE: Large-scale Information Network Embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel network embedding method called the ``LINE,'' which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted, and optimizes a carefully designed objective function that preserves both the local and global network structures."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10901371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "053f1cf10ced2321c1853f307075f0a6a83b6840",
            "isKey": false,
            "numCitedBy": 460,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Parsing algorithms that process the input from left to right and construct a single derivation have often been considered inadequate for natural language parsing because of the massive ambiguity typically found in natural language grammars. Nevertheless, it has been shown that such algorithms, combined with treebank-induced classifiers, can be used to build highly accurate disambiguating parsers, in particular for dependency-based syntactic representations. In this article, we first present a general framework for describing and analyzing algorithms for deterministic incremental dependency parsing, formalized as transition systems. We then describe and analyze two families of such algorithms: stack-based and list-based algorithms. In the former family, which is restricted to projective dependency structures, we describe an arc-eager and an arc-standard variant; in the latter family, we present a projective and a non-projective variant. For each of the four algorithms, we give proofs of correctness and complexity. In addition, we perform an experimental evaluation of all algorithms in combination with SVM classifiers for predicting the next parsing action, using data from thirteen languages. We show that all four algorithms give competitive accuracy, although the non-projective list-based algorithm generally outperforms the projective algorithms for languages with a non-negligible proportion of non-projective constructions. However, the projective algorithms often produce comparable results when combined with the technique known as pseudo-projective parsing. The linear time complexity of the stack-based algorithms gives them an advantage with respect to efficiency both in learning and in parsing, but the projective list-based algorithm turns out to be equally efficient in practice. Moreover, when the projective algorithms are used to implement pseudo-projective parsing, they sometimes become less efficient in parsing (but not in learning) than the non-projective list-based algorithm. Although most of the algorithms have been partially described in the literature before, this is the first comprehensive analysis and evaluation of the algorithms within a unified framework."
            },
            "slug": "Algorithms-for-Deterministic-Incremental-Dependency-Nivre",
            "title": {
                "fragments": [],
                "text": "Algorithms for Deterministic Incremental Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This article presents a general framework for describing and analyzing algorithms for deterministic incremental dependency parsing, formalized as transition systems and shows that all four algorithms give competitive accuracy, although the non-projective list-based algorithm generally outperforms the projective algorithms for languages with a non-negligible proportion of non- projective constructions."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3465712"
                        ],
                        "name": "Onur Kuru",
                        "slug": "Onur-Kuru",
                        "structuredName": {
                            "firstName": "Onur",
                            "lastName": "Kuru",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Onur Kuru"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33299173"
                        ],
                        "name": "Ozan Arkan Can",
                        "slug": "Ozan-Arkan-Can",
                        "structuredName": {
                            "firstName": "Ozan",
                            "lastName": "Can",
                            "middleNames": [
                                "Arkan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ozan Arkan Can"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2808366"
                        ],
                        "name": "Deniz Yuret",
                        "slug": "Deniz-Yuret",
                        "structuredName": {
                            "firstName": "Deniz",
                            "lastName": "Yuret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deniz Yuret"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 225
                            }
                        ],
                        "text": "Transitions Preconditions of transition actions LEFTl-\u2217 [i 6= 0] \u2227 \u00ac[(i\u2192\u2217 j) \u2208 R] \u2227 (j \u2208 E) RIGHTl-\u2217 \u00ac[(j \u2192\u2217 i) \u2208 R] \u2227 (j \u2208 E) \u2217-REDUCE \u00ac[\u2203k \u2208 \u03b2.(i\u2192 k) \u2228 (i\u2190 k)] \u2227 (j \u2208 E) \u2217-SHIFT \u00ac[\u2203k \u2208 \u03c3.(k 6= i) \u2227 ((k \u2192 j) \u2228 (k \u2190 j))] \u2227 (j \u2208 E) O-DELETE (j /\u2208 E) \u2227 (e = [ ]) GEN-SHIFT (j /\u2208 E) GEN-NER (j /\u2208 E) \u2227 (e 6\u2261 [ ])\nTable 2: Preconditions of transition actions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "O-DELETE pops wj out of \u03b2. GEN-SHIFT moves wj from \u03b2 to e. GEN-NER(y) pops all items from the top of e creating a \u201cchunk\u201d, labels this with label y, pushes a representation of this chunk onto \u03b2, and an entity is added to E."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "For the pipelined\n2The dataset can be downloaded at: https://github.com/shanzhenren/CoType.\nmethods, the NER results are obtained by Ren et al. [2017], then several classical relation classification methods are applied to detect the relations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "Entity Chunks When GEN-NER(y) is executed, the algorithm shifts the sequence of words on e to the top of \u03b2 as a single completed chunk."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 33
                            }
                        ],
                        "text": ", named entity recognition (NER) [Florian et al., 2010; Kuru et al., 2016] and relation extraction [Bunescu and Mooney, 2005; Liu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 112
                            }
                        ],
                        "text": "The former treats this task as two separated tasks, i.e., named entity recognition (NER) [Florian et al., 2010; Kuru et al., 2016] and relation extraction [Bunescu and Mooney, 2005; Liu et al., 2015; Lin et al., 2016]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18057757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d95f72fd2c84a4c412eb519b660e402db51d154a",
            "isKey": true,
            "numCitedBy": 85,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate a character-level tagger for language-independent Named Entity Recognition (NER). Instead of words, a sentence is represented as a sequence of characters. The model consists of stacked bidirectional LSTMs which inputs characters and outputs tag probabilities for each character. These probabilities are then converted to consistent word level named entity tags using a Viterbi decoder. We are able to achieve close to state-of-the-art NER performance in seven languages with the same basic model using only labeled NER data and no hand-engineered features or other external resources like syntactic taggers or Gazetteers."
            },
            "slug": "CharNER:-Character-Level-Named-Entity-Recognition-Kuru-Can",
            "title": {
                "fragments": [],
                "text": "CharNER: Character-Level Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work describes and evaluates a character-level tagger for language-independent Named Entity Recognition (NER) which consists of stacked bidirectional LSTMs which inputs characters and outputs tag probabilities for each character using a Viterbi decoder."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111824520"
                        ],
                        "name": "Hao Zhou",
                        "slug": "Hao-Zhou",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48378565"
                        ],
                        "name": "Yue Zhang",
                        "slug": "Yue-Zhang",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2046010"
                        ],
                        "name": "Shujian Huang",
                        "slug": "Shujian-Huang",
                        "structuredName": {
                            "firstName": "Shujian",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shujian Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838162"
                        ],
                        "name": "Jiajun Chen",
                        "slug": "Jiajun-Chen",
                        "structuredName": {
                            "firstName": "Jiajun",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiajun Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 230
                            }
                        ],
                        "text": "Recently, neural transition-based parsers have achieved highly competitive accuracies thanks to the modeling of output-output relations [Dyer et al., 2015; Kiperwasser and Goldberg, 2016; Lample et al., 2016; Liu and Zhang, 2017; Zhou et al., 2015; Wang et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17887856,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c22177821ffebc8bbdd8fd0d10b91a48c18d495",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural probabilistic parsers are attractive for their capability of automatic feature combination and small data sizes. A transition-based greedy neural parser has given better accuracies over its linear counterpart. We propose a neural probabilistic structured-prediction model for transition-based dependency parsing, which integrates search and learning. Beam search is used for decoding, and contrastive learning is performed for maximizing the sentence-level log-likelihood. In standard Penn Treebank experiments, the structured neural parser achieves a 1.8% accuracy improvement upon a competitive greedy neural parser baseline, giving performance comparable to the best linear parser."
            },
            "slug": "A-Neural-Probabilistic-Structured-Prediction-Model-Zhou-Zhang",
            "title": {
                "fragments": [],
                "text": "A Neural Probabilistic Structured-Prediction Model for Transition-Based Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural probabilistic structured-prediction model for transition-based dependency parsing, which integrates search and learning is proposed, giving performance comparable to the best linear parser."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40421028"
                        ],
                        "name": "David Nadeau",
                        "slug": "David-Nadeau",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nadeau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Nadeau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714612"
                        ],
                        "name": "S. Sekine",
                        "slug": "S.-Sekine",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Sekine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sekine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8310135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a554da55fd9ff76c99e25d2ce937b225dc1100c",
            "isKey": false,
            "numCitedBy": 2307,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "This survey covers fifteen years of research in the Named Entity Recognition and Classification (NERC) field, from 1991 to 2006. We report observations about languages, named entity types, domains and textual genres studied in the literature. From the start, NERC systems have been developed using hand-made rules, but now machine learning techniques are widely used. These techniques are surveyed along with other critical aspects of NERC such as features and evaluation methods. Features are word-level, dictionary-level and corpus-level representations of words in a document. Evaluation techniques, ranging from intuitive exact match to very complex matching techniques with adjustable cost of errors, are an indisputable key to progress."
            },
            "slug": "A-survey-of-named-entity-recognition-and-Nadeau-Sekine",
            "title": {
                "fragments": [],
                "text": "A survey of named entity recognition and classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Observations about languages, named entity types, domains and textual genres studied in the literature, along with other critical aspects of NERC such as features and evaluation methods, are reported."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39939186"
                        ],
                        "name": "Yue Zhang",
                        "slug": "Yue-Zhang",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7245369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f24fb33e739b0181fc171b515f957190e3bb6430",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model, trained by the generalized perceptron together with a generic beam-search decoder. We apply the framework to word segmentation, joint segmentation and POS-tagging, dependency parsing, and phrase-structure parsing. Both components of the framework are conceptually and computationally very simple. The beam-search decoder only requires the syntactic processing task to be broken into a sequence of decisions, such that, at each stage in the process, the decoder is able to consider the top-n candidates and generate all possibilities for the next stage. Once the decoder has been defined, it is applied to the training data, using trivial updates according to the generalized perceptron to induce a model. This simple framework performs surprisingly well, giving accuracy results competitive with the state-of-the-art on all the tasks we consider. The computational simplicity of the decoder and training algorithm leads to significantly higher test speeds and lower training times than their main alternatives, including log-linear and large-margin training algorithms and dynamic-programming for decoding. Moreover, the framework offers the freedom to define arbitrary features which can make alternative training and decoding algorithms prohibitively slow. We discuss how the general framework is applied to each of the problems studied in this article, making comparisons with alternative learning and decoding algorithms. We also show how the comparability of candidates considered by the beam is an important factor in the performance. We argue that the conceptual and computational simplicity of the framework, together with its language-independent nature, make it a competitive choice for a range of syntactic processing tasks and one that should be considered for comparison by developers of alternative approaches."
            },
            "slug": "Syntactic-Processing-Using-the-Generalized-and-Beam-Zhang-Clark",
            "title": {
                "fragments": [],
                "text": "Syntactic Processing Using the Generalized Perceptron and Beam Search"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that the conceptual and computational simplicity of the framework, together with its language-independent nature, make it a competitive choice for a range of syntactic processing tasks and one that should be considered for comparison by developers of alternative approaches."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4724587"
                        ],
                        "name": "Jinho D. Choi",
                        "slug": "Jinho-D.-Choi",
                        "structuredName": {
                            "firstName": "Jinho",
                            "lastName": "Choi",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinho D. Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 535770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a7ec9126bda529e15668420ddf05effe7bc2306",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach, called selectional branching, which uses confidence estimates to decide when to employ a beam, providing the accuracy of beam search at speeds close to a greedy transition-based dependency parsing approach. Selectional branching is guaranteed to perform a fewer number of transitions than beam search yet performs as accurately. We also present a new transition-based dependency parsing algorithm that gives a complexity ofO(n) for projective parsing and an expected linear time speed for non-projective parsing. With the standard setup, our parser shows an unlabeled attachment score of 92.96% and a parsing speed of 9 milliseconds per sentence, which is faster and more accurate than the current state-of-the-art transitionbased parser that uses beam search."
            },
            "slug": "Transition-based-Dependency-Parsing-with-Branching-Choi-McCallum",
            "title": {
                "fragments": [],
                "text": "Transition-based Dependency Parsing with Selectional Branching"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A novel approach, called selectional branching, is presented, which uses confidence estimates to decide when to employ a beam, providing the accuracy of beam search at speeds close to a greedy transition-based dependency parsing approach."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1379953252"
                        ],
                        "name": "Wang Ling",
                        "slug": "Wang-Ling",
                        "structuredName": {
                            "firstName": "Wang",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690706"
                        ],
                        "name": "A. Black",
                        "slug": "A.-Black",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Black",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691021"
                        ],
                        "name": "I. Trancoso",
                        "slug": "I.-Trancoso",
                        "structuredName": {
                            "firstName": "Isabel",
                            "lastName": "Trancoso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Trancoso"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 104
                            }
                        ],
                        "text": "Following Dyer et al. [2015], we use a variant of the skip n-gram model, namely structured skip n-gram [Ling et al., 2015], to create word embeddings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 81
                            }
                        ],
                        "text": "[2015], we use a variant of the skip n-gram model, namely structured skip n-gram [Ling et al., 2015], to create word embeddings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14800090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b92513dac9d5b6a4683bcc625b94dd1ced98734e",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two simple modifications to the models in the popular Word2Vec tool, in order to generate embeddings more suited to tasks involving syntax. The main issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing using our proposed models."
            },
            "slug": "Two/Too-Simple-Adaptations-of-Word2Vec-for-Syntax-Ling-Dyer",
            "title": {
                "fragments": [],
                "text": "Two/Too Simple Adaptations of Word2Vec for Syntax Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "Two simple modifications to the models in the popular Word2Vec tool are presented, in order to generate embeddings more suited to tasks involving syntax."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701942"
                        ],
                        "name": "N. Cercone",
                        "slug": "N.-Cercone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Cercone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cercone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 51
                            }
                        ],
                        "text": "There has been work using transition-based methods [Zhang and Clark, 2011; Nivre, 2008] to produce dependency trees and directed acyclic graphs (DAGs), but little work on more accurately directed graph in our joint tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2542222,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "521c0a9a920562c681aa01de5471d226f99c050f",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "1. What is Computational Linguistics? 1.1. A few sketches in the history of Computational Linguistics 2. Automatic text processing 2.1. Parsing 2.2. Computational lexicons and ontologies 2.3. Acquisition methodologies 3. Applications 4. Infrastructural Language Resources 4.1. European projects 5. NLP in the global information and knowledge society 5.1. NLP in Europe 5.2. Production and \u201cintelligent\u201d use of the digital content (also multimedia) 6. Future perspectives 6.1. The promotion of national languages in the global society and the new Internet generation Glossary Bibliography Biographical Sketch"
            },
            "slug": "Computational-Linguistics-Cercone",
            "title": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This chapter discusses the promotion of national languages in the global society and the new Internet generation, and investigates the role of NLP in this society."
            },
            "venue": {
                "fragments": [],
                "text": "Communications in Computer and Information Science"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 53
                            }
                        ],
                        "text": "Case Study We compare our method with LSTM-LSTMBias [Zheng et al., 2017] on some cases, as shown in Table 6."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 67
                            }
                        ],
                        "text": ", 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al., 2017; Katiyar and Cardie, 2017; Miwa and Bansal, 2016]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 184
                            }
                        ],
                        "text": "\u2026particular, it achieves 4.6 point improvement over the best jointly extracting method [Ren et al., 2017], and 1.4 point improvement over the best end-to-end sequence labeling method [Zheng et al., 2017], demonstrating the effectiveness of our model on modeling and predicting entities and relations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 98
                            }
                        ],
                        "text": "The labels of entity types are not considered when computing the final F1score [Ren et al., 2017; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 16
                            }
                        ],
                        "text": "LSTM-LSTM-Bias [Zheng et al., 2017] is the baseline end-to-end method in \u00a72, LSTM-LSTM-Bias* is our implementation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 146
                            }
                        ],
                        "text": "Joint models have been investigated using both statistical methods [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al., 2017; Katiyar and Cardie, 2017; Miwa and Bansal, 2016]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 70
                            }
                        ],
                        "text": "4 point improvement over the best end-to-end sequence labeling method [Zheng et al., 2017], demonstrating the effectiveness of our model on modeling and predicting entities and relations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 67
                            }
                        ],
                        "text": ", 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 193
                            }
                        ],
                        "text": "Existing joint methods include feature-based statistical systems [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 1227\u20131236"
            },
            "venue": {
                "fragments": [],
                "text": "July"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 149
                            }
                        ],
                        "text": "Relation Labels Recursive neural network models enable complex phrases to be represented compositionally in terms of their components and relations [Dyer et al., 2015]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 137
                            }
                        ],
                        "text": "Recently, neural transition-based parsers have achieved highly competitive accuracies thanks to the modeling of output-output relations [Dyer et al., 2015; Kiperwasser and Goldberg, 2016; Lample et al., 2016; Liu and Zhang, 2017; Zhou et al., 2015; Wang et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 38
                            }
                        ],
                        "text": "We borrow the idea of neural parsing [Dyer et al., 2015; Kiperwasser and Goldberg, 2016], designing a\nspecial recursive neural network to model underlying entityrelation and relation-relation dependencies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 90
                            }
                        ],
                        "text": "Shown in Figure 3, for better capturing non-local context information, we use stack LSTM [Dyer et al., 2015] to represent different components of each state."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 37
                            }
                        ],
                        "text": "We borrow the idea of neural parsing [Dyer et al., 2015; Kiperwasser and Goldberg, 2016], designing a Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of ACL and IJCNLP,"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 225
                            }
                        ],
                        "text": "Transitions Preconditions of transition actions LEFTl-\u2217 [i 6= 0] \u2227 \u00ac[(i\u2192\u2217 j) \u2208 R] \u2227 (j \u2208 E) RIGHTl-\u2217 \u00ac[(j \u2192\u2217 i) \u2208 R] \u2227 (j \u2208 E) \u2217-REDUCE \u00ac[\u2203k \u2208 \u03b2.(i\u2192 k) \u2228 (i\u2190 k)] \u2227 (j \u2208 E) \u2217-SHIFT \u00ac[\u2203k \u2208 \u03c3.(k 6= i) \u2227 ((k \u2192 j) \u2228 (k \u2190 j))] \u2227 (j \u2208 E) O-DELETE (j /\u2208 E) \u2227 (e = [ ]) GEN-SHIFT (j /\u2208 E) GEN-NER (j /\u2208 E) \u2227 (e 6\u2261 [ ])\nTable 2: Preconditions of transition actions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "O-DELETE pops wj out of \u03b2. GEN-SHIFT moves wj from \u03b2 to e. GEN-NER(y) pops all items from the top of e creating a \u201cchunk\u201d, labels this with label y, pushes a representation of this chunk onto \u03b2, and an entity is added to E."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "For the pipelined\n2The dataset can be downloaded at: https://github.com/shanzhenren/CoType.\nmethods, the NER results are obtained by Ren et al. [2017], then several classical relation classification methods are applied to detect the relations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "Entity Chunks When GEN-NER(y) is executed, the algorithm shifts the sequence of words on e to the top of \u03b2 as a single completed chunk."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 33
                            }
                        ],
                        "text": ", named entity recognition (NER) [Florian et al., 2010; Kuru et al., 2016] and relation extraction [Bunescu and Mooney, 2005; Liu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 90
                            }
                        ],
                        "text": "The former treats this task as two separated tasks, i.e., named entity recognition (NER) [Florian et al., 2010; Kuru et al., 2016] and relation extraction [Bunescu and Mooney, 2005; Liu et al., 2015; Lin et al., 2016]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of EMNLP,"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 230
                            }
                        ],
                        "text": "Recently, neural transition-based parsers have achieved highly competitive accuracies thanks to the modeling of output-output relations [Dyer et al., 2015; Kiperwasser and Goldberg, 2016; Lample et al., 2016; Liu and Zhang, 2017; Zhou et al., 2015; Wang et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "of ACL"
            },
            "venue": {
                "fragments": [],
                "text": "pages 1213\u20131222,"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 136
                            }
                        ],
                        "text": "Recently, neural transition-based parsers have achieved highly competitive accuracies thanks to the modeling of output-output relations [Dyer et al., 2015; Kiperwasser and Goldberg, 2016; Lample et al., 2016; Liu and Zhang, 2017; Zhou et al., 2015; Wang et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Transactions of the Association for Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "5,"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of EMNLP,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 208
                            }
                        ],
                        "text": "The joint methods are listed as follows: (4) DS-Joint [Li and Ji, 2014] is a supervised method, which jointly extracts entities and relations using structured perceptron on humanannotated dataset; (5) MultiR [Hoffmann et al., 2011] is a typical distant supervised method based on multi-instance learning algorithms to combat the noisy training data; (6) CoType [Ren et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Ji, 2014] is a supervised method, which jointly extracts entities and relations using structured perceptron on humanannotated dataset; (5) MultiR [Hoffmann et al., 2011] is a typical distant supervised method based on multi-instance learning algorithms to combat the noisy training data; (6)\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 201
                            }
                        ],
                        "text": "The joint methods are listed as follows: (4) DS-Joint [Li and Ji, 2014] is a supervised method, which jointly extracts entities and relations using structured perceptron on humanannotated dataset; (5) MultiR [Hoffmann et al., 2011] is a typical distant supervised method based on multi-instance learning algorithms to combat the noisy training data; (6) CoType [Ren et al., 2017] is a domain independent framework by jointly embedding entity mentions, relation mentions, text features and type labels into meaningful representations."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "of ACL"
            },
            "venue": {
                "fragments": [],
                "text": "pages 541\u2013550,"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 67
                            }
                        ],
                        "text": "Joint models have been investigated using both statistical methods [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 65
                            }
                        ],
                        "text": "Existing joint methods include feature-based statistical systems [Ren et al., 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In EMNLP"
            },
            "venue": {
                "fragments": [],
                "text": "pages 1858\u20131869,"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 182
                            }
                        ],
                        "text": "The former treats this task as two separated tasks, i.e., named entity recognition (NER) [Florian et al., 2010; Kuru et al., 2016] and relation extraction [Bunescu and Mooney, 2005; Liu et al., 2015; Lin et al., 2016]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "of ACL"
            },
            "venue": {
                "fragments": [],
                "text": "pages 285\u2013290,"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 136
                            }
                        ],
                        "text": "Recently, neural transition-based parsers have achieved highly competitive accuracies thanks to the modeling of output-output relations [Dyer et al., 2015; Kiperwasser and Goldberg, 2016; Lample et al., 2016; Liu and Zhang, 2017; Zhou et al., 2015; Wang et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 37
                            }
                        ],
                        "text": "We borrow the idea of neural parsing [Dyer et al., 2015; Kiperwasser and Goldberg, 2016], designing a Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TACL"
            },
            "venue": {
                "fragments": [],
                "text": "4:313\u2013327,"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 126
                            }
                        ],
                        "text": "We propose a novel transition system, which is a variant of the list-based arc-eager algorithm for nonprojective tree parsing [Choi and McCallum, 2013]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 98
                            }
                        ],
                        "text": "We propose a novel neural transition-based method, inspired by the list-based arc-eager algorithm [Choi and McCallum, 2013]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "of ACL"
            },
            "venue": {
                "fragments": [],
                "text": "pages 1052\u20131062,"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 249
                            }
                        ],
                        "text": "Recently, neural transition-based parsers have achieved highly competitive accuracies thanks to the modeling of output-output relations [Dyer et al., 2015; Kiperwasser and Goldberg, 2016; Lample et al., 2016; Liu and Zhang, 2017; Zhou et al., 2015; Wang et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Ting Liu"
            },
            "venue": {
                "fragments": [],
                "text": "A neural transition-based approach for semantic dependency graph parsing."
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 200
                            }
                        ],
                        "text": "The former treats this task as two separated tasks, i.e., named entity recognition (NER) [Florian et al., 2010; Kuru et al., 2016] and relation extraction [Bunescu and Mooney, 2005; Liu et al., 2015; Lin et al., 2016]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 2124\u20132133"
            },
            "venue": {
                "fragments": [],
                "text": "August"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 39
                            }
                        ],
                        "text": "These methods include: (1) DSlogistic [Mintz et al., 2009] is a distant supervised and feature based method, which combines the advantages of supervised IE and unsupervised IE features; (2) LINE [Tang et al., 2015] is a network embedding method, which is suitable for arbitrary types of information\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "These methods include: (1) DSlogistic [Mintz et al., 2009] is a distant supervised and feature based method, which combines the advantages of supervised IE and unsupervised IE features; (2) LINE [Tang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 27
                            }
                        ],
                        "text": "These methods include: (1) DSlogistic [Mintz et al., 2009] is a distant supervised and feature based method, which combines the advantages of supervised IE and unsupervised IE features; (2) LINE [Tang et al., 2015] is a network embedding method, which is suitable for arbitrary types of information networks; (3) FCM [Gormley et al., 2015] is a compositional model that combines lexicalized linguistic context and word embeddings for relation extraction."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of ACL,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 37
                            }
                        ],
                        "text": "However, most existing neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016] extract entities and relations separately, achieving joint learning only through parameter sharing, but not joint decoding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 67
                            }
                        ],
                        "text": ", 2017; Miwa and Sasaki, 2014; Li and Ji, 2014] and neural methods [Zheng et al., 2017; Katiyar and Cardie, 2017; Miwa and Bansal, 2016]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 67
                            }
                        ],
                        "text": ", 2017; Miwa and Sasaki, 2014; Li and Ji, 2014], and neural models [Katiyar and Cardie, 2017; Miwa and Bansal, 2016; Zheng et al., 2017]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of ACL,"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 188
                            }
                        ],
                        "text": "Recently, neural transition-based parsers have achieved highly competitive accuracies thanks to the modeling of output-output relations [Dyer et al., 2015; Kiperwasser and Goldberg, 2016; Lample et al., 2016; Liu and Zhang, 2017; Zhou et al., 2015; Wang et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 260\u2013270"
            },
            "venue": {
                "fragments": [],
                "text": "June"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 99
                            }
                        ],
                        "text": "The task has been traditionally solved as a pipeline of two separate sub-tasks: entity recognition [Nadeau and Sekine, 2007] and relation extraction [Zhou et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lingvisticae Investigationes"
            },
            "venue": {
                "fragments": [],
                "text": "30(1):3\u201326,"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 150
                            }
                        ],
                        "text": "The task has been traditionally solved as a pipeline of two separate sub-tasks: entity recognition [Nadeau and Sekine, 2007] and relation extraction [Zhou et al., 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "of ACL"
            },
            "venue": {
                "fragments": [],
                "text": "pages 427\u2013434,"
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 16,
            "methodology": 18
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 39,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Joint-Extraction-of-Entities-and-Relations-Based-on-Wang-Zhang/a252c7abc7286fab01d3f89b8655c8dbc2dbf512?sort=total-citations"
}