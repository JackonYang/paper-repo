{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "As shown in [2], this facilitates algorithms for solving the correspondence problem between two similar but not identical shapes such as seen in 1(a) and (b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 105
                            }
                        ],
                        "text": "In this paper we develop further an approach based on the representation ofshape contexts, introduced in Belongie, Malik and Puzicha [2], which arguably satisfies criteria (1), (2) and (4) above while (3) is yet only a distant possibility1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 248
                            }
                        ],
                        "text": "The thrust of this paper is in Section 3 where we develop two different algorithms for fast pruning based on shape contexts, resulting in a shortlist of likely candidat e shapes to be evaluated later by the more accurate and expensive procedure in [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 135
                            }
                        ],
                        "text": "In this paper we develop further an approach based on the representation of shape contexts , introduced in Belongie, Malik and Puzicha [2], which arguably satisfies criteria (1), (2) and (4) above while (3) is yet only a distant possibility1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "the richness of the shape context descriptor makes it robust to noise and occlusion, as indicated by the experiments reported in [2]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "An algorithm to achieve this, in a deformable template matching framework, was presented in [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8446909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "500db68171e4a961d7fa87b8020b3a3e62133caf",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. Dis-similarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework. Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset."
            },
            "slug": "Matching-shapes-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Matching shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A novel approach to measuring similarity between shapes and exploiting it for object recognition in a nearest-neighbor classification framework that applies regularized thin-plate splines to the transformation maps for this purpose."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2853573"
                        ],
                        "name": "D. Sharvit",
                        "slug": "D.-Sharvit",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sharvit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sharvit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113351148"
                        ],
                        "name": "J. Chan",
                        "slug": "J.-Chan",
                        "structuredName": {
                            "firstName": "Jacky",
                            "lastName": "Chan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144846057"
                        ],
                        "name": "H. Tek",
                        "slug": "H.-Tek",
                        "structuredName": {
                            "firstName": "H\u00fcseyin",
                            "lastName": "Tek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Tek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715265"
                        ],
                        "name": "B. Kimia",
                        "slug": "B.-Kimia",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Kimia",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kimia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18113743,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdfb0d5e7840fcb7d096c67465f1405c4e82d2d4",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of shape as a cue for indexing in pictorial databases has been traditionally based on global invariant statistics and deformable templates, on the one hand, and local edge correlation on the other. This paper proposes an intermediate approach based on a characterization of the symmetry in edge maps. The use of symmetry matching as a joint correlation measure between pairs of edge elements further constrains the comparison of edge maps. In addition, a natural organization of groups of symmetry into a hierarchy leads to a graph-based representation of relational structure of components of shape that allows for deformations by changing attributes of this relational graph. A graduate assignment graph matching algorithm is used to match symmetry structure in images to stored prototypes or sketches. The results of matching sketches and grey-scale images against a small database consisting of a variety of fish, planes, tools, etc., are depicted."
            },
            "slug": "Symmetry-based-indexing-of-image-databases-Sharvit-Chan",
            "title": {
                "fragments": [],
                "text": "Symmetry-Based Indexing of Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An intermediate approach based on a characterization of the symmetry in edge maps is proposed, which leads to a graph-based representation of relational structure of components of shape that allows for deformations by changing attributes of this relational graph."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739867"
                        ],
                        "name": "R. Veltkamp",
                        "slug": "R.-Veltkamp",
                        "structuredName": {
                            "firstName": "Remco",
                            "lastName": "Veltkamp",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Veltkamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1921784"
                        ],
                        "name": "M. Hagedoorn",
                        "slug": "M.-Hagedoorn",
                        "structuredName": {
                            "firstName": "Michiel",
                            "lastName": "Hagedoorn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hagedoorn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "An extensive survey of shape matching in computer vision can be found in [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39932777,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "3903efd2e310224ae987c0d43809650e0177d0bc",
            "isKey": false,
            "numCitedBy": 647,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Large image databases are used in an extraordinary number of multimedia applications in fields such as entertainment, business, art, engineering, and science. Retrieving images by their content, as opposed to external features, has become an important operation. A fundamental ingredient for content-based image retrieval is the technique used for comparing images. There are two general methods for image comparison: intensity based (color and texture) and geometry based (shape). A recent user survey about cognition aspects of image retrieval shows that users are more interested in retrieval by shape than by color and texture [62]. However, retrieval by shape is still considered one of the most difficult aspects of content-based search. Indeed, systems such as IBM\u2019s Query By Image Content, QBIC [57], perhaps one of the most advanced image retrieval systems to date, is relatively successful in retrieving by color and texture, but performs poorly when searching on shape. A similar behavior is exhibited in the new Alta Vista photo finder [10]."
            },
            "slug": "State-of-the-Art-in-Shape-Matching-Veltkamp-Hagedoorn",
            "title": {
                "fragments": [],
                "text": "State of the Art in Shape Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A recent user survey about cognition aspects of image retrieval shows that users are more interested in retrieval by shape than by color and texture, and systems such as IBM\u2019s Query By Image Content, QBIC, is relatively successful in retrieving by colors, but performs poorly when searching on shape."
            },
            "venue": {
                "fragments": [],
                "text": "Principles of Visual Information Retrieval"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 18
                            }
                        ],
                        "text": "Several approaches[14, 8] first at tempt to find correspondences between the two images, before doing the comparison."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15242659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f731b6745d829241941307c3ebf163e90e200318",
            "isKey": false,
            "numCitedBy": 7909,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN."
            },
            "slug": "Active-Shape-Models-Their-Training-and-Application-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Active Shape Models-Their Training and Application"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes a method for building models by learning patterns of variability from a training set of correctly annotated images that can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35651617"
                        ],
                        "name": "Kenneth Wilder",
                        "slug": "Kenneth-Wilder",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Wilder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Wilder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2023689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f7c640ea1fe32e017c68005ef5e18969039b3f4",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a very large family of binary features for two-dimensional shapes. The salient ones for separating particular shapes are determined by inductive learning during the construction of classification trees. There is a feature for every possible geometric arrangement of local topographic codes. The arrangements express coarse constraints on relative angles and distances among the code locations and are nearly invariant to substantial affine and nonlinear deformations. They are also partially ordered, which makes it possible to narrow the search for informative ones at each node of the tree. Different trees correspond to different aspects of shape. They are statistically and weakly dependent due to randomization and are aggregated in a simple way. Adapting the algorithm to a shape family is then fully automatic once training samples are provided. As an illustration, we classified handwritten digits from the NIST database; the error rate was 0.7 percent."
            },
            "slug": "Joint-Induction-of-Shape-Features-and-Tree-Amit-Wilder",
            "title": {
                "fragments": [],
                "text": "Joint Induction of Shape Features and Tree Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A very large family of binary features for two-dimensional shapes determined by inductive learning during the construction of classification trees is introduced, which makes it possible to narrow the search for informative ones at each node of the tree."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] usesorder structureto compute correspondences."
                    },
                    "intents": []
                }
            ],
            "corpusId": 31050079,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dcd7c0c8d6dbeaef6d29ad83dbefa84529dc41ee",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a general method for finding pointwise correspondence between 2-D shapes based on the concept of order structure and using geometric hashing. The problem of finding correspondence and the problem of establishing shape equivalence can be considered as one and the same problem. Given shape equivalence, we can in general and pointwise correspondence and the existence of a unambiguous correspondence mapping can be used as a rule for deciding shape equivalence. As a measure of shape equivalence we will use the concept of order structure which in principle can be defined for arbitrary geometric configurations such as points lines and curves. The order structure equivalence of subsets of points and tangent directions of a shape is will be used to establish pointwise correspondence. The finding of correspondence between different views of the same object and different instances of the same object category can be used as a foundation for establishment and recognition of visual categories."
            },
            "slug": "Order-Structure,-Correspondence,-and-Shape-Based-Carlsson",
            "title": {
                "fragments": [],
                "text": "Order Structure, Correspondence, and Shape Based Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A general method for finding pointwise correspondence between 2-D shapes based on the concept of order structure and using geometric hashing is proposed, which can be defined for arbitrary geometric configurations such as points lines and curves."
            },
            "venue": {
                "fragments": [],
                "text": "Shape, Contour and Grouping in Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other approaches[10, 8,  20 , 27] treat the shape as a set of points in the 2D image, extracted using, say, an edge detector."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1269370,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61a3ec03aff72b00ef17fbcf8577cbacd629a7f6",
            "isKey": false,
            "numCitedBy": 549,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Modal matching is a new method for establishing correspondences and computing canonical descriptions. The method is based on the idea of describing objects in terms of generalized symmetries, as defined by each object's eigenmodes. The resulting modal description is used for object recognition and categorization, where shape similarities are expressed as the amounts of modal deformation energy needed to align the two objects. In general, modes provide a global-to-local ordering of shape deformation and thus allow for selecting which types of deformations are used in object alignment and comparison. In contrast to previous techniques, which required correspondence to be computed with an initial or prototype shape, modal matching utilizes a new type of finite element formulation that allows for an object's eigenmodes to be computed directly from available image information. This improved formulation provides greater generality and accuracy, and is applicable to data of any dimensionality. Correspondence results with 2D contour and point feature data are shown, and recognition experiments with 2D images of hand tools and airplanes are described. >"
            },
            "slug": "Modal-Matching-for-Correspondence-and-Recognition-Sclaroff-Pentland",
            "title": {
                "fragments": [],
                "text": "Modal Matching for Correspondence and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Improved formulation of modal matching utilizes a new type of finite element formulation that allows for an object's eigenmodes to be computed directly from available image information, and is applicable to data of any dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3037691"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Edie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2676682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d5215f2b305c27969181a7c7b5ebeae419e5d2a",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to recognition of complex objects in cluttered 3-D scenes that does not require feature extraction or segmentation. Our object representation comprises descriptive images associated with each oriented point on the surface of an object. Using a single point basis constructed from an oriented point, the position of other points on the surface of the object can be described by two parameters. The accumulation of these parameters for many points on the surface of the object results in an image at each oriented point. These images, localized descriptions of the global shape of the object, are invariant to rigid transformations. Through correlation of images, point correspondences between a model and scene data are established and then grouped using geometric consistency. The effectiveness of our algorithm is demonstrated with results showing recognition of complex objects in cluttered scenes with occlusion."
            },
            "slug": "Recognizing-objects-by-matching-oriented-points-Johnson-Hebert",
            "title": {
                "fragments": [],
                "text": "Recognizing objects by matching oriented points"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work presents an approach to recognition of complex objects in cluttered 3-D scenes that does not require feature extraction or segmentation, and demonstrates the effectiveness of the algorithm with results showing recognition of complexes in clutters scenes with occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1915667"
                        ],
                        "name": "Y. Gdalyahu",
                        "slug": "Y.-Gdalyahu",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Gdalyahu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Gdalyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14669415,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93e6c80610ff9deaa476e3618d22ff30fd5846c3",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Curve matching is one instance of the fundamental correspondence problem. Our flexible algorithm is designed to match curves under substantial deformations and arbitrary large scaling and rigid transformations. A syntactic representation is constructed for both curves and an edit transformation which maps one curve to the other is found using dynamic programming. We present extensive experiments where we apply the algorithm to silhouette matching. In these experiments, we examine partial occlusion, viewpoint variation, articulation, and class matching (where silhouettes of similar objects are matched). Based on the qualitative syntactic matching, we define a dissimilarity measure and we compute it for every pair of images in a database of 121 images. We use this experiment to objectively evaluate our algorithm. First, we compare our results to those reported by others. Second, we use the dissimilarity values in order to organize the image database into shape categories. The veridical hierarchical organization stands as evidence to the quality of our matching and similarity estimation."
            },
            "slug": "Flexible-Syntactic-Matching-of-Curves-and-Its-to-of-Gdalyahu-Weinshall",
            "title": {
                "fragments": [],
                "text": "Flexible Syntactic Matching of Curves and Its Application to Automatic Hierarchical Classification of Silhouettes"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper presents extensive experiments where the flexible algorithm to match curves under substantial deformations and arbitrary large scaling and rigid transformations, and defines a dissimilarity measure which is used in order to organize the image database into shape categories."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 18
                            }
                        ],
                        "text": "Several approaches[14, 26, 7] firs t attempt to find correspondences between the two images, before doing the comparison."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6150049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cef9b899297bee5b50cb7a15442b18ac01f58784",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Flexible models of object classes, based on linear combinations of prototypical images, are capable of matching novel images of the same class and have been shown to be a powerful tool to solve several fundamental vision tasks such as recognition, synthesis and correspondence. The key problem in creating a specific flexible model is the computation of pixelwise correspondence between the prototypes, a task done until now in a semiautomatic way. In this paper we describe an algorithm that automatically bootstraps the correspondence between the prototypes. The algorithm -which can be used for 2D images as well as for 3D models-is shown to synthesize successfully a flexible model of frontal face images and a flexible model of handwritten digits."
            },
            "slug": "A-bootstrapping-algorithm-for-learning-linear-of-Vetter-Jones",
            "title": {
                "fragments": [],
                "text": "A bootstrapping algorithm for learning linear models of object classes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm that automatically bootstraps the correspondence between the prototypes is described, which can be used for 2D images as well as for 3D models and is shown to synthesize successfully a flexible model of frontal face images and a flexible models of handwritten digits."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some examples include [16, 5] for handwritten digit recognition, [17] for face recognition, and isolated 3D object recognition [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1266705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77e6ecfe96fb1270df167d539a819ca4e25c3574",
            "isKey": false,
            "numCitedBy": 650,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bayesian-face-recognition-Moghaddam-Jebara",
            "title": {
                "fragments": [],
                "text": "Bayesian face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3096453"
                        ],
                        "name": "Y. Lamdan",
                        "slug": "Y.-Lamdan",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Lamdan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lamdan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035149"
                        ],
                        "name": "J. Schwartz",
                        "slug": "J.-Schwartz",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26551855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0578e3d82416b0b15b6aaca19e92e18ea62218b7",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "New techniques are described for model-based recognition of the objects in 3-D space. The recognition is performed from single gray-scale images taken from unknown viewpoints. The objects in the scene may be overlapping and partially occluded. An efficient matching algorithm, which assumes affine approximation to the prospective viewing transformation, is proposed. The algorithm has an offline model preprocessing (shape representation) phase which is independent of the scene information and a recognition phase based on efficient indexing. It has a straightforward parallel implementation. The algorithm was successfully tested in recognition of industrial objects appearing in composite occluded scenes. >"
            },
            "slug": "Affine-invariant-model-based-object-recognition-Lamdan-Schwartz",
            "title": {
                "fragments": [],
                "text": "Affine invariant model-based object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An efficient matching algorithm, which assumes affine approximation to the prospective viewing transformation, is proposed and was successfully tested in recognition of industrial objects appearing in composite occluded scenes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Robotics Autom."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8054340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b37258659bcdbc380b1e6c4e22cce9ea06397a1",
            "isKey": false,
            "numCitedBy": 5632,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons (N \u00a3 36), can be derived from contrasts of five readily detectable properties of edges in a two-dimensiona l image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position an$ image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. Representational power derives from an allowance of free combinations of the geons. A Principle of Componential Recovery can account for the major phenomena of object recognition: If an arrangement of two or three geons can be recovered from the input, objects can be quickly recognized even when they are occluded, novel, rotated in depth, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory. Any single object can project an infinity of image configurations to the retina. The orientation of the object to the viewer can vary continuously, each giving rise to a different two-dimensional projection. The object can be occluded by other objects or texture fields, as when viewed behind foliage. The object need not be presented as a full-colored textured image but instead can be a simplified line drawing. Moreover, the object can even be missing some of its parts or be a novel exemplar of its particular category. But it is only with rare exceptions that an image fails to be rapidly and readily classified, either as an instance of a familiar object category or as an instance that cannot be so classified (itself a form of classification)."
            },
            "slug": "Recognition-by-components:-a-theory-of-human-image-Biederman",
            "title": {
                "fragments": [],
                "text": "Recognition-by-components: a theory of human image understanding."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recognition-by-components (RBC) provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": false,
            "numCitedBy": 2072,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754893"
                        ],
                        "name": "R. Lilien",
                        "slug": "R.-Lilien",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Lilien",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lilien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698040"
                        ],
                        "name": "C. Olson",
                        "slug": "C.-Olson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Olson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Olson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 17
                            }
                        ],
                        "text": "Other approaches [10, 9] treat the shape as a set of points in the 2D image, extracted using, say, an edge detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1320611,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0cfd9fe9ea6c8316f14a3386d54664f109b0c60",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "View-based recognition methods, such as those using eigenspace techniques, have been successful for a number of recognition tasks. Such approaches, however, are somewhat limited in their ability to recognize objects that are partly hidden from view or occur against cluttered backgrounds. In order to address these limitations, we have developed a view matching technique based on an eigenspace approximation to the generalized Hausdorff measure. This method achieves compact storage and fast indexing that are the main advantages of eigenspace view matching techniques, while also being tolerant of partial occlusion and background clutter. The method applies to binary feature maps, such as intensity edges, rather than directly to intensity images."
            },
            "slug": "View-Based-Recognition-Using-an-Eigenspace-to-the-Huttenlocher-Lilien",
            "title": {
                "fragments": [],
                "text": "View-Based Recognition Using an Eigenspace Approximation to the Hausdorff Measure"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper has developed a view matching technique based on an eigenspace approximation to the generalized Hausdorff measure that achieves compact storage and fast indexing that are the main advantages of eIGenspace view matching techniques, while also being tolerant of partial occlusion and background clutter."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762260"
                        ],
                        "name": "V. Philomin",
                        "slug": "V.-Philomin",
                        "structuredName": {
                            "firstName": "Vasanth",
                            "lastName": "Philomin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Philomin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other approaches [10, 9] treat the shape as a set of points in the 2D image, extracted using, say, an edge detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 766556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb490d879512b3d43b267e3ac8931c099a5a2fd3",
            "isKey": false,
            "numCitedBy": 760,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient shape-based object detection method based on Distance Transforms and describes its use for real-time vision on-board vehicles. The method uses a template hierarchy to capture the variety of object shapes; efficient hierarchies can be generated offline for given shape distributions using stochastic optimization techniques (i.e. simulated annealing). Online, matching involves a simultaneous coarse-to-fine approach over the shape hierarchy and over the transformation parameters. Very large speed-up factors are typically obtained when comparing this approach with the equivalent brute-force formulation; we have measured gains of several orders of magnitudes. We present experimental results on the real-time detection of traffic signs and pedestrians from a moving vehicle. Because of the highly time sensitive nature of these vision tasks, we also discuss some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned."
            },
            "slug": "Real-time-object-detection-for-\"smart\"-vehicles-Gavrila-Philomin",
            "title": {
                "fragments": [],
                "text": "Real-time object detection for \"smart\" vehicles"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An efficient shape-based object detection method based on Distance Transforms is presented and its use for real-time vision on-board vehicles and some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115888"
                        ],
                        "name": "C. T. Zahn",
                        "slug": "C.-T.-Zahn",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Zahn",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. T. Zahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2289704"
                        ],
                        "name": "R. Roskies",
                        "slug": "R.-Roskies",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Roskies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Roskies"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[24], skeletons derived using Blum\u2019s medial axis transform [20], or directly matched using dynamic programming."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5381608,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c3838456bb93d137463e2a3a219dcc4acc557fa8",
            "isKey": false,
            "numCitedBy": 2003,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for the analysis and synthesis of closed curves in the plane is developed using the Fourier descriptors FD's of Cosgriff [1]. A curve is represented parametrically as a function of arc length by the accumulated change in direction of the curve since the starting point. This function is expanded in a Fourier series and the coefficients are arranged in the amplitude/phase-angle form. It is shown that the amplitudes are pure form invariants as well as are certain simple functions of phase angles. Rotational and axial symmetry are related directly to simple properties of the Fourier descriptors. An analysis of shape similarity or symmetry can be based on these relationships; also closed symmetric curves can be synthesized from almost arbitrary Fourier descriptors. It is established that the Fourier series expansion is optimal and unique with respect to obtaining coefficients insensitive to starting point. Several examples are provided to indicate the usefulness of Fourier descriptors as features for shape discrimination and a number of interesting symmetric curves are generated by computer and plotted out."
            },
            "slug": "Fourier-Descriptors-for-Plane-Closed-Curves-Zahn-Roskies",
            "title": {
                "fragments": [],
                "text": "Fourier Descriptors for Plane Closed Curves"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is established that the Fourier series expansion is optimal and unique with respect to obtaining coefficients insensitive to starting point and the amplitudes are pure form invariants as well as are certain simple functions of phase angles."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084269"
                        ],
                        "name": "H. Chui",
                        "slug": "H.-Chui",
                        "structuredName": {
                            "firstName": "Haili",
                            "lastName": "Chui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145257017"
                        ],
                        "name": "Anand Rangarajan",
                        "slug": "Anand-Rangarajan",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Rangarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Rangarajan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1318268,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dabad3d9c7af2aec185737a1577d44c3b6164286",
            "isKey": false,
            "numCitedBy": 504,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new robust point matching algorithm (RPM) that can jointly estimate the correspondence and non-rigid transformations between two point-sets that may be of different sizes. The algorithm utilizes the soft assign for the correspondence and the thin-plate spline for the non-rigid mapping. Embedded within a deterministic annealing framework, the algorithm can automatically reject a fraction of the points as outliers. Experiments on both 2D synthetic point-sets with varying degrees of deformation, noise and outliers, and on real 3D sulcal point-sets (extracted from brain MRI) demonstrate the robustness of the algorithm."
            },
            "slug": "A-new-algorithm-for-non-rigid-point-matching-Chui-Rangarajan",
            "title": {
                "fragments": [],
                "text": "A new algorithm for non-rigid point matching"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new robust point matching algorithm (RPM) that can jointly estimate the correspondence and non-rigid transformations between two point-sets that may be of different sizes is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35281,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735300"
                        ],
                        "name": "S. Haykin",
                        "slug": "S.-Haykin",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Haykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713858"
                        ],
                        "name": "B. Kosko",
                        "slug": "B.-Kosko",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Kosko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kosko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64294544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f42b865e20e61a954239f421b42007236e671f19",
            "isKey": false,
            "numCitedBy": 3516,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer Neural Networks trained with the backpropagation algorithm constitute the best example of a successful Gradient-Based Learning technique. Given an appropriate network architecture, Gradient-Based Learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called Graph Transformer Networks (GTN), allows such multi-module systems to be trained globally using Gradient-Based methods so as to minimize an overall performance measure. Two systems for on-line handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of Graph Transformer Networks. A Graph Transformer Network for reading bank check is also described. It uses Convolutional Neural Network character recognizers combined with global training techniques to provides record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day."
            },
            "slug": "GradientBased-Learning-Applied-to-Document-Haykin-Kosko",
            "title": {
                "fragments": [],
                "text": "GradientBased Learning Applied to Document Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Various methods applied to handwritten character recognition are reviewed and compared and Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688317"
                        ],
                        "name": "P. Indyk",
                        "slug": "P.-Indyk",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Indyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Indyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84095744"
                        ],
                        "name": "R. Motwani",
                        "slug": "R.-Motwani",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Motwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Motwani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6110572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1955266a8a58d94e41ad0efe20d707c92a069e95",
            "isKey": false,
            "numCitedBy": 4276,
            "numCiting": 160,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two algorithms for the approximate nearest neighbor problem in high-dimensional spaces. For data sets of size n living in R d , the algorithms require space that is only polynomial in n and d, while achieving query times that are sub-linear in n and polynomial in d. We also show applications to other high-dimensional geometric problems, such as the approximate minimum spanning tree. The article is based on the material from the authors' STOC'98 and FOCS'01 papers. It unifies, generalizes and simplifies the results from those papers."
            },
            "slug": "Approximate-nearest-neighbors:-towards-removing-the-Indyk-Motwani",
            "title": {
                "fragments": [],
                "text": "Approximate nearest neighbors: towards removing the curse of dimensionality"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "Two algorithms for the approximate nearest neighbor problem in high-dimensional spaces are presented, which require space that is only polynomial in n and d, while achieving query times that are sub-linear inn and polynometric in d."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9434141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40e5a40ae66d44e6c00d562d068d35db6922715d",
            "isKey": false,
            "numCitedBy": 431,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Learning Machines (SVM) are finding application in pattern recognition, regression estimation, and operator inversion for ill-posed problems. Against this very general backdrop, any methods for improving the generalization performance, or for improving the speed in test phase, of SVMs are of increasing interest. In this paper we combine two such techniques on a pattern recognition problem. The method for improving generalization performance (the \"virtual support vector\" method) does so by incorporating known invariances of the problem. This method achieves a drop in the error rate on 10,000 NIST test digit images of 1.4% to 1.0%. The method for improving the speed (the \"reduced set\" method) does so by approximating the support vector decision surface. We apply this method to achieve a factor of fifty speedup in test phase over the virtual support vector machine. The combined approach yields a machine which is both 22 times faster than the original machine, and which has better generalization performance, achieving 1.1 % error. The virtual support vector method is applicable to any SVM problem with known invariances. The reduced set method is applicable to any support vector machine."
            },
            "slug": "Improving-the-Accuracy-and-Speed-of-Support-Vector-Burges-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "Improving the Accuracy and Speed of Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper combines two techniques for improving generalization performance and speed on a pattern recognition problem by incorporating known invariances of the problem, and applies the reduced set method, applicable to any support vector machine."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116158963"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Sheila",
                            "lastName": "Nayar",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The shape contextbased methods are shown to quickly produce an accurate shortlist of candidates suitable for a more exact matching engine in spite of pose variation and occlusion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58758670,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "77afac8f4d7f47c8b34371d8f8355cefbea1d4f6",
            "isKey": false,
            "numCitedBy": 2004,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Columbia Object Image Library COIL is a database of color images of objects The objects were placed on a motorized turntable against a black background The turntable was rotated through degrees to vary object pose with respect to a xed color camera Images of the objects were taken at pose intervals of degrees This corresponds to poses per object The images were size normalized COIL is available online via ftp"
            },
            "slug": "Columbia-Object-Image-Library-(COIL100)-Nayar",
            "title": {
                "fragments": [],
                "text": "Columbia Object Image Library (COIL100)"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Columbia Object Image Library COIL is a database of color images of objects that were placed on a motorized turntable against a black background and rotated through degrees to vary object pose with respect to a xed color camera."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180590"
                        ],
                        "name": "S. Thorpe",
                        "slug": "S.-Thorpe",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Thorpe",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thorpe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50780533"
                        ],
                        "name": "D. Fize",
                        "slug": "D.-Fize",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Fize",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fize"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3677347"
                        ],
                        "name": "Catherine Marlot",
                        "slug": "Catherine-Marlot",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Marlot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Marlot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4303570,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "addbd39fc775c12aa453ebd0cb77ea1bd3389572",
            "isKey": false,
            "numCitedBy": 2548,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speed-of-processing-in-the-human-visual-system-Thorpe-Fize",
            "title": {
                "fragments": [],
                "text": "Speed of processing in the human visual system"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50537578"
                        ],
                        "name": "W. Johnson",
                        "slug": "W.-Johnson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Johnson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "Indyk and Motwani [11] describe an algorithm for doing a -NN queries in , 5% ]80( # ,4] C,45 0 0 time that uses random projections and the Johnson-Lindenstrauss lemma [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117819162,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1d0635cda34b8af995313848a0c42bac6efe79ec",
            "isKey": false,
            "numCitedBy": 2547,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "(Here ll&lltip is the Lipschitz constant of the function g.) A classical result of Kirszbraun's [14, p. 48] states that L(t2, n) = 1 for all n, but it is easy to see that L(X, n) ~ ~ as n ~ ~ for many metric spaces X. Marcus and Pisier [10] initiated the study of L(X, n) for X = Lp. (For brevity, we will use hereafter the notation L(p, n) for L(Lp(O,l), n).) They prove that for each 1 < p < 2 there is a constant C(p) so that for n = 2, 3, 4, , , ,"
            },
            "slug": "Extensions-of-Lipschitz-mappings-into-Hilbert-space-Johnson",
            "title": {
                "fragments": [],
                "text": "Extensions of Lipschitz mappings into Hilbert space"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105872"
                        ],
                        "name": "F. Bookstein",
                        "slug": "F.-Bookstein",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Bookstein",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bookstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 47302,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "708d9a8baac3b47e5095c943fbe027675dd9eb7f",
            "isKey": false,
            "numCitedBy": 4776,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The decomposition of deformations by principal warps is demonstrated. The method is extended to deal with curving edges between landmarks. This formulation is related to other applications of splines current in computer vision. How they might aid in the extraction of features for analysis, comparison, and diagnosis of biological and medical images in indicated. >"
            },
            "slug": "Principal-Warps:-Thin-Plate-Splines-and-the-of-Bookstein",
            "title": {
                "fragments": [],
                "text": "Principal Warps: Thin-Plate Splines and the Decomposition of Deformations"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The decomposition of deformations by principal warps is demonstrated and the method is extended to deal with curving edges between landmarks to aid the extraction of features for analysis, comparison, and diagnosis of biological and medical images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 104
                            }
                        ],
                        "text": "Both methods were shown to perform well as efficient pruning mechanisms on the COIL-100 and Snodgrass & Vanderwart datasets, and deal robustly with occlusion and pose or intraclass variation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 75
                            }
                        ],
                        "text": "The query objects in Figure 7 show some distorted and occluded Snodgrass & Vanderwart images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 69
                            }
                        ],
                        "text": "Figure 7: Some shortlists for the distorted and occluded Snodgrass & Vanderwart dataset using the representative shape contexts method."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 56
                            }
                        ],
                        "text": "Figure 8: Some shortlists for the distorted Snodgrass & Vanderwart dataset using the representative shape contexts method."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 102
                            }
                        ],
                        "text": "In Section 5, we show experimental results on the Columbia (COIL-100) 3D object database [19] and the Snodgrass and Vanderwart drawings [21]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "(An excellent demonstration of this is the collection of Snodgrass and Vanderwart [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 58
                            }
                        ],
                        "text": "We use the Columbia (COIL-100) 3D object database and the Snodgrass and Vanderwart line drawings as our test sets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 43
                            }
                        ],
                        "text": "The second experiment uses the Snodgrass & Vanderwart line drawings [21]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 16
                            }
                        ],
                        "text": "The Snodgrass & Vanderwart dataset has only one image per object."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 117
                            }
                        ],
                        "text": "We verify the discriminative power of these methods with tests on the Columbia (COIL-100) 3D object database and the Snodgrass and Vanderwart line drawings."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 29
                            }
                        ],
                        "text": "The 260 original Snodgrass & Vanderwart images were used as the known set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "We demonstrate through our experiments on the Columbia (COIL100) 3D object database [18] and the Snodgrass and Vanderwart drawings [22], covering appearance variation and occlusion, that a handful of shape contexts can serve as a powerful indexing tool for retrieving likely shapes from a large collection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 64
                            }
                        ],
                        "text": "Figures 7 and 8 show some example shortlists on the Snodgrass & Vanderwart dataset using the representative\nshape contexts method."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A standardized set of 260 pictures : Norms for name agreement , familiarity and visual complexity"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Experimental Psychology : Human Learning and Memory"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 17
                            }
                        ],
                        "text": "Other approaches [10, 9] treat the shape as a set of points in the 2D image, extracted using, say, an edge detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real-time object detection f or smart vehicles"
            },
            "venue": {
                "fragments": [],
                "text": "InProc. 7th Int. Conf. Computer Vision  , pages 87\u201393,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 258
                            }
                        ],
                        "text": "They demonstrate the highly discriminative shape information that is conveyed by shape contexts through excellent performance in handwritten digit recognition, tests on the Columbia (COIL-20) 3D object database [19], and the MPEG-7 shape silhouette database [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Description of core experiment s for MPEG-7 motion/shape"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report ISO/IEC JTC 1/SC 29/WG 11 MPEG99/N2690, MPEG-7, Seoul, March"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Some examples include [16, 5] for handwritten digit recognition, [17] for face recognition, and isolated 3D object recognition [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian face recognition.Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 16
                            }
                        ],
                        "text": "Other approaches[10, 8, 20, 27] treat the shape as a set of points in the 2D image, extracted using, say, an edge detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modal matching for corresp  ondence and recognition"
            },
            "venue": {
                "fragments": [],
                "text": " IEEE Trans. PAMI  , 17(6):545\u2013561, June"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vanderwart . A standardized set of 260 pictures : Norms for name agreement , familiarity and visual complexity"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Experimental Psychology : Human Learning and Memory"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "This tradition of shape matching through deformation is at least as old as D\u2019Arcy Thompson\u2019s work [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Thompson.On Growth and Form"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1917
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "In Section 5, we show experimental results on the Columbia (COIL-100) 3D object database [19] and the Snodgrass and Vanderwart drawings [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "The second experiment uses the Snodgrass & Vanderwart line drawings [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vanderwart. A standardized set of 260 pictures: Norms for name agreement, familiarity and visual complexity.Journal of Experimental Psychology: Human Learning and Memory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Flexible syntactic matchi  ng of curves and its application to automatic hierarchical cla ssification of silhouettes.IEEE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 17
                            }
                        ],
                        "text": "Other approaches [10, 9] treat the shape as a set of points in the 2D image, extracted using, say, an edge detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "View-based re cognition using an eigenspace approximation to the Hausdorff measure.PAMI"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Thorpe, Fize and Merlot [22] showed that people, when presented with an image, can answer coarse queries such as presence or absence of an animal in as little as 150ms.\n3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Thorpe, Fize and Merlot [22] showed that people, when presented with an image, can answer coarse queries such as presence or absence of an animal in as little as 150ms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speed of processing in th e human visual system"
            },
            "venue": {
                "fragments": [],
                "text": "Nature,"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 12,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 37,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Shape-contexts-enable-efficient-retrieval-of-shapes-Mori-Belongie/0b8be52a054a5a3800e65170c02d688a80e6bab3?sort=total-citations"
}