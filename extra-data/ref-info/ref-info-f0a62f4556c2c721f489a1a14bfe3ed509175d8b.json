{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862313"
                        ],
                        "name": "J. Weinman",
                        "slug": "J.-Weinman",
                        "structuredName": {
                            "firstName": "Jerod",
                            "lastName": "Weinman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weinman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389846455"
                        ],
                        "name": "E. Learned-Miller",
                        "slug": "E.-Learned-Miller",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Learned-Miller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Learned-Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733922"
                        ],
                        "name": "A. Hanson",
                        "slug": "A.-Hanson",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hanson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "Thus, these processes must be integrated for optimal results [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "As in prior work [13], we use a discriminative semiMarkov field for jointly performing segmentation and recognition [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "We use the same features and pre-processing described in earlier work [13], briefly summarized here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2481071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fe95ca539e57b7079c7bddf497524aab2887b02",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a semi-Markov model for recognizing scene text that integrates character and word segmentation with recognition. Using wavelet features, it requires only approximate location of the text baseline and font size; no binarization or prior word segmentation is necessary. Our system is aided by a lexicon, yet it also allows non-lexicon words. To facilitate inference with a large lexicon, we use an approximate Viterbi beam search. Our system performs robustly on low-resolution images of signs containing text in fonts atypical of documents."
            },
            "slug": "A-discriminative-semi-Markov-model-for-robust-scene-Weinman-Learned-Miller",
            "title": {
                "fragments": [],
                "text": "A discriminative semi-Markov model for robust scene text recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A semi-Markov model for recognizing scene text that integrates character and word segmentation with recognition that performs robustly on low-resolution images of signs containing text in fonts atypical of documents is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2008 19th International Conference on Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3163684"
                        ],
                        "name": "Abdel Wahab Zramdini",
                        "slug": "Abdel-Wahab-Zramdini",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Zramdini",
                            "middleNames": [
                                "Wahab"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel Wahab Zramdini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 34
                            }
                        ],
                        "text": ", bold, italics) or font identity [6, 3, 9, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10014767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2097d07a289e65c4d676a502756726b75f24af80",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A new statistical approach based on global typographical features is proposed to the widely neglected problem of font recognition. It aims at the identification of the typeface, weight, slope and size of the text from an image block without any knowledge of the content of that text. The recognition is based on a multivariate Bayesian classifier and operates on a given set of known fonts. The effectiveness of the adopted approach has been experimented on a set of 280 fonts. Font recognition accuracies of about 97 percent were reached on high-quality images. In addition, rates higher than 99.9 percent were obtained for weight and slope detection. Experiments have also shown the system robustness to document language and text content and its sensitivity to text length."
            },
            "slug": "Optical-Font-Recognition-Using-Typographical-Zramdini-Ingold",
            "title": {
                "fragments": [],
                "text": "Optical Font Recognition Using Typographical Features"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A new statistical approach based on global typographical features is proposed to the widely neglected problem of font recognition that aims at the identification of the typeface, weight, slope and size of the text from an image block without any knowledge of the content of that text."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 45
                            }
                        ],
                        "text": "Examples include direct character appearance [4, 5, 1] and font metrics (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16610870,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c276ea86d17aefe9e6a77c307f465b536b84aa58",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Handwriting recognition and OCR systems need to cope with a wide variety of writing styles and fonts, many of them possibly not previously encountered during training. This paper describes a notion of Bayesian statistical similarity and demonstrates how it can be applied to rapid adaptation to new styles. The ability to generalize across different problem instances is illustrated in the Gaussian case, and the use of statistical similarity Gaussian case is shown to be related to adaptive metric classification methods. The relationship to prior approaches to multitask learning, as well as variable or adaptive metric classification, and hierarchical Bayesian methods, are discussed. Experimental results on character recognition from the NIST3 database are presented."
            },
            "slug": "Character-recognition-by-adaptive-statistical-Breuel",
            "title": {
                "fragments": [],
                "text": "Character recognition by adaptive statistical similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A notion of Bayesian statistical similarity is described and how it can be applied to rapid adaptation to new styles and the ability to generalize across different problem instances is illustrated in the Gaussian case."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862313"
                        ],
                        "name": "J. Weinman",
                        "slug": "J.-Weinman",
                        "structuredName": {
                            "firstName": "Jerod",
                            "lastName": "Weinman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weinman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389846455"
                        ],
                        "name": "E. Learned-Miller",
                        "slug": "E.-Learned-Miller",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Learned-Miller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Learned-Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "Other work has leveraged the assumption of consistency in character appearance by using a soft, probabilistic model for scene text [12], but the model required that characters be segmented beforehand."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1548186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fcf1755bc1fdc82e2469690d2ba7260812ab568",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Many sources of information relevant to computer vision and machine learning tasks are often underused. One example is the similarity between the elements from a novel source, such as a speaker, writer, or printed font. By comparing instances emitted by a source, we help ensure that similar instances are given the same label. Previous approaches have clustered instances prior to recognition. We propose a probabilistic framework that unifies similarity with prior identity and contextual information. By fusing information sources in a single model, we eliminate unrecoverable errors that result from processing the information in separate stages and improve overall accuracy. The framework also naturally integrates dissimilarity information, which has previously been ignored. We demonstrate with an application in printed character recognition from images of signs in natural scenes."
            },
            "slug": "Improving-Recognition-of-Novel-Input-with-Weinman-Learned-Miller",
            "title": {
                "fragments": [],
                "text": "Improving Recognition of Novel Input with Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A probabilistic framework that unifies similarity with prior identity and contextual information is proposed that fusing information sources in a single model to eliminate unrecoverable errors that result from processing the information in separate stages and improve overall accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48626927"
                        ],
                        "name": "Hongwei Shi",
                        "slug": "Hongwei-Shi",
                        "structuredName": {
                            "firstName": "Hongwei",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongwei Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 34
                            }
                        ],
                        "text": ", bold, italics) or font identity [6, 3, 9, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 32043853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f24e838ff2484d0ed687154853de51efd6826420",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Font recognition and contextual processing are developed as two components that enhance the recognition accuracy of a text recognition system presented in a previous paper ((H. Shi and T. Pavlidis, 1996). Font information is extracted from two sources: one is the global page properties, and the other is the graph matching result of recognized short words such as a, it and of etc. Contextual processing is done by first composing word candidates from the recognition results and then checking each candidate with a dictionary through a spelling checker. Positional binary trigrams and word affixes are used to prune the search for word candidates."
            },
            "slug": "Font-recognition-and-contextual-processing-for-more-Shi-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Font recognition and contextual processing for more accurate text recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Font recognition and contextual processing are developed as two components that enhance the recognition accuracy of a text recognition system presented in a previous paper."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2450058"
                        ],
                        "name": "S. Khoubyari",
                        "slug": "S.-Khoubyari",
                        "structuredName": {
                            "firstName": "Siamak",
                            "lastName": "Khoubyari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khoubyari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 34
                            }
                        ],
                        "text": ", bold, italics) or font identity [6, 3, 9, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17820223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "472b735336a8ddaad8e479d6eb28b8502845e497",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is presented that identifies the predominant font in which the running text in an English language document is printed. Frequent function words (such asthe,of,and,a, andto) are also recognized as part of the font identification. Clusters of word images are generated from an input document and matched to a database of function words derived from fonts and document images. The font or document that matches best provides the identification of the predominant font and function words. This technique takes advantage of the fact that most machine-printed documents are prepared with a single predominant font. Also, the repeated words in the document are utilized to overcome noise in the input. Advantages of this technique include its use as a preprocessing step for a document recognition algorithm. Experimental results show high accuracy is achieved on a database of original and degraded document images."
            },
            "slug": "Font-and-Function-Word-Identification-in-Document-Khoubyari-Hull",
            "title": {
                "fragments": [],
                "text": "Font and Function Word Identification in Document Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An algorithm is presented that identifies the predominant font in which the running text in an English language document is printed, and the repeated words in the document are utilized to overcome noise in the input."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1868906"
                        ],
                        "name": "J. Hobby",
                        "slug": "J.-Hobby",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hobby",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hobby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795578"
                        ],
                        "name": "T. Ho",
                        "slug": "T.-Ho",
                        "structuredName": {
                            "firstName": "Tin",
                            "lastName": "Ho",
                            "middleNames": [
                                "Kam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 45
                            }
                        ],
                        "text": "Examples include direct character appearance [4, 5, 1] and font metrics (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2682428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d375b85a3fdf928a5aa0672894f61276003d69f",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Proper display and accurate recognition of document images are often hampered by degradations caused by poor scanning or transmission conditions. The authors propose a method to enhance such degraded document images for better display quality and recognition accuracy. The essence of the method is in finding and averaging bitmaps of the same symbol that are scattered across a text page. Outline descriptions of the symbols are then obtained that can be rendered at arbitrary solution. The paper describes details of the algorithm and an experiment to demonstrate its capabilities using fax images."
            },
            "slug": "Enhancing-degraded-document-images-via-bitmap-and-Hobby-Ho",
            "title": {
                "fragments": [],
                "text": "Enhancing degraded document images via bitmap clustering and averaging"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method in finding and averaging bitmaps of the same symbol that are scattered across a text page that can be rendered at arbitrary solution for better display quality and recognition accuracy is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "75168337"
                        ],
                        "name": "R. Cooperman",
                        "slug": "R.-Cooperman",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cooperman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cooperman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 34
                            }
                        ],
                        "text": ", bold, italics) or font identity [6, 3, 9, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5231951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c06c21ca01fec2c4ca730e001c03fb0ba388018a",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A method to provide estimates of font attributes in an OCR system, using detectors of individual attributes that are error-prone. For an OCR system to preserve the appearance of a scanned document, it needs accurate detection of font attributes. However, OCR environments have noise and other sources of errors, tending to make font attribute detection unreliable. Certain assumptions about font use can greatly enhance accuracy. Attributes such as boldness and italics are more likely to change between neighboring words, while attributes such as serifness are less likely to change within the same paragraph. Furthermore, the document as a whole, tends to have a limited number of sets of font attributes. These assumptions allow a better use of context than the raw data, or what would be achieved by simpler methods that would oversmooth the data."
            },
            "slug": "Producing-good-font-attribute-determination-using-Cooperman",
            "title": {
                "fragments": [],
                "text": "Producing good font attribute determination using error-prone information"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A method to provide estimates of font attributes in an OCR system, using detectors of individual attributes that are error-prone, to allow better use of context than the raw data, or what would be achieved by simpler methods that would oversmooth the data."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40908101"
                        ],
                        "name": "T. Hong",
                        "slug": "T.-Hong",
                        "structuredName": {
                            "firstName": "Tsai",
                            "lastName": "Hong",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 45
                            }
                        ],
                        "text": "Examples include direct character appearance [4, 5, 1] and font metrics (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14861669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5addfe46d895e3c1dfedd034b0ec1c3612db2bc9",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a technique for improving the performance of an OCR system that uses information about equivalent word images inside a document. Words that are repeated inside a document are grouped into clusters by an image matching algorithm. The decisions of an OCR algorithm about the identities of those words are used to generate a common recognition result for each of the original word images. This technique thus combines information from the document image (word image clusters) with recognition results to correct errors made by OCR systems on different instances of the same word. Experimental results are presented that show about 50% of the words in a document are repeated two or more times. A clustering algorithm is able to reliably locate a large percentage of these words in the presence of noise. Experiments on images degraded with uniform noise show that the correct rate of a commercial OCR system can be improved from 79% to 92% on the words in those clusters. A n error analysis is given that shows with further development correct rates in the 98+ % range are achievable."
            },
            "slug": "Improving-ocr-performance-with-word-image-Hong-Hull",
            "title": {
                "fragments": [],
                "text": "Improving ocr performance with word image equivalence"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper proposes a technique for improving the performance of an OCR system that uses information about equivalent word images inside a document to correct errors made by OCR systems on different instances of the same word."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770124"
                        ],
                        "name": "Sunita Sarawagi",
                        "slug": "Sunita-Sarawagi",
                        "structuredName": {
                            "firstName": "Sunita",
                            "lastName": "Sarawagi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sunita Sarawagi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "As in prior work [13], we use a discriminative semiMarkov field for jointly performing segmentation and recognition [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14036493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "135ace829b6ad2ec9db040d8e5fd137034e83665",
            "isKey": false,
            "numCitedBy": 710,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe semi-Markov conditional random fields (semi-CRFs), a conditionally trained version of semi-Markov chains. Intuitively, a semi-CRF on an input sequence x outputs a \"segmentation\" of x, in which labels are assigned to segments (i.e., subsequences) of x rather than to individual elements xi of x. Importantly, features for semi-CRFs can measure properties of segments, and transitions within a segment can be non-Markovian. In spite of this additional power, exact learning and inference algorithms for semi-CRFs are polynomial-time\u2014often only a small constant factor slower than conventional CRFs. In experiments on five named entity recognition problems, semi-CRFs generally outperform conventional CRFs."
            },
            "slug": "Semi-Markov-Conditional-Random-Fields-for-Sarawagi-Cohen",
            "title": {
                "fragments": [],
                "text": "Semi-Markov Conditional Random Fields for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Intuitively, a semi-CRF on an input sequence x outputs a \"segmentation\" of x, in which labels are assigned to segments rather than to individual elements of xi, and transitions within a segment can be non-Markovian."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141915"
                        ],
                        "name": "W. Niblack",
                        "slug": "W.-Niblack",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Niblack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niblack"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "Each such text region is coarsely binarized with Niblack\u2019s algorithm [7] to speed recognition by limiting the number of segmentations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60929037,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "43678765df1d0b4594f7a49298cf27d75e174787",
            "isKey": false,
            "numCitedBy": 1417,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-introduction-to-digital-image-processing-Niblack",
            "title": {
                "fragments": [],
                "text": "An introduction to digital image processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37210858"
                        ],
                        "name": "Charles Sutton",
                        "slug": "Charles-Sutton",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Sutton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "The MAP estimate of model parameters\u2014linear weights \u03b8 and \u03b8 along with entries for U , U , and U\u2014is learned from data via decoupled piecewise training [11], a convex optimization problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1549479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "beb0766d6233836ac1203b224930dc037e2b1dff",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "For many large undirected models that arise in real-world applications, exact maximum-likelihood training is intractable, because it requires computing marginal distributions of the model. Conditional training is even more difficult, because the partition function depends not only on the parameters, but also on the observed input, requiring repeated inference over each training example. An appealing idea for such models is to independently train a local undirected classifier over each clique, afterwards combining the learned weights into a single global model. In this paper, we show that this piecewise method can be justified as minimizing a new family of upper bounds on the log partition function. On three natural-language data sets, piecewise training is more accurate than pseudolikelihood, and often performs comparably to global training using belief propagation."
            },
            "slug": "Piecewise-Training-for-Undirected-Models-Sutton-McCallum",
            "title": {
                "fragments": [],
                "text": "Piecewise Training for Undirected Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that this piecewise method can be justified as minimizing a new family of upper bounds on the log partition function, and on three natural-language data sets, piecewise training is more accurate than pseudolikelihood, and often performs comparably to global training using belief propagation."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Steerable pyramid filters [10] at six orientations are used on the original grayscale image and then normalized for brightness to form the feature vectors F (x) for the gap and character appearance discriminants."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1099364,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "89b6a5a136bc0a938b792df6bdde134def28335e",
            "isKey": false,
            "numCitedBy": 1149,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an architecture for efficient and accurate linear decomposition of an image into scale and orientation subbands. The basis functions of this decomposition are directional derivative operators of any desired order. We describe the construction and implementation of the transform."
            },
            "slug": "The-steerable-pyramid:-a-flexible-architecture-for-Simoncelli-Freeman",
            "title": {
                "fragments": [],
                "text": "The steerable pyramid: a flexible architecture for multi-scale derivative computation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An architecture for efficient and accurate linear decomposition of an image into scale and orientation subbands and the construction and implementation of the transform is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 13,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Typographical-Features-for-Scene-Text-Recognition-Weinman/f0a62f4556c2c721f489a1a14bfe3ed509175d8b?sort=total-citations"
}