{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 556474,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9188b661f2ae65a080676617cc83b7d09773c59f",
            "isKey": false,
            "numCitedBy": 588,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "There have been important recent advances in object recognition through the matching of invariant local image features. However, the existing approaches are based on matching to individual training images. This paper presents a method for combining multiple images of a 3D object into a single model representation. This provides for recognition of 3D objects from any viewpoint, the generalization of models to non-rigid changes, and improved robustness through the combination of features acquired under a range of imaging conditions. The decision of whether to cluster a training image into an existing view representation or to treat it as a new view is based on the geometric accuracy of the match to previous model views. A new probabilistic model is developed to reduce the false positive matches that would otherwise arise due to loosened geometric constraints on matching 3D and non-rigid models. A system has been developed based on these approaches that is able to robustly recognize 3D objects in cluttered natural images in sub-second times."
            },
            "slug": "Local-feature-view-clustering-for-3D-object-Lowe",
            "title": {
                "fragments": [],
                "text": "Local feature view clustering for 3D object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a method for combining multiple images of a 3D object into a single model representation that provides for recognition of 3D objects from any viewpoint, the generalization of models to non-rigid changes, and improved robustness through the combination of features acquired under a range of imaging conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3037691"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Edie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 171
                            }
                        ],
                        "text": "In our current implementation, we only match patches across pairs of images ( ), and follow a strategy similar to that used in the range data domain by Johnson and Hebert [7] with spin images ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 152
                            }
                        ],
                        "text": "In our current implementation, we only match patches across pairs of images ( ), and follow a strategy similar to that used in the range data domain by Johnson and Hebert [7] with spin images."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9442407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2354d26f7430266f458fda271d8f758ea89f00f",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Surface-matching-for-object-recognition-in-complex-Johnson-Hebert",
            "title": {
                "fragments": [],
                "text": "Surface matching for object recognition in complex three-dimensional scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 81
                            }
                        ],
                        "text": "Operators capable of finding rotation- [20], scale- [9, 11] and affine-invariant [1, 12, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of wide-baseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15626261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f693427d956c0dbc822e7f3452aee8ca36204b",
            "isKey": false,
            "numCitedBy": 767,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches. Features are detected in two or more images and characterised using affine texture invariants. The problem of window effects is explicitly addressed by our method-our feature characterisation is invariant to linear transformations of the image data including rotation, stretch and skew. The feature matching process is optimised for a structure-from-motion application where we wish to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "slug": "Reliable-feature-matching-across-widely-separated-Baumberg",
            "title": {
                "fragments": [],
                "text": "Reliable feature matching across widely separated views"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints that is optimised for a structure-from-motion application where it wishes to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 52
                            }
                        ],
                        "text": "Operators capable of finding rotation- [20], scale- [9, 11] and affine-invariant [1, 12, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of wide-baseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16256,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738392"
                        ],
                        "name": "Arthur R. Pope",
                        "slug": "Arthur-R.-Pope",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Pope",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur R. Pope"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 2
                            }
                        ],
                        "text": ", [15, 17, 20]), or limiting the range of admissible viewpoints (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1439451,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d1e696747a5452364579bea583196ed8bc2b254",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe how to model the appearance of a 3-D object using multiple views, learn such a model from training images, and use the model for object recognition. The model uses probability distributions to describe the range of possible variation in the object's appearance. These distributions are organized on two levels. Large variations are handled by partitioning training images into clusters corresponding to distinctly different views of the object. Within each cluster, smaller variations are represented by distributions characterizing uncertainty in the presence, position, and measurements of various discrete features of appearance. Many types of features are used, ranging in abstraction from edge segments to perceptual groupings and regions. A matching procedure uses the feature uncertainty information to guide the search for a match between model and image. Hypothesized feature pairings are used to estimate a viewpoint transformation taking account of feature uncertainty. These methods have been implemented in an object recognition system, OLIVER. Experiments show that OLIVER is capable of learning to recognize complex objects in cluttered images, while acquiring models that represent those objects using relatively few views."
            },
            "slug": "Probabilistic-Models-of-Appearance-for-3-D-Object-Pope-Lowe",
            "title": {
                "fragments": [],
                "text": "Probabilistic Models of Appearance for 3-D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This work describes how to model the appearance of a 3-D object using multiple views, learn such a model from training images, and use the model for object recognition, and demonstrates that OLIVER is capable of learning to recognize complex objects in cluttered images, while acquiring models that represent those objects using relatively few views."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 232
                            }
                        ],
                        "text": "When three or more views are available, on the other hand, it is a simple matter to compute the corresponding Euclidean weak-perspective projection matrices (assuming the aspect-ratios are known) and recover the Euclidean structure [15, 16, 23, 26]: Briefly, we find the 3 3 matrix Q such that AiQ is part of a (scaled) rotation matrix for i = 1; : : : ;m."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 73
                            }
                        ],
                        "text": "The matrix Q can then be computed via Cholesky decomposition for example [15, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1673652,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ada6208b40be9f11f8e7b8745f86af22e364bce2",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors show how to automatically acquire similarity-invariant shape representations of objects from noisy image sequences under a weak perspective. The incremental nature of the method makes it possible to process images one at a time, moving away from the storage-intensive batch methods of the past. It is based on the observation that the trajectories that points on the object form in weak-perspective image sequences are linear combinations of three of the trajectories themselves, and that the coefficients of the linear combinations represent shape in an affine-invariant basis. A nonlinear but numerically sound preprocessing state is added to improve the accuracy of the results even further. Experiments showed that attention to noise and computational techniques improved the shape results substantially with respect to previous methods.<<ETX>>"
            },
            "slug": "Linear-and-incremental-acquisition-of-invariant-Weinshall-Tomasi",
            "title": {
                "fragments": [],
                "text": "Linear and incremental acquisition of invariant shape models from image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The authors show how to automatically acquire similarity-invariant shape representations of objects from noisy image sequences under a weak perspective, based on the observation that the trajectories that points on the object form in weak-perspective image sequences are linear combinations of three of the trajectory themselves."
            },
            "venue": {
                "fragments": [],
                "text": "1993 (4th) International Conference on Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7785990"
                        ],
                        "name": "A. Salgian",
                        "slug": "A.-Salgian",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Salgian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Salgian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31614700"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Nelson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 2
                            }
                        ],
                        "text": ", [14, 17, 19, 21]), or limiting the range of admissible viewpoints (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15555340,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "15074808e5409638e7735c45ee0c1b7825405617",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider the problem of 3D object recognition and the role that perceptual grouping processes must play. In particular, we argue that reliance on a single level of perceptual grouping is inadequate, since it is responsible for the specific weaknesses of several well-known recognition techniques. Instead, recognition must use a hierarchy of perceptual grouping processes. We describe an appearance-based system that uses four distinct levels of perceptual grouping to represent 3D objects in a form that allows not only recognition, but reasoning about 3D manipulation of a sort that has been supported in the past only by 3D geometric models. The results of the algorithms have been previously reported, and the main contribution of this paper is the development of the perceptual organization hierarchy."
            },
            "slug": "A-Perceptual-Grouping-Hierarchy-for-3D-Object-Salgian-Nelson",
            "title": {
                "fragments": [],
                "text": "A Perceptual Grouping Hierarchy for Appearance-Based 3D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An appearance-based system that uses four distinct levels of perceptual grouping to represent 3D objects in a form that allows not only recognition, but reasoning about 3D manipulation of a sort that has been supported in the past only by 3D geometric models is described."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40316280"
                        ],
                        "name": "Dennis Tell",
                        "slug": "Dennis-Tell",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Tell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis Tell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38014951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a6ea7bd5be7631f671ea0069bc296cc51654895",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of establishing correspondences between images taken from different viewpoints is fundamental in computer vision. We propose an algorithm which is capable of handling larger changes in viewpoint than classical correlation based techniques. Optimal performance for the algorithm is achieved for textured objects which are locally planar in at least one direction. The algorithm works by computing affinely invariant fourier features from intensity profiles in each image. The intensity profiles are extracted from the image data between randomly selected pairs of image interest points. Using a voting scheme, pairs of interest points are matched across images by comparing vectors of fourier features. Outliers among the matches are rejected in two stages, a fast stage using novel view consistency constraints, and a second, slower stage using RANSAC and fundamental matrix computation. In order to demonstrate the quality of the results, the algorithm is tested on several different image pairs."
            },
            "slug": "Wide-Baseline-Point-Matching-Using-Affine-Computed-Tell-Carlsson",
            "title": {
                "fragments": [],
                "text": "Wide Baseline Point Matching Using Affine Invariants Computed from Intensity Profiles"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm which is capable of handling larger changes in viewpoint than classical correlation based techniques is proposed, which works by computing affinely invariant fourier features from intensity profiles in each image."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12209481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3565c5a65842f26091578b9d71d496cc1561239d",
            "isKey": false,
            "numCitedBy": 1292,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints."
            },
            "slug": "A-statistical-method-for-3D-object-detection-to-and-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "A statistical method for 3D object detection applied to faces and cars"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using this method, this work has developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithms thatCan reliably detect passenger cars over a wide range of viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "Thus it would be interesting to combine affine and perspective/projective matching constraints in modeling and recognition tasks (as was done by Tuytelaars and Van Gool [24] in the image matching domain)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 169
                            }
                        ],
                        "text": "We show in Section 3 that it is possible to exploit the multiview geometry of affine projection to impose effective poseconsistency constraints on matching patches (see [22, 24] for related work)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "In particular, the matrix H2 H1 has rank 1, a fact that can be used as a matching constraint for two patches observed in two views (see Tuytelaars and Van Gool [24] for a related result for planar patches related by an affine transformation but observed by perspective cameras)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 81
                            }
                        ],
                        "text": "Operators capable of finding rotation- [19], scale- [9, 10] and affine-invariant [1, 11, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of widebaseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matching widely separated views based on affinely invariant neighborhoods"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. of Comp. Vision"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076817912"
                        ],
                        "name": "P. Pritchett",
                        "slug": "P.-Pritchett",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Pritchett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pritchett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 81
                            }
                        ],
                        "text": "Operators capable of finding rotation- [20], scale- [9, 11] and affine-invariant [1, 12, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of wide-baseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46527015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4da91ba2e80a4d8deb597b1c884cda890f086653",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically. This facilitates matching between quite disparate views-wide baseline stereo. Two extensions are made to the current small baseline algorithms: first, and most importantly, a viewpoint invariant measure is developed for assessing the affinity of corner neighbourhoods over image pairs; second, algorithms are given for generating putative corner matches between image pairs using local homographies. Two novel infrastructure developments are also described: the automatic generation of local homographies, and the combination of possibly conflicting sets of matches prior to RANSAC estimation. The wide baseline matching algorithm is demonstrated on a number of image pairs with varying relative motion, and for different scene types. All processing is automatic."
            },
            "slug": "Wide-baseline-stereo-matching-Pritchett-Zisserman",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo matching"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically, and to facilitate matching between quite disparate views-wide baseline stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 224
                            }
                        ],
                        "text": "As noted in Section 2, a match between images of the same affine invariant patches is equivalent to a match between triples of points, thus the machinery developed in the structure from motion [3, 5, 23] and pose estimation [6, 8] literature can in principle be used to extend our approach to the perspective case."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 96
                            }
                        ],
                        "text": "It is thus clear that all the machinery of structure from motion [3, 5, 23] and pose estimation [6, 8] from point matches can be exploited in our modeling and object recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 112
                            }
                        ],
                        "text": "Traditional feature-based geometric approaches to this problem, for ex ample alignment and interpretation trees [6, 8], enumerate all triples of image features before pose consistency constrai ts can be used to confirm or discard competing match hypotheses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19251212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2583da9d16a6a596158a8eef220831b0d3d8f8a",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The viewpoint consistency constraint requires that the locations of all object features in an image must be consistent with projection from a single viewpoint. The application of this constraint is central to the problem of achieving robust recognition, since it allows the spatial information in an image to be compared with prior knowledge of an object's shape to the full degree of available image resolution. In addition, the constraint greatly reduces the size of the search space during model-based matching by allowing a few initial matches to provide tight constraints for the locations of other model features. Unfortunately, while simple to state, this constraint has seldom been effectively applied in model-based computer vision systems. This paper reviews the history of attempts to make use of the viewpoint consistency constraint and then describes a number of new techniques for applying it to the process of model-based recognition. A method is presented for probabilistically evaluating new potential matches to extend and refine an initial viewpoint estimate. This evaluation allows the model-based verification process to proceed without the expense of backtracking or search. It will be shown that the effective application of the viewpoint consistency constraint, in conjunction with bottom-up image description based upon principles of perceptual organization, can lead to robust three-dimensional object recognition from single gray-scale images."
            },
            "slug": "The-viewpoint-consistency-constraint-Lowe",
            "title": {
                "fragments": [],
                "text": "The viewpoint consistency constraint"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It will be shown that the effective application of the viewpoint consistency constraint, in conjunction with bottom-up image description based upon principles of perceptual organization, can lead to robust three-dimensional object recognition from single gray-scale images."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8970876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf1527807ebb16020b04d4166e7ba8d27652302",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars."
            },
            "slug": "Unsupervised-Learning-of-Models-for-Recognition-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Models for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method to learn object class models from unlabeled and unsegmented cluttered cluttered scenes for the purpose of visual object recognition that achieves very good classification results on human faces and rear views of cars."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 193
                            }
                        ],
                        "text": "As noted in Section 2, a match between images of the same affine invariant patches is equivalent to a match between triples of points, thus the machinery developed in the structure from motion [3, 5, 23] and pose estimation [6, 8] literature can in principle be used to extend our approach to the perspective case."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "Alternatively, singular value decomposition can be used as in Tomasi and Kanade [23] to factorize and compute estimates of the matrices and \u0005 that minimize the squared Frobenius norm of the matrix ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 234
                            }
                        ],
                        "text": "When three or more views are available, on the other hand, it is a simple matter to compute the corresponding Euclidean weak-perspective projec tion matrices (assuming the aspect-ratios are known) and re cover the Euclidean structure [16, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 62
                            }
                        ],
                        "text": "Alternatively, singular value decomposition can be used as in Tomasi and Kanade [23] to factorize\nand compute estimates of the matrices\nand that minimize the squared Frobenius norm of the matrix\n."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 243
                            }
                        ],
                        "text": "We propose such a surface representation in terms of the affine-invariant patches introduced by Mikolajczyk and Schmid [12] and geometric consistency constraints related to the multi-view geometry studied in the structure-fromotion literature [3, 5, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "factorization of by picking, as in Tomasi and Kanade [23], the center of mass of the observed patches\u2019 centers as the ori gin of the world coordinate system, and the center of mass of these points\u2019 projections as the origin of every image coordinate system: In this case, the projection matrices reduce to ' (, where is a matrix, and ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 65
                            }
                        ],
                        "text": "It is thus clear that all the machinery of structure from motion [3, 5, 23] and pose estimation [6, 8] from point matches can be exploited in our modeling and object recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 87
                            }
                        ],
                        "text": "To account for the form of , we construct a reduced factorization of\nby picking, as in Tomasi and Kanade [23], the center of mass of the observed patches\u2019 centers as the origin of the world coordinate system, and the center of mass of these points\u2019 projections as the origin of every image coordinate system: In this case, the projection matrices reduceto ' (, where is a matrix, and ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2931825,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee07d502c11c8ef8a152b6feef22695249d0764a",
            "isKey": true,
            "numCitedBy": 2454,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Inferring scene geometry and camera motion from a stream of images is possible in principle, but is an ill-conditioned problem when the objects are distant with respect to their size. We have developed a factorization method that can overcome this difficulty by recovering shape and motion under orthography without computing depth as an intermediate step.An image stream can be represented by the 2F\u00d7P measurement matrix of the image coordinates of P points tracked through F frames. We show that under orthographic projection this matrix is of rank 3.Based on this observation, the factorization method uses the singular-value decomposition technique to factor the measurement matrix into two matrices which represent object shape and camera rotation respectively. Two of the three translation components are computed in a preprocessing stage. The method can also handle and obtain a full solution from a partially filled-in measurement matrix that may result from occlusions or tracking failures.The method gives accurate results, and does not introduce smoothing in either shape or motion. We demonstrate this with a series of experiments on laboratory and outdoor image streams, with and without occlusions."
            },
            "slug": "Shape-and-motion-from-image-streams-under-a-method-Tomasi-Kanade",
            "title": {
                "fragments": [],
                "text": "Shape and motion from image streams under orthography: a factorization method"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A factorization method is developed that can overcome the difficulty by recovering shape and motion under orthography without computing depth as an intermediate step, and gives accurate results."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 2
                            }
                        ],
                        "text": ", [15, 17, 20]), or limiting the range of admissible viewpoints (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "Operators capable of finding rotation- [20], scale- [9, 11] and affine-invariant [1, 12, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of wide-baseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256432"
                        ],
                        "name": "C. Poelman",
                        "slug": "C.-Poelman",
                        "structuredName": {
                            "firstName": "Conrad",
                            "lastName": "Poelman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Poelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 232
                            }
                        ],
                        "text": "When three or more views are available, on the other hand, it is a simple matter to compute the corresponding Euclidean weak-perspective projection matrices (assuming the aspect-ratios are known) and recover the Euclidean structure [15, 16, 23, 26]: Briefly, we find the 3 3 matrix Q such that AiQ is part of a (scaled) rotation matrix for i = 1; : : : ;m."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 73
                            }
                        ],
                        "text": "The matrix Q can then be computed via Cholesky decomposition for example [15, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6601890,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d20b0e6a129014f415feb823a8fe5e1f306092b3",
            "isKey": false,
            "numCitedBy": 402,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The factorization method, first developed by Tomasi and Kanade (1992), recovers both the shape of an object and its motion from a sequence of images, using many images and tracking many feature points to obtain highly redundant feature position information. The method robustly processes the feature trajectory information using singular value decomposition (SVD), taking advantage of the linear algebraic properties of orthographic projection. However, an orthographic formulation limits the range of motions the method can accommodate. Paraperspective projection, first introduced by Ohta et al. (1981), is a projection model that closely approximates perspective projection by modeling several effects not modeled under orthographic projection, while retaining linear algebraic properties. Our paraperspective factorization method can be applied to a much wider range of motion scenarios, including image sequences containing motion toward the camera and aerial image sequences of terrain taken from a low-altitude airplane."
            },
            "slug": "A-Paraperspective-Factorization-Method-for-Shape-Poelman-Kanade",
            "title": {
                "fragments": [],
                "text": "A Paraperspective Factorization Method for Shape and Motion Recovery"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work has shown that the paraperspective factorization method can be applied to a much wider range of motion scenarios, including image sequences containing motion toward the camera and aerial image sequences of terrain taken from a low-altitude airplane."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] has allowed us to construct a normalized representatio of local surface appearance that can be used to select promis ing matches in 3D object modeling and recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 92
                            }
                        ],
                        "text": "In this paper, we use\nn implementation of the affine-invariant region detector developed by Mikolajczyk and Schmid [12] for low-level im-\nage description."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 81
                            }
                        ],
                        "text": "Operators capable of finding rotation- [20], scale- [9, 11] and affine-invariant [1, 12, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of wide-baseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "We propose such a surface representation in terms of the affine-invariant patches introduced by Mikolajczyk and Schmid [12] and geometric consistency constraints related to the multi-view geometry studied in the structure-fromotion literature [3, 5, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 96
                            }
                        ],
                        "text": "We propose such a surface representation in terms of the affine-invariant patches introduced by Mikolajczyk and Schmid [12] and geometric consistency constraints related to the multi-view geometry studied in the structure-from-\notion literature [3, 5, 23]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 57
                            }
                        ],
                        "text": "Combining this idea with the affine-invariant patches of Mikolajczyk and Schmid\n[12] has allowed us to construct a normalized representatio of local surface appearance that can be used to select promising matches in 3D object modeling and recognition tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "In this paper, we use n implementation of the affine-invariant region detector d eveloped by Mikolajczyk and Schmid [12] for low-level im-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": false,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145831381"
                        ],
                        "name": "J. Burns",
                        "slug": "J.-Burns",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Burns",
                            "middleNames": [
                                "Brian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20701132"
                        ],
                        "name": "R. Weiss",
                        "slug": "R.-Weiss",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Weiss",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": ", bilaterally symmetric ones) admit invariant s, general 3D shapes do not [2], which is the main reason why invariants have fallen out of favor after an intense flurry of activity in the early 1990s [13, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35177427,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee5d210aa0867618f32f8dc8ecb4fdb8a6db4435",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The variation, with respect to view, of 2D features defined for projections of 3D point sets and line segments is studied. It is established that general-case view-invariants do not exist for any number of points, given true perspective, weak perspective, or orthographic projection models. Feature variation under the weak perspective approximation is then addressed. Though there are no general-case weak-perspective invariants, there are special-case invariants of practical importance. Those cited in the literature are derived from linear dependence relations and the invariance of this type of relation to linear transformation. The variation with respect to view is studied for an important set of 2D line segment features: the relative orientation, size, and position of one line segment with respect to another. The analysis includes an evaluation criterion for feature utility in terms of view-variation. This relationship is a function of both the feature and the particular configuration of 3D line segments. The use of this information in objection recognition is demonstrated for difficult discrimination tasks. >"
            },
            "slug": "View-Variation-of-Point-Set-and-Line-Segment-Burns-Weiss",
            "title": {
                "fragments": [],
                "text": "View Variation of Point-Set and Line-Segment Features"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The variation, with respect to view, of 2D features defined for projections of 3D point sets and line segments is studied and it is established that general-case view-invariants do not exist for any number of points, given true perspective, weak perspective, or orthographic projection models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1699616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e81996384b030b580a0e02c0dc367d59c0c15ba",
            "isKey": false,
            "numCitedBy": 697,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been considerable success in automated reconstruction for image sequences where small baseline algorithms can be used to establish matches across a number of images. In contrast in the case of widely separated views, methods have generally been restricted to two or three views.In this paper we investigate the problem of establishing relative viewpoints given a large number of images where no ordering information is provided. A typical application would be where images are obtained from different sources or at different times: both the viewpoint (position, orientation, scale) and lighting conditions may vary significantly over the data set.Such a problem is not fundamentally amenable to exhaustive pair wise and triplet wide baseline matching because this would be prohibitively expensive as the number of views increases. Instead, we investiate how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching. The result is a matching algorithm which is linear in the number of views.The methods are illustrated on several real image data sets. The output enables an image based technique for navigating in a 3D scene, moving from one image to whichever image is the next most appropriate."
            },
            "slug": "Multi-view-Matching-for-Unordered-Image-Sets,-or-Do-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Multi-view Matching for Unordered Image Sets, or \"How Do I Organize My Holiday Snaps?\""
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper invests how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching and produces a matching algorithm which is linear in the number of views."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "Thus it would be interesting to combine affine and perspective/projective matching constraints in modeling and recognition tasks (as was done by Tuytelaars and Van Gool [24] in the image matching domain)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 169
                            }
                        ],
                        "text": "We show in Section 3 that it is possible to exploit the multiview geometry of affine projection to impose effective poseconsistency constraints on matching patches (see [22, 24] for related work)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "In particular, the matrix H2 H1 has rank 1, a fact that can be used as a matching constraint for two patches observed in two views (see Tuytelaars and Van Gool [24] for a related result for planar patches related by an affine transformation but observed by perspective cameras)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 81
                            }
                        ],
                        "text": "Operators capable of finding rotation- [19], scale- [9, 10] and affine-invariant [1, 11, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of widebaseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matching widely separated views based on affinely invariant neighborhoods"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. of Comp. Vision"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "Thus it would be interesting to combine affine and perspective/projective matching constraints in modeling and recognition tasks (as was done by Tuytelaars and Van Gool [24] in the image matching domain)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 169
                            }
                        ],
                        "text": "We show in Section 3 that it is possible to exploit the multiview geometry of affine projection to impose effective poseconsistency constraints on matching patches (see [22, 24] for related work)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "In particular, the matrix H2 H1 has rank 1, a fact that can be used as a matching constraint for two patches observed in two views (see Tuytelaars and Van Gool [24] for a related result for planar patches related by an affine transformation but observed by perspective cameras)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 81
                            }
                        ],
                        "text": "Operators capable of finding rotation- [19], scale- [9, 10] and affine-invariant [1, 11, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of widebaseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matching widely separated views based on affinely invariant neighborhoods"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. of Comp. Vision"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3453447"
                        ],
                        "name": "J. Mundy",
                        "slug": "J.-Mundy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Mundy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 199
                            }
                        ],
                        "text": ", bilaterally symmetric ones) admit invariant s, general 3D shapes do not [2], which is the main reason why invariants have fallen out of favor after an intense flurry of activity in the early 1990s [13, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117429742,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5ad56913c7b703eefde3ec61dd2ede2b7131ec23",
            "isKey": false,
            "numCitedBy": 696,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 Foundations: algebraic invariants - invariant theory and enumerative combinatorics of young tableaux, Shreeram S. Abhyankar, geometric interpretation of joint conic invariants, Joseph L. Mundy, et al, an experimental evaluation of projective invariants, Christopher Coelho, et al the projection of two non-coplanar conics, Stephen J. Maybank the non-existence of general-case view-invariants, J. Brian Burns, et al invariants of non-algebraic curves - noise resistant invariants of curves, Isaac Weiss, semi-differential invariants, Luc J. Van Gool, et al, projective invariants for curves in two and three dimensions, Michael H. Brill, et al, numerical evaluation of differential and semi-differential invariants, Christopher Brown, recognizing general curved objects efficiently, Andrew Zisserman, et al fitting affine invariant conics to curves, Deepak Kapur and Joseph L. Mundy, projectively invariant decomposition of planar shapes, Stefan Carlsson invariants from multiple views - invariant linear methods in photogrammetry and model-matching, Eamon B. Barrett, et al semi-differential invariants for nonplanar curves, Luc J. Van Gool, et al disambiguating stereo matches with spatio-temporal surfaces, Olivier Faugeras and Theo Papadopoulo. Part 2 Applications: transformation invariant indexing, Haim J. Wolfson and Yehezkel Lamdan affine invariants for model-based recognition, John E. Hopcroft, et al object recognition based on moment (or algebraic) invariants, Gabriel Taubin and David B. Cooper fast recognition using algebraic invariants, Charles A. Rothwell, et al toward 3D curved object recognition from image contours, Jean Ponce and David J. Kriegman relative positioning with uncalibrated cameras, Roger Mohr, et al. Appendix: projective geometry for machine vision, Joseph L. Mundy and Andrew Zisserman."
            },
            "slug": "Geometric-invariance-in-computer-vision-Mundy-Zisserman",
            "title": {
                "fragments": [],
                "text": "Geometric invariance in computer vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 2
                            }
                        ],
                        "text": ", [15, 17, 20]), or limiting the range of admissible viewpoints (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61999742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5648d1f511a5180cc0bf7af80a42d3dea3a4680",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, they formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. They present a new compact representation of object appearance that is parameterized by pose and illumination. They have conducted experiments using several objects with complex appearance characteristics.<<ETX>>"
            },
            "slug": "Learning-and-recognition-of-3D-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Learning and recognition of 3D objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation as one of matching visual appearance rather than shape and present a new compact representation of object appearance that is parameterized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "[1993] Proceedings IEEE Workshop on Qualitative Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3453447"
                        ],
                        "name": "J. Mundy",
                        "slug": "J.-Mundy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Mundy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 199
                            }
                        ],
                        "text": ", bilaterally symmetric ones) admit invariant s, general 3D shapes do not [2], which is the main reason why invariants have fallen out of favor after an intense flurry of activity in the early 1990s [13, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35703674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ea88bf2bb30b3ea83087db01c59f9d0dca43563",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Applications-of-Invariance-in-Computer-Vision-Mundy-Zisserman",
            "title": {
                "fragments": [],
                "text": "Applications of Invariance in Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 234
                            }
                        ],
                        "text": "When three or more views are available, on the other hand, it is a simple matter to compute the corresponding Euclidean weak-perspective projec tion matrices (assuming the aspect-ratios are known) and re cover the Euclidean structure [16, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18538474,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b9c185b35c422679ce0b09192c35d725e815cfbd",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how to upgrade the projective reconstruction of a scene to a metric one in the case where the only assumption made about the cameras observing that scene is that they have rectangular pixels (zero-skew cameras). The proposed approach is based on a simple characterization of zero-skew projection matrices in terms of line geometry, and it handles zero-skew cameras with arbitrary or known aspect ratios in a unified framework. The metric upgrade computation is decomposed into a sequence of linear operations, including linear least-squares parameter estimation and eigenvalue-based symmetric matrix factorization, followed by an optional non-linear least-squares refinement step. A few classes of critical motions for which a unique solution cannot be found are spelled out. A MATLAB implementation has been constructed and preliminary experiments with real data are presented."
            },
            "slug": "On-Computing-Metric-Upgrades-of-Projective-Under-Ponce",
            "title": {
                "fragments": [],
                "text": "On Computing Metric Upgrades of Projective Reconstructions Under the Rectangular Pixel Assumption"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper shows how to upgrade the projective reconstruction of a scene to a metric one in the case where the only assumption made about the cameras observing that scene is that they have rectangular pixels (zero-skew cameras)."
            },
            "venue": {
                "fragments": [],
                "text": "SMILE"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736489"
                        ],
                        "name": "Fred Rothganger",
                        "slug": "Fred-Rothganger",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Rothganger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fred Rothganger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 269829,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "368e872307ab1b686d4b8f6f27f76cdc16cdead8",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 130,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel representation for dynamic scenes composed of multiple rigid objects that may undergo different motions and are observed by a moving camera. Multiview constraints associated with groups of affine-covariant scene patches and a normalized description of their appearance are used to segment a scene into its rigid components, construct three-dimensional models of these components, and match instances of models recovered from different image sequences. The proposed approach has been applied to the detection and matching of moving objects in video sequences and to shot matching, i.e., the identification of shots that depict the same scene in a video clip"
            },
            "slug": "Segmenting,-Modeling,-and-Matching-Video-Clips-Rothganger-Lazebnik",
            "title": {
                "fragments": [],
                "text": "Segmenting, Modeling, and Matching Video Clips Containing Multiple Moving Objects"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 232
                            }
                        ],
                        "text": "When three or more views are available, on the other hand, it is a simple matter to compute the corresponding Euclidean weak-perspective projection matrices (assuming the aspect-ratios are known) and recover the Euclidean structure [15, 16, 23, 26]: Briefly, we find the 3 3 matrix Q such that AiQ is part of a (scaled) rotation matrix for i = 1; : : : ;m."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "We use the slightly more robust eigenvalue method described in [16] in our experiments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Metric upgrade of a projective reconstruction under the rectangular pixel assumption"
            },
            "venue": {
                "fragments": [],
                "text": "Second SMILE Workshop, pages 18\u201327"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 180
                            }
                        ],
                        "text": "Operators capable of finding rotation- [20], scale- [9, 11] and affine-invariant [1, 12, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of wide-baseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A combined edge and corner detector"
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference  , pages 189\u2013192"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Zisserman Multiview matching for unordered image sets , or \u201d How do I organize my holiday snaps ? \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc . ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69064006"
                        ],
                        "name": "T. Papadopoulo",
                        "slug": "T.-Papadopoulo",
                        "structuredName": {
                            "firstName": "Thodore",
                            "lastName": "Papadopoulo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Papadopoulo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 193
                            }
                        ],
                        "text": "As noted in Section 2, a match between images of the same affine invariant patches is equivalent to a match between triples of points, thus the machinery developed in the structure from motion [3, 5, 23] and pose estimation [6, 8] literature can in principle be used to extend our approach to the perspective case."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 243
                            }
                        ],
                        "text": "We propose such a surface representation in terms of the affine-invariant patches introduced by Mikolajczyk and Schmid [12] and geometric consistency constraints related to the multi-view geometry studied in the structure-fromotion literature [3, 5, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "A rectified patch can be thought of as a fictitiousview of the original surface patch (Figure 2), and the inverse mappi ng can thus be decomposed into an inverse projection [3] that maps the rectified patch onto the corresponding surface patch, followed by a projection that maps that patch onto its projection into image number , i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "As shown in [3] for example, planar homographies can also be written as the composition of a (perspective) projection and an inverse projection, although t his factorization is only defined up to an unknown scale factor, preventing the straightforward use of singular value decom position techniques."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 65
                            }
                        ],
                        "text": "It is thus clear that all the machinery of structure from motion [3, 5, 23] and pose estimation [6, 8] from point matches can be exploited in our modeling and object recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "The matrix is theinverse projection matrix[3] associated with the plane ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59635978,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "db56f13011e07f00394821dba6df39b621df9393",
            "isKey": true,
            "numCitedBy": 653,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Nitrocyclopropane is prepared by reacting 3-chloro-1-nitropropane with an amine which has a polar center in addition to an amino function in the presence of a polar, aprotic solvent. For example, the reaction of 3-chloro-1-nitropropane with ethylene diamine in the presence of dimethyl sulfoxide produces nitrocyclopropane in high yield."
            },
            "slug": "The-Geometry-of-Multiple-Images-Faugeras-Luong",
            "title": {
                "fragments": [],
                "text": "The Geometry of Multiple Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NRPSXWHUyZ"
            },
            "venue": {
                "fragments": [],
                "text": "NRPSXWHUyZ"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 224
                            }
                        ],
                        "text": "As noted in Section 2, a match between images of the same affine invariant patches is equivalent to a match between triples of points, thus the machinery developed in the structure from motion [3, 5, 23] and pose estimation [6, 8] literature can in principle be used to extend our approach to the perspective case."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 96
                            }
                        ],
                        "text": "It is thus clear that all the machinery of structure from motion [3, 5, 23] and pose estimation [6, 8] from point matches can be exploited in our modeling and object recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 112
                            }
                        ],
                        "text": "Traditional feature-based geometric approaches to this problem, for ex ample alignment and interpretation trees [6, 8], enumerate all triples of image features before pose consistency constrai ts can be used to confirm or discard competing match hypotheses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object recognition usi  ng alignment"
            },
            "venue": {
                "fragments": [],
                "text": "InProc. ICCV, pages 102\u2013111"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Zisserman Multiview matchingfor unordered image sets , or \u201d How do I organize my holiday snaps ? \u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 224
                            }
                        ],
                        "text": "As noted in Section 2, a match between images of the same affine invariant patches is equivalent to a match between triples of points, thus the machinery developed in the structure from motion [3, 5, 23] and pose estimation [6, 8] literature can in principle be used to extend our approach to the perspective case."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 111
                            }
                        ],
                        "text": "Traditional feature-based geometric approaches to this problem, for example alignment and interpretation trees [6, 8], enumerate all triples of image features before pose consistency constraints can be used to confirm or discard competing match hypotheses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 96
                            }
                        ],
                        "text": "It is thus clear that all the machinery of structure from motion [3, 5, 23] and pose estimation [6, 8] from point matches can be exploited in our modeling and object recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object recognition using alignment"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ICCV, pages 102\u2013111"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 145
                            }
                        ],
                        "text": "Thus it would be interesting to combine affine and perspective/projective matching constraints in modeling and recognition tasks (as was done by Tuytelaars and Van Gool [24] in the image matching domain)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "Thus it would be interesting to combine affine and perspective/projective matching constrain ts in modeling and recognition tasks (as was done by Tuytelaars and Van Gool [24] in the image matching domain)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 81
                            }
                        ],
                        "text": "Operators capable of finding rotation- [20], scale- [9, 11] and affine-invariant [1, 12, 18, 24] image descriptors in the neighborhood of salient image features (\u201cinterest points\u201d [4]) have recently been proposed in the context of wide-baseline stereo matching and image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matching widely separate  d views based on affinely invariant neighborhoods"
            },
            "venue": {
                "fragments": [],
                "text": "IJCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69064006"
                        ],
                        "name": "T. Papadopoulo",
                        "slug": "T.-Papadopoulo",
                        "structuredName": {
                            "firstName": "Thodore",
                            "lastName": "Papadopoulo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Papadopoulo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 193
                            }
                        ],
                        "text": "As noted in Section 2, a match between images of the same affine invariant patches is equivalent to a match between triples of points, thus the machinery developed in the structure from motion [3, 5, 23] and pose estimation [6, 8] literature can in principle be used to extend our approach to the perspective case."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 243
                            }
                        ],
                        "text": "We propose such a surface representation in terms of the affine-invariant patches introduced by Mikolajczyk and Schmid [12] and geometric consistency constraints related to the multi-view geometry studied in the structure-fromotion literature [3, 5, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "A rectified patch can be thought of as a fictitiousview of the original surface patch (Figure 2), and the inverse mappi ng can thus be decomposed into an inverse projection [3] that maps the rectified patch onto the corresponding surface patch, followed by a projection that maps that patch onto its projection into image number , i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "As shown in [3] for example, planar homographies can also be written as the composition of a (perspective) projection and an inverse projection, although t his factorization is only defined up to an unknown scale factor, preventing the straightforward use of singular value decom position techniques."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 65
                            }
                        ],
                        "text": "It is thus clear that all the machinery of structure from motion [3, 5, 23] and pose estimation [6, 8] from point matches can be exploited in our modeling and object recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "The matrix is theinverse projection matrix[3] associated with the plane ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59635978,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "db56f13011e07f00394821dba6df39b621df9393",
            "isKey": true,
            "numCitedBy": 653,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Nitrocyclopropane is prepared by reacting 3-chloro-1-nitropropane with an amine which has a polar center in addition to an amino function in the presence of a polar, aprotic solvent. For example, the reaction of 3-chloro-1-nitropropane with ethylene diamine in the presence of dimethyl sulfoxide produces nitrocyclopropane in high yield."
            },
            "slug": "The-Geometry-of-Multiple-Images-Faugeras-Luong",
            "title": {
                "fragments": [],
                "text": "The Geometry of Multiple Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 36,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/3D-object-modeling-and-recognition-using-patches-Rothganger-Lazebnik/1468251456faef0ef2dfa87937fda2aea0bacb90?sort=total-citations"
}