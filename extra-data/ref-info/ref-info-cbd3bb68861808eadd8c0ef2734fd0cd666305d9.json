{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326688"
                        ],
                        "name": "T. Yamazaki",
                        "slug": "T.-Yamazaki",
                        "structuredName": {
                            "firstName": "Takefumi",
                            "lastName": "Yamazaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Yamazaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694780"
                        ],
                        "name": "M. Pazzani",
                        "slug": "M.-Pazzani",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Pazzani",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pazzani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335246"
                        ],
                        "name": "C. Merz",
                        "slug": "C.-Merz",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Merz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Merz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 6
                            }
                        ],
                        "text": "Also, Yamazaki, Pazzani, and Merz (1995) learn both translation rules and semantic hierarchies from parsed parallel sentences in Japanese and English."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 22325037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "150fd27eba87f5a2bb26a0691668c76add88a07e",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Hierarchies-from-Ambiguous-Natural-Data-Yamazaki-Pazzani",
            "title": {
                "fragments": [],
                "text": "Learning Hierarchies from Ambiguous Natural Language Data"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28199373"
                        ],
                        "name": "S. Watkinson",
                        "slug": "S.-Watkinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Watkinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Watkinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756438"
                        ],
                        "name": "S. Manandhar",
                        "slug": "S.-Manandhar",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Manandhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Manandhar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 226
                            }
                        ],
                        "text": "Another related body of work is grammar acquisition, especially those areas that tightly integrate the grammar with a lexicon, such as with Categorial Grammars (Retore & Bonato, 2001; Dudau-Sofronie, Tellier, & Tommasi, 2001; Watkinson & Manandhar, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11203549,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "1df68a034ccc23d297e898730854ef2466377190",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we report on an unsupervised approach to learning Categorial Grammar (CG) lexicons. The learner is provided with a set of possible lexical CG categories, the forward and backward application rules of CG and unmarked positive only corpora. Using the categories and rules, the sentences from the corpus are probabilistically parsed. The parses and the history of previously parsed sentences are used to build a lexicon and annotate the corpus. We report the results from experiments on a number of small generated corpora, that contain examples from subsets of the English language. These show that the system is able to generate reasonable lexicons and provide accurately parsed corpora in the process. We also discuss ways in which the approach can be scaled up to deal with larger and more diverse corpora. 1 I n t r o d u c t i o n In this paper we discuss a potential solution to two problems in Natural Language Processing (NLP), using a combination of statistical and symbolic machine learning techniques. The first problem is learning the syntactic roles, or categories, of words o f a language i.e. learning a lexicon. Secondly, we discuss a method of annotating a corpus with parses. The aim is to learn Categorial Grammar (CG) lexicons, starting from a set of lexical categories, the functional application rules of CG and an unannotated corpus of positive examples. The CG formalism (discussed in Section 2) is chosen because it assigns distinct categories to words of different types, and the categories describe the exact syntactic role each word can play in a sentence. This problem is similar to the unsupervised part of speech tagging work of, for example, Brill (Brill, 1997) and Kupiec (Kupiec, 1992). In Brill's work a lexicon containing the parts of speech available to each word is provided and a simple tagger attaches a complex tag to each word in the corpus, which represents all the possible tags that word can have. Transformation rules are then learned which use the context of a word to determine which simple tag it should be assigned. The results are good, generally achieving around 95% accuracy on large corpora such as the Penn Treebank. Kupiec (Kupiec, 1992) uses an unsupervised version of the Baum-Welch algorithm, which is a way of using examples to iteratively estimate the probabilities of a Hidden Markov Model for part of speech tagging. Instead of supplying a lexicon, he places the words in equivalence classes. Words in the same equivalence class must take one of a specific set of parts of speech. This improves the accuracy of this algorithm to about the same level as Brill's approach. In both cases, the learner is provided with a large amount of background knowledge either a complete lexicon or set of equivalence classes. In the approach presented here, the most that is provided is a small partial lexicon. In fact the system learns the lexicon. The second problem annotating the corpus is solved because of the approach we use to learn the lexicon. The system uses parsing to determine which are the correct lexical entries for a word, thus annotating the corpus with the parse derivations (also providing less probable parses if desired). An example of another approach to doing this is the Fidditch parser of Hindle (Hindle, 1983) (based on the deterministic parser of Marcus (Marcus, 1980)), which was used to annotate the Penn Treebank (Marcus et al., 1993). However, instead of learning the lexicon, a complete grammar and lexicon"
            },
            "slug": "Unsupervised-Lexical-Learning-with-Categorial-Watkinson-Manandhar",
            "title": {
                "fragments": [],
                "text": "Unsupervised Lexical Learning with Categorial Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "An unsupervised approach to learning Categorial Grammar (CG) lexicons using a combination of statistical and symbolic machine learning techniques, which shows that the system is able to generate reasonable lexicons and provide accurately parsed corpora in the process."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29862116"
                        ],
                        "name": "Dale Russell",
                        "slug": "Dale-Russell",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Russell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Russell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 16
                            }
                        ],
                        "text": "Several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 56
                            }
                        ],
                        "text": "Finally, several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60693316,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "ef95b86490a1b5b74befb7919b3dd916d172f1d3",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the obstacles to be overcome in Natural Language Understanding is the existence of lexical gaps; that is, words or word senses which are not in the lexicon of the system. No lexicon, whether hand-coded or derived from an on-line dictionary, can ever be complete, in the sense of having entries for every word encountered in every syntactic category and with every semantic sense with which it may be used. \nIn order to address this issue, this thesis describes the implementation of MURRAY, a learning mechanism which is able to (i) infer the syntactic properties of a new lexical item from its syntactic environment; (ii) infer the meaning of a novel lexical item based on context and a domain-specific database of real-world knowledge; and (iii) combine those syntactic and semantic properties of a given unknown word inferred from multiple pieces of input, resulting in a version space of possible lexical entries for the unknown, each consistent with all environments in which it has been encountered. \nMURRAY is an extension to an existing unification-based grammar processing system, U scNICORN. It has been implemented to operate with grammars written in the style of Head-Driven Phrase Structure Grammar, though it is compatible with any unification-based grammar formalism. On each encounter with a word which does not exist in the lexicon of the system, MURRAY constructs a lexical version hyperspace, a disjunction of version spaces, one for each possible syntactic category that the unknown could be in the given linguistic context. On each encounter with the unknown, information from the version spaces thus constructed is combined, so that from multiple inputs, the system converges on the target definition of the new word."
            },
            "slug": "Language-acquisition-in-a-unification-based-grammar-Russell",
            "title": {
                "fragments": [],
                "text": "Language acquisition in a unification-based grammar processing system using a real-world knowledge base"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "MURRAY is an extension to an existing unification-based grammar processing system, U scNICORN, and has been implemented to operate with grammars written in the style of Head-Driven Phrase Structure Grammar, though it is compatible with any unification- based grammar formalism."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792119"
                        ],
                        "name": "P. S\u00e9billot",
                        "slug": "P.-S\u00e9billot",
                        "structuredName": {
                            "firstName": "Pascale",
                            "lastName": "S\u00e9billot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. S\u00e9billot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145141931"
                        ],
                        "name": "P. Bouillon",
                        "slug": "P.-Bouillon",
                        "structuredName": {
                            "firstName": "Pierrette",
                            "lastName": "Bouillon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bouillon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060439347"
                        ],
                        "name": "C\u00e9cile Fabre",
                        "slug": "C\u00e9cile-Fabre",
                        "structuredName": {
                            "firstName": "C\u00e9cile",
                            "lastName": "Fabre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C\u00e9cile Fabre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7884915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5a98f02c853463b3811554191e9f2241d37fba0",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose an Inductive Logic Programming learning method which aims at automatically extracting special Noun-Verb (N-V) pairs from a corpus in order to build up semantic lexicons based on Pustejovsky's Generative Lexicon (GL) principles (Pustejovsky, 1995). In one of the components of this lexical model, called the qualia structure, words are described in terms of semantic roles. For example, the telic role indicates the purpose or function of an item (cut for knife), the agentive role its creation mode (build for house), etc. The qualia structure of a noun is mainly made up of verbal associations, encoding relational information. The Inductive Logic Programming learning method that we have developed enables us to automatically extract from a corpus N-V pairs whose elements are linked by one of the semantic relations defined in the qualia structure in GL, and to distinguish them, in terms of surrounding categorial context from N-V pairs also present in sentences of the corpus but not relevant. This method has been theoretically and empirically validated, on a technical corpus. The N-V pairs that have been extracted will further be used in information retrieval applications for index expansion."
            },
            "slug": "Inductive-Logic-Programming-for-Corpus-Based-of-S\u00e9billot-Bouillon",
            "title": {
                "fragments": [],
                "text": "Inductive Logic Programming for Corpus-Based Acquisition of Semantic Lexicons"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An Inductive Logic Programming learning method which aims at automatically extracting special Noun-Verb (N-V) pairs from a corpus in order to build up semantic lexicons based on Pustejovsky's Generative Lexicon (GL) principles."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL/LLL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979239"
                        ],
                        "name": "T. Oates",
                        "slug": "T.-Oates",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Oates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Oates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403818113"
                        ],
                        "name": "Zachary Eyler-Walker",
                        "slug": "Zachary-Eyler-Walker",
                        "structuredName": {
                            "firstName": "Zachary",
                            "lastName": "Eyler-Walker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zachary Eyler-Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580830"
                        ],
                        "name": "P. Cohen",
                        "slug": "P.-Cohen",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Cohen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Oates, Eyler-Walker, and Cohen (1999) discuss the acquisition of lexical hierarchies and their associated meaning as defined by the sensory environment of a robot."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2479941,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "6a6978ba2feda4837ece44e0a4e77c92cce96d95",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Children learn natural languages by hearing utterances while interacting with their physical environment. We investigate one aspect of language acquisition by similarly situated, embodied artificial agents - using information about syntax to learn linguistically relevant semantic features. The agent is assumed to have no innate knowledge of syntax, and instead leverages the weak information about syntax available in word co-occurrences. Similarity of context (i.e.the surrounding words) is used to hierarchically cluster words, with clusters corresponding to sets of words that are similar syntactically and, often, semantically. The goal is to identify semantic features captured by the clusters. The leaves of the hierarchy are individual words, which are semantically very specific, and movement up the hierarchy leads to less specificity. The results of an experiment are discussed in which human subjects generated unrestricted natural language utterances to describe the activities of a Pioneer1 mobile robot. The combination of word clustering on this corpus and a common subsequence algorithm applied to the time series of sensor values recorded by the robot made it possible for the Pioneer1 to learn a variety of semantic features. May 17, 1999"
            },
            "slug": "Using-Syntax-to-Learn-Semantic:-An-Experiment-in-a-Oates-Eyler-Walker",
            "title": {
                "fragments": [],
                "text": "Using Syntax to Learn Semantic: An Experiment in Language Acquisition with a Mobile Robot"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work investigates one aspect of language acquisition by similarly situated, embodied artificial agents - using information about syntax to learn linguistically relevant semantic features in word co-occurrences."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710450"
                        ],
                        "name": "J. Zelle",
                        "slug": "J.-Zelle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zelle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 61
                            }
                        ],
                        "text": "For details on this and the other two parsing operators, see Zelle and Mooney (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 184
                            }
                        ],
                        "text": "In this paper, we limit our discussion to Chill\u2019s ability to acquire parsers that map natural language questions directly into Prolog queries that can be executed to produce an answer (Zelle & Mooney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 50
                            }
                        ],
                        "text": "First, its output can be used by a system, Chill (Zelle & Mooney, 1996; Zelle, 1995), that learns to parse sentences into semantic representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 263135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c0e47f8b768258b7d536c21b218e6c46ab8791",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "slug": "Learning-to-Parse-Database-Queries-Using-Inductive-Zelle-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning to Parse Database Queries Using Inductive Logic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart, and provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710450"
                        ],
                        "name": "J. Zelle",
                        "slug": "J.-Zelle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zelle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zelle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 61
                            }
                        ],
                        "text": "For details on this and the other two parsing operators, see Zelle and Mooney (1996). Figure 1 illustrates the complete system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 41
                            }
                        ],
                        "text": "First, it interacts with a system, Chill (Zelle & Mooney, 1996; Zelle, 1995), that learns to parse sentences into semantic representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 72
                            }
                        ],
                        "text": "First, its output can be used by a system, Chill (Zelle & Mooney, 1996; Zelle, 1995), that learns to parse sentences into semantic representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59081657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ab682d62af721cd93d2126db46277f9df6bda81",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 110,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing computer systems to understand natural language input is a difficult task. In recent years there has been considerable interest in corpus-based methods for constructing natural language parsers. These empirical approaches replace hand-crafted grammars with linguistic models acquired through automated training over language corpora. A common thread among such methods to date is the use of propositional or probabilistic representations for the learned knowledge. This dissertation presents an alternative approach based on techniques from a subfield of machine learning known as inductive logic programming (ILP). ILP, which investigates the learning of relational (first-order) rules, provides an empirical method for acquiring knowledge within traditional symbolic parsing frameworks. \nThis dissertation details the architecture, implementation and evaluation of C scHILL, a computer system for acquiring natural language parsers by training over corpora of parsed text. C scHILL treats language acquisition as the learning of search-control rules within a logic program that implements a shift-reduce parser. Control rules are induced using a novel ILP algorithm which handles difficult issues arising in the induction of search-control heuristics. Both the control-rule framework and the induction algorithm are crucial to C scHILL's success. \nThe main advantage of C scHILL over propositional counterparts is its flexibility in handling varied representations. C scHILL has produced parsers for various analyses including case-role mapping, detailed syntactic parse trees, and a logical form suitable for expressing first-order database queries. All of these tasks are accomplished within the same framework, using a single, general learning method that can acquire new syntactic and semantic categories for resolving ambiguities. \nExperimental evidence from both artificial and real-world corpora demonstrates that C scHILL learns parsers as well or better than previous artificial neural network or probabilistic approaches on comparable tasks. In the database query domain, which goes beyond the scope of previous empirical approaches, the learned parser outperforms an existing hand-crafted system. These results support the claim that ILP techniques as implemented in C scHILL represent a viable alternative with significant potential advantages over neural-network, propositional, and probabilistic approaches to empirical parser construction."
            },
            "slug": "Using-inductive-logic-programming-to-automate-the-Zelle",
            "title": {
                "fragments": [],
                "text": "Using inductive logic programming to automate the construction of natural language parsers"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results support the claim that ILP techniques as implemented in C scHILL represent a viable alternative with significant potential advantages over neural-network, propositional, and probabilistic approaches to empirical parser construction."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255957"
                        ],
                        "name": "Cynthia A. Thompson",
                        "slug": "Cynthia-A.-Thompson",
                        "structuredName": {
                            "firstName": "Cynthia",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cynthia A. Thompson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 15
                            }
                        ],
                        "text": "We previously (Thompson, 1995) presented results demonstrating learning representations of a different form, that of a case-role representation (Fillmore, 1968) augmented with Conceptual Dependency (Schank, 1975) information."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 4
                            }
                        ],
                        "text": "See Thompson, Califf, and Mooney (1999) for a description of active learning for Chill."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6341297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f19834f55c05ad45fa38e25c7bae02b93e17b54d",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A system, WOLFIE, that acquires a mapping of words to their semantic representation is presented and a preliminary evaluation is performed. Tree least general generalizations (TLGGs) of the representations of input sentences are performed to assist in determining the representations of individual words in the sentences. The best guess for a meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears. Some promising experimental results on a non-artificial data set are presented."
            },
            "slug": "Acquisition-of-a-Lexicon-from-Semantic-of-Sentences-Thompson",
            "title": {
                "fragments": [],
                "text": "Acquisition of a Lexicon from Semantic Representations of Sentences"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A system, WOLFIE, that acquires a mapping of words to their semantic representation is presented and a preliminary evaluation is performed and promising experimental results on a non-artificial data set are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3181713"
                        ],
                        "name": "Xuanyin Xia",
                        "slug": "Xuanyin-Xia",
                        "structuredName": {
                            "firstName": "Xuanyin",
                            "lastName": "Xia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuanyin Xia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 121
                            }
                        ],
                        "text": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17046237,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "b30a308a75472902aa593dd5ed87d1e33fb0ab64",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We report experimental results on automatic extraction of an English-Chinese translation lexicon, by statistical analysis of a large parallel corpus, using limited amounts of linguistic knowledge. To our knowledge, these are the first empirical results of the kind between an Indo-European and non-Indo-European language for any significant vocabulary and corpus size. The learned vocabulary size is about 6,500 English words, achieving translation precision in the 86\u201396% range, with alignment proceeding at paragraph, sentence, and word levels. Specifically, we report (1) progress on the HKUST English-Chinese Parallel Bilingual Corpus, (2) experiments supporting the usefulness of restricted lexical cues for statistical paragraph and sentence alignment, and (3) experiments that question the role of hand-derived monolingual lexicons for automatic word translation acquisition. Using a hand-derived monolingual lexicon, the learned translation lexicon averages 2.33 Chinese translations per English entry, with a manually-filtered precision of 95.1%, and an automatically-filtered weighted precision of 86.0%. We then introduce a fully automatic two-stage statistical methodology that is able to learn translations for collocations. A statistically-learned monolingual Chinese lexicon is first used to segment the Chinese text, before applying bilingual training to produce 6,429 English entries with 2.25 Chinese translations per entry. This method improves the manually-filtered precision to 96.0% and the automatically-filtered weighted precision to 91.0%, an error rate reduction of 35.7% from using a hand-derived monolingual lexicon."
            },
            "slug": "Large-scale-automatic-extraction-of-an-translation-Wu-Xia",
            "title": {
                "fragments": [],
                "text": "Large-scale automatic extraction of an English-Chinese translation lexicon"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work introduces a fully automatic two-stage statistical methodology that is able to learn translations for collocations and reports experimental results on automatic extraction of an English-Chinese translation lexicon, by statistical analysis of a large parallel corpus."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Translation"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801071"
                        ],
                        "name": "Frank Smadja",
                        "slug": "Frank-Smadja",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Smadja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Smadja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6720757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0285f18f1642c3684e6abb7d5162348278c41abf",
            "isKey": false,
            "numCitedBy": 576,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Collocations are notoriously difficult for non-native speakers to translate, primarily because they are opaque and cannot be translated on a word-by-word basis. We describe a program named Champollion which, given a pair of parallel corpora in two different languages and a list of collocations in one of them, automatically produces their translations. Our goal is to provide a tool for compiling bilingual lexical information above the word level in multiple languages, for different domains. The algorithm we use is based on statistical methods and produces p-word translations of n-word collocations in which n and p need not be the same. For example, Champollion translates make...decision, employment equity, and stock market into prendre...decision, equite en matiere d'emploi, and bourse respectively. Testing Champollion on three years' worth of the Hansards corpus yielded the French translations of 300 collocations for each year, evaluated at 73% accuracy on average. In this paper, we describe the statistical measures used, the algorithm, and the implementation of Champollion, presenting our results and evaluation."
            },
            "slug": "Translating-Collocations-for-Bilingual-Lexicons:-A-Smadja-McKeown",
            "title": {
                "fragments": [],
                "text": "Translating Collocations for Bilingual Lexicons: A Statistical Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A program named Champollion is described which, given a pair of parallel corpora in two different languages and a list of collocations in one of them, automatically produces their translations, to provide a tool for compiling bilingual lexical information above the word level in multiple languages, for different domains."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28199373"
                        ],
                        "name": "S. Watkinson",
                        "slug": "S.-Watkinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Watkinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Watkinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756438"
                        ],
                        "name": "S. Manandhar",
                        "slug": "S.-Manandhar",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Manandhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Manandhar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8712911,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "20102c9e4c290cc81420207cb6217af1000fdfa8",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we report on an unsupervised approach to learning Categorial Grammar (CG) lexicons. The learner is provided with a set of possible lexical CG categories, the forward and backward application rules of CG and unmarked positive only corpora. Using the categories and rules, the sentences from the corpus are probabilistically parsed. The parses of this example and the set of parses of earlier examples in the corpus are used to build a lexicon and annotate the corpus. We report the results from experiments on two generated corpora and also on the more complicated LLL corpus, that contains examples from subsets of English syntax. These show that the system is able to generate reasonable lexicons and provide accurately parsed corpora in the process. We also discuss ways in which the approach can be scaled up to deal with larger and more diverse corpora."
            },
            "slug": "Unsupervised-Lexical-Learning-with-Categorical-the-Watkinson-Manandhar",
            "title": {
                "fragments": [],
                "text": "Unsupervised Lexical Learning with Categorical Grammars Using the LLL Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The system is able to generate reasonable lexicons and provide accurately parsed corpora in the process and ways in which the approach can be scaled up to deal with larger and more diverse corpora are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Learning Language in Logic"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737754"
                        ],
                        "name": "J. Siskind",
                        "slug": "J.-Siskind",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Siskind",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Siskind"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 50
                            }
                        ],
                        "text": "One way to find candidate meanings is to fracture (Siskind, 1992) the meanings of sentences in which a phrase appears, which in our formalism corresponds to finding all possible connected subgraphs of the meaning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "We also describe Jeff Siskind\u2019s lexicon acquisition system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "As already noted, the most closely related work is that of Jeff Siskind, which we described briefly in Section 2 and whose system we ran comparisons to in Section 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Siskind (1996) shows the effectiveness of his approach on a series of artificial corpora."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "We would like to thank Jeff Siskind for providing us with his software, and for all his help in adapting it for use with our corpus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 14
                            }
                        ],
                        "text": "Earlier work (Siskind, 1992) also evaluated versions of his technique on a quite small corpus of real English and Japanese sentences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Thanks to Jeff Siskind for the initial corpus generation software, which we enhanced for these tests."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 113
                            }
                        ],
                        "text": "The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system developed by Siskind (1996), with results favorable to Wolfie."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 7
                            }
                        ],
                        "text": "2 Jeff Siskind\u2019s Lexicon Learning Research The most closely related previous research into automated lexicon acquisition is that of Siskind (1996). As we will be comparing our system to his in Section 5, we describe the main features of his research in this section."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 80
                            }
                        ],
                        "text": "We compared our system to an incremental (on-line) lexicon learner developed by Siskind (1996), and originally evaluated only on artificial data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 35
                            }
                        ],
                        "text": "While some of Siskind\u2019s work (e.g., Siskind, 1992) took syntactic constraints into account and did not encounter such difficulties, those versions did not handle lexical ambiguity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18117681,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "e20dc3e8ce9ba1906409bb90c423f2c69475ef48",
            "isKey": true,
            "numCitedBy": 92,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "How do children learn the language-specific components of their native language? How is language grounded in perception? Knowledge of the meanings of utterances containing unknown words presumably aids children in the process of determining their meanings. A complete account of such a process must ultimately explain how children extract utterance meanings from their non-linguistic context. Algorithms are presented which utilize a cross-situational learning strategy whereby the learner finds a language model which is consistent across several utterances paired with their non-linguistic context. This allows the learner to acquire partial knowledge from ambiguous situations and combine it across situations to infer a unique language model. M scAIMRA learns word-to-meaning and word-to-category mappings from a corpus pairing utterances with sets of expressions representing the potential meanings of those utterances hypothesized by the learner from the non-linguistic context. M scAIMRA's syntactic theory is embodied in a fixed context-free grammar. D scAVRA extends M scAIMRA by replacing the context-free grammar with a parameterized variant of X theory. K scENUNIA incorporates a more comprehensive model of universal grammar supporting movement, adjunction, and empty categories, as well as more extensive parameterization of its X theory component. \nI advance three claims about event perception and the process of grounding language in visual perception. Notions of support, contact, and attachment play a central role in defining the meanings of simple spatial motion verbs in a way that delineates prototypical occurrences of events described by those verbs from non-occurrences. Support, contact, and attachment relations between objects are recovered from images by a process of counterfactual simulation. This imagination capacity, while superficially similar in intent to traditional kinematic simulation, is actually based on a drastically different foundation which takes naive physical constraints such as substantiality, continuity, and attachment relations between objects to be primary. This theory of event perception has been implemented in a program called A scBIGAIL which watches a computer-generated animated movie and produces a description of the objects and events which occur in that movie. A scBIGAIL's event perception processes rely on counter-factual simulation to recover changing support, contact, and attachment relations between objects. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.) (Abstract shortened with permission of school.)"
            },
            "slug": "Naive-physics,-event-perception,-lexical-semantics,-Siskind",
            "title": {
                "fragments": [],
                "text": "Naive physics, event perception, lexical semantics, and language acquisition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Algorithms are presented which utilize a cross-situational learning strategy whereby the learner finds a language model which is consistent across several utterances paired with their non-linguistic context, and three claims about event perception and the process of grounding language in visual perception are advanced."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48546348"
                        ],
                        "name": "M. Johnston",
                        "slug": "M.-Johnston",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Johnston",
                            "middleNames": [
                                "J.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Johnston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713574"
                        ],
                        "name": "B. Boguraev",
                        "slug": "B.-Boguraev",
                        "structuredName": {
                            "firstName": "Branimir",
                            "lastName": "Boguraev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boguraev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707726"
                        ],
                        "name": "J. Pustejovsky",
                        "slug": "J.-Pustejovsky",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Pustejovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pustejovsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15171208,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ae29c3f7cb7cd314cd0aa0d88802ab8866af67cb",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Complex nominals present one of the greatest challenges in semantic analysis to date, particularly when viewed from the concerns of polymorphic expressiveness in natural language. From the perspective of the traditional lexicon designer, complex nominals are formed generatively and therefore do not merit explicit listing except when they are clearly non-compositional. In the spectrum of complex nominals, technical terminology occupies a special place, in that it is highly productive yet serves to encapsulate the essential concepts of a particular technical domain, therefore meriting inclusion in a technical glossary for that domain. Interpreting technical complex nominals (henceforth TCNs) -complex nominals with terminological status-generatively is not generally feasible because they are often composed of technical words for which conventional dictionaries will not provide coverage. As lexicons, and dictionaries, evolve from being static sources of word definitions to dynamic knowledge bases which function as resources for natural language technologies (such as NL-based information access and retrieval, machine translation, and natural language understanding), it will be increasingly important for them to support processing of technical documentation. Hence, they must serve not just the function of a lexicon but also that of a technical glossary. Given the frequency with which they are coined it is impractical to rely on manual listing of TCNs, and so it becomes critical that on-line lexical resources be able to acquire and interpret TCNs dynamically as text is processed."
            },
            "slug": "The-Acquisition-and-Interpretation-of-Complex-Johnston-Boguraev",
            "title": {
                "fragments": [],
                "text": "The Acquisition and Interpretation of Complex Nominals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255957"
                        ],
                        "name": "Cynthia A. Thompson",
                        "slug": "Cynthia-A.-Thompson",
                        "structuredName": {
                            "firstName": "Cynthia",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cynthia A. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967815"
                        ],
                        "name": "M. E. Califf",
                        "slug": "M.-E.-Califf",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Califf",
                            "middleNames": [
                                "Elaine"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. E. Califf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 117
                            }
                        ],
                        "text": "Only a few of the researchers applying machine learning to natural language processing have utilized active learning (Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; ArgamonEngelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of these have addressed classification tasks such as part of speech tagging and text categorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 153
                            }
                        ],
                        "text": "The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001), Soderland (1999), Thompson et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 142
                            }
                        ],
                        "text": "\u2026applying machine learning to natural language processing have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of these have addressed\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 86
                            }
                        ],
                        "text": "The latter two include work on active learning applied to information extraction, and Thompson et al. (1999) includes work on active learning for semantic parsing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 4
                            }
                        ],
                        "text": "See Thompson, Califf, and Mooney (1999) for a description of active learning for Chill."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1371723,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37c9408d511cbc1122b5b570694eed52b04e9636",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In natural language acquisition, it is dicult to gather the annotated data needed for supervised learning; however, unannotated data is fairly plentiful. Active learning methods attempt to select for annotation and training only the most informative examples, and therefore are potentially very useful in natural language applications. However, existing results for active learning have only considered standard classication tasks. To reduce annotation eort while maintaining accuracy, we apply active learning to two non-classication tasks in natural language processing: semantic parsing and information extraction. We show that active learning can signicantly reduce the number of annotated examples required to achieve a given level of performance for these complex tasks."
            },
            "slug": "Active-Learning-for-Natural-Language-Parsing-and-Thompson-Califf",
            "title": {
                "fragments": [],
                "text": "Active Learning for Natural Language Parsing and Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that active learning can signicantly reduce the number of annotated examples required to achieve a given level of performance for these complex tasks: semantic parsing and information extraction."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599392"
                        ],
                        "name": "I. D. Melamed",
                        "slug": "I.-D.-Melamed",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Melamed",
                            "middleNames": [
                                "Dan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. D. Melamed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 85
                            }
                        ],
                        "text": "Our work also has ties to the work on automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 106
                            }
                        ],
                        "text": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42fd4d469c53e4eedd7eb76e7859e3270367f795",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how to induce an N-best translation lexicon from a bilingual text corpus using statistical properties of the corpus together with four external knowledge sources. The knowledge sources are cast as filters, so that any subset of them can be cascaded in a uniform framework. A new objective evaluation measure is used to compare the quality of lexicons induced with different filter cascades. The best filter cascades improve lexicon quality by up to 137% over the plain vanilla statistical method, and approach human performance. Drastically reducing the size of the training corpus has a much smaller impact on lexicon quality when these knowledge sources are used. This makes it practical to train on small hand-built corpora for language pairs where large bilingual corpora are unavailable. Moreover, three of the four filters prove useful even when used with large training corpora."
            },
            "slug": "Automatic-Evaluation-and-Uniform-Filter-Cascades-Melamed",
            "title": {
                "fragments": [],
                "text": "Automatic Evaluation and Uniform Filter Cascades for Inducing N-Best Translation Lexicons"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper shows how to induce an N-best translation lexicon from a bilingual text corpus using statistical properties of the corpus together with four external knowledge sources, which improve lexicon quality by up to 137% over the plain vanilla statistical method, and approach human performance."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737754"
                        ],
                        "name": "J. Siskind",
                        "slug": "J.-Siskind",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Siskind",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Siskind"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ely apply widely across a corpus. 7. The code is available upon request from the \ufb01rst author. 8. Though, of course, interpretation functions are not the only way to guarantee a covering lexicon \u2013 see Siskind (1993) for an alternative. 13 Thompson &amp; Mooney cityid/2 1 texarkana answer/2 1 S state/1 eq/2 loc/2 2 2 2 1 C 1 2 C 1 S 2 S Figure 7: Tree with Variables Let us explain the algorithm in further detail "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ork is that of Je\ufb00 Siskind, which we described brie\ufb02y in Section 2 and whose system we ran comparisons to in Section 5. Our de\ufb01nition of the learning problem can be compared to his \u201cmapping problem\u201d (Siskind, 1993). That formulation di\ufb00ers from ours in several respects. First, his sentence representations are terms instead of trees. However, as shown in Figure 7, terms can also be represented as trees that conf"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Siskind (1993) defined fracturing (he also calls it the Unlink* operation) over terms such that the result includes all subterms of an expression plus \u22a5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "m which the \ufb01nal meaning(s) for that phrase could be chosen in a way that minimizes lexicon size. One way to \ufb01nd candidate meanings is to fracture the meanings of sentences in which a phrase appears. Siskind (1993) de\ufb01ned fracturing (he also calls it the Unlink* operation) over terms such that the result includes all subterms of an expression plus \u22a5. In our representation formalism, this corresponds to \ufb01nding a"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "allows phrasal lexicon entries. Siskind\u2019s work on this topic has explored many di\ufb00erent variations along a continuum of using many constraints but requiring more time to incorporate each new example (Siskind, 1993), versus few constraints but requiring more training data (Siskind, 1996). Thus, perhaps his earlier systems would have been able to learn the lexicons of Section 5 more quickly; but crucially those s"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 168
                            }
                        ],
                        "text": "Siskind\u2019s work on this topic has explored many different variations along a continuum of using many constraints but requiring more time to incorporate each new example (Siskind, 1993), versus few constraints but requiring more training data (Siskind, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 79
                            }
                        ],
                        "text": "Our definition of the learning problem can be compared to his \u201cmapping problem\u201d (Siskind, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 101
                            }
                        ],
                        "text": "Though, of course, interpretation functions are not the only way to guarantee a covering lexicon \u2013 see\nSiskind (1993) for an alternative."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9652401,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "5e6b9e0ac7b587404b860e8d22c8bfb964c4c883",
            "isKey": true,
            "numCitedBy": 11,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a computational study of lexical acquisition. We attempt to characterize the lexical acquisition task faced by children by defining a simplified formal approximation of this task which we term the mapping problem. We then present a novel strategy for solving large instances of this mapping problem. This strategy is capable of learning the word-to-meaning mappings for as many as 10,000 words given corpora of 20,000 utterances. Such lexical acquisition is accomplished in a language independent fashion without any reference to the syntax of the language being learned. Comments University of Pennsylvania Institute for Research in Cognitive Science Technical Report No. IRCS-93-41. This technical report is available at ScholarlyCommons: https://repository.upenn.edu/ircs_reports/190"
            },
            "slug": "Lexical-Acquisition-as-Constraint-Satisfaction-Siskind",
            "title": {
                "fragments": [],
                "text": "Lexical Acquisition as Constraint Satisfaction"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A novel strategy is presented that is capable of learning the word-to-meaning mappings for as many as 10,000 words given corpora of 20,000 utterances and is accomplished in a language independent fashion without any reference to the syntax of the language being learned."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736513"
                        ],
                        "name": "S. Wermter",
                        "slug": "S.-Wermter",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Wermter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wermter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2576323"
                        ],
                        "name": "G. Scheler",
                        "slug": "G.-Scheler",
                        "structuredName": {
                            "firstName": "Gabriele",
                            "lastName": "Scheler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Scheler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Although many others (S\u00b4ebillot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996;  Hastings, 1996;  Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, several systems (Knight, 1996;  Hastings, 1996;  Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21173842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "319a3a51457b5fcaa179576de11305a045177eaa",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning approaches for natural language processing.- Separating learning and representation.- Natural language grammatical inference: A comparison of recurrent neural networks and machine learning methods.- Extracting rules for grammar recognition from Cascade-2 networks.- Generating English plural determiners from semantic representations: A neural network learning approach.- Knowledge acquisition in concept and document spaces by using self-organizing neural networks.- Using hybrid connectionist learning for speech/language analysis.- SKOPE: A connectionist/symbolic architecture of spoken Korean processing.- Integrating different learning approaches into a multilingual spoken language translation system.- Learning language using genetic algorithms.- A statistical syntactic disambiguation program and what it learns.- Training stochastic grammars on semantical categories.- Learning restricted probabilistic link grammars.- Learning PP attachment from corpus statistics.- A minimum description length approach to grammar inference.- Automatic classification of dialog acts with Semantic Classification Trees and Polygrams.- Sample selection in natural language learning.- Learning information extraction patterns from examples.- Implications of an automatic lexical acquisition system.- Using learned extraction patterns for text classification.- Issues in inductive learning of domain-specific text extraction rules.- Applying machine learning to anaphora resolution.- Embedded machine learning systems for natural language processing: A general framework.- Acquiring and updating hierarchical knowledge for machine translation based on a clustering technique.- Applying an existing machine learning algorithm to text categorization.- Comparative results on using inductive logic programming for corpus-based parser construction.- Learning the past tense of English verbs using inductive logic programming.- A dynamic approach to paradigm-driven analogy.- Can punctuation help learning?.- Using parsed corpora for circumventing parsing.- A symbolic and surgical acquisition of terms through variation.- A revision learner to acquire verb selection rules from human-made rules and examples.- Learning from texts - A terminological metareasoning perspective."
            },
            "slug": "Connectionist,-Statistical-and-Symbolic-Approaches-Wermter-Riloff",
            "title": {
                "fragments": [],
                "text": "Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Embedded machine learning systems for natural language processing: Acquiring and updating hierarchical knowledge for machine translation based on a clustering technique and applying an existing machine learning algorithm to text categorization."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808089"
                        ],
                        "name": "L. Sikl\u00f3ssy",
                        "slug": "L.-Sikl\u00f3ssy",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Sikl\u00f3ssy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sikl\u00f3ssy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 65
                            }
                        ],
                        "text": "Work on automated lexicon and language acquisition dates back to Siklossy (1972), who demonstrated a system that learned transformation patterns from logic back to natural\nlanguage."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58822924,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d057f13d7f9bc2ddc98482df6088e35ea83c9df5",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Learning a natural language is taken as an improvement in a system's ability to express situations in a natural language. This dissertation describes a computer program, called Zbie, written in IPL-V, which accepts the description of situations in a uniform, structured functional language and tries to express these situations in a natural language. Examples are given for German and, mostly, Russian. At run-time, Zbie builds simple memory structures. Patterns and sets are built on the functional language. The translation rules of the patterns and an in-context vocabulary provide the transition to the natural language. Zbie is a cautious learner, and avoids errors by several mechanisms. Zbie is capable of some evolutionary learning."
            },
            "slug": "Natural-language-learning-by-computer-Sikl\u00f3ssy",
            "title": {
                "fragments": [],
                "text": "Natural language learning by computer"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This dissertation describes a computer program, called Zbie, written in IPL-V, which accepts the description of situations in a uniform, structured functional language and tries to express them in a natural language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726601"
                        ],
                        "name": "R. Hwa",
                        "slug": "R.-Hwa",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Hwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hwa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Hwa (2001) describes an interesting method for evaluating a statistical parser\u2019s uncertainty, when applied for syntactic parsing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "s on a neural network approach to active learning in a version-space of concepts. Only a few of the researchers applying machine learning to natural language processing have utilized active learning (Hwa, 2001; Schohn &amp; Cohn, 2000; Tong &amp; Koller, 2000; Thompson et al., 1999; Argamon-Engelson &amp; Dagan, 1999; Liere &amp; Tadepalli, 1997; Lewis &amp; Catlett, 1994), and the majority of these have a"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ex output, such as a parse tree, semantic representation, or \ufb01lled template. The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001), Soderland (1999), Thompson et al. (1999). The latter two include work on active learning applied to information extraction, and Thompson et al. (1999) includes work on active learning for semantic p"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 123
                            }
                        ],
                        "text": "The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001), Soderland (1999), Thompson et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 118
                            }
                        ],
                        "text": "Only a few of the researchers applying machine learning to natural language processing have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11913159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d827b3a07b50903a7c4e07b7404d7168dd72d61",
            "isKey": true,
            "numCitedBy": 33,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Many corpus-based natural language processing systems rely on using large quantities of annotated text as their training examples. Building this kind of resource is an expensive and labor-intensive project. To minimize effort spent on annotating examples that are not helpful the training process, recent research efforts have begun to apply active learning techniques to selectively choose data to be annotated. In this work, we consider selecting training examples with the tree-entropy metric. Our goal is to assess how well this selection technique can be applied for training different types of parsers. We find that tree-entropy can significantly reduce the amount of training annotation for both a history-based parser and an EM-based parser. Moreover, the examples selected for the history-based parser are also good for training the EM-based parser suggesting that the technique is parser independent."
            },
            "slug": "On-minimizing-training-corpus-for-parser-Hwa",
            "title": {
                "fragments": [],
                "text": "On minimizing training corpus for parser acquisition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is found that tree-entropy can significantly reduce the amount of training annotation for both a history-basedparser and an EM-based parser, suggesting that the technique is parser independent."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 21
                            }
                        ],
                        "text": "Although many others (S\u00e9billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 110
                            }
                        ],
                        "text": "Although many others (Se\u0301billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59193225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79ce31d005e599bdb25a9a9131712621ad24aa5d",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Until the recent past, there have been two extreme approaches toward extracting knowledge from text. On the one hand, artificial intelligence systems have long operated under the assumption that an a priori structuring of the text domain is necessary before treating the text. On the other, the information retrieval community has traditionally limited itself to simple document cooccurrence statistics as sole indicator of word semantics. The first approach is difficult to extend, while the second relies on context which is too coarse-grained. We present here SEXTANT, a complete system that uses finer-grained syntactic contexts to discover similarities between words. The system is based on the hypothesis that words that are used in a similar way throughout a corpus are indeed semantically similar. This system takes raw text in input, performs syntactic analysis to extract fine-grained contexts, compares contexts of words, and produces a list of similar words as output. Though no domain structuring is needed, the low-level semantic information that SEXTANT extracts can be thought of as an approximation to a domain-specific thesaurus. As one application, these similar words have been shown to improve classical information retrieval, through use in query expansion. This article will present a detailed description of the SEXTANT system."
            },
            "slug": "SEXTANT:-Extracting-Semantics-from-Raw-Text-Grefenstette",
            "title": {
                "fragments": [],
                "text": "SEXTANT: Extracting Semantics from Raw Text"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This article presents SEXTANT, a complete system that uses finer-grained syntactic contexts to discover similarities between words, based on the hypothesis that words that are used in a similar way throughout a corpus are indeed semantically similar."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737754"
                        ],
                        "name": "J. Siskind",
                        "slug": "J.-Siskind",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Siskind",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Siskind"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 69
                            }
                        ],
                        "text": "In fact, all of these assumptions except for single-use were made by Siskind (1996); see Section 7 for details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 80
                            }
                        ],
                        "text": "We compared our system to an incremental (on-line) lexicon learner developed by Siskind (1996)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Siskind (1996) shows the effectiveness of his approach on a series of artificial corpora."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 166
                            }
                        ],
                        "text": "We generated several lexicons and associated corpora, varying the ambiguity rate (number of meanings per word) and synonymy rate (number of words per meaning), as in Siskind (1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 82
                            }
                        ],
                        "text": "Wolfie is also compared to an alternative lexicon acquisition system developed by Siskind (1996), demonstrating superior performance on this task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 79
                            }
                        ],
                        "text": "Although many others (Se\u0301billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 89
                            }
                        ],
                        "text": "The most closely related previous research into automated lexicon acquisition is that of Siskind (1996), itself inspired by work by Rayner, Hugosson, and Hagert (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 241
                            }
                        ],
                        "text": "Siskind\u2019s work on this topic has explored many different variations along a continuum of using many constraints but requiring more time to incorporate each new example (Siskind, 1993), versus few constraints but requiring more training data (Siskind, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 128
                            }
                        ],
                        "text": "This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 14577201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2854f6721708f1f3d5fe746e11efe0c866f83c19",
            "isKey": true,
            "numCitedBy": 542,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-computational-study-of-cross-situational-for-Siskind",
            "title": {
                "fragments": [],
                "text": "A computational study of cross-situational techniques for learning word-to-meaning mappings"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794100"
                        ],
                        "name": "Brian Roark",
                        "slug": "Brian-Roark",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Roark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Roark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 65
                            }
                        ],
                        "text": "For example, Collins and Singer (1999), Riloff and Jones (1999), Roark and Charniak (1998), and Schneider (1998) define semantic lexicons as a grouping of words into semantic categories, and in the latter case, add relational information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 219307649,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e0415088488704d05f2cfacdff3b480129e7f0c",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Generating semantic lexicons semi-automatically could be a great time saver, relative to creating them by hand. In this paper, we present an algorithm for extracting potential entries for a category from an on-line corpus, based upon a small set of exemplars. Our algorithm finds more correct terms and fewer incorrect ones than previous work in this area. Additionally, the entries that are generated potentially provide broader coverage of the category than would occur to an individual coding them by hand. Our algorithm finds many terms not included within Wordnet (many more than previous algorithms), and could be viewed as an ``enhancer'' of existing broad-coverage resources."
            },
            "slug": "Noun-phrase-co-occurrence-statistics-for-semantic-Roark-Charniak",
            "title": {
                "fragments": [],
                "text": "Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon construction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents an algorithm for extracting potential entries for a category from an on-line corpus, based upon a small set of exemplars, that could be viewed as an ``enhancer'' of existing broad-coverage resources."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158597261"
                        ],
                        "name": "John R. Anderson",
                        "slug": "John-R.-Anderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Anderson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Anderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 97
                            }
                        ],
                        "text": "Thanks to net-citizen Dan Hirshberg for help with this analysis.\nfor each phrase, as proposed by Anderson (1977)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 192
                            }
                        ],
                        "text": "Since only positive examples are available, one might think of using most specific conjunctive learning, or finding the intersection of all the representations for each phrase, as proposed by Anderson (1977). However, the meanings of a polysemous phrase are disjunctive, and this intersection would be empty."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38457468,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "cd99be8700564c4874ea2fec6b430448dec7a861",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "LAS is a program that acquires augmented transition network (ATN) grammars. It requires as data sentences of the language and semantic network representatives of their meaning. In acquiring the ATN grammars, it induces the word classes of the language, the rules of formation for sentences, and the rules mapping sentences onto meaning. The induced ATN grammar can be used both for sentence generation and sentence comprehension. Critical to the performance of the program are assumptions that it makes about the relation between sentence structure and surface structure (the graph deformation condition), about when word classes may be formed and when ATN networks may be merged, and about the structure of noun phrases. These assumptions seem to be good heuristics which are largely true for natural languages although they would not be true for many nonnatural languages. Provided these assumptions are satisfied LAS seems capable of learning any context-free language."
            },
            "slug": "Induction-of-Augmented-Transition-Networks-Anderson",
            "title": {
                "fragments": [],
                "text": "Induction of Augmented Transition Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Critical to the performance of the program are assumptions that it makes about the relation between sentence structure and surface structure, about when word classes may be formed and when ATN networks may be merged, and about the structure of noun phrases."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799096"
                        ],
                        "name": "A. Gorin",
                        "slug": "A.-Gorin",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gorin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gorin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 21
                            }
                        ],
                        "text": "Along similar lines, Tishby and Gorin (1994) have a system that learns associations between words and actions, but they use a statistical framework to learn these associations, and do not handle structured representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35792676,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "335a8d819484831cd3f5b2d22efdf4229a941b8e",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Statistical association measures play an important role in many areas of natural language research. An impediment to reliable estimation of such associations is the problem of small-sample statistics, since in any natural corpus there will be many infrequently occurring words. This paper proposes an alternative method for estimating such associations, which circumvents the small-sample issues. The idea is to view sentence/meaning pairs as algebraic equations, rather than as observations of a pattern in some class. Associations are estimated via solving these equations rather than via relative frequency estimates of mutual information. We develop a theoretical foundation for the dual algebraic/statistical nature of associations, proving two uniqueness theorems. We then exploit this theory to provide an algorithmic solution to the estimation problem. This algorithm is experimentally evaluated on 1494 natural languages messages from a rudimentary Data Retrieval experiment. One striking result is that the algebraic algorithm can often provide reliable estimates even for words which occur only once in a corpus."
            },
            "slug": "Algebraic-learning-of-statistical-associations-for-Tishby-Gorin",
            "title": {
                "fragments": [],
                "text": "Algebraic learning of statistical associations for language acquisition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A theoretical foundation for the dual algebraic/statistical nature of associations is developed, proving two uniqueness theorems, and an algorithmic solution to the estimation problem is provided."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153220846"
                        ],
                        "name": "Peter Hastings",
                        "slug": "Peter-Hastings",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hastings",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Hastings"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 94
                            }
                        ],
                        "text": "Although many others (Se\u0301billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 40
                            }
                        ],
                        "text": "Finally, several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195912363,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "7e31abd738474bed3b76312ddb88df0149bfe802",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Camille, the Contextual Acquisition Mechanism for Incremental Lexeme LEarning, was implemented as an addition to Lytinen's LINK parser for use in an information extraction task, automatically inferring the meanings of unknown words from context. Unlike many previous lexical acquisition systems, Camille was thoroughly tested within a complex, real-world domain. The implementation of this system produced many lessons which are applicable to language learning in general. This paper describes Camille's implications for evaluation, for knowledge representation, and for cognitive modeling."
            },
            "slug": "Implications-of-an-automatic-lexical-acquisition-Hastings",
            "title": {
                "fragments": [],
                "text": "Implications of an automatic lexical acquisition system"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Camille, the Contextual Acquisition Mechanism for Incremental Lexeme LEarning, was implemented as an addition to Lytinen's LINK parser for use in an information extraction task, automatically inferring the meanings of unknown words from context."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599392"
                        ],
                        "name": "I. D. Melamed",
                        "slug": "I.-D.-Melamed",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Melamed",
                            "middleNames": [
                                "Dan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. D. Melamed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 17
                            }
                        ],
                        "text": "One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 15
                            }
                        ],
                        "text": "More recently, Pedersen and Chen (1995) describe a method for acquiring syntactic and semantic features of an unknown word, assuming access to an initial concept hierarchy, but they give no experimental results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2420674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38224f0aa39e4d4b9a0060e0fe3941f9e6d1bee1",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Parallel texts (bitexts) have properties that distinguish them from other kinds of parallel data. First, most words translate to only one other word. Second, bitext correspondence is typically only partialmany words in each text have no clear equivalent in the other text. This article presents methods for biasing statistical translation models to reflect these properties. Evaluation with respect to independent human judgments has confirmed that translation models biased in this fashion are significantly more accurate than a baseline knowledge-free model. This article also shows how a statistical translation model can take advantage of preexisting knowledge that might be available about particular language pairs. Even the simplest kinds of language-specific knowledge, such as the distinction between content words and function words, are shown to reliably boost translation model performance on some tasks. Statistical models that reflect knowledge about the model domain combine the best of both the rationalist and empiricist paradigms."
            },
            "slug": "Models-of-translation-equivalence-among-words-Melamed",
            "title": {
                "fragments": [],
                "text": "Models of translation equivalence among words"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article presents methods for biasing statistical translation models to reflect bitext properties, and shows how a statistical translation model can take advantage of preexisting knowledge that might be available about particular language pairs."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 16
                            }
                        ],
                        "text": "Several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 26
                            }
                        ],
                        "text": "Finally, several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12887739,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "114520c3d046e8e577dd298864a0e5627291a779",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop techniques for learning the meanings of unknown words in context. Working within a compositional semantics framework, we write down equations in which a sentence's meaning is some combination function of the meaning of its words. When one of the words is unknown, we ask for a paraphrase of the sentence. We then compute the meaning of the unknown word by inverting parts of the semantic combination function. This technique can be used to learn word-concept mappings, decomposed meanings, and mappings between syntactic and semantic roles. It works for all parts of speech."
            },
            "slug": "Learning-Word-Meanings-by-Instruction-Knight",
            "title": {
                "fragments": [],
                "text": "Learning Word Meanings by Instruction"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work develops techniques for learning the meanings of unknown words in context by inverting parts of the semantic combination function of the meaning of its words."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 1"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47348275"
                        ],
                        "name": "M. Haruno",
                        "slug": "M.-Haruno",
                        "structuredName": {
                            "firstName": "Masahiko",
                            "lastName": "Haruno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Haruno"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 39
                            }
                        ],
                        "text": "Many systems (Fukumoto & Tsujii, 1995; Haruno, 1995; Johnston, Boguraev, & Pustejovsky, 1995; Webster & Marcus, 1995) focus only on acquisition of verbs or nouns, rather than all types of words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17686875,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "99499680488cbbed656d0f9fa1e4ce7edb484611",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method for learning case frames of Japanese polysemous verbs from a roughly parsed corpus when given a semantic hierarchy for nouns (thesaurus). Japanese verbs usually have several meanings which take different case frames. Each contains different types and numbers of case particles (case marker) which turn select different noun categories. The proposed method employs a bottom-up covering technique to avoid combinatorial explosion of more than ten case particles in Japanese and more than 3000 semantic categories in our thesaurus. First, a sequence of case frame candidates is produced by generalizing training instances using the thesaurus. Then to select the most plausible frame, we introduce a new compression-based utility criteria which can uniformly compare candidates consisting of different structures. Finally, we remove the instances covered by the frame and iterate the procedure until the utility measure becomes less than a predefined threshold. This produces a set of case frames each corresponding to a single verb meaning. The proposed method is experimentally evaluated by typical polysemous verbs taken from one-year newspaper articles."
            },
            "slug": "A-Case-Frame-Learning-Method-for-Japanese-Verbs-Haruno",
            "title": {
                "fragments": [],
                "text": "A Case Frame Learning Method for Japanese Polysemous Verbs"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new method for learning case frames of Japanese polysemous verbs from a roughly parsed corpus when given a semantic hierarchy for nouns (thesaurus) using a new compression-based utility criteria which can uniformly compare candidates consisting of different structures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2257725"
                        ],
                        "name": "M. Webster",
                        "slug": "M.-Webster",
                        "structuredName": {
                            "firstName": "Mort",
                            "lastName": "Webster",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Webster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 94
                            }
                        ],
                        "text": "Many systems (Fukumoto & Tsujii, 1995; Haruno, 1995; Johnston, Boguraev, & Pustejovsky, 1995; Webster & Marcus, 1995) focus only on acquisition of verbs or nouns, rather than all types of words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11377623,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6e986f302a0b0b0fd700c89b94ec54585c5e45a7",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a computational model of verb acquisition which uses what we will call the principle of structured overcommitment to eliminate the need for negative evidence. The learner escapes from the need to be told that certain possibilities cannot occur (i.e., are \"ungrammatical\") by one simple expedient: It assumes that all properties it has observed are either obligatory or forbidden until it sees otherwise, at which point it decides that what it thought was either obligatory or forbidden is merely optional. This model is built upon a classification of verbs based upon a simple three-valued set of features which represents key aspects of a verb's syntactic structure, its predicate/argument structure, and the mapping between them."
            },
            "slug": "Automatic-Acquisition-of-the-Lexical-Semantics-of-Webster-Marcus",
            "title": {
                "fragments": [],
                "text": "Automatic Acquisition of the Lexical Semantics of Verbs from Sentence Frames"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A computational model of verb acquisition which uses the principle of structured overcommitment to eliminate the need for negative evidence and is built upon a classification of verbs based upon a simple three-valued set of features."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48786137"
                        ],
                        "name": "J. Haas",
                        "slug": "J.-Haas",
                        "structuredName": {
                            "firstName": "Juergen",
                            "lastName": "Haas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Haas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752885"
                        ],
                        "name": "B. Jayaraman",
                        "slug": "B.-Jayaraman",
                        "structuredName": {
                            "firstName": "Bharat",
                            "lastName": "Jayaraman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jayaraman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 148
                            }
                        ],
                        "text": "This assumption is similar to the linking rules of Jackendoff (1990), and has been used in previous work on grammar and language acquisition (e.g., Haas and Jayaraman, 1997; Siskind, 19964) While there is some debate in the linguistics community about the ability of compositional techniques to\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14414293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64babfa979109b3a65cc95327e05b5c5acbe2798",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "From-Context-Free-to-Definite-Clause-Grammars:-A-Haas-Jayaraman",
            "title": {
                "fragments": [],
                "text": "From Context-Free to Definite-Clause Grammars: A Type-Theoretic Approach"
            },
            "venue": {
                "fragments": [],
                "text": "J. Log. Program."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737754"
                        ],
                        "name": "J. Siskind",
                        "slug": "J.-Siskind",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Siskind",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Siskind"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 166
                            }
                        ],
                        "text": "We generated several lexicons and associated corpora, varying the ambiguity rate (number of meanings per word) and synonymy rate (number of words per meaning), as in Siskind (1996). Meaning representations were generated using a set of \u201cconceptual symbols\u201d that combined to form the meaning for each word."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 69
                            }
                        ],
                        "text": "In fact, all of these assumptions except for single-use were made by Siskind (1996); see Section 7 for details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "We also describe Jeff Siskind\u2019s lexicon acquisition system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 80
                            }
                        ],
                        "text": "We compared our system to an incremental (on-line) lexicon learner developed by Siskind (1996). To make a more equitable comparison to our batch algorithm, we ran his in a \u201csimulated\u201d batch mode, by repeatedly presenting the corpus 500 times, analogous to running 500 epochs to train a neural network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 103
                            }
                        ],
                        "text": "Though, of course, interpretation functions are not the only way to guarantee a covering lexicon \u2013 see Siskind (1993) for an alternative."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "As already noted, the most closely related work is that of Jeff Siskind, which we described briefly in Section 2 and whose system we ran comparisons to in Section 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 7
                            }
                        ],
                        "text": "2 Jeff Siskind\u2019s Lexicon Learning Research The most closely related previous research into automated lexicon acquisition is that of Siskind (1996), itself inspired by work by Rayner, Hugosson, and Hagert (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Siskind (1996) shows the effectiveness of his approach on a series of artificial corpora."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "We would like to thank Jeff Siskind for providing us with his software, and for all his help in adapting it for use with our corpus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Thanks to Jeff Siskind for the initial corpus generation software, which we enhanced for these tests."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 7
                            }
                        ],
                        "text": "2 Jeff Siskind\u2019s Lexicon Learning Research The most closely related previous research into automated lexicon acquisition is that of Siskind (1996), itself inspired by work by Rayner, Hugosson, and Hagert (1988). As we will be comparing our system to his in Section 5, we describe the main features of his research in this section."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 16
                            }
                        ],
                        "text": "His later work (Siskind, 2000) relaxes this to allow ambiguity and noise, but still biases towards minimizing ambiguity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14120506,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "879000346aea99947212452452a6e3055fccec9b",
            "isKey": true,
            "numCitedBy": 16,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Children face ve central diiculties when learning the vocabulary of their native language: learning from multi-word utterances, bootstrapping from an empty mental lexicon, referential uncertainty, noise, and homonymy. These diiculties are modeled formally via a simpliied lexical acquisition task called the mapping problem. Algorithms for solving this mapping problem are developed, based on the intuitive notions of cross-situational learning and the principle of contrast. Computer simulation demonstrates that these techniques are eeective in solving this mapping problem. This motivates the hypothesis that children use such techniques, inter alia, when learning language."
            },
            "slug": "Learning-Word-to-Meaning-Mappings-Siskind",
            "title": {
                "fragments": [],
                "text": "Learning Word-to-Meaning Mappings"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Computer simulation demonstrates that algorithms for solving the mapping problem are developed, based on the intuitive notions of cross-situational learning and the principle of contrast, which motivates the hypothesis that children use such techniques, inter alia, when learning language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761581"
                        ],
                        "name": "Manny Rayner",
                        "slug": "Manny-Rayner",
                        "structuredName": {
                            "firstName": "Manny",
                            "lastName": "Rayner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manny Rayner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2867599"
                        ],
                        "name": "\u00c5sa Hugosson",
                        "slug": "\u00c5sa-Hugosson",
                        "structuredName": {
                            "firstName": "\u00c5sa",
                            "lastName": "Hugosson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c5sa Hugosson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830156"
                        ],
                        "name": "G\u00f6ran Hagert",
                        "slug": "G\u00f6ran-Hagert",
                        "structuredName": {
                            "firstName": "G\u00f6ran",
                            "lastName": "Hagert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G\u00f6ran Hagert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 132
                            }
                        ],
                        "text": "The most closely related previous research into automated lexicon acquisition is that of Siskind (1996), itself inspired by work by Rayner, Hugosson, and Hagert (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1484391,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "d0c290377ca9520cd34cd1ad11b4b81879f4a14c",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "It is suggested that the concept of \"logic grammar\" as relation between a string and a parse-tree can be extended by admitting the lexicon as part of the relation. This makes it possible to give a simple and elegant formulation of the process of infering a lexicon from example sentences in conjunction with a grammar. Various problems arising from implementation and complexity factors are considered, and examples are shown to support the claim that the method shows potential as a practical tool for automatic lexicon acquisition."
            },
            "slug": "Using-a-Logic-Grammar-to-Learn-a-Lexicon-Rayner-Hugosson",
            "title": {
                "fragments": [],
                "text": "Using a Logic Grammar to Learn a Lexicon"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is suggested that the concept of \"logic grammar\" as relation between a string and a parse-tree can be extended by admitting the lexicon as part of the relation."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069508107"
                        ],
                        "name": "Ren\u00e9 Schneider",
                        "slug": "Ren\u00e9-Schneider",
                        "structuredName": {
                            "firstName": "Ren\u00e9",
                            "lastName": "Schneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ren\u00e9 Schneider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 96
                            }
                        ],
                        "text": "For example, Collins and Singer (1999), Riloff and Jones (1999), Roark and Charniak (1998), and Schneider (1998) define semantic lexicons as a grouping of words into semantic categories, and in the latter case, add relational information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6019603,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ba46d8a1231b04e3360b15b82e4ab371d0802ed9",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is an outline of a statistical learning algorithm for information extraction systems. It is based on a lexically intensive analysis of a small number of texts that belong to one domain and provides a robust lemmatisation of the word forms and the collection of the most important syntagmatic dependencies in weighted regular expressions. The lexical and syntactical knowledge is collected in a very compact knowledge base that enables the analysis of correct and partly incorrect texts or messages, which due to transmission errors, spelling or grammatical mistakes otherwise would have been rejected by conventional systems."
            },
            "slug": "A-Lexically-Intensive-Algorithm-for-Domain-Specific-Schneider",
            "title": {
                "fragments": [],
                "text": "A Lexically-Intensive Algorithm for Domain-Specific Knowlegde Acquisition"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper is an outline of a statistical learning algorithm for information extraction systems based on a lexically intensive analysis of a small number of texts that belong to one domain and provides a robust lemmatisation of the word forms and the collection of the most important syntagmatic dependencies in weighted regular expressions."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49404233"
                        ],
                        "name": "Hang Li",
                        "slug": "Hang-Li",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "Li (1998) further expands on the subcategorization work by inducing clustering information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15332696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e897d8485a01e616f5a2ec44a8554f10d388c55",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 237,
            "paperAbstract": {
                "fragments": [],
                "text": "In this thesis, I address the problem of automatically acquiring lexical semantic knowledge, especially that of case frame patterns, from large corpus data and using the acquired knowledge in structural disambiguation. The approach I adopt has the following characteristics: (1) dividing the problem into three subproblems: case slot generalization, case dependency learning, and word clustering (thesaurus construction). (2) viewing each subproblem as that of statistical estimation and defining probability models for each subproblem, (3) adopting the Minimum Description Length (MDL) principle as learning strategy, (4) employing efficient learning algorithms, and (5) viewing the disambiguation problem as that of statistical prediction. Major contributions of this thesis include: (1) formalization of the lexical knowledge acquisition problem, (2) development of a number of learning methods for lexical knowledge acquisition, and (3) development of a high-performance disambiguation method."
            },
            "slug": "A-Probabilistic-Approach-to-Lexical-Semantic-and-Li",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Approach to Lexical Semantic Knowledge Acquisition and Structural Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This thesis addresses the problem of automatically acquiring lexical semantic knowledge, especially that of case frame patterns, from large corpus data and using the acquired knowledge in structural disambiguation using the Minimum Description Length principle."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092656"
                        ],
                        "name": "Akira Kumano",
                        "slug": "Akira-Kumano",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Kumano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akira Kumano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72740473"
                        ],
                        "name": "H. Hirakawa",
                        "slug": "H.-Hirakawa",
                        "structuredName": {
                            "firstName": "Hideki",
                            "lastName": "Hirakawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hirakawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 137
                            }
                        ],
                        "text": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2499682,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "230ffcb119b64b4d0c9e46d1f603a5dc60e93fa8",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for generating a machine translation (MT) dictionary from parallel texts is described. This method utilizes both statistical information and linguistic information to obtain corresponding words or phrases in parallel texts. By combining these two types of information, translation pairs which cannot be obtained by a linguistic-based method can be extracted. Over 70% accurate translations of compound nouns and over 50% of unknown words are obtained as the first candidate from small Japanese/English parallel texts containing severe distortions."
            },
            "slug": "Building-an-MT-Dictionary-From-Parallel-Texts-Based-Kumano-Hirakawa",
            "title": {
                "fragments": [],
                "text": "Building an MT Dictionary From Parallel Texts Based on Linguistic and Statistical Information"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A method for generating a machine translation (MT) dictionary from parallel texts is described, using both statistical information and linguistic information to obtain corresponding words or phrases in parallel texts."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 2
                            }
                        ],
                        "text": ", (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991)) discuss the acquisition of subcategorization information for verbs, which is different from the information required for mapping to semantic representation, but could be useful as a source of information to further constrain the search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 13
                            }
                        ],
                        "text": "For example, Riloff and Jones (1999) define semantic lexicons as a grouping of words into semantic categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 103
                            }
                        ],
                        "text": "This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 109
                            }
                        ],
                        "text": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-\ntion information for verbs, and others describe work on learning selectional restrictions (Manning, 1993; Brent, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116972934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1c25c6d030605df497ac599deaf6c0693e6c80e",
            "isKey": true,
            "numCitedBy": 524,
            "numCiting": 211,
            "paperAbstract": {
                "fragments": [],
                "text": "Selectional constraints are limitations on the applicability of predicates to arguments. For example, the statement \"The number two is blue\" may be syntactically well formed, but at some level it is anomalous-- scBLUE is not a predicate that can be applied to numbers. \nIn this dissertation, I propose a new, information-theoretic account of selectional constraints. Unlike previous approaches, this proposal requires neither the identification of primitive semantic features nor the formalization of complex inferences based on world knowledge. The proposed model assumes instead that lexical items are organized in a conceptual taxonomy according to class membership, where classes are defined simply as sets--that is, extensionally, rather than in terms of explicit features or properties. Selection is formalized in terms of a probabilistic relationship between predicates and concepts: the selectional behavior of a predicate is modeled as its distributional effect on the conceptual classes of its arguments, expressed using the information-theoretic measure of relative entropy. The use of relative entropy leads to an illuminating interpretation of what selectional constraints are: the strength of a predicate's selection for an argument is identified with the quantity of information it carries about that argument. \nIn addition to arguing that the model is empirically adequate, I explore its application to two problems. The first concerns a linguistic question: why some transitive verbs permit implicit direct objects (\"John ate $\\emptyset$\") and others do not (\"*John brought $\\emptyset$\"). It has often been observed informally that the omission of objects is connected to the ease with which the object can be inferred. I have made this observation more formal by positing a relationship between inferability and selectional constraints, and have confirmed the connection between selectional constraints and implicit objects in a set of computational experiments. \nSecond, I have explored the practical applications of the model in resolving syntactic ambiguity. A number of authors have recently begun investigating the use of corpus-based lexical statistics in automatic parsing; the results of computational experiments using the present model suggest that often lexical relationships are better viewed in terms of underlying conceptual relationships such as selectional preference and concept similarity. Thus the information-theoretic measures proposed here can serve not only as components in a theory of selectional constraints, but also as tools for practical natural language processing."
            },
            "slug": "Selection-and-information:-a-class-based-approach-Resnik",
            "title": {
                "fragments": [],
                "text": "Selection and information: a class-based approach to lexical relationships"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new, information-theoretic account of selectional constraints is proposed, which assumes that lexical items are organized in a conceptual taxonomy according to class membership, where classes are defined simply as sets rather than in terms of explicit features or properties."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15773387"
                        ],
                        "name": "D. Gabbay",
                        "slug": "D.-Gabbay",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Gabbay",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gabbay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785306"
                        ],
                        "name": "M. Sergot",
                        "slug": "M.-Sergot",
                        "structuredName": {
                            "firstName": "Marek",
                            "lastName": "Sergot",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sergot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This assumption is similar to the linking rules of Jackendo (1990), and has been used in previous work on grammar and language acquisition (e.g.,  Haas and Jayaraman, 1997;  Siskind, 19964) While there is"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120242670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1a209fecf3fc6a7baaf82fe58d3adb6470f490b",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Negation-as-inconsistency-.I-Gabbay-Sergot",
            "title": {
                "fragments": [],
                "text": "Negation as inconsistency .I"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8184544"
                        ],
                        "name": "C. D. Marcken",
                        "slug": "C.-D.-Marcken",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Marcken",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Marcken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 16
                            }
                        ],
                        "text": "For example, De Marcken (1994) also uses child language learning as a motivation, but approaches the segmentation problem instead of the learning of semantics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6864856,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "7568bd156b47919b18695d30f362618c2ffa75fe",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm that acquires words (pairings of phonological forms and semantic representations) from larger utterances of unsegmented phoneme sequences and semantic representations. The algorithm maintains from utterance to utterance only a single coherent dictionary, and learns in the presence of homonymy, synonymy, and noise. Test results over a corpus of utterances generated from the Childes database of mother-child interactions are presented."
            },
            "slug": "The-Acquisition-of-a-Lexicon-from-Paired-Phoneme-Marcken",
            "title": {
                "fragments": [],
                "text": "The Acquisition of a Lexicon from Paired Phoneme Sequences and Semantic Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An algorithm that acquires words (pairings of phonological forms and semantic representation) from larger utterances of unsegmented phoneme sequences and semantic representations is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICGI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52424485"
                        ],
                        "name": "Peter Broeder",
                        "slug": "Peter-Broeder",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Broeder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Broeder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939627"
                        ],
                        "name": "J. Murre",
                        "slug": "J.-Murre",
                        "structuredName": {
                            "firstName": "Jaap",
                            "lastName": "Murre",
                            "middleNames": [
                                "M.",
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Murre"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 16
                            }
                        ],
                        "text": "His later work (Siskind, 2000) relaxes this to allow ambiguity and noise, but still biases towards minimizing ambiguity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58135196,
            "fieldsOfStudy": [
                "Biology",
                "Linguistics"
            ],
            "id": "3726c2b380401d84c76c2e0e8796aafcece546b4",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Chapter 1: Introduction PART I: WORDS Chapter 2: Lexicalist Connectionism Chapter 3: Are SRNs Sufficient for Modelling Language Acquisition? Chapter 4: A Distributed, Yet Symbolic Model for Text-to-Speech Processing Chapter 5: \"Lazy Learning\": A Comparison of Natural and Machine Learning of Word Stress PART II: WORD FORMATION Chapter 6: Statistical and Connectionist Modelling of the Development of Speech Segmentation Chapter 7: Learning Word-to-Meaning Mappings Chapter 8: Children's Overregularization and its Implication for Cognition Chapter 9: The Performance of a Recurrent Network with Short Term Memory Capacity Learning the German -S Plural Chapter 19: A Cross-Linguistic Comparison of Single and Dual-Route Models of Inflectional Morphology PART III: WORD ORDER Chapter 11: Formal Models for Learning in the Principles and Parameters Framework Chapter 12: An Output-as-Input Hypothesis for Language Acquisition: Arguments, Model, Evidence"
            },
            "slug": "Models-of-Language-Acquisition:-Inductive-and-Broeder-Murre",
            "title": {
                "fragments": [],
                "text": "Models of Language Acquisition: Inductive and Deductive Approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This book presents an Output-as-Input Hypothesis for Language Acquisition: Arguments, Model, Evidence and a Cross-Linguistic Comparison of Single and Dual-Route Models of Inflectional Morphology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144628595"
                        ],
                        "name": "S. Argamon",
                        "slug": "S.-Argamon",
                        "structuredName": {
                            "firstName": "Shlomo",
                            "lastName": "Argamon",
                            "middleNames": [
                                "Engelson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Argamon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 0
                            }
                        ],
                        "text": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 717,
                                "start": 0
                            }
                        ],
                        "text": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging. In their work, a committee of hidden Markov models is used to select examples for annotation. Lewis and Catlett (1994) use heterogeneous certainty-based methods, in which a simple classifier is used to select examples that are then annotated and presented to a more powerful classifier. However, many language learning tasks require annotating natural language text with a complex output, such as a parse tree, semantic representation, or filled template. The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Soderland (1999), Thompson et al. (1999). Both of these include work on active learning applied to information extraction, and the latter includes work on active learning for semantic parsing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 0
                            }
                        ],
                        "text": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging. In their work, a committee of hidden Markov models is used to select examples for annotation. Lewis and Catlett (1994) use heterogeneous certainty-based methods, in which a simple classifier is used to select examples that are then annotated and presented to a more powerful classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 148
                            }
                        ],
                        "text": "\u2026learning to natural language processing have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of these have addressed classification tasks such\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10854509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08587b10ff2fa88261a61459a3b80d7aa132a641",
            "isKey": true,
            "numCitedBy": 171,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "In many real-world learning tasks it is expensive to acquire a sufficient number of labeled examples for training. This paper investigates methods for reducing annotation cost by sample selection. In this approach, during training the learning program examines many unlabeled examples and selects for labeling only those that are most informative at each stage. This avoids redundantly labeling examples that contribute little new information. \n \nOur work follows on previous research on Query By Committee, and extends the committee-based paradigm to the context of probabilistic classification. We describe a family of empirical methods for committee-based sample selection in probabilistic classification models, which evaluate the informativeness of an example by measuring the degree of disagreement between several model variants. These variants (the committee) are drawn randomly from a probability distribution conditioned by the training set labeled so far. \n \nThe method was applied to the real-world natural language processing task of stochastic part-of-speech tagging. We find that all variants of the method achieve a significant reduction in annotation cost, although their computational efficiency differs. In particular, the simplest variant, a two member committee with no parameters to tune, gives excellent results. We also show that sample selection yields a significant reduction in the size of the model used by the tagger."
            },
            "slug": "Committee-Based-Sample-Selection-for-Probabilistic-Argamon-Dagan",
            "title": {
                "fragments": [],
                "text": "Committee-Based Sample Selection for Probabilistic Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A family of empirical methods for committee-based sample selection in probabilistic classification models, which evaluate the informativeness of an example by measuring the degree of disagreement between several model variants, are described."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416786"
                        ],
                        "name": "Mats Rooth",
                        "slug": "Mats-Rooth",
                        "structuredName": {
                            "firstName": "Mats",
                            "lastName": "Rooth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mats Rooth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2694275"
                        ],
                        "name": "D. Prescher",
                        "slug": "D.-Prescher",
                        "structuredName": {
                            "firstName": "Detlef",
                            "lastName": "Prescher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Prescher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3264213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d0c052eabed016faeb1fba49dcd8ef6c551a79c",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for automatic induction of slot annotations for subcategorization frames, based on induction of hidden classes in the EM framework of statistical estimation. The models are empirically evaluated by a general decision test. Induction of slot labeling for subcategorization frames is accomplished by a further application of EM, and applied experimentally on frame observations derived from parsing large corpora. We outline an interpretation of the learned representations as theoretical-linguistic decompositional lexical entries."
            },
            "slug": "Inducing-a-Semantically-Annotated-Lexicon-via-Rooth-Riezler",
            "title": {
                "fragments": [],
                "text": "Inducing a Semantically Annotated Lexicon via EM-Based Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A technique for automatic induction of slot annotations for subcategorization frames, based on induction of hidden classes in the EM framework of statistical estimation, and an interpretation of the learned representations as theoretical-linguistic decompositional lexical entries are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2255318"
                        ],
                        "name": "R. Liere",
                        "slug": "R.-Liere",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Liere",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Liere"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729906"
                        ],
                        "name": "Prasad Tadepalli",
                        "slug": "Prasad-Tadepalli",
                        "structuredName": {
                            "firstName": "Prasad",
                            "lastName": "Tadepalli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasad Tadepalli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 140
                            }
                        ],
                        "text": "\u2026have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of these have addressed classification tasks such as part of speech tagging and\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 13
                            }
                        ],
                        "text": "For example, Liere and Tadepalli (1997) apply active learning with committees to the problem of text categorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 144
                            }
                        ],
                        "text": "This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Manning (1993) and Brent (1991) describe work on learning selectional restrictions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 198
                            }
                        ],
                        "text": "Existing work in the area has emphasized two approaches, certainty-based methods (Lewis & Catlett, 1994), and committee-based methods (McCallum & Nigam, 1998; Freund, Seung, Shamir, & Tishby, 1997; Liere & Tadepalli, 1997; Dagan & Engelson, 1995; Cohn et al., 1994); we focus here on the former."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7530337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80ef14d2a1b8c7efbf45bedae9d001fe5446c7de",
            "isKey": true,
            "numCitedBy": 183,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In many real-world domains, supervised learning requires a large number of training examples. In this paper, we describe an active learning method that uses a committee of learners to reduce the number of training examples required for learning. Our approach is similar to the Query by Committee framework, where disagreement among the committee members on the predicted label for the input part of the example is used to signal the need for knowing the actual value of the label. Our experiments are conducted in the text categorization domain, which is characterized by a large number of features, many of which are irrelevant. We report here on experiments using a committee of Winnowbased learners and demonstrate that this approach can reduce the number of labeled training examples required over that used by a single Winnow learner by l-2 orders of magnitude. 1. Hntroduction"
            },
            "slug": "Active-Learning-with-Committees-for-Text-Liere-Tadepalli",
            "title": {
                "fragments": [],
                "text": "Active Learning with Committees for Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper reports on experiments using a committee of Winnowbased learners and demonstrates that this approach can reduce the number of labeled training examples required over that used by a single Winnow learner by l-2 orders of magnitude."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1946987"
                        ],
                        "name": "Eliana Colunga",
                        "slug": "Eliana-Colunga",
                        "structuredName": {
                            "firstName": "Eliana",
                            "lastName": "Colunga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eliana Colunga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2740806"
                        ],
                        "name": "M. Gasser",
                        "slug": "M.-Gasser",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Gasser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gasser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 120
                            }
                        ],
                        "text": "For example, Nenov and Dyer (1994) describe a neural network model to map between visual and verbal-motor commands, and Colunga and Gasser (1998) use neural network modeling techniques for learning spatial concepts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13959076,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "a672d02a16daa077ebe4535900596b9740593ed0",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Language plays a pervasive role in our day-to-day experience and is likely to have an effect on other non-linguistic aspects of life. At the same time, language is itself constrained by the world. In this paper we study this interaction using Playpen, a connectionist model of the acquisition of word meaning. We argue that the interaction between linguistic and non-linguistic categories depends on the pattern of correlations in the world and on their relation to the correlations defined by words. We then discuss three kinds of possible interactions and present simulations of each using Playpen, a neural-network model of the acquisition of word meaning."
            },
            "slug": "Linguistic-Relativity-and-Word-Acquisition:-A-Colunga-Gasser",
            "title": {
                "fragments": [],
                "text": "Linguistic Relativity and Word Acquisition: A Computational Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is argued that the interaction between linguistic and non-linguistic categories depends on the pattern of correlations in the world and on their relation to the correlations defined by words."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 2
                            }
                        ],
                        "text": ", (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991)) discuss the acquisition of subcategorization information for verbs, which is different from the information required for mapping to semantic representation, but could be useful as a source of information to further constrain the search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 94
                            }
                        ],
                        "text": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-\ntion information for verbs, and others describe work on learning selectional restrictions (Manning, 1993; Brent, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 144
                            }
                        ],
                        "text": "This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2729729,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d6775b3b8a3775821a01d2a54ddc471dac6e570",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method for producing a dictionary of subcategorization frames from unlabelled text corpora. It is shown that statistical filtering of the results of a finite state parser running on the output of a stochastic tagger produces high quality results, despite the error rates of the tagger and the parser. Further, it is argued that this method can be used to learn all subcategorization frames, whereas previous methods are not extensible to a general solution to the problem."
            },
            "slug": "Automatic-Acquisition-of-a-Large-Sub-Categorization-Manning",
            "title": {
                "fragments": [],
                "text": "Automatic Acquisition of a Large Sub Categorization Dictionary From Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that statistical filtering of the results of a finite state parser running on the output of a stochastic tagger produces high quality results, despite the error rates of the tagger and the parser."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 13
                            }
                        ],
                        "text": "For example, Collins and Singer (1999), Riloff and Jones (1999), Roark and Charniak (1998), and Schneider (1998) define semantic lexicons as a grouping of words into semantic categories, and in the latter case, add relational information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 859162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c0ece611643cfb8f3a23e4802c754ea583ebe37",
            "isKey": false,
            "numCitedBy": 1013,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the use of unlabeled examples for the problem of named entity classification. A large number of rules is needed for coverage of the domain, suggesting that a fairly large number of labeled examples should be required to train a classifier. However, we show that the use of unlabeled data can reduce the requirements for supervision to just 7 simple \"seed\" rules. The approach gains leverage from natural redundancy in the data: for many named-entity instances both the spelling of the name and the context inwhich it appears are sufficient to determine its type. We present two algorithms. The first method uses a similar algorithm to that of (Yarowsky 95), with modifications motivated by (Blum and Mitchell 98). The second algorithm extends ideas from boosting algorithms, designed for supervised learning tasks, to the framework suggested by (Blum and Mitchell 98)."
            },
            "slug": "Unsupervised-Models-for-Named-Entity-Classification-Collins-Singer",
            "title": {
                "fragments": [],
                "text": "Unsupervised Models for Named Entity Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that the use of unlabeled data can reduce the requirements for supervision to just 7 simple \"seed\" rules, gaining leverage from natural redundancy in the data."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 135
                            }
                        ],
                        "text": "The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001), Soderland (1999), Thompson et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8359747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22fb3b3b2bdf768dd435eedfc5ef5155d3e56b1a",
            "isKey": false,
            "numCitedBy": 1071,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "A wealth of on-line text information can be made available to automatic processing by information extraction (IE) systems. Each IE application needs a separate set of rules tuned to the domain and writing style. WHISK helps to overcome this knowledge-engineering bottleneck by learning text extraction rules automatically.WHISK is designed to handle text styles ranging from highly structured to free text, including text that is neither rigidly formatted nor composed of grammatical sentences. Such semi-structured text has largely been beyond the scope of previous systems. When used in conjunction with a syntactic analyzer and semantic tagging, WHISK can also handle extraction from free text such as news stories."
            },
            "slug": "Learning-Information-Extraction-Rules-for-and-Free-Soderland",
            "title": {
                "fragments": [],
                "text": "Learning Information Extraction Rules for Semi-Structured and Free Text"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "WHISK is designed to handle text styles ranging from highly structured to free text, including text that is neither rigidly formatted nor composed of grammatical sentences, and can also handle extraction from free text such as news stories."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144494993"
                        ],
                        "name": "R. Jones",
                        "slug": "R.-Jones",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 40
                            }
                        ],
                        "text": "For example, Collins and Singer (1999), Riloff and Jones (1999), Roark and Charniak (1998), and Schneider (1998) define semantic lexicons as a grouping of words into semantic categories, and in the latter case, add relational information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 57
                            }
                        ],
                        "text": "Although many others (Se\u0301billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 87
                            }
                        ],
                        "text": "1 Lexicon Acquisition Work on automated lexicon and language acquisition dates back to Siklossy (1972), who demonstrated a system that learned transformation patterns from logic back to natural language."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 103
                            }
                        ],
                        "text": "This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1053009,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41e936981f5a2d55bfec0143e9a15e23ad96436b",
            "isKey": true,
            "numCitedBy": 890,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction systems usually require two dictionaries: a semantic lexicon and a dictionary of extraction patterns for the domain. We present a multilevel bootstrapping algorithm that generates both the semantic lexicon and extraction patterns simultaneously. As input, our technique requires only unannotated training texts and a handful of seed words for a category. We use a mutual bootstrapping technique to alternately select the best extraction pattern for the category and bootstrap its extractions into the semantic lexicon, which is the basis for selecting the next extraction pattern. To make this approach more robust, we add a second level of bootstrapping (metabootstrapping) that retains only the most reliable lexicon entries produced by mutual bootstrapping and then restarts the process. We evaluated this multilevel bootstrapping technique on a collection of corporate web pages and a corpus of terrorism news articles. The algorithm produced high-quality dictionaries for several semantic categories."
            },
            "slug": "Learning-Dictionaries-for-Information-Extraction-by-Riloff-Jones",
            "title": {
                "fragments": [],
                "text": "Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A multilevel bootstrapping algorithm is presented that generates both the semantic lexicon and extraction patterns simultaneously simultaneously and produces high-quality dictionaries for several semantic categories."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731375"
                        ],
                        "name": "M. Brent",
                        "slug": "M.-Brent",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brent",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3086368"
                        ],
                        "name": "R. Berwick",
                        "slug": "R.-Berwick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Berwick",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Berwick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "t show the usefulness of the learned lexicons for a speci\ufb01c application. Several authors (Rooth, Riezler, Prescher, Carroll, &amp; Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza35 Thompson &amp; Mooney tion information for verbs, and others describe work on learning selectional restrictions (Manning, 1993; Brent, 1991). Both of these "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "interfaces from a single training set of annotated sentences. Although many others (S\u00b4ebillot, Bouillon, &amp; Fabre, 2000; Rilo\ufb00 &amp; Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information aboutlexical semantics, we present here a system for learning lexicons of phrasemeaning pairs. Further, our work is unique in its combination of severa"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "s grows. 3.2 Implications of the De\ufb01nition This de\ufb01nition of the lexicon acquisition problem di\ufb00ers from that given by other authors, including Rilo\ufb00 and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7. Our de\ufb01nition of the problem makes some assumptions about the training input. First, by making f a function instead of a relation, the de\ufb01nition assumes"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6782079,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "b18ac643377521bbd7e56521ef169ccafcd1b774",
            "isKey": true,
            "numCitedBy": 111,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an implemented program that takes a tagged text corpus and generates a partial list of the subcategorization frames in which each verb occurs. The completeness of the output list increases monotonically with the total occurrences of each verb in the training corpus. False positive rates are one to three percent. Five subcategorization frames are currently detected and we foresee no impediment to detecting many more. Ultimately, we expect to provide a large subcategorization dictionary to the NLP community and to train dictionaries for specific corpora."
            },
            "slug": "Automatic-Acquisition-of-Subcategorization-Frames-Brent-Berwick",
            "title": {
                "fragments": [],
                "text": "Automatic Acquisition of Subcategorization Frames from Tagged Text"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An implemented program that takes a tagged text corpus and generates a partial list of the subcategorization frames in which each verb occurs and expects to provide a large subc categorization dictionary to the NLP community and to train dictionaries for specific corpora."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 198
                            }
                        ],
                        "text": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 201085,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "5051e54af8c0d6b84f8459c57d55bd19be9f0cee",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers in both machine translation (e.g., Brown et a/, 1990) arm bilingual lexicography (e.g., Klavans and Tzoukermarm, 1990) have recently become interested in studying parallel texts (also known as bilingual corpora), bodies of text such as the Canadian Hansards (parliamentary debates) which are available in multiple languages (such as French and English). Much of the current excitement surrounding parallel texts was initiated by Brown et aL (1990), who outline a selforganizing method for using these parallel texts to build a machine translation system."
            },
            "slug": "Identifying-Word-Correspondences-in-Parallel-Texts-Gale-Church",
            "title": {
                "fragments": [],
                "text": "Identifying Word Correspondences in Parallel Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "Researchers in both machine translation and bilingual lexicography have recently become interested in studying parallel texts, bodies of text such as the Canadian Hansards which are available in multiple languages (such as French and English)."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029852"
                        ],
                        "name": "Fumiyo Fukumoto",
                        "slug": "Fumiyo-Fukumoto",
                        "structuredName": {
                            "firstName": "Fumiyo",
                            "lastName": "Fukumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fumiyo Fukumoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 14
                            }
                        ],
                        "text": "Many systems (Fukumoto & Tsujii, 1995; Haruno, 1995; Johnston, Boguraev, & Pustejovsky, 1995; Webster & Marcus, 1995) focus only on acquisition of verbs or nouns, rather than all types of words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18995160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d38150ff6ff618d428f4968a531c0cfae373fa7",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we focused on an appropriate definition of polysemy in temas of distributional behaviour of words in monolingual texts and proposed a dustering method which recosnkes verbal polysemies from a textual corpus. The chara~eristic of ou~ clust~ 8 algoritkm is that it explicitly introduces new entities, i.e. hFpothetical t~\u2019bs when an entity is judged poly~mous and mmociates them with contexts which are subcente~t~ of the context of the original entity. We report the results of two experiments. The first is concerned with verifying the ~ect of our algorithm which explidtly introduces a hypothetical ,3erb. The second one is based on the assumption of possible causes of failures mentioned in the firs t experiment sad is conducted to see how various parameters alfect the clustering results. The results of experiments demonstrate the ei~ectiveness of our proposed method."
            },
            "slug": "Representation-and-Acquisition-of-Verbal-Polysemy-Fukumoto",
            "title": {
                "fragments": [],
                "text": "Representation and Acquisition of Verbal Polysemy"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper focused on an appropriate definition of polysemy in temas of distributional behaviour of words in monolingual texts and proposed a dustering method which recosnkes verbal polysemies from a textual corpus."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 198
                            }
                        ],
                        "text": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61449354,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "df563691b20b727fe346fc00f6b2afc25d97fb8d",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers in both machine translation (e.g., Brown et al, 1990) and bilingual lexicography (e.g., Klavans and Tzoukermann, 1990) have recently become interested in studying parallel texts (also known as bilingual corpora), bodies of text such as the Canadian Hansards (parliamentary debates) which are available in multiple languages (such as French and English). Much of the current excitement surrounding parallel texts was initiated by Brown et al. (1990), who outline a self-organizing method for using these parallel texts to build a machine translation system."
            },
            "slug": "Identifying-word-correspondence-in-parallel-texts-Gale-Church",
            "title": {
                "fragments": [],
                "text": "Identifying word correspondence in parallel texts"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Researchers in both machine translation and bilingual lexicography have recently become interested in studying parallel texts, bodies of text which are available in multiple languages and who outline a self-organizing method for using these parallel texts to build a machine translation system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144628595"
                        ],
                        "name": "S. Argamon",
                        "slug": "S.-Argamon",
                        "structuredName": {
                            "firstName": "Shlomo",
                            "lastName": "Argamon",
                            "middleNames": [
                                "Engelson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Argamon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 223
                            }
                        ],
                        "text": "Existing work in the area has emphasized two approaches, certainty-based methods (Lewis & Catlett, 1994), and committee-based methods (McCallum & Nigam, 1998; Freund, Seung, Shamir, & Tishby, 1997; Liere & Tadepalli, 1997; Dagan & Engelson, 1995; Cohn et al., 1994); we focus here on the former."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17288818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f78d6f79b3ef103cb2d8d170632eb74d9496412",
            "isKey": false,
            "numCitedBy": 501,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Committee-Based-Sampling-For-Training-Probabilistic-Dagan-Argamon",
            "title": {
                "fragments": [],
                "text": "Committee-Based Sampling For Training Probabilistic Classifiers"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114553"
                        ],
                        "name": "V. Nenov",
                        "slug": "V.-Nenov",
                        "structuredName": {
                            "firstName": "Valeriy",
                            "lastName": "Nenov",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Nenov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2806570"
                        ],
                        "name": "M. Dyer",
                        "slug": "M.-Dyer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Dyer",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dyer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For example,  Nenov and Dyer (1994)  describe a neural network model to map between visual and verbal-motor commands, and Colunga and Gasser (1998) use neural network modeling techniques for learning spatial concepts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 13
                            }
                        ],
                        "text": "For example, Nenov and Dyer (1994) describe a neural network model to map between visual and verbal-motor commands, and Colunga and Gasser (1998) use neural network modeling techniques for learning spatial concepts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34352613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37b1bde13fa81a1b3c423eb76be2ef949895ebda",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In Part 1 of this two-part series, we introduced Katamic memory\u2014a neural network architecture capable of robust sequence learning and recognition. In Part 2, we introduce the Blobs World taskjdomain for language learning and describe the DETE language learning system, which is composed of over 50 Katamic memory modules. DETE currently learns small subsets of English and Spanish via association with perceptual! motor inputs. In addition to Kaiamic memory, DETE employs several other novel features: (1) use of feature planes, to encode visual shapes, spatial relationships and the motions of objects, (2) phase-locking of neural firing, in order to represent focus of atention and to bind objects across multiple feature planes, and (3) a method for encoding temporal relationships, so that DETE can learn utterances involving the immediate past and future. We compare DETE to related models and discuss the implications of this approach for language-learning research."
            },
            "slug": "Perceptually-Grounded-Language-Learning:-Part-2-A-Nenov-Dyer",
            "title": {
                "fragments": [],
                "text": "Perceptually Grounded Language Learning: Part 2 - DETE: A Neural/Procedural Model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The DETE language learning system is described, which is composed of over 50 Katamic memory modules and employs several other novel features, including use of feature planes, to encode visual shapes, spatial relationships and the motions of objects."
            },
            "venue": {
                "fragments": [],
                "text": "Connect. Sci."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2853381"
                        ],
                        "name": "Francesc Ribas Framis",
                        "slug": "Francesc-Ribas-Framis",
                        "structuredName": {
                            "firstName": "Francesc",
                            "lastName": "Framis",
                            "middleNames": [
                                "Ribas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesc Ribas Framis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 2
                            }
                        ],
                        "text": ", (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991)) discuss the acquisition of subcategorization information for verbs, which is different from the information required for mapping to semantic representation, but could be useful as a source of information to further constrain the search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 81
                            }
                        ],
                        "text": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-\ntion information for verbs, and others describe work on learning selectional restrictions (Manning, 1993; Brent, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8323644,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f0ab8eb169dafb221f60e98413262fa306dcbb6",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a methodology to extract Selectional Restrictions at a variable level of abstraction from phrasally analyzed corpora. The method relays in the use of a wide-coverage noun taxonomy and a statistical measure of the co-occurrence of linguistic items. Some experimental results about the performance of the method are provided."
            },
            "slug": "An-Experiment-on-Learning-Appropriate-Selectional-a-Framis",
            "title": {
                "fragments": [],
                "text": "An Experiment on Learning Appropriate Selectional Restrictions From a Parsed Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The method relays in the use of a wide-coverage noun taxonomy and a statistical measure of the co-occurrence of linguistic items to extract Selectional Restrictions at a variable level of abstraction from phrasally analyzed corpora."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71486292"
                        ],
                        "name": "M. Tomita",
                        "slug": "M.-Tomita",
                        "structuredName": {
                            "firstName": "Masaru",
                            "lastName": "Tomita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tomita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60902655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f60a9c6f58eef2749b71f288b819410fc787f5d",
            "isKey": false,
            "numCitedBy": 472,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction.- 2. Informal Description of the Algorithm.- 3. Examples.- 4. Formal Specification of the Algorithm.- 5. Comparison with Other Algorithms.- 6. Empirical Results.- 7. Left-to-Right on-Line Parsing.- 8. Sentence Disambiguation by Asking.- 9. Interactive/Personal Machine Translation.- 10. Concluding Remarks.- Appendix A. The Parsing Table Constructor.- Appendix B. Earley's Algorithm.- Appendix C. Proof of Correctness of the Algorithm.- C.1. Introduction.- C.2. Soundness of the Algorithm.- C.3. Completeness of the Algorithm.- Appendix D. Raw Empirical Data.- Appendix E. Programs Used in the Experiments.- E.1. Tomita's Algorithm.- E.2. Earley's Algorithm.- E.3. Earley's Algorithm with an Improvement.- E.4. LR(0) Table Construction Algorithm.- E.5. Utility Functions.- Appendix F. Grammars Used in the Experiments.- Appendix G. Sentences Used in the Experiments.- Appendix H. Nishida and Doshita's System.- References.- Author Index."
            },
            "slug": "Efficient-Parsing-for-Natural-Language:-A-Fast-for-Tomita",
            "title": {
                "fragments": [],
                "text": "Efficient Parsing for Natural Language: A Fast Algorithm for Practical Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A Parsing Table Constructor for Nishida and Doshita's System, with examples of left-to-Right on-Line Parsing and Interactive/Personal Machine Translation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48682462"
                        ],
                        "name": "R. Bonato",
                        "slug": "R.-Bonato",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Bonato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bonato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1834390"
                        ],
                        "name": "C. Retor\u00e9",
                        "slug": "C.-Retor\u00e9",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Retor\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Retor\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 136
                            }
                        ],
                        "text": "2 Implications of the Definition This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 161
                            }
                        ],
                        "text": "Another related body of work is grammar acquisition, especially those areas that tightly integrate the grammar with a lexicon, such as with Categorial Grammars (Retore & Bonato, 2001; Dudau-Sofronie, Tellier, & Tommasi, 2001; Watkinson & Manandhar, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16734764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1569829d03b3ef0c9d219cf2d337d327c72995f3",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an extension of Buszkowski\u2019s learning algorithm for categorial grammars to rigid Lambek grammars and then for minimalist categorial grammars. The Kanazawa proof of the convergence in the Gold sense is simplified and extended to these new algorithms. We thus show that this technique based on principal type algorithm and type unification is quite general and applies to learning issues for different type logical grammars, which are larger, linguistically more accurate and closer to semantics."
            },
            "slug": "Learning-Rigid-Lambek-Grammars-and-Minimalist-from-Bonato-Retor\u00e9",
            "title": {
                "fragments": [],
                "text": "Learning Rigid Lambek Grammars and Minimalist Grammars from Structured Sentences ?"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that this technique based on principal type algorithm and type unification is quite general and applies to learning issues for different type logical grammars, which are larger, linguistically more accurate and closer to semantics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2001885"
                        ],
                        "name": "Ted Pedersen",
                        "slug": "Ted-Pedersen",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Pedersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2029532280"
                        ],
                        "name": "Weidong Chen",
                        "slug": "Weidong-Chen",
                        "structuredName": {
                            "firstName": "Weidong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weidong Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Pedersen and Chen (1995) describe a method for acquiring syntactic and semantic features of an unknown word, assuming access to an initial concept hierarchy, but they give no experimental results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1357,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "55eed987173d79a2d70fe296175001d7ee3ab69f",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method to automatically acquire the syntactic and semantic classifications of unknown words. Our method reduces the search space of the lexical acquisition problem by utilizing both the left and the right context of the unknown word. Link Grammar provides a convenient framework in which to implement our method."
            },
            "slug": "Lexical-Acquisition-via-Constraint-Solving-Pedersen-Chen",
            "title": {
                "fragments": [],
                "text": "Lexical Acquisition via Constraint Solving"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper describes a method to automatically acquire the syntactic and semantic classifications of unknown words by utilizing both the left and the right context of the unknown word."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024985"
                        ],
                        "name": "P. Suppes",
                        "slug": "P.-Suppes",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Suppes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Suppes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155275265"
                        ],
                        "name": "L. Liang",
                        "slug": "L.-Liang",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30067824"
                        ],
                        "name": "M. B\u00f6ttner",
                        "slug": "M.-B\u00f6ttner",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "B\u00f6ttner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. B\u00f6ttner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001),  Soderland (1999) , Thompson et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17132879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fc61b5fdb0eca9af2f573b06495b39d5e41d323",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In Sections 1, 2 and 3, the theoretical framework we have been developing for a probabilistic theory of machine learning of natural language is outlined. In Section 4, some simple examples showing how mean learning curves can be constructed from the theory are given. But we also show that the explicit computation of the mean learning curve for an arbitrary number of sentences is unfeasible. This result holds even when the learning itself is quite rapid. In Section 5 we briefly describe the kinds of comprehension grammars generated by our theory from a given finite sample of sentences."
            },
            "slug": "Complexity-Issues-in-Robotic-Machine-Learning-of-Suppes-Liang",
            "title": {
                "fragments": [],
                "text": "Complexity Issues in Robotic Machine Learning of Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The theoretical framework for a probabilistic theory of machine learning of natural language is outlined and it is shown that the explicit computation of the mean learning curve for an arbitrary number of sentences is unfeasible."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067160148"
                        ],
                        "name": "T. Regier",
                        "slug": "T.-Regier",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Regier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Regier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 39
                            }
                        ],
                        "text": "Another Berkeley effort, the system by Regier (1996) is given examples of pictures paired with natural language descriptions that apply to the picture, and learns to judge whether a new sentence is true of a given picture."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Another Berkeley eort, the system by  Regier (1996)  is given examples of pictures paired with natural language descriptions that apply to the picture, and learns to judge whether a new sentence is true of a given picture."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16802536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16801777230a7970f1d4afe675e86e46a07264bb",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 Introduction: matter and method space and semantic potential negative evidence and language learning the modelling challenge constrained connectionism a brief exchange an overview of the book. Part 2 The linguistic categorization of space: perception and the human semantic potential the primacy of space crosslinguistic variation cognitive linguistics summary. Part 3 Connectionism and cognitive models: overview parallel distributed processing structured connectionism constrained connectionism learning sequences using back-propagation another brief exchange. Part 4 Learning without explicit negative evidence: the problem a solution - mutual exclusivity difficulties with mutual exclusivity salvaging mutual exclusivity implementation results. Part 5 Structures: structures and constrained connectionism orientation combination map comparison motion - source, path and destination. Part 6 A model of spatial semantics: overview the problem the model a run through the model results prototype effects discussion. Part 7 Extensions: polysemy deixis prelinguistic conceptual development key events distance convex hulls implicit paths. Part 8 Discussion: inquiry into linguistic universals falsifiability the nature of the model what have we learned about models? a final word."
            },
            "slug": "The-Human-Semantic-Potential:-Spatial-Language-and-Regier",
            "title": {
                "fragments": [],
                "text": "The Human Semantic Potential: Spatial Language and Constrained Connectionism"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Part 1 Introduction: matter and method space and semantic potential negative evidence and language learning the modelling challenge constrained connectionism a brief exchange an overview of the book."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 2
                            }
                        ],
                        "text": ", (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991)) discuss the acquisition of subcategorization information for verbs, which is different from the information required for mapping to semantic representation, but could be useful as a source of information to further constrain the search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 87
                            }
                        ],
                        "text": "Another example of pursuing language learning from a cognitive perspective is found in Colunga and Gasser (1998), who use neural network modeling techniques for learning spatial concepts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 66
                            }
                        ],
                        "text": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-\ntion information for verbs, and others describe work on learning selectional restrictions (Manning, 1993; Brent, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 87
                            }
                        ],
                        "text": "Another example of pursuing language learning from a cognitive perspective is found in Colunga and Gasser (1998), who use neural network modeling techniques for learning spatial concepts. Another related goal is pursued by De Marcken (1994), who uses a flat list of tokens for semantic representations, but does not segment sentences into words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ffa423a5283396c88ff3d4033d541796bd039cc",
            "isKey": true,
            "numCitedBy": 873,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we first propose a new statistical parsing model, which is a generative model of lexicalised context-free grammar. We then extend the model to include a probabilistic treatment of both subcategorisation and wh-movement. Results on Wall Street Journal text show that the parser performs at 88.1/87.5% constituent precision/recall, an average improvement of 2.3% over (Collins 96)."
            },
            "slug": "Three-Generative,-Lexicalised-Models-for-Parsing-Collins",
            "title": {
                "fragments": [],
                "text": "Three Generative, Lexicalised Models for Statistical Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A new statistical parsing model is proposed, which is a generative model of lexicalised context-free grammar and extended to include a probabilistic treatment of both subcategorisation and wh-movement."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 135
                            }
                        ],
                        "text": "Existing work in the area has emphasized two approaches, certainty-based methods (Lewis & Catlett, 1994), and committee-based methods (McCallum & Nigam, 1998; Freund, Seung, Shamir, & Tishby, 1997; Liere & Tadepalli, 1997; Dagan & Engelson, 1995; Cohn et al., 1994); we focus here on the former."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14278367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b3b54848c1bc6ffea2625ce79302abed8e8deb9",
            "isKey": false,
            "numCitedBy": 836,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how a text classifier\u2019s need for labeled training documents can be reduced by taking advantage of a large pool of unlabeled documents. We modify the Query-by-Committee (QBC) method of active learning to use the unlabeled pool for explicitly estimating document density when selecting examples for labeling. Then active learning is combined with ExpectationMaximization in order to \u201cfill in\u201d the class labels of those documents that remain unlabeled. Experimental results show that the improvements to active learning require less than two-thirds as many labeled training examples as previous QBC approaches, and that the combination of EM and active learning requires only slightly more than half as many labeled training examples to achieve the same accuracy as either the improved active learning or EM alone."
            },
            "slug": "Employing-EM-and-Pool-Based-Active-Learning-for-McCallum-Nigam",
            "title": {
                "fragments": [],
                "text": "Employing EM and Pool-Based Active Learning for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This paper shows how a text classifier\u2019s need for labeled training documents can be reduced by taking advantage of a large pool of unlabeled documents by modifying the Query-by-Committee method of active learning to use it for explicitly estimating document density when selecting examples for labeling."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71486292"
                        ],
                        "name": "M. Tomita",
                        "slug": "M.-Tomita",
                        "structuredName": {
                            "firstName": "Masaru",
                            "lastName": "Tomita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tomita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 128
                            }
                        ],
                        "text": "Chill uses inductive logic programming (Muggleton, 1992; Lavrac\u0306 & Dz\u0306eroski, 1994) to learn a deterministic shift-reduce parser (Tomita, 1986) written in Prolog."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62691315,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "321aeab25a35a813f8c8bb5f0b86470a2d769a5d",
            "isKey": false,
            "numCitedBy": 384,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Any books that you read, no matter how you got the sentences that have been read from the books, surely they will give you goodness. But, we will show you one of recommendation of the book that you need to read. This efficient parsing for natural language is what we surely mean. We will show you the reasonable reasons why you need to read this book. This book is a kind of precious book written by an experienced author."
            },
            "slug": "Efficient-parsing-for-natural-language-Tomita",
            "title": {
                "fragments": [],
                "text": "Efficient parsing for natural language"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "One of recommendation of the book that you need to read is shown, which is a kind of precious book written by an experienced author and it will show the reasonable reasons why you should read this book."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145147566"
                        ],
                        "name": "S. Muggleton",
                        "slug": "S.-Muggleton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Muggleton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muggleton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117343701"
                        ],
                        "name": "C. Feng",
                        "slug": "C.-Feng",
                        "structuredName": {
                            "firstName": "Cao",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Feng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 168
                            }
                        ],
                        "text": "While in this example we show the LICS for all pairs that a phrase appears in, in the actual algorithm we randomly sample a subset for efficiency reasons, as in Golem (Muggleton & Feng, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14992676,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a669636e0ada62a0fb444e95435e24fdbdf4dbd",
            "isKey": false,
            "numCitedBy": 848,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently there has been increasing interest in systems which induce rst order logic programs from examples. However, many diiculties need to be overcome. Well-known algorithms fail to discover correct logical descriptions for large classes of interesting predicates , due either to the intractability of search or overly strong limitations applied to the hypothesis space. In contrast, search is avoided within Plotkin's framework of relative least general generalisation (rlgg). It is replaced by the process of constructing a unique clause which covers a set of examples relative to given background knowledge. However, such a clause can in the worst case contain innnitely many literals, or at best grow exponentially with the number of examples involved. In this paper we introduce the concept of h-easy rlgg clauses and show that they have nite length. We also prove that the length of a certain class of \\determinate\" rlgg is bounded by a polynomial function of certain features of the background knowledge. This function is independent of the number of examples used to construct them. An existing implementation called GOLEM is shown to be capable of inducing many interesting logic programs which have not been demonstrated to be learnable using other algorithms."
            },
            "slug": "Efficient-Induction-of-Logic-Programs-Muggleton-Feng",
            "title": {
                "fragments": [],
                "text": "Efficient Induction of Logic Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The concept of h-easy rlgg clauses is introduced and it is proved that the length of a certain class of \\determinate\" r lgg is bounded by a polynomial function of certain features of the background knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "ALT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058177533"
                        ],
                        "name": "Simon Tong",
                        "slug": "Simon-Tong",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 150
                            }
                        ],
                        "text": "Only a few of the researchers applying machine learning to natural language processing have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7806109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8797f1d253c75669d96e6fcceda2be3f8534e1d",
            "isKey": false,
            "numCitedBy": 3138,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines have met with significant success in numerous real-world learning tasks. However, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. In many settings, we also have the option of using pool-based active learning. Instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them. We introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. We provide a theoretical motivation for the algorithm using the notion of a version space. We present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings."
            },
            "slug": "Support-Vector-Machine-Active-Learning-with-to-Text-Tong-Koller",
            "title": {
                "fragments": [],
                "text": "Support Vector Machine Active Learning with Applications to Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experimental results showing that employing the active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings are presented."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39340971"
                        ],
                        "name": "B. Partee",
                        "slug": "B.-Partee",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Partee",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Partee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909891"
                        ],
                        "name": "A. T. Meulen",
                        "slug": "A.-T.-Meulen",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Meulen",
                            "middleNames": [
                                "ter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. T. Meulen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40383053"
                        ],
                        "name": "R. Wall",
                        "slug": "R.-Wall",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Wall",
                            "middleNames": [
                                "E."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118066274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9602400f20ed0e275e92937a4060df43e894fd2f",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. Part A. Set Theory. 1. Basic Concepts of Set Theory. 2. Relations and Functions. 3. Properties of Relations. 4. Infinities. Appendix A1. Part B. Logic and Formal Systems. 5. Basic Concepts of Logic. 6.Statement Logic. 7. Predicate Logic. 8. Formal Systems, Axiomatization, and Model Theory. Appendix B1. Appendix BII. Part C. Algebra. 9. Basic Concepts of Algebra. 10. Operational Structures. 11. Lattices. 12. Boolean and Heyting Algebras. Part D. English as a Formal Language. 13. Basic Concepts of Formal Languages. 14. Generalized Quantifiers. 15. Intensionality. Part E. Languages, Grammars, and Automata. 16. Basic Concepts of Languages, Grammars, and Automata. 17. Finite Automata, Regular Languages and Type 3 Grammars. 18. Pushdown Automata, Context-Free Grammars and Languages. 19. Turing Machines, Recursively Enumberable Languages, and Type 0 Grammars. 20. Linear Bounded Automata, Context-Sensitive Languages and Type 1 Grammars. 21. Languages Between Context-Free and Context-Sensitive. 22. Transformational Grammars. Appendix EI. Appendix EII. Review Problems. Index."
            },
            "slug": "Mathematical-Methods-in-Linguistics-Partee-Meulen",
            "title": {
                "fragments": [],
                "text": "Mathematical Methods in Linguistics"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The aim of this book is to clarify the role that language plays in the development of set theory and to provide a framework for the future development of such a system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 162
                            }
                        ],
                        "text": "Active learning is a research area in machine learning that features systems that automatically select the most informative examples for annotation and training (Angluin, 1988; Seung, Opper, & Sompolinsky, 1992), rather than relying on a benevolent teacher or random sampling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11357867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e16333259bb4a688fe2568f0d757299846a3e696",
            "isKey": false,
            "numCitedBy": 1142,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of using queries to learn an unknown concept. Several types of queries are described and studied: membership, equivalence, subset, superset, disjointness, and exhaustiveness queries. Examples are given of efficient learning methods using various subsets of these queries for formal domains, including the regular languages, restricted classes of context-free languages, the pattern languages, and restricted types of propositional formulas. Some general lower bound techniques are given. Equivalence queries are compared with Valiant's criterion of probably approximately correct identification under random sampling."
            },
            "slug": "Queries-and-concept-learning-Angluin",
            "title": {
                "fragments": [],
                "text": "Queries and concept learning"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work considers the problem of using queries to learn an unknown concept, and several types of queries are described and studied: membership, equivalence, subset, superset, disjointness, and exhaustiveness queries."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976268"
                        ],
                        "name": "D. Cohn",
                        "slug": "D.-Cohn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705299"
                        ],
                        "name": "L. Atlas",
                        "slug": "L.-Atlas",
                        "structuredName": {
                            "firstName": "Les",
                            "lastName": "Atlas",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Atlas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762656"
                        ],
                        "name": "R. Ladner",
                        "slug": "R.-Ladner",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Ladner",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ladner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 55
                            }
                        ],
                        "text": "With respect to additional active learning techniques, Cohn et al. (1994) were among the first to discuss certainty-based active learning methods in detail."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "The last approach, selective sampling (Cohn et al., 1994), is particularly attractive in natural-language learning, since there is an abundance of text, and we would like to annotate only the most informative sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 93
                            }
                        ],
                        "text": "One critical problem is obtaining diverse committees that properly sample the version space (Cohn et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 73
                            }
                        ],
                        "text": "2 Active Learning With respect to additional active learning techniques, Cohn et al. (1994) were among the first to discuss certainty-based active learning methods in detail."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 171
                            }
                        ],
                        "text": "Active learning is an emerging research area in machine learning that features systems that automatically select the most informative examples for annotation and training (Cohn et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 39
                            }
                        ],
                        "text": "The last approach, selective sampling (Cohn et al., 1994), is particularly attractive in natural language learning, since there is an abundance of text, and we would like to annotate only the most informative sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 247
                            }
                        ],
                        "text": "Existing work in the area has emphasized two approaches, certainty-based methods (Lewis & Catlett, 1994), and committee-based methods (McCallum & Nigam, 1998; Freund, Seung, Shamir, & Tishby, 1997; Liere & Tadepalli, 1997; Dagan & Engelson, 1995; Cohn et al., 1994); we focus here on the former."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8483688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da71a0d60d40f2bb42467dfe4dc6da5dba4fff8c",
            "isKey": true,
            "numCitedBy": 1477,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Active learning differs from \u201clearning from examples\u201d in that the learning algorithm assumes at least some control over what part of the input domain it receives information about. In some situations, active learning is provably more powerful than learning from examples alone, giving better generalization for a fixed number of training examples.In this article, we consider the problem of learning a binary concept in the absence of noise. We describe a formalism for active concept learning calledselective sampling and show how it may be approximately implemented by a neural network. In selective sampling, a learner receives distribution information from the environment and queries an oracle on parts of the domain it considers \u201cuseful.\u201d We test our implementation, called anSG-network, on three domains and observe significant improvement in generalization."
            },
            "slug": "Improving-generalization-with-active-learning-Cohn-Atlas",
            "title": {
                "fragments": [],
                "text": "Improving generalization with active learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A formalism for active concept learning called selective sampling is described and it is shown how it may be approximately implemented by a neural network."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145634459"
                        ],
                        "name": "M. Garey",
                        "slug": "M.-Garey",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Garey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444582"
                        ],
                        "name": "David S. Johnson",
                        "slug": "David-S.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 492,
                                "start": 31
                            }
                        ],
                        "text": "Several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available. Tishby and Gorin (1994) learn associations between words and actions (as meanings of those words). They test their system on a corpus of sentences paired with representations but do not demonstrate the integration of learning a semantic parser using the learned lexicon. Similarly, Oates, Eyler-Walker, and Cohen (1999) discuss the acquisition of lexical hierarchies and their associated meaning as defined by the sensory environment of a robot."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 31
                            }
                        ],
                        "text": "Several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available. Tishby and Gorin (1994) learn associations between words and actions (as meanings of those words)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": "The analogous Largest Common Subgraph problem (Garey & Johnson, 1979) is solvable in polynomial time if, as we assume, both inputs are trees and if K, the number of edges to include, is given."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2211006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdede1e17c947540b50e6e2db9e8467ddc6e7336",
            "isKey": true,
            "numCitedBy": 47656,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Horn formulae play a prominent role in artificial intelligence and logic programming. In this paper we investigate the problem of optimal compression of propositional Horn production rule knowledge bases. The standard approach to this problem, consisting in the removal of redundant rules from a knowledge base, leads to an \"irredundant\" but not necessarily optimal knowledge base. We prove here that the number of rules in any irredundant Horn knowledge base involving n propositional variables is at most n 0 1 times the minimum possible number of rules. In order to formalize the optimal compression problem, we define a Boolean function of a knowledge base as being the function whose set of true points is the set of models of the knowledge base. In this way the optimal compression of production rule knowledge bases becomes a problem of Boolean function minimization. In this paper we prove that the minimization of Horn functions (i.e. Boolean functions associated to Horn knowledge bases) is..."
            },
            "slug": "Computers-and-Intractability:-A-Guide-to-the-Theory-Garey-Johnson",
            "title": {
                "fragments": [],
                "text": "Computers and Intractability: A Guide to the Theory of NP-Completeness"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This is the second edition of a quarterly column the purpose of which is to provide a continuing update to the list of problems (NP-complete and harder) presented by M. R. Garey and myself in the authors' book \u2018\u2018Computers and Intractability: A Guide to the Theory of NP-Completeness\u2019\u2019."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761866"
                        ],
                        "name": "Greg Schohn",
                        "slug": "Greg-Schohn",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Schohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Schohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50742419"
                        ],
                        "name": "David A. Cohn",
                        "slug": "David-A.-Cohn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Cohn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 129
                            }
                        ],
                        "text": "Only a few of the researchers applying machine learning to natural language processing have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1713753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "609e5cc1da126d7f760d1444b43b4fae41602841",
            "isKey": false,
            "numCitedBy": 911,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a simple active learning heuristic which greatly enhances the generalization behavior of support vector machines (SVMs) on several practical document classification tasks. We observe a number of benefits, the most surprising of which is that a SVM trained on a wellchosen subset of the available corpus frequently performs better than one trained on all available data. The heuristic for choosing this subset is simple to compute, and makes no use of information about the test set. Given that the training time of SVMs depends heavily on the training set size, our heuristic not only offers better performance with fewer data, it frequently does so in less time than the naive approach of training on all available data."
            },
            "slug": "Less-is-More:-Active-Learning-with-Support-Vector-Schohn-Cohn",
            "title": {
                "fragments": [],
                "text": "Less is More: Active Learning with Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A simple active learning heuristic is described which greatly enhances the generalization behavior of support vector machines (SVMs) on several practical document classification tasks and frequently does so in less time than the naive approach of training on all available data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720547"
                        ],
                        "name": "H. Sompolinsky",
                        "slug": "H.-Sompolinsky",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Sompolinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sompolinsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7869993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "941ef255d31b5becbf0a3281bcf7ac0122e4c833",
            "isKey": false,
            "numCitedBy": 1619,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an algorithm called query by commitee, in which a committee of students is trained on the same data set. The next query is chosen according to the principle of maximal disagreement. The algorithm is studied for two toy models: the high-low game and perceptron learning of another perceptron. As the number of queries goes to infinity, the committee algorithm yields asymptotically finite information gain. This leads to generalization error that decreases exponentially with the number of examples. This in marked contrast to learning from randomly chosen inputs, for which the information gain approaches zero and the generalization error decreases with a relatively slow inverse power law. We suggest that asymptotically finite information gain may be an important characteristic of good query algorithms."
            },
            "slug": "Query-by-committee-Seung-Opper",
            "title": {
                "fragments": [],
                "text": "Query by committee"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is suggested that asymptotically finite information gain may be an important characteristic of good query algorithms, in which a committee of students is trained on the same data set."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144356748"
                        ],
                        "name": "J. Catlett",
                        "slug": "J.-Catlett",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Catlett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Catlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "Existing work in the area has emphasized two approaches, certainty-based methods (Lewis & Catlett, 1994), and committee-based methods (McCallum & Nigam, 1998; Freund, Seung, Shamir, & Tishby, 1997; Liere & Tadepalli, 1997; Dagan & Engelson, 1995; Cohn et al., 1994); we focus here on the former."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Lewis and Catlett (1994) use heterogeneous certainty-based methods, in which a simple classifier is used to select examples that are then annotated and presented to a more powerful classifier."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 151
                            }
                        ],
                        "text": "\u2026active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of these have addressed classification tasks such as part of speech tagging and text categorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5319590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b69e0cce79eb288ffb43ad7ae3b99b8dea9ac5ac",
            "isKey": false,
            "numCitedBy": 1095,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Heterogeneous-Uncertainty-Sampling-for-Supervised-Lewis-Catlett",
            "title": {
                "fragments": [],
                "text": "Heterogeneous Uncertainty Sampling for Supervised Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46212202"
                        ],
                        "name": "A. Goldberg",
                        "slug": "A.-Goldberg",
                        "structuredName": {
                            "firstName": "Adele",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Goldberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "isition (e.g., Haas and Jayaraman, 1997; Siskind, 19964) While there is some debate in the linguistics community about the ability of compositional techniques to handle all phenomena (Fillmore, 1988; Goldberg, 1995), making this assumption simpli\ufb01es the learning process and works reasonably for the domains of interest here. Also, since we allow multi-word phrases in the lexicon (e.g., (\u201ckick the bucket\u201d, die()))"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 166
                            }
                        ],
                        "text": "\u20261997; Siskind, 19964) While there is some debate in the linguistics community about the ability of compositional techniques to handle all phenomena (Fillmore, 1988; Goldberg, 1995), making this assumption simplifies the learning process and works reasonably for the domains of interest here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 142790460,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "78e6c78ebb00d7626557caff7f7544f6157716bc",
            "isKey": false,
            "numCitedBy": 2060,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Acknowledgments 1: Introduction 2: The Interaction between Verbs and Constructions 3: Relations among Constructions 4: On Linking 5: Partial Productivity 6: The English Ditransitive Construction 7: The English Caused-Motion Construction 8: The English Resultative Construction 9: The Way Construction 10: Conclusion Notes Bibliography Index"
            },
            "slug": "Constructions:-A-Construction-Grammar-Approach-to-Goldberg",
            "title": {
                "fragments": [],
                "text": "Constructions: A Construction Grammar Approach to Argument Structure"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8993101"
                        ],
                        "name": "D. Fisher",
                        "slug": "D.-Fisher",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Fisher",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 82
                            }
                        ],
                        "text": "The first component is analogous the cluster evaluation\nheuristic used by Cobweb (Fisher, 1987), which measures the utility of clusters based on attribute-value pairs and categories, instead of meanings and phrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 85
                            }
                        ],
                        "text": "The first component is analogous the the cluster evaluation heuristic used by Cobweb (Fisher, 1987), which measures the utility of clusters based on attribute-value pairs and categories, instead of meanings and phrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1249171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7fc8100e73591ce8af1d553d4296ec38f939c248",
            "isKey": false,
            "numCitedBy": 1454,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Conceptual clustering is an important way of summarizing and explaining data. However, the recent formulation of this paradigm has allowed little exploration of conceptual clustering as a means of improving performance. Furthermore, previous work in conceptual clustering has not explicitly dealt with constraints imposed by real world environments. This article presents COBWEB, a conceptual clustering system that organizes data so as to maximize inference ability. Additionally, COBWEB is incremental and computationally economical, and thus can be flexibly applied in a variety of domains."
            },
            "slug": "Knowledge-Acquisition-Via-Incremental-Conceptual-Fisher",
            "title": {
                "fragments": [],
                "text": "Knowledge Acquisition Via Incremental Conceptual Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "COBWEB is a conceptual clustering system that organizes data so as to maximize inference ability, and is incremental and computationally economical, and thus can be flexibly applied in a variety of domains."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730104"
                        ],
                        "name": "N. Lavrac",
                        "slug": "N.-Lavrac",
                        "structuredName": {
                            "firstName": "Nada",
                            "lastName": "Lavrac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lavrac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693549"
                        ],
                        "name": "S. D\u017eeroski",
                        "slug": "S.-D\u017eeroski",
                        "structuredName": {
                            "firstName": "Sa\u0161o",
                            "lastName": "D\u017eeroski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D\u017eeroski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 57
                            }
                        ],
                        "text": "Chill uses inductive logic programming (Muggleton, 1992; Lavrac\u0306 & Dz\u0306eroski, 1994) to learn a deterministic shift-reduce parser (Tomita, 1986) written in Prolog."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 39
                            }
                        ],
                        "text": ", 1999; ArgamonEngelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of these have addressed classification tasks such as part of speech tagging and text categorization. For example, Liere and Tadepalli (1997) apply active learning with committees to the problem of text categorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36237350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58095bae1d836943bdaa52b76fa8d17cf77d06b3",
            "isKey": false,
            "numCitedBy": 931,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 Empirical inductive logic programming: introduction empirical ILP systems - an overview LINUS - using attribute-value learners in an ILP framework experiments in learning relations with LINUS ILP as search for program clauses. Part 2 Learning relations from imperfect data: handling imperfect data in ILP using heuristics to handle noise in ILP mFOIL - extending noise-handling in FOIL experiments in learning relations from noisy examples. Part 3 Applications of inductive logic programming: learning rules for early diagnosis of rheumatic diseases finite element mesh design an overview of selected ILP applications."
            },
            "slug": "Inductive-logic-programming-techniques-and-Lavrac-D\u017eeroski",
            "title": {
                "fragments": [],
                "text": "Inductive logic programming - techniques and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Applications of inductive logic programming: learning rules for early diagnosis of rheumatic diseases finite element mesh design an overview of selected ILP applications."
            },
            "venue": {
                "fragments": [],
                "text": "Ellis Horwood series in artificial intelligence"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726733"
                        ],
                        "name": "Ron Kohavi",
                        "slug": "Ron-Kohavi",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Kohavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Kohavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34929449"
                        ],
                        "name": "George H. John",
                        "slug": "George-H.-John",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "John",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George H. John"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 150
                            }
                        ],
                        "text": "Modulo this consideration, results are not overly-sensitive to the weights and automatically setting them using cross-validation on the training set (Kohavi & John, 1995) had little effect on overall performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7594891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20c25424a20bc4f88accb35fbfd98d2ca7ffc525",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-Parameter-Selection-by-Minimizing-Error-Kohavi-John",
            "title": {
                "fragments": [],
                "text": "Automatic Parameter Selection by Minimizing Estimated Error"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870604"
                        ],
                        "name": "E. Shamir",
                        "slug": "E.-Shamir",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Shamir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Shamir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 323241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01dfd7b78017ea4059f02081680a9fd4b2bb2a34",
            "isKey": false,
            "numCitedBy": 1120,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze the \u201cquery by committee\u201d algorithm, a method for filtering informative queries from a random stream of inputs. We show that if the two-member committee algorithm achieves information gain with positive lower bound, then the prediction error decreases exponentially with the number of queries. We show that, in particular, this exponential decrease holds for query learning of perceptrons."
            },
            "slug": "Selective-Sampling-Using-the-Query-by-Committee-Freund-Seung",
            "title": {
                "fragments": [],
                "text": "Selective Sampling Using the Query by Committee Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "It is shown that if the two-member committee algorithm achieves information gain with positive lower bound, then the prediction error decreases exponentially with the number of queries, and this exponential decrease holds for query learning of perceptrons."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912454"
                        ],
                        "name": "C. Fillmore",
                        "slug": "C.-Fillmore",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fillmore",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fillmore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 150
                            }
                        ],
                        "text": "\u20261997; Siskind, 19964) While there is some debate in the linguistics community about the ability of compositional techniques to handle all phenomena (Fillmore, 1988; Goldberg, 1995), making this assumption simplifies the learning process and works reasonably for the domains of interest here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "nd language acquisition (e.g., Haas and Jayaraman, 1997; Siskind, 19964) While there is some debate in the linguistics community about the ability of compositional techniques to handle all phenomena (Fillmore, 1988; Goldberg, 1995), making this assumption simpli\ufb01es the learning process and works reasonably for the domains of interest here. Also, since we allow multi-word phrases in the lexicon (e.g., (\u201ckick the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60802075,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "06f717f51b1a6b21482f72a502b0a9fe620c4e39",
            "isKey": false,
            "numCitedBy": 447,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Proceedings of the Fourteenth Annual Meeting of the Berkeley Linguistics \nSociety (1988), pp. 35-55"
            },
            "slug": "The-Mechanisms-of-\u201cConstruction-Grammar\u201d-Fillmore",
            "title": {
                "fragments": [],
                "text": "The Mechanisms of \u201cConstruction Grammar\u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144716964"
                        ],
                        "name": "J. Cocke",
                        "slug": "J.-Cocke",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cocke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3069902"
                        ],
                        "name": "P. Roossin",
                        "slug": "P.-Roossin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Roossin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roossin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 541,
                                "start": 242
                            }
                        ],
                        "text": "Our work also has ties to the work on automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990). While most of these methods also compute association scores between pairs (in their case, word/word pairs) and use a greedy algorithm to choose the best translation(s) for each word, they do not take advantage of the constraints between pairs. One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 705,
                                "start": 242
                            }
                        ],
                        "text": "Our work also has ties to the work on automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990). While most of these methods also compute association scores between pairs (in their case, word/word pairs) and use a greedy algorithm to choose the best translation(s) for each word, they do not take advantage of the constraints between pairs. One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does. Also, Yamazaki, Pazzani, and Merz (1995) learn both translation rules and semantic hierarchies from parsed parallel sentences in Japanese and English."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14386564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1066659ec1afee9dce586f6f49b7d44527827e1",
            "isKey": false,
            "numCitedBy": 1940,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a statistical approach to machine translation. We describe the application of our approach to translation from French to English and give preliminary results."
            },
            "slug": "A-Statistical-Approach-to-Machine-Translation-Brown-Cocke",
            "title": {
                "fragments": [],
                "text": "A Statistical Approach to Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The application of the statistical approach to translation from French to English and preliminary results are described and the results are given."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731375"
                        ],
                        "name": "M. Brent",
                        "slug": "M.-Brent",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brent",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 998,
                                "start": 76
                            }
                        ],
                        "text": "Although a few others (Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Brent, 1991) have presented systems for learning information about lexical semantics, the developed system is unique in combining several features. First, it interacts with a system, Chill (Zelle & Mooney, 1996; Zelle, 1995), that learns to parse sentences into semantic representations. Second, it uses a fairly straightforward batch, greedy learning algorithm that is fast and accurate. Third, it is easily extendible to new representation formalisms. Fourth, it requires no prior knowledge although it can exploit an initial lexicon if provided. Finally, it simplifies the mapping problem by making a compositionality assumption that states that the meaning of a sentence is composed from the meanings of the individual words and phrases in that sentence, in addition, perhaps to some \u201cconnecting\u201d information specific to the representation at hand. This assumption is similar to the linking rules of Jackendoff (1990), and has been used in previous work on grammar and language acquisition (e."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 160
                            }
                        ],
                        "text": "This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 19
                            }
                        ],
                        "text": "Manning (1993) and Brent (1991) describe work on learning selectional restrictions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 130
                            }
                        ],
                        "text": "Although many others (Se\u0301billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 370,
                                "start": 109
                            }
                        ],
                        "text": ", (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991)) discuss the acquisition of subcategorization information for verbs, which is different from the information required for mapping to semantic representation, but could be useful as a source of information to further constrain the search. Li (1998) further expands on this by inducing clustering information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1736,
                                "start": 76
                            }
                        ],
                        "text": "Although a few others (Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Brent, 1991) have presented systems for learning information about lexical semantics, the developed system is unique in combining several features. First, it interacts with a system, Chill (Zelle & Mooney, 1996; Zelle, 1995), that learns to parse sentences into semantic representations. Second, it uses a fairly straightforward batch, greedy learning algorithm that is fast and accurate. Third, it is easily extendible to new representation formalisms. Fourth, it requires no prior knowledge although it can exploit an initial lexicon if provided. Finally, it simplifies the mapping problem by making a compositionality assumption that states that the meaning of a sentence is composed from the meanings of the individual words and phrases in that sentence, in addition, perhaps to some \u201cconnecting\u201d information specific to the representation at hand. This assumption is similar to the linking rules of Jackendoff (1990), and has been used in previous work on grammar and language acquisition (e.g., Haas and Jayaraman (1997), Siskind (1996)). We test Wolfie\u2019s ability to acquire a semantic lexicon for a natural language interface to a geographical database using a corpus of queries collected from human subjects and annotated with their logical form. In this test, Wolfie is integrated with Chill, which learns parsers but requires a semantic lexicon (previously built manually). The results demonstrate that the final acquired parser performs nearly as accurately at answering novel questions when using a learned lexicon as when using a hand-built lexicon. Wolfie is also compared to an alternative lexicon acquisition system developed by Siskind (1996), demonstrating superior performance on this task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 123
                            }
                        ],
                        "text": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-\ntion information for verbs, and others describe work on learning selectional restrictions (Manning, 1993; Brent, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 160
                            }
                        ],
                        "text": "This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1103,
                                "start": 76
                            }
                        ],
                        "text": "Although a few others (Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Brent, 1991) have presented systems for learning information about lexical semantics, the developed system is unique in combining several features. First, it interacts with a system, Chill (Zelle & Mooney, 1996; Zelle, 1995), that learns to parse sentences into semantic representations. Second, it uses a fairly straightforward batch, greedy learning algorithm that is fast and accurate. Third, it is easily extendible to new representation formalisms. Fourth, it requires no prior knowledge although it can exploit an initial lexicon if provided. Finally, it simplifies the mapping problem by making a compositionality assumption that states that the meaning of a sentence is composed from the meanings of the individual words and phrases in that sentence, in addition, perhaps to some \u201cconnecting\u201d information specific to the representation at hand. This assumption is similar to the linking rules of Jackendoff (1990), and has been used in previous work on grammar and language acquisition (e.g., Haas and Jayaraman (1997), Siskind (1996))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 2
                            }
                        ],
                        "text": ", (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991)) discuss the acquisition of subcategorization information for verbs, which is different from the information required for mapping to semantic representation, but could be useful as a source of information to further constrain the search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 22
                            }
                        ],
                        "text": "Although a few others (Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Brent, 1991) have presented systems for learning information about lexical semantics, the developed system is unique in combining several features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61284815,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "2ffde8e3e02edca7b3638297c6a04b0994569f45",
            "isKey": true,
            "numCitedBy": 110,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an implemented program that takes a raw, untagged text corpus as its only input (no open-class dictionary) and generates a partial list of verbs occurring in the text and the subcategorization frames (SFs) in which they occur. Verbs are detected by a novel technique based on the Case Filter of Rouvret and Vergnaud (1980). The completeness of the output list increases monotonically with the total number of occurrences of each verb in the corpus. False positive rates are one to three percent of observations. Five SFs are currently detected and more are planned. Ultimately, I expect to provide a large SF dictionary to the NLP community and to train dictionaries for specific corpora."
            },
            "slug": "Automatic-Acquisition-of-Subcategorization-Frames-Brent",
            "title": {
                "fragments": [],
                "text": "Automatic Acquisition of Subcategorization Frames from Untagged Text"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An implemented program that takes a raw, untagged text corpus as its only input and generates a partial list of verbs occurring in the text and the subcategorization frames (SFs) in which they occur to provide a large SF dictionary to the NLP community and to train dictionaries for specific corpora."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 16
                            }
                        ],
                        "text": "Several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 40
                            }
                        ],
                        "text": "Finally, several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 101
                            }
                        ],
                        "text": "cial, and the sentence representation is a variable-free representation, as suggested by the work of Jackendoff (1990) and others."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 94
                            }
                        ],
                        "text": "Although many others (Se\u0301billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 22
                            }
                        ],
                        "text": "Although a few others (Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Brent, 1991) have presented systems for learning information about lexical semantics, the developed system is unique in combining several features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Implications of an automatic lexical acquisition mechanism"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145634459"
                        ],
                        "name": "M. Garey",
                        "slug": "M.-Garey",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Garey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 232754604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08421c787d9a9e2d9f5ba4bda1bfc9866fa4b04f",
            "isKey": false,
            "numCitedBy": 4057,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Johnson:-computers-and-intractability:-a-guide-to-Garey",
            "title": {
                "fragments": [],
                "text": "Johnson: computers and intractability: a guide to the theory of np- completeness (freeman"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4632093"
                        ],
                        "name": "G. Zipf",
                        "slug": "G.-Zipf",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Zipf",
                            "middleNames": [
                                "Kingsley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zipf"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 163
                            }
                        ],
                        "text": "We used a grammar to generate utterances and their meanings from each original lexicon, with terminal categories selected using a distribution based on Zipf\u2019s Law (Zipf, 1949)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 6
                            }
                        ],
                        "text": "Under Zipf\u2019s Law, the occurrence frequency of a word is inversely proportional to its ranking by occurrence."
                    },
                    "intents": []
                }
            ],
            "corpusId": 141120597,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "2bcf3e6c2b45c052a0bd0183cc29c03acc4b49ac",
            "isKey": false,
            "numCitedBy": 7038,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-behavior-and-the-principle-of-least-effort-Zipf",
            "title": {
                "fragments": [],
                "text": "Human behavior and the principle of least effort"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1949
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058177533"
                        ],
                        "name": "Simon Tong",
                        "slug": "Simon-Tong",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 150
                            }
                        ],
                        "text": "Only a few of the researchers applying machine learning to natural language processing have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34678574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0489e71af49c919f691c562c1ba0058bd2da136a",
            "isKey": false,
            "numCitedBy": 368,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Support-Vector-Machine-Active-Learning-with-sto-Tong-Koller",
            "title": {
                "fragments": [],
                "text": "Support Vector Machine Active Learning with Application sto Text Classification"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Turbo Prolog 2.0 Reference Guide"
            },
            "venue": {
                "fragments": [],
                "text": "Borland International Borland International"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The neural theory of language project http"
            },
            "venue": {
                "fragments": [],
                "text": "The neural theory of language project http"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Deriving translation data from bilingual texts"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the First International Lexical Acquisition Workshop"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The neural theory of language project http://www.icsi.berkeley.edu/ntl"
            },
            "venue": {
                "fragments": [],
                "text": "International Computer Science Institute,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 183
                            }
                        ],
                        "text": "In this corpus, both the sentences and their representations are completely artificial, and the sentence representation is a variable-free representation, as suggested by the work of Jackendoff (1990) and others."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 51
                            }
                        ],
                        "text": "This assumption is similar to the linking rules of Jackendoff (1990), and has been used in previous work on grammar and language acquisition (e.g., Haas and Jayaraman, 1997; Siskind, 19964) While there is some debate in the linguistics community about the ability of compositional techniques to\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantic Structures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 65
                            }
                        ],
                        "text": "Work on automated lexicon and language acquisition dates back to Siklossy (1972), who demonstrated a system that learned transformation patterns from logic back to natural\nlanguage."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Natural language learning by computer Representation and meaning: Experiments with Information Processsing Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Natural language learning by computer Representation and meaning: Experiments with Information Processsing Systems"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning categorial grammars from semantic types"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 13th Amsterdam Colloquium"
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 63,
            "methodology": 25,
            "result": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 91,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/Acquiring-Word-Meaning-Mappings-for-Natural-Thompson-Mooney/cbd3bb68861808eadd8c0ef2734fd0cd666305d9?sort=total-citations"
}