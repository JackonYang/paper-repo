{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230605"
                        ],
                        "name": "Daniel Strigl",
                        "slug": "Daniel-Strigl",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Strigl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Strigl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094229001"
                        ],
                        "name": "Klaus Kofler",
                        "slug": "Klaus-Kofler",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Kofler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus Kofler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828543"
                        ],
                        "name": "Stefan Podlipnig",
                        "slug": "Stefan-Podlipnig",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Podlipnig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Podlipnig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13377478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "687a0ce2ec2711ef206e2486cd56d192a88b3145",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present the implementation of a framework for accelerating training and classification of arbitrary Convolutional Neural Networks (CNNs) on the GPU. CNNs are a derivative of standard Multilayer Perceptron (MLP) neural networks optimized for two-dimensional pattern recognition problems such as Optical Character Recognition (OCR) or face detection. We describe the basic parts of a CNN and demonstrate the performance and scalability improvement that can be achieved by shifting the computation-intensive tasks of a CNN to the GPU. Depending on the network topology training and classification on the GPU performs 2 to 24 times faster than on the CPU. Furthermore, the GPU version scales much better than the CPU implementation with respect to the network size."
            },
            "slug": "Performance-and-Scalability-of-GPU-Based-Neural-Strigl-Kofler",
            "title": {
                "fragments": [],
                "text": "Performance and Scalability of GPU-Based Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents the implementation of a framework for accelerating training and classification of arbitrary Convolutional Neural Networks (CNNs) on the GPU and describes the basic parts of a CNN and demonstrates the performance and scalability improvement that can be achieved by shifting the computation-intensive tasks of aCNN to the GPU."
            },
            "venue": {
                "fragments": [],
                "text": "2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809791"
                        ],
                        "name": "K. Chellapilla",
                        "slug": "K.-Chellapilla",
                        "structuredName": {
                            "firstName": "Kumar",
                            "lastName": "Chellapilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chellapilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2568084"
                        ],
                        "name": "Sidd Puri",
                        "slug": "Sidd-Puri",
                        "structuredName": {
                            "firstName": "Sidd",
                            "lastName": "Puri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sidd Puri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "CNNs vary in how convolutional and subsampling layers are realized and how the nets are trained."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "CNNs are hierarchical neural networks whose convolutional layers alternate with subsampling layers, reminiscent of simple and complex cells in the primary visual cortex [Wiesel and Hubel, 1959]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Our implementation allows for training large CNNs within days instead of months, such that we can investigate the influence of various structural parameters by exploring large parameter spaces [Pinto et al., 2009] and performing error analysis on repeated experiments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "The implemented CNN\u2019s plain feed-forward architecture is trained using on-line gradient descent."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "Fully connected convolutional layers lead to an exploding number of network connections and weights, making training of big and deep CNNs for hundreds of epochs impractical even on GPUs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "With additional translations of at most 5%, the average error rate drops to 4.71%, contradicting the common belief that CNNs are translation invariant."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 38
                            }
                        ],
                        "text": "Previous GPU implementations of CNNs [Chellapilla et al., 2006; Uetz and Behnke, 2009; Strigl et al., 2010] were hard-coded to satisfy GPU hardware constraints or use general purpose libraries, whereas our implementation is flexible and fully online (i.e., weight updates after each image)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 37
                            }
                        ],
                        "text": "Previous GPU implementations of CNNs [Chellapilla et al., 2006; Uetz and Behnke, 2009; Strigl et al., 2010] were hard-coded to satisfy GPU hardware constraints or use general purpose libraries, whereas our implementation is flexible and fully online (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 322,
                                "start": 318
                            }
                        ],
                        "text": "These findings in conjunction with experimental studies of the visual cortex justify the use of such filters in the so-called standard model for object recognition [Riesenhuber and Poggio, 1999; Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks\n(CNNs) [LeCun et al., 1998; Behnke, 2003; Simard et al., 2003], whose weights (filters) are randomly initialized and changed in a supervised way using back-propagation (BP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Good results require big and deep but sparsely connected CNNs, computationally prohibitive on CPUs, but feasible on current GPUs, where our implementation is 10 to 60 times faster than a compileroptimized CPU version."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "The tested CNNs differ only in the number of maps per convolutional and max-pooling layer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "These results are on par or better than others in the literature: 5.90% error rate for a combination of CNNs and SVMs [LeCun et al., 2004] and 5.20% error rate for restricted Boltzman machines [Nair and Hinton, 2009]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14936779,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2cc157afda51873c30b195fff56e917b9c06b853",
            "isKey": true,
            "numCitedBy": 416,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks (CNNs) are well known for producing state-of-the-art recognizers for document processing [1]. However, they can be difficult to implement and are usually slower than traditional multi-layer perceptrons (MLPs). We present three novel approaches to speeding up CNNs: a) unrolling convolution, b) using BLAS (basic linear algebra subroutines), and c) using GPUs (graphic processing units). Unrolled convolution converts the processing in each convolutional layer (both forward-propagation and back-propagation) into a matrix-matrix product. The matrix-matrix product representation of CNNs makes their implementation as easy as MLPs. BLAS is used to efficiently compute matrix products on the CPU. We also present a pixel shader based GPU implementation of CNNs. Results on character recognition problems indicate that unrolled convolution with BLAS produces a dramatic 2.4X\u22123.0X speedup. The GPU implementation is even faster and produces a 3.1X\u22124.1X speedup."
            },
            "slug": "High-Performance-Convolutional-Neural-Networks-for-Chellapilla-Puri",
            "title": {
                "fragments": [],
                "text": "High Performance Convolutional Neural Networks for Document Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Three novel approaches to speeding up CNNs are presented: a) unrolling convolution, b) using BLAS (basic linear algebra subroutines), and c) using GPUs (graphic processing units)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1983697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd7f8b53e6802787179a961e766760cbbe2d5011",
            "isKey": false,
            "numCitedBy": 358,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the approach that won the preliminary phase of the German traffic sign recognition benchmark with a better-than-human recognition rate of 98.98%.We obtain an even better recognition rate of 99.15% by further training the nets. Our fast, fully parameterizable GPU implementation of a Convolutional Neural Network does not require careful design of pre-wired feature extractors, which are rather learned in a supervised way. A CNN/MLP committee further boosts recognition performance."
            },
            "slug": "A-committee-of-neural-networks-for-traffic-sign-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "A committee of neural networks for traffic sign classification"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This work describes the approach that won the preliminary phase of the German traffic sign recognition benchmark with a better-than-human recognition rate, and obtains an even better recognition rate by further training the nets."
            },
            "venue": {
                "fragments": [],
                "text": "The 2011 International Joint Conference on Neural Networks"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1884105"
                        ],
                        "name": "Rafael Uetz",
                        "slug": "Rafael-Uetz",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Uetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rafael Uetz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "Previous GPU implementations of CNNs [Chellapilla et al., 2006; Uetz and Behnke, 2009; Strigl et al., 2010] were hard-coded to satisfy GPU hardware constraints or use general purpose libraries, whereas our implementation is flexible and fully online (i.e., weight updates after each image)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 60
                            }
                        ],
                        "text": "This result improves the previous state of the art on NORB [Uetz and Behnke, 2009]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 159
                            }
                        ],
                        "text": "%) was obtained by a hierarchical neural network which to every convolutional layer provides a subsampled version plus edge information of the original image [Uetz and Behnke, 2009]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 37
                            }
                        ],
                        "text": "Previous GPU implementations of CNNs [Chellapilla et al., 2006; Uetz and Behnke, 2009; Strigl et al., 2010] were hard-coded to satisfy GPU hardware constraints or use general purpose libraries, whereas our implementation is flexible and fully online (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 160
                            }
                        ],
                        "text": "87%) was obtained by a hierarchical neural network which to every convolutional layer provides a subsampled version plus edge information of the original image [Uetz and Behnke, 2009]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6779371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fa5450f1c0795527939cfef5fbe3912c4dab3ab",
            "isKey": true,
            "numCitedBy": 86,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Robust recognition of arbitrary object classes in natural visual scenes is an aspiring goal with numerous practical applications, for instance, in the area of autonomous robotics and autonomous vehicles. One obstacle on the way towards human-like recognition performance is the limitation of computational power, restricting the size of the training and testing dataset as well as the complexity of the object recognition system. In this work, we present a hierarchical, locally-connected neural network model that is well-suited for large-scale, high-performance object recognition. By using the NVIDIA CUDA framework, we create a massively parallel implementation of the model which is executed on a state-of-the-art graphics card. This implementation is up to 82 times faster than a single-core CPU version of the system. This significant gain in computational performance allows us to evaluate the model on a very large, realistic, and challenging set of natural images which we extracted from the LabelMe dataset. To compare our model to other approaches, we also evaluate the recognition performance using the well-known MNIST and NORB datasets, achieving a testing error rate of 0.76% and 2.87 %, respectively."
            },
            "slug": "Large-scale-object-recognition-with-hierarchical-Uetz-Behnke",
            "title": {
                "fragments": [],
                "text": "Large-scale object recognition with CUDA-accelerated hierarchical neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents a hierarchical, locally-connected neural network model that is well-suited for large-scale, high-performance object recognition and creates a massively parallel implementation of the model which is executed on a state-of-the-art graphics card."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE International Conference on Intelligent Computing and Intelligent Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070963479"
                        ],
                        "name": "Dominik Scherer",
                        "slug": "Dominik-Scherer",
                        "structuredName": {
                            "firstName": "Dominik",
                            "lastName": "Scherer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dominik Scherer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113785713"
                        ],
                        "name": "Andreas C. M\u00fcller",
                        "slug": "Andreas-C.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "M\u00fcller",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas C. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18388506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d21006fa32ff69f6b0a646f26ce0db84f2f4d33",
            "isKey": false,
            "numCitedBy": 1285,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A common practice to gain invariant features in object recognition models is to aggregate multiple low-level features over a small neighborhood. However, the differences between those models makes a comparison of the properties of different aggregation functions hard. Our aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks. Empirical results show that a maximum pooling operation significantly outperforms subsampling operations. Despite their shift-invariant properties, overlapping pooling windows are no significant improvement over nonoverlapping pooling windows. By applying this knowledge, we achieve state-of-the-art error rates of 4.57% on the NORB normalized-uniform dataset and 5.6% on the NORB jittered-cluttered dataset."
            },
            "slug": "Evaluation-of-Pooling-Operations-in-Convolutional-Scherer-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks, and empirical results show that a maximum pooling operation significantly outperforms subsampling operations."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 308212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be9a17321537d9289875fe475b71f4821457b435",
            "isKey": false,
            "numCitedBy": 2600,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR by employing increasingly complex unsupervised learning algorithms and deep models. In this paper, however, we show that several simple factors, such as the number of hidden nodes in the model, may be more important to achieving high performance than the learning algorithm or the depth of the model. Specifically, we will apply several othe-shelf feature learning algorithms (sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures) to CIFAR, NORB, and STL datasets using only singlelayer networks. We then present a detailed analysis of the eect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (\u201cstride\u201d) between extracted features, and the eect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance\u2014so critical, in fact, that when these parameters are pushed to their limits, we achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyperparameters to tune beyond the model structure itself, and is very easy to implement. Despite the simplicity of our system, we achieve accuracy beyond all previously published results on the CIFAR-10 and NORB datasets (79.6% and 97.2% respectively)."
            },
            "slug": "An-Analysis-of-Single-Layer-Networks-in-Feature-Coates-Ng",
            "title": {
                "fragments": [],
                "text": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance\u2014so critical, in fact, that when these parameters are pushed to their limits, they achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6803671"
                        ],
                        "name": "L. Gambardella",
                        "slug": "L.-Gambardella",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Gambardella",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 66
                            }
                        ],
                        "text": "A 0.35% error rate was recently also obtained by a big, deep MLP [Ciresan et al., 2010] with many more free parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 83
                            }
                        ],
                        "text": "These deformations improve recognition rates for digits that are intrinsically 2D [Ciresan et al., 2010], but seem inadequate for 3D objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1918673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b98cd08b75ebf2bd1d1ec47c51ef75777a7e64bd",
            "isKey": false,
            "numCitedBy": 876,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35 error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning."
            },
            "slug": "Deep,-Big,-Simple-Neural-Nets-for-Handwritten-Digit-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "Deep, Big, Simple Neural Nets for Handwritten Digit Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35 error rate on the MNIST handwritten digits benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 48
                            }
                        ],
                        "text": "20% error rate for restricted Boltzman machines [Nair and Hinton, 2009]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 194
                            }
                        ],
                        "text": "These results are on par or better than others in the literature: 5.90% error rate for a combination of CNNs and SVMs [LeCun et al., 2004] and 5.20% error rate for restricted Boltzman machines [Nair and Hinton, 2009]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2416787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a2668bf420d8509a4dfa28e1cdcdac14c649975",
            "isKey": true,
            "numCitedBy": 356,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new type of top-level model for Deep Belief Nets and evaluate it on a 3D object recognition task. The top-level model is a third-order Boltzmann machine, trained using a hybrid algorithm that combines both generative and discriminative gradients. Performance is evaluated on the NORB database (normalized-uniform version), which contains stereo-pair images of objects under different lighting conditions and viewpoints. Our model achieves 6.5% error on the test set, which is close to the best published result for NORB (5.9%) using a convolutional neural net that has built-in knowledge of translation invariance. It substantially outperforms shallow models such as SVMs (11.6%). DBNs are especially suited for semi-supervised learning, and to demonstrate this we consider a modified version of the NORB recognition task in which additional unlabeled images are created by applying small translations to the images in the database. With the extra unlabeled data (and the same amount of labeled data as before), our model achieves 5.2% error."
            },
            "slug": "3D-Object-Recognition-with-Deep-Belief-Nets-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "3D Object Recognition with Deep Belief Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new type of top-level model for Deep Belief Nets is introduced, a third-order Boltzmann machine, trained using a hybrid algorithm that combines both generative and discriminative gradients that substantially outperforms shallow models such as SVMs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 174
                            }
                        ],
                        "text": "We evaluate various networks on the handwritten digit benchmark MNIST [LeCun et al., 1998] and two image classification benchmarks: NORB [LeCun et al., 2004] and CIFAR10 [Krizhevsky, 2009]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18268744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "isKey": false,
            "numCitedBy": 17110,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images."
            },
            "slug": "Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky",
            "title": {
                "fragments": [],
                "text": "Learning Multiple Layers of Features from Tiny Images"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex, using a novel parallelization algorithm to distribute the work among multiple machines connected on a network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35268,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 57
                            }
                        ],
                        "text": "In particular, we find that a contrast-extracting layer [Fukushima, 2003] helps to improve the recognition rate for NORB."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 85
                            }
                        ],
                        "text": "We try simple edge masks (Sobel, Scharr), but find that a contrast-extraction layer [Fukushima, 2003] realized by mexican hat shaped filters of size 21\u00d7 21 works best."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12476611,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "581528b2215e017eba96ef4ee16d33a74645755f",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neocognitron-for-handwritten-digit-recognition-Fukushima",
            "title": {
                "fragments": [],
                "text": "Neocognitron for handwritten digit recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38767254"
                        ],
                        "name": "David Steinkraus",
                        "slug": "David-Steinkraus",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Steinkraus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Steinkraus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 87
                            }
                        ],
                        "text": "Affine (translation, rotation, scaling, horizontal shearing) and elastic deformations [Simard et al., 2003] are combined."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 165
                            }
                        ],
                        "text": "\u2026Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks\n(CNNs) [LeCun et al., 1998; Behnke, 2003; Simard et al., 2003], whose weights (filters) are randomly initialized and changed in a supervised way using back-propagation (BP)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 117
                            }
                        ],
                        "text": ", 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks (CNNs) [LeCun et al., 1998; Behnke, 2003; Simard et al., 2003], whose weights (filters) are randomly initialized and changed in a supervised way using back-propagation (BP)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 26
                            }
                        ],
                        "text": "No such layer is used by [Simard et al., 2003] who simply skips nearby pixels prior to convolution, instead of pooling or averaging."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 48
                            }
                        ],
                        "text": "The best previous CNN result on MNIST is 0.40% [Simard et al., 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4659176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5562a56da3a96dae82add7de705e2bd841eb00fc",
            "isKey": true,
            "numCitedBy": 2432,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are a powerful technology forclassification of visual inputs arising from documents.However, there is a confusing plethora of different neuralnetwork methods that are used in the literature and inindustry. This paper describes a set of concrete bestpractices that document analysis researchers can use toget good results with neural networks. The mostimportant practice is getting a training set as large aspossible: we expand the training set by adding a newform of distorted data. The next most important practiceis that convolutional neural networks are better suited forvisual document tasks than fully connected networks. Wepropose that a simple \"do-it-yourself\" implementation ofconvolution with a flexible architecture is suitable formany visual document problems. This simpleconvolutional neural network does not require complexmethods, such as momentum, weight decay, structure-dependentlearning rates, averaging layers, tangent prop,or even finely-tuning the architecture. The end result is avery simple yet general architecture which can yieldstate-of-the-art performance for document analysis. Weillustrate our claims on the MNIST set of English digitimages."
            },
            "slug": "Best-practices-for-convolutional-neural-networks-to-Simard-Steinkraus",
            "title": {
                "fragments": [],
                "text": "Best practices for convolutional neural networks applied to visual document analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A set of concrete bestpractices that document analysis researchers can use to get good results with neural networks, including a simple \"do-it-yourself\" implementation of convolution with a flexible architecture suitable for many visual document problems."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6803671"
                        ],
                        "name": "L. Gambardella",
                        "slug": "L.-Gambardella",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Gambardella",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2753763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aab23d5ca13256a7fc72e118f0092a4b1209f8e2",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method to train the members of a committee of one-hidden-layer neural nets. Instead of training various nets on subsets of the training data we preprocess the training data for each individual model such that the corresponding errors are decor related. On the MNIST digit recognition benchmark set we obtain a recognition error rate of 0.39%, using a committee of 25 one-hidden-layer neural nets, which is on par with state-of-the-art recognition rates of more complicated systems."
            },
            "slug": "Better-Digit-Recognition-with-a-Committee-of-Simple-Meier-Ciresan",
            "title": {
                "fragments": [],
                "text": "Better Digit Recognition with a Committee of Simple Neural Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A new method to train the members of a committee of one-hidden-layer neural nets is presented, which obtains a recognition error rate on the MNIST digit recognition benchmark set of 0.39%, on par with state-of-the-art recognition rates of more complicated systems."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077257730"
                        ],
                        "name": "Kevin Jarrett",
                        "slug": "Kevin-Jarrett",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Jarrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Jarrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 102
                            }
                        ],
                        "text": "We reduce the number of connections between convolutional layers in a random way [LeCun et al., 1998; Jarrett et al., 2009]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 24
                            }
                        ],
                        "text": "A notable exception is [Jarrett et al., 2009] who performed a thorough analysis of the influence of all building blocks of a multistage architecture on recognition performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206769720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f88427d7aa8225e47f946ac41a0667d7b69ac52",
            "isKey": false,
            "numCitedBy": 2085,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (\u226b 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%)."
            },
            "slug": "What-is-the-best-multi-stage-architecture-for-Jarrett-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "What is the best multi-stage architecture for object recognition?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks and that two stages of feature extraction yield better accuracy than one."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 119
                            }
                        ],
                        "text": "These results are on par or better than others in the literature: 5.90% error rate for a combination of CNNs and SVMs [LeCun et al., 2004] and 5.20% error rate for restricted Boltzman machines [Nair and Hinton, 2009]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "We evaluate various networks on the handwritten digit benchmark MNIST [LeCun et al., 1998] and two image classification benchmarks: NORB [LeCun et al., 2004] and CIFAR10 [Krizhevsky, 2009]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 712708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f354310098e09c1e1dc88758fca36767fd9d084d",
            "isKey": true,
            "numCitedBy": 1306,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second."
            },
            "slug": "Learning-methods-for-generic-object-recognition-to-LeCun-Huang",
            "title": {
                "fragments": [],
                "text": "Learning methods for generic object recognition with invariance to pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second and proved impractical, while convolutional nets yielded 16/7% error."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30017846"
                        ],
                        "name": "N. Pinto",
                        "slug": "N.-Pinto",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3250342"
                        ],
                        "name": "D. Doukhan",
                        "slug": "D.-Doukhan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doukhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doukhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865831"
                        ],
                        "name": "J. DiCarlo",
                        "slug": "J.-DiCarlo",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "DiCarlo",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. DiCarlo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042941"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215779860,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "d46fd54609e09bcd135fd28750003185a5ee4125",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "While many models of biological object recognition share a common set of \u201cbroad-stroke\u201d properties, the performance of any one model depends strongly on the choice of parameters in a particular instantiation of that model\u2014e.g., the number of units per layer, the size of pooling kernels, exponents in normalization operations, etc. Since the number of such parameters (explicit or implicit) is typically large and the computational cost of evaluating one particular parameter set is high, the space of possible model instantiations goes largely unexplored. Thus, when a model fails to approach the abilities of biological visual systems, we are left uncertain whether this failure is because we are missing a fundamental idea or because the correct \u201cparts\u201d have not been tuned correctly, assembled at sufficient scale, or provided with enough training. Here, we present a high-throughput approach to the exploration of such parameter sets, leveraging recent advances in stream processing hardware (high-end NVIDIA graphic cards and the PlayStation 3's IBM Cell Processor). In analogy to high-throughput screening approaches in molecular biology and genetics, we explored thousands of potential network architectures and parameter instantiations, screening those that show promising object recognition performance for further analysis. We show that this approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature. As the scale of available computational power continues to expand, we argue that this approach has the potential to greatly accelerate progress in both artificial vision and our understanding of the computational underpinning of biological vision."
            },
            "slug": "A-High-Throughput-Screening-Approach-to-Discovering-Pinto-Doukhan",
            "title": {
                "fragments": [],
                "text": "A High-Throughput Screening Approach to Discovering Good Forms of Biologically Inspired Visual Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature."
            },
            "venue": {
                "fragments": [],
                "text": "PLoS Comput. Biol."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243801"
                        ],
                        "name": "Jim Mutch",
                        "slug": "Jim-Mutch",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Mutch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Mutch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 146
                            }
                        ],
                        "text": "\u2026cortex justify the use of such filters in the so-called standard model for object recognition [Riesenhuber and Poggio, 1999; Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks\n(CNNs) [LeCun et al., 1998; Behnke, 2003;\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 147
                            }
                        ],
                        "text": "\u2026cortex justify the use of such filters in the so-called standard model for object recognition [Riesenhuber and Poggio, 1999; Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks\n(CNNs) [LeCun et al., 1998; Behnke, 2003; Simard\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2640801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2355a243662cb2379cc3e2949d7455c2d6510ac3",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the role of sparsity and localized features in a biologically-inspired model of visual object classification. As in the model of Serre, Wolf, and Poggio, we first apply Gabor filters at all positions and scales; feature complexity and position/scale invariance are then built up by alternating template matching and max pooling operations. We refine the approach in several biologically plausible ways. Sparsity is increased by constraining the number of feature inputs, lateral inhibition, and feature selection. We also demonstrate the value of retaining some position and scale information above the intermediate feature level. Our final model is competitive with current computer vision algorithms on several standard datasets, including the Caltech 101 object categories and the UIUC car localization task. The results further the case for biologically-motivated approaches to object classification."
            },
            "slug": "Object-Class-Recognition-and-Localization-Using-Mutch-Lowe",
            "title": {
                "fragments": [],
                "text": "Object Class Recognition and Localization Using Sparse Features with Limited Receptive Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work investigates the role of sparsity and localized features in a biologically-inspired model of visual object classification and demonstrates the value of retaining some position and scale information above the intermediate feature level."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49104973"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 126
                            }
                        ],
                        "text": "Our 19.51% error rate is better than the previous state of the art for this dataset, 20.40% [Coates et al., 2010] and 25.50% [Yu and Zhang, 2010]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "50% [Yu and Zhang, 2010]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2419778,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5ee556c355392db1750df92ae2dc8867073e771",
            "isKey": true,
            "numCitedBy": 162,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Local Coordinate Coding (LCC), introduced in (Yu et al., 2009), is a high dimensional nonlinear learning method that explicitly takes advantage of the geometric structure of the data. Its successful use in the winning system of last year's Pascal image classification Challenge (Everingham, 2009) shows that the ability to integrate geometric information is critical for some real world machine learning applications. This paper further develops the idea of integrating geometry in machine learning by extending the original LCC method to include local tangent directions. These new correction terms lead to better approximation of high dimensional nonlinear functions when the underlying data manifold is locally relatively flat. The method significantly reduces the number of anchor points needed in LCC, which not only reduces computational cost, but also improves prediction performance. Experiments are included to demonstrate that this method is more effective than the original LCC method on some image classification tasks."
            },
            "slug": "Improved-Local-Coordinate-Coding-using-Local-Yu-Zhang",
            "title": {
                "fragments": [],
                "text": "Improved Local Coordinate Coding using Local Tangents"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper further develops the idea of integrating geometry in machine learning by extending the original LCC method to include local tangent directions to lead to better approximation of high dimensional nonlinear functions when the underlying data manifold is locally relatively flat."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90841478"
                        ],
                        "name": "Y-Lan Boureau",
                        "slug": "Y-Lan-Boureau",
                        "structuredName": {
                            "firstName": "Y-Lan",
                            "lastName": "Boureau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y-Lan Boureau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 96
                            }
                        ],
                        "text": "A theoretical analysis of feature pooling in general and max-pooling in particular is given by [Boureau et al., 2010]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2167514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "405aed4b8ecdd869b2e83095dde51c396334115f",
            "isKey": false,
            "numCitedBy": 1131,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Many modern visual recognition algorithms incorporate a step of spatial 'pooling', where the outputs of several nearby feature detectors are combined into a local or global 'bag of features', in a way that preserves task-related information while removing irrelevant details. Pooling is used to achieve invariance to image transformations, more compact representations, and better robustness to noise and clutter. Several papers have shown that the details of the pooling operation can greatly influence the performance, but studies have so far been purely empirical. In this paper, we show that the reasons underlying the performance of various pooling methods are obscured by several confounding factors, such as the link between the sample cardinality in a spatial pool and the resolution at which low-level features have been extracted. We provide a detailed theoretical analysis of max pooling and average pooling, and give extensive empirical comparisons for object recognition tasks."
            },
            "slug": "A-Theoretical-Analysis-of-Feature-Pooling-in-Visual-Boureau-Ponce",
            "title": {
                "fragments": [],
                "text": "A Theoretical Analysis of Feature Pooling in Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the reasons underlying the performance of various pooling methods are obscured by several confounding factors, such as the link between the sample cardinality in a spatial pool and the resolution at which low-level features have been extracted."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128145"
                        ],
                        "name": "Lior Wolf",
                        "slug": "Lior-Wolf",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lior Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 260426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "040c23e5a409fbdedd5032263dfcb1a4d7dfd200",
            "isKey": false,
            "numCitedBy": 969,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex."
            },
            "slug": "Object-recognition-with-features-inspired-by-visual-Serre-Wolf",
            "title": {
                "fragments": [],
                "text": "Object recognition with features inspired by visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex and exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 225
                            }
                        ],
                        "text": "Unsupervised learning methods applied to patches of natural images tend to produce localized filters that resemble off-center-on-surround filters, orientation-sensitive bar detectors, Gabor filters [Schmidhuber et al., 1996; Olshausen and Field, 1997; Hoyer and Hyva\u0308rinen, 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14208692,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2805537bec87a6177037b18f9a3a9d3f1038867b",
            "isKey": false,
            "numCitedBy": 3574,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sparse-coding-with-an-overcomplete-basis-set:-A-by-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Sparse coding with an overcomplete basis set: A strategy employed by V1?"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983976"
                        ],
                        "name": "M. Eldracher",
                        "slug": "M.-Eldracher",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Eldracher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Eldracher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51073406"
                        ],
                        "name": "Bernhard Foltin",
                        "slug": "Bernhard-Foltin",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Foltin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard Foltin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 199
                            }
                        ],
                        "text": "Unsupervised learning methods applied to patches of natural images tend to produce localized filters that resemble off-center-on-surround filters, orientation-sensitive bar detectors, Gabor filters [Schmidhuber et al., 1996; Olshausen and Field, 1997; Hoyer and Hyva\u0308rinen, 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 198
                            }
                        ],
                        "text": "Unsupervised learning methods applied to patches of natural images tend to produce localized filters that resemble off-center-on-surround filters, orientation-sensitive bar detectors, Gabor filters [Schmidhuber et al., 1996; Olshausen and Field, 1997; Hoyer and Hyv\u00e4rinen, 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16154391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bf2479e607ff547012b54dab3f35dc01613ef86",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Predictability minimization (PMSchmidhuber 1992) exhibits various intuitive and theoretical advantages over many other methods for unsupervised redundancy reduction. So far, however, there have not been any serious practical applications of PM. In this paper, we apply semilinear PM to static real world images and find that without a teacher and without any significant preprocessing, the system automatically learns to generate distributed representations based on well-known feature detectors, such as orientation-sensitive edge detectors and off-centeron-surround detectors, thus extracting simple features related to those considered useful for image preprocessing and compression."
            },
            "slug": "Semilinear-Predictability-Minimization-Produces-Schmidhuber-Eldracher",
            "title": {
                "fragments": [],
                "text": "Semilinear Predictability Minimization Produces Well-Known Feature Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper applies semilinear PM to static real world images and finds that without a teacher and without any significant preprocessing, the system automatically learns to generate distributed representations based on well-known feature detectors, thus extracting simple features related to those considered useful for image preprocessing and compression."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211061"
                        ],
                        "name": "P. Hoyer",
                        "slug": "P.-Hoyer",
                        "structuredName": {
                            "firstName": "Patrik",
                            "lastName": "Hoyer",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791548"
                        ],
                        "name": "A. Hyv\u00e4rinen",
                        "slug": "A.-Hyv\u00e4rinen",
                        "structuredName": {
                            "firstName": "Aapo",
                            "lastName": "Hyv\u00e4rinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hyv\u00e4rinen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 252
                            }
                        ],
                        "text": "Unsupervised learning methods applied to patches of natural images tend to produce localized filters that resemble off-center-on-surround filters, orientation-sensitive bar detectors, Gabor filters [Schmidhuber et al., 1996; Olshausen and Field, 1997; Hoyer and Hyva\u0308rinen, 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 959667,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "032bb6ea9b99b3adb9b7f0e45a62c9f37f9e1bc5",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 148,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work has shown that independent component analysis (ICA) applied to feature extraction from natural image data yields features resembling Gabor functions and simple-cell receptive fields. This article considers the effects of including chromatic and stereo information. The inclusion of colour leads to features divided into separate red/green, blue/yellow, and bright/dark channels. Stereo image data, on the other hand, leads to binocular receptive fields which are tuned to various disparities. The similarities between these results and the observed properties of simple cells in the primary visual cortex are further evidence for the hypothesis that visual cortical neurons perform some type of redundancy reduction, which was one of the original motivations for ICA in the first place. In addition, ICA provides a principled method for feature extraction from colour and stereo images; such features could be used in image processing operations such as denoising and compression, as well as in pattern recognition."
            },
            "slug": "Independent-component-analysis-applied-to-feature-Hoyer-Hyv\u00e4rinen",
            "title": {
                "fragments": [],
                "text": "Independent component analysis applied to feature extraction from colour and stereo images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The similarities between these results and the observed properties of simple cells in the primary visual cortex are further evidence for the hypothesis that visual cortical neurons perform some type of redundancy reduction, which was one of the original motivations for ICA in the first place."
            },
            "venue": {
                "fragments": [],
                "text": "Network"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 152
                            }
                        ],
                        "text": "\u2026Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks\n(CNNs) [LeCun et al., 1998; Behnke, 2003; Simard et al., 2003], whose weights (filters) are randomly initialized and changed in a supervised way using back-propagation (BP)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1304548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43b87f5f4da973a513eaddb779032f0ceacfa394",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 267,
            "paperAbstract": {
                "fragments": [],
                "text": "I. Theory.- Neurobiological Background.- Related Work.- Neural Abstraction Pyramid Architecture.- Unsupervised Learning.- Supervised Learning.- II. Applications.- Recognition of Meter Values.- Binarization of Matrix Codes.- Learning Iterative Image Reconstruction.- Face Localization.- Summary and Conclusions."
            },
            "slug": "Hierarchical-Neural-Networks-for-Image-Behnke",
            "title": {
                "fragments": [],
                "text": "Hierarchical Neural Networks for Image Interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The results show clear trends in the direction of improvement in the level of supervised learning in relation to the recognition of meter values and in the application of Matrix Codes."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206775608,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "69e68bfaadf2dccff800158749f5a50fe82d173b",
            "isKey": false,
            "numCitedBy": 3718,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname \u201cneocognitron\u201d. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of \u201cS-cells\u201d, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of \u201cC-cells\u201d similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any \u201cteacher\u201d during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern."
            },
            "slug": "Neocognitron:-A-self-organizing-neural-network-for-Fukushima",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A neural network model for a mechanism of visual pattern recognition that is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity of their shapes without affected by their positions."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996960"
                        ],
                        "name": "M. Riesenhuber",
                        "slug": "M.-Riesenhuber",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Riesenhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riesenhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 148
                            }
                        ],
                        "text": "\u2026conjunction with experimental studies of the visual cortex justify the use of such filters in the so-called standard model for object recognition [Riesenhuber and Poggio, 1999; Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 8920227,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "85abadb689897997f1e37baa7b5fc6f7d497518b",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function."
            },
            "slug": "Hierarchical-models-of-object-recognition-in-cortex-Riesenhuber-Poggio",
            "title": {
                "fragments": [],
                "text": "Hierarchical models of object recognition in cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions is described."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2204972"
                        ],
                        "name": "M. V. Rossum",
                        "slug": "M.-V.-Rossum",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Rossum",
                            "middleNames": [
                                "C.",
                                "W.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. V. Rossum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 66
                            }
                        ],
                        "text": "A 0.35% error rate was recently also obtained by a big, deep MLP [Ciresan et al., 2010] with many more free parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 83
                            }
                        ],
                        "text": "These deformations improve recognition rates for digits that are intrinsically 2D [Ciresan et al., 2010], but seem inadequate for 3D objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 61
                            }
                        ],
                        "text": "35% error rate was recently also obtained by a big, deep MLP [Ciresan et al., 2010] with many more free parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2281536,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6",
            "isKey": true,
            "numCitedBy": 1657,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "Lecture Notes for the MSc/DTC module. The brain is a complex computing machine which has evolved to give the ttest output to a given input. Neural computation has as goal to describe the function of the nervous system in mathematical and computational terms. By analysing or simulating the resulting equations, one can better understand its function, research how changes in parameters would eect the function, and try to mimic the nervous system in hardware or software implementations. Neural Computation is a bit like physics, that has been successful in describing numerous physical phenomena. However, approaches developed in those elds not always work for neural computation, because: 1. Physical systems are best studied in reduced, simplied circumstances, but the nervous system is hard to study in isolation. Neurons require a narrow range of operating conditions (temperature, oxygen, presence of other neurons, ion concentrations, ...) under which they work as they should. These conditions are hard to reproduce outside the body. Secondly, the neurons form a highly interconnected network. The function of the nervous systems depends on this connectivity and interaction, by trying to isolate the components, you are likely to alter the function. 2. It is not clear how much detail one needs to describe the computations in the brain. In these lectures we shall see various description levels. 3. Neural signals and neural connectivity are hard to measure, especially, if disturbance and damage to the nervous system is to be kept minimal. Perhaps Neural Computation has more in common with trying to gure out how a complicated machine, such as a computer or car works. Knowledge of the basic physics helps, but is not sucient. Luckily there are factors which perhaps make understanding the brain easier than understanding an arbitrary complicated machine: 1. There is a high degree of conservation across species. This means that animal studies can be used to gain information about the human brain. Furthermore, study of, say, the visual system might help to understand the auditory system. 2. The nervous system is able to develop by combining on one hand a only limited amount of genetic information and, on the other hand, the input it receives. Therefore it might be possible to nd the organising principles and develop a brain from there. This would be easier than guring out the complete 'wiring diagram'. 3. The nervous system is exible and robust, neurons die everyday. This stands \u2026"
            },
            "slug": "Neural-Computation-Rossum",
            "title": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The nervous system is able to develop by combining on one hand a only limited amount of genetic information and, on the other hand, the input it receives, and it might be possible to develop a brain from there."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "CNNs are hierarchical neural networks whose convolutional layers alternate with subsampling layers, reminiscent of simple and complex cells in the primary visual cortex [Wiesel and Hubel, 1959]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14801990,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6f20e254e3993538c79e0ff2b9b8f198d3359cb3",
            "isKey": false,
            "numCitedBy": 4215,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In the central nervous system the visual pathway from retina to striate cortex provides an opportunity to observe and compare single unit responses at several distinct levels. Patterns of light stimuli most effective in influencing units at one level may no longer be the most effective at the next. From differences in responses at successive stages in the pathway one may hope to gain some understanding of the part each stage plays in visual perception. By shining small spots of light on the light-adapted cat retina Kuffler (1953) showed that ganglion cells have concentric receptive fields, with an 'on' centre and an 'off ' periphery, or vice versa. The 'on' and 'off' areas within a receptive field were found to be mutually antagonistic, and a spot restricted to the centre of the field was more effective than one covering the whole receptive field (Barlow, FitzHugh & Kuffler, 1957). In the freely moving lightadapted cat it was found that the great majority of cortical cells studied gave little or no response to light stimuli covering most of the animal's visual field, whereas small spots shone in a restricted retinal region often evoked brisk responses (Hubel, 1959). A moving spot of light often produced stronger responses than a stationary one, and sometimes a moving spot gave more activation for one direction than for the opposite. The present investigation, made in acute preparations, includes a study of receptive fields of cells in the cat's striate cortex. Receptive fields of the cells considered in this paper were divided into separate excitatory and inhibitory ('on' and 'off') areas. In this respect they resembled retinal ganglion-cell receptive fields. However, the shape and arrangement of excitatory and inhibitory areas differed strikingly from the concentric pattern found in retinal ganglion cells. An attempt was made to correlate responses to moving stimuli"
            },
            "slug": "Receptive-fields-of-single-neurones-in-the-cat's-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Receptive fields of single neurones in the cat's striate cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present investigation, made in acute preparations, includes a study of receptive fields of cells in the cat's striate cortex, which resembled retinal ganglion-cell receptive fields, but the shape and arrangement of excitatory and inhibitory areas differed strikingly from the concentric pattern found in retinalganglion cells."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144500726"
                        ],
                        "name": "A. Karimi",
                        "slug": "A.-Karimi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Karimi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Karimi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8591486,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79c24e7d31afe659fd42f5a72f8547bc83c49501",
            "isKey": false,
            "numCitedBy": 4614,
            "numCiting": 411,
            "paperAbstract": {
                "fragments": [],
                "text": "Web mediated communications revolutionized traditional social interactions. It is designed to facilitate information exchange between individuals and to enable people to connect with friends, family, classmates etc. virtually. By the formation of virtual communities, \u201cweb mediated communication\u201d is defined as a wider concept known as \u201csocial media\u201d. Social media enhances the volume of communications and interpersonal interactions based on the power of web 2.0 technology. People join to the virtual communities of online social networks to procure information from everywhere, share ideas, experiences, photos, videos and memorable moments while extending friendships beyond the geographical and cultural borders. The emergence and fast growth of social media among people added value to the web activities and convinced web masters to integrate web services such as e-mail, chat, discussion rooms, forums and third party applications to the social media web sites. Many of social media web sites are hosting millions of members, equipping their web sites with communication tools, sharing options, dynamic content creation and collaborative authoring facilities which never experienced before. Facebook, Twitter and GooglePlus are examples of most known social media web sites which gained popularity among people so fast. Social media helps people to make new friends, find lost friends and old classmates while providing an opportunity to build new friendships. This new communication technology empowers people to collaborate in authoring of the web content and causes the information sharing synergy. Such positive aspects are enough for people to ignore the consequences of joining social media. Despite the rise of friendships in number, the physical encounters are substituted by virtual ones which causes weak friendship ties. In addition, social media platforms promise the security and privacy of users, but issues such as identity theft and worm attacks threaten users' privacy and security. Social media is in its infancy, adopted among people for less than a decade whereas a lack of research in this field is evident. The author of this thesis aimed at filling this gap by investigating the positive and negative effects of using social media through collecting the users' experiences and professionals' viewpoints. Theoretical study primarily illuminated the main positive and negative aspects while the findings of empirical research verified by theoretical study identified other practical effects and aspects of social media."
            },
            "slug": "MASTER\u2019S-THESIS-Karimi",
            "title": {
                "fragments": [],
                "text": "MASTER\u2019S THESIS"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The author of this thesis aimed at investigating the positive and negative effects of using social media through collecting the users' experiences and professionals' viewpoints, and identified other practical effects and aspects of social media."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51921883"
                        ],
                        "name": "Refractor",
                        "slug": "Refractor",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Refractor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Refractor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 164
                            }
                        ],
                        "text": "These findings in conjunction with experimental studies of the visual cortex justify the use of such filters in the so-called standard model for object recognition [Riesenhuber and Poggio, 1999; Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks (CNNs) [LeCun et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 208793436,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "c3a24b0b38922c4f3a825edb97cc470a4ca7af75",
            "isKey": false,
            "numCitedBy": 3113,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-Refractor",
            "title": {
                "fragments": [],
                "text": "Vision"
            },
            "venue": {
                "fragments": [],
                "text": "The Lancet"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "On MNIST the best network achieved a recognition test error rate of 0.35%, on NORB 2.53% and on CIFAR10 19.51%."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 8
                            }
                        ],
                        "text": "For the MNIST dataset the networks are trained on deformed images, continually generated in on-line fashion."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 94
                            }
                        ],
                        "text": "Each\nneuron\u2019s activation function is a scaled hyperbolic tangent: y(a) = 1.7159 tanh(0.6666a) [LeCun et al., 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 71
                            }
                        ],
                        "text": "We evaluate various networks on the handwritten digit benchmark MNIST [LeCun et al., 1998] and two image classification benchmarks: NORB [LeCun et al., 2004] and CIFAR10 [Krizhevsky, 2009]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 4
                            }
                        ],
                        "text": "For MNIST and CIFAR10 such pre-processing has little or no effect."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 69
                            }
                        ],
                        "text": "We applied our networks to benchmark datasets for digit recognition (MNIST), 3D object recognition (NORB), and natural images (CIFAR10)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 149
                            }
                        ],
                        "text": "\u2026and Poggio, 1999; Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks\n(CNNs) [LeCun et al., 1998; Behnke, 2003; Simard et al., 2003], whose weights (filters) are randomly initialized and changed in a supervised way using\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 9
                            }
                        ],
                        "text": "Like for MNIST, the learning rate is initialized by 0.001 and multiplied by 0.993 after every epoch."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 82
                            }
                        ],
                        "text": "We reduce the number of connections between convolutional layers in a random way [LeCun et al., 1998; Jarrett et al., 2009]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 117
                            }
                        ],
                        "text": ", 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks (CNNs) [LeCun et al., 1998; Behnke, 2003; Simard et al., 2003], whose weights (filters) are randomly initialized and changed in a supervised way using back-propagation (BP)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 50
                            }
                        ],
                        "text": "Initial experiments on NORB show that unlike with MNIST where we use deformations, the CNN needs only 3 to 6 epochs to reach zero validation error."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 80
                            }
                        ],
                        "text": "The biggest architectural difference between our implementation and the CNN of [LeCun et al., 1998] is the use of a max-pooling layer instead of a sub-sampling layer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 32
                            }
                        ],
                        "text": "The best previous CNN result on MNIST is 0.40% [Simard et al., 2003]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 70
                            }
                        ],
                        "text": "We evaluate various networks on the handwritten digit benchmark MNIST [LeCun et al., 1998] and two image classification benchmarks: NORB [LeCun et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "86(11):2278\u20132324"
            },
            "venue": {
                "fragments": [],
                "text": "November"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "CNNs vary in how convolutional and subsampling layers are realized and how the nets are trained."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "CNNs are hierarchical neural networks whose convolutional layers alternate with subsampling layers, reminiscent of simple and complex cells in the primary visual cortex [Wiesel and Hubel, 1959]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Our implementation allows for training large CNNs within days instead of months, such that we can investigate the influence of various structural parameters by exploring large parameter spaces [Pinto et al., 2009] and performing error analysis on repeated experiments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "The implemented CNN\u2019s plain feed-forward architecture is trained using on-line gradient descent."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "Fully connected convolutional layers lead to an exploding number of network connections and weights, making training of big and deep CNNs for hundreds of epochs impractical even on GPUs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "With additional translations of at most 5%, the average error rate drops to 4.71%, contradicting the common belief that CNNs are translation invariant."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 87
                            }
                        ],
                        "text": "Previous GPU implementations of CNNs [Chellapilla et al., 2006; Uetz and Behnke, 2009; Strigl et al., 2010] were hard-coded to satisfy GPU hardware constraints or use general purpose libraries, whereas our implementation is flexible and fully online (i.e., weight updates after each image)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 37
                            }
                        ],
                        "text": "Previous GPU implementations of CNNs [Chellapilla et al., 2006; Uetz and Behnke, 2009; Strigl et al., 2010] were hard-coded to satisfy GPU hardware constraints or use general purpose libraries, whereas our implementation is flexible and fully online (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 322,
                                "start": 318
                            }
                        ],
                        "text": "These findings in conjunction with experimental studies of the visual cortex justify the use of such filters in the so-called standard model for object recognition [Riesenhuber and Poggio, 1999; Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks\n(CNNs) [LeCun et al., 1998; Behnke, 2003; Simard et al., 2003], whose weights (filters) are randomly initialized and changed in a supervised way using back-propagation (BP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Good results require big and deep but sparsely connected CNNs, computationally prohibitive on CPUs, but feasible on current GPUs, where our implementation is 10 to 60 times faster than a compileroptimized CPU version."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "The tested CNNs differ only in the number of maps per convolutional and max-pooling layer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "These results are on par or better than others in the literature: 5.90% error rate for a combination of CNNs and SVMs [LeCun et al., 2004] and 5.20% error rate for restricted Boltzman machines [Nair and Hinton, 2009]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In 18th Euromicro Conference on Parallel"
            },
            "venue": {
                "fragments": [],
                "text": "Distributed, and Network-Based Processing,"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 50
                            }
                        ],
                        "text": "90% error rate for a combination of CNNs and SVMs [LeCun et al., 2004] and 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 119
                            }
                        ],
                        "text": "These results are on par or better than others in the literature: 5.90% error rate for a combination of CNNs and SVMs [LeCun et al., 2004] and 5.20% error rate for restricted Boltzman machines [Nair and Hinton, 2009]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "We evaluate various networks on the handwritten digit benchmark MNIST [LeCun et al., 1998] and two image classification benchmarks: NORB [LeCun et al., 2004] and CIFAR10 [Krizhevsky, 2009]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 54
                            }
                        ],
                        "text": ", 1998] and two image classification benchmarks: NORB [LeCun et al., 2004] and CIFAR10 [Krizhevsky, 2009]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of Computer Vision and Pattern Recognition Conference,"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 151
                            }
                        ],
                        "text": "\u2026Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks\n(CNNs) [LeCun et al., 1998; Behnke, 2003; Simard et al., 2003], whose weights (filters) are randomly initialized and changed in a supervised way using back-propagation (BP)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 59703313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46d2216289fa276811c09234ac09215c450bc820",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hierarchical-Neural-Networks-for-Image-(Lecture-in-Behnke",
            "title": {
                "fragments": [],
                "text": "Hierarchical Neural Networks for Image Interpretation (Lecture Notes in Computer Science)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 254
                            }
                        ],
                        "text": "Unsupervised learning methods applied to patches of natural images tend to produce localized filters that resemble off-center-on-surround filters, orientation-sensitive bar detectors, Gabor filters [Schmidhuber et al., 1996; Olshausen and Field, 1997; Hoyer and Hyva\u0308rinen, 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Independent component analysis applied to feature extraction from colour and stero images"
            },
            "venue": {
                "fragments": [],
                "text": "Network: Computation in Neural Systems"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kunihiko Fukushima. Neocognitron for handwritten digit recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 81
                            }
                        ],
                        "text": "We reduce the number of connections between convolutional layers in a random way [LeCun et al., 1998; Jarrett et al., 2009]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 23
                            }
                        ],
                        "text": "A notable exception is [Jarrett et al., 2009] who performed a thorough analysis of the influence of all building blocks of a multistage architecture on recognition performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Marc\u2019Aurelio Ranzato"
            },
            "venue": {
                "fragments": [],
                "text": "and Yann LeCun. What is the best multi-stage architecture for object recognition? In Proc. International Conference on Computer Vision,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 198
                            }
                        ],
                        "text": "Unsupervised learning methods applied to patches of natural images tend to produce localized filters that resemble off-center-on-surround filters, orientation-sensitive bar detectors, Gabor filters [Schmidhuber et al., 1996; Olshausen and Field, 1997; Hoyer and Hyv\u00e4rinen, 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Network: Computation in Neural Systems"
            },
            "venue": {
                "fragments": [],
                "text": "11(3):191\u2013210,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hoyer and Aapo Hyv\u00e4rinen . Independent component analysis applied to feature extraction from colour and stero images"
            },
            "venue": {
                "fragments": [],
                "text": "Network : Computation in Neural Systems"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 194
                            }
                        ],
                        "text": "Our implementation allows for training large CNNs within days instead of months, such that we can investigate the influence of various structural parameters by exploring large parameter spaces [Pinto et al., 2009] and performing error analysis on repeated experiments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "5(11):e1000579"
            },
            "venue": {
                "fragments": [],
                "text": "November"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 117
                            }
                        ],
                        "text": ", 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks (CNNs) [LeCun et al., 1998; Behnke, 2003; Simard et al., 2003], whose weights (filters) are randomly initialized and changed in a supervised way using back-propagation (BP)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "volume 2766 of Lecture Notes in Computer Science"
            },
            "venue": {
                "fragments": [],
                "text": "Springer,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 164
                            }
                        ],
                        "text": "These findings in conjunction with experimental studies of the visual cortex justify the use of such filters in the so-called standard model for object recognition [Riesenhuber and Poggio, 1999; Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks (CNNs) [LeCun et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 148
                            }
                        ],
                        "text": "\u2026studies of the visual cortex justify the use of such filters in the so-called standard model for object recognition [Riesenhuber and Poggio, 1999; Serre et al., 2007; Mutch and Lowe, 2008], whose filters are fixed, in contrast to those of Convolutional Neural Networks\n(CNNs) [LeCun et al., 1998;\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of Computer Vision and Pattern Recognition Conference,"
            },
            "year": 2007
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 17,
            "result": 13
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 42,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Flexible,-High-Performance-Convolutional-Neural-for-Ciresan-Meier/5a47ba057a858f8c024d2518cc3731fc7eb40de1?sort=total-citations"
}