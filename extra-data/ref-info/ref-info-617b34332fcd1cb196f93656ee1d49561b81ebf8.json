{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4754199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a393ad864f6fe95002e8d4412f3ebe5c42f699d6",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a technique for finding pixelwise correspondences between two images by using models of objects of the same class to guide the search. The object models are \"learned\" from example images (also called prototypes) of an object class. The models consist of a linear combination of prototypes. The flow fields giving pixelwise correspondences between a base prototype and each of the other prototypes must be given. A novel image of an object of the same class is matched to a model by minimizing an error between the novel image and the current guess for the closest model image. Currently, the algorithm applies to line drawings of objects. An extension to real grey level images is discussed.<<ETX>>"
            },
            "slug": "Model-based-matching-of-line-drawings-by-linear-of-Jones-Poggio",
            "title": {
                "fragments": [],
                "text": "Model-based matching of line drawings by linear combinations of prototypes"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A technique for finding pixelwise correspondences between two images by using models of objects of the same class to guide the search, which applies to line drawings of objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3893740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82962da5c273a9e6627a040d56c8a7973fe22440",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this note we discuss how recognition can be achieved from a single 2D model view exploiting prior knowledge of an object''s structure (e.g. symmetry). We prove that for any bilaterally symmetric 3D object one non- accidental 2D model view is sufficient for recognition. Symmetries of higher order allow the recovery of structure from one 2D view. Linear transformations can be learned exactly from a small set of examples in the case of \"linear object classes\" and used to produce new views of an object from a single view."
            },
            "slug": "Recognition-and-Structure-from-one-2D-Model-View:-Poggio-Vetter",
            "title": {
                "fragments": [],
                "text": "Recognition and Structure from one 2D Model View: Observations on Prototypes, Object Classes and Symmetries"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proved that for any bilaterally symmetric 3D object one non- accidental 2D model view is sufficient for recognition and linear transformations can be learned exactly from a small set of examples in the case of \"linear object classes\"."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 25628199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c6dce15657b09846726dc1e3e442f5033503be0",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "According to the 1.5-views theorem (Poggio, Technical Report #9005-03, IRST, Povo, 1990; Ullman and Basri, IEEE Trans. PAMI 13, 992-1006, 1991) recognition of a specific 3D object (defined in terms of pointwise features) from a novel 2D view can be achieved from at least two 2D model views (for each object, for orthographic projection). This note considers how recognition can be achieved from a single 2D model view by exploiting prior knowledge of an object's symmetry. It is proved that, for any bilaterally symmetric 3D object, one non-accidental 2D model view is sufficient for recognition since it can be used to generate additional 'virtual' views. It is also proved that, for bilaterally symmetric objects, the correspondence of four points between two views determines the correspondence of all other points. Symmetries of higher order allow the recovery of Euclidean structure from a single 2D view."
            },
            "slug": "Symmetric-3D-objects-are-an-easy-case-for-2D-object-Vetter-Poggio",
            "title": {
                "fragments": [],
                "text": "Symmetric 3D objects are an easy case for 2D object recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is proved that, for any bilaterally symmetric 3D object, one non-accidental 2D model view is sufficient for recognition since it can be used to generate additional 'virtual' views."
            },
            "venue": {
                "fragments": [],
                "text": "Spatial vision"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15242659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f731b6745d829241941307c3ebf163e90e200318",
            "isKey": false,
            "numCitedBy": 7909,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN."
            },
            "slug": "Active-Shape-Models-Their-Training-and-Application-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Active Shape Models-Their Training and Application"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes a method for building models by learning patterns of variability from a training set of correctly annotated images that can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747836"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3029110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf4019d3cac928a63409520026bbad0636c1e80",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-importance-of-symmetry-and-virtual-views-in-Vetter-Poggio",
            "title": {
                "fragments": [],
                "text": "The importance of symmetry and virtual views in three-dimensional object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Current Biology"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13151746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8abe2824f9851d3c465b1aa11849661430d60ca0",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Image analysis and graphics synthesis can be achieved with learning techniques using directly image examples without physically-based, 3D models. In our technique: -- the mapping from novel images to a vector of ``pose'''' and ``expression'''' parameters can be learned from a small set of example images using a function approximation technique that we call an {\\it analysis network}; -- the inverse mapping from input ``pose'''' and ``expression'''' parameters to output images can be synthesized from a small set of example images and used to produce new images using a similar {\\it synthesis network}. The techniques described here have several applications in computer graphics, special effects, interactive multimedia and very low bandwidth teleconferencing."
            },
            "slug": "Example-Based-Image-Analysis-and-Synthesis-Beymer-Shashua",
            "title": {
                "fragments": [],
                "text": "Example Based Image Analysis and Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The mapping from novel images to a vector of ``pose'''' and ``expression'''' parameters can be learned from a small set of example images using a function approximation technique that it analysis network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "We demonstrate the approach on artificial objects and then show preliminary evidence that the technique can effectively \u201crotate\u201d highresolution face images from a single 2D view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61001553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d34bac36fcaa3fa5bdc9d843a7fd0972649116b0",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that we can optimally represent the set of 2D images produced by the point features of a rigid 3D model as two lines in two high-dimensional spaces. We then decribe a working recognition system in which we represent these spaces discretely in a hash table. We can access this table at run time to find all the groups of model features that could match a group of image features, accounting for the effects of sensing error. We also use this representation of a model''s images to demonstrate significant new limitations of two other approaches to recognition: invariants, and non- accidental properties."
            },
            "slug": "A-Novel-Approach-to-Graphics-Poggio-Brunelli",
            "title": {
                "fragments": [],
                "text": "A Novel Approach to Graphics"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This work shows that it can optimally represent the set of 2D images produced by the point features of a rigid 3D model as two lines in two high-dimensional spaces, and decribes a working recognition system in which these spaces are represented discretely in a hash table."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 106
                            }
                        ],
                        "text": "However, if the class of objects is known in advance, a method speci c to this object class could be used [9, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13952915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34a823d412c2134f87ab4f5e8a87c8a203a08b5c",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The correspondence problem in computer vision is basically a matching task between two or more sets of features. In this paper, we introduce a vectorized image representation, which is a feature-based representation where correspondence has been established with respect to a reference image. This representation has two components: (1) shape, or (x, y) feature locations, and (2) texture, defined as the image grey levels mapped onto the standard reference image. This paper explores an automatic technique for ``vectorizing'''' face images. Our face vectorizer alternates back and forth between computation steps for shape and texture, and a key idea is to structure the two computations so that each one uses the output of the other. A hierarchical coarse-to-fine implementation is discussed, and applications are presented to the problems of facial feature detection and registration of two arbitrary faces."
            },
            "slug": "Vectorizing-Face-Images-by-Interleaving-Shape-and-Beymer",
            "title": {
                "fragments": [],
                "text": "Vectorizing Face Images by Interleaving Shape and Texture Computations"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper introduces a vectorized image representation, which is a feature-based representation where correspondence has been established with respect to a reference image, and explores an automatic technique for ``vectorizing'' face images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14814282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66505cb708b098a93331471f079965f6ded4ea7f",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "To create a pose-invariant face recognizer, one strategy is the view-based approach, which uses a set of real example views at different poses. But what if we only have one real view available, such as a scanned passport photo-can we still recognize faces under different poses? Given one real view at a known pose, it is still possible to use the view-based approach by exploiting prior knowledge of faces to generate virtual views, or views of the face as seen from different poses. To represent prior knowledge, we use 2D example views of prototype faces under different rotations. We develop example-based techniques for applying the rotation seen in the prototypes to essentially \"rotate\" the single real view which is available. Next, the combined set of one real and multiple virtual views is used as example views for a view-based, pose-invariant face recognizer. Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques.<<ETX>>"
            },
            "slug": "Face-recognition-from-one-example-view-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Face recognition from one example view"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684073"
                        ],
                        "name": "A. Hurlbert",
                        "slug": "A.-Hurlbert",
                        "structuredName": {
                            "firstName": "Anya",
                            "lastName": "Hurlbert",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hurlbert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Poggio and Vetter [6] examined, in particular, the case of bilateral symmetry of certain 3D objects such as faces."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "(compare Hurlbert and Poggio [15]) can be used to learn the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 35
                            }
                        ],
                        "text": "E-mail: vetter@mpik-tueb.mpg.de \u2022 T. Poggio is with the Center for Computational and Biological Learning at the Massachusetts Institute of Technology, Cambridge, Mass.\nE-mail: poggio@ai.mit.edu."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 97
                            }
                        ],
                        "text": "In this paper, we introduce such a technique by extending the notion of linear class proposed by Poggio and Vetter."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 150
                            }
                        ],
                        "text": "Key to our approach is a representation of an object view in terms of a shape vector and a texture vector (see [1] and also Beymer [10] and Jones and Poggio [11])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 54
                            }
                        ],
                        "text": "Although our approach originates from the proposal of Poggio and Brunelli [3], and of Poggio and Vetter [6], for countering the curse-of-dimensionality in applications of supervised learning techniques, similar approaches with different motivations have been used in several different fields."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "Beymer and Poggio [1] demonstrated that new textures of an object can be generated by linear combinations of textures of different objects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 208
                            }
                        ],
                        "text": "It also requires correspondence between the new image and one of the prototypes in the same pose, but does not need correspondence between different poses as required in the parallel deformation technique of Poggio and Brunelli [3] and Beymer et al. [2]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 21
                            }
                        ],
                        "text": "Beymer, Shashua, and Poggio [2], as well as Beymer and Poggio [1], have developed and demonstrated a more powerful version of this approach based on non-linear learning networks for generating new gray-level images of the same object or of objects of a known class."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 51
                            }
                        ],
                        "text": "In this case, a one-layer, linear network\n(compare Hurlbert and Poggio [15]) can be used to learn the transformation L."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19636254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a63f35c6f8ecf6491fccdcf0a1156ce61c2405a4",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A lightness algorithm that separates surface reflectance from illumination in a Mondrian world is synthesized automatically from a set of examples, which consist of pairs of input (intensity signal) and desired output (surface reflectance) images. The algorithm, which resembles a new lightness algorithm recently proposed by Land, is approximately equivalent to filtering the image through a center-surround receptive field in individual chromatic channels. The synthesizing technique, optimal linear estimation, requires only one assumption, that the operator that transforms input into output is linear. This assumption is true for a certain class of early vision algorithms that may therefore be synthesized in a similar way from examples. Other methods of synthesizing algorithms from examples, or \"learning,\" such as back-propagation, do not yield a significantly better lightness algorithm."
            },
            "slug": "Synthesizing-a-color-algorithm-from-examples.-Hurlbert-Poggio",
            "title": {
                "fragments": [],
                "text": "Synthesizing a color algorithm from examples."
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A lightness algorithm that separates surface reflectance from illumination in a Mondrian world is synthesized automatically from a set of examples, which consist of pairs of input and desired output (surface reflectance) images."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684073"
                        ],
                        "name": "A. Hurlbert",
                        "slug": "A.-Hurlbert",
                        "structuredName": {
                            "firstName": "Anya",
                            "lastName": "Hurlbert",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hurlbert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(compare Hurlbert and Poggio [ 15 ]) can be used to learn the transformation L. L can then transform a view of a novel object of the same class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 214792667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "584191fbcbe62bdaf6e1ed51c8a047e2c6348b54",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A lightness algorithm that separates surface reflectance from illumination in a Mondrian world is synthesized automatically from a set of examples, which consist of pairs of input (intensity signal) and desired output (surface reflectance) images. The algorithm, which resembles a new lightness algorithm recently proposed by Land, is approximately equivalent to filtering the image through a center-surround receptive field in individual chromatic channels. The synthesizing technique, optimal linear estimation, requires only one assumption, that the operator that transforms input into output is linear. This assumption is true for a certain class of early vision algorithms that may therefore be synthesized in a similar way from examples. Other methods of synthesizing algorithms from examples, or \"learning,\" such as back-propagation, do not yield a significantly better lightness algorithm."
            },
            "slug": "Synthesizing-a-color-algorithm-from-examples-Hurlbert-Poggio",
            "title": {
                "fragments": [],
                "text": "Synthesizing a color algorithm from examples"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A lightness algorithm that separates surface reflectance from illumination in a Mondrian world is synthesized automatically from a set of examples, which consist of pairs of input and desired output (surface reflectance) images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932365"
                        ],
                        "name": "N. Troje",
                        "slug": "N.-Troje",
                        "structuredName": {
                            "firstName": "Nikolaus",
                            "lastName": "Troje",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Troje"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747836"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Bilateral symmetry has been used in face recognition systems [1] and psychophysical evidence supports its use by the human visual system [7],[5],[8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our visual system is certainly able to perform this task\u2014even if at performance levels that are likely to be lower than expected from our introspection [4], [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13115909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53d415bf5018255f57d36108cfd9c8b8216d9d2f",
            "isKey": false,
            "numCitedBy": 435,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-recognition-under-varying-poses:-The-role-of-Troje-B\u00fclthoff",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying poses: The role of texture and shape"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "The orientation of faces can be approximated computing the correlation of a new image to templates of faces in various orientations [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2546027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e5949d95c53dd041c721bf40e67b3966805e385",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers in computer vision and pattern recognition have worked on automatic techniques for recognizing human faces for the last 20 years. While some systems, especially template-based ones, have been quite successful on expressionless, frontal views of faces with controlled lighting, not much work has taken face recognizers beyond these narrow imaging conditions. Our goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth. Building on successful template-based systems, our basic approach is to represent faces with templates from multiple model views that cover different poses from the viewing sphere. To recognize a novel view, the recognizer locates the eyes and nose features, uses these locations to geometrically register the input with model views, and then uses correlation on model templates to find the best match in the data base of people. Our system has achieved a recognition rate of 98% on a data base of 62 people containing 10 testing and 15 modeling views per person.<<ETX>>"
            },
            "slug": "Face-recognition-under-varying-pose-Beymer",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying pose"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684073"
                        ],
                        "name": "A. Hurlbert",
                        "slug": "A.-Hurlbert",
                        "structuredName": {
                            "firstName": "Anya",
                            "lastName": "Hurlbert",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hurlbert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2441722,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "3ee07fc62801c8e76c8d31292c120580b03b2176",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper sketches a hypothetical cortical architecture for visual 3D object recognition based on a recent computational model. The view-centered scheme relies on modules for learning from examples, such as Hyperbf-like networks. Such models capture a class of explanations we call Memory-Based Models (MBM) that contains sparse population coding, memory-based recognition, and codebooks of prototypes. Unlike the sigmoidal units of some artificial neural networks, the units of MBMs are consistent with the description of cortical neurons. We describe how an example of MBM may be realized in terms of cortical circuitry and biophysical mechanisms, consistent with psychophysical and physiological data."
            },
            "slug": "Observations-on-Cortical-Mechanisms-for-Object-and-Poggio-Hurlbert",
            "title": {
                "fragments": [],
                "text": "Observations on Cortical Mechanisms for Object Recognition and Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper sketches a hypothetical cortical architecture for visual 3D object recognition based on a recent computational model that contains sparse population coding, memory-based recognition, and codebooks of prototypes that is consistent with the description of cortical neurons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40019208"
                        ],
                        "name": "Thaddeus Beier",
                        "slug": "Thaddeus-Beier",
                        "structuredName": {
                            "firstName": "Thaddeus",
                            "lastName": "Beier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thaddeus Beier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094398048"
                        ],
                        "name": "Shawn Neely",
                        "slug": "Shawn-Neely",
                        "structuredName": {
                            "firstName": "Shawn",
                            "lastName": "Neely",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shawn Neely"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9124441,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "be73726c6a538bc3ed05e62ba5faec183f777ff6",
            "isKey": false,
            "numCitedBy": 833,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "2.1 Conventional Metamorphosis Techniques Mc[:ml(wpht)iii twlween lWo or mor\u2019c imafys (wer lime i) u uwi\u2019ul \\ i~u;ii tcchniquc. (Jflen uwd f\u2019orCducaliomd (n\u2019tMCid;liMll Cnt purpt>wi. \u20181\u2019l-:idi(ional Iilmmahing techniques for (his cflcc[ include ~\u2019lckcr c\u2019ut~(iuc\u2019h LISu chwwwr cxhibi(ing ch:mgm while running thr(mgll ;! toreil and prosing behind several trws ) tind op[ic:d cro\\\\diswdv<\u2019. in which onc image is f:ide(i out while wwther is sinwlt:lnLNNI\\l)f\u2019:idcdin (Mith makeup ch:mge. tippliwcm, or nhjecl subs[i [u[I(m ). Sc\\\u2019~\u2019riilclawic horror lilm~ illu$tfiite [he process: who ctwld hnycl ~hc b:lir-tai~ing (fiiniform;ilml of the Woitman. or the drw m:itic lllct;itll(~rpll(~sii from Dr. Jchyll [o Mr. Hyde\u2019? This pupcr prcwmls ii c(mtcnlp{mmy w~lu(i(mto the vi~u:d translonmrtion pnh lL\u2019nl."
            },
            "slug": "Feature-based-image-metamorphosis-Beier-Neely",
            "title": {
                "fragments": [],
                "text": "Feature-based image metamorphosis"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "2.1 Conventional Metamorphosis Techniques Mc[:ml(wpht)iii twlween lWo or mor\u2019c imafys (wer lime i) u uwi\u2019ul \\ i~u;ii tcchniquc."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1380483709"
                        ],
                        "name": "M. Medard",
                        "slug": "M.-Medard",
                        "structuredName": {
                            "firstName": "Muriel",
                            "lastName": "Medard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Medard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4153826,
            "fieldsOfStudy": [
                "Law"
            ],
            "id": "defd66114b63aae75e0af2bcff2e52ae8fd2c873",
            "isKey": false,
            "numCitedBy": 1752,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "WARNING NOTICE: The experiments described in these materials are potentially hazardous and require a high level ofsafety training, special facilities and equipment, and supervision by appropriate individuals. You bear the sole responsibility, liability, and risk for the implementation of such safety procedures and measures. MIT shall have no responsibility, liability, or risk for the content or implementation of any of the material presented. Legal Notices"
            },
            "slug": "Massachusetts-Institute-of-Technology-Medard",
            "title": {
                "fragments": [],
                "text": "Massachusetts Institute of Technology"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Poggio and Vetter [6] examined, in particular, the case of bilateral symmetry of certain 3D objects such as faces."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "Beymer, Shashua and Poggio [6] as well as Beymer and Poggio [5] have developed and demonstrated a more powerful version of this approach based on non-linear learning networks for generating new grey-level images of the same object or of objects of a known class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 44
                            }
                        ],
                        "text": "The technique is similar to the approach of [5, 6] but more powerful since it relies less on correspondence between prototypical examples and the new image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 35
                            }
                        ],
                        "text": "E-mail: vetter@mpik-tueb.mpg.de \u2022 T. Poggio is with the Center for Computational and Biological Learning at the Massachusetts Institute of Technology, Cambridge, Mass.\nE-mail: poggio@ai.mit.edu."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 238
                            }
                        ],
                        "text": "It also require correspondence between the new image and one of the prototypes in the same pose but does not need correspondence between di erent poses as in the parallel deformation technique of Poggio and Brunelli [11] and Beymer et al.[6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 97
                            }
                        ],
                        "text": "In this paper, we introduce such a technique by extending the notion of linear class proposed by Poggio and Vetter."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 150
                            }
                        ],
                        "text": "Key to our approach is a representation of an object view in terms of a shape vector and a texture vector (see [1] and also Beymer [10] and Jones and Poggio [11])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 54
                            }
                        ],
                        "text": "Although our approach originates from the proposal of Poggio and Brunelli [3], and of Poggio and Vetter [6], for countering the curse-of-dimensionality in applications of supervised learning techniques, similar approaches with different motivations have been used in several different fields."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "Beymer and Poggio [1] demonstrated that new textures of an object can be generated by linear combinations of textures of different objects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 91
                            }
                        ],
                        "text": "While the traditional approach relies on the use of 3D models, we have recently introduced [11, 6, 5] techniques that are applicable under restricted conditions but simpler."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 236
                            }
                        ],
                        "text": "It also requires correspondence between the new image and one of the prototypes in the same pose, but does not need correspondence between different poses as required in the parallel deformation technique of Poggio and Brunelli [3] and Beymer et al. [2]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 21
                            }
                        ],
                        "text": "Beymer, Shashua, and Poggio [2], as well as Beymer and Poggio [1], have developed and demonstrated a more powerful version of this approach based on non-linear learning networks for generating new gray-level images of the same object or of objects of a known class."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 64
                            }
                        ],
                        "text": "In this case, a one-layer, linear network\n(compare Hurlbert and Poggio [15]) can be used to learn the transformation L."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Examplebased image anaysis and synthesis"
            },
            "venue": {
                "fragments": [],
                "text": "A.I. Memo No. 1431,"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40019208"
                        ],
                        "name": "Thaddeus Beier",
                        "slug": "Thaddeus-Beier",
                        "structuredName": {
                            "firstName": "Thaddeus",
                            "lastName": "Beier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thaddeus Beier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094398048"
                        ],
                        "name": "Shawn Neely",
                        "slug": "Shawn-Neely",
                        "structuredName": {
                            "firstName": "Shawn",
                            "lastName": "Neely",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shawn Neely"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 86351869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f954137c1765a29685794eb0f901805c28e610ca",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-based-image-metamorphosis-Beier-Neely",
            "title": {
                "fragments": [],
                "text": "Feature-based image metamorphosis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vectorizing face images by i n terleaving shape and texture computations. to appear as A.I. Memo, Artiicial Intelligence Laboratory, M a s sachusetts Institute of Technology"
            },
            "venue": {
                "fragments": [],
                "text": "Vectorizing face images by i n terleaving shape and texture computations. to appear as A.I. Memo, Artiicial Intelligence Laboratory, M a s sachusetts Institute of Technology"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "We use a coarse-to-fine gradient-based method [13] and follow an implementation described in [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical, Computationally Efficient Motion Estimation Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "J. Opt. Soc. Am. A"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "To what extent can the recognition of unfamiliar faces be accounted for by a representation of the direct output of simple cell"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Examplebased image anaysis and synthesis. A.I. Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "Examplebased image anaysis and synthesis. A.I. Memo No"
            },
            "year": 1431
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical motionbased frame rate conversion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 137
                            }
                        ],
                        "text": "Bilateral symmetry has been used in face recognition systems [5] and psychophysical evidence supports its use by the human visual system [15, 13, 18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 154
                            }
                        ],
                        "text": "Our visual system is certainly able to perform this task { even if at performance levels that are likely to be lower than expected from our introspection [10, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "B\u007f  ultho"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A n o vel approach t o graphics"
            },
            "venue": {
                "fragments": [],
                "text": "A n o vel approach t o graphics"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical, computationally eecient motion estimation algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Hierarchical, computationally eecient motion estimation algorithm"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Example-based image anaysis and synthesis. A.I. Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "Example-based image anaysis and synthesis. A.I. Memo No"
            },
            "year": 1431
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 152
                            }
                        ],
                        "text": "Our visual system is certainly able to perform this task\u2014even if at performance levels that are likely to be lower than expected from our introspection [4], [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "To What Extent Can the Recognition of Unfamiliar Faces Be Accounted For by a Representation of the Direct Output of Simple Cell"
            },
            "venue": {
                "fragments": [],
                "text": "Ann. Meeting of the Assn. for Research in Vision and Ophthalmology"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition From One Model View"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Fifth Int'l Conf. Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Synthetizing a color algorithm from"
            },
            "venue": {
                "fragments": [],
                "text": "examples. SCIENCE,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "We use a coarse-to- ne gradient-based gradient method [2] and follow an implementation described in [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical motionbased frame rate conversion"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report, David Sarno Research Center Princeton NJ 08540,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "To what extent can the recognition of unfamiliar faces be accounted for by a representation of the direct output of simple cell"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sparse observations on cortical mechanisms for object recognition and learning. A.I. Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "Sparse observations on cortical mechanisms for object recognition and learning. A.I. Memo No"
            },
            "year": 1404
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Symmetric 3 D objects are an easy case for 2 D object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Spatial Vision ."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature - based imagemetamorphosis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Warping. Los Alamitos Calif"
            },
            "venue": {
                "fragments": [],
                "text": "Image Warping. Los Alamitos Calif"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theimportance of symmetry and virtual views inthreedimensional object recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition from one model view"
            },
            "venue": {
                "fragments": [],
                "text": "ICCV proceedings"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical , computationally e \u000e cient motion estimation algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 137
                            }
                        ],
                        "text": "Bilateral symmetry has been used in face recognition systems [5] and psychophysical evidence supports its use by the human visual system [15, 13, 18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "B\u007f  ultho"
            },
            "venue": {
                "fragments": [],
                "text": "Current Biology,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical , computationally e \u000e cient motion estimationalgorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Examplebased image anaysis and synthesis. A.I. Memo No. 1431, Artiicial Intelligence Laboratory, M a s sachusetts Institute of Technology"
            },
            "venue": {
                "fragments": [],
                "text": "Examplebased image anaysis and synthesis. A.I. Memo No. 1431, Artiicial Intelligence Laboratory, M a s sachusetts Institute of Technology"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "We use a coarse-to-fine gradient-based method [13] and follow an implementation described in [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical Motion-Based Frame Rate Conversion"
            },
            "venue": {
                "fragments": [],
                "text": "N.J"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying pose: The role of texture and shape. submitted"
            },
            "venue": {
                "fragments": [],
                "text": "Face recognition under varying pose: The role of texture and shape. submitted"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "We use a coarse-to- ne gradient-based gradient method [2] and follow an implementation described in [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical, computationally e cient motion estimation algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying pose. A.I. Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "Face recognition under varying pose. A.I. Memo No"
            },
            "year": 1461
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognitionfrom one model view"
            },
            "venue": {
                "fragments": [],
                "text": "ICCV proceedings"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 48,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Linear-Object-Classes-and-Image-Synthesis-From-a-Vetter-Poggio/617b34332fcd1cb196f93656ee1d49561b81ebf8?sort=total-citations"
}