{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679880"
                        ],
                        "name": "H. Wactlar",
                        "slug": "H.-Wactlar",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Wactlar",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wactlar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7661726"
                        ],
                        "name": "Alexander Hauptmann",
                        "slug": "Alexander-Hauptmann",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Hauptmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Hauptmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152736800"
                        ],
                        "name": "M. Smith",
                        "slug": "M.-Smith",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15208555"
                        ],
                        "name": "K. Pendyala",
                        "slug": "K.-Pendyala",
                        "structuredName": {
                            "firstName": "Krishna",
                            "lastName": "Pendyala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Pendyala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121795196"
                        ],
                        "name": "D. Garlington",
                        "slug": "D.-Garlington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Garlington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Garlington"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "[8] Zhang, H., et a.l, \u201cAutomatic Partitioning of Full-Motion Video,\u201d Multimedia Systems 1993 1, pp. 10-28."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61476392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08cd3d520bcddc037f3c405719c6c299f0d0afd8",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The Informedia Digital Video Library project is implementing full content search and retrieval from digital video, audio, and text libraries through the utilization of integrated speech, image, and language understanding technologies for automated creation and exploration. Image processing analyzes scenes, speech processing transcribes the audio signal, and natural language processing determines word relevance. Together, these generate a meaningful index into the video content. Segment breaks produced by image processing are examined, along with the boundaries identified by the natural language processing of the transcript to partition the video library into sets of segments, or video paragraphs. Automating these techniques into a unified collaborative system uniquely enables us to include and search through vast amounts of video data in the library with little to no human intervention."
            },
            "slug": "Automated-video-indexing-of-very-large-video-Wactlar-Hauptmann",
            "title": {
                "fragments": [],
                "text": "Automated video indexing of very large video libraries"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The Informedia Digital Video Library project is implementing full content search and retrieval from digital video, audio, and text libraries through the utilization of integrated speech, image, and language understanding technologies for automated creation and exploration."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13087918"
                        ],
                        "name": "F. Arman",
                        "slug": "F.-Arman",
                        "structuredName": {
                            "firstName": "Farshid",
                            "lastName": "Arman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Arman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2998944"
                        ],
                        "name": "R. Depommier",
                        "slug": "R.-Depommier",
                        "structuredName": {
                            "firstName": "Remi",
                            "lastName": "Depommier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Depommier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46891469"
                        ],
                        "name": "A. Hsu",
                        "slug": "A.-Hsu",
                        "structuredName": {
                            "firstName": "Arding",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957701"
                        ],
                        "name": "M. Chiu",
                        "slug": "M.-Chiu",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Chiu",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chiu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[14] Smallman, K., \u201cCreative Film-Making\u201d, 1st ed., Publisher Macmillan, New York 1970."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1360834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9895be389b31013b477e3bb48a006ad5c73f3a14",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel methodology to represent the contents of a video sequence is presented. The representation is used to allow the user to rapidly view a video sequence in order to find a particular point within the sequence and/or to decide whether the contents of the sequence are relevant to his or her needs. This system, referred to as content-based browsing, forms an abstraction to represent each shot of the sequence by using a representative frame, or an Rframe, and it includes management techniques to allow the user to easily navigate the Rframes. This methodology is superior to the current techniques of fast forward and rewind because rather than using every frame to view and judge the contents, only a few abstractions are used. Therefore, the need to retrieve the video from a storage system and to transmit every frame over the network in its entirety no longer exists, saving time, expenses, and bandwidth."
            },
            "slug": "Content-based-browsing-of-video-sequences-Arman-Depommier",
            "title": {
                "fragments": [],
                "text": "Content-based browsing of video sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The need to retrieve the video from a storage system and to transmit every frame over the network in its entirety no longer exists, saving time, expenses, and bandwidth."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679880"
                        ],
                        "name": "H. Wactlar",
                        "slug": "H.-Wactlar",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Wactlar",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wactlar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116645471"
                        ],
                        "name": "Michael A. Smith",
                        "slug": "Michael-A.-Smith",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48817314"
                        ],
                        "name": "S. Stevens",
                        "slug": "S.-Stevens",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Stevens",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Stevens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "[8] Zhang, H., et a.l, \u201cAutomatic Partitioning of Full-Motion Video,\u201d Multimedia Systems 1993 1, pp. 10-28."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8345108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b4d170b81ffc895e5b7960040a3f44a044d6bb8",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Carnegie Mellon's Informedia Digital Video Library project will establish a large, on-line digital video library featuring full-content and knowledge-based search and retrieval. Intelligent, automatic mechanisms will be developed to populate the library. Search and retrieval from digital video, audio, and text libraries will take place via desktop computer over local, metropolitan, and wide-area networks. The project's approach applies several techniques for content-based searching and video-sequence retrieval. Content is conveyed in both the narrative (speech and language) and the image. Only by the collaborative interaction of image, speech, and natural language understanding technology is it possible to successfully populate, segment, index, and search diverse video collections with satisfactory recall and precision. This collaborative interaction approach uniquely compensates for problems of interpretation and search in error-ridden and ambiguous data sets. The authors have focused the work on two corpuses. One is science documentaries and lectures, the other is broadcast news content with partial closed-captions. Further work will continue to improve the accuracy and performance of the underlying processing as well as explore performance issues related to Web-based access and interoperability with other digital video resources."
            },
            "slug": "Intelligent-Access-to-Digital-Video:-Informedia-Wactlar-Kanade",
            "title": {
                "fragments": [],
                "text": "Intelligent Access to Digital Video: Informedia Project"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "Carnegie Mellon's Informedia Digital Video Library project will establish a large, on-line digital video library featuring full-content and knowledge-based search and retrieval, and focused the work on two corpuses."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713407"
                        ],
                        "name": "S. Pfeiffer",
                        "slug": "S.-Pfeiffer",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Pfeiffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pfeiffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739319"
                        ],
                        "name": "R. Lienhart",
                        "slug": "R.-Lienhart",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Lienhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lienhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061646861"
                        ],
                        "name": "Stephan Fischer",
                        "slug": "Stephan-Fischer",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephan Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750165"
                        ],
                        "name": "W. Effelsberg",
                        "slug": "W.-Effelsberg",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Effelsberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Effelsberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[14] Smallman, K., \u201cCreative Film-Making\u201d, 1st ed., Publisher Macmillan, New York 1970."
                    },
                    "intents": []
                }
            ],
            "corpusId": 43383351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01f7baa4bfc99e0b6805a7e10300e96ac1839cf3",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Large video on demand databases consisting of thousands of digital movies are not easy to handle: the user must have an attractive means to retrieve his movie of choice. For analog video, movie trailers are produced to allow a quick preview and perhaps stimulate possible buyers. This paper presents techniques to automatically produce such movie abstracts of digtial videos. We define a video abstract to be a sequence of still or moving images presenting the content of a video in such a way that the resprective target groupis rapidly provided with concise information about the content while the essential message of the original is preserved. We therefore mainly distinguish video abstracts consisting of a collection of salient still images and video abstracts consisting of a collection of scenes (sequences of images) which are therefore a video themselves. Still-images abstracting systems have been reported often in the literature. We propose a moving-images abstracting system, called VAbstract, and explain its concept, algorithmic realization and advantages. The paper also describes a series of abstracting experiments in which we compared our automatically produced abstracts to manually produced trailers of TV series."
            },
            "slug": "Abstracting-Digital-Movies-Automatically-Pfeiffer-Lienhart",
            "title": {
                "fragments": [],
                "text": "Abstracting Digital Movies Automatically"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A moving-images abstracting system, called VAbstract, is proposed, and its concept, algorithmic realization and advantages are explained, and a series of abstracting experiments are described in which the automatically produced abstracts are compared to manually produced trailers of TV series."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800421"
                        ],
                        "name": "M. Yeung",
                        "slug": "M.-Yeung",
                        "structuredName": {
                            "firstName": "Minerva",
                            "lastName": "Yeung",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yeung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692339"
                        ],
                        "name": "B. Yeo",
                        "slug": "B.-Yeo",
                        "structuredName": {
                            "firstName": "Boon-Lock",
                            "lastName": "Yeo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yeo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145136049"
                        ],
                        "name": "W. Wolf",
                        "slug": "W.-Wolf",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Wolf",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108661679"
                        ],
                        "name": "Bede Liu",
                        "slug": "Bede-Liu",
                        "structuredName": {
                            "firstName": "Bede",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bede Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[14] Smallman, K., \u201cCreative Film-Making\u201d, 1st ed., Publisher Macmillan, New York 1970."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60647111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c39b606f5d4e15992ae1ec51b720dbe0639c4994",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new technique for extracting a hierarchical decomposition of a complex video selection for browsing purposes. The technique combines visual and temporal information to capture the important relations within a scene and between scenes in a video, thus allowing the analysis of the underlying story structure with no a priori knowledge of the content. We define a general model of hierarchical scene transition graph, and apply this model in an implementation for browsing. Video shots are first identified and a collection of key frames is used to represent each video segment. These collections are then classified according to gross visual information. A platform is built on which the video is presented as directed graphs to the user, with each category of video shots represented by a node and each edge denotes a temporal relationship between categories. The analysis and processing of video is carried out directly on the compressed videos. Preliminary tests show that the narrative structure of a video selection can be effectively captured using this technique."
            },
            "slug": "Video-browsing-using-clustering-and-scene-on-Yeung-Yeo",
            "title": {
                "fragments": [],
                "text": "Video browsing using clustering and scene transitions on compressed sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new technique for extracting a hierarchical decomposition of a complex video selection for browsing purposes that combines visual and temporal information to capture the important relations within a scene and between scenes in a video, thus allowing the analysis of the underlying story structure with no a priori knowledge of the content."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2523644"
                        ],
                        "name": "A. Akutsu",
                        "slug": "A.-Akutsu",
                        "structuredName": {
                            "firstName": "Akihito",
                            "lastName": "Akutsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Akutsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34638339"
                        ],
                        "name": "Yoshinobu Tonomura",
                        "slug": "Yoshinobu-Tonomura",
                        "structuredName": {
                            "firstName": "Yoshinobu",
                            "lastName": "Tonomura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshinobu Tonomura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17185163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb3503e948fcda8e40e2be1191a9e51d63e036bd",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new, efficient and practical way to extract lens zoom, camera pan and camera tilt information using modified motion analysis. The proposed method is called the Video Tomography Method (VTM), in which tomographic techniques are introduced into a motion estimation algorithm. By using the VTM, one is able to visualize motion as a spatiotemporal flow for motion analysis. The VTM is an extremely robust [resistant to noise] method for estimating camera operation due to its tomographic nature. The practicality of this type of motion estimation and analysis is confirmed by the results of our simulations and experiments in testing the prototype platform with a low quality video source. Other possible applications that might use extracted motion data are discussed. This method is targeted towards video handling applications that attribute extracted motion data into a video index. It will enhance the process of editing and browsing structured video, and will allow the visualization of scenes spatiotemporally so that video may be accessed intuitively and spatially in relation to its temporal location. This type of access is a new interface for structured video. Scene reconstruction techniques can be extended to apply to the problem of reconstructing occluded images and resolution enhancement."
            },
            "slug": "Video-tomography:-an-efficient-method-for-and-Akutsu-Tonomura",
            "title": {
                "fragments": [],
                "text": "Video tomography: an efficient method for camerawork extraction and motion analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This method is targeted towards video handling applications that attribute extracted motion data into a video index, and will allow the visualization of scenes spatiotemporally so that video may be accessed intuitively and spatially in relation to its temporal location."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35497738"
                        ],
                        "name": "M. Mauldin",
                        "slug": "M.-Mauldin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mauldin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mauldin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "[12] Hauptmann, A.G. and Smith, M, \u201cVideo Segmentation in the Informedia Project\u201d, IJCAI95, Workshop on Intelligent Multimedia Information Retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60835163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8809dbe0bb06859786dc6426026fd6ab5e10735e",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Most information retrieval systems today use only the presence or absence of keywords to classify and retrieve texts. But simple word searches and frequency distributions do not provide these systems with any understanding of those texts. We call this limit the keyword barrier. To go beyond this barrier, information retrieval systems must at least partially understand the texts they retrieve. Although full natural language parsers are capable today of deep understanding within limited domains, they are still too restrictive and slow for general information retrieval. Text skimming parsers, such as DeJong's F scRUMP, are capable of coarse-level understanding, but they require large amounts of domain-specific knowledge in each application domain. \nThis dissertation describes F scERRET: a full text, conceptual information retrieval system that uses a partial understanding of its texts to provide greater precision and recall performance than keyword search techniques. F scERRET parses its input documents by text skimming and then stores their representations as canonical case frames (called abstracts). User queries are similarly converted to case frames, and are matched to the abstracts using a case frame matcher. F scERRET uses the M sc CF scRUMP parser, a derivative of F scRUMP with two important additions. First, it is able to access an on-line English dictionary (Webster's Seventh) to handle unknown words, using script-based expectations to resolve multiple-meaning ambiguities. Second, a script learning component based on Holland's genetic algorithms updates the script database, augmenting M sc CF scRUMP's episodic world knowledge. \nComparison studies of F scERRET's retrieval performance on 1065 astronomy texts show significant improvement in both recall and precision versus the standard boolean keyword search. Precision increased from 35 to 48 percent, and recall more than doubled, from 19 to 52 percent. The script learning component generated new scripts that significantly improved the recall performance of the basic F scERRET system without significant effects on precision. \nThe robust parsing abilities demonstrated, with the depth and flexibility provided by on-line dictionary access and script learning, make text skimming a useful foundation for many applications. The partial understanding provided by a canonical case frame representation is useful for tasks as diverse as information filtering, routing, categorization and summarization."
            },
            "slug": "Information-retrieval-by-text-skimming-Mauldin",
            "title": {
                "fragments": [],
                "text": "Information retrieval by text skimming"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "F scERRET is described: a full text, conceptual information retrieval system that uses a partial understanding of its texts to provide greater precision and recall performance than keyword search techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48232483"
                        ],
                        "name": "Leo Degen",
                        "slug": "Leo-Degen",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Degen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leo Degen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27449564"
                        ],
                        "name": "Richard Mander",
                        "slug": "Richard-Mander",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Mander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Mander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925732"
                        ],
                        "name": "G. Salomon",
                        "slug": "G.-Salomon",
                        "structuredName": {
                            "firstName": "Gitta",
                            "lastName": "Salomon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salomon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[14] Smallman, K., \u201cCreative Film-Making\u201d, 1st ed., Publisher Macmillan, New York 1970."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1193051,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15a92ae29a97756eba42a571e86cd55bcf6fd8b2",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Audio data is rarely used on desktop computers today, although audio is otherwise widely used for communication tasks. This paper describes early work aimed at creating computer tools that support the ways users may want to work with audio data. User needs for the system were determined by intervieweing people already working with audio data, using existing devices such as portable tape recorders. A preliminary prototype system \u2013 consisting of a personal tape recorder for recording and simultaneously marking audio and a Macintosh application for browsing these recordings \u2013 was built. Informal field user tests of this prototype system have indicated areas for improvement and directions for future work."
            },
            "slug": "Working-with-audio:-integrating-personal-tape-and-Degen-Mander",
            "title": {
                "fragments": [],
                "text": "Working with audio: integrating personal tape recorders and desktop computers"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Early work aimed at creating computer tools that support the ways users may want to work with audio data are described, using existing devices such as portable tape recorders."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52578536"
                        ],
                        "name": "Kirk Smallman",
                        "slug": "Kirk-Smallman",
                        "structuredName": {
                            "firstName": "Kirk",
                            "lastName": "Smallman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kirk Smallman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56768795,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "a3de9dfd913a9b4426d5280857ec0dcdde9f9978",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Creative-Film-Making-Smallman",
            "title": {
                "fragments": [],
                "text": "Creative Film Making"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2413848"
                        ],
                        "name": "B. Shahraray",
                        "slug": "B.-Shahraray",
                        "structuredName": {
                            "firstName": "Behzad",
                            "lastName": "Shahraray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Shahraray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2387879"
                        ],
                        "name": "D. Gibbon",
                        "slug": "D.-Gibbon",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gibbon",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gibbon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[14] Smallman, K., \u201cCreative Film-Making\u201d, 1st ed., Publisher Macmillan, New York 1970."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5224918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcf83f7c59600adc5cab55f2a56a52ff445d7230",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automated-authoring-of-hypermedia-documents-of-Shahraray-Gibbon",
            "title": {
                "fragments": [],
                "text": "Automated authoring of hypermedia documents of video programs"
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48817314"
                        ],
                        "name": "S. Stevens",
                        "slug": "S.-Stevens",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Stevens",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Stevens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065857317"
                        ],
                        "name": "Michael Christen",
                        "slug": "Michael-Christen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Christen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Christen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679880"
                        ],
                        "name": "H. Wactlar",
                        "slug": "H.-Wactlar",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Wactlar",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wactlar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27777431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ecdbb4dc0dc539645483ce625ee76186de5a5f5",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Informedia:-improving-access-to-digital-video-Stevens-Christen",
            "title": {
                "fragments": [],
                "text": "Informedia: improving access to digital video"
            },
            "venue": {
                "fragments": [],
                "text": "INTR"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MPEG-1 Video Standard"
            },
            "venue": {
                "fragments": [],
                "text": "Comm. of the ACM"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 2nd Text Retrieval Conference, D. Harmon, Ed., sponsored by ARPA/ SISTO"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2nd Text Retrieval Conference, D. Harmon, Ed., sponsored by ARPA/ SISTO"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 2nd Text Retrieval Conference, D. Harmon, Ed., sponsored by ARPAJ SISTO"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2nd Text Retrieval Conference, D. Harmon, Ed., sponsored by ARPAJ SISTO"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Creative Film-Making\u201d, 1st ed"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MPEG-l Video Standard"
            },
            "venue": {
                "fragments": [],
                "text": "Comm. of the ACM"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Video-skimming-and-characterization-through-the-of-Smith/5d98302953046ebf4d574d05db26a90db95789cc?sort=total-citations"
}