{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 209
                            }
                        ],
                        "text": "Another possibility is to compute the per-pixel residual motion between the predicted and real image, and to compensate one of the two images by this motion to obtain a compensated RMS or robust error measure [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "A more detailed description of these issues can be found in our framework paper, which lays the foundations for prediction error as a quality metric [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1849941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5a42788e0ffcf73f59cdc1f8eca5144f4054c43",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new methodology for evaluating the quality of motion estimation and stereo correspondence algorithms. Motivated by applications such as novel view generation and motion-compensated compression, we suggest that the ability to predict new views or frames is a natural metric for evaluating such algorithms. Our new metric has several advantages over comparing algorithm outputs to true motions or depths. First of all, it does not require the knowledge of ground truth data, which may be difficult or laborious to obtain. Second, it more closely matches the ultimate requirements of the application, which are typically tolerant of errors in uniform color regions, but very sensitive to isolated pixel errors or disocclusion errors. In the paper we develop a number of error metrics based on this paradigm, including forward and inverse prediction errors, residual motion error and local motion-compensated prediction error. We show results on a number of widely used motion and stereo sequences, many of which do not have associated ground truth data."
            },
            "slug": "Prediction-error-as-a-quality-metric-for-motion-and-Szeliski",
            "title": {
                "fragments": [],
                "text": "Prediction error as a quality metric for motion and stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A number of error metrics are developed, including forward and inverse prediction errors, residual motion error and local motion-compensated prediction error, which match the ultimate requirements of the application, which are typically tolerant of errors in uniform color regions, but very sensitive to isolated pixel errors or disocclusion errors."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 95
                            }
                        ],
                        "text": "Some stereo methods minimize a 1-dimensional energy function independently along each scanline [1,4,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1053319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7db5db57bdea8c347b202230f43655c8a247008f",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A half-occluded region in a stereo pair is a set of pixels in one image representing points in space visible to that camera or eye only, and not to the other. These occur typically as parts of the background immediately to the left and right sides of nearby occluding objects, and are present in most natural scenes. Previous approaches to stereo either ignored these unmatchable points or attempted to weed them out in a second pass. An algorithm that incorporates them from the start as a strong clue to depth discontinuities is presented. The authors first derive a measure for goodness of fit and a prior based on a simplified model of objects in space, which leads to an energy functional depending both on the depth as measured from a central cyclopean eye and on the regions of points occluded from the left and right eye perspectives. They minimize this using dynamic programming along epipolar lines followed by annealing in both dimensions. Experiments indicate that this method is very effective even in difficult scenes.<<ETX>>"
            },
            "slug": "A-Bayesian-treatment-of-the-stereo-correspondence-Belhumeur-Mumford",
            "title": {
                "fragments": [],
                "text": "A Bayesian treatment of the stereo correspondence problem using half-occluded regions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The authors first derive a measure for goodness of fit and a prior based on a simplified model of objects in space, which leads to an energy functional depending both on the depth as measured from a central cyclopean eye and on the regions of points occluded from the left and right eye perspectives."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "# errors (> \u00b11) Total pixels Discontinuities Low-texture areas Image 84,863 1,926 6,037 L1 distance 10,457 1,025 967 Annealing 4,244 720 765 Zitnick/Kanade [23] 2,191 749 60 Graph cuts [7] 1,591 572 0"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "This algorithm, due to Zitnick and Kanade [23], is a cooperative method in the style of the Marr-Poggio algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Zitnick/Kanade [23] L1 Distance (r = 6)"
                    },
                    "intents": []
                }
            ],
            "corpusId": 2298962,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b0d1f99124422b71c1afa9c47cf451ef835a37c4",
            "isKey": false,
            "numCitedBy": 560,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a stereo algorithm for obtaining disparity maps with occlusion explicitly detected. To produce smooth and detailed disparity maps, two assumptions that were originally proposed by Marr and Poggio (1976, 1979) are adopted: uniqueness and continuity. That is, the disparity maps have a unique value per pixel and are continuous almost everywhere. These assumptions are enforced within a three-dimensional array of match values in disparity space. Each match value corresponds to a pixel in an image and a disparity relative to another image. An iterative algorithm updates the match values by diffusing support among neighboring values and inhibiting others along similar lines of sight. By applying the uniqueness assumption, occluded regions can be explicitly identified. To demonstrate the effectiveness of the algorithm, we present the processing results from synthetic and real image pairs, including ones with ground-truth values for quantitative comparison with other methods."
            },
            "slug": "A-Cooperative-Algorithm-for-Stereo-Matching-and-Zitnick-Kanade",
            "title": {
                "fragments": [],
                "text": "A Cooperative Algorithm for Stereo Matching and Occlusion Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "Presents a stereo algorithm for obtaining disparity maps with occlusion explicitly detected, and presents the processing results from synthetic and real image pairs, including ones with ground-truth values for quantitative comparison with other methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073254280"
                        ],
                        "name": "S. L. Hingorani",
                        "slug": "S.-L.-Hingorani",
                        "structuredName": {
                            "firstName": "Sunita",
                            "lastName": "Hingorani",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. L. Hingorani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109493725"
                        ],
                        "name": "Satish Rao",
                        "slug": "Satish-Rao",
                        "structuredName": {
                            "firstName": "Satish",
                            "lastName": "Rao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satish Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711252"
                        ],
                        "name": "B. Maggs",
                        "slug": "B.-Maggs",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Maggs",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Maggs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "We have found that one of these methods, MLMHV [9], performs quite well in practice, so we have included it in our study."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "Simulated annealing, meanfield estimation, M-estimation, and MLMHV [9] seem to have comparable performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16802006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b232e3426e0014389ea05132ea8d08789dcc0566",
            "isKey": false,
            "numCitedBy": 555,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A stereo algorithm is presented that optimizes a maximum likelihood cost function. The maximum likelihood cost function assumes that corresponding features in the left and right images are normally distributed about a common true value and consists of a weighted squared error term if two features are matched or a (fixed) cost if a feature is determined to be occluded. The stereo algorithm finds the set of correspondences that maximize the cost function subject to ordering and uniqueness constraints. The stereo algorithm is independent of the matching primitives. However, for the experiments described in this paper, matching is performed on the $cf4$individual pixel intensities.$cf3$ Contrary to popular belief, the pixel-based stereo appears to be robust for a variety of images. It also has the advantages of (i) providing adensedisparity map, (ii) requiringnofeature extraction, and (iii)avoidingthe adaptive windowing problem of area-based correlation methods. Because feature extraction and windowing are unnecessary, a very fast implementation is possible. Experimental results reveal that good stereo correspondences can be found using only ordering and uniqueness constraints, i.e., withoutlocalsmoothness constraints. However, it is shown that the original maximum likelihood stereo algorithm exhibits multiple global minima. The dynamic programming algorithm is guaranteed to find one, but not necessarily the same one for each epipolar scanline, causing erroneous correspondences which are visible as small local differences between neighboring scanlines. Traditionally, regularization, which modifies the original cost function, has been applied to the problem of multiple global minima. We developed several variants of the algorithm that avoid classical regularization while imposing several global cohesiveness constraints. We believe this is a novel approach that has the advantage of guaranteeing that solutions minimize the original cost function and preserve discontinuities. The constraints are based on minimizing the total number of horizontal and/or vertical discontinuities along and/or between adjacent epipolar lines, and local smoothing is avoided. Experiments reveal that minimizing the sum of the horizontal and vertical discontinuities provides the most accurate results. A high percentage of correct matches and very little smearing of depth discontinuities are obtained. An alternative to imposing cohesiveness constraints to reduce the correspondence ambiguities is to use more than two cameras. We therefore extend the two camera maximum likelihood toNcameras. TheN-camera stereo algorithm determines the \u201cbest\u201d set of correspondences between a given pair of cameras, referred to as the principal cameras. Knowledge of the relative positions of the cameras allows the 3D point hypothesized by an assumed correspondence of two features in the principal pair to be projected onto the image plane of the remainingN? 2 cameras. TheseN? 2 points are then used to verify proposed matches. Not only does the algorithm explicitly model occlusion between features of the principal pair, but the possibility of occlusions in theN? 2 additional views is also modeled. Previous work did not model this occlusion process, the benefits and importance of which are experimentally verified. Like other multiframe stereo algorithms, the computational and memory costs of this approach increase linearly with each additional view. Experimental results are shown for two outdoor scenes. It is clearly demonstrated that the number of correspondence errors is significantly reduced as the number of views/cameras is increased."
            },
            "slug": "A-Maximum-Likelihood-Stereo-Algorithm-Cox-Hingorani",
            "title": {
                "fragments": [],
                "text": "A Maximum Likelihood Stereo Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Several variants of the algorithm are developed that avoid classical regularization while imposing several global cohesiveness constraints, and this is a novel approach that has the advantage of guaranteeing that solutions minimize the original cost function and preserve discontinuities."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145337347"
                        ],
                        "name": "H. Baker",
                        "slug": "H.-Baker",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Baker",
                            "middleNames": [
                                "Harlyn"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 95
                            }
                        ],
                        "text": "Some stereo methods minimize a 1-dimensional energy function independently along each scanline [1,4,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11002139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278618251450aaeb334227ec82bacabfc1c266de",
            "isKey": false,
            "numCitedBy": 545,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The past few years have seen a growing interest in the application\" of three-dimensional image processing. With the increasing demand for 3-D spatial information for tasks of passive navigation [7,12], automatic surveillance [9], aerial cartography [10,13], and inspection in industrial automation, the importance of effective stereo analysis has been made quite clear. A particular challenge is to provide reliable and accurate depth data for input to object or terrain modelling systems (such as [5]. This paper describes an algorithm for such stereo sensing It uses an edge-based line-by-line stereo correlation scheme, and appears to be fast, robust, and parallel implementable. The processing consists of extracting edge descriptions for a stereo pair of images, linking these edges to their nearest neighbors to obtain the edge connectivity structure, correlating the edge descriptions on the basis of local edge properties, then cooperatively removmg those edge correspondences determined to be in error - those which violate the connectivity structure of the two images. A further correlation process, using a technique similar to that used for the edges, is applied to the image intensity values over intervals defined by the previous correlation The result of the processing is a full image array disparity map of the scene viewed."
            },
            "slug": "Depth-from-Edge-and-Intensity-Based-Stereo-Baker-Binford",
            "title": {
                "fragments": [],
                "text": "Depth from Edge and Intensity Based Stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes an algorithm for stereo sensing that uses an edge-based line-by-line stereo correlation scheme, and appears to be fast, robust, and parallel implementable."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705903"
                        ],
                        "name": "S. Intille",
                        "slug": "S.-Intille",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Intille",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Intille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "This minimization can be done efficiently via dynamic programming [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15575633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbf5ed8a605e0698389599775e591127e99f3614",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for solving the stereo matching problem in the presence of large occlusion is presented. A data structure \u2014 the disparity space image \u2014 is defined in which we explicitly model the effects of occlusion regions on the stereo solution. We develop a dynamic programming algorithm that finds matches and occlusions simultaneously. We show that while some cost must be assigned to unmatched pixels, our algorithm's occlusion-cost sensitivity and algorithmic complexity can be significantly reduced when highly-reliable matches, or ground control points, are incorporated into the matching process. The use of ground control points eliminates both the need for biasing the process towards a smooth solution and the task of selecting critical prior probabilities describing image formation."
            },
            "slug": "Disparity-Space-Images-and-Large-Occlusion-Stereo-Intille-Bobick",
            "title": {
                "fragments": [],
                "text": "Disparity-Space Images and Large Occlusion Stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that while some cost must be assigned to unmatched pixels, the algorithm's occlusion-cost sensitivity and algorithmic complexity can be significantly reduced when highly-reliable matches, or ground control points, are incorporated into the matching process."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066073"
                        ],
                        "name": "Y. Hsieh",
                        "slug": "Y.-Hsieh",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Hsieh",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Hsieh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34865602"
                        ],
                        "name": "D. McKeown",
                        "slug": "D.-McKeown",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McKeown",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McKeown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2749409"
                        ],
                        "name": "F. Perlant",
                        "slug": "F.-Perlant",
                        "structuredName": {
                            "firstName": "Frederic",
                            "lastName": "Perlant",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perlant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "(However, see [13] for a case where real imagery was used to compare a hierarchical area-based method with a hierarchical scanline matching algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29139203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "637d69008882898aa1f2f005870ce78138c4018a",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Three major areas in the development of competent 3-D scene interpretation system are discussed. First, the importance of accurate automatic scene registration and the difficulty in automated extraction and matching of scene reference points are described. Second, the authors describe two stereo matching algorithms, S1, which is an area-based matcher previously used in the SPAM system, and S2, which is a feature-based matching algorithm based on hierarchical waveform matching. Third, the authors introduce several performance evaluation metrics that made it possible to measure the quality of the overall scene recovery, the building disparity estimate, and the quality and sharpness of the building delineations. Such manually generated scene reference models are critical for understanding strengths and weaknesses of various matching algorithms and in the incremental development of improvements to existing algorithms. Experiments were performed on difficult examples of aerial imagery. >"
            },
            "slug": "Performance-Evaluation-of-Scene-Registration-and-Hsieh-McKeown",
            "title": {
                "fragments": [],
                "text": "Performance Evaluation of Scene Registration and Stereo Matching for Artographic Feature Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The authors introduce several performance evaluation metrics that made it possible to measure the quality of the overall scene recovery, the building disparity estimate, and the quality and sharpness of the building delineations in the development of competent 3-D scene interpretation system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144520793"
                        ],
                        "name": "S\u00e9bastien Roy",
                        "slug": "S\u00e9bastien-Roy",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Roy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 50
                            }
                        ],
                        "text": "Other algorithms based on graph cuts are given in [18,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16612668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "006328c8add2ce30c186048c89097560d2661c27",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new algorithm for solving the N-camera stereo correspondence problem by transforming it into a maximum-flow problem. Once solved, the minimum-cut associated to the maximum-flow yields a disparity surface for the whole image at once. This global approach to stereo analysis provides a more accurate and coherent depth map than the traditional line-by-line stereo. Moreover, the optimality of the depth surface is guaranteed and can be shown to be a generalization of the dynamic programming approach that is widely used in standard stereo. Results show improved depth estimation as well as better handling of depth discontinuities. While the worst case running time is O(n/sup 2/d/sup 2/log(nd)), the observed average running time is O(n/sup 1.2/ d/sup 1.3/) for an image size of n pixels and depth resolution d."
            },
            "slug": "A-maximum-flow-formulation-of-the-N-camera-stereo-Roy-Cox",
            "title": {
                "fragments": [],
                "text": "A maximum-flow formulation of the N-camera stereo correspondence problem"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new algorithm for solving the N-camera stereo correspondence problem by transforming it into a maximum-flow problem that provides a more accurate and coherent depth map than the traditional line-by-line stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49860655"
                        ],
                        "name": "L. Brown",
                        "slug": "L.-Brown",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 71
                            }
                        ],
                        "text": "A large number of algorithms have been proposed in the literature (see [8,10] for literature surveys)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14576088,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "a1068be6f66ae6a56b7dffbdfabc73b253de0ab3",
            "isKey": false,
            "numCitedBy": 4576,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": "Registration is a fundamental task in image processing used to match two or more pictures taken, for example, at different times, from different sensors, or from different viewpoints. Virtually all large systems which evaluate images require the registration of images, or a closely related operation, as an intermediate step. Specific examples of systems where image registration is a significant component include matching a target with a real-time image of a scene for target recognition, monitoring global land usage using satellite images, matching stereo images to recover shape for autonomous navigation, and aligning images from different medical modalities for diagnosis.\nOver the years, a broad range of techniques has been developed for various types of data and problems. These techniques have been independently studied for several different applications, resulting in a large body of research. This paper organizes this material by establishing the relationship between the variations in the images and the type of registration techniques which can most appropriately be applied. Three major types of variations are distinguished. The first type are the variations due to the differences in acquisition which cause the images to be misaligned. To register images, a spatial transformation is found which will remove these variations. The class of transformations which must be searched to find the optimal transformation is determined by knowledge about the variations of this type. The transformation class in turn influences the general technique that should be taken. The second type of variations are those which are also due to differences in acquisition, but cannot be modeled easily such as lighting and atmospheric conditions. This type usually effects intensity values, but they may also be spatial, such as perspective distortions. The third type of variations are differences in the images that are of interest such as object movements, growths, or other scene changes. Variations of the second and third type are not directly removed by registration, but they make registration more difficult since an exact match is no longer possible. In particular, it is critical that variations of the third type are not removed. Knowledge about the characteristics of each type of variation effect the choice of feature space, similarity measure, search space, and search strategy which will make up the final technique. All registration techniques can be viewed as different combinations of these choices. This framework is useful for understanding the merits and relationships between the wide variety of existing techniques and for assisting in the selection of the most suitable technique for a specific problem."
            },
            "slug": "A-survey-of-image-registration-techniques-Brown",
            "title": {
                "fragments": [],
                "text": "A survey of image registration techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper organizes this material by establishing the relationship between the variations in the images and the type of registration techniques which can most appropriately be applied, and establishing a framework for understanding the merits and relationships between the wide variety of existing techniques."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This is especially true because minimizing the energy functions that arise in early vision is almost inevitably NP-hard [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118960561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "752623161a999ceb79ee7b828b67fd4835aff5c6",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Energy minimization is an elegant approach to computer vision. Vision problems usually have many solutions due to uncertainties in the imaging process and ambiguities in visual interpretation. The energy function encodes the problem constraints, and its minimum gives the optimal solution. Despite numerous advantages, this approach is severely limited by the high computational cost. \nThe main contribution of my thesis lies in developing efficient combinatorial optimization algorithms for several important classes of energy functions which incorporate everywhere smooth, piecewise constant, and piecewise smooth priors. These priors assume, respectively, that the quantity to be estimated varies smoothly over its domain, consist of several pieces with constant values, or consist of several pieces with smoothly varying values. The algorithms rely on graph cuts as a powerful optimization technique. \nFor a certain everywhere smooth prior we develop an algorithm which finds the exact minimum by computing a single graph cut. This method is most suitable to estimate quantities without discontinuities. But even when discontinuities exist, the method produces good results in certain cases. The running time is low order polynomial. \nFor several wide classes of piecewise smooth priors we develop two approximation algorithms (we show that exact minimization in NP-hard in these cases). These algorithms produce a local minimum in interesting large move spaces. Furthermore, one of them finds a solution within a known factor from the optimum. The algorithms are iterative and compute several graph cuts at each iteration. The running time at each iteration is effectively linear due to the special graph structure. In practice it takes just a few iterations to converge. Moreover most of the progress happens during the first iteration. \nFor a certain piecewise constant prior we adapt the algorithms developed for the piecewise smooth prior. One of them finds a solution within a factor of two from the optimum. In addition we develop a third algorithm which finds a local minimum in yet another move space. \nWe demonstrate the effectiveness of our approach on image restoration, stereo, and motion. For the data with ground truth, our methods significantly outperform standard methods."
            },
            "slug": "Efficient-Graph-Based-Energy-Minimization-Methods-Veksler",
            "title": {
                "fragments": [],
                "text": "Efficient Graph-Based Energy Minimization Methods in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This thesis develops efficient combinatorial optimization algorithms for several important classes of energy functions which incorporate everywhere smooth, piecewise constant, and piecewise smooth priors, and demonstrates the effectiveness of the approach on image restoration, stereo, and motion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755632"
                        ],
                        "name": "U. R. Dhond",
                        "slug": "U.-R.-Dhond",
                        "structuredName": {
                            "firstName": "Umesh",
                            "lastName": "Dhond",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. R. Dhond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 71
                            }
                        ],
                        "text": "A large number of algorithms have been proposed in the literature (see [8,10] for literature surveys)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 25699143,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "0ea52687ca254ea1e19ba6f43268875ee1b81f93",
            "isKey": false,
            "numCitedBy": 1013,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors review major recent developments in establishing stereo correspondence for the extraction of the 3D structure of a scene. Broad categories of stereo algorithms are identified on the basis of differences in imaging geometry, matching primitives, and the computational structure used. The performance of these stereo techniques on various classes of test images is reviewed, and possible directions of future research are indicated. >"
            },
            "slug": "Structure-from-stereo-a-review-Dhond-Aggarwal",
            "title": {
                "fragments": [],
                "text": "Structure from stereo-a review"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Broad categories of stereo algorithms are identified on the basis of differences in imaging geometry, matching primitives, and the computational structure used for the extraction of the 3D structure of a scene."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14489533"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 Mean field methods replace the stochastic update rules of simulated annealing with deterministic rules based either on the behavior of the mean or mode disparity at each pixel [11], or the local distribution of probabilities across disparity [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46023735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d5a193fdbf9d34118f136935cfd07a81b3e0d77",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Deterministic approximations to Markov random field (MRF) models are derived. One of the models is shown to give in a natural way the graduated nonconvexity (GNC) algorithm proposed by A. Blake and A. Zisserman (1987). This model can be applied to smooth a field preserving its discontinuities. A class of more complex models is then proposed in order to deal with a variety of vision problems. All the theoretical results are obtained in the framework of statistical mechanics and mean field techniques. A parallel, iterative algorithm to solve the deterministic equations of the two models is presented, together with some experiments on synthetic and real images. >"
            },
            "slug": "Parallel-and-Deterministic-Algorithms-from-MRFs:-Geiger-Girosi",
            "title": {
                "fragments": [],
                "text": "Parallel and Deterministic Algorithms from MRFs: Surface Reconstruction"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Deterministic approximations to Markov random field (MRF) models are derived and one of the models is shown to give in a natural way the graduated nonconvexity (GNC) algorithm proposed by A. Blake and A. Zisserman (1987)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14930294,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65297c4e40fd9b8129fc593be1b8c8ef775c86ba",
            "isKey": false,
            "numCitedBy": 507,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors consider the problem of robustly estimating optical flow from a pair of images using a new framework based on robust estimation which addresses violations of the brightness constancy and spatial smoothness assumptions. They also show the relationship between the robust estimation framework and line-process approaches for coping with spatial discontinuities. In doing so, the notion of a line process is generalized to that of an outlier process that can account for violations in both the brightness and smoothness assumptions. A graduated non-convexity algorithm is presented for recovering optical flow and motion discontinuities. The performance of the robust formulation is demonstrated on both synthetic data and natural images.<<ETX>>"
            },
            "slug": "A-framework-for-the-robust-estimation-of-optical-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "A framework for the robust estimation of optical flow"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "The authors consider the problem of robustly estimating optical flow from a pair of images using a new framework based on robust estimation which addresses violations of the brightness constancy and spatial smoothness assumptions and presents a graduated non-convexity algorithm for recovering optical flow and motion discontinuities."
            },
            "venue": {
                "fragments": [],
                "text": "1993 (4th) International Conference on Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 185
                            }
                        ],
                        "text": "# errors (> \u00b11) Total pixels Discontinuities Low-texture areas Image 84,863 1,926 6,037 L1 distance 10,457 1,025 967 Annealing 4,244 720 765 Zitnick/Kanade [23] 2,191 749 60 Graph cuts [7] 1,591 572 0"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "\u2013 Graph cuts are a combinatorial optimization technique that can be used to minimize a number of different energy functions [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2430892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3120324069ec20eed853d3f9bbbceb32e4173b93",
            "isKey": false,
            "numCitedBy": 3913,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of minimizing a large class of energy functions that occur in early vision. The major restriction is that the energy function's smoothness term must only involve pairs of pixels. We propose two algorithms that use graph cuts to compute a local minimum even when very large moves are allowed. The first move we consider is an /spl alpha/-/spl beta/-swap: for a pair of labels /spl alpha/,/spl beta/, this move exchanges the labels between an arbitrary set of pixels labeled a and another arbitrary set labeled /spl beta/. Our first algorithm generates a labeling such that there is no swap move that decreases the energy. The second move we consider is an /spl alpha/-expansion: for a label a, this move assigns an arbitrary set of pixels the label /spl alpha/. Our second algorithm, which requires the smoothness term to be a metric, generates a labeling such that there is no expansion move that decreases the energy. Moreover, this solution is within a known factor of the global minimum. We experimentally demonstrate the effectiveness of our approach on image restoration, stereo and motion."
            },
            "slug": "Fast-approximate-energy-minimization-via-graph-cuts-Boykov-Veksler",
            "title": {
                "fragments": [],
                "text": "Fast approximate energy minimization via graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes two algorithms that use graph cuts to compute a local minimum even when very large moves are allowed, and generates a labeling such that there is no expansion move that decreases the energy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66193516"
                        ],
                        "name": "H. Ishikawa",
                        "slug": "H.-Ishikawa",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Ishikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ishikawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14489533"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 50
                            }
                        ],
                        "text": "Other algorithms based on graph cuts are given in [18,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 95
                            }
                        ],
                        "text": "Some stereo methods minimize a 1-dimensional energy function independently along each scanline [1,4,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14277438,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0e2fdbfd7b4699743010ddf2aa52b8aedf1d496d",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Binocular stereo is the process of obtaining depth information from a pair of left and right views of a scene. We present a new approach to compute the disparity map by solving a global optimization problem that models occlusions, discontinuities, and epipolar-line interactions."
            },
            "slug": "Occlusions,-Discontinuities,-and-Epipolar-Lines-in-Ishikawa-Geiger",
            "title": {
                "fragments": [],
                "text": "Occlusions, Discontinuities, and Epipolar Lines in Stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new approach to compute the disparity map by solving a global optimization problem that models occlusions, discontinuities, and epipolar-line interactions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 22
                            }
                        ],
                        "text": "\u2013 Simulated annealing [12,2] is the most common energy minimization technique."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18704,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768661"
                        ],
                        "name": "G. Wolberg",
                        "slug": "G.-Wolberg",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Wolberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wolberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "We can generate novel views from a color/depth image using forward warping [22], which involves moving the source pixels to the destination image and potentially filling in gaps."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205071458,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "51a59fd4b7b44667b952f644ab2abd133638b298",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Restoration-of-binary-images-using-stochastic-with-Wolberg-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Restoration of binary images using stochastic relaxation with annealing"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Following [6], we experimented with several different annealing schedules; our data is from the one that performed best."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5219840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2885d58fb0fe8a4940379c39c6366f71696e73ba",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Piecewise continuous reconstruction of real-valued data can be formulated in terms of nonconvex optimization problems. Both stochastic and deterministic algorithms have been devised to solve them. The simplest such reconstruction process is the weak string. Exact solutions can be obtained for it and are used to determine the success or failure of the algorithms under precisely controlled conditions. It is concluded that the deterministic algorithm (graduated nonconvexity) outstrips stochastic (simulated annealing) algorithms both in computational efficiency and in problem-solving power. >"
            },
            "slug": "Comparison-of-the-Efficiency-of-Deterministic-and-Blake",
            "title": {
                "fragments": [],
                "text": "Comparison of the Efficiency of Deterministic and Stochastic Algorithms for Visual Reconstruction"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is concluded that the deterministic algorithm (graduated nonconvexity) outstrips stochastic (simulated annealing) algorithms both in computational efficiency and in problem-solving power."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2218687"
                        ],
                        "name": "P. Rousseeuw",
                        "slug": "P.-Rousseeuw",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Rousseeuw",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Rousseeuw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152878142"
                        ],
                        "name": "A. Leroy",
                        "slug": "A.-Leroy",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Leroy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leroy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "It is also possible to use a robust measure, which downweights large error, and to count the number of outliers [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "\u2013 Robust correlation using Least Median Squares [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61563242,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "4fecc029c30800e5be60f2fbf22276c29e3c9f68",
            "isKey": false,
            "numCitedBy": 5806,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction. 2. Simple Regression. 3. Multiple Regression. 4. The Special Case of One-Dimensional Location. 5. Algorithms. 6. Outlier Diagnostics. 7. Related Statistical Techniques. References. Table of Data Sets. Index."
            },
            "slug": "Robust-Regression-and-Outlier-Detection-Rousseeuw-Leroy",
            "title": {
                "fragments": [],
                "text": "Robust regression and outlier detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents the results of a two-year study of the statistical treatment of outliers in the context of one-Dimensional Location and its applications to discrete-time reinforcement learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153918727"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Fua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076198688"
                        ],
                        "name": "Y. G. Leclerc",
                        "slug": "Y.-G.-Leclerc",
                        "structuredName": {
                            "firstName": "Yvan",
                            "lastName": "Leclerc",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. G. Leclerc"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "2 A third possibility is to run the stereo algorithm on several different pairs within a multi-image data set, and to compute the self-consistency between different disparity estimates [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "In the future, we hope to collaborate with the authors of [16] to apply our different methodologies to the same sets of data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14523366,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "35082347e626edd2f0af6ceae13a8a07bc25dde1",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Reference CVLAB-CONF-1999-005 URL: http://cvlab.epfl.ch/publications/publications/1999/LeclercTF99.pdf Record created on 2006-02-03, modified on 2016-08-08"
            },
            "slug": "Self-Consistency:-A-Novel-Approach-to-the-Accuracy-Fua-Luong",
            "title": {
                "fragments": [],
                "text": "Self-Consistency: A Novel Approach to Characterizing the Accuracy and Reliability of Point Correspon"
            },
            "venue": {
                "fragments": [],
                "text": "ICCV 1999"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum likelihood stereo algorithm. Computer Vision, Graphics and Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/An-Experimental-Comparison-of-Stereo-Algorithms-Szeliski-Zabih/a6fbefbee8b814dc3183e26ef37a44fc5015600d?sort=total-citations"
}