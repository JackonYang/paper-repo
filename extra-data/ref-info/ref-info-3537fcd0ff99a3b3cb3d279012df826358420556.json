{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137198"
                        ],
                        "name": "R. Shepard",
                        "slug": "R.-Shepard",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Shepard",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shepard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13920364,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5905c7ed15aa13654e540bb785176998e709dd3f",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "The universality, invariance, and elegance of principles governing the universe may be reflected in principles of the minds that have evolved in that universe\u2014provided that the mental principles are formulated with respect to the abstract spaces appropriate for the representation of biologically significant objects and their properties. (1)Positions andmotions of objects conserve theirshapes in the geometrically fullest and simplest way when represented as points and connecting geodesic paths in the six-dimensional manifold jointly determined by the Euclidean group of three-dimensional space and the symmetry group of each object. (2)Colors of objects attain constancy when represented as points in a three-dimensional vector space in which each variation in natural illumination is cancelled by application of its inverse from the three-dimensional linear group of terrestrial transformations of the invariant solar source. (3)Kinds of objects support optimal generalization and categorization when represented, in an evolutionarily shaped space of possible objects, as connected regions with associated weights determined by Bayesian revision of maximum-entropy priors."
            },
            "slug": "Perceptual-cognitive-universals-as-reflections-of-Shepard",
            "title": {
                "fragments": [],
                "text": "Perceptual-cognitive universals as reflections of the world"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The universality, invariance, and elegance of principles governing the universe may be reflected in principles of the minds that have evolved in that universe\u2014provided that the mental principles are formulated with respect to the abstract spaces appropriate for the representation of biologically significant objects and their properties."
            },
            "venue": {
                "fragments": [],
                "text": "Psychonomic bulletin & review"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758350"
                        ],
                        "name": "M. Kramer",
                        "slug": "M.-Kramer",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Kramer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kramer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15907287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87c280d0dc204ca5db0d325991a21c211aeec866",
            "isKey": false,
            "numCitedBy": 2273,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Nonlinear principal component analysis is a novel technique for multivariate data analysis, similar to the well-known method of principal component analysis. NLPCA, like PCA, is used to identify and remove correlations among problem variables as an aid to dimensionality reduction, visualization, and exploratory data analysis. While PCA identifies only linear correlations between variables, NLPCA uncovers both linear and nonlinear correlations, without restriction on the character of the nonlinearities present in the data. NLPCA operates by training a feedforward neural network to perform the identity mapping, where the network inputs are reproduced at the output layer. The network contains an internal \u201cbottleneck\u201d layer (containing fewer nodes than input or output layers), which forces the network to develop a compact representation of the input data, and two additional hidden layers. The NLPCA method is demonstrated using time-dependent, simulated batch reaction data. Results show that NLPCA successfully reduces dimensionality and produces a feature space map resembling the actual distribution of the underlying system parameters."
            },
            "slug": "Nonlinear-principal-component-analysis-using-neural-Kramer",
            "title": {
                "fragments": [],
                "text": "Nonlinear principal component analysis using autoassociative neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The NLPCA method is demonstrated using time-dependent, simulated batch reaction data and shows that it successfully reduces dimensionality and produces a feature space map resembling the actual distribution of the underlying system parameters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2662552"
                        ],
                        "name": "M. Svens\u00e9n",
                        "slug": "M.-Svens\u00e9n",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Svens\u00e9n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Svens\u00e9n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207605229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2639515c248f220c73d44688c0097a99b01e1474",
            "isKey": false,
            "numCitedBy": 1456,
            "numCiting": 132,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent variable models represent the probability density of data in a space of several dimensions in terms of a smaller number of latent, or hidden, variables. A familiar example is factor analysis, which is based on a linear transformation between the latent space and the data space. In this article, we introduce a form of nonlinear latent variable model called the generative topographic mapping, for which the parameters of the model can be determined using the expectation-maximization algorithm. GTM provides a principled alternative to the widely used self-organizing map (SOM) of Kohonen (1982) and overcomes most of the significant limitations of the SOM. We demonstrate the performance of the GTM algorithm on a toy problem and on simulated data from flow diagnostics for a multiphase oil pipeline."
            },
            "slug": "GTM:-The-Generative-Topographic-Mapping-Bishop-Svens\u00e9n",
            "title": {
                "fragments": [],
                "text": "GTM: The Generative Topographic Mapping"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A form of nonlinear latent variable model called the generative topographic mapping, for which the parameters of the model can be determined using the expectation-maximization algorithm, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764560"
                        ],
                        "name": "T. Martinetz",
                        "slug": "T.-Martinetz",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Martinetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Martinetz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144340430"
                        ],
                        "name": "K. Schulten",
                        "slug": "K.-Schulten",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Schulten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schulten"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1526800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3589df97fca025b4b2bebcdcb2327078a0483e4a",
            "isKey": false,
            "numCitedBy": 929,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Topology-representing-networks-Martinetz-Schulten",
            "title": {
                "fragments": [],
                "text": "Topology representing networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1701422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d7d0e8c4791700defd4b0df82a26b50055346e0",
            "isKey": false,
            "numCitedBy": 8756,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in \"blind\" signal processing."
            },
            "slug": "An-Information-Maximization-Approach-to-Blind-and-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "An Information-Maximization Approach to Blind Separation and Blind Deconvolution"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is suggested that information maximization provides a unifying framework for problems in \"blind\" signal processing and dependencies of information transfer on time delays are derived."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401987027"
                        ],
                        "name": "C. Bailer-Jones",
                        "slug": "C.-Bailer-Jones",
                        "structuredName": {
                            "firstName": "Coryn",
                            "lastName": "Bailer-Jones",
                            "middleNames": [
                                "A.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bailer-Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5058806"
                        ],
                        "name": "M. Irwin",
                        "slug": "M.-Irwin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Irwin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Irwin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2183759"
                        ],
                        "name": "T. Hippel",
                        "slug": "T.-Hippel",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Hippel",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hippel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15158733,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b713daba8444397e7836782bd9ca9f3ae9e09439",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of neural networks to the automation of MK spectral classification. The data set for this project consists of a set of over 5000 optical (3800\u20135200\u00a0A) spectra obtained from objective prism plates from the Michigan Spectral Survey. These spectra, along with their two-dimensional MK classifications listed in the Michigan Henry Draper Catalogue, were used to develop supervised neural network classifiers. We show that neural networks can give accurate spectral type classifications (\u03c368= 0.82 subtypes, \u03c3rms= 1.09 subtypes) across the full range of spectral types present in the data set (B2\u2013M7). We show also that the networks yield correct luminosity classes for over 95 per cent of both dwarfs and giants with a high degree of confidence. \u00a0Stellar spectra generally contain a large amount of redundant information. We investigate the application of principal components analysis (PCA) to the optimal compression of spectra. We show that PCA can compress the spectra by a factor of over 30 while retaining essentially all of the useful information in the data set. Furthermore, it is shown that this compression optimally removes noise and can be used to identify unusual spectra. \u00a0This paper is a continuation of the work carried out by von Hippel et al. (Paper I)."
            },
            "slug": "Automated-classification-of-stellar-spectra-II.-and-Bailer-Jones-Irwin",
            "title": {
                "fragments": [],
                "text": "Automated classification of stellar spectra - II. Two-dimensional classification with neural networks and principal components analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that PCA can compress the spectra by a factor of over 30 while retaining essentially all of the useful information in the data set, and that this compression optimally removes noise and can be used to identify unusual spectra."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783831"
                        ],
                        "name": "P. Comon",
                        "slug": "P.-Comon",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Comon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Comon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18340548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96a1effa4be3f8caa88270d6d258de418993d2e7",
            "isKey": false,
            "numCitedBy": 8327,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Independent-component-analysis,-A-new-concept-Comon",
            "title": {
                "fragments": [],
                "text": "Independent component analysis, A new concept?"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398229863"
                        ],
                        "name": "R. Hecht-Nielsen",
                        "slug": "R.-Hecht-Nielsen",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Hecht-Nielsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hecht-Nielsen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33988163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c42ee8d7811dec703207001b81177edc51620a86",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Replicator neural networks self-organize by using their inputs as desired outputs; they internally form a compressed representation for the input data. A theorem shows that a class of replicator networks can, through the minimization of mean squared reconstruction error (for instance, by training on raw data examples), carry out optimal data compression for arbitrary data vector sources. Data manifolds, a new general model of data sources, are then introduced and a second theorem shows that, in a practically important limiting case, optimal-compression replicator networks operate by creating an essentially unique natural coordinate system for the manifold."
            },
            "slug": "Replicator-neural-networks-for-universal-optimal-Hecht-Nielsen",
            "title": {
                "fragments": [],
                "text": "Replicator neural networks for universal optimal source coding."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A theorem shows that a class of replicator networks can, through the minimization of mean squared reconstruction error, carry out optimal data compression for arbitrary data vector sources."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137198"
                        ],
                        "name": "R. Shepard",
                        "slug": "R.-Shepard",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Shepard",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shepard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7580495,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7266160bf923845c122adb812ee54350d10f5835",
            "isKey": false,
            "numCitedBy": 694,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "American mathematical psychologists have developed computer-based methods for constructing representations of the psychological structure of a set of stimuli on the basis of pairwise measures of similarity or confusability. Applications to perceptual and semantic data illustrate how complementary aspects of the underlying psychological structure are revealed by different types of representations, including multidimensional spatial configurations and nondimensional tree-structures or clusterings."
            },
            "slug": "Multidimensional-Scaling,-Tree-Fitting,-and-Shepard",
            "title": {
                "fragments": [],
                "text": "Multidimensional Scaling, Tree-Fitting, and Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Applications to perceptual and semantic data illustrate how complementary aspects of the underlying psychological structure are revealed by different types of representations, including multidimensional spatial configurations and nondimensional tree-structures or clusterings."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053227062"
                        ],
                        "name": "Richard Durbin",
                        "slug": "Richard-Durbin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Durbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Durbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40227361"
                        ],
                        "name": "D. Willshaw",
                        "slug": "D.-Willshaw",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Willshaw",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Willshaw"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4321691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a94be030ccd68f3a5a3bf9245137fe114c549819",
            "isKey": false,
            "numCitedBy": 855,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The travelling salesman problem1 is a classical problem in the field of combinatorial optimization, concerned with efficient methods for maximizing or minimizing a function of many independent variables. Given the positions of N cities, which in the simplest case lie in the plane, what is the shortest closed tour in which each city can be visited once? We describe how a parallel analogue algorithm, derived from a formal model2\u20133 for the establishment of topographically ordered projections in the brain4\u201310, can be applied to the travelling salesman problem1,11,12. Using an iterative procedure, a circular closed path is gradually elongated non-uniformly until it eventually passes sufficiently near to all the cities to define a tour. This produces shorter tour lengths than another recent parallel analogue algorithm13, scales well with the size of the problem, and is naturally extendable to a large class of optimization problems involving topographic mappings between geometrical structures14."
            },
            "slug": "An-analogue-approach-to-the-travelling-salesman-an-Durbin-Willshaw",
            "title": {
                "fragments": [],
                "text": "An analogue approach to the travelling salesman problem using an elastic net method"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work describes how a parallel analogue algorithm, derived from a formal model for the establishment of topographically ordered projections in the brain, can be applied to the travelling salesman problem, and produces shorter tour lengths than another recent parallel analogue algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50555333"
                        ],
                        "name": "M. Young",
                        "slug": "M.-Young",
                        "structuredName": {
                            "firstName": "Malcolm",
                            "lastName": "Young",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706597"
                        ],
                        "name": "S. Yamane",
                        "slug": "S.-Yamane",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Yamane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yamane"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43706067,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "7272898bc3774d08510f6300290857c2ecc5a7b5",
            "isKey": false,
            "numCitedBy": 614,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "How does the brain represent objects in the world? A proportion of cells in the temporal cortex of monkeys responds specifically to objects, such as faces, but the type of coding used by these cells is not known. Population analysis of two sets of such cells showed that information is carried at the level of the population and that this information relates, in the anterior inferotemporal cortex, to the physical properties of face stimuli and, in the superior temporal polysensory area, to other aspects of the faces, such as their familiarity. There was often sufficient information in small populations of neurons to identify particular faces. These results suggest that representations of complex stimuli in the higher visual areas may take the form of a sparse population code."
            },
            "slug": "Sparse-population-coding-of-faces-in-the-cortex.-Young-Yamane",
            "title": {
                "fragments": [],
                "text": "Sparse population coding of faces in the inferotemporal cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Population analysis of cells in the temporal cortex of monkeys showed that information is carried at the level of the population and that representations of complex stimuli in the higher visual areas may take the form of a sparse population code."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172770680"
                        ],
                        "name": "N. L. Johnson",
                        "slug": "N.-L.-Johnson",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Johnson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. L. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4206943,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "182f77976b08d832b5cdc7debdaeacc300c8e723",
            "isKey": false,
            "numCitedBy": 5733,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An Introduction to Multivariate Statistical AnalysisBy Prof. T. W. Anderson. (Wiley Publications in Mathematical Statistics.) Pp. xii + 374. (New York: John Wiley and Sons, Inc.; London: Chapman and Hall, Ltd., 1958.) 100s. net.Some Aspects of Multivariate AnalysisBy Prof. S. N. Roy. (Indian Statistical Series, No. 1.) Pp. viii + 214. (New York: John Wiley and Sons, Inc.; Calcutta: Indian Statistical Institute; London: Chapman and Hall, Ltd., 1957.) 64s. net.The Analysis of Multiple Time-SeriesBy M. H. Quenouille. (Griffin's Statistical Monographs and Courses, No. 1.) Pp. 105. (London: Charles Griffin and Co., Ltd., 1957.) 24s."
            },
            "slug": "Multivariate-Analysis-Johnson",
            "title": {
                "fragments": [],
                "text": "Multivariate Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20678424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c86590e947c28e8791d1e8bab8fc8ab53302341f",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In the work described here, the backpropagation neural network learning procedure is applied to the analysis and recognition of speech. This procedure takes a set of input/output pattern pairs and attempts to learn their functional relationship; it develops the necessary representational features during the course of learning. A series of computer simulation studies was carried out to assess the ability of these networks to accurately label sounds, to learn to recognize sounds without labels, and to learn feature representations of continuous speech. These studies demonstrated that the networks can learn to label presegmented test tokens with accuracies of up to 95%. Networks trained on segmented sounds using a strategy that requires no external labels were able to recognize and delineate sounds in continuous speech. These networks developed rich internal representations that included units which corresponded to such traditional distinctions as vowels and consonants, as well as units that were sensitive to novel and nonstandard features. Networks trained on a large corpus of unsegmented, continuous speech without labels also developed interesting feature representations, which may be useful in both segmentation and label learning. The results of these studies, while preliminary, demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "slug": "Learning-the-hidden-structure-of-speech.-Elman-Zipser",
            "title": {
                "fragments": [],
                "text": "Learning the hidden structure of speech."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results of these studies demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40262540"
                        ],
                        "name": "P. Menozzi",
                        "slug": "P.-Menozzi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Menozzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Menozzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80441660"
                        ],
                        "name": "A. Piazza",
                        "slug": "A.-Piazza",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Piazza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Piazza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410571596"
                        ],
                        "name": "L. Cavalli-Sforza",
                        "slug": "L.-Cavalli-Sforza",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Cavalli-Sforza",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cavalli-Sforza"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32758618,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "98d479e5b840112adc49f31aa9032a423ad06498",
            "isKey": false,
            "numCitedBy": 638,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Multivarate techniques can be used to condense the information for a large number of loci and alleles into one or a few synthetic variables. The geographic distribution of synthetic variables can be plotted by the same technique used in mapping the gene frequency of a single allele. Synthetic maps were constructed for Europe and the Near East, with the use of principal components to condense the information of 38 independent alleles from ten loci. The first principal component summarizes close to 30% of the total information and shows gradients. Maps thus constructed show clines in remarkable agreement with those expected on the basis of the spread of early farming in Europe, thus supporting the hypothesis that this spread was a demic spread rather than a cultural diffusion of farming technology."
            },
            "slug": "Synthetic-maps-of-human-gene-frequencies-in-Menozzi-Piazza",
            "title": {
                "fragments": [],
                "text": "Synthetic maps of human gene frequencies in Europeans."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Synthetic maps constructed for Europe and the Near East show clines in remarkable agreement with those expected on the basis of the spread of early farming in Europe, supporting the hypothesis that this spread was a demic spread rather than a cultural diffusion of farming technology."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107978892"
                        ],
                        "name": "Vipin Kumar",
                        "slug": "Vipin-Kumar",
                        "structuredName": {
                            "firstName": "Vipin",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vipin Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732163"
                        ],
                        "name": "A. Grama",
                        "slug": "A.-Grama",
                        "structuredName": {
                            "firstName": "Ananth",
                            "lastName": "Grama",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Grama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110759944"
                        ],
                        "name": "Anshul Gupta",
                        "slug": "Anshul-Gupta",
                        "structuredName": {
                            "firstName": "Anshul",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anshul Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50877490"
                        ],
                        "name": "G. Karypis",
                        "slug": "G.-Karypis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Karypis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Karypis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "More efficient algorithms exploiting the sparse structure of the neighborhood graph can be found in (38)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60863431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36482ff0eb3401a05a5d0f002105556512b1ee75",
            "isKey": false,
            "numCitedBy": 1499,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction. What is Parallel Computing? The Scope of Parallel Computing. Issues in Parallel Computing. Organization and Contents of The Text. Bibliographic Remarks. Problems. References. Models of Parallel Computers. A Taxonomy of Parallel Architectures. An Idealized Parallel Computer. Dynamic Interconnection Networks. Static Interconnection Networks. Embedding Other Networks Into a Hypercube. Routing Mechanisms For Static Networks. Communication Costs in Static Interconnection Networks. Cost-Performance Tradeoffs. Architectural Models For Parallel Algorithm Design. Bibliographic Remarks. References. Basic Communication Operations. Simple Message Transfer Between Two Processors. One-To-All Broadcast. All-To-All Broadcast, Reduction, and Prefix Sums. One-To-All Personalized Communications. All-To-All Personalized Communications. Circular Shift. Faster Methods For Some Communication Operations. Summary. Bibliographic Remarks. Problems. References. Performance and Scalability of Parallel Systems. Performance Metrics For Parallel Systems. The Effect of Granularity and Data Mapping On Performance. The Scalability of Parallel Systems. The Isoefficiency Metric of Scalability. Sources of Parallel Overhead. Minimum Execution Time and Minimum Cost-Optimal Execution Time. Other Scalability Metrics and Bibliographic Remarks. Problems. References. Dense Matrix Algorithms. Mapping Matrices Onto Processors. Matrix Transpositon. Matrix-Vector Multiplication. Matrix Multiplication. Solving a System of Linear Equations. Bibliographic Remarks. Problems. References. Sorting. Issues in Sorting On Parallel Computers. Sorting Networks. Bubble Sort and Its Variants. Quicksort. Other Sorting Algorithms. Bibliographic Remarks. Problems. References. Graph Algorithms. Definitions and Representation. Minimum Spanning Tree: Prim's Algorithm. Single-Source Shortest Paths: Dijkstra's Algorithms. All-Pairs Shortest Paths. Transitive Closure. Connected Components. Algorithms For Sparse Graphs. Bibliographic Remarks. Problems. References. Search Algorithms For Discrete Optimization Problems. Definitions and Examples. Sequential Search Algorithms. Search Overhead Factor. Parallel Depth-First Search. Parallel Best-First Search. Speedup Anomalies in Parallel Search Algorithms. Bibliographic Remarks. Problems. References. Dynamic Programming. Serial Monadic Dp Formulations. Nonserial Monadic Dp Formulations. Serial Polyadic Dp Formulations. Nonserial Polyadic Dp Formulations. Summary and Discussion. Bibliographic Remarks. Problems. References. Fast Fourier Transform. The Serial Algorithm. The Binary-Exchange Algorithm. The Transpose Algorithm. Cost-Effectiveness of Meshes and Hypercubes For Fft. Bibliographic Remarks. Problems. References. Solving Sparse Systems of Linear Equations. Basic Operations. Iterative Methods. Finite Element Method. Direct Methods For Sparse Linear Systems. Multigrid Methods. Bibliographic Remarks. Problems. References. Systolic Algorithms and Their Mapping Onto Parallel Computers. Examples of Systolic Systems. General Issues in Mapping Systolic Systems Onto Parallel Computers. Mapping One-Dimensional Systolic Arrays. Bibliographic Remarks. Problems. References. Parallel Programming. Parallel Programming Paradigms. Primitive For The Message-Passing Programming Paradigm. Data-Parallel Languages. Primitives For The Shared-Address-Space Programming Paradigm. Fortran D. Bibliographic Remarks. References. Appendix A. Complexity of Functions and Order Analysis. Author Index. Subject Index. 0805331700T04062001"
            },
            "slug": "Introduction-to-parallel-computing:-design-and-of-Kumar-Grama",
            "title": {
                "fragments": [],
                "text": "Introduction to parallel computing: design and analysis of algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Performance and Scalability of Parallel Systems, General Issues in Mapping Systolic Systems Onto Parallel Computers, and Speedup Anomalies in Parallel Search Algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62531491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89121ed4d0d3db9bc192fd79f541fc299eba7d6b",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models. Many of these techniques depend on a representation of images that induces a linear vector space structure and in principle requires dense feature correspondence. This image representation allows the use of learning techniques for the analysis of images (for computer vision) as well as for the synthesis of images (for computer graphics)."
            },
            "slug": "Image-Representations-for-Visual-Learning-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Image Representations for Visual Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054107253"
                        ],
                        "name": "W. Klein",
                        "slug": "W.-Klein",
                        "structuredName": {
                            "firstName": "W",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143714546"
                        ],
                        "name": "R. Plomp",
                        "slug": "R.-Plomp",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Plomp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Plomp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779596"
                        ],
                        "name": "L. Pols",
                        "slug": "L.-Pols",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Pols",
                            "middleNames": [
                                "C.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pols"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37955319,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0995b04be433a15e6b9ec6a466cbdd95b5d76374",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Twelve Dutch vowels, each pronounced by 50 male speakers, were analyzed in 18 filter bands comparable in bandwidth with the ear's critical band. By considering the sound levels (in decibels) in these filter bands as dimensions, with a principal\u2010component analysis the 18 dimensions per sound were reduced to four factors which together explain 75% of the total variance. The configuration of the average vowels in the factor space appeared to be highly correlated with their configuration in the F1\u2212F2 formant plane. After matching to maximal congruence, correlation coefficients along corresponding axes were 0.997 and 0.979. Machine vowel identification, based upon the position of the individual vowels in the four\u2010dimensional factor space, resulted (after three pairs of related vowels were grouped together) in 98% correct identifications if correction was applied for personal timbre of the speakers' voices. Ten listeners, to whom the 600 vowels were presented as 100\u2010msec segments, gave 86% correct responses in ..."
            },
            "slug": "Vowel-spectra,-vowel-spaces,-and-vowel-Klein-Plomp",
            "title": {
                "fragments": [],
                "text": "Vowel spectra, vowel spaces, and vowel identification."
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Twelve Dutch vowels, each pronounced by 50 male speakers, were analyzed in 18 filter bands comparable in bandwidth with the ear's critical band and machine vowel identification resulted in 98% correct identifications if correction was applied for personal timbre of the speakers' voices."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2405492"
                        ],
                        "name": "E. Bizzi",
                        "slug": "E.-Bizzi",
                        "structuredName": {
                            "firstName": "Emilio",
                            "lastName": "Bizzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bizzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401226990"
                        ],
                        "name": "F. Mussa-Ivaldi",
                        "slug": "F.-Mussa-Ivaldi",
                        "structuredName": {
                            "firstName": "Ferdinando",
                            "lastName": "Mussa-Ivaldi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mussa-Ivaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3318348"
                        ],
                        "name": "S. Giszter",
                        "slug": "S.-Giszter",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Giszter",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Giszter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2088379,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "4fbe7d8a7a267e42684d312074378f7efa7f800f",
            "isKey": false,
            "numCitedBy": 683,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "To execute voluntary movements, the central nervous system must transform the neural representation of the direction, amplitude, and velocity of the limb, represented by the activity of cortical and subcortical neurons, into signals that activate the muscles that move the limb. This task is equivalent to solving an \"ill-posed\" computational problem because the number of degrees of freedom of the musculoskeletal apparatus is much larger than that specified in the plan of action. Some of the mechanisms and circuitry underlying the transformation of motor plans into motor commands are described. A central feature of this transformation is a coarse map of limb postures in the premotor areas of the spinal cord. Vectorial combination of motor outputs among different areas of the spinal map may produce a large repertoire of motor behaviors."
            },
            "slug": "Computations-underlying-the-execution-of-movement:-Bizzi-Mussa-Ivaldi",
            "title": {
                "fragments": [],
                "text": "Computations underlying the execution of movement: a biological perspective."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Some of the mechanisms and circuitry underlying the transformation of motor plans into motor commands are described and a central feature of this transformation is a coarse map of limb postures in the premotor areas of the spinal cord."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 222292199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10055eb6f2f711a36d9aa8f759d3b3f01ebddb5d",
            "isKey": false,
            "numCitedBy": 6561,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Various Aspects of Memory.- 1.1 On the Purpose and Nature of Biological Memory.- 1.1.1 Some Fundamental Concepts.- 1.1.2 The Classical Laws of Association.- 1.1.3 On Different Levels of Modelling.- 1.2 Questions Concerning the Fundamental Mechanisms of Memory.- 1.2.1 Where Do the Signals Relating to Memory Act Upon?.- 1.2.2 What Kind of Encoding is Used for Neural Signals?.- 1.2.3 What are the Variable Memory Elements?.- 1.2.4 How are Neural Signals Addressed in Memory?.- 1.3 Elementary Operations Implemented by Associative Memory.- 1.3.1 Associative Recall.- 1.3.2 Production of Sequences from the Associative Memory.- 1.3.3 On the Meaning of Background and Context.- 1.4 More Abstract Aspects of Memory.- 1.4.1 The Problem of Infinite-State Memory.- 1.4.2 Invariant Representations.- 1.4.3 Symbolic Representations.- 1.4.4 Virtual Images.- 1.4.5 The Logic of Stored Knowledge.- 2. Pattern Mathematics.- 2.1 Mathematical Notations and Methods.- 2.1.1 Vector Space Concepts.- 2.1.2 Matrix Notations.- 2.1.3 Further Properties of Matrices.- 2.1.4 Matrix Equations.- 2.1.5 Projection Operators.- 2.1.6 On Matrix Differential Calculus.- 2.2 Distance Measures for Patterns.- 2.2.1 Measures of Similarity and Distance in Vector Spaces.- 2.2.2 Measures of Similarity and Distance Between Symbol Strings.- 2.2.3 More Accurate Distance Measures for Text.- 3. Classical Learning Systems.- 3.1 The Adaptive Linear Element (Adaline).- 3.1.1 Description of Adaptation by the Stochastic Approximation.- 3.2 The Perceptron.- 3.3 The Learning Matrix.- 3.4 Physical Realization of Adaptive Weights.- 3.4.1 Perceptron and Adaline.- 3.4.2 Classical Conditioning.- 3.4.3 Conjunction Learning Switches.- 3.4.4 Digital Representation of Adaptive Circuits.- 3.4.5 Biological Components.- 4. A New Approach to Adaptive Filters.- 4.1 Survey of Some Necessary Functions.- 4.2 On the \"Transfer Function\" of the Neuron.- 4.3 Models for Basic Adaptive Units.- 4.3.1 On the Linearization of the Basic Unit.- 4.3.2 Various Cases of Adaptation Laws.- 4.3.3 Two Limit Theorems.- 4.3.4 The Novelty Detector.- 4.4 Adaptive Feedback Networks.- 4.4.1 The Autocorrelation Matrix Memory.- 4.4.2 The Novelty Filter.- 5. Self-Organizing Feature Maps.- 5.1 On the Feature Maps of the Brain.- 5.2 Formation of Localized Responses by Lateral Feedback.- 5.3 Computational Simplification of the Process.- 5.3.1 Definition of the Topology-Preserving Mapping.- 5.3.2 A Simple Two-Dimensional Self-Organizing System.- 5.4 Demonstrations of Simple Topology-Preserving Mappings.- 5.4.1 Images of Various Distributions of Input Vectors.- 5.4.2 \"The Magic TV\".- 5.4.3 Mapping by a Feeler Mechanism.- 5.5 Tonotopic Map.- 5.6 Formation of Hierarchical Representations.- 5.6.1 Taxonomy Example.- 5.6.2 Phoneme Map.- 5.7 Mathematical Treatment of Self-Organization.- 5.7.1 Ordering of Weights.- 5.7.2 Convergence Phase.- 5.8 Automatic Selection of Feature Dimensions.- 6. Optimal Associative Mappings.- 6.1 Transfer Function of an Associative Network.- 6.2 Autoassociative Recall as an Orthogonal Projection.- 6.2.1 Orthogonal Projections.- 6.2.2 Error-Correcting Properties of Projections.- 6.3 The Novelty Filter.- 6.3.1 Two Examples of Novelty Filter.- 6.3.2 Novelty Filter as an Autoassociative Memory.- 6.4 Autoassociative Encoding.- 6.4.1 An Example of Autoassociative Encoding.- 6.5 Optimal Associative Mappings.- 6.5.1 The Optimal Linear Associative Mapping.- 6.5.2 Optimal Nonlinear Associative Mappings.- 6.6 Relationship Between Associative Mapping, Linear Regression, and Linear Estimation.- 6.6.1 Relationship of the Associative Mapping to Linear Regression.- 6.6.2 Relationship of the Regression Solution to the Linear Estimator.- 6.7 Recursive Computation of the Optimal Associative Mapping.- 6.7.1 Linear Corrective Algorithms.- 6.7.2 Best Exact Solution (Gradient Projection).- 6.7.3 Best Approximate Solution (Regression).- 6.7.4 Recursive Solution in the General Case.- 6.8 Special Cases.- 6.8.1 The Correlation Matrix Memory.- 6.8.2 Relationship Between Conditional Averages and Optimal Estimator.- 7. Pattern Recognition.- 7.1 Discriminant Functions.- 7.2 Statistical Formulation of Pattern Classification.- 7.3 Comparison Methods.- 7.4 The Subspace Methods of Classification.- 7.4.1 The Basic Subspace Method.- 7.4.2 The Learning Subspace Method (LSM).- 7.5 Learning Vector Quantization.- 7.6 Feature Extraction.- 7.7 Clustering.- 7.7.1 Simple Clustering (Optimization Approach).- 7.7.2 Hierarchical Clustering (Taxonomy Approach).- 7.8 Structural Pattern Recognition Methods.- 8. More About Biological Memory.- 8.1 Physiological Foundations of Memory.- 8.1.1 On the Mechanisms of Memory in Biological Systems.- 8.1.2 Structural Features of Some Neural Networks.- 8.1.3 Functional Features of Neurons.- 8.1.4 Modelling of the Synaptic Plasticity.- 8.1.5 Can the Memory Capacity Ensue from Synaptic Changes?.- 8.2 The Unified Cortical Memory Model.- 8.2.1 The Laminar Network Organization.- 8.2.2 On the Roles of Interneurons.- 8.2.3 Representation of Knowledge Over Memory Fields.- 8.2.4 Self-Controlled Operation of Memory.- 8.3 Collateral Reading.- 8.3.1 Physiological Results Relevant to Modelling.- 8.3.2 Related Modelling.- 9. Notes on Neural Computing.- 9.1 First Theoretical Views of Neural Networks.- 9.2 Motives for the Neural Computing Research.- 9.3 What Could the Purpose of the Neural Networks be?.- 9.4 Definitions of Artificial \"Neural Computing\" and General Notes on Neural Modelling.- 9.5 Are the Biological Neural Functions Localized or Distributed?.- 9.6 Is Nonlinearity Essential to Neural Computing?.- 9.7 Characteristic Differences Between Neural and Digital Computers.- 9.7.1 The Degree of Parallelism of the Neural Networks is Still Higher than that of any \"Massively Parallel\" Digital Computer.- 9.7.2 Why the Neural Signals Cannot be Approximated by Boolean Variables.- 9.7.3 The Neural Circuits do not Implement Finite Automata.- 9.7.4 Undue Views of the Logic Equivalence of the Brain and Computers on a High Level.- 9.8 \"Connectionist Models\".- 9.9 How can the Neural Computers be Programmed?.- 10. Optical Associative Memories.- 10.1 Nonholographic Methods.- 10.2 General Aspects of Holographic Memories.- 10.3 A Simple Principle of Holographic Associative Memory.- 10.4 Addressing in Holographic Memories.- 10.5 Recent Advances of Optical Associative Memories.- Bibliography on Pattern Recognition.- References."
            },
            "slug": "Self-Organization-and-Associative-Memory-Kohonen",
            "title": {
                "fragments": [],
                "text": "Self-Organization and Associative Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The purpose and nature of Biological Memory, as well as some of the aspects of Memory Aspects, are explained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1995854"
                        ],
                        "name": "M. Shiffrar",
                        "slug": "M.-Shiffrar",
                        "structuredName": {
                            "firstName": "Maggie",
                            "lastName": "Shiffrar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shiffrar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2683931"
                        ],
                        "name": "J. Freyd",
                        "slug": "J.-Freyd",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Freyd",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Freyd"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 145567436,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "34aa2366d7f0f130856ca06f6b38826a8bc793b0",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Observers viewed pairs of alternating photographs of a human body in different positions. Shortest-path motion solutions were pitted against anatomically possible movements. With short stimulus onset asynchronies (SOAs), observers tended to report the shortest path despite violations of anatomical constraints. However, with longer SOAs observers became increasingly likely to report the anatomically possible, but longer, paths. This finding, in conjunction with those from a second study, challenges the accepted wisdom that apparent motion paths are independent of the object. Instead, our findings suggest that when given enough time and appropriate stimuli, the visual system prefers at least some object-appropriate apparent motion paths."
            },
            "slug": "Apparent-Motion-of-the-Human-Body-Shiffrar-Freyd",
            "title": {
                "fragments": [],
                "text": "Apparent Motion of the Human Body"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6836790"
                        ],
                        "name": "J. W. McClurkin",
                        "slug": "J.-W.-McClurkin",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "McClurkin",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. W. McClurkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723819"
                        ],
                        "name": "L. Optican",
                        "slug": "L.-Optican",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Optican",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Optican"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3007646"
                        ],
                        "name": "B. Richmond",
                        "slug": "B.-Richmond",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Richmond",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Richmond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2017909"
                        ],
                        "name": "T. Gawne",
                        "slug": "T.-Gawne",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Gawne",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gawne"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35354242,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Psychology"
            ],
            "id": "be8a8c78807d1ab3763ad4188fa86e0588c52867",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The intrinsic neuronal code that carries visual information and the perceptual mechanism for decoding that information are not known. However, multivariate statistics and information theory show that neurons in four visual areas simultaneously carry multiple, stimulus-related messages by utilizing multiplexed temporal codes. The complexity of these temporal messages increases progressively across the visual system, yet the temporal codes overlap in time. Thus, visual perception may depend on the concurrent processing of multiplexed temporal messages from all visual areas."
            },
            "slug": "Concurrent-processing-and-complexity-of-temporally-McClurkin-Optican",
            "title": {
                "fragments": [],
                "text": "Concurrent processing and complexity of temporally encoded neuronal messages in visual perception."
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Multivariate statistics and information theory show that neurons in four visual areas simultaneously carry multiple, stimulus-related messages by utilizing multiplexed temporal codes, suggesting that visual perception may depend on the concurrent processing of multiplexing temporal messages from all visual areas."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137198"
                        ],
                        "name": "R. Shepard",
                        "slug": "R.-Shepard",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Shepard",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shepard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058246261"
                        ],
                        "name": "S. Judd",
                        "slug": "S.-Judd",
                        "structuredName": {
                            "firstName": "Sylvester.",
                            "lastName": "Judd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Judd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 24660386,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9705f25f168f4fe42fdefe553a99412805eb4cb3",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Perspective views of the same three-dimensional object in two orientations, when presented in alternation, produced an illusion of rigid rotation. The minimum cycle duration required for the illusion increased linearly with the angular difference between the orientations and at the same slope for rotations in depth and in the picture plane."
            },
            "slug": "Perceptual-illusion-of-rotation-of-objects.-Shepard-Judd",
            "title": {
                "fragments": [],
                "text": "Perceptual illusion of rotation of three-dimensional objects."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Perspective views of the same three-dimensional object in two orientations, when presented in alternation, produced an illusion of rigid rotation."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4054686"
                        ],
                        "name": "J. Hurrell",
                        "slug": "J.-Hurrell",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hurrell",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hurrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 23769140,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "4283a6212ebdcb4dcc0f1297796f093f9e1f5b08",
            "isKey": false,
            "numCitedBy": 7453,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Greenland ice-core data have revealed large decadal climate variations over the North Atlantic that can be related to a major source of low-frequency variability, the North Atlantic Oscillation. Over the past decade, the Oscillation has remained in one extreme phase during the winters, contributing significantly to the recent wintertime warmth across Europe and to cold conditions in the northwest Atlantic. An evaluation of the atmospheric moisture budget reveals coherent large-scale changes since 1980 that are linked to recent dry conditions over southern Europe and the Mediterranean, whereas northern Europe and parts of Scandinavia have generally experienced wetter than normal conditions."
            },
            "slug": "Decadal-Trends-in-the-North-Atlantic-Oscillation:-Hurrell",
            "title": {
                "fragments": [],
                "text": "Decadal Trends in the North Atlantic Oscillation: Regional Temperatures and Precipitation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An evaluation of the atmospheric moisture budget reveals coherent large-scale changes since 1980 that are linked to recent dry conditions over southern Europe and the Mediterranean, whereas northern Europe and parts of Scandinavia have generally experienced wetter than normal conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060364618"
                        ],
                        "name": "J. Ashby",
                        "slug": "J.-Ashby",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Ashby",
                            "middleNames": [
                                "Gary"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ashby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 116066461,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ebef523c81a685e695202c99c731e9ee47c6a341",
            "isKey": false,
            "numCitedBy": 3656,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "our experimentation could eventually be used to discredit our findings, should they happen not to agree with the original observations. It seems important that all experiments in the rapidly expanding area of endocrine disruption toxicology should be carefully designed and fully reported. The use of concurrent positive and negative control groups also seems to be prudent. These needs are independent of who conducts or sponsors studies. Good science is good science. Finally, it should be noted that the only formal retraction of endocrine disruption data currently encountered derived from an academic laboratory (15), a salutary counterbalance to the assertions that stimulated this letter (1-3)."
            },
            "slug": "References-and-Notes-Ashby",
            "title": {
                "fragments": [],
                "text": "References and Notes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Philos. Trans. R. Soc. London Ser. B"
            },
            "venue": {
                "fragments": [],
                "text": "Philos. Trans. R. Soc. London Ser. B"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Cogn. Neurosci"
            },
            "venue": {
                "fragments": [],
                "text": "J. Cogn. Neurosci"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "AIChE J"
            },
            "venue": {
                "fragments": [],
                "text": "AIChE J"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Available at www.research.att.com/\u03f3yann/ocr/mnist"
            },
            "venue": {
                "fragments": [],
                "text": "Available at www.research.att.com/\u03f3yann/ocr/mnist"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adv. Neural Info. Proc. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Neural Info. Proc. Syst"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pharmacol. Biochem. Behav"
            },
            "venue": {
                "fragments": [],
                "text": "Pharmacol. Biochem. Behav"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Neurosci"
            },
            "venue": {
                "fragments": [],
                "text": "J. Neurosci"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Self-Organisation and Associative Memory (Springer-Verlag, Berlin, ed"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Available at www"
            },
            "venue": {
                "fragments": [],
                "text": "Available at www"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adv. Neural Info. Proc. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Neural Info. Proc. Syst"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For a surface represented as a polyhedral mesh"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Brain Res"
            },
            "venue": {
                "fragments": [],
                "text": "Brain Res"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Annu. Rev. Psychol"
            },
            "venue": {
                "fragments": [],
                "text": "Annu. Rev. Psychol"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Acoust. Soc. Am"
            },
            "venue": {
                "fragments": [],
                "text": "J. Acoust. Soc. Am"
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Isomap embedding of the hand images is available at Science Online at www.sciencemag.org/cgi/ content/full/290/5500/2319/DC1. For additional material and computer code"
            },
            "venue": {
                "fragments": [],
                "text": "The Isomap embedding of the hand images is available at Science Online at www.sciencemag.org/cgi/ content/full/290/5500/2319/DC1. For additional material and computer code"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Acoust. Soc. Am"
            },
            "venue": {
                "fragments": [],
                "text": "J. Acoust. Soc. Am"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "We express our appreciation to S References and Notes"
            },
            "venue": {
                "fragments": [],
                "text": "We express our appreciation to S References and Notes"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Netw"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Netw"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neuropsychobiology"
            },
            "venue": {
                "fragments": [],
                "text": "Neuropsychobiology"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Annu. Rev. Neurosci"
            },
            "venue": {
                "fragments": [],
                "text": "Annu. Rev. Neurosci"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Psychol. Science"
            },
            "venue": {
                "fragments": [],
                "text": "Psychol. Science"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adv. Neural Info. Proc. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Neural Info. Proc. Syst"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adv. Neural Info. Proc. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Neural Info. Proc. Syst"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In order to evaluate the fits of PCA, MDS, and Isomap on comparable grounds, we use the residual variance References and Notes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Neurophysiol"
            },
            "venue": {
                "fragments": [],
                "text": "J. Neurophysiol"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The scale-invariant K parameter is typically easier to set than \u2440, but may yield misleading results when the"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. B. Tenenbaum, Adv. Neural Info. Proc. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "J. B. Tenenbaum, Adv. Neural Info. Proc. Syst"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Brain Res"
            },
            "venue": {
                "fragments": [],
                "text": "Brain Res"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Int. J. Comp. Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Comp. Vision"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mon. Not. R. Astron. Soc"
            },
            "venue": {
                "fragments": [],
                "text": "Mon. Not. R. Astron. Soc"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ann. N.Y. Acad. Sci"
            },
            "venue": {
                "fragments": [],
                "text": "Ann. N.Y. Acad. Sci"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Psychon. Bull. Rev"
            },
            "venue": {
                "fragments": [],
                "text": "Psychon. Bull. Rev"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Am. Stat. Assoc"
            },
            "venue": {
                "fragments": [],
                "text": "Am. Stat. Assoc"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Syst"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Neurosci"
            },
            "venue": {
                "fragments": [],
                "text": "J. Neurosci"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Curr. Opin. Neurobiol"
            },
            "venue": {
                "fragments": [],
                "text": "Curr. Opin. Neurobiol"
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 61,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/A-global-geometric-framework-for-nonlinear-Tenenbaum-Silva/3537fcd0ff99a3b3cb3d279012df826358420556?sort=total-citations"
}