{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303987"
                        ],
                        "name": "J. V. Campenhout",
                        "slug": "J.-V.-Campenhout",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Campenhout",
                            "middleNames": [
                                "M.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Campenhout"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17865740,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "92c209e326e38bccfcac4670d31a989fda25a9b4",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well-known that maximum entropy distributions, subject to appropriate moment constraints, arise in physics and mathematics. In an attempt to find a physical reason for the appearance of maximum entropy distributions, the following theorem is offered. The conditional distribution of X_{l} given the empirical observation (1/n)\\sum^{n}_{i}=_{l}h(X_{i})=\\alpha , where X_{1},X_{2}, \\cdots are independent identically distributed random variables with common density g converges to f_{\\lambda}(x)=e^{\\lambda^{t}h(X)}g(x) (Suitably normalized), where \\lambda is chosen to satisfy \\int f_{lambda}(x)h(x)dx= \\alpha . Thus the conditional distribution of a given random variable X is the (normalized) product of the maximum entropy distribution and the initial distribution. This distribution is the maximum entropy distribution when g is uniform. The proof of this and related results relies heavily on the work of Zabell and Lanford."
            },
            "slug": "Maximum-entropy-and-conditional-probability-Campenhout-Cover",
            "title": {
                "fragments": [],
                "text": "Maximum entropy and conditional probability"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The following theorem is offered, which states that the conditional distribution of a given random variable X is the (normalized) product of the maximum entropy distribution and the initial distribution."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35206065"
                        ],
                        "name": "E. Jaynes",
                        "slug": "E.-Jaynes",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Jaynes",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Jaynes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14478367,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "b3266b25cb2ff34634aff48434652bacb3fede9c",
            "isKey": false,
            "numCitedBy": 342,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "It seems intuitively reasonable that Gibbs' variational principle de\u00ad termining the conditions of heterogeneous equilibrium can be gener\u00ad alized to nonequilibrium conditions. That is, a nonequilibriurn steady state should be the one that makes some kind of generalized-entropy production stationary; and even in the presence of irreversible fluxes, the condition for migrational equilibrium should still be the equality of some generalized chemical potentials. We summarize progress to date toward this goal, reviewing (a) the early history, (b) work of Onsager and first attempts at generalization, (c) the new direction the field took after 1967 with the work of Tykodi and Mitchell, and (d) the present situation and prospects. Our conclu\u00ad sion will be, briefly, that the outlook is good in that the basic principles are believed known; but we do not yet \ufffdnow whether they can be reduced to simple rules immediately useful in practice, in the way that the Gibbs phase rule is useful. For this, we need more experience in the technique of applying them to particular cases, and more data to test some conjectures."
            },
            "slug": "The-Minimum-Entropy-Production-Principle-Jaynes",
            "title": {
                "fragments": [],
                "text": "The Minimum Entropy Production Principle"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772421"
                        ],
                        "name": "P. Fougere",
                        "slug": "P.-Fougere",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Fougere",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fougere"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 129377788,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "11ecf4d19e61cf7a78b5e74e473bed83fb236bc6",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Under certain conditions, Burg maximum entropy spectra of sampled sine waves, in the presence of additive Gaussian white noise, show either spontaneous line splitting (at low noise levels) or appreciable frequency shifting (at moderate noise levels). This difficulty arises because an unnecessary constraint is imposed during the minimization of the prediction error power. When the constraint is relaxed and a lighter one imposed, the error power decreases and the problem is solved. The nature of the constraint is discussed, and the mathematical details of the new method are presented. The new method is verified by using a few simple test cases in which spontaneous line splitting is healed or frequency shifting is reduced drastically (Fougere, 1975)."
            },
            "slug": "A-solution-to-the-problem-of-spontaneous-line-in-Fougere",
            "title": {
                "fragments": [],
                "text": "A solution to the problem of spontaneous line splitting in maximum entropy power spectrum analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2575645"
                        ],
                        "name": "A. Bos",
                        "slug": "A.-Bos",
                        "structuredName": {
                            "firstName": "Adriaan",
                            "lastName": "Bos",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45243448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3769ddaaefe8fc97c9254e09dd16cae000bbaa5",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Maximum entropy spectral analysis is a method for the estimation of power spectra with a higher resolution than can be obtained with conventional techniques. This is achieved by extrapolation of the autocorrelation function in such a way that the entropy of the corresponding probability density function is maximized in each step of the extrapolation. This correspondence also gives a simple interpretation of the method without entropy considerations."
            },
            "slug": "Alternative-interpretation-of-maximum-entropy-Bos",
            "title": {
                "fragments": [],
                "text": "Alternative interpretation of maximum entropy spectral analysis (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "Maximum entropy spectral analysis is a method for the estimation of power spectra with a higher resolution than can be obtained with conventional techniques by extrapolation of the autocorrelation function in such a way that the entropy of the corresponding probability density function is maximized in each step of the extrapolation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35206065"
                        ],
                        "name": "E. Jaynes",
                        "slug": "E.-Jaynes",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Jaynes",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Jaynes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17870175,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "08b67692bc037eada8d3d7ce76cc70994e7c8116",
            "isKey": false,
            "numCitedBy": 10876,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Treatment of the predictive aspect of statistical mechanics as a form of statistical inference is extended to the density-matrix formalism and applied to a discussion of the relation between irreversibility and information loss. A principle of \"statistical complementarity\" is pointed out, according to which the empirically verifiable probabilities of statistical mechanics necessarily correspond to incomplete predictions. A preliminary discussion is given of the second law of thermodynamics and of a certain class of irreversible processes, in an approximation equivalent to that of the semiclassical theory of radiation."
            },
            "slug": "Information-Theory-and-Statistical-Mechanics-Jaynes",
            "title": {
                "fragments": [],
                "text": "Information Theory and Statistical Mechanics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49065525"
                        ],
                        "name": "J. S. Rowlinson",
                        "slug": "J.-S.-Rowlinson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Rowlinson",
                            "middleNames": [
                                "Shipley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. S. Rowlinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36986203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38e5f4892b88be266118fc9795dffdc240e987f1",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The claim that information theory provides a foundation for statistical thermodynamics which is independent of the use of ensembles can be sustained only if probabilities can be determined numerically without treating them as frequencies. The use of Shannon's measure of information to assign probabilities is correct only in the same conditions as justify Gibbs's use of ensembles."
            },
            "slug": "Probability,-Information-and-Entropy-Rowlinson",
            "title": {
                "fragments": [],
                "text": "Probability, Information and Entropy"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The claim that information theory provides a foundation for statistical thermodynamics which is independent of the use of ensembles can be sustained only if probabilities can be determined numerically without treating them as frequencies."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143791812"
                        ],
                        "name": "S. Gull",
                        "slug": "S.-Gull",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gull",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "23120751"
                        ],
                        "name": "G. Daniell",
                        "slug": "G.-Daniell",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Daniell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Daniell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4163124,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f877039f938f84ced099513832b2758e82e07cce",
            "isKey": false,
            "numCitedBy": 914,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Results are presented of a powerful technique for image reconstruction by a maximum entropy method, which is sufficiently fast to be useful for large and complicated images. Although our examples are taken from the fields of radio and X-ray astronomy, the technique is immediately applicable in spectroscopy, electron microscopy, X-ray crystallography, geophysics and virtually any type of optical image processing. Applied to radioastronomical data, the algorithm reveals details not seen by conventional analysis, but which are known to exist."
            },
            "slug": "Image-reconstruction-from-incomplete-and-noisy-data-Gull-Daniell",
            "title": {
                "fragments": [],
                "text": "Image reconstruction from incomplete and noisy data"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34282899"
                        ],
                        "name": "J. Burg",
                        "slug": "J.-Burg",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Burg",
                            "middleNames": [
                                "Parker"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117128529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32adb370a144d22b0dbba18700d94b3bcacbfd71",
            "isKey": false,
            "numCitedBy": 1459,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Maximum-entropy-spectral-analysis.-Burg",
            "title": {
                "fragments": [],
                "text": "Maximum entropy spectral analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 8,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/On-the-rationale-of-maximum-entropy-methods-Jaynes/8c32c4eda83a9e464ab01ee74f243127c38d8662?sort=total-citations"
}