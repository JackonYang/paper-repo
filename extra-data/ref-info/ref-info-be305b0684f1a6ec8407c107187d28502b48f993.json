{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841773"
                        ],
                        "name": "S. Konishi",
                        "slug": "S.-Konishi",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Konishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Konishi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8436115"
                        ],
                        "name": "J. Coughlan",
                        "slug": "J.-Coughlan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Coughlan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Coughlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "So the decision for a single point is made based on an image patch centered at it."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11835209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51a7851893d599d93913dab129efbcf179ab0fdd",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We formulate edge detection as statistical inference. This statistical edge detection is data driven, unlike standard methods for edge detection which are model based. For any set of edge detection filters (implementing local edge cues), we use presegmented images to learn the probability distributions of filter responses conditioned on whether they are evaluated on or off an edge. Edge detection is formulated as a discrimination task specified by a likelihood ratio test on the filter responses. This approach emphasizes the necessity of modeling the image background (the off-edges). We represent the conditional probability distributions nonparametrically and illustrate them on two different data sets of 100 (Sowerby) and 50 (South Florida) images. Multiple edges cues, including chrominance and multiple-scale, are combined by using their joint distributions. Hence, this cue combination is optimal in the statistical sense. We evaluate the effectiveness of different visual cues using the Chernoff information and Receiver Operator Characteristic (ROC) curves. This shows that our approach gives quantitatively better results than the Canny edge detector when the image background contains significant clutter. In addition, it enables us to determine the effectiveness of different edge cues and gives quantitative measures for the advantages of multilevel processing, for the use of chrominance, and for the relative effectiveness of different detectors. Furthermore, we show that we can learn these conditional distributions on one data set and adapt them to the other with only slight degradation of performance without knowing the ground truth on the second data set. This shows that our results are not purely domain specific. We apply the same approach to the spatial grouping of edge cues and obtain analogies to nonmaximal suppression and hysteresis."
            },
            "slug": "Statistical-Edge-Detection:-Learning-and-Evaluating-Konishi-Yuille",
            "title": {
                "fragments": [],
                "text": "Statistical Edge Detection: Learning and Evaluating Edge Cues"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work uses presegmented images to learn the probability distributions of filter responses conditioned on whether they are evaluated on or off an edge, and evaluates the effectiveness of different visual cues using the Chernoff information and Receiver Operator Characteristic (ROC) curves."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "\u2026we avoid traversing the entire tree by recursing to both subtrees only if the sample is near the decision boundary:\nIf q(+1|x)\u2212 1 2 > \u03b5: p\u0303(y|x) = q(+1|x)p\u0303R(y|x) + q(\u22121|x)q\u0302L(y) else if q(\u22121|x)\u2212 1 2\n> \u03b5: p\u0303(y|x) = q(+1|x)q\u0302R(y) + q(\u22121|x)p\u0303L(y|x)\nelse: p\u0303(y|x) = q(+1|x)p\u0303R(y|x) +\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "For each sample (xi, yi, wi) compute q(+1|xi) and q(\u22121|xi), then:\n(xi, yi, wi \u2217 q(+1|xi)) \u2192 SR (xi, yi, wi \u2217 q(\u22121|xi)) \u2192 SL.\nFinally normalize all the weights in SL and also SR.\n6."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This makes our method very versatile, and as we show in the experiments section we were able to apply it to a very broad range of domains."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 235084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cb4d685b47001652b29dc41c1b3e786277e7647",
            "isKey": true,
            "numCitedBy": 4016,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [4]. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performance comparable to the best previous systems [16, 11, 14, 10, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second. Author email: fPaul.Viola,Mike.J.Jonesg@compaq.com c Compaq Computer Corporation, 2001 This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of the Cambridge Research Laboratory of Compaq Computer Corporation in Cambridge, Massachusetts; an acknowledgment of the authors and individual contributors to the work; and all applicable portions of the copyright notice. Copying, reproducing, or republishing for any other purpose shall require a license with payment of fee to the Cambridge Research Laboratory. All rights reserved. CRL Technical reports are available on the CRL\u2019s web page at http://crl.research.compaq.com. Compaq Computer Corporation Cambridge Research Laboratory One Cambridge Center Cambridge, Massachusetts 02142 USA"
            },
            "slug": "Robust-Real-time-Object-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-time Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates is described, with the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some results are shown in Figure (5)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "SB is supported by NSF-CAREER Award #0448615 and the Alfred P. Sloan Research Fellowship."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "Some results on gray scale images are shown in Figure (8)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "So the decision for a single point is made based on an image patch centered at it."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "We experimented with using the output of the Canny edge detector at various scales as input to our method, although these Canny features were not very informative and for speed reasons were not included in the final version of our classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "\u2026all the rules needed for edge detection, for example how to exploit all sorts of mid-level Gestalt laws such as junction, parallelism, symmetry, and closure, how to deal with texture and color, how to resolve disagreements between cues that give conflicting local information, and so on, even\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8165754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33a7a59f785ef46091c30c4c85ef88c6bdabab51",
            "isKey": true,
            "numCitedBy": 2381,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "slug": "Learning-to-detect-natural-image-boundaries-using-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Learning to detect natural image boundaries using local brightness, color, and texture cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The two main results are that cue combination can be performed adequately with a simple linear model and that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "A number of tasks in computer vision can be formulated as finding a likely interpretation W for an observed image\nI, where W includes information about the spatial location and extent of objects, regions, object boundaries, curves and so on."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "Methods that rely on local features, such as the Canny [2] detector, do not take into account the context (e.g. if the surrounding area is textured), mid-level information (e.g. the Gestalt laws [12]), or\n\u2217This work was performed while PD and ZT were at Siemens Corporate Research.\nhigh level\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13284142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec",
            "isKey": false,
            "numCitedBy": 27659,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge."
            },
            "slug": "A-Computational-Approach-to-Edge-Detection-Canny",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a natural uncertainty principle between detection and localization performance, which are the two main goals, and with this principle a single operator shape is derived which is optimal at any scale."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We present an extension of the probabilistic boosting tree algorithm that copes with this data much better than did either boosting or cascade approaches [ 22 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Cascades of boosted classifiers [ 22 ] allow for efficient evaluation, and combined with bootstrapping allow for training on very large datasets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Features included gradients at multiple scales and locations, differences between histograms computed over filter responses (difference of Gaussian (DoG) and difference of offset Gaussian (DooG)) again at multiple scales and locations, and also Haar wavelets[ 22 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": true,
            "numCitedBy": 11222,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "A number of tasks in computer vision can be formulated as finding a likely interpretation W for an observed image\nI, where W includes information about the spatial location and extent of objects, regions, object boundaries, curves and so on."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "The goal is to classify each pixel as belonging to a road or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "The method in [19] uses edges obtained from bottom-up (discriminative) processes as proposals to guide the top-down (generative) search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5839283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8392ada55a60ba7814aaf4ad32d1a014d1acbeae",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of curvilinear grouping using piece-wise linear representations of contours and a conditional random field to capture continuity and the frequency of different junction types. Potential completions are generated by building a constrained Delaunay triangulation (CDT) over the set of contours found by a local edge detector. Maximum likelihood parameters for the model are learned from human labeled ground truth. Using held out test data, we measure how the model, by incorporating continuity structure, improves boundary detection over the local edge detector. We also compare performance with a baseline local classifier that operates on pairs of edgels. Both algorithms consistently dominate the low-level boundary detector at all thresholds. To our knowledge, this is the first time that curvilinear continuity has been shown quantitatively useful for a large variety of natural images. Better boundary detection has immediate application in the problem of object detection and recognition"
            },
            "slug": "Scale-invariant-contour-completion-using-random-Ren-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Scale-invariant contour completion using conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This is the first time that curvilinear continuity has been shown quantitatively useful for a large variety of natural images and better boundary detection has immediate application in the problem of object detection and recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8540654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e56ae29377bff8e04336c778cac011f2bcf2b88",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a new learning framework - probabilistic boosting-tree (PBT), is proposed for learning two-class and multi-class discriminative models. In the learning stage, the probabilistic boosting-tree automatically constructs a tree in which each node combines a number of weak classifiers (evidence, knowledge,) into a strong classifier (a conditional posterior probability). It approaches the target posterior distribution by data augmentation (tree expansion) through a divide-and-conquer strategy. In the testing stage, the conditional probability is computed at each tree node based on the learned classifier, which guides the probability propagation in its sub-trees. The top node of the tree therefore outputs the overall posterior probability by integrating the probabilities gathered from its sub-trees. Also, clustering is naturally embedded in the learning phase and each sub-tree represents a cluster of certain level. The proposed framework is very general and it has interesting connections to a number of existing methods such as the A* algorithm, decision tree algorithms, generative models, and cascade approaches. In this paper, we show the applications of PBT for classification, detection, and object recognition. We have also applied the framework in segmentation"
            },
            "slug": "Probabilistic-boosting-tree:-learning-models-for-Tu",
            "title": {
                "fragments": [],
                "text": "Probabilistic boosting-tree: learning discriminative models for classification, recognition, and clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The applications of PBT for classification, detection, and object recognition are shown and the framework has interesting connections to a number of existing methods such as the A* algorithm, decision tree algorithms, generative models, and cascade approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "Just as in training, we avoid traversing the entire tree by recursing to both subtrees only if the sample is near the decision boundary:\nIf q(+1|x)\u2212 1 2 > \u03b5: p\u0303(y|x) = q(+1|x)p\u0303R(y|x) + q(\u22121|x)q\u0302L(y) else if q(\u22121|x)\u2212 1 2\n> \u03b5: p\u0303(y|x) = q(+1|x)q\u0302R(y) + q(\u22121|x)p\u0303L(y|x)\nelse: p\u0303(y|x) = q(+1|x)p\u0303R(y|x)\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 9913392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f4493eff2531536a7aeb3fc11d62c30a8f487f6",
            "isKey": false,
            "numCitedBy": 4825,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting is one of the most important recent developments in classification methodology. Boosting works by sequentially applying a classification algorithm to reweighted versions of the training data and then taking a weighted majority vote of the sequence of classifiers thus produced. For many classification algorithms, this simple strategy results in dramatic improvements in performance. We show that this seemingly mysterious phenomenon can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multiclass generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multiclass generalizations of boosting in most situations, and far superior in some. We suggest a minor modification to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-first truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally, making it more suitable to large-scale data mining applications."
            },
            "slug": "Special-Invited-Paper-Additive-logistic-regression:-Friedman",
            "title": {
                "fragments": [],
                "text": "Special Invited Paper-Additive logistic regression: A statistical view of boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that this seemingly mysterious phenomenon of boosting can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood, and develops more direct approximations and shows that they exhibit nearly identical results to boosting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772671"
                        ],
                        "name": "Xiangrong Chen",
                        "slug": "Xiangrong-Chen",
                        "structuredName": {
                            "firstName": "Xiangrong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangrong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "high level information (e.g. object knowledge [ 19 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The method in [ 19 ] uses edges obtained from bottom-up (discriminative) processes as proposals to guide the top-down (generative) search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Complex generative models, such as presented in [ 19 , 15], have the potential to integrate both low-level and high-level information but present significant computational challenges."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A representative set is given by [2, 14,  19 , 15], we review each in some detail below."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1752880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47f3de18f63136823c523f74460ddb7a014bda7a",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a Bayesian framework for parsing images into their constituent visual patterns. The parsing algorithm optimizes the posterior probability and outputs a scene representation as a \u201cparsing graph\u201d, in a spirit similar to parsing sentences in speech and natural language. The algorithm constructs the parsing graph and re-configures it dynamically using a set of moves, which are mostly reversible Markov chain jumps. This computational framework integrates two popular inference approaches\u2014generative (top-down) methods and discriminative (bottom-up) methods. The former formulates the posterior probability in terms of generative models for images defined by likelihood functions and priors. The latter computes discriminative probabilities based on a sequence (cascade) of bottom-up tests/filters. In our Markov chain algorithm design, the posterior probability, defined by the generative models, is the invariant (target) probability for the Markov chain, and the discriminative probabilities are used to construct proposal probabilities to drive the Markov chain. Intuitively, the bottom-up discriminative probabilities activate top-down generative models. In this paper, we focus on two types of visual patterns\u2014generic visual patterns, such as texture and shading, and object patterns including human faces and text. These types of patterns compete and cooperate to explain the image and so image parsing unifies image segmentation, object detection, and recognition (if we use generic visual patterns only then image parsing will correspond to image segmentation (Tu and Zhu, 2002. IEEE Trans. PAMI, 24(5):657\u2013673). We illustrate our algorithm on natural images of complex city scenes and show examples where image segmentation can be improved by allowing object specific knowledge to disambiguate low-level segmentation cues, and conversely where object detection can be improved by using generic visual patterns to explain away shadows and occlusions."
            },
            "slug": "Image-Parsing:-Unifying-Segmentation,-Detection,-Tu-Chen",
            "title": {
                "fragments": [],
                "text": "Image Parsing: Unifying Segmentation, Detection, and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A Bayesian framework for parsing images into their constituent visual patterns that optimizes the posterior probability and outputs a scene representation as a \u201cparsing graph\u201d, in a spirit similar to parsing sentences in speech and natural language is presented."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "Just as in training, we avoid traversing the entire tree by recursing to both subtrees only if the sample is near the decision boundary:\nIf q(+1|x)\u2212 1 2 > \u03b5: p\u0303(y|x) = q(+1|x)p\u0303R(y|x) + q(\u22121|x)q\u0302L(y) else if q(\u22121|x)\u2212 1 2\n> \u03b5: p\u0303(y|x) = q(+1|x)q\u0302R(y) + q(\u22121|x)p\u0303L(y|x)\nelse: p\u0303(y|x) = q(+1|x)p\u0303R(y|x)\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6644398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccf5208521cb8c35f50ee8873df89294b8ed7292",
            "isKey": false,
            "numCitedBy": 13118,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
            },
            "slug": "A-decision-theoretic-generalization-of-on-line-and-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "A decision-theoretic generalization of on-line learning and an application to boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The model studied can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting, and it is shown that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2521020"
                        ],
                        "name": "B. Jedynak",
                        "slug": "B.-Jedynak",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Jedynak",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jedynak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Road detection is a well known problem, see for example [6]; here we show that our algorithm is directly applicable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7358010,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0ce6df6d6f009cbdd5f8c395bd422581e9aa0769",
            "isKey": false,
            "numCitedBy": 598,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for tracking roads from satellite images, and thereby illustrate a general computational strategy (\"active testing\") for tracking 1D structures and other recognition tasks in computer vision. Our approach is related to recent work in active vision on \"where to look next\" and motivated by the \"divide-and-conquer\" strategy of parlour games. We choose \"tests\" (matched filters for short road segments) one at a time in order to remove as much uncertainty as possible about the \"true hypothesis\" (road position) given the results of the previous tests. The tests are chosen online based on a statistical model for the joint distribution of tests and hypotheses. The problem of minimizing uncertainty (measured by entropy) is formulated in simple and explicit analytical terms. At each iteration new image data are examined and a new entropy minimization problem is solved (exactly), resulting in a new image location to inspect, and so forth. We report experiments using panchromatic SPOT satellite imagery with a ground resolution of ten meters."
            },
            "slug": "An-Active-Testing-Model-for-Tracking-Roads-in-Geman-Jedynak",
            "title": {
                "fragments": [],
                "text": "An Active Testing Model for Tracking Roads in Satellite Images"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A new approach for tracking roads from satellite images, and thereby illustrate a general computational strategy for tracking 1D structures and other recognition tasks in computer vision, related to recent work in active vision and motivated by the \"divide-and-conquer\" strategy of parlour games."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320582"
                        ],
                        "name": "Visvanathan Ramesh",
                        "slug": "Visvanathan-Ramesh",
                        "structuredName": {
                            "firstName": "Visvanathan",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visvanathan Ramesh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "A number of tasks in computer vision can be formulated as finding a likely interpretation W for an observed image\nI, where W includes information about the spatial location and extent of objects, regions, object boundaries, curves and so on."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59792530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c7c9360c6c126cf02af4e63c019b6882147d7c1",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "Image Understanding (IU) Systems are complex and they are composed of different algorithms applied in sequence. A system for model-based recognition has three essential components: feature extraction, grouping and model matching. In each of these components, tuning parameters (thresholds) are often used. These parameters have been traditionally chosen by trial and error or from empirical data. In this dissertation we discuss a methodology for the analysis and design of IU algorithms and systems that follows sound systems engineering principles. We illustrate how the algorithm parameters can be optimally selected for a given image understanding algorithm sequence that accomplishes an IU task. The essential steps for each of the algorithm components involved are: component identification (performance characterization), and application domain characterization (achieved by an annotation). There is an optimization step that is used to optimize a criterion function relevant to the final task. \nPerformance characterization of an algorithm involves the establishment of the correspondence between random perturbations in the input to the random perturbations in the output. This involves the setup of the model for the output random perturbations for a given ideal input model and input random perturbation model. \nGiven these models and a criterion function, it is possible to characterize the performance of the algorithm as a function of its tuning parameters and automatically set the tuning parameters. The specification of the model for the population of ideal input data varies with problem domain. Domain-specific prior information on the parameters that describe the ideal input data is gathered during the annotation step. Appropriate theoretical approximations for the prior distributions are then specified, validated and utilized in computing the performance of the algorithm over the entire input population. Tuning parameters are selected to optimize the performance over the input population."
            },
            "slug": "Performance-characterization-of-image-understanding-Ramesh",
            "title": {
                "fragments": [],
                "text": "Performance characterization of image understanding algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This dissertation discusses a methodology for the analysis and design of IU algorithms and systems that follows sound systems engineering principles and illustrates how the algorithm parameters can be optimally selected for a given image understanding algorithm sequence that accomplishes an IU task."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2955375"
                        ],
                        "name": "L. Williams",
                        "slug": "L.-Williams",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Williams",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 57
                            }
                        ],
                        "text": "Though there has been substantial work done in this vein [3, 7, 8, 15, 23], individual studies tend to focus on particular Gestalt laws, and it is not clear how to combine them into a unified framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12429143,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0fd62892dc5919d48ed03e7874bab66fb9d7e5ca",
            "isKey": false,
            "numCitedBy": 284,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an algorithm and representation-level theory of illusory contour shape and salience. Unlike previous theories, our model is derived from a single assumption: that the prior probability distribution of boundary completion shape can be modeled by a random walk in a lattice whose points are positions and orientations in the image plane (i.e., the space that one can reasonably assume is represented by neurons of the mammalian visual cortex). Our model does not employ numerical relaxation or other explicit minimization, but instead relies on the fact that the probability that a particle following a random walk will pass through a given position and orientation on a path joining two boundary fragments can be computed directly as the product of two vector-field convolutions. We show that for the random walk we define, the maximum likelihood paths are curves of least energy, that is, on average, random walks follow paths commonly assumed to model the shape of illusory contours. A computer model is demonstrated on numerous illusory contour stimuli from the literature."
            },
            "slug": "Stochastic-Completion-Fields:-A-Neural-Model-of-and-Williams-Jacobs",
            "title": {
                "fragments": [],
                "text": "Stochastic Completion Fields: A Neural Model of Illusory Contour Shape and Salience"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An algorithm and representation-level theory of illusory contour shape and salience that relies on the fact that the probability that a particle following a random walk will pass through a given position and orientation on a path joining two boundary fragments can be computed directly as the product of two vector-field convolutions."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747779"
                        ],
                        "name": "Aaron Hertzmann",
                        "slug": "Aaron-Hertzmann",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Hertzmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Hertzmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10251113"
                        ],
                        "name": "C. Jacobs",
                        "slug": "C.-Jacobs",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060131244"
                        ],
                        "name": "Nuria Oliver",
                        "slug": "Nuria-Oliver",
                        "structuredName": {
                            "firstName": "Nuria",
                            "lastName": "Oliver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nuria Oliver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800609"
                        ],
                        "name": "B. Curless",
                        "slug": "B.-Curless",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Curless",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Curless"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some results are shown in Figure (5)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2201072,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "923562d216386a88947d40da310d94bbb1376a41",
            "isKey": false,
            "numCitedBy": 1639,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new framework for processing images by example, called \u201cimage analogies.\u201d The framework involves two stages: a design phase, in which a pair of images, with one image purported to be a \u201cfiltered\u201d version of the other, is presented as \u201ctraining data\u201d; and an application phase, in which the learned filter is applied to some new target image in order to create an \u201canalogous\u201d filtered result. Image analogies are based on a simple multi-scale autoregression, inspired primarily by recent results in texture synthesis. By choosing different types of source image pairs as input, the framework supports a wide variety of \u201cimage filter\u201d effects, including traditional image filters, such as blurring or embossing; improved texture synthesis, in which some textures are synthesized with higher quality than by previous approaches; super-resolution, in which a higher-resolution image is inferred from a low-resolution source; texture transfer, in which images are \u201ctexturized\u201d with some arbitrary source texture; artistic filters, in which various drawing and painting styles are synthesized based on scanned real-world examples; and texture-by-numbers, in which realistic scenes, composed of a variety of textures, are created using a simple painting interface."
            },
            "slug": "Image-analogies-Hertzmann-Jacobs",
            "title": {
                "fragments": [],
                "text": "Image analogies"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a new framework for processing images by example, called \u201cimage analogies,\u201d based on a simple multi-scale autoregression, inspired primarily by recent results in texture synthesis."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50626295"
                        ],
                        "name": "J. Sullivan",
                        "slug": "J.-Sullivan",
                        "structuredName": {
                            "firstName": "Josephine",
                            "lastName": "Sullivan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sullivan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "It finds application in tasks such as object detection/recognition, structure from motion, segmentation and tracking, e.g. [17, 18, 1, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16234776,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa96efb495cbf73da18737cdaa2200d597015476",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Human activity can be described as a sequence of 3D body postures. The traditional approach to recognition and 3D reconstruction of human activity has been to track motion in 3D, mainly using advanced geometric and dynamic models. In this paper we reverse this process. View based activity recognition serves as an input to a human body location tracker with the ultimate goal of 3D reanimation in mind. We demonstrate that specific human actions can be detected from single frame postures in a video sequence. By recognizing the image of a person's posture as corresponding to a particular key frame from a set of stored key frames, it is possible to map body locations from the key frames to actual frames. This is achieved using a shape matching algorithm based on qualitative similarity that computes point to point correspondence between shapes, together with information about appearance. As the mapping is from fixed key frames, our tracking does not suffer from the problem of having to reinitialise when it gets lost. It is effectively a closed loop. We present experimental results both for recognition and tracking for a sequence of a tennis player."
            },
            "slug": "Recognizing-and-Tracking-Human-Action-Sullivan-Carlsson",
            "title": {
                "fragments": [],
                "text": "Recognizing and Tracking Human Action"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated that specific human actions can be detected from single frame postures in a video sequence and identified using a shape matching algorithm based on qualitative similarity that computes point to point correspondence between shapes, together with information about appearance."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31589308"
                        ],
                        "name": "C. J. Taylor",
                        "slug": "C.-J.-Taylor",
                        "structuredName": {
                            "firstName": "Camillo",
                            "lastName": "Taylor",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "It finds application in tasks such as object detection/recognition, structure from motion, segmentation and tracking, e.g. [17, 18, 1, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2497525,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "db89c7cea6094cb71162462508e013e769aaad05",
            "isKey": false,
            "numCitedBy": 300,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach for recovering the structure of a rigid scene composed of straight line segments and the pose of moving camera from multiple images under perspective projection is presented. Recovery is formulated as minimizing the total squared image distance between measured segments and the projection of the reconstructed infinite lines with respect to structural and motion parameters. An efficient algorithm for minimizing this nonlinear objective function is presented. The approach can be directly used for accurately locating correspondences in multieyed stereo, as well as for pose estimation from landmarks. Its effectiveness is demonstrated quantitatively through simulation and qualitatively with a real image sequence.<<ETX>>"
            },
            "slug": "Structure-and-motion-from-line-segments-in-multiple-Taylor-Kriegman",
            "title": {
                "fragments": [],
                "text": "Structure and Motion from Line Segments in Multiple Images"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A new method for recovering the three dimensional structure of a scene composed of straight line segments using the image data obtained from a moving camera using an objective function which measures the total squared distance in the image plane between the observed edge segments and the projections (perspective) of the reconstructed lines."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424812"
                        ],
                        "name": "K. Branson",
                        "slug": "K.-Branson",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Branson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Branson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 133
                            }
                        ],
                        "text": "It finds application in tasks such as object detection/recognition, structure from motion, segmentation and tracking, e.g. [17, 18, 1, 21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 552833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07eb0776cebbb753558389017e18872c4e0ae1eb",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a particle filtering algorithm for robustly tracking the contours of multiple deformable objects through severe occlusions. Our algorithm combines a multiple blob tracker with a contour tracker in a manner that keeps the required number of samples small. This is a natural combination because both algorithms have complementary strengths. The multiple blob tracker uses a natural multi-target model and searches a smaller and simpler space. On the other hand, contour tracking gives more fine-tuned results and relies on cues that are available during severe occlusions. Our choice of combination of these two algorithms accentuates the advantages of each. We demonstrate good performance on challenging video of three identical mice that contains multiple instances of severe occlusion."
            },
            "slug": "Tracking-multiple-mouse-contours-(without-too-many-Branson-Belongie",
            "title": {
                "fragments": [],
                "text": "Tracking multiple mouse contours (without too many samples)"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A particle filtering algorithm for robustly tracking the contours of multiple deformable objects through severe occlusions that combines a multiple blob tracker with a contour tracker in a manner that keeps the required number of samples small."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870855"
                        ],
                        "name": "Cheng-en Guo",
                        "slug": "Cheng-en-Guo",
                        "structuredName": {
                            "firstName": "Cheng-en",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-en Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39092098"
                        ],
                        "name": "Y. Wu",
                        "slug": "Y.-Wu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Wu",
                            "middleNames": [
                                "Nian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "The goal is to classify each pixel as belonging to a road or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "They can also serve as a basis for other forms of image representation, such as the primal sketch [10, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7035968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d60da7c722f8c75ebf0bcbbb72bd465715b14c1",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a mathematical theory for Marr's primal sketch. We first conduct a theoretical study of the descriptive Markov random field model and the generative wavelet/sparse coding model from the perspective of entropy and complexity. The competition between the two types of models defines the concept of \"sketchability\", which divides image into texture and geometry. We then propose a primal sketch model that integrates the two models and, in addition, a Gestalt field model for spatial organization. We also propose a sketching pursuit process that coordinates the competition between two pursuit algorithms: the matching pursuit (Mallat and Zhang, 1993) and the filter pursuit (Zhu, et al., 1997), that seek to explain the image by bases and filters respectively. The model can be used to learn a dictionary of image primitives, or textons in Julesz's language, for natural images. The primal sketch model is not only parsimonious for image representation, but produces meaningful sketches over a large number of generic images."
            },
            "slug": "Towards-a-mathematical-theory-of-primal-sketch-and-Guo-Zhu",
            "title": {
                "fragments": [],
                "text": "Towards a mathematical theory of primal sketch and sketchability"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A primal sketch model is proposed that integrates the descriptive Markov random field model and the generative wavelet/sparse coding model and, in addition, a Gestalt field model for spatial organization that produces meaningful sketches over a large number of generic images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152964847"
                        ],
                        "name": "Manish Singh",
                        "slug": "Manish-Singh",
                        "structuredName": {
                            "firstName": "Manish",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manish Singh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "Modal completion occurs when portions of an object are occluded by another object that happens to have the same color as nearby regions [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19015361,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bc63ef0576dab3cdf22adebcf281b32be75ae51e",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Mechanisms of contour completion are critical for computing visual surface structure in the face of occlusion. Theories of visual completion posit that mechanisms of contour interpolation operate independently of whether the completion is modal or amodal\u2014thereby generating identical shapes in the two cases. This identity hypothesis was tested in two experiments using a configuration of two overlapping objects and a modified Kanizsa configuration. Participants adjusted the shape of a comparison display in order to match the shape of perceived interpolated contours in a standard completion display. Results revealed large and systematic shape differences between modal and amodal contours in both configurations. Participants perceived amodal (i.e., partly occluded) contours to be systematically more angular\u2014that is, closer to a corner\u2014than corresponding modal (i.e., illusory) contours. The results falsify the identity hypothesis in its current form: Corresponding modal and amodal contours can have different shapes, and, therefore, mechanisms of contour interpolation cannot be independent of completion type."
            },
            "slug": "Modal-and-Amodal-Completion-Generate-Different-Singh",
            "title": {
                "fragments": [],
                "text": "Modal and Amodal Completion Generate Different Shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The results falsify the identity hypothesis in its current form: Corresponding modal and amodal contours can have different shapes, and, therefore, mechanisms of contour interpolation cannot be independent of completion type."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological science"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114409274"
                        ],
                        "name": "K. Koffka",
                        "slug": "K.-Koffka",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Koffka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Koffka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Each satellite image is aligned with its road map; to generate the ground truth we converted the road map to a binary mask (the process could easily be automated)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1775179,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c6688c195b3f30267f4a832605e4d8904de9bd64",
            "isKey": false,
            "numCitedBy": 3010,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Routledge is now re-issuing this prestigious series of 204 volumes originally published between 1910 and 1965. The titles include works by key figures such asC.G. Jung, Sigmund Freud, Jean Piaget, Otto Rank, James Hillman, Erich Fromm, Karen Horney and Susan Isaacs. Each volume is available on its own, as part of a themed mini-set, or as part of a specially-priced 204-volume set. A brochure listing each title in the \"International Library of Psychology\" series is available upon request."
            },
            "slug": "Principles-Of-Gestalt-Psychology-Koffka",
            "title": {
                "fragments": [],
                "text": "Principles of Gestalt Psychology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1936
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51921883"
                        ],
                        "name": "Refractor",
                        "slug": "Refractor",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Refractor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Refractor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 208793436,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "c3a24b0b38922c4f3a825edb97cc470a4ca7af75",
            "isKey": false,
            "numCitedBy": 3113,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-Refractor",
            "title": {
                "fragments": [],
                "text": "Vision"
            },
            "venue": {
                "fragments": [],
                "text": "The Lancet"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97504239"
                        ],
                        "name": "J. Urry",
                        "slug": "J.-Urry",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Urry",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Urry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 57
                            }
                        ],
                        "text": "Though there has been substantial work done in this vein [3, 7, 8, 15, 23], individual studies tend to focus on particular Gestalt laws, and it is not clear how to combine them into a unified framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 220894599,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "12424ea599562fdca9222880a94b49f44eec6d35",
            "isKey": false,
            "numCitedBy": 1080,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The term \u2018complexity\u2019 has recently sprung into the physical and social sciences, humanities and semi-popular writings. \u2018Complexity\u2019 practices are constituted as something of a self-organizing global network that is spreading \u2018complexity\u2019 notions around the globe. There is a new \u2018structure of feeling\u2019 that complexity approaches both signify and enhance. Such an emergent structure of feeling involves a greater sense of contingent openness to people, corporations and societies, of the unpredictability of outcomes in time\u2013space, of a charity towards objects and nature, of the diverse and non-linear changes in relationships, households and persons, and of the sheer increase in the hyper-complexity of products, technologies and socialities."
            },
            "slug": "Complexity-Urry",
            "title": {
                "fragments": [],
                "text": "Complexity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "The goal is to classify each pixel as belonging to a road or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Complexity, Confusion, and Perceptual Grouping"
            },
            "venue": {
                "fragments": [],
                "text": "Complexity, Confusion, and Perceptual Grouping"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "The goal is to classify each pixel as belonging to a road or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perceptual Grouping and the Bayesian Statistics of Natural Scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Bayes"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 48
                            }
                        ],
                        "text": "Complex generative models, such as presented in [19, 15], have the potential to integrate both low-level and high-level information but present significant computational challenges."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 33
                            }
                        ],
                        "text": "A representative set is given by [2, 14, 19, 15], we review each in some detail below."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "The method in [19] uses edges obtained from bottom-up (discriminative) processes as proposals to guide the top-down (generative) search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Parsing: Unifying Segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Detection, and Object Recognition\u201d,  IJCV"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 166
                            }
                        ],
                        "text": "The Gestalt laws of perceptual organization, including symmetry, closure, parallelism and so on, are rules of how component parts are organized into overall patterns [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "the Gestalt laws [12]), or high level information ( e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Principles of Gestalt Psychology\u201d, New York: Harcourt, Brace and company"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1935
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "There have been many methods proposed for edge detection, we have already mentioned a few."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "A number of tasks in computer vision can be formulated as finding a likely interpretation W for an observed image\nI, where W includes information about the spatial location and extent of objects, regions, object boundaries, curves and so on."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Parsing: Unifying Segmentation, Detection, and Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Image Parsing: Unifying Segmentation, Detection, and Object Recognition"
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 21,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Supervised-Learning-of-Edges-and-Object-Boundaries-Doll\u00e1r-Tu/be305b0684f1a6ec8407c107187d28502b48f993?sort=total-citations"
}