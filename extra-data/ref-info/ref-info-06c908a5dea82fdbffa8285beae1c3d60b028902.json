{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2866369"
                        ],
                        "name": "T. Strat",
                        "slug": "T.-Strat",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Strat",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strat"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 158
                            }
                        ],
                        "text": "We have proposed a mechanism whereby context sets can be modi ed automatically, using the experiences of the system to re ne the knowledge base incrementally [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 35
                            }
                        ],
                        "text": "In this paper and its predecessors [7, 8, 21, 22], we have outlined a new paradigm which explicitly invokes context and stored knowledge to control the complexity of the decision-making processes involved in correctly identifying natural objects and describing natural scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35417149,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dab5e5b70114b38a82093b8834a7c5d8493f5bb8",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "An autonomous vehicle that is to operate outdoors must be able to recognize features of the natural world as they appear in ground-level imagery. Geometric reconstruction alone is insufficient for an agent to plan its actions intelligently--objects in the world must be recognized, and not just located. \nMost work in visual recognition by computer has focused on recognizing objects by their geometric shape, or by the presence or absence of some prespecified collection of locally measurable attributes (e.g., spectral reflectance, texture, or distinguished markings). On the other hand, most entities in the natural world defy compact description of their shapes, and have no characteristic features with discriminatory power. As a result, image-understanding research has achieved little success towards recognizing natural scenes. \nIn this thesis we offer a new approach to visual recognition that avoids these limitations and has been used to recognize trees, bushes, grass, and trails in ground-level scenes of a natural environment. Reliable recognition is achieved by employing an architecture with a number of innovative aspects. These include: context-controlled generation of hypotheses instead of universal partitioning; a hypothesis comparison scheme that allows a linear growth in computational complexity as the recognition vocabulary is increased; recognition at the level of complete contexts instead of individual objects; and provisions for contextual information to guide processing at all levels. \nRecognition results are added to a persistent, labeled, three-dimensional model of the environment which is used as context for interpreting subsequent imagery. In this way, the system constructs a description of the objects it sees, and, at the same time, improves its recognition abilities by exploiting the context provided by what it has previously recognized."
            },
            "slug": "Natural-Object-Recognition-Strat",
            "title": {
                "fragments": [],
                "text": "Natural Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A new approach to visual recognition is offered that avoids limitations and has been used to recognize trees, bushes, grass, and trails in ground-level scenes of a natural environment and improves its recognition abilities by exploiting the context provided by what it has previously recognized."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Series in Perception Engineering"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2866369"
                        ],
                        "name": "T. Strat",
                        "slug": "T.-Strat",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Strat",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 35
                            }
                        ],
                        "text": "In this paper and its predecessors [7, 8, 21, 22], we have outlined a new paradigm which explicitly invokes context and stored knowledge to control the complexity of the decision-making processes involved in correctly identifying natural objects and describing natural scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 107594121,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5510faad6864b665d6e04376c3b36505bd47714",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Existing machine vision techniques are not competent to reliably recognize objects in unconstrained views of natural scenes. In this paper we identify a number of weaknesses in current recognition systems, including an inability to solve the partitioning problem or to effectively use context and other types of knowledge beyond that of immediate object appearance. We propose specific mechanisms for dealing with some of these problems and describe the design of a vision system that incorporates these new mechanisms. The system has been partially implemented and we include some experimental results indicative of its operation and performance."
            },
            "slug": "Recognizing-objects-in-a-natural-environment:-a-Fischler-Strat",
            "title": {
                "fragments": [],
                "text": "Recognizing objects in a natural environment: a contextual vision system (CVS)"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A number of weaknesses in current recognition systems, including an inability to solve the partitioning problem or to effectively use context and other types of knowledge beyond that of immediate object appearance, are identified and specific mechanisms for dealing with them are proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2866369"
                        ],
                        "name": "T. Strat",
                        "slug": "T.-Strat",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Strat",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 35
                            }
                        ],
                        "text": "In this paper and its predecessors [7, 8, 21, 22], we have outlined a new paradigm which explicitly invokes context and stored knowledge to control the complexity of the decision-making processes involved in correctly identifying natural objects and describing natural scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62284339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dcba612c414e4b383a829e32ba4868431ca1d5b",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing machine vision techniques are not able to recognize objects in unconstrained views of natural scenes. In this paper we identify a number of weaknesses in current recognition systems, including an inability to use contextual information and other knowledge beyond that of immediate object appearance. We propose specific mechanisms for dealing with some of these problems and describe the design af a vision system that incorporates these new mechanisms. The system has been partially implemented and we include some experimental results indicative of its operation and performance.\u2019"
            },
            "slug": "Context-based-vision:-Recognition-of-natural-scenes-Strat-Fischler",
            "title": {
                "fragments": [],
                "text": "Context-based vision: Recognition of natural scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A number of weaknesses in current recognition systems are identified, including an inability to use contextual information and other knowledge beyond that of immediate object appearance, and specific mechanisms for dealing with some of these problems are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Twenty-Third Asilomar Conference on Signals, Systems and Computers, 1989."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592244"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145440080"
                        ],
                        "name": "S. Weyl",
                        "slug": "S.-Weyl",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Weyl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weyl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 183
                            }
                        ],
                        "text": "There has been some work directed toward the goal of semantic understanding of natural outdoor scenes, but surprisingly, very little new work has been initiated in the last ten years [2, 11, 16, 17, 18, 23, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7835587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25a53745f7e6d39d223ccfae0099dc3efbbf0a26",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An Interactive Scene Interpretation System (ISIS) is being developed by Stanford Research Institute's Artificial Intelligence Center as a tool for constructing and experimenting with man-achine and automatic scene analysis methods tailored for particular image domains. A region analysis subsystem was developed recently based on the work of Brice and Fennema, and Yaklmovsky. Using this subsystem a series of experiments was conducted to determine good criteria for initially partitioning a scene into atomic regions and merging these regions into a final partition of the scene along object boundaries. Semantic (problem-dependent) knowledge is essential for complete, correct partitionis of complex real-world scenes. An interactive approach to semantic scene segmentation was developed and demonstrated on both landscape and indoor scenes. This approach provides a reasonable methodology for segmenting scenes that cannot be processed completely automatically at present and Is a promising basis for a future fully automatic system."
            },
            "slug": "A-Region-Analysis-Subsystem-For-Interactive-Scene-Tenenbaum-Weyl",
            "title": {
                "fragments": [],
                "text": "A Region-Analysis Subsystem For Interactive Scene Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An interactive approach to semantic scene segmentation was developed and demonstrated on both landscape and indoor scenes and provides a reasonable methodology for segmenting scenes that cannot be processed completely automatically at present and is a promising basis for a future fully automatic system."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730461"
                        ],
                        "name": "A. Hanson",
                        "slug": "A.-Hanson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hanson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hanson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "These techniques employ a parameterized model (as in Acronym [5]), or a generic model (as in Fua [9])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "These techniques employ a parameterized model (as in Acronym [5]), or ageneric model (as in Fua [9])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "[9] Fua, Pascal, and Hanson, Andrew J., \\Using Generic Geometric Models for Intelligent ShapeExtraction,\" Proceedings: DARPA Image Understanding Workshop, Los Angeles, California,February 1987, pp. 227{233."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14515301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d85f68371be60fc8d5d8083a27b43c2d98d1022",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Object delineation that is based only on low-level segmentation or edge-finding algorithms is difficult because typical edge maps have either too few object edges or too many irrelevant edges, while object-containing regions are generally oversegmented or undersegmented. We correct these shortcomings by using model-based geometric constraints to produce delineations belonging to generic shape classes. Our work thus supplies an essential link between low-level and high-level image-understanding techniques. We show representative results achieved when our models for buildings, roads, and trees are applied to aerial images."
            },
            "slug": "Using-Generic-Geometric-Models-for-Intelligent-Fua-Hanson",
            "title": {
                "fragments": [],
                "text": "Using Generic Geometric Models for Intelligent Shape Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work corrects shortcomings by using model-based geometric constraints to produce delineations belonging to generic shape classes, supplying an essential link between low-level and high-level image-understanding techniques."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722219"
                        ],
                        "name": "Y. Ohta",
                        "slug": "Y.-Ohta",
                        "structuredName": {
                            "firstName": "Yuichi",
                            "lastName": "Ohta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ohta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 183
                            }
                        ],
                        "text": "There has been some work directed toward the goal of semantic understanding of natural outdoor scenes, but surprisingly, very little new work has been initiated in the last ten years [2, 11, 16, 17, 18, 23, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58823151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d6c884ed12df33dd02b93db81c62060cfe078f0",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In this thesis, we study a region analyzer for color scenes. The major Issues addressed and described here are the following:(1) the role of color information in region segmentation; (2) the technique of partitioning an image into a set of regions; (3) the technique of managing the regions in a symbolic data structure; and (4) the modeling and control scheme for obtaining the \u201dbest\u201d match between the model 0fa task world and the set of regions obtained from an input Image\u3002 Systematic exper:tments have been performed to elx\u00b0\u201dline th role of color information in region segmentation. A segmentation scheme. called \u201ddynamic\u30fb  K. L. transformation\u201d,  was developed for this purpose.  We have found a new set of color features effective for region segmentation\u3002 A powerful segmentation program was developed for preliminarily partitioning an image data Into a set of regions.  The result of segmentation 1S organized into  a well-structured symbolic data network, named \u201dPatchery Data Structure\u201d, with retrieving facilities\u3002 The knowledge of the task world is represented as a set of rules.  Bottom-up control and top-down control are combined in the rule\u2015based region analyzer. A plan is generated by the bottom-up control as a representation of the rough structures in an input scene. A symbolic description of the scene is made in the top-down analysis. The top-down process is constructed by using a production system architecture\u3002 Outdoor scenes Including sky, trees, buildings. and roads have been successfu:Lly analyzed by the system."
            },
            "slug": "A-Region-Oriented-Image-Analysis-System-by-Computer-Ohta",
            "title": {
                "fragments": [],
                "text": "A Region-Oriented Image-Analysis System by Computer"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A region analyzer for color scenes is studied, finding a new set of color features effective for region segmentation and a powerful segmentation program was developed for preliminarily partitioning an image data Into a set of regions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34865602"
                        ],
                        "name": "D. McKeown",
                        "slug": "D.-McKeown",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McKeown",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McKeown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46559289"
                        ],
                        "name": "W. Harvey",
                        "slug": "W.-Harvey",
                        "structuredName": {
                            "firstName": "Wilson",
                            "lastName": "Harvey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Harvey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14828509"
                        ],
                        "name": "J. McDermott",
                        "slug": "J.-McDermott",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "McDermott",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. McDermott"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "The goal, similar in spirit to that employed by McKeown in SPAM [15], is to nd a mutually consistent set of candidates that explains as much of the image as possible."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "The goal, similar in spirit to thatemployed by McKeown in SPAM [15], is to nd a mutually consistent set of candidates thatexplains as much of the image as possible."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1155371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d844f45b56657f9b34d5765a5718b910b603d0b",
            "isKey": false,
            "numCitedBy": 295,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe the organization of a rule-based system, SPAM, that uses map and domain-specific knowledge to interpret airport scenes. This research investigates the use of a rule-based system for the control of image processing and interpretation of results with respect to a world model, as well as the representation of the world model within an image/map database. We present results on the interpretation of a high-resolution airport scene wvhere the image segmentation has been performed by a human, and by a region-based image segmentation program. The results of the system's analysis is characterized by the labeling of individual regions in the image and the collection of these regions into consistent interpretations of the major components of an airport model. These interpretations are ranked on the basis of their overall spatial and structural consistency. Some evaluations based on the results from three evolutionary versions of SPAM are presented."
            },
            "slug": "Rule-Based-Interpretation-of-Aerial-Imagery-McKeown-Harvey",
            "title": {
                "fragments": [],
                "text": "Rule-Based Interpretation of Aerial Imagery"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The organization of a rule-based system, SPAM, that uses map and domain-specific knowledge to interpret airport scenes is described, characterized by the labeling of individual regions in the image and the collection of these regions into consistent interpretations of the major components of an airport model."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730461"
                        ],
                        "name": "A. Hanson",
                        "slug": "A.-Hanson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hanson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hanson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517449"
                        ],
                        "name": "L. Quam",
                        "slug": "L.-Quam",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Quam",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Quam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 45
                            }
                        ],
                        "text": "Inaddition, the CKS has been integrated with SRI's Cartographic Modeling Environment [12]16\nto provide a capability of generating synthetic views of terrain."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "In addition, the CKS has been integrated with SRI's Cartographic Modeling Environment [12] 16"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 129818095,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31aecac22980a8f722c9df6e34c99b131b749c61",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The SRI Cartographic Modeling Environment has been created to support research on interactive, semiautomated, and automated computer-based cartographic activities. The underlying image manipulation capabilities are provided by the SRI ImagCalc(TM) system. The cartographic features and data that can be entered include multiple images, camera models, digital terrain elevation data, point, line, and area cartographic features, and a wide assortment of three-dimensional objects. Interactive capabilities include free-hand feature lighting entry, altering features while constraining them to conform to the terrain and lighting geometry, adjustment of feature parameters, and the adjustment of the camera model to display the scene features from arbitrary viewpoints. Cartographic features are depictable either as wire-frame sketches for interactive purposes or as texture-mapped renderings for realistic scene synthesis. High-quality simulated scenes are created by texture-mapping images onto terrain data and adding renderings of cartographic features using depth-buffering and antialiasing techniques. Motion sequences can be created by choosing a series of camera models and rendering the simulated appearance of the scene from each viewpoint."
            },
            "slug": "Overview-of-the-SRI-Cartographic-Modeling-Hanson-Quam",
            "title": {
                "fragments": [],
                "text": "Overview of the SRI Cartographic Modeling Environment"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The SRI Cartographic Modeling Environment has been created to support research on interactive, semiautomated, and automated computer-based cartographic activities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592244"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "[2] Barrow, Harry G., and Tenenbaum, Jay M., \\MSYS: A System for Reasoning about Scenes,\"Technical Note 121, Arti cial Intelligence Center, SRI International, April 1976."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Hawkeye [3], MSYS [2], and the approach described here, are examples of the few systems that have been designed without a primary reliance on geometric models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Hawkeye [3], MSYS [2], and the approach described here,are examples of the few systems that have been designed without a primary reliance ongeometric models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 183
                            }
                        ],
                        "text": "There has been some work directed toward the goal of semantic understanding of natural outdoor scenes, but surprisingly, very little new work has been initiated in the last ten years [2, 11, 16, 17, 18, 23, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60510746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d625945e6c7dc923d98feeeab91de19107130c83",
            "isKey": true,
            "numCitedBy": 87,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : MSYS is a system for reasoning with uncertain information and inexact rules of inference. Its major application, to date, has been to the interpretation of visual features (such as regions) in scene analysis. In this application, features are assigned sets of possible interpretations with associated likelihoods based on local attributes (e.g., color, size, and shape). Interpretations are related by rules of inference that adjust the likelihoods up or down in accordance with the interpretation likelihoods of related features. An asynchronous relaxation process repeatedly applies the rules until a consistent set of likelihood values is attained. At this point, several alternative interpretations still exist for each feature. One feature is chosen and the most likely of its alternatives is assumed. The rules are then used in this more precise context to determine likelihoods for the interpretations of remaining features by a further round of relaxation. The selection and relaxation steps are repeated until all features have been interpreted."
            },
            "slug": "MSYS:-A-System-for-Reasoning-About-Scenes.-Tenenbaum-Barrow",
            "title": {
                "fragments": [],
                "text": "MSYS: A System for Reasoning About Scenes."
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "MSYS is a system for reasoning with uncertain information and inexact rules of inference that contributes to the interpretation of visual features in scene analysis by repeatedly applying rules until a consistent set of likelihood values is attained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30489560"
                        ],
                        "name": "R. Hummel",
                        "slug": "R.-Hummel",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Hummel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hummel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698824"
                        ],
                        "name": "S. Zucker",
                        "slug": "S.-Zucker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Zucker",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zucker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 183
                            }
                        ],
                        "text": "There has been some work directed toward the goal of semantic understanding of natural outdoor scenes, but surprisingly, very little new work has been initiated in the last ten years [2, 11, 16, 17, 18, 23, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18603445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5df9cdc54c8085781c4199a95576a14cb7198b9d",
            "isKey": false,
            "numCitedBy": 1518,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of objects in a scene whose identifications are ambiguous, it is often possible to use relationships among the objects to reduce or eliminate the ambiguity. A striking example of this approach was given by Waltz [13]. This paper formulates the ambiguity-reduction process in terms of iterated parallel operations (i.e., relaxation operations) performed on an array of (object, identification) data. Several different models of the process are developed, convergence properties of these models are established, and simple examples are given."
            },
            "slug": "Scene-Labeling-by-Relaxation-Operations-Rosenfeld-Hummel",
            "title": {
                "fragments": [],
                "text": "Scene Labeling by Relaxation Operations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper formulates the ambiguity-reduction process in terms of iterated parallel operations (i.e., relaxation operations) performed on an array of object, identification data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72419159"
                        ],
                        "name": "R. Brooks",
                        "slug": "R.-Brooks",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Brooks",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brooks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5711553,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ed34b294b10e8fe49d8584578216d87da2f2de34",
            "isKey": false,
            "numCitedBy": 385,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "ACRONYM is a comprehensive domain independent model-based system for vision and manipulation related tasks. Many of its submodules and representations have been described elsewhere. Here the derivation and use of invariants for image feature prediction is described. Predictions of image features and their relations are made from three-dimensional geometric models. Instructions are generated which teli the interpretation algorithms how to make use of image feature measurements to derive three-dimensional size, structural, and spatial constraints on the original three-dimensional models. Some preliminary examples of ACRONYM's interpretations of aerial images are shown."
            },
            "slug": "Model-Based-Three-Dimensional-Interpretations-of-Brooks",
            "title": {
                "fragments": [],
                "text": "Model-Based Three-Dimensional Interpretations of Two-Dimensional Images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The derivation and use of invariants for image feature prediction is described and predictions of image features and their relations are made from three-dimensional geometric models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727801"
                        ],
                        "name": "K. Laws",
                        "slug": "K.-Laws",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Laws",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Laws"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 600,
                                "start": 595
                            }
                        ],
                        "text": "Algorithm ExplanationASSOCIATION Finds connected sets of pixels in a binary imageSTRIATIONS Finds the orientation and strength of local textureDELINEATION Finds line-like structureOUTLINING Finds the boundary of a regionTHRESHOLDING Uses scale-space techniques to choose thresholdsEDGE FINDING Any of several well-known edge- nding routinesCONTRAST enhancement Stretches the histogram of an imageSMOOTHING Low-pass lterHISTOGRAMMING Computes a histogram and associated statisticsTEXTURE Any of several well-known algorithms for measuring textureSEGMENTATION Completely partitions an image using KNIFE [14]DENSE STEREO Computes a dense depth image using CYCLOPS [1]SPARSE STEREO Computes depths at some easily correlated points [10]HOMOGENEITY A noise tolerant algorithm for measuring local homogeneityTable 1: Candidate generation operatorsType II context sets (candidate evaluation) are assembled from evaluation metrics thatcan be used to compare two candidates."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 616,
                                "start": 612
                            }
                        ],
                        "text": "Algorithm Explanation ASSOCIATION Finds connected sets of pixels in a binary image STRIATIONS Finds the orientation and strength of local texture DELINEATION Finds line-like structure OUTLINING Finds the boundary of a region THRESHOLDING Uses scale-space techniques to choose thresholds EDGE FINDING Any of several well-known edge- nding routines CONTRAST enhancement Stretches the histogram of an image SMOOTHING Low-pass lter HISTOGRAMMING Computes a histogram and associated statistics TEXTURE Any of several well-known algorithms for measuring texture SEGMENTATION Completely partitions an image using KNIFE [14] DENSE STEREO Computes a dense depth image using CYCLOPS [1] SPARSE STEREO Computes depths at some easily correlated points [10] HOMOGENEITY A noise tolerant algorithm for measuring local homogeneity Table 1: Candidate generation operators Type II context sets (candidate evaluation) are assembled from evaluation metrics that can be used to compare two candidates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 65182967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "050d98702d6bf1b08a6f5ee92b560846c834bd8f",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The KNIFE segmentation algorithm interleaves splitting and merging of regionsduring monochrome or multiband image partitioning. KNIFE splitsregions along object boundaries, thus avoiding rectangular quadtree artifactsand establishing a context for good statistical decisions. Its iterative subregionextraction is based on multiband cluster analysis, with histogram-basedthreshold analysis used as a heuristic shortcut in simple cases. Splitting andmerging decisions are based on sloped (rather than constant) surface fits, withsuccessively more powerful thresholds and techniques employed until each regionis split or found homogeneous. The user specifies only a desired level ofsegmentation, which is converted to procedural form by the KNIFE controlprocess. The KNIFE package also offers a region-growing algorithm based onrecursive splitting of neighboring regions. Examples of the two techniques aregiven for the domains of aerial cartography and reconnaissance, target cuing,and navigational vision."
            },
            "slug": "Integrated-Split/Merge-Image-Segmentation-Laws",
            "title": {
                "fragments": [],
                "text": "Integrated Split/Merge Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "The KNIFE segmentation algorithm interleaves splitting and merging of regions during monochrome or multiband image partitioning, thus avoiding rectangular quadtree artifacts and establishing a context for good statistical decisions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3071950"
                        ],
                        "name": "Y. Yakimovsky",
                        "slug": "Y.-Yakimovsky",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Yakimovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yakimovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2165973"
                        ],
                        "name": "J. Feldman",
                        "slug": "J.-Feldman",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Feldman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 183
                            }
                        ],
                        "text": "There has been some work directed toward the goal of semantic understanding of natural outdoor scenes, but surprisingly, very little new work has been initiated in the last ten years [2, 11, 16, 17, 18, 23, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18074297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4178fe9655963e9b361fed0a27b497b04cc480d5",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of breaking an image into meaningful regions is considered. Bayesian decision theory is seen to provide a mechanism for including problem dependent (semantic) information in a general system. Some results are presented which make the computation feasible. A programming system based on these ideas and their application to road scenes is described."
            },
            "slug": "A-Semantics-Based-Decision-Theory-Region-Analyser-Yakimovsky-Feldman",
            "title": {
                "fragments": [],
                "text": "A Semantics-Based Decision Theory Region Analyser"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Bayesian decision theory is seen to provide a mechanism for including problem dependent (semantic) information in a general system and a programming system based on these ideas and their application to road scenes is described."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2866369"
                        ],
                        "name": "T. Strat",
                        "slug": "T.-Strat",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Strat",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103036550"
                        ],
                        "name": "Grahame B. Smith",
                        "slug": "Grahame-B.-Smith",
                        "structuredName": {
                            "firstName": "Grahame",
                            "lastName": "Smith",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Grahame B. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The CKS provides a menu-drivenquery mechanism that is useful for inspecting the intermediate states of computation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The CKS treats allincoming data as the opinions of the data sources, so logical inconsistencies will not corruptthe database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "Rather thanfusing information as it arises, the CKS has the option of postponing combination until itsresults are needed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "The temporal continuityprovided by the information in the CKS allows Condor to improve the results it wouldhave obtained without this additional contextual information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "For an object recognition system like Condor, theCKS seems to provide the right tradeo ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 99
                            }
                        ],
                        "text": "As a result, Condor selects the rst clique as its best interpretation and stores its resultsin the CKS database to be used as context for future reference."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "For example, the CKS can bequeried for all trees within 10 meters of any dirt road, and will nd all such trees regardlessof whether they were originally categorized as oaks or pines or whether any roadway waspresent when they were instantiated in the database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "Without range data, Condor uses the imagelocation of detected objects along with a digital terrain model stored in the CKS to constrainthe possible locations of each object."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 214
                            }
                        ],
                        "text": "Condor'srecognition vocabulary is represented as nodes in the semantic network, which allows thesystem to refer to objects at an appropriate level in the abstraction hierarchy.15\n4.2.2 Inheritance and inferenceThe CKS uses the semantic network to perform some limited types of inference that easethe burden of querying the data store."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "Inaddition, the CKS has been integrated with SRI's Cartographic Modeling Environment [12]16\nto provide a capability of generating synthetic views of terrain."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Some information may never be needed, in which case the CKS may foregoits combination entirely."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The CKS is an object-oriented knowledge/database that was originally designed to serveas the central information manager for a perceptual system [19, 20]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "Each candidate is stored in the CKS as the opinion of the cliqueto which it pertains.4.2.4 User interfaceAlthough Condor is designed to be a fully automated recognition system, a comprehensiveuser interface is invaluable for development and debugging."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "The following fourfacilities of the CKS are of particular importance for Condor.4.2.1 Multiple ResolutionThe CKS employs a multiresolution octree to locate objects only as precisely as warranted bythe data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "Upon completion, Condor stores its recognition results in the CKS and reanalyzesthe same image or a similar but di erent image of the same scene."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "In Condor, these capabilities are providedby the Core Knowledge Structure (CKS) [20]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "The results of processing each image are stored in the CKS andmade available as context for analyzing subsequent images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "In Condor, these capabilities are provided by the Core Knowledge Structure (CKS) [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "Candidates depictingpreviously known objects are used to update the location, size, shape, and appearance ofthat object in the CKS."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 146
                            }
                        ],
                        "text": "The CKS is an object-oriented knowledge/database that was originally designed to serve as the central information manager for a perceptual system [19, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64248896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6902c894cbdb0e611b6a855b83e27a3482c09ad",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-KNOWLEDGE-BASED-INFORMATION-MANAGER-FOR-VEHICLES-Strat-Smith",
            "title": {
                "fragments": [],
                "text": "A KNOWLEDGE-BASED INFORMATION MANAGER FOR AUTONOMOUS VEHICLES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076857013"
                        ],
                        "name": "\u5927\u7530 \u53cb\u4e00",
                        "slug": "\u5927\u7530-\u53cb\u4e00",
                        "structuredName": {
                            "firstName": "\u5927\u7530",
                            "lastName": "\u53cb\u4e00",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5927\u7530 \u53cb\u4e00"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57211036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f219a35497ad2e244b8cfc725bcb20a45b1777a5",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-region-oriented-image-analysis-system-by-computer-\u5927\u7530",
            "title": {
                "fragments": [],
                "text": "A region-oriented image-analysis system by computer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144059247"
                        ],
                        "name": "J. Sloan",
                        "slug": "J.-Sloan",
                        "structuredName": {
                            "firstName": "Jr.",
                            "lastName": "Sloan",
                            "middleNames": [
                                "Kenneth",
                                "Robert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sloan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 183
                            }
                        ],
                        "text": "There has been some work directed toward the goal of semantic understanding of natural outdoor scenes, but surprisingly, very little new work has been initiated in the last ten years [2, 11, 16, 17, 18, 23, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54093980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a12033df59bf7baece3adaec87d83b3dccc8d745",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "World-model-driven-recognition-of-natural-scenes.-Sloan",
            "title": {
                "fragments": [],
                "text": "World model driven recognition of natural scenes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 744,
                                "start": 740
                            }
                        ],
                        "text": "Algorithm Explanation ASSOCIATION Finds connected sets of pixels in a binary image STRIATIONS Finds the orientation and strength of local texture DELINEATION Finds line-like structure OUTLINING Finds the boundary of a region THRESHOLDING Uses scale-space techniques to choose thresholds EDGE FINDING Any of several well-known edge- nding routines CONTRAST enhancement Stretches the histogram of an image SMOOTHING Low-pass lter HISTOGRAMMING Computes a histogram and associated statistics TEXTURE Any of several well-known algorithms for measuring texture SEGMENTATION Completely partitions an image using KNIFE [14] DENSE STEREO Computes a dense depth image using CYCLOPS [1] SPARSE STEREO Computes depths at some easily correlated points [10] HOMOGENEITY A noise tolerant algorithm for measuring local homogeneity Table 1: Candidate generation operators Type II context sets (candidate evaluation) are assembled from evaluation metrics that can be used to compare two candidates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SRI's Baseline Stereo System,\" Proceedings: DARPA Image Understanding  Workshop"
            },
            "venue": {
                "fragments": [],
                "text": "Miami Beach, Florida,"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "This makes it computationally feasible to exhaustively search for the presence of these models (via \\geometric alignment\") as a way of producing a suitable description of some given scene (as in [4] and [13], for example)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3DPO: A 3D Part Orientation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 8th International Joint Conference on Arti cial Intelligence,"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 203
                            }
                        ],
                        "text": "This makes it computationally feasible to exhaustively search for the presence of these models (via \\geometric alignment\") as a way of producing a suitable description of some given scene (as in [4] and [13], for example)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing Solid Objects by Alignment,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings: DARPA Image Understanding Workshop,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 35
                            }
                        ],
                        "text": "In this paper and its predecessors [7, 8, 21, 22], we have outlined a new paradigm which explicitly invokes context and stored knowledge to control the complexity of the decision-making processes involved in correctly identifying natural objects and describing natural scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing Trees, Bushes, Rocks and Rivers,\"  Proceedings of the AAAI Spring Symposium Series: Physical and Biological Approaches to"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Recognizing Trees, Bushes, Rocks and Rivers"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the AAAI Spring Symposium Series: Physical and Biological Approaches to Computational Vision"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shimon, \\Recognizing Solid Objects by Alignment"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings: DARPA Image Understanding Workshop"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\VISIONS: A Computer System for Interpreting Scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision Systems"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "These techniques employ a parameterized model (as in Acronym [5]), or a generic model (as in Fua [9])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 53
                            }
                        ],
                        "text": "These techniques employ a parameterized model (as in Acronym [5]), or ageneric model (as in Fua [9])."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Model-Based 3-D Interpretations of 2-D Images"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 146
                            }
                        ],
                        "text": "The CKS is an object-oriented knowledge/database that was originally designed to serve as the central information manager for a perceptual system [19, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Management in a Sensor-Based  Autonomous System,\" Proceedings: DARPA Image Understanding Workshop"
            },
            "venue": {
                "fragments": [],
                "text": "Los Angeles,  California,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\SRI's Baseline Stereo System"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings: DARPA Image Understanding Workshop"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 183
                            }
                        ],
                        "text": "There has been some work directed toward the goal of semantic understanding of natural outdoor scenes, but surprisingly, very little new work has been initiated in the last ten years [2, 11, 16, 17, 18, 23, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "VISIONS: A Computer System for Interpreting Scenes,\"  in Computer Vision Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Information Management in a Sensor-Based Autonomous System"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings: DARPA Image Understanding Workshop"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\3DPO: A 3D Part Orientation System"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 8th International Joint Conference on Artiicial Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "Hawkeye [3], MSYS [2], and the approach described here, are examples of the few systems that have been designed without a primary reliance on geometric models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Interactive Aids for Cartography and Interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Note"
            },
            "year": 1977
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Context-Based-Vision:-Recognizing-Objects-Using-2D-Strat-Fischler/06c908a5dea82fdbffa8285beae1c3d60b028902?sort=total-citations"
}