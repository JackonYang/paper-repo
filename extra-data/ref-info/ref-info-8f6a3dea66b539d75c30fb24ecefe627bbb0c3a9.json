{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "Due to space limitations the details of the extended algorithm are described in the accompanying technical report [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15917455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c0c7b1cffe166ab4cee7887db9ecd0ff2b613d3",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a new vision based motion capture te chnique that is able to recover high degree-of-freedom articu lated human body configurations in complex video sequences. It does n t require any markers, body suits, or other devices attached t o the subject. The only input needed is a video recording of the per son whose motion is to be captured. For visual tracking we introduce the use of a novel mathematical technique, the produ ct of exponential maps and twist motions, and its integration int o a differential motion estimation. This results in solving simpl e linear systems, and enables us to recover robustly the kinematic de greesof-freedom in noise and complex self occluded configuration s. We demonstrate this on several image sequences of people doing articulated full body movements, and visualize the results in re-a nim ting an artificial 3D human model. We are also able to recover and re animate the famous movements of Eadweard Muybridge\u2019s motio n studies from the last century. To the best of our knowledge, t his is the first computer vision based system that is able to process such challenging footage and recover complex motions with such h ig accuracy."
            },
            "slug": "Video-Motion-Capture-Bregler-Malik",
            "title": {
                "fragments": [],
                "text": "Video Motion Capture"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper demonstrates a new vision based motion capture system that is able to recover high degree-of-freedom articu lated human body configurations in complex video sequences and is the first computer vision based system able to process such challenging footage and recover complex motions with such accuracy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8611534"
                        ],
                        "name": "S. Basu",
                        "slug": "S.-Basu",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Basu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Basu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21472040"
                        ],
                        "name": "Irfan Essa",
                        "slug": "Irfan-Essa",
                        "structuredName": {
                            "firstName": "Irfan",
                            "lastName": "Essa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irfan Essa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 191
                            }
                        ],
                        "text": "Euler angles are commonly used to constrain the rotation matrix to SO(3), but they suffer from singularities and don\u2019t lead to a simple formulation in the optimization procedure (for example [2] propose a 3D ellipsoidal tracker based on Euler angles)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6856455,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "066ca46f4e4b932b7044f386248d726a7425be51",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for the robust tracking of rigid head motion from video. This method uses a 3D ellipsoidal model of the head and interprets the optical flow in terms of the possible rigid motions of the model. This method is robust to large angular and translational motions of the head and is not subject to the singularities of a 2D model. The method has been successfully applied to heads with a variety of shapes, hair styles, etc. This method also has the advantage of accurately capturing the 3D motion parameters of the head. This accuracy is shown through comparison with a ground truth synthetic sequence (a rendered 3D animation of a model head). In addition, the ellipsoidal model is robust to small variations in the initial fit, enabling the automation of the model initialization. Lastly, due to its consideration of the entire 3D aspect of the head, the tracking is very stable over a large number of frames. This robustness extends even to sequences with very low frame rates and noisy camera images."
            },
            "slug": "Motion-regularization-for-model-based-head-tracking-Basu-Essa",
            "title": {
                "fragments": [],
                "text": "Motion regularization for model-based head tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper describes a method for the robust tracking of rigid head motion from video that uses a 3D ellipsoidal model of the head and interprets the optical flow in terms of the possible rigid motions of the model."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Others have modeled the human body with rigid segments connected at joints [14, 24, 23, 13, 10, 9,  16 , 17], but use different representations and features (for example Denavit-Hartenburg and edge detection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5170789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e3b20fb94803d71910043059f402554aa5137b2",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the work of Black and Yacoob (1995) on the tracking and recognition of human facial expressions using parametrized models of optical flow to deal with the articulated motion of human limbs. We define a \"card-board person model\" in which a person's limbs are represented by a set of connected planar patches. The parametrized image motion of these patches in constrained to enforce articulated motion and is solved for directly using a robust estimation technique. The recovered motion parameters provide a rich and concise description of the activity that can be used for recognition. We propose a method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion. We illustrate the method with examples of tracking human legs of long image sequences."
            },
            "slug": "Cardboard-people:-a-parameterized-model-of-image-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Cardboard people: a parameterized model of articulated image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706204"
                        ],
                        "name": "I. Kakadiaris",
                        "slug": "I.-Kakadiaris",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Kakadiaris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kakadiaris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 75
                            }
                        ],
                        "text": "Others have modeled the human body with rigid segments connected at joints [14, 24, 23, 13, 10, 9, 16, 17], but use different representations and features (for example DenavitHartenburg and edge detection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18748251,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4d24117d83ad925d837ed0b7d6aa065140fb0248",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for the 3D model-based tracking of human body parts. To mitigate the difficulties arising due to occlusion among body parts, we employ multiple calibrated cameras in a mutually orthogonal configuration. In addition, we develop criteria for a time varying active selection of a set of cameras to track the motion of a particular human part. In particular, at every frame, each camera tracks a number of parts depending on the visibility of these parts and the observability of their predicted motion from the specific camera. To relate points on the occluding contours of the parts to points on their models we apply concepts from projective geometry. Then, within the physics-based framework we compute the generalized forces applied from the parts' occluding contours to model points of the body parts. These forces update the translational and rotational degrees of freedom of the model, such as to minimize the discrepancy between the sensory data and the estimated model state. We present initial tracking results from a series of experiments involving the recovery of complex 3D motions in the presence of significant occlusion."
            },
            "slug": "Model-based-estimation-of-3D-human-motion-with-on-Kakadiaris-Metaxas",
            "title": {
                "fragments": [],
                "text": "Model-based estimation of 3D human motion with occlusion based on active multi-viewpoint selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Initial tracking results from a series of experiments involving the recovery of complex 3D motions in the presence of significant occlusion are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 75
                            }
                        ],
                        "text": "Others have modeled the human body with rigid segments connected at joints [14, 24, 23, 13, 10, 9, 16, 17], but use different representations and features (for example DenavitHartenburg and edge detection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17525960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e88ca837b122a9c9e546db5395b451f27ea01f19",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe our work on 3-D model-based tracking and recognition of human movement from real images. Our system has two major components. The rst component takes real image sequences acquired from multiple views and recovers the 3-D body pose at each time instant. The pose-recovery problem is formulated as a search problem and entails nding the pose parameters of a graphical human model for which its synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. Currently, we use a best-rst search technique and chamfer matching as a fast similarity measure between synthesized and real edge images. The second component of our system deals with the representation and recognition of human movement patterns. The recognition of human movement patterns is considered as a classiication problem involving the matching of a test sequence with several reference sequences representing prototypical activities. A variation of dynamic time-warping is used to match movement patterns using 3-D joint angles as features. We illustrate our approach on real data acquired simultaneously from three views and data derived from stereo Moving Light Displays with diierent types of hand-gestures."
            },
            "slug": "Towards-3-D-model-based-tracking-and-recognition-of-Gavrila-Davis",
            "title": {
                "fragments": [],
                "text": "Towards 3-D model-based tracking and recognition of human movement: a multi-view approach"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "3-D model-based tracking and recognition of human movement from real images, and a variation of dynamic time-warping is used to match movement patterns using 3-D joint angles as features."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Robust statistics would be one solution to this problem [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14070356,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eee90c038f43370a29b07e46f38dfe6527143a2c",
            "isKey": false,
            "numCitedBy": 1786,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "Most approaches for estimating optical flow assume that, within a finite image region, only a single motion is present. Thissingle motion assumptionis violated in common situations involving transparency, depth discontinuities, independently moving objects, shadows, and specular reflections. To robustly estimate optical flow, the single motion assumption must be relaxed. This paper presents a framework based onrobust estimationthat addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions. We show how therobust estimation frameworkcan be applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions. The approach has been applied to three standard techniques for recovering optical flow: area-based regression, correlation, and regularization with motion discontinuities. This paper focuses on the recovery of multiple parametric motion models within a region, as well as the recovery of piecewise-smooth flow fields, and provides examples with natural and synthetic image sequences."
            },
            "slug": "The-Robust-Estimation-of-Multiple-Motions:-and-Flow-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "The Robust Estimation of Multiple Motions: Parametric and Piecewise-Smooth Flow Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A framework based on robust estimation is presented that addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions of optical flow, and is applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 90
                            }
                        ],
                        "text": "Others have shown how to extend this approach to multiple independent moving motion areas [15, 1, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15129224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14d3e82f9e108392ce0d649200a38f34eba4486a",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent progress in motion analysis has been achieved with systems that estimate global pa-rameterized motion by integrating multiple constraints. The success of these approaches depends critically on the ability to segment constraints derived from diierent motions. Hence the problems of motion estimation and segmen-tation are tightly coupled. We believe it is impossible to solve these problems solely in the motion domain, and that mechanisms of spatial form analysis must be incorporated into the motion estimation procedure. We present a new framework which allows the incorporation of form information in a graceful manner. It combines concepts from perceptual organization with the powerful optimization technique of EM. We show that the algorithm is guaranteed to decrease a cost function at every iteration, and that in the absence of form information the cost function reduces to the one minimized by EM. We demonstrate that the approach can achieve good motion estimation and segmentation with challenging motion sequences. Recent progress in motion analysis has been achieved with systems that estimate global parameterized mo-These methods have advantages over local optic ow in that they overcome the local ill-posedness of the motion estimation problem by integrating multiple constraints. The sucess of these approaches , however, depends critically on the ability to segment constraints derived from diierent motions. Hence the problems of motion estimation and segmentation have become tightly coupled. The joint solution of these problems remains diicult, even for scenes that are very simple. Consider, for example, the scene shown in g 1(a) (see also Bergen et al., 1990]). Two bars of diierent grey shades are moving, one to the left and one to the right. We will consider how several kinds of motion analyses treat this input. First, the output of a standard least-squares optic ow routine is shown in g. 1(b), as an arrow plot; the x and y components of velocity are shown in g. 1(c) and (d) (velocities below some threshold conndence are set to zero, a b c d Figure 1: a A simple image sequence which causes problems for traditional motion estimation algorithms. b Least squares optical ow shown as an arrow plot c Least squares optical ow horizontal component. d Least squares optical ow vertical component. the algorithm is an implementation of Lucas and Kanade (1981) modiied according to Simoncelli et al., 1991]). Although this sequence is a synthetic one, it illustrates problems that occur frequently in analyzing real \u2026"
            },
            "slug": "Perceptually-Organized-Em:-a-Framework-for-Motion-Adelson-Weiss",
            "title": {
                "fragments": [],
                "text": "Perceptually Organized Em: a Framework for Motion Segmentation That Combines Information about Form and Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a new framework which allows the incorporation of form information in a graceful manner that combines concepts from perceptual organization with the powerful optimization technique of EM and demonstrates that the approach can achieve good motion estimation and segmentation with challenging motion sequences."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3175562,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "4ef915fa9e5b2260d4b45927c0033a7ba53bf66e",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces. Parametric flow models (for example affine) are popular for estimating motion in rigid scenes. We observe that within local regions in space and time, such models not only accurately model non-rigid facial motions but also provide a concise description of the motion in terms of a small number of parameters. These parameters are intuitively related to the motion of facial features during facial expressions and we show how expressions such as anger, happiness, surprise, fear, disgust and sadness can be recognized from the local parametric motions in the presence of significant head motion. The motion tracking and expression recognition approach performs with high accuracy in extensive laboratory experiments involving 40 subjects as well as in television and movie sequences.<<ETX>>"
            },
            "slug": "Tracking-and-recognizing-rigid-and-non-rigid-facial-Black-Yacoob",
            "title": {
                "fragments": [],
                "text": "Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces and shows how expressions can be recognized from the local parametric motions in the presence of significant head motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144429686"
                        ],
                        "name": "James W. Davis",
                        "slug": "James-W.-Davis",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Davis",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James W. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "Alternative solutions to tracking of human bodies were proposed by [27] in tracking color blobs, and by [11] in using motion templates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16135896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf8e9dc8a261ea9cf2a4bd4e15a2bd9e6237a5ab",
            "isKey": false,
            "numCitedBy": 558,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A new view-based approach to the representation and recognition of action is presented. The basis of the representation is a temporal template-a static vector-image where the vector value at each point is a function of the motion properties at the corresponding spatial location in an image sequence. Using 18 aerobics exercises as a test domain, we explore the representational power of a simple, two component version of the templates: the first value is a binary value indicating the presence of motion, and the second value is a function of the recency of motion in a sequence. We then develop a recognition method which matches these temporal templates against stored instances of views of known actions. The method automatically performs temporal segmentation, is invariant to linear changes in speed, and runs in real-time on a standard platform. We recently incorporated this technique into the KIDSROOM: an interactive, narrative play-space for children."
            },
            "slug": "The-representation-and-recognition-of-human-using-Davis-Bobick",
            "title": {
                "fragments": [],
                "text": "The representation and recognition of human movement using temporal templates"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A new view-based approach to the representation and recognition of action is presented, using a temporal template-a static vector-image where the vector value at each point is a function of the motion properties at the corresponding spatial location in an image sequence."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772763"
                        ],
                        "name": "E. Bernardo",
                        "slug": "E.-Bernardo",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bernardo",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bernardo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149680415"
                        ],
                        "name": "L. Goncalves",
                        "slug": "L.-Goncalves",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Goncalves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goncalves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46614172"
                        ],
                        "name": "Enrico Ursella",
                        "slug": "Enrico-Ursella",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Ursella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrico Ursella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Others have modeled the human body with rigid segments connected at joints [14, 24, 23, 13, 10, 9, 16, 17], but use different representations and features (for example DenavitHartenburg and edge detection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19164875,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7d91d26d47289d5633693cb6e91cb23b26195486",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of estimating the position and motion of a human arm in 3D without any constraints on its behavior and without the use of special markers. We model the arm as two truncated right-circular cones connected with spherical joints. We propose to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image. The system is demonstrated and tested on a real image sequence.<<ETX>>"
            },
            "slug": "Monocular-tracking-of-the-human-arm-in-3D-Bernardo-Goncalves",
            "title": {
                "fragments": [],
                "text": "Monocular tracking of the human arm in 3D"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Nonrigid models were proposed by [22, 7, 5, 6]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 28815139,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "f706f1babe84c0728be3a06a4d3023cdc44f61c2",
            "isKey": false,
            "numCitedBy": 417,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors introduce a physically correct model of elastic nonrigid motion. This model is based on the finite element method, but decouples the degrees of freedom by breaking down object motion into rigid and nonrigid vibration or deformation modes. The result is an accurate representation for both rigid and nonrigid motion that has greatly reduced dimensionality, capturing the intuition that nonrigid motion is normally coherent and not chaotic. Because of the small number of parameters involved, this representation is used to obtain accurate overstrained estimates of both rigid and nonrigid global motion. It is also shown that these estimates can be integrated over time by use of an extended Kalman filter, resulting in stable and accurate estimates of both three-dimensional shape and three-dimensional velocity. The formulation is then extended to include constrained nonrigid motion. Examples of tracking single nonrigid objects and multiple constrained objects are presented. >"
            },
            "slug": "Recovery-of-Nonrigid-Motion-and-Structure-Pentland-Horowitz",
            "title": {
                "fragments": [],
                "text": "Recovery of Nonrigid Motion and Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This model is based on the finite element method, but decouples the degrees of freedom by breaking down object motion into rigid and nonrigid vibration or deformation modes, resulting in an accurate representation for both rigid andnonrigid motion that has greatly reduced dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058487"
                        ],
                        "name": "D. Reynard",
                        "slug": "D.-Reynard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Reynard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reynard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To the best of our knowledge, this is the first computer vision based system that is able to process such challenging footage and recover complex motions with such high accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4663494,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "eead38c8bd414e8bb89f449676fbae14173f6a46",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-to-Track-the-Visual-Motion-of-Contours-Blake-Isard",
            "title": {
                "fragments": [],
                "text": "Learning to Track the Visual Motion of Contours"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Others have modeled the human body with rigid segments connected at joints [14, 24, 23, 13, 10, 9, 16, 17], but use different representations and features (for example DenavitHartenburg and edge detection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17009967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3740a2ab2936c2d87f6a3d8b742841a383ba502",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer sensing of hand and limb motion is an important problem for applications in human computer interaction and computer graphics. We describe a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another. Our approach uses a kinematic model to predict occlusions and windowed templates to track partially occluded objects. We present offline 3D tracking results for hand motion with significant self occlusion.<<ETX>>"
            },
            "slug": "Model-based-tracking-of-self-occluding-articulated-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "Model-based tracking of self-occluding articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work describes a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another, using a kinematic model to predict occlusions and windowed templates to track partially occluded objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116003860"
                        ],
                        "name": "J. Bergen",
                        "slug": "J.-Bergen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3315356"
                        ],
                        "name": "K. Hanna",
                        "slug": "K.-Hanna",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Hanna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hanna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055557"
                        ],
                        "name": "R. Hingorani",
                        "slug": "R.-Hingorani",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Hingorani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hingorani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "One class of motion estimation techniques are based on parametric algorithms [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 95
                            }
                        ],
                        "text": "2 Motion Estimation We first describe a commonly used region-based motion estimation framework [3, 25], and then describe the extension to kinematic chain constraints [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "For the case that the motion model is linear (as in the affine case), we can write the set of equations in matrix form (see [3] for details):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6267598,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "404f3544a7db67c38ba3b8f78f02759d2326684e",
            "isKey": false,
            "numCitedBy": 1510,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a hierarchical estimation framework for the computation of diverse representations of motion information. The key features of the resulting framework (or family of algorithms) are a global model that constrains the overall structure of the motion estimated, a local model that is used in the estimation process, and a coarse-fine refinement strategy. Four specific motion models: affine flow, planar surface flow, rigid body motion, and general optical flow, are described along with their application to specific examples."
            },
            "slug": "Hierarchical-Model-Based-Motion-Estimation-Bergen-Anandan",
            "title": {
                "fragments": [],
                "text": "Hierarchical Model-Based Motion Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper describes a hierarchical estimation framework for the computation of diverse representations of motion information that constrains the overall structure of the motion estimated, a local model that is used in the estimation process, and a coarse-fine refinement strategy."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To the best of our knowledge, this is the first computer vision based system that is able to process such challenging footage and recover complex motions with such high accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 403007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24cde5de8abd1ebf70b9439dc4cf8cf545e73e45",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework for learning parameterized models of optical flow from image sequences is presented. A class of motions is represented by a set of orthogonal basis flow fields that are computed from a training set using principal component analysis. Many complex image motions can be represented by a linear combination of a small number of these basis flows. The learned motion models may be used for optical flow estimation and for model-based recognition. For optical flow estimation we describe a robust, multi-resolution scheme for directly computing the parameters of the learned flow models from image derivatives. As examples we consider learning motion discontinuities, non-rigid motion of human mouths, and articulated human motion."
            },
            "slug": "Learning-parameterized-models-of-image-motion-Black-Yacoob",
            "title": {
                "fragments": [],
                "text": "Learning parameterized models of image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A framework for learning parameterized models of optical flow from image sequences is presented and a robust, multi-resolution scheme for directly computing the parameters of the learned flow models from image derivatives is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076270"
                        ],
                        "name": "N. Madrane",
                        "slug": "N.-Madrane",
                        "structuredName": {
                            "firstName": "Nabil",
                            "lastName": "Madrane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Madrane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686820"
                        ],
                        "name": "B. M\u00e9rialdo",
                        "slug": "B.-M\u00e9rialdo",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "M\u00e9rialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M\u00e9rialdo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 75
                            }
                        ],
                        "text": "Others have modeled the human body with rigid segments connected at joints [14, 24, 23, 13, 10, 9, 16, 17], but use different representations and features (for example DenavitHartenburg and edge detection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16923015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2eb457ebe56e8c4f66c8c6feab31b2d9a16b081e",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Technology is making possible the creation and handling of multimedia documents which contain video segments. At present there is a lack of tools for automatically indexing and representing these documents. In this paper we restrict our attention to a special class of video documents, those sequences containing images of people in movement. These sequences are analyzed and Spatio-Temporal Indices are extracted and used to describe the body motion. The analysis makes use of a 3-D human model composed of an articulated 10 segment structure. The next step is to recognize the identity of the human in motion. To do this we have developed a face recognition procedure based upon projective invariants. Examples are presented and demonstrate the feasibility of our ap-"
            },
            "slug": "Automatic-Face-and-Gestual-Recognition-for-Video-Madrane-M\u00e9rialdo",
            "title": {
                "fragments": [],
                "text": "Automatic Face and Gestual Recognition for Video Indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "To recognize the identity of the human in motion, a face recognition procedure based upon projective invariants is developed and examples are presented to demonstrate the feasibility of this procedure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 95
                            }
                        ],
                        "text": "2 Motion Estimation We first describe a commonly used region-based motion estimation framework [3, 25], and then describe the extension to kinematic chain constraints [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 778478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ab46391005cea85fa5c204b6e77a9c870fdbaed",
            "isKey": false,
            "numCitedBy": 8403,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments.<<ETX>>"
            },
            "slug": "Good-features-to-track-Shi-Tomasi",
            "title": {
                "fragments": [],
                "text": "Good features to track"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 55
                            }
                        ],
                        "text": "Another solution is an EM-based layered representation [12, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 90
                            }
                        ],
                        "text": "Others have shown how to extend this approach to multiple independent moving motion areas [15, 1, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 47379266,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d237b135d9cb6c5ea76faa421fa461d3128b61e8",
            "isKey": false,
            "numCitedBy": 308,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The computation of optical flow relies on merging information available over an image patch to form an estimate of 2-D image velocity at a point. This merging process raises many issues. These include the treatment of outliers in component velocity measurements and the modeling of multiple motions within a patch which arise from occlusion boundaries or transparency. A new approach for dealing with these issues is presented. It is based on the use of a probabilistic mixture model to explicitly represent multiple motions within a patch. A simple extension of the EM-algorithm is used to compute a maximum likelihood estimate for the various motion parameters. Preliminary experiments indicate that this approach is computationally efficient, and that it can provide robust estimates of the optical flow values in the presence of outliers and multiple motions.<<ETX>>"
            },
            "slug": "Mixture-models-for-optical-flow-computation-Jepson-Black",
            "title": {
                "fragments": [],
                "text": "Mixture models for optical flow computation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new approach based on the use of a probabilistic mixture model to explicitly represent multiple motions within a patch is presented, which can provide robust estimates of the optical flow values in the presence of outliers and multiple motions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 75
                            }
                        ],
                        "text": "Others have modeled the human body with rigid segments connected at joints [14, 24, 23, 13, 10, 9, 16, 17], but use different representations and features (for example DenavitHartenburg and edge detection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34873540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92f98b189cec1220d479e3079b942e71b244aa65",
            "isKey": false,
            "numCitedBy": 597,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-based-vision:-a-program-to-see-a-walking-Hogg",
            "title": {
                "fragments": [],
                "text": "Model-based vision: a program to see a walking person"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 75
                            }
                        ],
                        "text": "Others have modeled the human body with rigid segments connected at joints [14, 24, 23, 13, 10, 9, 16, 17], but use different representations and features (for example DenavitHartenburg and edge detection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15268662,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "86086a48021d34c1e36cc9e0d1fa532d3a3efb1e",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach that uses a volume model consisting of cylinders for model-based recognition of pedestrians in real-world images is presented. The human body is represented by a volume model, and medical motion data are used for simulating the movement of walking. This knowledge is exploited to determine the 3-D position, as well as the posture of an observed person. By applying a Kalman filter, the model parameters in consecutive images are incrementally estimated. The approach is tested on real image data.<<ETX>>"
            },
            "slug": "Incremental-recognition-of-pedestrians-from-image-Rohr",
            "title": {
                "fragments": [],
                "text": "Incremental recognition of pedestrians from image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An approach that uses a volume model consisting of cylinders for model-based recognition of pedestrians in real-world images is presented, and medical motion data are used for simulating the movement of walking."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34751187"
                        ],
                        "name": "C. R. Wren",
                        "slug": "C.-R.-Wren",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Wren",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. R. Wren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271456"
                        ],
                        "name": "A. Azarbayejani",
                        "slug": "A.-Azarbayejani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Azarbayejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Azarbayejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Alternative solutions to tracking of human bodies were proposed by [ 27 ] in tracking color blobs, and by [11] in using motion templates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9458767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69b7efd02ea06e6aa372b5c1a46167e6a5366bfd",
            "isKey": false,
            "numCitedBy": 3548,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Pfinder is a real-time system for tracking and interpretation of people. It runs on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions. These representations are useful for applications such as wireless interfaces, video databases, and low-bandwidth coding, without cumbersome wires or attached sensors."
            },
            "slug": "Pfinder:-real-time-tracking-of-the-human-body-Wren-Azarbayejani",
            "title": {
                "fragments": [],
                "text": "Pfinder: Real-Time Tracking of the Human Body"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Pfinder uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions, useful for applications such as wireless interfaces, video databases, and low-bandwidth coding."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825734"
                        ],
                        "name": "S. Ayer",
                        "slug": "S.-Ayer",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Ayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 90
                            }
                        ],
                        "text": "Others have shown how to extend this approach to multiple independent moving motion areas [15, 1, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3135763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e26a23b57bff5e1246e49dae394eb636a3c099d1",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Representing and modeling the motion and spatial support of multiple objects and surfaces from motion video sequences is an important intermediate step towards dynamic image understanding. One such representation, called layered representation, has recently been proposed. Although a number of algorithms have been developed for computing these representations, there has not been a consolidated effort into developing a precise mathematical formulation of the problem. This paper presents one such formulation based on maximum likelihood estimation (MLE) of mixture models and the minimum description length (MDL) encoding principle. The three major issues in layered motion representation are: (i) how many motion models adequately describe image motion, (ii) what are the motion model parameters, and (iii) what is the spatial support layer for each motion model.<<ETX>>"
            },
            "slug": "Layered-representation-of-motion-video-using-robust-Ayer-Sawhney",
            "title": {
                "fragments": [],
                "text": "Layered representation of motion video using robust maximum-likelihood estimation of mixture models and MDL encoding"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents one such formulation based on maximum likelihood estimation (MLE) of mixture models and the minimum description length (MDL) encoding principle of layered motion representation, and examines how many motion models adequately describe image motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144696890"
                        ],
                        "name": "R. Murray",
                        "slug": "R.-Murray",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Murray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144797536"
                        ],
                        "name": "S. Sastry",
                        "slug": "S.-Sastry",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sastry",
                            "middleNames": [
                                "Shankar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sastry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9230809"
                        ],
                        "name": "Li Ze-xiang",
                        "slug": "Li-Ze-xiang",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Ze-xiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Ze-xiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "angular velocities u0012\u03071; u0012\u03072; :::; u0012\u0307k (see [20] for the derivations):"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "2 Motion Estimation We first describe a commonly used region-based motion estimation framework [3, 25], and then describe the extension to kinematic chain constraints [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "In contrast, the twist representation provides a more elegant solution [20] and leads to a very simple linear representation of the motion model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "A convenient way of describing these additional domain constraints is the twist and product of exponential map formalism for kinematic chains [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "See [20] for a detailed geometric interpretation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "This is a revolute joint, and can be modeled by a twist ([20]):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "The pose of an object relative to the camera frame can be represented as a rigid body transformation in <3 using homogeneous coordinates (we will use the notation from [20]):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "It can be shown [20] that for any arbitrary G 2 SE(3) there exists a 2 <6 twist representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 108605633,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "ca442cc2eef5d9bd5cd5cb4c516cd15991569d93",
            "isKey": true,
            "numCitedBy": 6493,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "INTRODUCTION: Brief History. Multifingered Hands and Dextrous Manipulation. Outline of the Book. Bibliography. RIGID BODY MOTION: Rigid Body Transformations. Rotational Motion in R3. Rigid Motion in R3. Velocity of a Rigid Body. Wrenches and Reciprocal Screws. MANIPULATOR KINEMATICS: Introduction. Forward Kinematics. Inverse Kinematics. The Manipulator Jacobian. Redundant and Parallel Manipulators. ROBOT DYNAMICS AND CONTROL: Introduction. Lagrange's Equations. Dynamics of Open-Chain Manipulators. Lyapunov Stability Theory. Position Control and Trajectory Tracking. Control of Constrained Manipulators. MULTIFINGERED HAND KINEMATICS: Introduction to Grasping. Grasp Statics. Force-Closure. Grasp Planning. Grasp Constraints. Rolling Contact Kinematics. HAND DYNAMICS AND CONTROL: Lagrange's Equations with Constraints. Robot Hand Dynamics. Redundant and Nonmanipulable Robot Systems. Kinematics and Statics of Tendon Actuation. Control of Robot Hands. NONHOLONOMIC BEHAVIOR IN ROBOTIC SYSTEMS: Introduction. Controllability and Frobenius' Theorem. Examples of Nonholonomic Systems. Structure of Nonholonomic Systems. NONHOLONOMIC MOTION PLANNING: Introduction. Steering Model Control Systems Using Sinusoids. General Methods for Steering. Dynamic Finger Repositioning. FUTURE PROSPECTS: Robots in Hazardous Environments. Medical Applications for Multifingered Hands. Robots on a Small Scale: Microrobotics. APPENDICES: Lie Groups and Robot Kinematics. A Mathematica Package for Screw Calculus. Bibliography. Index Each chapter also includes a Summary, Bibliography, and Exercises"
            },
            "slug": "A-Mathematical-Introduction-to-Robotic-Manipulation-Murray-Sastry",
            "title": {
                "fragments": [],
                "text": "A Mathematical Introduction to Robotic Manipulation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52321125"
                        ],
                        "name": "M. P. Murray",
                        "slug": "M.-P.-Murray",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Murray",
                            "middleNames": [
                                "Pat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4597251"
                        ],
                        "name": "R. C. Kory",
                        "slug": "R.-C.-Kory",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Kory",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. C. Kory"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "23819523"
                        ],
                        "name": "B. Clarkson",
                        "slug": "B.-Clarkson",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Clarkson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Clarkson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6235658"
                        ],
                        "name": "S. Sepic",
                        "slug": "S.-Sepic",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Sepic",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sepic"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31776436,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b8106a73ad8c761cfc811bc8da9419d41d9ea076",
            "isKey": false,
            "numCitedBy": 337,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In a previous study we have described a simple, inexpensive photographic method for recording simultaneously the displacements which occur in walking. With this method we have studied the gait patterns of 60 men and have delineated the ranges of normal values for 16 excursions during free speed walking (1). In analyzing the data obtained in this study, we noted that certain displacement patterns appeared to relate to the speed of walking. I n the presenl; study, therefore, we have compared the displacement patterns of free and fast speed walking for 30 of the men previously studied. Since the subjects selected represent broad ranges of age and height, the normal values obtained for this fast speed study should provide much-needed baselines for comparison of a wide variety of pathological gaits in which the speed deficit is manifested. Although the effect of speed on normal locomotion has been studied by many investigators, these studies have been confined for the most part to the temporal components of the walking cycle and to stride dimensions. The effect of walking speed on the various temporal components of walking has been studied extensively (2-8). There is general agreement that the duration of the phases of the walking cycle decreases with increased cadence. The relationship between step length and step rate has also been studied by many investigators (3, 8-12). Despite the lack of conformity in the various experimental methods, it was apparent that increased walking speeds, up to a point, are accomplished by decreasing the step duration and by increasing the step length. Hoffman (13), Basler (2), and Morton (14) all observed straightening of the foot angles with increased walking speeds. Weber (8), Carlet (3), and Farfel (lo), with different"
            },
            "slug": "COMPARISON-OF-FREE-AND-FAST-SPEED-WALKING-PATTERNS-Murray-Kory",
            "title": {
                "fragments": [],
                "text": "COMPARISON OF FREE AND FAST SPEED WALKING PATTERNS OF NORMAL MEN"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This study has compared the displacement patterns of free and fast speed walking for 30 of the men previously studied, and it was apparent that increased walking speeds, up to a point, are accomplished by decreasing the step duration and by increasing the step length."
            },
            "venue": {
                "fragments": [],
                "text": "American journal of physical medicine"
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588702"
                        ],
                        "name": "B. D. Lucas",
                        "slug": "B.-D.-Lucas",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lucas",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "The first-order Taylor series expansion of (1) leads to the commonly used gradient formulation [18]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2121536,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "isKey": false,
            "numCitedBy": 13329,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system."
            },
            "slug": "An-Iterative-Image-Registration-Technique-with-an-Lucas-Kanade",
            "title": {
                "fragments": [],
                "text": "An Iterative Image Registration Technique with an Application to Stereo Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration, and can be generalized to handle rotation, scaling and shearing."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52321125"
                        ],
                        "name": "M. P. Murray",
                        "slug": "M.-P.-Murray",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Murray",
                            "middleNames": [
                                "Pat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51089097"
                        ],
                        "name": "A. B. Drought",
                        "slug": "A.-B.-Drought",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Drought",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. B. Drought"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4597251"
                        ],
                        "name": "R. C. Kory",
                        "slug": "R.-C.-Kory",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Kory",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. C. Kory"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "1a shows the curves for the knee and ankle reported in [19], and figure 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "Murray, Brought, and Kory published [19] such measurements for the hip, knee, and angle joints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41732051,
            "fieldsOfStudy": [
                "Biology",
                "Physics"
            ],
            "id": "fec5c3a9bf9fcfe02e6dc418b6d88809184c5276",
            "isKey": false,
            "numCitedBy": 1108,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A simple and inexpensive photographic method has been developed whereby many kinematic components of the walking act in the sagittal, frontal, and transverse planes can be measured and related temporally. A factorial design was used to study the displacement patterns of sixty normal men who ranged i"
            },
            "slug": "WALKING-PATTERNS-OF-NORMAL-MEN.-Murray-Drought",
            "title": {
                "fragments": [],
                "text": "WALKING PATTERNS OF NORMAL MEN."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A simple and inexpensive photographic method has been developed whereby many kinematic components of the walking act in the sagittal, frontal, and transverse planes can be measured and related temporally."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of bone and joint surgery. American volume"
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 55
                            }
                        ],
                        "text": "Another solution is an EM-based layered representation [12, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48403,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 75
                            }
                        ],
                        "text": "Others have modeled the human body with rigid segments connected at joints [14, 24, 23, 13, 10, 9, 16, 17], but use different representations and features (for example DenavitHartenburg and edge detection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 108068634,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "dc132c04da4d6817a775efdac86372ae77f12b0f",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cardboard-people:-A-parametrized-model-of-motion-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Cardboard people: A parametrized model of articulated motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97016811"
                        ],
                        "name": "E. Muybridge",
                        "slug": "E.-Muybridge",
                        "structuredName": {
                            "firstName": "Eadweard",
                            "lastName": "Muybridge",
                            "middleNames": [
                                "photographer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Muybridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1823507"
                        ],
                        "name": "R. Taft",
                        "slug": "R.-Taft",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Taft",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Taft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57239504,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "4ceec43ae8486fb7d0bacd73604f30adbf26500e",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Human-Figure-in-Motion-Muybridge-Taft",
            "title": {
                "fragments": [],
                "text": "The Human Figure in Motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1955
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Human Figure In Motion. Various Publishers , latest edition by Dover Publications"
            },
            "venue": {
                "fragments": [],
                "text": "The Human Figure In Motion. Various Publishers , latest edition by Dover Publications"
            },
            "year": 1901
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adelson . Perceptually organized EM : A framework for motion segmentaiton that combines information about form and motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 19,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Tracking-people-with-twists-and-exponential-maps-Bregler-Malik/8f6a3dea66b539d75c30fb24ecefe627bbb0c3a9?sort=total-citations"
}