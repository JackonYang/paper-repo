{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049705"
                        ],
                        "name": "L. Cohen",
                        "slug": "L.-Cohen",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Cohen",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "Following the procedure of [3], we can extend a partial labeling of regions to a full one by assigning to each unlabeled region the label of its closest (in terms of the ultrametric distance) labeled region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15964258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0f01530370383ac34c9ef4ad2a5a5a6f54c2cf7",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of constrained segmentation of natural images, in which a human user places one seed point inside each object of interest in the image and the task is to determine the object boundaries. For this purpose, we study the connection between seed-based and hierarchical segmentation. We consider an Ultrametric Contour Map (UCM), the representation of a hierarchy of segmentations as a real-valued boundary image. Starting from a set of seed points, we propose an algorithm for constructing Voronoi tessellations with respect to a distance defined by the UCM. As a result, the main contribution of the paper is a method that allows exploiting the information of any hierarchical scheme for constrained segmentation. Our algorithm is parameter-free, computationally efficient and robust. We prove the interest of the approach proposed by evaluating quantitatively the results with respect to ground-truth data."
            },
            "slug": "Constrained-image-segmentation-from-hierarchical-Arbel\u00e1ez-Cohen",
            "title": {
                "fragments": [],
                "text": "Constrained image segmentation from hierarchical boundaries"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper considers an Ultrametric Contour Map, the representation of a hierarchy of segmentations as a real-valued boundary image, and proposes an algorithm for constructing Voronoi tessellations with respect to a distance defined by the UCM."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 236
                            }
                        ],
                        "text": "The problem of oversegmentation is common across approaches based on feature clustering since smooth changes in texture or brightness due to perspective or shading can cause patches to appear dissimilar despite belonging to the same image region."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4474066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8463e6acd5b03dc6f4c13858a8aed980cf2fed31",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a low-level system for boundary extraction and segmentation of natural images and the evaluation of its performance. We study the problem in the framework of hierarchical classification, where the geometric structure of an image can be represented by an ultrametric contour map, the soft boundary image associated to a family of nested segmentations. We define generic ultrametric distances by integrating local contour cues along the regions boundaries and combining this information with region attributes. Then, we evaluate quantitatively our results with respect to ground-truth segmentation data, proving that our system outperforms significantly two widely used hierarchical segmentation techniques, as well as the state of the art in local edge detection."
            },
            "slug": "Boundary-Extraction-in-Natural-Images-Using-Contour-Arbel\u00e1ez",
            "title": {
                "fragments": [],
                "text": "Boundary Extraction in Natural Images Using Ultrametric Contour Maps"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents a low-level system for boundary extraction and segmentation of natural images and the evaluation of its performance proves that this system outperforms significantly two widely used hierarchical segmentation techniques, as well as the state of the art in local edge detection."
            },
            "venue": {
                "fragments": [],
                "text": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "\u2026formulations [30, 29] and level set techniques [26]), three algorithms in this category appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and Huttenlocher\u2019s\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9569642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be43b5f8007cfb215697d515a6fb8c6fa7cca3e5",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nUsing a large set of human segmented natural images, we study the statistics of region boundaries. We observe several power law distributions which likely arise from both multi-scale structure within individual objects and from arbitrary viewing distance. Accordingly, we develop a scale-invariant representation of images from the bottom up, using a piecewise linear approximation of contours and constrained Delaunay triangulation to complete gaps. We model curvilinear grouping on top of this graphical/geometric structure using a conditional random field to capture the statistics of continuity and different junction types. Quantitative evaluations on several large datasets show that our contour grouping algorithm consistently dominates and significantly improves on local edge detection.\n"
            },
            "slug": "Learning-Probabilistic-Models-for-Contour-in-Images-Ren-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Learning Probabilistic Models for Contour Completion in Natural Images"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work develops a scale-invariant representation of images from the bottom up, using a piecewise linear approximation of contours and constrained Delaunay triangulation to complete gaps and model curvilinear grouping on top of this graphical/geometric structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688714"
                        ],
                        "name": "Laurent Najman",
                        "slug": "Laurent-Najman",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Najman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Najman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862326"
                        ],
                        "name": "M. Schmitt",
                        "slug": "M.-Schmitt",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Schmitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schmitt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "The problem of oversegmentation is common across approaches based on feature clustering since smooth changes in texture or brightness due to perspective or shading can cause patches to appear dissimilar despite belonging to the same image region."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11219068,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b894683d59ef6d671d98387a7b9dc86212c02d8c",
            "isKey": false,
            "numCitedBy": 541,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The watershed is one of the latest segmentation tools developed in mathematical morphology. In order to prevent its oversegmentation, the notion of dynamics of a minimum, based on geodesic reconstruction, has been proposed. In this paper, we extend the notion of dynamics to the contour arcs. This notion acts as a measure of the saliency of the contour. Contrary to the dynamics of minima, our concept reflects the extension and shape of the corresponding object in the image. This representation is also much more natural, because it is expressed in terms of partitions of the plane, i.e., segmentations. A hierarchical segmentation process is then derived, which gives a compact description of the image, containing all the segmentations one can obtain by the notion of dynamics, by means of a simple thresholding. Finally, efficient algorithms for computing the geodesic reconstruction as well as the dynamics of contours are presented."
            },
            "slug": "Geodesic-Saliency-of-Watershed-Contours-and-Najman-Schmitt",
            "title": {
                "fragments": [],
                "text": "Geodesic Saliency of Watershed Contours and Hierarchical Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A hierarchical segmentation process is derived, which gives a compact description of the image, containing all the segmentations one can obtain by the notion of dynamics, by means of a simple thresholding."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 174
                            }
                        ],
                        "text": "We provide extensive experimental evaluation to demonstrate that, when coupled to a high-performance contour detector, the OWT-UCM algorithm produces state-of-the-art image segmentations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13571735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a9049a50dfe94fa4473880a9b60c99333ade685",
            "isKey": false,
            "numCitedBy": 1644,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a two-class classification model for grouping. Human segmented natural images are used as positive examples. Negative examples of grouping are constructed by randomly matching human segmentations and images. In a preprocessing stage an image is over-segmented into super-pixels. We define a variety of features derived from the classical Gestalt cues, including contour, texture, brightness and good continuation. Information-theoretic analysis is applied to evaluate the power of these grouping cues. We train a linear classifier to combine these features. To demonstrate the power of the classification model, a simple algorithm is used to randomly search for good segmentations. Results are shown on a wide range of images."
            },
            "slug": "Learning-a-classification-model-for-segmentation-Ren-Malik",
            "title": {
                "fragments": [],
                "text": "Learning a classification model for segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A two-class classification model for grouping is proposed that defines a variety of features derived from the classical Gestalt cues, including contour, texture, brightness and good continuation, and trains a linear classifier to combine these features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "Applications such as object recognition [34, 25, 1, 19] and monocular inference of 3D structure [20, 41] have led to a renewed interest in algorithms for automatic segmentation of an image into closed regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12812,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256849"
                        ],
                        "name": "R. Unnikrishnan",
                        "slug": "R.-Unnikrishnan",
                        "structuredName": {
                            "firstName": "Ranjith",
                            "lastName": "Unnikrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Unnikrishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2997956"
                        ],
                        "name": "C. Pantofaru",
                        "slug": "C.-Pantofaru",
                        "structuredName": {
                            "firstName": "Caroline",
                            "lastName": "Pantofaru",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pantofaru"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [45], this drawback is addressed by normalization with an empirical estimation of its expected value."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 46
                            }
                        ],
                        "text": "Variants of the Rand Index have been proposed [45, 47] for dealing with the case of multiple ground-truth segmentations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[45, 47], and its values across images and algorithms are often very similar."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17173984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16365ad9bf7fd7dd8b1867ef0d6b791488770b52",
            "isKey": false,
            "numCitedBy": 820,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised image segmentation is an important component in many image understanding algorithms and practical vision systems. However, evaluation of segmentation algorithms thus far has been largely subjective, leaving a system designer to judge the effectiveness of a technique based only on intuition and results in the form of a few example segmented images. This is largely due to image segmentation being an ill-defined problem-there is no unique ground-truth segmentation of an image against which the output of an algorithm may be compared. This paper demonstrates how a recently proposed measure of similarity, the normalized probabilistic rand (NPR) index, can be used to perform a quantitative comparison between image segmentation algorithms using a hand-labeled set of ground-truth segmentations. We show that the measure allows principled comparisons between segmentations created by different algorithms, as well as segmentations on different images. We outline a procedure for algorithm evaluation through an example evaluation of some familiar algorithms - the mean-shift-based algorithm, an efficient graph-based segmentation algorithm, a hybrid algorithm that combines the strengths of both methods, and expectation maximization. Results are presented on the 300 images in the publicly available Berkeley segmentation data set"
            },
            "slug": "Toward-Objective-Evaluation-of-Image-Segmentation-Unnikrishnan-Pantofaru",
            "title": {
                "fragments": [],
                "text": "Toward Objective Evaluation of Image Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated how a recently proposed measure of similarity, the normalized probabilistic rand (NPR) index, can be used to perform a quantitative comparison between image segmentation algorithms using a hand-labeled set of ground-truth segmentations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944189"
                        ],
                        "name": "S. Bagon",
                        "slug": "S.-Bagon",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Bagon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bagon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1910299"
                        ],
                        "name": "Oren Boiman",
                        "slug": "Oren-Boiman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Boiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Boiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144611617"
                        ],
                        "name": "M. Irani",
                        "slug": "M.-Irani",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Irani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Irani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "Human assisted segmentation is relevant for many applications, and recent approaches rely on the graph-cuts formalism [7, 40, 21] or other energy minimization procedure [4] to extract single foreground regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6219585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "614f96feb0acc25e5166aacb8fc3bc0f28ecb5c4",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a huge diversity of definitions of \"visually meaningful\" image segments, ranging from simple uniformly colored segments, textured segments, through symmetric patterns, and up to complex semantically meaningful objects. This diversity has led to a wide range of different approaches for image segmentation. In this paper we present a single unified framework for addressing this problem --- \"Segmentation by Composition\". We define a good image segment as one which can be easily composed using its own pieces, but is difficult to compose using pieces from other parts of the image. This non-parametric approach captures a large diversity of segment types, yet requires no pre-definition or modelling of segment types, nor prior training. Based on this definition, we develop a segment extraction algorithm --- i.e., given a single point-of-interest, provide the \"best\" image segment containing that point. This induces a figure-ground image segmentation, which applies to a range of different segmentation tasks: single image segmentation, simultaneous co-segmentation of several images, and class-based segmentations."
            },
            "slug": "What-Is-a-Good-Image-Segment-A-Unified-Approach-to-Bagon-Boiman",
            "title": {
                "fragments": [],
                "text": "What Is a Good Image Segment? A Unified Approach to Segment Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper defines a good image segment as one which can be easily composed using its own pieces, but is difficult to compose using pieces from other parts of the image, and develops a segment extraction algorithm which induces a figure-ground image segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17582380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34d4eb4666a20f7e3fad689d7862959bd128130b",
            "isKey": false,
            "numCitedBy": 1296,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture. Natural images contain both textured and untextured regions, so the cues of contour and texture differences are exploited simultaneously. Contours are treated in the intervening contour framework, while texture is analyzed using textons. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on the texturedness of the neighborhood at a pixel. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown."
            },
            "slug": "Contour-and-Texture-Analysis-for-Image-Segmentation-Malik-Belongie",
            "title": {
                "fragments": [],
                "text": "Contour and Texture Analysis for Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture, and introduces a gating operator based on the texturedness of the neighborhood at a pixel to facilitate cue combination."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "From mPb, we define an affinity matrix W between pixels using the intervening contour cue [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8443636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e2dac76a5876104f273b0a30617dac4c1c3033f",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper studies the problem of combining region and boundary cues for natural image segmentation. We employ a large database of manually segmented images in order to learn an optimal affinity function between pairs of pixels. These pairwise affinities can then be used to cluster the pixels into visually coherent groups. Region cues are computed as the similarity in brightness, color, and texture between image patches. Boundary cues are incorporated by looking for the presence of an \"intervening contour\", a large gradient along a straight line connecting two pixels. We first use the dataset of human segmentations to individually optimize parameters of the patch and gradient features for brightness, color, and texture cues. We then quantitatively measure the power of different feature combinations by computing the precision and recall of classifiers trained using those features. The mutual information between the output of the classifiers and the same-segment indicator function provides an alternative evaluation technique that yields identical conclusions. As expected, the best classifier makes use of brightness, color, and texture features, in both patch and gradient forms. We find that for brightness, the gradient cue outperforms the patch similarity. In contrast, using color patch similarity yields better results than using color gradients. Texture is the most powerful of the three channels, with both patches and gradients carrying significant independent information. Interestingly, the proximity of the two pixels does not add any information beyond that provided by the similarity cues. We also find that the convexity assumptions made by the intervening contour approach are supported by the ecological statistics of the dataset."
            },
            "slug": "Learning-affinity-functions-for-image-segmentation:-Fowlkes-Martin",
            "title": {
                "fragments": [],
                "text": "Learning affinity functions for image segmentation: combining patch-based and gradient-based approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A large database of manually segmented images is employed in order to learn an optimal affinity function between pairs of pixels, and it is found that for brightness, the gradient cue outperforms the patch similarity; in contrast, using color patch similarity yields better results than using color gradients."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "\u2026appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and Huttenlocher\u2019s graph based region merging [15]\n\u2217This work was supported by ONR MURI N00014-06-1-0734."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5839283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8392ada55a60ba7814aaf4ad32d1a014d1acbeae",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of curvilinear grouping using piece-wise linear representations of contours and a conditional random field to capture continuity and the frequency of different junction types. Potential completions are generated by building a constrained Delaunay triangulation (CDT) over the set of contours found by a local edge detector. Maximum likelihood parameters for the model are learned from human labeled ground truth. Using held out test data, we measure how the model, by incorporating continuity structure, improves boundary detection over the local edge detector. We also compare performance with a baseline local classifier that operates on pairs of edgels. Both algorithms consistently dominate the low-level boundary detector at all thresholds. To our knowledge, this is the first time that curvilinear continuity has been shown quantitatively useful for a large variety of natural images. Better boundary detection has immediate application in the problem of object detection and recognition"
            },
            "slug": "Scale-invariant-contour-completion-using-random-Ren-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Scale-invariant contour completion using conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This is the first time that curvilinear continuity has been shown quantitatively useful for a large variety of natural images and better boundary detection has immediate application in the problem of object detection and recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "The best detector, gPb [23], does not produce closed boundaries required to form a segmentation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "the Canny edge detector before thresholding, for the input E(x, y, \u03b8) signal, for best results, we employ the gPb detector introduced in our previous work [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 78
                            }
                        ],
                        "text": "[27] on the BSDS has become a standard, as demonstrated by its widespread use [37, 16, 12, 2, 48, 22, 36, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "\u2022 Using the gPb contour detector [23] as input, our method, gPb-owt-ucm provides a powerful mid-level grouping mechanism which outperforms all existing segmentation algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7002261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bb0f3a570936826401b4d1d322725bec3267dce",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Contours and junctions are important cues for perceptual organization and shape recognition. Detecting junctions locally has proved problematic because the image intensity surface is confusing in the neighborhood of a junction. Edge detectors also do not perform well near junctions. Current leading approaches to junction detection, such as the Harris operator, are based on 2D variation in the intensity signal. However, a drawback of this strategy is that it confuses textured regions with junctions. We believe that the right approach to junction detection should take advantage of the contours that are incident at a junction; contours themselves can be detected by processes that use more global approaches. In this paper, we develop a new high-performance contour detector using a combination of local and global cues. This contour detector provides the best performance to date (F=0.70) on the Berkeley Segmentation Dataset (BSDS) benchmark. From the resulting contours, we detect and localize candidate junctions, taking into account both contour salience and geometric configuration. We show that improvements in our contour model lead to better junctions. Our contour and junction detectors both provide state of the art performance."
            },
            "slug": "Using-contours-to-detect-and-localize-junctions-in-Maire-Arbel\u00e1ez",
            "title": {
                "fragments": [],
                "text": "Using contours to detect and localize junctions in natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new high-performance contour detector using a combination of local and global cues that provides the best performance to date on the Berkeley Segmentation Dataset (BSDS) benchmark and shows that improvements in the contour model lead to better junctions."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39599498"
                        ],
                        "name": "Chunhui Gu",
                        "slug": "Chunhui-Gu",
                        "structuredName": {
                            "firstName": "Chunhui",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chunhui Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109780936"
                        ],
                        "name": "Joseph J. Lim",
                        "slug": "Joseph-J.-Lim",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Lim",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph J. Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "We propose a generic grouping algorithm that constructs a hierarchy of regions from the output of any contour detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2100273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42a5da01c672b2d37e76c62f851c1f88e6b988c0",
            "isKey": false,
            "numCitedBy": 433,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a unified framework for object detection, segmentation, and classification using regions. Region features are appealing in this context because: (1) they encode shape and scale information of objects naturally; (2) they are only mildly affected by background clutter. Regions have not been popular as features due to their sensitivity to segmentation errors. In this paper, we start by producing a robust bag of overlaid regions for each image using Arbeldez et al., CVPR 2009. Each region is represented by a rich set of image cues (shape, color and texture). We then learn region weights using a max-margin framework. In detection and segmentation, we apply a generalized Hough voting scheme to generate hypotheses of object locations, scales and support, followed by a verification classifier and a constrained segmenter on each hypothesis. The proposed approach significantly outperforms the state of the art on the ETHZ shape database(87.1% average detection rate compared to Ferrari et al. 's 67.2%), and achieves competitive performance on the Caltech 101 database."
            },
            "slug": "Recognition-using-regions-Gu-Lim",
            "title": {
                "fragments": [],
                "text": "Recognition using regions"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper presents a unified framework for object detection, segmentation, and classification using regions using a generalized Hough voting scheme to generate hypotheses of object locations, scales and support, followed by a verification classifier and a constrained segmenter on each hypothesis."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197071"
                        ],
                        "name": "M. Jolly",
                        "slug": "M.-Jolly",
                        "structuredName": {
                            "firstName": "Marie-Pierre",
                            "lastName": "Jolly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jolly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 118
                            }
                        ],
                        "text": "Human assisted segmentation is relevant for many applications, and recent approaches rely on the graph-cuts formalism [7, 40, 21] or other energy minimization procedure [4] to extract single foreground regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2245438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d3b177e8d027d44c191e739a3a70ccacc2eac82",
            "isKey": false,
            "numCitedBy": 4174,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new technique for general purpose interactive segmentation of N-dimensional images. The user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation. Additional soft constraints incorporate both boundary and region information. Graph cuts are used to find the globally optimal segmentation of the N-dimensional image. The obtained solution gives the best balance of boundary and region properties among all segmentations satisfying the constraints. The topology of our segmentation is unrestricted and both \"object\" and \"background\" segments may consist of several isolated parts. Some experimental results are presented in the context of photo/video editing and medical image segmentation. We also demonstrate an interesting Gestalt example. A fast implementation of our segmentation method is possible via a new max-flow algorithm."
            },
            "slug": "Interactive-graph-cuts-for-optimal-boundary-&-of-in-Boykov-Jolly",
            "title": {
                "fragments": [],
                "text": "Interactive graph cuts for optimal boundary & region segmentation of objects in N-D images"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A new technique for general purpose interactive segmentation of N-dimensional images where the user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 158
                            }
                        ],
                        "text": "\u2026appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and Huttenlocher\u2019s graph based region merging [15]\n\u2217This work was supported by ONR MURI N00014-06-1-0734."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8165754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33a7a59f785ef46091c30c4c85ef88c6bdabab51",
            "isKey": false,
            "numCitedBy": 2381,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "slug": "Learning-to-detect-natural-image-boundaries-using-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Learning to detect natural image boundaries using local brightness, color, and texture cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The two main results are that cue combination can be performed adequately with a simple linear model and that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "\u2026appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and Huttenlocher\u2019s graph based region merging [15]\n\u2217This work was supported by ONR MURI N00014-06-1-0734."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6425029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8df48e3d8ad8d5684f26c8f9c2611b85b7b2bd1d",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of deriving a global interpretation of an image in terms of a small set of smooth curves. The problem is posed using a statistical model for images with multiple curves. Besides having important applications to edge detection and grouping the curve finding task is a special case of a more general problem, where we want to explain the whole image in terms of a small set of objects. We describe a novel approach for estimating the content of scenes with multiple objects using a min-cover framework that is simple and powerful. The min-cover problem is NP-hard but there is a good approximation algorithm that sequentially selects objects minimizing a \"cost per pixel\" measure. In the case of curve detection we use a type of best-first search to quickly find good curves for the covering algorithm. The method integrates image data over long curves without relying on binary feature detection. We have applied the curve detection method for finding object boundaries in natural scenes and measured its performance using the Berkeley segmentation dataset."
            },
            "slug": "A-Min-Cover-Approach-for-Finding-Salient-Curves-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A Min-Cover Approach for Finding Salient Curves"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel approach is described for estimating the content of scenes with multiple objects using a min-cover framework that is simple and powerful and integrates image data over long curves without relying on binary feature detection."
            },
            "venue": {
                "fragments": [],
                "text": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143856428"
                        ],
                        "name": "S. Todorovic",
                        "slug": "S.-Todorovic",
                        "structuredName": {
                            "firstName": "Sinisa",
                            "lastName": "Todorovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Todorovic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "We propose a generic grouping algorithm that constructs a hierarchy of regions from the output of any contour detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7420545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee5c2d73d5146f3a56be9b091a9f9ff3109deabd",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new object representation, called connected segmentation tree (CST), which captures canonical characteristics of the object in terms of the photometric, geometric, and spatial adjacency and containment properties of its constituent image regions. CST is obtained by augmenting the objectpsilas segmentation tree (ST) with inter-region neighbor links, in addition to their recursive embedding structure already present in ST. This makes CST a hierarchy of region adjacency graphs. A regionpsilas neighbors are computed using an extension to regions of the Voronoi diagram for point patterns. Unsupervised learning of the CST model of a category is formulated as matching the CST graph representations of unlabeled training images, and fusing their maximally matching subgraphs. A new learning algorithm is proposed that optimizes the model structure by simultaneously searching for both the most salient nodes (regions) and the most salient edges (containment and neighbor relationships of regions) across the image graphs. Matching of the category model to the CST of a new image results in simultaneous detection, segmentation and recognition of all occurrences of the category, and a semantic explanation of these results."
            },
            "slug": "Connected-Segmentation-Tree-\u2014-A-joint-of-region-and-Ahuja-Todorovic",
            "title": {
                "fragments": [],
                "text": "Connected Segmentation Tree \u2014 A joint representation of region layout and hierarchy"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new object representation, called connected segmentation tree (CST), is proposed, which captures canonical characteristics of the object in terms of the photometric, geometric, and spatial adjacency and containment properties of its constituent image regions."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 161
                            }
                        ],
                        "text": "Contour detection ignores such smooth variations by directly searching for locations in the image where brightness or other features undergo rapid local changes [9, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13284142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec",
            "isKey": false,
            "numCitedBy": 27661,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge."
            },
            "slug": "A-Computational-Approach-to-Edge-Detection-Canny",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a natural uncertainty principle between detection and localization performance, which are the two main goals, and with this principle a single operator shape is derived which is optimal at any scale."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "We propose a generic grouping algorithm that constructs a hierarchy of regions from the output of any contour detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206769405,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ae89592317675c9c7642a3976c3a064cef736f92",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision algorithms limit their performance by ignoring the underlying 3D geometric structure in the image. We show that we can estimate the coarse geometric properties of a scene by learning appearance-based models of geometric classes, even in cluttered natural scenes. Geometric classes describe the 3D orientation of an image region with respect to the camera. We provide a multiple-hypothesis framework for robustly estimating scene structure from a single image and obtaining confidences for each geometric label. These confidences can then be used to improve the performance of many other applications. We provide a thorough quantitative evaluation of our algorithm on a set of outdoor images and demonstrate its usefulness in two applications: object detection and automatic single-view reconstruction."
            },
            "slug": "Geometric-context-from-a-single-image-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Geometric context from a single image"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work shows that it can estimate the coarse geometric properties of a scene by learning appearance-based models of geometric classes, even in cluttered natural scenes, and provides a multiple-hypothesis framework for robustly estimating scene structure from a single image and obtaining confidences for each geometric label."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 161
                            }
                        ],
                        "text": "Contour detection ignores such smooth variations by directly searching for locations in the image where brightness or other features undergo rapid local changes [9, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5315394,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "83f3321b8f57c11d30252b3a86e35b8ca94eb358",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The projection of depth or orientation discontinuities in a physical scene results in image intensity edges which are not ideal step edges but are more typically a combination of step, peak and roof profiles. Most edge detection schemes ignore the composite nature of these edges, resulting in systematic errors in detection and localization. The problem of detecting and localizing these edges is addressed, along with the problem of false responses in smoothly shaded regions with constant gradient of the image brightness. A class of nonlinear filters, known as quadratic filters, is appropriate for this task, while linear filters are not. Performance criteria are derived for characterizing the SNR, localization and multiple responses of these filters in a manner analogous to Canny's criteria for linear filters. A two-dimensional version of the approach is developed which has the property of being able to represent multiple edges at the same location and determine the orientation of each to any desired precision. This permits junctions to be localized without rounding. Experimental results are presented.<<ETX>>"
            },
            "slug": "Detecting-and-localizing-edges-composed-of-steps,-Perona-Malik",
            "title": {
                "fragments": [],
                "text": "Detecting and localizing edges composed of steps, peaks and roofs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A two-dimensional version of the approach is developed which has the property of being able to represent multiple edges at the same location and determine the orientation of each to any desired precision, which permits junctions to be localized without rounding."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40984420"
                        ],
                        "name": "A. Yang",
                        "slug": "A.-Yang",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Yang",
                            "middleNames": [
                                "Yuqing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143607492"
                        ],
                        "name": "John Wright",
                        "slug": "John-Wright",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wright",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Wright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50032052"
                        ],
                        "name": "Yi Ma",
                        "slug": "Yi-Ma",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144797536"
                        ],
                        "name": "S. Sastry",
                        "slug": "S.-Sastry",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sastry",
                            "middleNames": [
                                "Shankar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sastry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8428748,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f69ff6128d33789242f4cec0dcb164cb32f4d99c",
            "isKey": false,
            "numCitedBy": 514,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Unsupervised-segmentation-of-natural-images-via-Yang-Wright",
            "title": {
                "fragments": [],
                "text": "Unsupervised segmentation of natural images via lossy data compression"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 118
                            }
                        ],
                        "text": "Human assisted segmentation is relevant for many applications, and recent approaches rely on the graph-cuts formalism [7, 40, 21] or other energy minimization procedure [4] to extract single foreground regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6202829,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a953aaf29ef67ee094943d4be50d753b3744573",
            "isKey": false,
            "numCitedBy": 5201,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for \"border matting\" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools."
            },
            "slug": "\"GrabCut\":-interactive-foreground-extraction-using-Rother-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "\"GrabCut\": interactive foreground extraction using iterated graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A more powerful, iterative version of the optimisation of the graph-cut approach is developed and the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7726541"
                        ],
                        "name": "R. Malladi",
                        "slug": "R.-Malladi",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Malladi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Malladi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9397819"
                        ],
                        "name": "J. Sethian",
                        "slug": "J.-Sethian",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Sethian",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sethian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733005"
                        ],
                        "name": "B. Vemuri",
                        "slug": "B.-Vemuri",
                        "structuredName": {
                            "firstName": "Baba",
                            "lastName": "Vemuri",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Vemuri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9505101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4c2d802cf9fe8de8f213727512e18bbfe3dc631",
            "isKey": false,
            "numCitedBy": 3572,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "Shape modeling is an important constituent of computer vision as well as computer graphics research. Shape models aid the tasks of object representation and recognition. This paper presents a new approach to shape modeling which retains some of the attractive features of existing methods and overcomes some of their limitations. The authors' techniques can be applied to model arbitrarily complex shapes, which include shapes with significant protrusions, and to situations where no a priori assumption about the object's topology is made. A single instance of the authors' model, when presented with an image having more than one object of interest, has the ability to split freely to represent each object. This method is based on the ideas developed by Osher and Sethian (1988) to model propagating solid/liquid interfaces with curvature-dependent speeds. The interface (front) is a closed, nonintersecting, hypersurface flowing along its gradient field with constant speed or a speed that depends on the curvature. It is moved by solving a \"Hamilton-Jacobi\" type equation written for a function in which the interface is a particular level set. A speed term synthesized from the image is used to stop the interface in the vicinity of object boundaries. The resulting equation of motion is solved by employing entropy-satisfying upwind finite difference schemes. The authors present a variety of ways of computing the evolving front, including narrow bands, reinitializations, and different stopping criteria. The efficacy of the scheme is demonstrated with numerical experiments on some synthesized images and some low contrast medical images. >"
            },
            "slug": "Shape-Modeling-with-Front-Propagation:-A-Level-Set-Malladi-Sethian",
            "title": {
                "fragments": [],
                "text": "Shape Modeling with Front Propagation: A Level Set Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The authors' techniques can be applied to model arbitrarily complex shapes, which include shapes with significant protrusions, and to situations where no a priori assumption about the object's topology is made."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807482"
                        ],
                        "name": "Timoth\u00e9e Cour",
                        "slug": "Timoth\u00e9e-Cour",
                        "structuredName": {
                            "firstName": "Timoth\u00e9e",
                            "lastName": "Cour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timoth\u00e9e Cour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2475859"
                        ],
                        "name": "F. B\u00e9n\u00e9zit",
                        "slug": "F.-B\u00e9n\u00e9zit",
                        "structuredName": {
                            "firstName": "Florence",
                            "lastName": "B\u00e9n\u00e9zit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. B\u00e9n\u00e9zit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "Applications such as object recognition [34, 25, 1, 19] and monocular inference of 3D structure [20, 41] have led to a renewed interest in algorithms for automatic segmentation of an image into closed regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6830366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b820164b7597c186232e90f076b95382a36ed0c",
            "isKey": false,
            "numCitedBy": 615,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a multiscale spectral image segmentation algorithm. In contrast to most multiscale image processing, this algorithm works on multiple scales of the image in parallel, without iteration, to capture both coarse and fine level details. The algorithm is computationally efficient, allowing to segment large images. We use the normalized cut graph partitioning framework of image segmentation. We construct a graph encoding pairwise pixel affinity, and partition the graph for image segmentation. We demonstrate that large image graphs can be compressed into multiple scales capturing image structure at increasingly large neighborhood. We show that the decomposition of the image segmentation graph into different scales can be determined by ecological statistics on the image grouping cues. Our segmentation algorithm works simultaneously across the graph scales, with an inter-scale constraint to ensure communication and consistency between the segmentations at each scale. As the results show, we incorporate long-range connections with linear-time complexity, providing high-quality segmentations efficiently. Images that previously could not be processed because of their size have been accurately segmented thanks to this method."
            },
            "slug": "Spectral-segmentation-with-multiscale-graph-Cour-B\u00e9n\u00e9zit",
            "title": {
                "fragments": [],
                "text": "Spectral segmentation with multiscale graph decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The segmentation algorithm works simultaneously across the graph scales, with an inter-scale constraint to ensure communication and consistency between the segmentations at each scale, and incorporates long-range connections with linear-time complexity, providing high-quality segmentations efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "\u2026appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and Huttenlocher\u2019s graph based region merging [15]\n\u2217This work was supported by ONR MURI N00014-06-1-0734."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1930439,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "4f010c71058d841a0b4f5db309c0b912a9322f5d",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we empirically study the multi-scale boundary detection problem in natural images. We utilize local boundary cues including contrast, localization and relative contrast, and train a classifier to integrate them across scales. Our approach successfully combines strengths from both large-scale detection (robust but poor localization) and small-scale detection (detail-preserving but sensitive to clutter). We carry out quantitative evaluations on a variety of boundary and object datasets with human-marked groundtruth. We show that multi-scale boundary detection offers large improvements, ranging from 20% to 50%, over single-scale approaches. This is the first time that multi-scale is demonstrated to improve boundary detection on large datasets of natural images."
            },
            "slug": "Multi-scale-Improves-Boundary-Detection-in-Natural-Ren",
            "title": {
                "fragments": [],
                "text": "Multi-scale Improves Boundary Detection in Natural Images"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This work empirically studies the multi-scale boundary detection problem in natural images, utilizing local boundary cues including contrast, localization and relative contrast, and train a classifier to integrate them across scales."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045340"
                        ],
                        "name": "Tomasz Malisiewicz",
                        "slug": "Tomasz-Malisiewicz",
                        "structuredName": {
                            "firstName": "Tomasz",
                            "lastName": "Malisiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomasz Malisiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "We propose a generic grouping algorithm that constructs a hierarchy of regions from the output of any contour detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15599169,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "562b04ee16f27c47625b4989ab011510518d0b0a",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Sliding window scanning is the dominant paradigm in object recognition research today. But while much success has been reported in detecting several rectangular-shaped object classes (i.e. faces, cars, pedestrians), results have been much less impressive for more general types of objects. Several researchers have advocated the use of image segmentation as a way to get a better spatial support for objects. In this paper, our aim is to address this issue by studying the following two questions: 1) how important is good spatial support for recognition? 2) can segmentation provide better spatial support for objects? To answer the first, we compare recognition performance using ground-truth segmentation vs. bounding boxes. To answer the second, we use the multiple segmentation approach to evaluate how close can real segments approach the ground-truth for real objects, and at what cost. Our results demonstrate the importance of finding the right spatial support for objects, and the feasibility of doing so without excessive computational burden."
            },
            "slug": "Improving-Spatial-Support-for-Objects-via-Multiple-Malisiewicz-Efros",
            "title": {
                "fragments": [],
                "text": "Improving Spatial Support for Objects via Multiple Segmentations"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The multiple segmentation approach is used to evaluate how close can real segments approach the ground-truth for real objects, and at what cost."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38336119"
                        ],
                        "name": "P. Parent",
                        "slug": "P.-Parent",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Parent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Parent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698824"
                        ],
                        "name": "S. Zucker",
                        "slug": "S.-Zucker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Zucker",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zucker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "\u2026by variational formulations [30, 29] and level set techniques [26]), three algorithms in this category appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6779369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c21b3372894b25ed595a73ff058ec5876976ca6",
            "isKey": false,
            "numCitedBy": 567,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach is described for curve inference that is based on curvature information. The inference procedure is divided into two stages: a trace inference stage, which is the subject of the present work, and a curve synthesis stage. It is shown that recovery of the trace of a curve requires estimating local models for the curve at the same time, and that tangent and curvature information are sufficient. These make it possible to specify powerful constraints between estimated tangents to a curve, in terms of a neighborhood relationship called cocircularity, and between curvature estimates, in terms of a curvature consistency relation. Because all curve information is quantized, special care must be taken to obtain accurate estimates of trace points, tangents, and curvatures. This issue is addressed specifically to the introduction of a smoothness constraint and a maximum curvature constraint. The procedure is applied to two types of images: artificial images designed to evaluate curvature and noise sensitivity, and natural images. >"
            },
            "slug": "Trace-Inference,-Curvature-Consistency,-and-Curve-Parent-Zucker",
            "title": {
                "fragments": [],
                "text": "Trace Inference, Curvature Consistency, and Curve Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that recovery of the trace of a curve requires estimating local models for the curve at the same time, and that tangent and curvature information are sufficient, which make it possible to specify powerful constraints between estimated tangents to a curve."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Applications such as object recognition [34, 25, 1, 19] and monocular inference of 3D structure [20, 41] have led to a renewed interest in algorithms for automatic segmentation of an image into closed regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": false,
            "numCitedBy": 11480,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "Our generic grouping machinery has found use in optical flow [8] and object recognition [19] applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3243550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa9f82781a0d844faec8616ffbe68113536fefea",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The literature currently provides two ways to establish point correspondences between images with moving objects. On one side, there are energy minimization methods that yield very accurate, dense flow fields, but fail as displacements get too large. On the other side, there is descriptor matching that allows for large displacements, but correspondences are very sparse, have limited accuracy, and due to missing regularity constraints there are many outliers. In this paper we propose a method that can combine the advantages of both matching strategies. A region hierarchy is established for both images. Descriptor matching on these regions provides a sparse set of hypotheses for correspondences. These are integrated into a variational approach and guide the local optimization to large displacement solutions. The variational optimization selects among the hypotheses and provides dense and subpixel accurate estimates, making use of geometric constraints and all available image information."
            },
            "slug": "Large-displacement-optical-flow-Brox-Bregler",
            "title": {
                "fragments": [],
                "text": "Large displacement optical flow"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a method that can combine the advantages of both matching strategies and provides dense and subpixel accurate estimates, making use of geometric constraints and all available image information."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000933"
                        ],
                        "name": "David Tolliver",
                        "slug": "David-Tolliver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tolliver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Tolliver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144985503"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16967230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47b0c6b290669e1927e5aa9c11d9e1f8321d8797",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a family of spectral partitioning methods. Edge separators of a graph are produced by iteratively reweighting the edges until the graph disconnects into the prescribed number of components. At each iteration a small number of eigenvectors with small eigenvalue are computed and used to determine the reweighting. In this way spectral rounding directly produces discrete solutions where as current spectral algorithms must map the continuous eigenvectors to discrete solutions by employing a heuristic geometric separator (e.g. k-means). We show that spectral rounding compares favorably to current spectral approximations on the Normalized Cut criterion (NCut). Results are given for natural image segmentation, medical image segmentation, and clustering. A practical version is shown to converge."
            },
            "slug": "Graph-Partitioning-by-Spectral-Rounding:-in-Image-Tolliver-Miller",
            "title": {
                "fragments": [],
                "text": "Graph Partitioning by Spectral Rounding: Applications in Image Segmentation and Clustering"
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2599292"
                        ],
                        "name": "J. Mairal",
                        "slug": "J.-Mairal",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Mairal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mairal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749627"
                        ],
                        "name": "M. Leordeanu",
                        "slug": "M.-Leordeanu",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Leordeanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leordeanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 173
                            }
                        ],
                        "text": "\u2026appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and Huttenlocher\u2019s graph based region merging [15]\n\u2217This work was supported by ONR MURI N00014-06-1-0734."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18747497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b11f559432f453fb801befe5e43768a97855c8ca",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse signal models learned from data are widely used in audio, image, and video restoration. They have recently been generalized to discriminative image understanding tasks such as texture segmentation and feature selection. This paper extends this line of research by proposing a multiscale method to minimize least-squares reconstruction errors and discriminative cost functions under ?0 or ?1 regularization constraints. It is applied to edge detection, category-based edge selection and image classification tasks. Experiments on the Berkeley edge detection benchmark and the PASCAL VOC'05 and VOC'07 datasets demonstrate the computational efficiency of our algorithm and its ability to learn local image descriptions that effectively support demanding computer vision tasks."
            },
            "slug": "Discriminative-Sparse-Image-Models-for-Edge-and-Mairal-Leordeanu",
            "title": {
                "fragments": [],
                "text": "Discriminative Sparse Image Models for Class-Specific Edge Detection and Image Interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34261820"
                        ],
                        "name": "Qihui Zhu",
                        "slug": "Qihui-Zhu",
                        "structuredName": {
                            "firstName": "Qihui",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qihui Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145349654"
                        ],
                        "name": "G. Song",
                        "slug": "G.-Song",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "\u2026appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and Huttenlocher\u2019s graph based region merging [15]\n\u2217This work was supported by ONR MURI N00014-06-1-0734."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1297614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0c3b858afcbe291dec3f43149927d31286207e9",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel topological formulation for contour grouping. Our grouping criterion, called untangling cycles, exploits the inherent topological 1D structure of salient contours to extract them from the otherwise 2D image clutter. To define a measure for topological classification robust to clutter and broken edges, we use a graph formulation instead of the standard computational topology. The key insight is that a pronounced ID contour should have a clear ordering of edges, to which all graph edges adhere, and no long range entanglements persist. Finding the contour grouping by optimizing these topological criteria is challenging. We introduce a novel concept of circular embedding to encode this combinatorial task. Our solution leads to computing the dominant complex eigenvectors/eigenvalues of the random walk matrix of the contour grouping graph. We demonstrate major improvements over state-of-the-art approaches on challenging real images."
            },
            "slug": "Untangling-Cycles-for-Contour-Grouping-Zhu-Song",
            "title": {
                "fragments": [],
                "text": "Untangling Cycles for Contour Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel concept of circular embedding is introduced to encode this combinatorial task that leads to computing the dominant complex eigenvectors/eigenvalues of the random walk matrix of the contour grouping graph."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2955375"
                        ],
                        "name": "L. Williams",
                        "slug": "L.-Williams",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Williams",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "\u2026formulations [30, 29] and level set techniques [26]), three algorithms in this category appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12429143,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0fd62892dc5919d48ed03e7874bab66fb9d7e5ca",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an algorithm and representation-level theory of illusory contour shape and salience. Unlike previous theories, our model is derived from a single assumption: that the prior probability distribution of boundary completion shape can be modeled by a random walk in a lattice whose points are positions and orientations in the image plane (i.e., the space that one can reasonably assume is represented by neurons of the mammalian visual cortex). Our model does not employ numerical relaxation or other explicit minimization, but instead relies on the fact that the probability that a particle following a random walk will pass through a given position and orientation on a path joining two boundary fragments can be computed directly as the product of two vector-field convolutions. We show that for the random walk we define, the maximum likelihood paths are curves of least energy, that is, on average, random walks follow paths commonly assumed to model the shape of illusory contours. A computer model is demonstrated on numerous illusory contour stimuli from the literature."
            },
            "slug": "Stochastic-Completion-Fields:-A-Neural-Model-of-and-Williams-Jacobs",
            "title": {
                "fragments": [],
                "text": "Stochastic Completion Fields: A Neural Model of Illusory Contour Shape and Salience"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An algorithm and representation-level theory of illusory contour shape and salience that relies on the fact that the probability that a particle following a random walk will pass through a given position and orientation on a path joining two boundary fragments can be computed directly as the product of two vector-field convolutions."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "\u2026appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and Huttenlocher\u2019s graph based region merging [15]\n\u2217This work was supported by ONR MURI N00014-06-1-0734."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6382669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be305b0684f1a6ec8407c107187d28502b48f993",
            "isKey": false,
            "numCitedBy": 464,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Edge detection is one of the most studied problems in computer vision, yet it remains a very challenging task. It is difficult since often the decision for an edge cannot be made purely based on low level cues such as gradient, instead we need to engage all levels of information, low, middle, and high, in order to decide where to put edges. In this paper we propose a novel supervised learning algorithm for edge and object boundary detection which we refer to as Boosted Edge Learning or BEL for short. A decision of an edge point is made independently at each location in the image; a very large aperture is used providing significant context for each decision. In the learning stage, the algorithm selects and combines a large number of features across different scales in order to learn a discriminative model using an extended version of the Probabilistic Boosting Tree classification algorithm. The learning based framework is highly adaptive and there are no parameters to tune. We show applications for edge detection in a number of specific image domains as well as on natural images. We test on various datasets including the Berkeley dataset and the results obtained are very good."
            },
            "slug": "Supervised-Learning-of-Edges-and-Object-Boundaries-Doll\u00e1r-Tu",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Edges and Object Boundaries"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes a novel supervised learning algorithm for edge and object boundary detection which it refers to as Boosted Edge Learning or BEL for short and shows applications for edge detection in a number of specific image domains as well as on natural images."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774737"
                        ],
                        "name": "J. Shotton",
                        "slug": "J.-Shotton",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Shotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shotton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Table 3 reports the comparison between Canny-owt-ucm and gPb-owt-ucm on two other publicly available datasets:\n\u2022 MSRC [43] The MSRC object recognition database is composed of 591 natural images with objects belong-\ning to 21 classes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "\u2022 MSRC [43] The MSRC object recognition database is composed of 591 natural images with objects belonging to 21 classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6075144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb444dc25bab36a8e273ed654d49e3841905e5af",
            "isKey": false,
            "numCitedBy": 1349,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently. The learned model is used for automatic visual recognition and semantic segmentation of photographs. Our discriminative model exploits novel features, based on textons, which jointly model shape and texture. Unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of classes. Accurate image segmentation is achieved by incorporating these classifiers in a conditional random field. Efficient training of the model on very large datasets is achieved by exploiting both random feature selection and piecewise training methods. \n \nHigh classification and segmentation accuracy are demonstrated on three different databases: i) our own 21-object class database of photographs of real objects viewed under general lighting conditions, poses and viewpoints, ii) the 7-class Corel subset and iii) the 7-class Sowerby database used in [1]. The proposed algorithm gives competitive results both for highly textured (e.g. grass, trees), highly structured (e.g. cars, faces, bikes, aeroplanes) and articulated objects (e.g. body, cow)."
            },
            "slug": "TextonBoost:-Joint-Appearance,-Shape-and-Context-Shotton-Winn",
            "title": {
                "fragments": [],
                "text": "TextonBoost: Joint Appearance, Shape and Context Modeling for Multi-class Object Recognition and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently, is proposed, which is used for automatic visual recognition and semantic segmentation of photographs."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80271822"
                        ],
                        "name": "J. Shah",
                        "slug": "J.-Shah",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 222243846,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a1067e837c7cbbefb30f8324c1eacb1afde39fc6",
            "isKey": false,
            "numCitedBy": 5156,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This reprint will introduce and study the most basic properties of three new variational problems which are suggested by applications to computer vision. In computer vision, a fundamental problem is to appropriately decompose the domain R of a function g (x,y) of two variables. This problem starts by describing the physical situation which produces images: assume that a three-dimensional world is observed by an eye or camera from some point P and that g1(rho) represents the intensity of the light in this world approaching the point sub 1 from a direction rho. If one has a lens at P focusing this light on a retina or a film-in both cases a plane domain R in which we may introduce coordinates x, y then let g(x,y) be the strength of the light signal striking R at a point with coordinates (x,y); g(x,y) is essentially the same as sub 1 (rho) -possibly after a simple transformation given by the geometry of the imaging syste. The function g(x,y) defined on the plane domain R will be called an image. What sort of function is g? The light reflected off the surfaces Si of various solid objects O sub i visible from P will strike the domain R in various open subsets R sub i. When one object O1 is partially in front of another object O2 as seen from P, but some of object O2 appears as the background to the sides of O1, then the open sets R1 and R2 will have a common boundary (the 'edge' of object O1 in the image defined on R) and one usually expects the image g(x,y) to be discontinuous along this boundary. (JHD)"
            },
            "slug": "Optimal-approximations-by-piecewise-smooth-and-Mumford-Shah",
            "title": {
                "fragments": [],
                "text": "Optimal approximations by piecewise smooth functions and associated variational problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143980357"
                        ],
                        "name": "W. Rand",
                        "slug": "W.-Rand",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Rand",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 17
                            }
                        ],
                        "text": "In our case, the Rand Index between test and groundtruth segmentationsS andG is given by the sum of the number of pairs of pixels that have the same label in S andG and those that have different labels in both segmentations, divided by the total number of pairs of pixels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 16
                            }
                        ],
                        "text": "Variants of the Rand Index have been proposed [45, 47] for dealing with the case of multiple ground-truth segmentations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 76
                            }
                        ],
                        "text": "When the sample mean is used to estimate pij , (5) amounts to averaging the Rand Index among different ground-truth segmentations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Originally, the Rand Index [35] was introduced for general clustering evaluation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 66
                            }
                        ],
                        "text": "Given a set of ground-truth segmentations {Gk}, the Probabilistic Rand Index is defined as\nPRI(S, {Gk}) = 1\nT\n\u2211\ni j\n[cijpij + (1 \u2212 cij)(1 \u2212 pij)] (5)\nwhere cij is the event that pixels i and j have the same label and pij its probability."
                    },
                    "intents": []
                }
            ],
            "corpusId": 197457299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "954937ece00fd465f6a639fa739a04af8d5d7efb",
            "isKey": true,
            "numCitedBy": 5534,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Many intuitively appealing methods have been suggested for clustering data, however, interpretation of their results has been hindered by the lack of objective criteria. This article proposes several criteria which isolate specific aspects of the performance of a method, such as its retrieval of inherent structure, its sensitivity to resampling and the stability of its results in the light of new data. These criteria depend on a measure of similarity between two different clusterings of the same set of data; the measure essentially considers how each pair of data points is assigned in each clustering."
            },
            "slug": "Objective-Criteria-for-the-Evaluation-of-Clustering-Rand",
            "title": {
                "fragments": [],
                "text": "Objective Criteria for the Evaluation of Clustering Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This article proposes several criteria which isolate specific aspects of the performance of a method, such as its retrieval of inherent structure, its sensitivity to resampling and the stability of its results in the light of new data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39863668"
                        ],
                        "name": "Andrew Rabinovich",
                        "slug": "Andrew-Rabinovich",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Rabinovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1954793"
                        ],
                        "name": "C. Galleguillos",
                        "slug": "C.-Galleguillos",
                        "structuredName": {
                            "firstName": "Carolina",
                            "lastName": "Galleguillos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Galleguillos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766844"
                        ],
                        "name": "Eric Wiewiora",
                        "slug": "Eric-Wiewiora",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Wiewiora",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Wiewiora"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 40
                            }
                        ],
                        "text": "Applications such as object recognition [34, 25, 1, 19] and monocular inference of 3D structure [20, 41] have led to a renewed interest in algorithms for automatic segmentation of an image into closed regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 749550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4d13788112f0fec457d31e1f7de9a53bbcec8e6",
            "isKey": false,
            "numCitedBy": 717,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In the task of visual object categorization, semantic context can play the very important role of reducing ambiguity in objects' visual appearance. In this work we propose to incorporate semantic object context as a post-processing step into any off-the-shelf object categorization model. Using a conditional random field (CRF) framework, our approach maximizes object label agreement according to contextual relevance. We compare two sources of context: one learned from training data and another queried from Google Sets. The overall performance of the proposed framework is evaluated on the PASCAL and MSRC datasets. Our findings conclude that incorporating context into object categorization greatly improves categorization accuracy."
            },
            "slug": "Objects-in-Context-Rabinovich-Vedaldi",
            "title": {
                "fragments": [],
                "text": "Objects in Context"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes to incorporate semantic object context as a post-processing step into any off-the-shelf object categorization model using a conditional random field (CRF) framework, which maximizes object label agreement according to contextual relevance."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681995"
                        ],
                        "name": "Ashutosh Saxena",
                        "slug": "Ashutosh-Saxena",
                        "structuredName": {
                            "firstName": "Ashutosh",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashutosh Saxena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112610462"
                        ],
                        "name": "Sung H. Chung",
                        "slug": "Sung-H.-Chung",
                        "structuredName": {
                            "firstName": "Sung",
                            "lastName": "Chung",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sung H. Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 96
                            }
                        ],
                        "text": "Applications such as object recognition [34, 25, 1, 19] and monocular inference of 3D structure [20, 41] have led to a renewed interest in algorithms for automatic segmentation of an image into closed regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9620866,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3635881d5632816df7762f2c588138c0baa339ef",
            "isKey": false,
            "numCitedBy": 621,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe consider the task of 3-d depth estimation from a single still image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured indoor and outdoor environments which include forests, sidewalks, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the value of the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufficient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a hierarchical, multiscale Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models the depths and the relation between depths at different points in the image. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps. We further propose a model that incorporates both monocular cues and stereo (triangulation) cues, to obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone.\n"
            },
            "slug": "3-D-Depth-Reconstruction-from-a-Single-Still-Image-Saxena-Chung",
            "title": {
                "fragments": [],
                "text": "3-D Depth Reconstruction from a Single Still Image"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a model that incorporates both monocular cues and stereo (triangulation) cues, to obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111190090"
                        ],
                        "name": "Yin Li",
                        "slug": "Yin-Li",
                        "structuredName": {
                            "firstName": "Yin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152147500"
                        ],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2088295"
                        ],
                        "name": "Chi-Keung Tang",
                        "slug": "Chi-Keung-Tang",
                        "structuredName": {
                            "firstName": "Chi-Keung",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chi-Keung Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 118
                            }
                        ],
                        "text": "Human assisted segmentation is relevant for many applications, and recent approaches rely on the graph-cuts formalism [7, 40, 21] or other energy minimization procedure [4] to extract single foreground regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1904479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f51d84009a1ec30dffa5ab8a1c3214f669086cf",
            "isKey": false,
            "numCitedBy": 650,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present Lazy Snapping, an interactive image cutout tool. Lazy Snapping separates coarse and fine scale processing, making object specification and detailed adjustment easy. Moreover, Lazy Snapping provides instant visual feedback, snapping the cutout contour to the true object boundary efficiently despite the presence of ambiguous or low contrast edges. Instant feedback is made possible by a novel image segmentation algorithm which combines graph cut with pre-computed over-segmentation. A set of intuitive user interface (UI) tools is designed and implemented to provide flexible control and editing for the users. Usability studies indicate that Lazy Snapping provides a better user experience and produces better segmentation results than the state-of-the-art interactive image cutout tool, Magnetic Lasso in Adobe Photoshop."
            },
            "slug": "Lazy-snapping-Li-Sun",
            "title": {
                "fragments": [],
                "text": "Lazy snapping"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Usability studies indicate that Lazy Snapping provides a better user experience and produces better segmentation results than the state-of-the-art interactive image cutout tool, Magnetic Lasso in Adobe Photoshop."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2316129"
                        ],
                        "name": "M. Meil\u0103",
                        "slug": "M.-Meil\u0103",
                        "structuredName": {
                            "firstName": "Marina",
                            "lastName": "Meil\u0103",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meil\u0103"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Although V I possesses some interesting theoretical properties [28], its perceptual meaning and applicability in the presence of several ground-truth segmentations remains unclear."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 578125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "102ae5a579538aa00569553c3151578561bc8b6f",
            "isKey": false,
            "numCitedBy": 621,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper views clusterings as elements of a lattice. Distances between clusterings are analyzed in their relationship to the lattice. From this vantage point, we first give an axiomatic characterization of some criteria for comparing clusterings, including the variation of information and the unadjusted Rand index. Then we study other distances between partitions w.r.t these axioms and prove an impossibility result: there is no \"sensible\" criterion for comparing clusterings that is simultaneously (1) aligned with the lattice of partitions, (2) convexely additive, and (3) bounded."
            },
            "slug": "Comparing-clusterings:-an-axiomatic-view-Meil\u0103",
            "title": {
                "fragments": [],
                "text": "Comparing clusterings: an axiomatic view"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper views clusterings as elements of a lattice and gives an axiomatic characterization of some criteria for comparing clusterings, including the variation of information and the unadjusted Rand index, and proves an impossibility result: there is no \"sensible\" criterion for comparing clusters that is simultaneously aligned with the lattice of partitions, convexely additive, and bounded."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27053481"
                        ],
                        "name": "J. Morel",
                        "slug": "J.-Morel",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Morel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Morel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10014835"
                        ],
                        "name": "S. Solimini",
                        "slug": "S.-Solimini",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Solimini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solimini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117709783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91f4b167f36f7fd4499f57bca71c07b01ebfb3f6",
            "isKey": false,
            "numCitedBy": 712,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Variational-methods-in-image-segmentation-Morel-Solimini",
            "title": {
                "fragments": [],
                "text": "Variational methods in image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "\u2026formulations [30, 29] and level set techniques [26]), three algorithms in this category appear to be the most widely used as sources of image segments in recent applications, due to a combination of reasonable performance and publicly available implementations:\n\u2022 Felzenszwalb and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computing contour closures"
            },
            "venue": {
                "fragments": [],
                "text": "Computing contour closures"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Segments come with their own scale estimates and provide natural domains for computing features used in recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient graph-based segmentation algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Efficient graph-based segmentation algorithm"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "www.cs.berkeley.edu/projects/vision/grouping/segbench"
            },
            "venue": {
                "fragments": [],
                "text": "www.cs.berkeley.edu/projects/vision/grouping/segbench"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These hierarchical segmentations can optionally be further refined by user-specified annotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Colorand texture-based image segmentation using EM and its application to content-based image retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Colorand texture-based image segmentation using EM and its application to content-based image retrieval"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Obtain OWT by reweighting arcs according to E(x, y, \u03b8) at the orientation \u03b8 of their associated line segments"
            },
            "venue": {
                "fragments": [],
                "text": "Obtain OWT by reweighting arcs according to E(x, y, \u03b8) at the orientation \u03b8 of their associated line segments"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "The problem of oversegmentation is common across approaches based on feature clustering since smooth changes in texture or brightness due to perspective or shading can cause patches to appear dissimilar despite belonging to the same image region."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mathematical morphology in image processing, chapter 12"
            },
            "venue": {
                "fragments": [],
                "text": "Mathematical morphology in image processing, chapter 12"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Subdivide arcs K 0 into approximating straight line segments"
            },
            "venue": {
                "fragments": [],
                "text": "Subdivide arcs K 0 into approximating straight line segments"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Berkeley Segmentation Dataset and Benchmark (BSDB)"
            },
            "venue": {
                "fragments": [],
                "text": "The Berkeley Segmentation Dataset and Benchmark (BSDB)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lazy snapping. SIGGRAPH"
            },
            "venue": {
                "fragments": [],
                "text": "Lazy snapping. SIGGRAPH"
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 33,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 51,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/From-contours-to-regions:-An-empirical-evaluation-Arbel\u00e1ez-Maire/779dea9b105d8f48c9bc86f479b91f9c1d3c5963?sort=total-citations"
}