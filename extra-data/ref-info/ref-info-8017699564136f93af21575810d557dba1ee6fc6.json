{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59770361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7bb7027fecb01fb6292d6c51d417f2ea003d57d",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Techniques for discovering rules by induction from large collections of instances are developed. These are based on an iterative scheme for dividing the instances into two sets, only one of which needs to be randomly accessible. These techniques have made it possible to discover complex rules from data bases containing many thousands of instances. Results of several experiments using them are reported."
            },
            "slug": "Induction-over-large-data-bases-Quinlan",
            "title": {
                "fragments": [],
                "text": "Induction over large data bases"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Techniques for discovering rules by induction from large collections of instances are developed based on an iterative scheme for dividing the instances into two sets, only one of which needs to be randomly accessible."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702517"
                        ],
                        "name": "I. Sethi",
                        "slug": "I.-Sethi",
                        "structuredName": {
                            "firstName": "Ishwar",
                            "lastName": "Sethi",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sethi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116148967"
                        ],
                        "name": "Biswanath Chattkerjee",
                        "slug": "Biswanath-Chattkerjee",
                        "structuredName": {
                            "firstName": "Biswanath",
                            "lastName": "Chattkerjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Biswanath Chattkerjee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29975961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c4a39e43d22b9e39507cde0ccae50859d447a7e",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficient-decision-tree-design-for-discrete-pattern-Sethi-Chattkerjee",
            "title": {
                "fragments": [],
                "text": "Efficient decision tree design for discrete variable pattern recognition problems"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3268154"
                        ],
                        "name": "C. Hartmann",
                        "slug": "C.-Hartmann",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Hartmann",
                            "middleNames": [
                                "R.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hartmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925309"
                        ],
                        "name": "P. Varshney",
                        "slug": "P.-Varshney",
                        "structuredName": {
                            "firstName": "Pramod",
                            "lastName": "Varshney",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Varshney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743871"
                        ],
                        "name": "K. Mehrotra",
                        "slug": "K.-Mehrotra",
                        "structuredName": {
                            "firstName": "Kishan",
                            "lastName": "Mehrotra",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mehrotra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17126878"
                        ],
                        "name": "C. L. Gerberich",
                        "slug": "C.-L.-Gerberich",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Gerberich",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Gerberich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "nition [ l]-[lo], logic design [ 111, taxonomy, questionnaires, and diagnostic manuals [12], expert systems, and machine learning [13]-[20], and the conversion of decision tables to nested \u201cif . . . then . . . else\u201d rules for computer programs [21]-[ 31 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18200443,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e30a6b22ed4e4800a92eea07d3b297456f02f846",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of conversion of decision tables to decision trees is treated. In most cases, the construction of optimal decision trees is an NP-complete problem and, therefore, a heuristic approach to this problem is necessary. In this heuristic approach, an application of information theoretic concepts to construct efficient decision trees for decision tables which may include \"don't care\" entries is made. In contrast to most of the existing heuristic algorithms, this algorithm is systematic and is intuitively appealing from an information theoretic standpoint. The algorithm has low design complexity and yet provides near-optimal decision trees."
            },
            "slug": "Application-of-information-theory-to-the-of-trees-Hartmann-Varshney",
            "title": {
                "fragments": [],
                "text": "Application of information theory to the construction of efficient decision trees"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This heuristic approach to the problem of conversion of decision tables to decision trees is treated and has low design complexity and yet provides near-optimal decision trees."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2960620"
                        ],
                        "name": "W. Meisel",
                        "slug": "W.-Meisel",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Meisel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meisel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39926861"
                        ],
                        "name": "D. Michalopoulos",
                        "slug": "D.-Michalopoulos",
                        "structuredName": {
                            "firstName": "Demetrios",
                            "lastName": "Michalopoulos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Michalopoulos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39513211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5189ef7b7a7e9a1b49decfca061d57f441087bac",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The efficient partitioning of a finite-dimensional space by a decision tree, each node of which corresponds to a comparison involving a single variable, is a problem occurring in pattern classification, piecewise-constant approximation, and in the efficient programming of decision trees. A two-stage algorithm is proposed. The first stage obtains a sufficient partition suboptimally, either by methods suggested in the paper or developed elsewhere; the second stage optimizes the results of the first stage through a dynamic programming approach. In pattern classification, the resulting decision rule yields the minimum average number of calculations to reach a decision. In approximation, arbitrary accuracy for a finite number of unique samples is possible. In programming decision trees, the expected number of computations to reach a decision is minimized."
            },
            "slug": "A-Partitioning-Algorithm-with-Application-in-and-of-Meisel-Michalopoulos",
            "title": {
                "fragments": [],
                "text": "A Partitioning Algorithm with Application in Pattern Classification and the Optimization of Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A two-stage algorithm that obtains a sufficient partition suboptimally, either by methods suggested in the paper or developed elsewhere, and optimizes the results of the first stage through a dynamic programming approach is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702517"
                        ],
                        "name": "I. Sethi",
                        "slug": "I.-Sethi",
                        "structuredName": {
                            "firstName": "Ishwar",
                            "lastName": "Sethi",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sethi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266532"
                        ],
                        "name": "G. P. R. Sarvarayudu",
                        "slug": "G.-P.-R.-Sarvarayudu",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Sarvarayudu",
                            "middleNames": [
                                "P.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. P. R. Sarvarayudu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18707355,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66ee4bb5d704856f43d751c259a7b5de9c77b764",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric algorithm is presented for the hierarchical partitioning of the feature space. The algorithm is based on the concept of average mutual information, and is suitable for multifeature multicategory pattern recognition problems. The algorithm generates an efficient partitioning tree for specified probability of error by maximizing the amount of average mutual information gain at each partitioning step. A confidence bound expression is presented for the resulting classifier. Three examples, including one of handprinted numeral recognition, are presented to demonstrate the effectiveness of the algorithm."
            },
            "slug": "Hierarchical-Classifier-Design-Using-Mutual-Sethi-Sarvarayudu",
            "title": {
                "fragments": [],
                "text": "Hierarchical Classifier Design Using Mutual Information"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A nonparametric algorithm is presented for the hierarchical partitioning of the feature space that generates an efficient partitioning tree for specified probability of error by maximizing the amount of average mutual information gain at each partitioning step."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49603217"
                        ],
                        "name": "R. Payne",
                        "slug": "R.-Payne",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Payne",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Payne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2023904"
                        ],
                        "name": "D. Preece",
                        "slug": "D.-Preece",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Preece",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Preece"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "nition [ l]-[lo], logic design [ 111, taxonomy, questionnaires, and diagnostic manuals [ 12 ], expert systems, and machine learning [13]-[20], and the conversion of decision tables to nested \u201cif . . . then . . . else\u201d rules for computer programs [21]-[31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 107429448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b857656e52d103f7ed0c34af225e1945d3887c7e",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 171,
            "paperAbstract": {
                "fragments": [],
                "text": "Professor E. M. L. BEALE in the Chair] SUMMARY The methodology and fields of application of identification keys and diagnostic tables are reviewed, consideration being given to both mathematical theory and practical requirements. Probabilistic and non-probabilistic techniques are covered. The paper attempts a synthesis of a large and widely dispersed literature that is not properly integrated, in that workers in one field of application have often been unaware of relevant theory developed in other fields."
            },
            "slug": "Identification-Keys-and-Diagnostic-Tables:-a-Review-Payne-Preece",
            "title": {
                "fragments": [],
                "text": "Identification Keys and Diagnostic Tables: a Review"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The paper attempts a synthesis of a large and widely dispersed literature that is not properly integrated, in that workers in one field of application have often been unaware of relevant theory developed in other fields."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16926,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144589701"
                        ],
                        "name": "H. Payne",
                        "slug": "H.-Payne",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Payne",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Payne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2960620"
                        ],
                        "name": "W. Meisel",
                        "slug": "W.-Meisel",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Meisel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meisel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7004358,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8c9fa00e4b148060c5f79a9d5446b9ec1e1e54c3",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of optimally partitioning an n-dimensional lattice, L = L, X ... X LN, where Lj is a one-dimensional lattice with kj elements, by means of a binary tree into specified (labeled) subsets of L. Such lattices arise from problems in pattern classification, in nonlinear regression, in defining logical equations, and a number of related areas. When viewed as the partitioning of a vector space, each point in the lattice corresponds to a subregion of the space which is relatively homogeneous with respect to classification or range of a dependent variable. Optimality is defined in terms of a general cost function which includes the following: 1) min-max path length (i. e., minimize the maximum number of nodes traversed in making a decision); 2) minimum number of nodes in the tree; and 3) expected path length. It is shown that an optimal tree can be recursively constructed through the application of invariant imbedding (dynamic programming). An algorithm is detailed which embodies this recursive approach. The algorithm allows the assignment of a \"don't care\" label to elements of L."
            },
            "slug": "An-Algorithm-for-Constructing-Optimal-Binary-Trees-Payne-Meisel",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Constructing Optimal Binary Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is shown that an optimal tree can be recursively constructed through the application of invariant imbedding (dynamic programming) and an algorithm is detailed which embodies this recursive approach."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2550392"
                        ],
                        "name": "B. Efron",
                        "slug": "B.-Efron",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Efron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Efron"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120750007,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b7bd8ec9ed208323617540a5e4a4a94bb898dd4f",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We consider regression situations for which the response variable is dichotomous. The most common analysis fits successively richer linear logistic models and measures the residual variation from the model by minus twice the maximized log likelihood. General measures of residual variation are considered here, including ordinary squared error and prediction error as well as the log likelihood. All of these are shown to be satisfactory in a certain primitive sense, unlike quantitative regression theory where only squared error is logically satisfactory. The relation of Goodman and Kruskal's measures of categorical association to the theory of penalty functions and probability elicitation is demonstrated."
            },
            "slug": "Regression-and-ANOVA-with-Zero-One-Data:-Measures-Efron",
            "title": {
                "fragments": [],
                "text": "Regression and ANOVA with Zero-One Data: Measures of Residual Variation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104537710"
                        ],
                        "name": "J. MacQueen",
                        "slug": "J.-MacQueen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "MacQueen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacQueen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In fact, this algorithm is equivalent to the K-means algorithm [ 42 ] for determining pattern clusters or the generalized Lloyd algorithm [46] for designing vector quantizers, using the divergence as a distortion measure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6278891,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ac8ab51a86f1a9ae74dd0e4576d1a019f5e654ed",
            "isKey": false,
            "numCitedBy": 24206,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to describe a process for partitioning an N-dimensional population into k sets on the basis of a sample. The process, which is called 'k-means,' appears to give partitions which are reasonably efficient in the sense of within-class variance. That is, if p is the probability mass function for the population, S = {S1, S2, * *, Sk} is a partition of EN, and ui, i = 1, 2, * , k, is the conditional mean of p over the set Si, then W2(S) = ff=ISi f z u42 dp(z) tends to be low for the partitions S generated by the method. We say 'tends to be low,' primarily because of intuitive considerations, corroborated to some extent by mathematical analysis and practical computational experience. Also, the k-means procedure is easily programmed and is computationally economical, so that it is feasible to process very large samples on a digital computer. Possible applications include methods for similarity grouping, nonlinear prediction, approximating multivariate distributions, and nonparametric tests for independence among several variables. In addition to suggesting practical classification methods, the study of k-means has proved to be theoretically interesting. The k-means concept represents a generalization of the ordinary sample mean, and one is naturally led to study the pertinent asymptotic behavior, the object being to establish some sort of law of large numbers for the k-means. This problem is sufficiently interesting, in fact, for us to devote a good portion of this paper to it. The k-means are defined in section 2.1, and the main results which have been obtained on the asymptotic behavior are given there. The rest of section 2 is devoted to the proofs of these results. Section 3 describes several specific possible applications, and reports some preliminary results from computer experiments conducted to explore the possibilities inherent in the k-means idea. The extension to general metric spaces is indicated briefly in section 4. The original point of departure for the work described here was a series of problems in optimal classification (MacQueen [9]) which represented special"
            },
            "slug": "Some-methods-for-classification-and-analysis-of-MacQueen",
            "title": {
                "fragments": [],
                "text": "Some methods for classification and analysis of multivariate observations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3235476"
                        ],
                        "name": "L. Hyafil",
                        "slug": "L.-Hyafil",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Hyafil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hyafil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113911099"
                        ],
                        "name": "R. Rivest",
                        "slug": "R.-Rivest",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rivest",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rivest"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Due to the inherent computational complexity of constructing optimal trees (i.e., trees having the minimal expected loss for their size) [ 37 ], [38], practical procedures for constructing trees are almost universally steepest-descent greedy procedures that \u201cgrow\u201d trees outward from the root."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27041365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b823846c6c8f1861424256467086ecec3fcd4693",
            "isKey": false,
            "numCitedBy": 1001,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Constructing-Optimal-Binary-Decision-Trees-is-Hyafil-Rivest",
            "title": {
                "fragments": [],
                "text": "Constructing Optimal Binary Decision Trees is NP-Complete"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Lett."
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2748598"
                        ],
                        "name": "S. Kullback",
                        "slug": "S.-Kullback",
                        "structuredName": {
                            "firstName": "Solomon",
                            "lastName": "Kullback",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kullback"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This corresponds exactly to Kullback\u2019s information divergence [ 50 ], when the log likelihood loss function is used (hence our use of the name \u201cdivergence\u201d)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "and the above arguments can be applied rigorously in this case [ 50 ], [60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 86412308,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "51739712c9b795f9533131122698cd5d01699f9d",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "information theory and statistics. Book lovers, when you need a new book to read, find the book here. Never worry not to find what you need. Is the information theory and statistics your needed book now? That's true; you are really a good reader. This is a perfect book that comes from great author to share with you. The book offers the best experience and lesson to take, not only take, but also learn."
            },
            "slug": "Information-Theory-and-Statistics-Kullback",
            "title": {
                "fragments": [],
                "text": "Information Theory and Statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145234927"
                        ],
                        "name": "A. Martelli",
                        "slug": "A.-Martelli",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Martelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Martelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690890"
                        ],
                        "name": "U. Montanari",
                        "slug": "U.-Montanari",
                        "structuredName": {
                            "firstName": "Ugo",
                            "lastName": "Montanari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Montanari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15617462,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "91e26e7251b2a53952a72860d54c11045e0c38dd",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Optimal decision table conversion has been tackled in the literature using two approaches, dynamic programming and branch-and-bound. The former technique is quite effective, but its time and space requirements are independent of how \u201ceasy\u201d the given table is. Furthermore, it cannot be used to produce good, quasioptimal solutions. The branch-and-bound technique uses a good heuristic to direct the search, but is cluttered up by an enormous search space, since the number of solutions increases with the number of test variables according to a double exponential. In this paper we suggest a heuristically guided top-down search algorithm which, like dynamic programming, recognizes identical subproblems but which can be used to find both optimal and quasioptimal solutions. The heuristic search method introduced in this paper combines the positive aspects of the above two techniques. Compressed tables with a large number of variables can be handled without deriving expanded tables first."
            },
            "slug": "Optimizing-decision-trees-through-heuristically-Martelli-Montanari",
            "title": {
                "fragments": [],
                "text": "Optimizing decision trees through heuristically guided search"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A heuristically guided top-down search algorithm which, like dynamic programming, recognizes identical subproblems but which can be used to find both optimal and quasioptimal solutions is suggested."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145634459"
                        ],
                        "name": "M. Garey",
                        "slug": "M.-Garey",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Garey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444582"
                        ],
                        "name": "David S. Johnson",
                        "slug": "David-S.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Due to the inherent computational complexity of constructing optimal trees (i.e., trees having the minimal expected loss for their size) [37], [ 38 ], practical procedures for constructing trees are almost universally steepest-descent greedy procedures that \u201cgrow\u201d trees outward from the root."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2211006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdede1e17c947540b50e6e2db9e8467ddc6e7336",
            "isKey": false,
            "numCitedBy": 47653,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Horn formulae play a prominent role in artificial intelligence and logic programming. In this paper we investigate the problem of optimal compression of propositional Horn production rule knowledge bases. The standard approach to this problem, consisting in the removal of redundant rules from a knowledge base, leads to an \"irredundant\" but not necessarily optimal knowledge base. We prove here that the number of rules in any irredundant Horn knowledge base involving n propositional variables is at most n 0 1 times the minimum possible number of rules. In order to formalize the optimal compression problem, we define a Boolean function of a knowledge base as being the function whose set of true points is the set of models of the knowledge base. In this way the optimal compression of production rule knowledge bases becomes a problem of Boolean function minimization. In this paper we prove that the minimization of Horn functions (i.e. Boolean functions associated to Horn knowledge bases) is..."
            },
            "slug": "Computers-and-Intractability:-A-Guide-to-the-Theory-Garey-Johnson",
            "title": {
                "fragments": [],
                "text": "Computers and Intractability: A Guide to the Theory of NP-Completeness"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This is the second edition of a quarterly column the purpose of which is to provide a continuing update to the list of problems (NP-complete and harder) presented by M. R. Garey and myself in the authors' book \u2018\u2018Computers and Intractability: A Guide to the Theory of NP-Completeness\u2019\u2019."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the two-bin case, if the nearest neighbor condition reduces to a hyperplane test, the number of partitions satisfying the necessary conditions for optimality is at most the number of linearly separable dichotomies of N points in A4 dimensions, or C(N, M). (A dichotomy of N points into two sets A0 and A1 is linearly separable if there exists a hyperplane separating points in A0 from points in A,.) Cover [ 52 ] has shown that"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18251470,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "445ad69010658097fc317f7b83f1198179eebae8",
            "isKey": false,
            "numCitedBy": 1840,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops the separating capacities of families of nonlinear decision surfaces by a direct application of a theorem in classical combinatorial geometry. It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes. Applying these ideas to the vertices of a binary n-cube yields bounds on the number of spherically, quadratically, and, in general, nonlinearly separable Boolean functions of n variables. It is shown that the set of all surfaces which separate a dichotomy of an infinite, random, separable set of pattern vectors can be characterized, on the average, by a subset of only 2d extreme pattern vectors. In addition, the problem of generalizing the classifications on a labeled set of pattern points to the classification of a new point is defined, and it is found that the probability of ambiguous generalization is large unless the number of training patterns exceeds the capacity of the set of separating surfaces."
            },
            "slug": "Geometrical-and-Statistical-Properties-of-Systems-Cover",
            "title": {
                "fragments": [],
                "text": "Geometrical and Statistical Properties of Systems of Linear Inequalities with Applications in Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48380723"
                        ],
                        "name": "Michael Montalbano",
                        "slug": "Michael-Montalbano",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Montalbano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Montalbano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46545455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d6ba62884c2f897867cf7d76001fc8a507da30c",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "There are, of course, many problems meriting further investigation: tables in their present form can become unwieldy when problem segments are prefaced by one or two simple decisions rather than six or seven complicated ones; it would sometimes be convenient to have rules in a table refer to other rules in the same table; rule identifiers in which the variable values are connected by (\u201cor\u201d rather than (\u201cand\u201d would sometimes be a convenience, and so on. Such further investigation would be desirable, since it would enhance the already considerable merit of tables as a means to implement program logic."
            },
            "slug": "Tables,-Flow-Charts-and-Program-Logic-Montalbano",
            "title": {
                "fragments": [],
                "text": "Tables, Flow Charts and Program Logic"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "There are, of course, many problems meriting further investigation: tables in their present form can become unwieldy when problem segments are prefaced by one or two simple decisions rather than six or seven complicated ones."
            },
            "venue": {
                "fragments": [],
                "text": "IBM Syst. J."
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826712"
                        ],
                        "name": "Lewis T. Reinwald",
                        "slug": "Lewis-T.-Reinwald",
                        "structuredName": {
                            "firstName": "Lewis",
                            "lastName": "Reinwald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lewis T. Reinwald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2178636"
                        ],
                        "name": "R. Soland",
                        "slug": "R.-Soland",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Soland",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Soland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17664149,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7945f6530a7597a5e79424ce6d8e1825c7a26795",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Given the number of words of computer storage required by the individual tests in a limited-entry decision table, it is sometimes desirable to find an equivalent computer program with minimum total storage requirement. In this paper an algorithm is developed to do this. The rules in the decision table are grouped into action sets, so that several rules with the same actions need not be distinguished. Moreover, if certain combinations of conditions can be excluded from consideration, the algorithm will take advantage of this extra information. The algorithm is initially developed for computer programs possessing a treelike form and then extended to a wider class of programs. The algorithm can be combined with one which finds an equivalent computer program with minimum average processing time, and thus used to find an equivalent computer program which minimizes a cost function which is nondecreasing in both average processing time and total storage requirement."
            },
            "slug": "Conversion-of-Limited-Entry-Decision-Tables-to-II:-Reinwald-Soland",
            "title": {
                "fragments": [],
                "text": "Conversion of Limited-Entry Decision Tables to Optimal Computer Programs II: minimum storage requirement"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The algorithm is initially developed for computer programs possessing a treelike form and then extended to a wider class of programs to find an equivalent computer program which minimizes a cost function which is nondecreasing in both average processing time and total storage requirement."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064923128"
                        ],
                        "name": "J. Markel",
                        "slug": "J.-Markel",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Markel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Markel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121743269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f35b697a119f626a5923115cd9bed44f72eab60",
            "isKey": false,
            "numCitedBy": 1456,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction.- 1.1 Basic Physical Principles.- 1.2 Acoustical Waveform Examples.- 1.3 Speech Analysis and Synthesis Models.- 1.4 The Linear Prediction Model.- 1.5 Organization of Book.- 2. Formulations.- 2.1 Historical Perspective.- 2.2 Maximum Likelihood.- 2.3 Minimum Variance.- 2.4 Prony's Method.- 2.5 Correlation Matching.- 2.6 PARCOR (Partial Correlation).- 2.6.1 Inner Products and an Orthogonality Principle.- 2.6.2 The PARCOR Lattice Structure.- 3. Solutions and Properties.- 3.1 Introduction.- 3.2 Vector Spaces and Inner Products.- 3.2.1 Filter or Polynomial Norms.- 3.2.2 Properties of Inner Products.- 3.2.3 Orthogonality Relations.- 3.3 Solution Algorithms.- 3.3.1 Correlation Matrix.- 3.3.2 Initialization.- 3.3.3 Gram-Schmidt Orthogonalization.- 3.3.4 Levinson Recursion.- 3.3.5 Updating Am(z).- 3.3.6 A Test Example.- 3.4 Matrix Forms.- 4. Acoustic Tube Modeling.- 4.1 Introduction.- 4.2 Acoustic Tube Derivation.- 4.2.1 Single Section Derivation.- 4.2.2 Continuity Conditions.- 4.2.3 Boundary Conditions.- 4.3 Relationship between Acoustic Tube and Linear Prediction.- 4.4 An Algorithm, Examples, and Evaluation.- 4.4.1 An Algorithm.- 4.4.2 Examples.- 4.4.3 Evaluation of the Procedure.- 4.5 Estimation of Lip Impedance.- 4.5.1 Lip Impedance Derivation.- 4.6 Further Topics.- 4.6.1 Losses in the Acoustic Tube Model.- 4.6.2 Acoustic Tube Stability.- 5. Speech Synthesis Structures.- 5.1 Introduction.- 5.2 Stability.- 5.2.1 Step-up Procedure.- 5.2.2 Step-down Procedure.- 5.2.3 Polynomial Properties.- 5.2.4 A Bound on |Fm(z)|.- 5.2.5 Necessary and Sufficient Stability Conditions.- 5.2.6 Application of Results.- 5.3 Recursive Parameter Evaluation.- 5.3.1 Inner Product Properties.- 5.3.2 Equation Summary with Program.- 5.4 A General Synthesis Structure.- 5.5 Specific Speech Synthesis Structures.- 5.5.1 The Direct Form.- 5.5.2 Two-Multiplier Lattice Model.- 5.5.3 Kelly-Lochbaum Model.- 5.5.4 One-Multiplier Models.- 5.5.5 Normalized Filter Model.- 5.5.6 A Test Example.- 6. Spectral Analysis.- 6.1 Introduction.- 6.2 Spectral Properties.- 6.2.1 Zero Mean All-Pole Model.- 6.2.2 Gain Factor for Spectral Matching.- 6.2.3 Limiting Spectral Match.- 6.2.4 Non-uniform Spectral Weighting.- 6.2.5 Minimax Spectral Matching.- 6.3 A Spectral Flatness Model.- 6.3.1 A Spectral Flatness Measure.- 6.3.2 Spectral Flatness Transformations.- 6.3.3 Numerical Evaluation.- 6.3.4 Experimental Results.- 6.3.5 Driving Function Models.- 6.4 Selective Linear Prediction.- 6.4.1 Selective Linear Prediction (SLP) Algorithm.- 6.4.2 A Selective Linear Prediction Program.- 6.4.3 Computational Considerations.- 6.5 Considerations in Choice of Analysis Conditions.- 6.5.1 Choice of Method.- 6.5.2 Sampling Rates.- 6.5.3 Order of Filter.- 6.5.4 Choice of Analysis Interval.- 6.5.5 Windowing.- 6.5.6 Pre-emphasis.- 6.6 Spectral Evaluation Techniques.- 6.7 Pole Enhancement.- 7. Automatic Formant Trajectory Estimation.- 7.1 Introduction.- 7.2 Formant Trajectory Estimation Procedure.- 7.2.1 Introduction.- 7.2.2 Raw Data from A(z).- 7.2.3 Examples of Raw Data.- 7.3 Comparison of Raw Data from Linear Prediction and Cepstral Smoothing.- 7.4 Algorithm 1.- 7.5 Algorithm 2.- 7.5.1 Definition of Anchor Points.- 7.5.2 Processing of Each Voiced Segment.- 7.5.3 Final Smoothing.- 7.5.4 Results and Discussion.- 7.6 Formant Estimation Accuracy.- 7.6.1 An Example of Synthetic Speech Analysis.- 7.6.2 An Example of Real Speech Analysis.- 7.6.3 Influence of Voice Periodicity.- 8. Fundamental Frequency Estimation.- 8.1 Introduction.- 8.2 Preprocessing by Spectral Flattening.- 8.2.1 Analysis of Voiced Speech with Spectral Regularity.- 8.2.2 Analysis of Voiced Speech with Spectral Irregularities.- 8.2.3 The STREAK Algorithm.- 8.3 Correlation Techniques.- 8.3.1 Autocorrelation Analysis.- 8.3.2 Modified Autocorrelation Analysis.- 8.3.3 Filtered Error Signal Autocorrelation Analysis.- 8.3.4 Practical Considerations.- 8.3.5 The SIFT Algorithm.- 9. Computational Considerations in Analysis.- 9.1 Introduction.- 9.2 Ill-Conditioning.- 9.2.1 A Measure of Ill-Conditioning.- 9.2.2 Pre-emphasis of Speech Data.- 9.2.3 Prefiltering before Sampling.- 9.3 Implementing Linear Prediction Analysis.- 9.3.1 Autocorrelation Method.- 9.3.2 Covariance Method.- 9.3.3 Computational Comparison.- 9.4 Finite Word Length Considerations.- 9.4.1 Finite Word Length Coefficient Computation.- 9.4.2 Finite Word Length Solution of Equations.- 9.4.3 Overall Finite Word Length Implementation.- 10. Vocoders.- 10.1 Introduction.- 10.2 Techniques.- 10.2.1 Coefficient Transformations.- 10.2.2 Encoding and Decoding.- 10.2.3 Variable Frame Rate Transmission.- 10.2.4 Excitation and Synthesis Gain Matching.- 10.2.5 A Linear Prediction Synthesizer Program.- 10.3 Low Bit Rate Pitch Excited Vocoders.- 10.3.1 Maximum Likelihood and PARCOR Vocoders.- 10.3.2 Autocorrelation Method Vocoders.- 10.3.3 Covariance Method Vocoders.- 10.4 Base-Band Excited Vocoders.- 11. Further Topics.- 11.1 Speaker Identification and Verification.- 11.2 Isolated Word Recognition.- 11.3 Acoustical Detection of Laryngeal Pathology.- 11.4 Pole-Zero Estimation.- 11.5 Summary and Future Directions.- References."
            },
            "slug": "Linear-Prediction-of-Speech-Markel-Gray",
            "title": {
                "fragments": [],
                "text": "Linear Prediction of Speech"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Speech Analysis and Synthesis Models: Basic Physical Principles, Speech Synthesis Structures, and Considerations in Choice of Analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Communication and Cybernetics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40586825"
                        ],
                        "name": "J. Egler",
                        "slug": "J.-Egler",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Egler",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Egler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31875664,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "1c32b9054983a7119794f0d763556518a39368db",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "human (or any other) judgment. The writers of monitor systems are generally very skilled programmers of high intelligence. If the monitor systems were as good as the persons writing them, there could be no complaint. But this is not the ease, and cannot be the ease. Instructions carried out big a machine obeying the commands of a monitor program are not and cannot be the equivalent of intelligent operation of the machine by the system designer who wrote the monitor. In all this talk of bigger, better and faster machines, let us not forget the fact tha t a machine is still just a dumb piece of hardware, obeying a list of specific and largely inflexible instructions. As long as this remains a fact, monitor systems had better remain discreet."
            },
            "slug": "A-procedure-for-converting-logic-table-conditions-Egler",
            "title": {
                "fragments": [],
                "text": "A procedure for converting logic table conditions into an efficient sequence of test instructions"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "In all this talk of bigger, better and faster machines, let us not forget the fact that a machine is still just a dumb piece of hardware, obeying a list of specific and largely inflexible instructions."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2233956"
                        ],
                        "name": "Y. Matsuyama",
                        "slug": "Y.-Matsuyama",
                        "structuredName": {
                            "firstName": "Yasuo",
                            "lastName": "Matsuyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Matsuyama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It turns out that this is easy to compute [ 62 ], [34]:"
                    },
                    "intents": []
                }
            ],
            "corpusId": 124419055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "508aaa8c28b538214b7cb76dfeb6cdb9994e664d",
            "isKey": false,
            "numCitedBy": 403,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Several properties, interrelations, and interpretations are developed for various speech spectral distortion measures. The principle results are 1) the development of notions of relative strength and equivalence of the various distortion measures both in a mathematical sense corresponding to subjective equivalence and in a coding sense when used in minimum distortion or nearest neighbor speech processing systems; 2) the demonstration that the Itakura-Saito and related distortion measures possess a property similar to the triangle inequality when used in nearest neighbor systems such as quantization and cluster analysis; and 3) that the Itakura-Saito and normalized model distortion measures yield efficient computation algorithms for generalized centroids or minimum distortion points of groups or clusters of speech frames, an important computation in both classical cluster analysis techniques and in algorithms for optimal quantizer design. We also argue that the Itakura-Saito and related distortions are well-suited computationally, mathematically, and intuitively for such applications."
            },
            "slug": "Distortion-measures-for-speech-processing-Gray-Buzo",
            "title": {
                "fragments": [],
                "text": "Distortion measures for speech processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that the Itakura-Saito and related distortions are well-suited computationally, mathematically, and intuitively for such applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144478790"
                        ],
                        "name": "D. Wong",
                        "slug": "D.-Wong",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62258903,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "9430a4fa1db5e942639be9f5225e72d04aa43d4d",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "An 800 bit/s vector quantization linear predictive coding (LPC) vocoder has been developed. The recently developed LPC vector quantization theory is applied to reduce the bit rate for LPC coefficients coding by a factor of four. Branch search techniques and separation of voiced and unvoiced codebooks are applied for better algorithm efficiency. Differential coding is applied to reduce the bit rate for the pitch and gain parameters by one third. Formal subjective evaluation shows that the 800 bit/s vocoder preserves most of the intelligibility of an LPC system. It is also robust under different transmission error and acoustic conditions. Informal listening comparisons show the quality to be acceptable and sometimes very close to 2400 bit/s LPC speech. The computational cost of the 800 bit/s vocoder is equivalent to or even lower than the 2400 bit/s LPC-10. Compatibility with any LPC-10 vocoder is guaranteed because the 800 bit/s design only differs in the quantization and encoding algorithms. Further bit rate reduction can be achieved by removing frame to frame redundancy in the code."
            },
            "slug": "An-800-bit/s-vector-quantization-LPC-vocoder-Wong-Juang",
            "title": {
                "fragments": [],
                "text": "An 800 bit/s vector quantization LPC vocoder"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An 800 bit/s vector quantization linear predictive coding (LPC) vocoder has been developed that preserves most of the intelligibility of an LPC system and compatibility with any LPC-10 vocoder is guaranteed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2720005"
                        ],
                        "name": "J. Markel",
                        "slug": "J.-Markel",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Markel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Markel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It turns out that this is easy to compute [62], [ 34 ]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Regression trees have also found applications in a number of areas, including least squares regression [32], [33], [7] and vector quantization [ 34 ] - [36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29755416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4de6f0516c24abf35941f88f522fa6221c6ccf8",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "With rare exception, all presently available narrow-band speech coding systems implement scalar quantization (independent quantization) of the transmission parameters (such as reflection coefficients or transformed reflection coefficients in LPC systems). This paper presents a new approach called vector quantization. For very low data rates, realistic experiments have shown that vector quantization can achieve a given level of average distortion with 15 to 20 fewer bits/frame than that required for the optimized scalar quantizing approaches presently in use. The vector quantizing approach is shown to be a mathematically and computationally tractable method which builds upon knowledge obtained in linear prediction analysis studies. This paper introduces the theory in a nonrigorous form, along with practical results to date and an extensive list of research topics for this new area of speech coding."
            },
            "slug": "Speech-coding-based-upon-vector-quantization-Buzo-Gray",
            "title": {
                "fragments": [],
                "text": "Speech coding based upon vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The vector quantizing approach is shown to be a mathematically and computationally tractable method which builds upon knowledge obtained in linear prediction analysis studies and is introduced in a nonrigorous form."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32741853"
                        ],
                        "name": "S. Kotz",
                        "slug": "S.-Kotz",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Kotz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kotz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145021112"
                        ],
                        "name": "C. Reid",
                        "slug": "C.-Reid",
                        "structuredName": {
                            "firstName": "Constance",
                            "lastName": "Reid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Reid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124880229,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "49f7da78646665072d12e1c74e16cdd62babb4c3",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neyman:-From-Life.-Kotz-Reid",
            "title": {
                "fragments": [],
                "text": "Neyman: From Life."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2140578338"
                        ],
                        "name": "E. Forgy",
                        "slug": "E.-Forgy",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Forgy",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Forgy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118110564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c4feeae0d911e30866b7149c1195cd8c007199b",
            "isKey": false,
            "numCitedBy": 2293,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cluster-analysis-of-multivariate-data-:-efficiency-Forgy",
            "title": {
                "fragments": [],
                "text": "Cluster analysis of multivariate data : efficiency versus interpretability of classifications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This corresponds exactly to Kullback\u2019s information divergence [ 50 ], when the log likelihood loss function is used (hence our use of the name \u201cdivergence\u201d)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "and the above arguments can be applied rigorously in this case [ 50 ], [60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 125523249,
            "fieldsOfStudy": [],
            "id": "11fbf06e4c1c4eddc91a68e434433a4fc5f7cfc4",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Theory and Statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40481777"
                        ],
                        "name": "E. Hunt",
                        "slug": "E.-Hunt",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Hunt",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hunt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49017920"
                        ],
                        "name": "J. Marin",
                        "slug": "J.-Marin",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Marin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Marin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14664289"
                        ],
                        "name": "P. Stone",
                        "slug": "P.-Stone",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Stone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56683335,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b329779f34e72ad8ffdad16102b0d97ab445c3b2",
            "isKey": false,
            "numCitedBy": 881,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experiments-in-induction-Hunt-Marin",
            "title": {
                "fragments": [],
                "text": "Experiments in induction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computationally, rather than looking at all the cases in our data set, we just look at the ones where A = a and B = b , and calculate as though that were all the data"
            },
            "venue": {
                "fragments": [],
                "text": "Computationally, rather than looking at all the cases in our data set, we just look at the ones where A = a and B = b , and calculate as though that were all the data"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Classification-and-Regression-Trees-Breiman-Friedman/8017699564136f93af21575810d557dba1ee6fc6?sort=total-citations"
}