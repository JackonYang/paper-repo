{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6219133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca1d23be869380ac9e900578c601c2d1febcc0c9",
            "isKey": false,
            "numCitedBy": 2373,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-\u201cindependent-components\u201d-of-natural-scenes-are-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "The \u201cindependent components\u201d of natural scenes are edge filters"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150165387"
                        ],
                        "name": "J. Urgen Schmidhuber",
                        "slug": "J.-Urgen-Schmidhuber",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Urgen Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Urgen Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 110
                            }
                        ],
                        "text": "It then turns out that the objective function VC isessentially equivalent to the following one (also given in Schmidhuber, 1992):Xi V AR(yi) Xi;p (P pi yi)2; (3)where yi denotes the mean activation of unit i, and VAR denotes the variance operator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 132
                            }
                        ],
                        "text": "The clue is: the code units are trained (in our experiments by online backprop) to maximize essentially the same objective function (Schmidhuber, 1992) the predictors try to minimize: VC =Xi;p (P p i yp i )2: (2) Predictors and code units co-evolve by ghting each other."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 103
                            }
                        ],
                        "text": "The simple approach in this paper is based on the recent principle of predictability minimization (PM) (Schmidhuber, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 103
                            }
                        ],
                        "text": "The simple approach in this paper is based on therecent principle of predictability minimization (PM) (Schmidhuber, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 132
                            }
                        ],
                        "text": "The clue is: the code units are trained (in our experiments by online backprop) to maximizeessentially the same objective function (Schmidhuber, 1992) the predictors try to minimize:VC =Xi;p (P pi ypi )2: (2)Predictors and code units co-evolve by ghting each other."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 151
                            }
                        ],
                        "text": "\u2026Corso Elvezia 366900 Lugano, SwitzerlandBernhard FoltinFakult at f ur InformatikTUM, 80290 M unchen, GermanyAbstractPredictability minimization (PM | Schmidhuber, 1992) exhibits various intuitive andtheoretical advantages over many other methods for unsupervised redundancy reduction."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2142508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "675d381653da0d2825ae37ab06069a1525fafb79",
            "isKey": true,
            "numCitedBy": 179,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "I propose a novel general principle for unsupervised learning of distributed non-redundant internal representations of input patterns. The principle is based on two opposing forces. For each represen-tational unit there is an adaptive predictor which tries to predict the unit from the remaining units. In turn, each unit tries to react to the environment such that it minimizes its predictability. This encourages each unit to lter\u00e0bstract concepts' out of the environmental input such that these concepts are statistically independent of those upon which the other units focus. I discuss various simple yet potentially powerful implementations of the principle which aim at nding binary factorial codes (Bar-low et al., 1989), i.e. codes where the probability of the occurrence of a particular input is simply the product of the probabilities of the corresponding code symbols. Such codes are potentially relevant for (1) segmentation tasks, (2) speeding up supervised learning, (3) novelty detection. Methods for nding factorial codes automatically implement Occam's razor for nding codes using a minimal number of units. Unlike previous methods the novel principle has a potential for removing not only linear but also non-linear output redundancy. Illustrative experiments show that algorithms based on the principle of predictability minimization are practically feasible. The nal part of this paper describes an entirely local algorithm that has a potential for learning unique representations of extended input sequences."
            },
            "slug": "Learning-Factorial-Codes-by-Predictability-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Learning Factorial Codes by Predictability Minimization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An entirely local algorithm is described that has a potential for learning unique representations of extended input sequences that are potentially relevant for segmentation tasks, speeding up supervised learning, and novelty detection."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2250837"
                        ],
                        "name": "C. Chubb",
                        "slug": "C.-Chubb",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Chubb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chubb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48462258"
                        ],
                        "name": "Zhong-Lin Lu",
                        "slug": "Zhong-Lin-Lu",
                        "structuredName": {
                            "firstName": "Zhong-Lin",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhong-Lin Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145251723"
                        ],
                        "name": "G. Sperling",
                        "slug": "G.-Sperling",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Sperling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sperling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 16952251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87176645e7cf3df264d6b595ef5991b6d563879a",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Structure-detection:-a-statistically-certified-Chubb-Lu",
            "title": {
                "fragments": [],
                "text": "Structure detection: a statistically certified unsupervised learning procedure"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51969664"
                        ],
                        "name": "Corso Elvezia",
                        "slug": "Corso-Elvezia",
                        "structuredName": {
                            "firstName": "Corso",
                            "lastName": "Elvezia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corso Elvezia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 86
                            }
                        ],
                        "text": "Redundancy reduction is widely regarded as an important goal of unsupervised learning (see, e.g., Barlow et al. 1989; Atick et al. 1992; Schmidhuber 1994; compare also Linsker 1988; Foldiak 1990; Deco and Obradovic 1996; Miller 1994; Field 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 50
                            }
                        ],
                        "text": "See e.g.(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F oldi ak,1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "Despite its potential advantages, PM has been tested on arti cial dataonly (Lindst adt, 1993; Schmidhuber, 1993, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18892811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02f9ed5c3bf9b26a2c92f8c71efdb7e43cb2b35f",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "The components of most real-world patterns contain redundant information. However, most pattern classiiers (e.g., statistical classiiers and neural nets) work better if pattern components are nonredundant. I present various unsupervised nonlinear predictor-based \\neural\" learning algorithms that transform patterns and pattern sequences into less redundant patterns without loss of information. The rst part of the paper shows how a neural predictor can be used to remove redundant information from input sequences. Experiments with artiicial sequences demonstrate that certain supervised classiication techniques can greatly beneet from this kind of unsupervised preprocessing. In the second part of the paper, a neural predictor is used to remove redundant information from natural text. With certain short newspaper articles, the neural method can achieve better compression ratios than the widely used asymptotically optimal Lempel-Ziv string compression algorithm. The third part of the paper shows how a system of co-evolving neural predictors and neural code generating modules can build factorial (statistically nonredundant) codes of pattern ensembles. The method is successfully applied to images of letters randomly presented according to the probabilities of English language."
            },
            "slug": "Neural-Predictors-for-Detecting-and-Removing-Elvezia",
            "title": {
                "fragments": [],
                "text": "Neural Predictors for Detecting and Removing Redundant Information"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Various unsupervised nonlinear predictor-based \"neural\" learning algorithms that transform patterns and pattern sequences into less redundant patterns without loss of information are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6999498"
                        ],
                        "name": "J. Rubner",
                        "slug": "J.-Rubner",
                        "structuredName": {
                            "firstName": "Jeanne",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144340430"
                        ],
                        "name": "K. Schulten",
                        "slug": "K.-Schulten",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Schulten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schulten"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 131
                            }
                        ],
                        "text": "See Figure 8 for an example.4 DISCUSSIONWe do not claim that PM is the only parallel method (as opposed to sequential methods, e.g.Rubner and Schulten, 1990) that can lead to well-known feature detectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 107
                            }
                        ],
                        "text": "Potential advantages of PM over other methods are: (1) Unlike certain inherently sequen-tial methods (e.g. Rubner and Schulten, 1990), PM can be implemented in a parallel way."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 31506754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48d91d9dfb5cd4037565524c081e8718b1eb65fc",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a two-layered network of linear neurons that organizes itself as to extract the complete information contained in a set of presented patterns. The weights between layers obey a Hebbian rule. We propose a local anti-Hebbian rule for lateral, hierarchically organized weights within the output layer. This rule forces the activities of the output units to become uncorrelated and the lateral weights to vanish. The weights between layers converge to the eigenvectors of the covariance matrix of input patterns, i.e., the network performs a principal component analysis, yielding all principal components. As a consequence of the proposed learning scheme, the output units become detectors of orthogonal features, similar to ones found in the brain of mammals."
            },
            "slug": "Development-of-feature-detectors-by-A-network-Rubner-Schulten",
            "title": {
                "fragments": [],
                "text": "Development of feature detectors by self-organization. A network model."
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A two-layered network of linear neurons that organizes itself as to extract the complete information contained in a set of presented patterns, and the output units become detectors of orthogonal features, similar to ones found in the brain of mammals."
            },
            "venue": {
                "fragments": [],
                "text": "Biological cybernetics"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577641"
                        ],
                        "name": "R. Linsker",
                        "slug": "R.-Linsker",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Linsker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Linsker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 84
                            }
                        ],
                        "text": "See e.g.(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F oldi ak,1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 41
                            }
                        ],
                        "text": ", 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F\u007f oldi ak, 1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1527671,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16d70e8af45ca0ae2c1bb73f3be6628518d40b8f",
            "isKey": false,
            "numCitedBy": 1417,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The emergence of a feature-analyzing function from the development rules of simple, multilayered networks is explored. It is shown that even a single developing cell of a layered network exhibits a remarkable set of optimization properties that are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representation in artificial intelligence, and information theory. The network studied is based on the visual system. These results are used to infer an information-theoretic principle that can be applied to the network as a whole, rather than a single cell. The organizing principle proposed is that the network connections develop in such a way as to maximize the amount of information that is preserved when signals are transformed at each processing stage, subject to certain constraints. The operation of this principle is illustrated for some simple cases.<<ETX>>"
            },
            "slug": "Self-organization-in-a-perceptual-network-Linsker",
            "title": {
                "fragments": [],
                "text": "Self-organization in a perceptual network"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "It is shown that even a single developing cell of a layered network exhibits a remarkable set of optimization properties that are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representation in artificial intelligence, and information theory."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758194"
                        ],
                        "name": "K. Miller",
                        "slug": "K.-Miller",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Miller",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10292734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8de5d975cbd5c1c18068408cddd036f903692ad",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Linsker has reported the development of center-surround receptive fields and oriented receptive fields in simulations of a Hebb-type equation in a linear network. The dynamics of the learning rule are analyzed in terms of the eigenvectors of the covariance matrix of cell activities. Analytic and computational results for Linsker's covariance matrices, and some general theorems, lead to an explanation of the emergence of center-surround and certain oriented structures. We estimate criteria for the parameter regime in which center-surround structures emerge."
            },
            "slug": "Analysis-of-Linsker's-Simulations-of-Hebbian-Rules-Mackay-Miller",
            "title": {
                "fragments": [],
                "text": "Analysis of Linsker's Simulations of Hebbian Rules"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Analytic and computational results for Linsker's covariance matrices, and some general theorems, lead to an explanation of the emergence of center-surround and certain oriented structures."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059566454"
                        ],
                        "name": "G. Deco",
                        "slug": "G.-Deco",
                        "structuredName": {
                            "firstName": "Gustavo",
                            "lastName": "Deco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Deco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687300"
                        ],
                        "name": "D. Obradovic",
                        "slug": "D.-Obradovic",
                        "structuredName": {
                            "firstName": "Dragan",
                            "lastName": "Obradovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Obradovic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 115
                            }
                        ],
                        "text": "See e.g.(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F oldi ak,1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 41
                            }
                        ],
                        "text": ", 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F\u007f oldi ak, 1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 35682003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "034f59dd5c0af2ced15aa1770bd4ac593cea273a",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 136,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nNeural networks provide a powerful new technology to model and control nonlinear and complex systems. In this book, the authors present a detailed formulation of neural networks from the information-theoretic viewpoint. They show how this perspective provides new insights into the design theory of neural networks. In particular, they show how these methods may be applied to the topics of supervised and unsupervised learning, including feature extraction, linear and nonlinear independent component analysis, and Boltzmann machines. Readers are assumed to have a basic understanding of neural networks, but all of the relevant concepts from information theory are carefully introduced and explained. Consequently, readers from several different scientific disciplines - notably, cognitive scientists, engineers, physicists, statisticians, and computer scientists - will find this book to be a very valuable contribution to this topic."
            },
            "slug": "An-Information-Theoretic-Approach-to-Neural-Deco-Obradovic",
            "title": {
                "fragments": [],
                "text": "An Information-Theoretic Approach to Neural Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This book presents a detailed formulation of neural networks from the information-theoretic viewpoint, and shows how these methods may be applied to the topics of supervised and unsupervised learning, including feature extraction, linear and nonlinear independent component analysis, and Boltzmann machines."
            },
            "venue": {
                "fragments": [],
                "text": "Perspectives in Neural Computing"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1650980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff1152582155acaa0e9d0ccbc900a4641504256d",
            "isKey": false,
            "numCitedBy": 1344,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of recent attempts have been made to describe early sensory coding in terms of a general information processing strategy. In this paper, two strategies are contrasted. Both strategies take advantage of the redundancy in the environment to produce more effective representations. The first is described as a compact coding scheme. A compact code performs a transform that allows the input to be represented with a reduced number of vectors (cells) with minimal RMS error. This approach has recently become popular in the neural network literature and is related to a process called Principal Components Analysis (PCA). A number of recent papers have suggested that the optimal compact code for representing natural scenes will have units with receptive field profiles much like those found in the retina and primary visual cortex. However, in this paper, it is proposed that compact coding schemes are insufficient to account for the receptive field properties of cells in the mammalian visual pathway. In contrast, it is proposed that the visual system is near to optimal in representing natural scenes only if optimality is defined in terms of sparse distributed coding. In a sparse distributed code, all cells in the code have an equal response probability across the class of images but have a low response probability for any single image. In such a code, the dimensionality is not reduced. Rather, the redundancy of the input is transformed into the redundancy of the firing pattern of cells. It is proposed that the signature for a sparse code is found in the fourth moment of the response distribution (i.e., the kurtosis). In measurements with 55 calibrated natural scenes, the kurtosis was found to peak when the bandwidths of the visual code matched those of cells in the mammalian visual cortex. Codes resembling wavelet transforms are proposed to be effective because the response histograms of such codes are sparse (i.e., show high kurtosis) when presented with natural scenes. It is proposed that the structure of the image that allows sparse coding is found in the phase spectrum of the image. It is suggested that natural scenes, to a first approximation, can be considered as a sum of self-similar local functions (the inverse of a wavelet). Possible reasons for why sensory systems would evolve toward sparse coding are presented."
            },
            "slug": "What-Is-the-Goal-of-Sensory-Coding-Field",
            "title": {
                "fragments": [],
                "text": "What Is the Goal of Sensory Coding?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proposed that compact coding schemes are insufficient to account for the receptive field properties of cells in the mammalian visual pathway and suggested that natural scenes, to a first approximation, can be considered as a sum of self-similar local functions (the inverse of a wavelet)."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6999498"
                        ],
                        "name": "J. Rubner",
                        "slug": "J.-Rubner",
                        "structuredName": {
                            "firstName": "Jeanne",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729696"
                        ],
                        "name": "P. Tavan",
                        "slug": "P.-Tavan",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Tavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tavan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121154409,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46674924177f7df6fbe06268d4fa95fb6cacf8f2",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a two-layered network of linear neurons that organizes itself in response to a set of presented patterns. After completion of the learning process, the net transforms the complete information contained in a pattern into mutually independent features. The synaptic weights between layers obey a Hebbian learning rule. We propose a local anti-Hebbian rule for lateral, hierarchically organized weights within the output layer. For a proper choice of the learning parameters, the rule forces the activities of the output units to becomes uncorrelated and the lateral weights to vanish. The weights between the two layers converge to the eigenvectors of the covariance matrix of input patterns, i.e. the network performs a principal-component analysis of the input information."
            },
            "slug": "A-self-organizing-network-for-principal-component-Rubner-Tavan",
            "title": {
                "fragments": [],
                "text": "A self-organizing network for principal-component analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A two-layered network of linear neurons that organizes itself in response to a set of presented patterns and proposes a local anti-Hebbian rule for lateral, hierarchically organized weights within the output layer."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683937"
                        ],
                        "name": "C. Zetzsche",
                        "slug": "C.-Zetzsche",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Zetzsche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Zetzsche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1839848"
                        ],
                        "name": "E. Barth",
                        "slug": "E.-Barth",
                        "structuredName": {
                            "firstName": "Erhardt",
                            "lastName": "Barth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Barth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145090451"
                        ],
                        "name": "G. Krieger",
                        "slug": "G.-Krieger",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Krieger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Krieger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708059"
                        ],
                        "name": "B. Wegmann",
                        "slug": "B.-Wegmann",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Wegmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Wegmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 25532277,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "fe0ed6cdc9519df5ed7a94e08333ba817b2fb587",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-network-models-and-the-visual-cortex:-the-Zetzsche-Barth",
            "title": {
                "fragments": [],
                "text": "Neural network models and the visual cortex: the missing link between orientation selectivity and the natural environment"
            },
            "venue": {
                "fragments": [],
                "text": "Neuroscience Letters"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577641"
                        ],
                        "name": "R. Linsker",
                        "slug": "R.-Linsker",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Linsker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Linsker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 162
                            }
                        ],
                        "text": "\u2026derivativesof determinants of covariance matrices, which is computationally expensive, and also biologicallyimplausible (the multiple cell approach presented in Linsker (1986b) does not have certain problemsof his later infomax approach, but it also does not have that nice theoretical foundation)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 81
                            }
                        ],
                        "text": "For instance, in caseof Gaussian input distributions, Linsker's linear approach (Linsker, 1986b; Linsker, 1986a) forsingle output units also generates certain kinds of orientation sensitive elds (see also MacKay andMiller, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7708166,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "f8fba8a2a6f1209f4e09cede01c8b2c64a656aea",
            "isKey": false,
            "numCitedBy": 377,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The functional architecture of mammalian visual cortex has been elucidated in impressive detail by experimental work of the past 20-25 years. The origin of many of the salient features of this architecture, however, has remained unexplained. This paper is the first of three (the others will appear in subsequent issues of these Proceedings) that address the origin and organization of feature-analyzing (spatial-opponent and orientation-selective) cells in simple systems governed by biologically plausible development rules. I analyze the progressive maturation of a system composed of a few layers of cells, with connections that develop according to a simple set of rules (including Hebb-type modification). To understand the prenatal origin of orientation-selective cells in certain primates, I consider the case in which there is no external input, with the first layer exhibiting random spontaneous electrical activity. No orientation preference is specified to the system at any stage, and none of the basic developmental rules is specific to visual processing. Here I introduce the theory of \"modular self-adaptive networks,\" of which this system is an example, and explicitly demonstrate the emergence of a layer of spatial-opponent cells. This sets the stage for the emergence, in succeeding layers, of an orientation-selective cell population."
            },
            "slug": "From-basic-network-principles-to-neural-emergence-Linsker",
            "title": {
                "fragments": [],
                "text": "From basic network principles to neural architecture: emergence of spatial-opponent cells."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper is the first of three that address the origin and organization of feature-analyzing cells in simple systems governed by biologically plausible development rules, and introduces the theory of \"modular self-adaptive networks,\" of which this system is an example, and explicitly demonstrates the emergence of a layer of spatial-opponent cells."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5062473"
                        ],
                        "name": "Zhaoping Li",
                        "slug": "Zhaoping-Li",
                        "structuredName": {
                            "firstName": "Zhaoping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaoping Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144513847"
                        ],
                        "name": "A. Redlich",
                        "slug": "A.-Redlich",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Redlich",
                            "middleNames": [
                                "Norman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Redlich"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 118
                            }
                        ],
                        "text": "SEMILINEAR PREDICTABILITY MINIMIZATIONPRODUCES WELL-KNOWN FEATURE DETECTORSNeural Computation, 1996 (accepted)J urgen Schmidhuber IDSIA, Corso Elvezia 366900 Lugano, Switzerland Martin EldracherIDSIA, Corso Elvezia 366900 Lugano, SwitzerlandBernhard FoltinFakult at f ur InformatikTUM, 80290 M\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 30
                            }
                        ],
                        "text": "See e.g.(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F oldi ak,1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8487334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bd9b030a5ef8071119fe237a6fa04e67e032ab8",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A previously proposed theory of visual processing, based on redundancy reduction, is used to derive the retinal transfer function including color. The predicted kernels show the nontrivial mixing of space-time with color coding observed in experiments. The differences in color-coding between species are found to be due to differences among the chromatic autocorrelators for natural scenes in different environments."
            },
            "slug": "Understanding-Retinal-Color-Coding-from-First-Atick-Li",
            "title": {
                "fragments": [],
                "text": "Understanding Retinal Color Coding from First Principles"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The predicted kernels show the nontrivial mixing of space-time with color coding observed in experiments, and differences in color-coding between species are found to be due to differences among the chromatic autocorrelators for natural scenes in different environments."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577641"
                        ],
                        "name": "R. Linsker",
                        "slug": "R.-Linsker",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Linsker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Linsker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 162
                            }
                        ],
                        "text": "\u2026derivativesof determinants of covariance matrices, which is computationally expensive, and also biologicallyimplausible (the multiple cell approach presented in Linsker (1986b) does not have certain problemsof his later infomax approach, but it also does not have that nice theoretical foundation)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 81
                            }
                        ],
                        "text": "For instance, in caseof Gaussian input distributions, Linsker's linear approach (Linsker, 1986b; Linsker, 1986a) forsingle output units also generates certain kinds of orientation sensitive elds (see also MacKay andMiller, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5175050,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "06f5a18780d7332ed68a9c786e1c597b27a8e0f6",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Orientation-selective cells--cells that are selectively responsive to bars and edges at particular orientations--are a salient feature of the architecture of mammalian visual cortex. In the previous paper of this series, I showed that such cells emerge spontaneously during the development of a simple multilayered network having local but initially random feedforward connections that mature, one layer at a time, according to a simple development rule (of Hebb type). In this paper, I show that, in the presence of lateral connections between developing orientation cells, these cells self-organize into banded patterns of cells of similar orientation. These patterns are similar to the \"orientation columns\" found in mammalian visual cortex. No orientation preference is specified to the system at any stage, none of the basic developmental rules is specific to visual processing, and the results emerge even in the absence of visual input to the system (as has been observed in macaque monkey)."
            },
            "slug": "From-basic-network-principles-to-neural-emergence-Linsker",
            "title": {
                "fragments": [],
                "text": "From basic network principles to neural architecture: emergence of orientation columns."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that, in the presence of lateral connections between developing orientation cells, these cells self-organize into banded patterns of cells of similar orientation, similar to the \"orientation columns\" found in mammalian visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577641"
                        ],
                        "name": "R. Linsker",
                        "slug": "R.-Linsker",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Linsker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Linsker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15600894,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "727690d076c9a73f77a6c5d863b40fdc14da0ba1",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This is the second paper in a series of three that explores the emergence of several prominent features of the functional architecture of visual cortex, in a \"modular self-adaptive network\" containing several layers of cells with parallel feedforward connections whose strengths develop according to a Hebb-type correlation-rewarding rule. In the present paper I show that orientation-selective cells, similar to the \"simple\" cortical cells of Hubel and Wiesel [Hubel, D. H. & Wiesel, T. N. (1962) J. Physiol. 160, 106-154], emerge in such a network. No orientation preference is specified to the system at any stage, the orientation-selective cell layer emerges even in the absence of environmental input to the system, and none of the basic developmental rules is specific to visual processing."
            },
            "slug": "From-basic-network-principles-to-neural-emergence-Linsker",
            "title": {
                "fragments": [],
                "text": "From basic network principles to neural architecture: emergence of orientation-selective cells."
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "It is shown that orientation-selective cells, similar to the \"simple\" cortical cells of Hubel and Wiesel, emerge in a \"modular self-adaptive network\" containing several layers of cells with parallel feedforward connections whose strengths develop according to a Hebb-type correlation-rewarding rule."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144246983"
                        ],
                        "name": "H. Barlow",
                        "slug": "H.-Barlow",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Barlow",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barlow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2315855"
                        ],
                        "name": "T. P. Kaushal",
                        "slug": "T.-P.-Kaushal",
                        "structuredName": {
                            "firstName": "Tej",
                            "lastName": "Kaushal",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. P. Kaushal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145666307"
                        ],
                        "name": "G. Mitchison",
                        "slug": "G.-Mitchison",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Mitchison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mitchison"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 163
                            }
                        ],
                        "text": "Its goal isto respond with informative but less redundant output patterns, ideally by creating a factorial(statistically nonredundant) code of the input ensemble (Barlow et al., 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 164
                            }
                        ],
                        "text": "Its goal is to respond with informative but less redundant output patterns, ideally by creating a factorial (statistically nonredundant) code of the input ensemble (Barlow et al., 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 9
                            }
                        ],
                        "text": "See e.g.(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F oldi ak,1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 0
                            }
                        ],
                        "text": "(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F\u007f oldi ak, 1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 28107770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5074f2219ddac70995f0a5e81ee2e892cb884b56",
            "isKey": true,
            "numCitedBy": 203,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "To determine whether a particular sensory event is a reliable predictor of reward or punishment it is necessary to know the prior probability of that event. If the variables of a sensory representation normally occur independently of each other, then it is possible to derive the prior probability of any logical function of the variables from the prior probabilities of the individual variables, without any additional knowledge; hence such a representation enormously enlarges the scope of definable events that can be searched for reliable predictors. Finding a Minimum Entropy Code is a possible method of forming such a representation, and methods for doing this are explored in this paper. The main results are (1) to show how to find such a code when the probabilities of the input states form a geometric progression, as is shown to be nearly true for keyboard characters in normal text; (2) to show how a Minimum Entropy Code can be approximated by repeatedly recoding pairs, triples, etc. of an original 7-bit code for keyboard characters; (3) to prove that in some cases enlarging the capacity of the output channel can lower the entropy."
            },
            "slug": "Finding-Minimum-Entropy-Codes-Barlow-Kaushal",
            "title": {
                "fragments": [],
                "text": "Finding Minimum Entropy Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Find a Minimum Entropy Code is a possible method of forming such a representation, and methods for doing this are explored, and the main results are to show how to find such a code when the probabilities of the input states form a geometric progression."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157288735"
                        ],
                        "name": "KD Miller",
                        "slug": "KD-Miller",
                        "structuredName": {
                            "firstName": "KD",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "KD Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 86
                            }
                        ],
                        "text": "Redundancy reduction is widely regarded as an important goal of unsupervised learning (see, e.g., Barlow et al. 1989; Atick et al. 1992; Schmidhuber 1994; compare also Linsker 1988; Foldiak 1990; Deco and Obradovic 1996; Miller 1994; Field 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 141
                            }
                        ],
                        "text": "See e.g.(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F oldi ak,1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 12
                            }
                        ],
                        "text": "tem (1990), Rubner and Tavan's system (19891, and Deco and Obradovic's system (1996) might come up with similar edge detectors when applied to real world images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15444045,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "a7b98f55482fd1b1b40456691859c79d4b7b7969",
            "isKey": false,
            "numCitedBy": 382,
            "numCiting": 162,
            "paperAbstract": {
                "fragments": [],
                "text": "Neurons in the primary visual cortex of higher mammals respond selectively to light/dark borders of a particular orientation. The receptive fields of simple cells, a type of orientation-selective cell, consist of adjacent, oriented regions alternately receiving ON-center and OFF-center excitatory input. I show that this segregation of inputs within receptive fields can occur through an activity-dependent competition between ON-center and OFF-center inputs, just as segregation of inputs between different postsynaptic cells into ocular dominance columns appears to occur through activity-dependent competition between left-eye and right-eye inputs. These different outcomes are proposed to result, not from different mechanisms, but from different spatial structures of the correlations in neural activity among the competing inputs in each case. Simple cells result if ON-center inputs are best correlated with other ON-center inputs, and OFF with OFF, at small retinotopic separations, but ON-center inputs are best correlated with OFF-center inputs at larger separations. This hypothesis leads robustly to development of simple cell receptive fields selective for orientation and spatial frequency, and to the continuous and periodic arrangement of preferred orientation across the cortex. Input correlations determine the mean preferred spatial frequency and degree of orientation selectivity. Estimates of these correlations based on measurements in adult cat retina (Mastronarde, 1983a,b) produce quantitative predictions for the mean preferred spatial frequencies of cat simple cells across eccentricities that agree with experiments (Movshon et al., 1978b). Intracortical interactions are the primary determinant of cortical organization. Simple cell spatial phases can play a key role in this organization, so arrangements of spatial phases and preferred orientations may need to be studied together to understand either alone. Possible origins for other cortical features including spatial frequency clusters, afferent ON/OFF segregation, blobs, pinwheels, and opponent inhibition within simple cell receptive fields are suggested. A number of strong experimental tests of the hypothesis are proposed."
            },
            "slug": "A-model-for-the-development-of-simple-cell-fields-Miller",
            "title": {
                "fragments": [],
                "text": "A model for the development of simple cell receptive fields and the ordered arrangement of orientation columns through activity-dependent competition between ON- and OFF-center inputs"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This hypothesis leads robustly to development of simple cell receptive fields selective for orientation and spatial frequency, and to the continuous and periodic arrangement of preferred orientation across the cortex."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Neural Computation, 4:559{572."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 630,
                                "start": 3
                            }
                        ],
                        "text": "PM has the following potential advantages over other methods: (1) Unlike certain inherently sequential methods (e.g., Rubner and Schulten 1YYO), PM can be implemented in a parallel way. (2) Unlike, e.g., with Barrow\u2019s model (1Y87), there may be iizaizy simultaneously active code units (multiple \u201dwinners\u201d instead of single \u201dwinners\u201d), as long as they represent rfiffermt aspects of the environment (distributed coding instead of local coding). (3) Unlike, e.g., with Linsker\u2019s INFOMAX (1988), there is no need to compute the derivatives of determinants of covariance matrices. (4) Unlike e.g., Deco and Obradovic\u2018s system (1996), Foldiaks system (19901, Rubner and Tavan\u2018s system (1989), and antiHebbian systems in general, PM requires neither time-consuming settling phases (due to recurrent connections) nor analytic computation of weight vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 10
                            }
                        ],
                        "text": "NeuvaI Computation 8, 773-786 (1996) @ 1996 Massachusetts Institute of Technology"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Comparison of two unsupervised neural network models for redundancyreduction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 32
                            }
                        ],
                        "text": "In case of multiple code units, however, to prevent different code units from representing the same information, Linsker\u2019s INFOMAX approach (1988) requires computing the derivatives of determinants of covariance matrices, which is computationally expensive and also biologically implausible [the multiple cell approach presented in Linsker (1986b) does not have certain problems of his later infomax approach, but it also does not have that nice theoretical foundation]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 493,
                                "start": 3
                            }
                        ],
                        "text": "PM has the following potential advantages over other methods: (1) Unlike certain inherently sequential methods (e.g., Rubner and Schulten 1YYO), PM can be implemented in a parallel way. (2) Unlike, e.g., with Barrow\u2019s model (1Y87), there may be iizaizy simultaneously active code units (multiple \u201dwinners\u201d instead of single \u201dwinners\u201d), as long as they represent rfiffermt aspects of the environment (distributed coding instead of local coding). (3) Unlike, e.g., with Linsker\u2019s INFOMAX (1988), there is no need to compute the derivatives of determinants of covariance matrices."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Neural Com-putation, 4(6):863{879."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "IEEE Computer, 21:105{117."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 19
                            }
                        ],
                        "text": "I t is noticeable that in Figure 6 there appears to be a smooth gradient of weight strengths from strongly positive to strongly iiegative as one inoves perpendicular to the positive/ negative border. This is different from, e.g., MacKay and Miller (1990), where all weights tend to zero at the edge of the receptive field."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Neural Computation, 1(3):412{423."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Neural Computation, 6:559{601."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "SEMILINEAR PREDICTABILITY MINIMIZATIONPRODUCES WELL-KNOWN FEATURE DETECTORSNeural Computation, 1996 (accepted)J urgen Schmidhuber IDSIA, Corso Elvezia 366900 Lugano, Switzerland Martin EldracherIDSIA, Corso Elvezia 366900 Lugano, SwitzerlandBernhard FoltinFakult at f ur InformatikTUM, 80290 M unchen, GermanyAbstractPredictability minimization (PM | Schmidhuber, 1992) exhibits various intuitive andtheoretical advantages over many other methods for unsupervised redundancy reduction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Neural Computation, 2:173{187."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning receptive fields"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. I E E E 1st Annu . Conf. Neural Deco, G., and Obradovic, L. 1996. An Information-Theoretic Approach lo Neural Field, D. J. 1994. What is the goal of sensory coding? Neural Coinp., 6, 559-601. Foldiak,"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48965924"
                        ],
                        "name": "Stefanie N. Lindstaedt",
                        "slug": "Stefanie-N.-Lindstaedt",
                        "structuredName": {
                            "firstName": "Stefanie",
                            "lastName": "Lindstaedt",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefanie N. Lindstaedt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 77
                            }
                        ],
                        "text": "Despite its potential advantages, PM has been tested on artificial data only (Lindstadt 1993; Schmidhuber 1993, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 201873020,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "b1562255f01904f35e1a89bc632f213a4b3c33ae",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Comparison-of-two-Unsupervised-Neural-Network-for-Lindstaedt",
            "title": {
                "fragments": [],
                "text": "Comparison of two Unsupervised Neural Network Models for Redundancy Reduction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055652029"
                        ],
                        "name": "J\u00fcrgen Schmidhuber",
                        "slug": "J\u00fcrgen-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J\u00fcrgen Schmidhuber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 141
                            }
                        ],
                        "text": "Theequivalence of (2) and (3) was observed by Peter Dayan, Richard Zemel and Alex Pouget (personalcommunication, SALK Institute, 1992 | see (Schmidhuber, 1993) for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 142
                            }
                        ],
                        "text": "The equivalence of (2) and (3) was observed by Peter Dayan, Richard Zemel and Alex Pouget (personal communication, SALK Institute, 1992 | see (Schmidhuber, 1993) for details)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "Despite its potential advantages, PM has been tested on arti cial dataonly (Lindst adt, 1993; Schmidhuber, 1993, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 196113676,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4a9af3c0418bceef7e057db0f08fdfeab4cdff5",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Netzwerkarchitekturen,-Zielfunktionen-und-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Netzwerkarchitekturen, Zielfunktionen und Kettenregel"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A self-organization network for principal-component analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Europhysics Letters"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 86
                            }
                        ],
                        "text": "Redundancy reduction is widely regarded as an important goal of unsupervised learning (see, e.g., Barlow et al. 1989; Atick et al. 1992; Schmidhuber 1994; compare also Linsker 1988; Foldiak 1990; Deco and Obradovic 1996; Miller 1994; Field 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 30
                            }
                        ],
                        "text": "See e.g.(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F oldi ak,1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Understanding retinal color coding Barlow, H"
            },
            "venue": {
                "fragments": [],
                "text": "B., Kaushal, T. P., and Mitchison, G. J. 1989. Finding minimum Barrow,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning receptive elds"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the IEEE 1st Annual Conference"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A self-organization network for principalcomponent analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Europlzys. Lett"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 30
                            }
                        ],
                        "text": "See e.g.(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F oldi ak,1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 0
                            }
                        ],
                        "text": "(Barlow et al., 1989; Atick et al., 1992; Schmidhuber, 1994); compare also (Linsker, 1988; F\u007f oldi ak, 1990; Deco and Obradovic, 1996; Miller, 1994; Field, 1994)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Understanding retinal color coding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 141
                            }
                        ],
                        "text": "Theequivalence of (2) and (3) was observed by Peter Dayan, Richard Zemel and Alex Pouget (personalcommunication, SALK Institute, 1992 | see (Schmidhuber, 1993) for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "Despite its potential advantages, PM has been tested on arti cial dataonly (Lindst adt, 1993; Schmidhuber, 1993, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Netzwerkarchitekturen, Zielfunktionen und Ketten"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Semilinear-Predictability-Minimization-Produces-Schmidhuber-Eldracher/6bf2479e607ff547012b54dab3f35dc01613ef86?sort=total-citations"
}