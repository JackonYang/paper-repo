{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121534"
                        ],
                        "name": "J. Heel",
                        "slug": "J.-Heel",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Heel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Heel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Previous work involving explicitly model-based motion estimation includes direct methods [17, 21], [ 13 ] as well as methods for estimation under restricted conditions [7, 9]. The first class of methods uses a global egomotion constraint while those in the second class of methods rely on parametric motion models within local regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4506115,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "ad4abf104f8ff605f16819172bf57ec844bd2094",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for the estimation of scene structure and camera motion from a sequence of images. This approach is fundamentally new. No computation of optical flow or feature correspondences is required. The method processes image sequences of arbitrary length and exploits the redundancy for a significant reduction in error over time. No assumptions are made about camera motion or surface structure. Both quantities are fully recovered. Our method combines the ``direct'''' motion vision approach with the theory of recursive estimation. Each step is illustrated and evaluated with results from real images."
            },
            "slug": "Direct-Estimation-of-Structure-and-Motion-from-Heel",
            "title": {
                "fragments": [],
                "text": "Direct Estimation of Structure and Motion from Multiple Frames"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3315356"
                        ],
                        "name": "K. Hanna",
                        "slug": "K.-Hanna",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Hanna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hanna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "More experimental results and a detailed discussion of the algorithm's performance on various types of scenes can be found in [ 12 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hanna [ 12 ] provides further details and results, and also describes how the local and global models interact at corner-like and edge-like image structures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 86862810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "396ffa315a2944832c7c2f8a58e909b77afb841d",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes an iterative algorithm that estimates the motion of a camera through an environment directly from brightness derivatives of an image pair. A global ego-motion constraint is combined with the local brightness constancy constraint to relate local surface models with the global ego-motion model and local brightness derivatives. In an iterative process, the author first refines the local surface models using the ego-motion as a constraint, and then refines the ego-motion model using the local surface models as constraints. He performs this analysis at multiple resolutions. He shows how information from local corner-like and edge-like image structures contribute to the refinement of the global ego-motion estimate, and how the ego-motion constraint can help resolve local motion ambiguities that arise from the aperture problem. Results of the algorithm are shown on uncalibrated outdoor image sequences, and also on a computer-rendered image sequence.<<ETX>>"
            },
            "slug": "Direct-multi-resolution-estimation-of-ego-motion-Hanna",
            "title": {
                "fragments": [],
                "text": "Direct multi-resolution estimation of ego-motion and structure from motion"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An iterative algorithm that estimates the motion of a camera through an environment directly from brightness derivatives of an image pair and how the ego-motion constraint can help resolve local motion ambiguities that arise from the aperture problem is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Workshop on Visual Motion"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080797"
                        ],
                        "name": "J. Dengler",
                        "slug": "J.-Dengler",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Dengler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dengler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The former facilitates direct local estimation [18, 20], whereas the latter model requires iterative relaxation techniques [16] It is also not uncommon to use the combination of these two types of local models (e.g., [3,  10 ])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hierarchical approaches have been used by various researchers e.g., see [2,  10 , 11, 22, 19])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118769990,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "bd6ea03a9e135f649ab327ead3ccfa9e42feda99",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The Dynamic Pyramid is a tool for analyzing monocular moving image sequences. Its process for achieving correspondence between successive frames is based on the physical model of the elastic membrane, where the cost function consisting of the similarity between the frames and the deformation of the transformation vector field is minimized."
            },
            "slug": "Local-motion-estimation-with-the-dynamic-pyramid-Dengler",
            "title": {
                "fragments": [],
                "text": "Local motion estimation with the dynamic pyramid"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The Dynamic Pyramid is a tool for analyzing monocular moving image sequences based on the physical model of the elastic membrane, where the cost function consisting of the similarity between the frames and the deformation of the transformation vector field is minimized."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190675"
                        ],
                        "name": "Gilad Adiv",
                        "slug": "Gilad-Adiv",
                        "structuredName": {
                            "firstName": "Gilad",
                            "lastName": "Adiv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilad Adiv"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18974396,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3733124d9fedd380e7e0c6b82eef9f2db3344fc3",
            "isKey": false,
            "numCitedBy": 899,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A new approach for the interpretation of optical flow fields is presented. The flow field, which can be produced by a sensor moving through an environment with several independently moving, rigid objects, is allowed to be sparse, noisy, and partially incorrect. The approach is based on two main stages. In the first stage, the flow field is partitioned into connected segments of flow vectors, where each segment is consistent with a rigid motion of a roughly planar surface. In the second stage, segments are grouped under the hypothesis that they are induced by a single, rigidly moving object. Each hypothesis is tested by searching for three-dimensional (3-D) motion parameters which are compatible with all the segments in the corresponding group. Once the motion parameters are recovered, the relative environmental depth can be estimated as well. Experiments based on real and simulated data are presented."
            },
            "slug": "Determining-Three-Dimensional-Motion-and-Structure-Adiv",
            "title": {
                "fragments": [],
                "text": "Determining Three-Dimensional Motion and Structure from Optical Flow Generated by Several Moving Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A new approach for the interpretation of optical flow fields is presented, where the flow field is partitioned into connected segments of flow vectors, where each segment is consistent with a rigid motion of a roughly planar surface."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117775627"
                        ],
                        "name": "Ajit Singh",
                        "slug": "Ajit-Singh",
                        "structuredName": {
                            "firstName": "Ajit",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ajit Singh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Hierarchical approaches have been used by various researchers e.g., see [2, 10, 11,  22 , 19])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2037306,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "92a073390876de93e6ab7192c70f4446a743e151",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel framework for computing image flow from time-varying imagery is described. This framework offers the following principal advantages. First, it allows estimation of certain types of discontinuous flow fields without any prior knowledge about the location of discontinuities. The flow fields thus recovered are not blurred at motion boundaries. Second, covariance matrices (or alternatively, confidence measures) are associated with the estimate of image flow at each stage of computation. The estimation-theoretic nature of the framework and its ability to provide covariance matrices make it very useful in the context of applications such as incremental estimation of scene-depth using techniques based on Kalman filtering. The framework is used to recover image flow from two image sequences. To illustrate an application, the image-flow estimates and their covariance matrices thus obtained are also used to recover scene depth.<<ETX>>"
            },
            "slug": "An-estimation-theoretic-framework-for-image-flow-Singh",
            "title": {
                "fragments": [],
                "text": "An estimation-theoretic framework for image-flow computation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The estimation-theoretic nature of the framework and its ability to provide covariance matrices make it very useful in the context of applications such as incremental estimation of scene-depth using techniques based on Kalman filtering."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116003860"
                        ],
                        "name": "J. Bergen",
                        "slug": "J.-Bergen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055557"
                        ],
                        "name": "R. Hingorani",
                        "slug": "R.-Hingorani",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Hingorani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hingorani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144406261"
                        ],
                        "name": "Shmuel Peleg",
                        "slug": "Shmuel-Peleg",
                        "structuredName": {
                            "firstName": "Shmuel",
                            "lastName": "Peleg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shmuel Peleg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[8] and the advantages of using parametric models within such a framework have also been discussed in [ 5 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "With only a few exceptions ([ 5 , 9]), much of this work has concentrated on using a small family of \"generic\" motion models within the hierarchical estimation framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37070313,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "252813d2601e072e3792ee75fc3f1cbd11462bcf",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A fundamental assumption made in formulating optical-flow algorithms is that motion at any point in any image can be represented as a single pattern undergoing a simple translation: even complex motion will appear as a uniform displacement when viewed through a sufficiently small window. This assumption fails in a number of common situations. The authors propose an alternative formulation in which there may be two distinct patterns undergoing coherent motion within a given local analysis region. They then present an algorithm for the analysis of two-component motion. They also demonstrate that the algorithm provides precise motion estimates for a set of elementary two-motion configurations, and show that it is robust in the presence of noise.<<ETX>>"
            },
            "slug": "Computing-two-motions-from-three-frames-Bergen-Burt",
            "title": {
                "fragments": [],
                "text": "Computing two motions from three frames"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The authors propose an alternative formulation of optical-flow algorithms in which there may be two distinct patterns undergoing coherent motion within a given local analysis region, and present an algorithm for the analysis of two-component motion."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116003860"
                        ],
                        "name": "J. Bergen",
                        "slug": "J.-Bergen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055557"
                        ],
                        "name": "R. Hingorani",
                        "slug": "R.-Hingorani",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Hingorani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hingorani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3102157"
                        ],
                        "name": "R. Kolczynski",
                        "slug": "R.-Kolczynski",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Kolczynski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kolczynski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120269072"
                        ],
                        "name": "W.A. Lee",
                        "slug": "W.A.-Lee",
                        "structuredName": {
                            "firstName": "W.A.",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W.A. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079117486"
                        ],
                        "name": "A. Leung",
                        "slug": "A.-Leung",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Leung",
                            "middleNames": [
                                "Po"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39102803"
                        ],
                        "name": "J. Lubin",
                        "slug": "J.-Lubin",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Lubin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lubin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70032864"
                        ],
                        "name": "H. Shvayster",
                        "slug": "H.-Shvayster",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Shvayster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shvayster"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60698311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "566d312680433125e37b2be0348fba94a985378a",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe the implementation of the local and focal levels of a dynamic-motion-analysis framework. Dynamic motion analysis achieves efficiency through sequential decomposition of a complex analysis task into simpler tasks, by 'peeling off complexity', and by directing analysis to portions of a scene that are most critical to the vision task. The authors describe four basic techniques for implementing dynamic analysis: foveation, two-stage motion computation, tracking, and one-component-at-a-time segmentation. Each process entails several iterations of a basic operation but convergence is fast and the computations themselves can be relatively crude. By way of illustration, the dynamic motion analysis technique was applied to a number of image sequences. Particular attention is given to an actual video sequence of a helicopter flying over a terrain. The sequence was obtained from a camera moving relative to the helicopter. It is concluded that the dynamic approach to motion analysis holds the promise of performing real-time processing to obtain precise, robust results, using practical hardware.<<ETX>>"
            },
            "slug": "Object-tracking-with-a-moving-camera-Burt-Bergen",
            "title": {
                "fragments": [],
                "text": "Object tracking with a moving camera"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The authors describe the implementation of the local and focal levels of a dynamic-motion-analysis framework and concludes that the dynamic approach to motion analysis holds the promise of performing real-time processing to obtain precise, robust results, using practical hardware."
            },
            "venue": {
                "fragments": [],
                "text": "[1989] Proceedings. Workshop on Visual Motion"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055557"
                        ],
                        "name": "R. Hingorani",
                        "slug": "R.-Hingorani",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Hingorani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hingorani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3102157"
                        ],
                        "name": "R. Kolczynski",
                        "slug": "R.-Kolczynski",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Kolczynski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kolczynski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 8 ] and the advantages of using parametric models within such a framework have also been discussed in [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122831257,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f787532b046767f9efa200401adb7158c16f45d7",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Pyramid techniques are commonly used to provide computational efficiency in the analysis of image motion. But these techniques can play an even more important role in the analysis of multiple motion, where, for example, a transparent pattern moves in front of a differently moving background pattern. The pyramid framework then separates motion components based on their spatial and temporal frequency characteristics so that each can be estimated independently of the others. This property is key to recently proposed selective stabilization algorithms for the sequential analysis of multiple motion and for the detection of moving objects from a moving platform. The authors determine the conditions for component selection. Results can provide important guidance in practical applications of motion analysis.<<ETX>>"
            },
            "slug": "Mechanisms-for-isolating-component-patterns-in-the-Burt-Hingorani",
            "title": {
                "fragments": [],
                "text": "Mechanisms for isolating component patterns in the sequential analysis of multiple motion"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Workshop on Visual Motion"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270435"
                        ],
                        "name": "J. Eklundh",
                        "slug": "J.-Eklundh",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Eklundh",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eklundh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "With only a few exceptions ([5,  9 ]), much of this work has concentrated on using a small family of \"generic\" motion models within the hierarchical estimation framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Previous work involving explicitly model-based motion estimation includes direct methods [17, 21], [13] as well as methods for estimation under restricted conditions [7,  9 ]. The first class of methods uses a global egomotion constraint while those in the second class of methods rely on parametric motion models within local regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5180290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb6bd5234f217403caaf54e5ef7edb3127378aaa",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "When a visual observer moves forward, the projections of the objects in the scene will move over the visual image. If an object extends vertically from the ground, its image will move differently from the immediate background. This difference is called motion parallax [1, 2]. Much work in automatic visual navigation and obstacle detection has been concerned with computing motion fields or more or less complete 3-D information about the scene [3\u20135]. These approaches, in general, assume a very unconstrained environment and motion. If the environment is constrained, for example, motion occurs on a planar road, then this information can be exploited to give more direct solutions to, for example, obstacle detection [6]. Figure 6.1 shows superposed the images from two successive times for an observer translating relative to a planar road. The arrows show the displacement field, that is, the transformation of the image points between the successive time points."
            },
            "slug": "Object-detection-using-model-based-prediction-and-Carlsson-Eklundh",
            "title": {
                "fragments": [],
                "text": "Object detection using model based prediction and motion parallax"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work superposed the images from two successive times for an observer translating relative to a planar road and showed the displacement field, that is, the transformation of the image points between the successive time points."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697964"
                        ],
                        "name": "S. Negahdaripour",
                        "slug": "S.-Negahdaripour",
                        "structuredName": {
                            "firstName": "Shahriar",
                            "lastName": "Negahdaripour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Negahdaripour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143814637"
                        ],
                        "name": "Berthold K. P. Horn",
                        "slug": "Berthold-K.-P.-Horn",
                        "structuredName": {
                            "firstName": "Berthold",
                            "lastName": "Horn",
                            "middleNames": [
                                "K.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthold K. P. Horn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The problem of estimating planar surface motion has been has been extensively studied before [ 21 , 1, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In particular, Negahdaripour and Horn [ 21 ] suggest iterative methods for estimating the motion and the surface parameters, as well as a method of estimating the 8 parameters and then decomposing them into the five rigid motion parameters the three surface parameters in closed form."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Previous work involving explicitly model-based motion estimation includes direct methods [17,  21 ], [13] as well as methods for estimation under restricted conditions [7, 9]. The first class of methods uses a global egomotion constraint while those in the second class of methods rely on parametric motion models within local regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1379898,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "11df9e9c7020f9df38e03bca2b3bddfa6c8e0ada",
            "isKey": true,
            "numCitedBy": 284,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this correspondence, we show how to recover the motion of an observer relative to a planar surface from image brightness derivatives. We do not compute the optical flow as an intermediate step, only the spatial and temporal brightness gradients (at a minimum of eight points). We first present two iterative schemes for solving nine nonlinear equations in terms of the motion and surface parameters that are derived from a least-squares fomulation. An initial pass over the relevant image region is used to accumulate a number of moments of the image brightness derivatives. All of the quantities used in the iteration are efficiently computed from these totals without the need to refer back to the image. We then show that either of two possible solutions can be obtained in closed form. We first solve a linear matrix equation for the elements of a 3 \u00d7 3 matrix. The eigenvalue decomposition of the symmetric part of the matrix is then used to compute the motion parameters and the plane orientation. A new compact notation allows us to show easily that there are at most two planar solutions."
            },
            "slug": "Direct-Passive-Navigation-Negahdaripour-Horn",
            "title": {
                "fragments": [],
                "text": "Direct Passive Navigation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This correspondence presents two iterative schemes for solving nine nonlinear equations in terms of the motion and surface parameters that are derived from a least-squares fomulation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2038179"
                        ],
                        "name": "A. Waxman",
                        "slug": "A.-Waxman",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Waxman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waxman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7505678"
                        ],
                        "name": "K. Wohn",
                        "slug": "K.-Wohn",
                        "structuredName": {
                            "firstName": "Kwangyoen",
                            "lastName": "Wohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Wohn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119046582,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4c20b1add2454602ac41044ff0760559769867ab",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In the kinematic analysis of time-varying imagery, where the goal is to recover object surface structure and space motion from image flow, an appropriate representation for the flow field consists of a set of deformation parameters that describe the rate of change of an image neighborhood. In this paper we develop methods for extracting these deformation param eters from evolving contours in an image sequence, the image contours being manifestations of surface texture seen in perspective projection. Our results follow directly from the analytic structure of the underlying image flow; no heuristics are imposed. The deformation parameters we seek are actu ally linear combinations of the Taylor series coefficients (through second derivatives) of the local image flow field. Thus, a by-product of our approach is a second-order polyno mial approximation to the image flow in the neighborhood of a contour. For curved surfaces this approximation is only locally valid, but for planar surfaces it is globally valid (i.e., it is exact). Our analysis reveals an \"aperture problem in the large\" in which insufficient contour structure leaves the set of 12 deformation parameters underdetermined. We also assess the sensitivity of our method to the simulated effects of noise in the \"normal flow\" around contours as well as the angular field of view subtended by contours. The sensitivity analysis is carried out in the context of planar surfaces executing general rigid-body motions in space. Future work will address the additional considerations relevant to curved surface patches."
            },
            "slug": "Contour-Evolution,-Neighborhood-Deformation,-and-in-Waxman-Wohn",
            "title": {
                "fragments": [],
                "text": "Contour Evolution, Neighborhood Deformation, and Global Image Flow: Planar Surfaces in Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Methods for extracting deformation parameters from evolving contours in an image sequence, the image contours being manifestations of surface texture seen in perspective projection, and a second-order polyno mial approximation to the image flow in the neighborhood of a contour are developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717435"
                        ],
                        "name": "B. G. Schunck",
                        "slug": "B.-G.-Schunck",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Schunck",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. G. Schunck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 81902,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "7173228b2c4b98bcc8447768d925c91c55116de2",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Image flow is the velocity field in the image plane caused by the motion of the observer, objects in the scene, or apparent motion, and can contain discontinuities due to object occlusion in the scene. An algorithm that can estimate the image flow velocity field when there are discontinuities due to occlusions is described. The constraint line clustering algorithm uses a statistical test to estimate the image flow velocity field in the presence of step discontinuities in the image irradiance or velocity field. Particular emphasis is placed on motion estimation and segmentation in situations such as random dot patterns where motion is the only cue to segmentation. Experimental results on a demanding synthetic test case and a real image are presented. A smoothing algorithm for improving the velocity field estimate is also described. The smoothing algorithm constructs a smooth estimate of the velocity field by approximating a surface between step discontinuities. It is noted that the velocity field estimate can be improved using surface reconstruction between velocity field boundaries. >"
            },
            "slug": "Image-Flow-Segmentation-and-Estimation-by-Line-Schunck",
            "title": {
                "fragments": [],
                "text": "Image Flow Segmentation and Estimation by Constraint Line Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The constraint line clustering algorithm uses a statistical test to estimate the image flow velocity field in the presence of step discontinuities in the image irradiance or velocity field, with particular emphasis on motion estimation and segmentation in situations where motion is the only cue to segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2677311"
                        ],
                        "name": "W. Enkelmann",
                        "slug": "W.-Enkelmann",
                        "structuredName": {
                            "firstName": "Wilfried",
                            "lastName": "Enkelmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Enkelmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2461604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36161ff10beeaf8bc2edb585d91dc1dad31bda80",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Investigations-of-multigrid-algorithms-for-the-of-Enkelmann",
            "title": {
                "fragments": [],
                "text": "Investigations of multigrid algorithms for the estimation of optical flow fields in image sequences"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The former facilitates direct local estimation [18,  20 ], whereas the latter model requires iterative relaxation techniques [16] It is also not uncommon to use the combination of these two types of local models (e.g., [3, 10])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In many cases, however, this assumption is not expressed explicitly as such, rather it is presented as a regularization term in an objective function [14, 16] or described primarily as a computational issue [18, 4, 2,  20 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28394904,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f52207ea03f4e7ce52e9fbbdfc3c909f6c17e9c1",
            "isKey": false,
            "numCitedBy": 521,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Displacement-vectors-derived-from-second-order-in-Nagel",
            "title": {
                "fragments": [],
                "text": "Displacement vectors derived from second-order intensity variations in image sequences"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143814637"
                        ],
                        "name": "Berthold K. P. Horn",
                        "slug": "Berthold-K.-P.-Horn",
                        "structuredName": {
                            "firstName": "Berthold",
                            "lastName": "Horn",
                            "middleNames": [
                                "K.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthold K. P. Horn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34995520,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "a0d00264c3f5616a9c8f00ca70d0864a31a38cf2",
            "isKey": false,
            "numCitedBy": 2258,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book presents a coherent approach to the fast-moving field of computer vision, using a consistent notation based on a detailed understanding of the image formation process. It covers even the most recent research and will provide a useful and current reference for professionals working in the fields of machine vision, image processing, and pattern recognition. \nAn outgrowth of the author's course at MIT, Robot Vision presents a solid framework for understanding existing work and planning future research. Its coverage includes a great deal of material that is important to engineers applying machine vision methods in the real world. The chapters on binary image processing, for example, help explain and suggest how to improve the many commercial devices now available. And the material on photometric stereo and the extended Gaussian image points the way to what may be the next thrust in commercialization of the results in this area. \nChapters in the first part of the book emphasize the development of simple symbolic descriptions from images, while the remaining chapters deal with methods that exploit these descriptions. The final chapter offers a detailed description of how to integrate a vision system into an overall robotics system, in this case one designed to pick parts out of a bin. \nThe many exercises complement and extend the material in the text, and an extensive bibliography will serve as a useful guide to current research. \nErrata (164k PDF)"
            },
            "slug": "Robot-vision-Horn",
            "title": {
                "fragments": [],
                "text": "Robot vision"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This book presents a coherent approach to the fast-moving field of computer vision, using a consistent notation based on a detailed understanding of the image formation process, and will provide a useful and current reference for professionals working in the fields of machine vision, image processing, and pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "MIT electrical engineering and computer science series"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143814637"
                        ],
                        "name": "Berthold K. P. Horn",
                        "slug": "Berthold-K.-P.-Horn",
                        "structuredName": {
                            "firstName": "Berthold",
                            "lastName": "Horn",
                            "middleNames": [
                                "K.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthold K. P. Horn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717435"
                        ],
                        "name": "B. G. Schunck",
                        "slug": "B.-G.-Schunck",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Schunck",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. G. Schunck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1371968,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a3229dc33ecb80c59a75b906c46b586dd059b781",
            "isKey": false,
            "numCitedBy": 11344,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical flow cannot be computed locally, since only one independent measurement is available from the image sequence at a point, while the flow velocity has two components. A second constraint is needed. A method for finding the optical flow pattern is presented which assumes that the apparent velocity of the brightness pattern varies smoothly almost everywhere in the image. An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences. The algorithm is robust in that it can handle image sequences that are quantized rather coarsely in space and time. It is also insensitive to quantization of brightness levels and additive noise. Examples are included where the assumption of smoothness is violated at singular points or along lines in the image."
            },
            "slug": "Determining-Optical-Flow-Horn-Schunck",
            "title": {
                "fragments": [],
                "text": "Determining Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences and is robust in that it can handle image sequences that are quantified rather coarsely in space and time."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31857045"
                        ],
                        "name": "E. Hildreth",
                        "slug": "E.-Hildreth",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Hildreth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hildreth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In many cases, however, this assumption is not expressed explicitly as such, rather it is presented as a regularization term in an objective function [ 14 , 16] or described primarily as a computational issue [18, 4, 2, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62198913,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "c416a885cc36515740ef8dfa9220366fa2a379f8",
            "isKey": false,
            "numCitedBy": 660,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nComputer scientists designing machine vision systems, psychologists working in visual perception, visual neurophysiologists, and theoretical biologists will derive a deeper understanding of visual function - in particular the computations that the human visual system uses to analyze motion-from the important research reported in this book. \nThe organization of movement in the changing image that reaches the eye provides our visual system with a valuable source of information for analyzing the structure of our surroundings. This book examines the measurement of this movement and the use of relative movement to locate the boundaries of physical objects in the environment. It investigates the nature of the computations that are necessary to perform this analysis by any vision system, biological or artificial. \nThe author first defines the goals of these visual tasks, reveals the properties of the physical world that a vision system can rely upon to achieve such goals, and suggests general methods that can be used to carry out the tasks. From the general methods, she designs algorithms specifying a particular sequence of computations that a vision system can execute to perform these visual tasks. These algorithms are implemented on a computer system under a variety of circumstances. Combined with the traditional approaches of psychology and neurophysiology, this computational approach provides an exciting analysis of visual function, raising many new questions about the human vision system for further investigation. \nEllen Catherine Hildreth received her doctorate from MIT. She is a Research Scientist in the MIT Artificial Intelligence Laboratory and associate director of theCenter for Biological Information Processing at the Whitaker College of Health Sciences, Technology, and Management. The Measurement of Visual Motion is an ACM Distinguished Dissertation."
            },
            "slug": "Measurement-of-Visual-Motion-Hildreth",
            "title": {
                "fragments": [],
                "text": "Measurement of Visual Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Combined with the traditional approaches of psychology and neurophysiology, this computational approach provides an exciting analysis of visual function, raising many new questions about the human vision system for further investigation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588702"
                        ],
                        "name": "B. D. Lucas",
                        "slug": "B.-D.-Lucas",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lucas",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The former facilitates direct local estimation [ 18 , 20], whereas the latter model requires iterative relaxation techniques [16] It is also not uncommon to use the combination of these two types of local models (e.g., [3, 10])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In many cases, however, this assumption is not expressed explicitly as such, rather it is presented as a regularization term in an objective function [14, 16] or described primarily as a computational issue [ 18 , 4, 2, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This is the same model as used by Lucas and Kanade [ 18 ] but here it is embedded as a local model within the hierarchical estimation framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2121536,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "isKey": true,
            "numCitedBy": 13329,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system."
            },
            "slug": "An-Iterative-Image-Registration-Technique-with-an-Lucas-Kanade",
            "title": {
                "fragments": [],
                "text": "An Iterative Image Registration Technique with an Application to Stereo Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration, and can be generalized to handle rotation, scaling and shearing."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our implementation uses the Laplacian pyramid described in [ 6 ], which involves simple local computations and provides the necessary spatial-frequency decomposition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This image (or images) must be propagated via a pyramid expansion operation as described in [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8018433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83074157d165b6245915508d891b2d0cd066f3ad",
            "isKey": false,
            "numCitedBy": 6693,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a technique for image encoding in which local operators of many scales but identical shape serve as the basis functions. The representation differs from established techniques in that the code elements are localized in spatial frequency as well as in space. Pixel-to-pixel correlations are first removed by subtracting a lowpass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance and entropy, and the low-pass filtered image may represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the low-pass image. Iteration of the process at appropriately expanded scales generates a pyramid data structure. The encoding process is equivalent to sampling the image with Laplacian operators of many scales. Thus, the code tends to enhance salient image features. A further advantage of the present code is that it is well suited for many image analysis tasks as well as for image compression. Fast algorithms are described for coding and decoding."
            },
            "slug": "The-Laplacian-Pyramid-as-a-Compact-Image-Code-Burt-Adelson",
            "title": {
                "fragments": [],
                "text": "The Laplacian Pyramid as a Compact Image Code"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A technique for image encoding in which local operators of many scales but identical shape serve as the basis functions, which tends to enhance salient image features and is well suited for many image analysis tasks as well as for image compression."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717329"
                        ],
                        "name": "V. Cantoni",
                        "slug": "V.-Cantoni",
                        "structuredName": {
                            "firstName": "Virginio",
                            "lastName": "Cantoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cantoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990702"
                        ],
                        "name": "S. Levialdi",
                        "slug": "S.-Levialdi",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Levialdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levialdi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29282208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c33529c14a78783fe9aeb1035be2e0cc76421b03",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 145,
            "paperAbstract": {
                "fragments": [],
                "text": "This book presents papers on image processing using supercomputers and array processors. Topics considered include parallel processing, computer architecture, performance, data-flow processing, algorithms, computer vision, pattern recognition, equipment interfaces, programming languages, silicon implementation on multiprocessor pyramid architecture, and fault-tolerance techniques in arrays for image processing."
            },
            "slug": "Pyramidal-Systems-for-Computer-Vision-Cantoni-Levialdi",
            "title": {
                "fragments": [],
                "text": "Pyramidal Systems for Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This book presents papers on image processing using supercomputers and array processors that include parallel processing, computer architecture, performance, data-flow processing, algorithms, computer vision, pattern recognition, equipment interfaces, programming languages, silicon implementation on multiprocessor pyramid architecture, and fault-tolerance techniques in arrays for image processing."
            },
            "venue": {
                "fragments": [],
                "text": "NATO ASI Series"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Displacement vectors derived from second order intensity variations in intensity sequences. computer vision, Pattern reognition and Image Ptocessing"
            },
            "venue": {
                "fragments": [],
                "text": "Displacement vectors derived from second order intensity variations in intensity sequences. computer vision, Pattern reognition and Image Ptocessing"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Direct methods for recovering motionAo 'it\"r.tive image registration technique with an application to stereo vision"
            },
            "venue": {
                "fragments": [],
                "text": "Image {Jnderstsnding Workshop"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Messureme,nt o! visual Motion' The MIT Press"
            },
            "venue": {
                "fragments": [],
                "text": "B.K.P.Ilorn.RobotVision,.MITPress"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SzensKl' ar depth from image-sequences"
            },
            "venue": {
                "fragments": [],
                "text": "rn International conference on computer vision"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 24,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Hierarchical-Model-Based-Motion-Estimation-Bergen-Anandan/404f3544a7db67c38ba3b8f78f02759d2326684e?sort=total-citations"
}