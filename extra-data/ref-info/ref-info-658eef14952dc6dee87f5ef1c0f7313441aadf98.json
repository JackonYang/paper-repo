{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057440295"
                        ],
                        "name": "Sebastian Schreiber",
                        "slug": "Sebastian-Schreiber",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Schreiber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Schreiber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582412"
                        ],
                        "name": "S. Agne",
                        "slug": "S.-Agne",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Agne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144651288"
                        ],
                        "name": "I. Wolf",
                        "slug": "I.-Wolf",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734717217"
                        ],
                        "name": "Sheraz Ahmed",
                        "slug": "Sheraz-Ahmed",
                        "structuredName": {
                            "firstName": "Sheraz",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sheraz Ahmed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "We reimplemented the DeepDeSRT table structure model [6] and trained it on the same private data as our proposed model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "We did so by reimplementing the DeepDeSRT model [6] and training on the same data as our proposed model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 184
                            }
                        ],
                        "text": "However, we were unable to obtain reasonable performance, even after exploring a variety of values for post processing thresholds and training hyperparameters (values not specified in [6])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "The Deep DeSRT model [6] uses a neural network originally designed for semantic segmentation of natural scenes and thus primarily uses local information to classify pixels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "The DeepDeSRT [6] learning model formulates table structure extraction as two independent pixel labeling tasks to respectively segment row objects and segment column objects."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "Recently, deep learning has been proposed to learn table structure directly from images [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [6], better results were obtained when resizing the initial input to make the separator regions bigger."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 188
                            }
                        ],
                        "text": "We were unable to find any official implementations of prior works, so for comparison, we use the commercial software system Acrobat Pro DC and our reimplementation of the DeepDeSRT model [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 448,
                                "start": 439
                            }
                        ],
                        "text": "Category Method F-measure Recall Precision PDF Input Image Input\nProposed Models\nSplit 86.79 86.64 86.93 Split-PDF 91.63 91.26 92.00 SPLERGE-PDF 90.89 90.44 91.36 SPLERGE-PDF + Heuristics 91.95 91.46 92.45\nSplit + Heuristics 93.00 92.24 93.78 Split-PDF + Heuristics 95.26 94.64 95.89\nPreviously Reported Results\nNurminen [3] 94.60 94.09 95.12 TEXUS [4] 82.59 84.23 81.02 Shigarov [5] C1 91.50 91.21 91.80 Shigarov [5] C2 93.64 92.33 94.99 DeepDeSRT [6] 91.44\u2020 87.36\u2020 95.93\u2020\n\u2020 result not directly comparable due to evaluation on a random subset of 34 tables."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10191334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8bead3ae810cd3f7427d3004e45b4158da9b744",
            "isKey": true,
            "numCitedBy": 158,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel end-to-end system for table understanding in document images called DeepDeSRT. In particular, the contribution of DeepDeSRT is two-fold. First, it presents a deep learning-based solution for table detection in document images. Secondly, it proposes a novel deep learning-based approach for table structure recognition, i.e. identifying rows, columns, and cell positions in the detected tables. In contrast to existing rule-based methods, which rely on heuristics or additional PDF metadata (like, for example, print instructions, character bounding boxes, or line segments), the presented system is data-driven and does not need any heuristics or metadata to detect as well as to recognize tabular structures in document images. Furthermore, in contrast to most existing table detection and structure recognition methods, which are applicable only to PDFs, DeepDeSRT processes document images, which makes it equally suitable for born-digital PDFs (as they can automatically be converted into images) as well as even harder problems, e.g. scanned documents. To gauge the performance of DeepDeSRT, the system is evaluated on the publicly available ICDAR 2013 table competition dataset containing 67 documents with 238 pages overall. Evaluation results reveal that DeepDeSRT outperforms state-of-the-art methods for table detection and structure recognition and achieves F1-measures of 96.77% and 91.44% for table detection and structure recognition, respectively. Additionally, DeepDeSRT is evaluated on a closed dataset from a real use case of a major European aviation company comprising documents which are highly unlike those in ICDAR 2013. Tested on a randomly selected sample from this dataset, DeepDeSRT achieves high detection accuracy for tables which demonstrates the sound generalization capabilities of our system."
            },
            "slug": "DeepDeSRT:-Deep-Learning-for-Detection-and-of-in-Schreiber-Agne",
            "title": {
                "fragments": [],
                "text": "DeepDeSRT: Deep Learning for Detection and Structure Recognition of Tables in Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In contrast to most existing table detection and structure recognition methods, which are applicable only to PDFs, DeepDeSRT processes document images, which makes it equally suitable for born-digital PDFs as well as even harder problems, e.g. scanned documents."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782282"
                        ],
                        "name": "Evan Shelhamer",
                        "slug": "Evan-Shelhamer",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Shelhamer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Shelhamer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117314646"
                        ],
                        "name": "Jonathan Long",
                        "slug": "Jonathan-Long",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "It finetunes the FCN-2s model [7] that has been pretrained on the PASCAL VOC semantic segmentation challenge [8] for natural scenes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1629541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "317aee7fc081f2b137a85c4f20129007fd8e717e",
            "isKey": false,
            "numCitedBy": 15652,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image."
            },
            "slug": "Fully-Convolutional-Networks-for-Semantic-Shelhamer-Long",
            "title": {
                "fragments": [],
                "text": "Fully Convolutional Networks for Semantic Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that convolutional networks by themselves, trained end- to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047516905"
                        ],
                        "name": "Max C. G\u00f6bel",
                        "slug": "Max-C.-G\u00f6bel",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "G\u00f6bel",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max C. G\u00f6bel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "18592170"
                        ],
                        "name": "Tamir Hassan",
                        "slug": "Tamir-Hassan",
                        "structuredName": {
                            "firstName": "Tamir",
                            "lastName": "Hassan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamir Hassan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759801"
                        ],
                        "name": "Ermelinda Oro",
                        "slug": "Ermelinda-Oro",
                        "structuredName": {
                            "firstName": "Ermelinda",
                            "lastName": "Oro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ermelinda Oro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35203250"
                        ],
                        "name": "G. Orsi",
                        "slug": "G.-Orsi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Orsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orsi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Many previous works that extract table structure are rule based systems that analyze PDF drawing commands [2]\u2013[5], i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "The ICDAR 2013 Table Competition [2] compared many systems for table structure recognition, including the current state-of-the-art method by Nurminen [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "We tested SPLERGE on two datasets, including the ICDAR 2013 Table Competition benchmark dataset [2], where we achieve state-of-the-art results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Following [2], reported precision and recall are computed per-table and then averaged."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Lined tables are generally easier than unlined tables [2] because they have explicit visual cues that delimit cells, columns, and rows."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 44
                            }
                        ],
                        "text": "Table I shows the results on the ICDAR 2013 Table Competition dataset (task 2)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 58
                            }
                        ],
                        "text": "We achieve state-of-the-art performance on the ICDAR 2013 Table Competition dataset [2], obtaining an adjacency relationship F-measure of 95.15% compared to the best published result of 94.6% [2]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "We achieve state-of-the-art performance on the ICDAR 2013 Table Competition dataset [2], obtaining an adjacency relationship F-measure of 95."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 50
                            }
                        ],
                        "text": "When evaluating the split model on the ICDAR 2013 Table Competition dataset, we achieve state-of-the-art performance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206777311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cbc1582175b5c03b8203ec38bb25bae9d66397d",
            "isKey": true,
            "numCitedBy": 120,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Table understanding is a well studied problem in document analysis, and many academic and commercial approaches have been developed to recognize tables in several document formats, including plain text, scanned page images and born-digital, object-based formats such as PDF. Despite the abundance of these techniques, an objective comparison of their performance is still missing. The Table Competition held in the context of ICDAR 2013 is our first attempt at objectively evaluating these techniques against each other in a standardized way, across several input formats. The competition independently addresses three problems: (i) table location, (ii) table structure recognition, and (iii) these two tasks combined. We received results from seven academic systems, which we have also compared against four commercial products. This paper presents our findings."
            },
            "slug": "ICDAR-2013-Table-Competition-G\u00f6bel-Hassan",
            "title": {
                "fragments": [],
                "text": "ICDAR 2013 Table Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The Table Competition held in the context of ICDAR 2013 is the first attempt at objectively evaluating these techniques against each other in a standardized way, across several input formats."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807197"
                        ],
                        "name": "F. Yu",
                        "slug": "F.-Yu",
                        "structuredName": {
                            "firstName": "Fisher",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145231047"
                        ],
                        "name": "V. Koltun",
                        "slug": "V.-Koltun",
                        "structuredName": {
                            "firstName": "Vladlen",
                            "lastName": "Koltun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Koltun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "The SFCN is composed of 3 convolution layers with 7x7 kernels, with the last layer performing a dilated convolution [11] with a dilation factor of 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17127188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f5fc84819c0cf94b771fe15141f65b123f7b8ec",
            "isKey": false,
            "numCitedBy": 5425,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction and image classification are structurally different. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy."
            },
            "slug": "Multi-Scale-Context-Aggregation-by-Dilated-Yu-Koltun",
            "title": {
                "fragments": [],
                "text": "Multi-Scale Context Aggregation by Dilated Convolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work develops a new convolutional network module that is specifically designed for dense prediction, and shows that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797981"
                        ],
                        "name": "Shih-En Wei",
                        "slug": "Shih-En-Wei",
                        "structuredName": {
                            "firstName": "Shih-En",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-En Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20569810"
                        ],
                        "name": "V. Ramakrishna",
                        "slug": "V.-Ramakrishna",
                        "structuredName": {
                            "firstName": "Varun",
                            "lastName": "Ramakrishna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ramakrishna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774867"
                        ],
                        "name": "Yaser Sheikh",
                        "slug": "Yaser-Sheikh",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Sheikh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaser Sheikh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 163946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "864e7db59f2ccfec1ee9f6eba79566ac7b0634df",
            "isKey": false,
            "numCitedBy": 2019,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Pose Machines provide a sequential prediction framework for learning rich implicit spatial models. In this work we show a systematic design for how convolutional networks can be incorporated into the pose machine framework for learning image features and image-dependent spatial models for the task of pose estimation. The contribution of this paper is to implicitly model long-range dependencies between variables in structured prediction tasks such as articulated pose estimation. We achieve this by designing a sequential architecture composed of convolutional networks that directly operate on belief maps from previous stages, producing increasingly refined estimates for part locations, without the need for explicit graphical model-style inference. Our approach addresses the characteristic difficulty of vanishing gradients during training by providing a natural learning objective function that enforces intermediate supervision, thereby replenishing back-propagated gradients and conditioning the learning procedure. We demonstrate state-of-the-art performance and outperform competing methods on standard benchmarks including the MPII, LSP, and FLIC datasets."
            },
            "slug": "Convolutional-Pose-Machines-Wei-Ramakrishna",
            "title": {
                "fragments": [],
                "text": "Convolutional Pose Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work designs a sequential architecture composed of convolutional networks that directly operate on belief maps from previous stages, producing increasingly refined estimates for part locations, without the need for explicit graphical model-style inference in structured prediction tasks such as articulated pose estimation."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3355714"
                        ],
                        "name": "A. Shigarov",
                        "slug": "A.-Shigarov",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Shigarov",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shigarov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144116982"
                        ],
                        "name": "A. Mikhailov",
                        "slug": "A.-Mikhailov",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Mikhailov",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mikhailov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90059384"
                        ],
                        "name": "A. Altaev",
                        "slug": "A.-Altaev",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Altaev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Altaev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5] later proposed a simpler set of heuristics based on bottomup merging of PDF components."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "Many previous works that extract table structure are rule based systems that analyze PDF drawing commands [2]\u2013[5], i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15800424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53a69f1de96a66f0a1b335dfa34895c6d3792354",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Today, PDF is one of the most popular document formats in the web. Many PDF documents are not images, but remain untagged. They have no tags for identifying the logical reading order, paragraphs, figures, and tables. One of the challenges with these documents is how to extract tables from them. The paper discusses a new system for table structure recognition in untagged PDF documents. It is formulated as a set of configurable parameters and ad-hoc heuristics for recovering table cells. We consider two different configurations for the system and demonstrate experimental results based on the existing competition dataset for both of them."
            },
            "slug": "Configurable-Table-Structure-Recognition-in-PDF-Shigarov-Mikhailov",
            "title": {
                "fragments": [],
                "text": "Configurable Table Structure Recognition in Untagged PDF documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new system for table structure recognition in untagged PDF documents is discussed, formulated as a set of configurable parameters and ad-hoc heuristics for recovering table cells."
            },
            "venue": {
                "fragments": [],
                "text": "DocEng"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2207074"
                        ],
                        "name": "S. Clinchant",
                        "slug": "S.-Clinchant",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Clinchant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clinchant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131960"
                        ],
                        "name": "Herv\u00e9 D\u00e9jean",
                        "slug": "Herv\u00e9-D\u00e9jean",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "D\u00e9jean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Herv\u00e9 D\u00e9jean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066113788"
                        ],
                        "name": "J. Meunier",
                        "slug": "J.-Meunier",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Meunier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Meunier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059294500"
                        ],
                        "name": "E. Lang",
                        "slug": "E.-Lang",
                        "structuredName": {
                            "firstName": "Eva",
                            "lastName": "Lang",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Lang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729636"
                        ],
                        "name": "Florian Kleber",
                        "slug": "Florian-Kleber",
                        "structuredName": {
                            "firstName": "Florian",
                            "lastName": "Kleber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florian Kleber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] compare two learning models on scanned images of seventeeth century handwritten tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49407309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e652226d2f58435d97de6899bb347e0e39de310a",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present in this paper experiments on Table Recognition in hand-written register books. We first explain how the problem of row and column detection is modelled, and then compare two Machine Learning approaches (Conditional Random Field and Graph Convolutional Network) for detecting these table elements. Evaluation was conducted on death records provided by the Archives of the Diocese of Passau. With an F-1 score of 89, both methods provide a quality which allows for Information Extraction. Software and dataset are open source/data."
            },
            "slug": "Comparing-Machine-Learning-Approaches-for-Table-in-Clinchant-D\u00e9jean",
            "title": {
                "fragments": [],
                "text": "Comparing Machine Learning Approaches for Table Recognition in Historical Register Books"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper first explains how the problem of row and column detection is modelled, and then compares two Machine Learning approaches (Conditional Random Field and Graph Convolutional Network) for detecting these table elements."
            },
            "venue": {
                "fragments": [],
                "text": "2018 13th IAPR International Workshop on Document Analysis Systems (DAS)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Several factors complicate table structure parsing (see [1] for an overview)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16106027,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "9e16dcd290d9ab780107270c666d71c00e569b22",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The principle that for every document analysis task there exists a mechanism for creating well-defined ground-truth is a widely held tenet. Past experience with standard datasets providing ground-truth for character recognition and page segmentation tasks supports this belief. In the process of attempting to evaluate several table recognition algorithms we have been developing, however, we have uncovered a number of serious hurdles connected with the ground-truthing of tables. This problem may, in fact, be much more difficult than it appears. We present a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "slug": "Why-table-ground-truthing-is-hard-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Why table ground-truthing is hard"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3101288"
                        ],
                        "name": "Qiongkai Xu",
                        "slug": "Qiongkai-Xu",
                        "structuredName": {
                            "firstName": "Qiongkai",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiongkai Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117944850"
                        ],
                        "name": "Qing Wang",
                        "slug": "Qing-Wang",
                        "structuredName": {
                            "firstName": "Qing",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qing Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49770180"
                        ],
                        "name": "Chenchen Xu",
                        "slug": "Chenchen-Xu",
                        "structuredName": {
                            "firstName": "Chenchen",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chenchen Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14564042"
                        ],
                        "name": "Lizhen Qu",
                        "slug": "Lizhen-Qu",
                        "structuredName": {
                            "firstName": "Lizhen",
                            "lastName": "Qu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lizhen Qu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 135
                            }
                        ],
                        "text": "To recover table rows, they use either a Conditional Random\nField (CRF) or their proposed Edge Convolutional Networks, an extension of Graph Convolutional Networks [10]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "To recover table rows, they use either a Conditional Random Field (CRF) or their proposed Edge Convolutional Networks, an extension of Graph Convolutional Networks [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16481868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a5dbd65e539082eeb8a56af64ef36266d1603b1",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Collective classification of vertices is a task of assigning categories to each vertex in a graph based on both vertex attributes and link structure. Nevertheless, some existing approaches do not use the features of neighbouring vertices properly, due to the noise introduced by these features. In this paper, we propose a graph-based recursive neural network framework for collective vertex classification. In this framework, we generate hidden representations from both attributes of vertices and representations of neighbouring vertices via recursive neural networks. Under this framework, we explore two types of recursive neural units, naive recursive neural unit and long short-term memory unit. We have conducted experiments on four real-world network datasets. The experimental results show that our frame- work with long short-term memory model achieves better results and outperforms several competitive baseline methods."
            },
            "slug": "Collective-Vertex-Classification-Using-Recursive-Xu-Wang",
            "title": {
                "fragments": [],
                "text": "Collective Vertex Classification Using Recursive Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "In this paper, a graph-based recursive neural network framework for collective vertex classification is proposed, which generates hidden representations from both attributes of vertices and representations of neighbouring vertices via recursive neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047516905"
                        ],
                        "name": "Max C. G\u00f6bel",
                        "slug": "Max-C.-G\u00f6bel",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "G\u00f6bel",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max C. G\u00f6bel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "18592170"
                        ],
                        "name": "Tamir Hassan",
                        "slug": "Tamir-Hassan",
                        "structuredName": {
                            "firstName": "Tamir",
                            "lastName": "Hassan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamir Hassan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759801"
                        ],
                        "name": "Ermelinda Oro",
                        "slug": "Ermelinda-Oro",
                        "structuredName": {
                            "firstName": "Ermelinda",
                            "lastName": "Oro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ermelinda Oro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35203250"
                        ],
                        "name": "G. Orsi",
                        "slug": "G.-Orsi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Orsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orsi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "The evaluation metric for this dataset is the F-measure over detected adjacency relationships [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3223096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f79cfbecadb5c7cce7618ea4cff65f5e941f8951",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a methodology for the evaluation of table understanding algorithms for PDF documents. The evaluation takes into account three major tasks: table detection, table structure recognition and functional analysis. We provide a general and flexible output model for each task along with corresponding evaluation metrics and methods. We also present a methodology for collecting and ground-truthing PDF documents based on consensus-reaching principles and provide a publicly available ground-truthed dataset."
            },
            "slug": "A-methodology-for-evaluating-algorithms-for-table-G\u00f6bel-Hassan",
            "title": {
                "fragments": [],
                "text": "A methodology for evaluating algorithms for table understanding in PDF documents"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The evaluation takes into account three major tasks: table detection, table structure recognition and functional analysis and provides a general and flexible output model for each task along with corresponding evaluation metrics and methods."
            },
            "venue": {
                "fragments": [],
                "text": "DocEng '12"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2724875"
                        ],
                        "name": "Roya Rastan",
                        "slug": "Roya-Rastan",
                        "structuredName": {
                            "firstName": "Roya",
                            "lastName": "Rastan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roya Rastan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33548540"
                        ],
                        "name": "H. Paik",
                        "slug": "H.-Paik",
                        "structuredName": {
                            "firstName": "Hye-young",
                            "lastName": "Paik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Paik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145534891"
                        ],
                        "name": "J. Shepherd",
                        "slug": "J.-Shepherd",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shepherd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shepherd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "The TEXUS system [4] performs simple table structure parsing by considering each text chunk to be a cell."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 292476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8cd18e63e99fe91dd4d24c3ec9fcb9af0497901f",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a precise, comprehensive model of table processing which aims to remedy some of the problems in the discussion of table processing in the literature. The model targets application-independent, end-to-end table processing, and thus encompasses a large subset of the work in the area. The model can be used to aid the design of table processing systems (We provide an example of such a system), can be considered as a reference framework for evaluating the performance of table processing systems, and can assist in clarifying terminological differences in the table processing literature."
            },
            "slug": "TEXUS:-A-Task-based-Approach-for-Table-Extraction-Rastan-Paik",
            "title": {
                "fragments": [],
                "text": "TEXUS: A Task-based Approach for Table Extraction and Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The model targets application-independent, end-to-end table processing, and thus encompasses a large subset of the work in the area, and can be used to aid the design of table processing systems and assist in clarifying terminological differences in the table processing literature."
            },
            "venue": {
                "fragments": [],
                "text": "DocEng"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "It finetunes the FCN-2s model [7] that has been pretrained on the PASCAL VOC semantic segmentation challenge [8] for natural scenes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4246903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82635fb63640ae95f90ee9bdc07832eb461ca881",
            "isKey": false,
            "numCitedBy": 11690,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension."
            },
            "slug": "The-Pascal-Visual-Object-Classes-(VOC)-Challenge-Everingham-Gool",
            "title": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The state-of-the-art in evaluated methods for both classification and detection are reviewed, whether the methods are statistically different, what they are learning from the images, and what the methods find easy or confuse."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "We train the model from random initialization with the ADAM optimizer [13] for approximately 10(6) weight updates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90052,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720466"
                        ],
                        "name": "Tapio Elomaa",
                        "slug": "Tapio-Elomaa",
                        "structuredName": {
                            "firstName": "Tapio",
                            "lastName": "Elomaa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tapio Elomaa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "The ICDAR 2013 Table Competition [2] compared many systems for table structure recognition, including the current state-of-the-art method by Nurminen [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "Previously Reported Results Nurminen [3] 94."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 320,
                                "start": 312
                            }
                        ],
                        "text": "Category Method F-measure Recall Precision PDF Input Image Input\nProposed Models\nSplit 86.79 86.64 86.93 Split-PDF 91.63 91.26 92.00 SPLERGE-PDF 90.89 90.44 91.36 SPLERGE-PDF + Heuristics 91.95 91.46 92.45\nSplit + Heuristics 93.00 92.24 93.78 Split-PDF + Heuristics 95.26 94.64 95.89\nPreviously Reported Results\nNurminen [3] 94.60 94.09 95.12 TEXUS [4] 82.59 84.23 81.02 Shigarov [5] C1 91.50 91.21 91.80 Shigarov [5] C2 93.64 92.33 94.99 DeepDeSRT [6] 91.44\u2020 87.36\u2020 95.93\u2020\n\u2020 result not directly comparable due to evaluation on a random subset of 34 tables."
                    },
                    "intents": []
                }
            ],
            "corpusId": 33157514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9b167a86fb189bfcd366c3839f33f0404db9c10",
            "isKey": true,
            "numCitedBy": 11,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "TAMPERE UNIVERSITY OF TECHNOLOGY Degree Programme in Information Technology NURMINEN, ANSSI: Algorithmic Extraction of Data in Tables in PDF Documents Master of Science Thesis: 64 pages, 4 appendices (8 pages) April 2013 Majoring in: Embedded systems (software emphasis) Examiners: Prof. Tapio Elomaa, MSc. Teemu Heinim\u00e4ki"
            },
            "slug": "ANSSI-NURMINEN-ALGORITHMIC-EXTRACTION-OF-DATA-IN-IN-Elomaa",
            "title": {
                "fragments": [],
                "text": "ANSSI NURMINEN ALGORITHMIC EXTRACTION OF DATA IN TABLES IN PDF DOCUMENTS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49026551"
                        ],
                        "name": "D. Greig",
                        "slug": "D.-Greig",
                        "structuredName": {
                            "firstName": "Darryl",
                            "lastName": "Greig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Greig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146294528"
                        ],
                        "name": "B. Porteous",
                        "slug": "B.-Porteous",
                        "structuredName": {
                            "firstName": "Baroness",
                            "lastName": "Porteous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Porteous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887111"
                        ],
                        "name": "A. Seheult",
                        "slug": "A.-Seheult",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Seheult",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Seheult"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "To do so, we partition the image into rows and row separator regions by performing a graphcut segmentation [14] over r."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115691220,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a717b20e99b76cb228b47694140ed3dce082b530",
            "isKey": false,
            "numCitedBy": 1257,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Exact-Maximum-A-Posteriori-Estimation-for-Binary-Greig-Porteous",
            "title": {
                "fragments": [],
                "text": "Exact Maximum A Posteriori Estimation for Binary Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "volutional pose machines"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision and Pattern Recognition"
            },
            "year": 2016
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 11,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 16,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Deep-Splitting-and-Merging-for-Table-Structure-Tensmeyer-Morariu/658eef14952dc6dee87f5ef1c0f7313441aadf98?sort=total-citations"
}