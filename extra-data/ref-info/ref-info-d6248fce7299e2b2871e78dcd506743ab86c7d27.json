{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33539632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a9b87770207d7d3aef0f1745c58ba56f8038699",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A key problem in the use of context-dependent bidden Markov models is the need to balance the desired model complexity with the amount of available training data. This paper describes a method which uses a simple agglomerative algorithm to cluster and tie acoustically similar states. The main properties of the algorithm are explored using phone recognition on the TIMIT database where it is shown that there is an optimum between the clustering extrema of an untied context-dependent system and a fully tied monophone system. At this optimum, phone recognition performance was 76\u00b77% correct and 72\u00b73% accuracy. The use of state-tying in the HTK continuous speech recognition system is then described and results are presented using the Resource Management database. The average error rate across the Feb '89, Oct '89 and Feb '91 test sets was less than 4\u00b73% and this was achieved without cross-word triphones. Gender-dependent models were also compared to gender-independent models but found to give little improvement."
            },
            "slug": "State-clustering-in-hidden-Markov-model-based-Young-Woodland",
            "title": {
                "fragments": [],
                "text": "State clustering in hidden Markov model-based continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A method which uses a simple agglomerative algorithm to cluster and tie acoustically similar states in context-dependent bidden Markov models and results are presented using the Resource Management database."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759928"
                        ],
                        "name": "A. Ljolje",
                        "slug": "A.-Ljolje",
                        "structuredName": {
                            "firstName": "Andrej",
                            "lastName": "Ljolje",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ljolje"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28546388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d918ce10d9c9cd3278730d3d162445c9a606191f",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A new phone recognizer has been implemented which extends the (phonotactic) decoding constraint to sequences of three phones. It is based on a structure similar to a second order ergodic hidden Markov model (HMM). This kind of a model assumes direct correspondence between the model states and phones, thus constraints on possible state sequences are equivalent to phonotactic constraints. Very high coverage by both left and right context-dependent phone models has been achieved using two methods. The first assumes that some contexts have the same or very similar effect on the phone in question. Thus they are merged into the same contextual class. The outcome is a set of 19 left context classes and 18 right context classes. The second assumes that left context mostly influences the beginning of a phone, whereas the right context influences the end of the phone. Each phone (a state in an ergodic HMM) is represented by a sequence of three probability density functions (pdfs), which is similar to a three state left-to-right HMM. We generate acoustic models such that the first pdf in the model is conditioned on the left context, the middle pdf is context independent (or it can also be context dependent), and the last pdf is conditioned on the right context. A large number of such quasi-triphonic acoustic models can be generated, thus providing a good triphone coverage for a given task, efficiently utilizing the available training data set. The current implementations of the recognizer described here have been applied to the DARPA Resource Management Task to demonstrate feasibility of performing phone (not phoneme ) recognition using an untranscribed database, and the TIMIT database, for comparison to existing phone recognition systems. Since true phone sequences for the training utterances are not available for the RM database, they are estimated from text using a phone realization classification tree trained on the TIMIT database transcriptions. The estimates of the true phone sequences are used in training the models and generating reference phone sequences for scoring. The best phone recognition match between the most likely path through the classification tree and the phone recognizer output for the DARPA February 89 test set was 80\u00b75% accurate and 84\u00b70% correct. The best result obtained using the same recognizer structure on the TIMIT database is 69\u00b74% accurate and 74\u00b78% correct, which is a significant improvement over the best published result, when they are both reduced to the same phone set."
            },
            "slug": "High-accuracy-phone-recognition-using-context-and-Ljolje",
            "title": {
                "fragments": [],
                "text": "High accuracy phone recognition using context clustering and quasi-triphonic models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The current implementations of the recognizer described here have been applied to the DARPA Resource Management Task to demonstrate feasibility of performing phone (not phoneme ) recognition using an untranscribed database, and the TIMIT database, for comparison to existing phone recognition systems."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The merging is based on the increase in the weighted-by-counts entropy [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Context clustering has been combined into both the model-interpolation and quasi-triphone systems to improve the models' trainability [6][7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This technique can improve the robustness of the models and the weights, balancing the combination, have been determined either by hand-tuning [9] or by using the deleted-interpolation algorithm [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Previous studies have attacked this problem by using model-interpolation [6] and quasi-triphone [7] techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195701839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf2dbecb0adcd9b1bec1ec90f78f7bf4aaa13db4",
            "isKey": true,
            "numCitedBy": 207,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Context-dependent phone models are applied to speaker-independent continuous speech recognition and shown to be effective in this domain. Several previously proposed context-dependent models are evaluated, and two new context-dependent phonetic units are introduced: function-word-dependent phone models, which focus on the most difficult subvocabulary; and generalized triphones, which combine similar triphones on the basis of an information-theoretic measure. The subword clustering procedure used for generalized triphones can find the optimal number of models, given a fixed amount of training data. It is shown that context-dependent modeling reduces the error rate by as much as 60%. >"
            },
            "slug": "Context-independent-phonetic-hidden-Markov-models-Lee",
            "title": {
                "fragments": [],
                "text": "Context-independent phonetic hidden Markov models for speaker-independent continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Two new context-dependent phonetic units are introduced: function-word-dependent phone models, which focus on the most difficult subvocabulary; and generalized triphones, which combine similar triphones on the basis of an information-theoretic measure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166786309"
                        ],
                        "name": "X. Huang",
                        "slug": "X.-Huang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Huang",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20900207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c962b5fdfb024eb168a1a28908d03de633b687",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Speaker-dependent phoneme recognition experiments were conducted using variants of the semicontinuous hidden Markov model (SCHMM) with explicit state duration modeling. Results clearly demonstrated that the SCHMM with state duration offers significantly improved phoneme classification accuracy compared to both the discrete HMM and the continuous HMM; the error rate was reduced by more than 30% and 20%, respectively. The use of a limited number of mixture densities significantly reduced the amount of computation. Explicit state duration modeling further reduced the error rate. >"
            },
            "slug": "Phoneme-classification-using-semicontinuous-hidden-Huang",
            "title": {
                "fragments": [],
                "text": "Phoneme classification using semicontinuous hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Speaker-dependent phoneme recognition experiments were conducted using variants of the semicontinuous hidden Markov model (SCHMM) with explicit state duration modeling, and results clearly demonstrated that the SCHMM with state duration offers significantly improved phoneme classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3090152"
                        ],
                        "name": "Ruxin Chen",
                        "slug": "Ruxin-Chen",
                        "structuredName": {
                            "firstName": "Ruxin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruxin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2667435"
                        ],
                        "name": "L. Jamieson",
                        "slug": "L.-Jamieson",
                        "structuredName": {
                            "firstName": "Leah",
                            "lastName": "Jamieson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jamieson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38407161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a04ec2e411585fed4dda1ca8672be51f7e9bb1a5",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new statistical speech model in which coarticulation is modeled explicitly. Unlike HMMs, in which the current state depends only on the previous state and the current observation, the proposed model supports dependence on the previous and next states and on the previous and current observations. The degree of coarticulation between adjacent phones is modeled parametrically, and can be adjusted according to a parameter representing the speaking rate. The model also incorporates a parameter that represents a frame-by-frame measure of confidence in the speech. We present two methods for solving the system parameters: one based on the K-means method, and a novel method based on explicitly minimizing a measure of the segmentation error. A new, efficient forward algorithm and the use of top candidates in the search greatly reduce the computational complexity. In evaluation on the TIMIT data base, we achieve a phone recognition rate of 77.1%."
            },
            "slug": "Explicit-modeling-of-coarticulation-in-a-speech-Chen-Jamieson",
            "title": {
                "fragments": [],
                "text": "Explicit modeling of coarticulation in a statistical speech recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A new statistical speech model in which coarticulation is modeled explicitly, and a novel method based on explicitly minimizing a measure of the segmentation error is presented."
            },
            "venue": {
                "fragments": [],
                "text": "1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40268570"
                        ],
                        "name": "A. J. Robinson",
                        "slug": "A.-J.-Robinson",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Robinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Robinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14787570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6629770cb6a00ad585918e71fe6dbad829ad0d1",
            "isKey": false,
            "numCitedBy": 543,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an application of recurrent networks for phone probability estimation in large vocabulary speech recognition. The need for efficient exploitation of context information is discussed; a role for which the recurrent net appears suitable. An overview of early developments of recurrent nets for phone recognition is given along with the more recent improvements that include their integration with Markov models. Recognition results are presented for the DARPA TIMIT and Resource Management tasks, and it is concluded that recurrent nets are competitive with traditional means for performing phone probability estimation."
            },
            "slug": "An-application-of-recurrent-nets-to-phone-Robinson",
            "title": {
                "fragments": [],
                "text": "An application of recurrent nets to phone probability estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Recognition results are presented for the DARPA TIMIT and Resource Management tasks, and it is concluded that recurrent nets are competitive with traditional means for performing phone probability estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152901373"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "Evan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2727234"
                        ],
                        "name": "Y. Chow",
                        "slug": "Y.-Chow",
                        "structuredName": {
                            "firstName": "Yen-lu",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353221"
                        ],
                        "name": "O. Kimball",
                        "slug": "O.-Kimball",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Kimball",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kimball"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4953636"
                        ],
                        "name": "M. Krasner",
                        "slug": "M.-Krasner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Krasner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krasner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60579533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df53e0dc66eb13bb51c6e4803ceae56d3ebe6f23",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the results of our work in designing a system for phonetic recognition of unrestricted continuous speech. We describe several algorithms used to recognize phonemes using context-dependent Hidden Markov Models of the phonemes. We present results for several variations of the parameters of the algorithms. In addition, we propose a technique that makes it possible to integrate traditional acoustic-phonetic features into a hidden Markov process. The categorical decisions usually associated with heuristic acoustic-phonetic algorithms are replaced by automated training techniques and global search strategies. The combination of general spectral information and specific acoustic-phonetic features is shown to result in more accurate phonetic recognition than either representation by itself."
            },
            "slug": "Context-dependent-modeling-for-acoustic-phonetic-of-Schwartz-Chow",
            "title": {
                "fragments": [],
                "text": "Context-dependent modeling for acoustic-phonetic recognition of continuous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The combination of general spectral information and specific acoustic-phonetic features is shown to result in more accurate phonetic recognition than either representation by itself."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '85. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145204681"
                        ],
                        "name": "L. Lamel",
                        "slug": "L.-Lamel",
                        "structuredName": {
                            "firstName": "Lori",
                            "lastName": "Lamel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lamel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685010"
                        ],
                        "name": "J. Gauvain",
                        "slug": "J.-Gauvain",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Gauvain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gauvain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 251250,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "b250c7238711b5203f2ab9a5e5693d097e38b027",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we report high phone accuracies on three corpora: WSJ0, BREF and TIMIT. The main characteristics of the phone recognizerare: high dimensional feature vector (48), contextand genderdependent phone models with duration distribution, continuous density HMM with Gaussian mixtures, and n-gram probabilities for the phonotatic constraints. These models are trained on speech data that have either phonetic or orthographic transcriptions using maximum likelihood and maximum a posteriori estimation techniques. On the WSJ0 corpus with a 46 phone set we obtain phone accuraciesof 72.4% and 74.4% using 500 and 1600 CD phone units, respectively. Accuracy on BREF with 35 phones is as high as 78.7% with only 428 CD phone units. On TIMIT using the 61 phone symbols and only 500 CD phone units, we obtain a phone accuracyof 67.2% which correspond to 73.4% when the recognizer output is mapped to the commonly used 39 phone set. Making reference to our work on large vocabulary CSR, we show that it is worthwhile to perform phone recognition experiments as opposed to only focusing attention on word recognition results."
            },
            "slug": "High-performance-speaker-independent-phone-using-Lamel-Gauvain",
            "title": {
                "fragments": [],
                "text": "High performance speaker-independent phone recognition using CDHMM"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that it is worthwhile to perform phone recognition experiments as opposed to only focusing attention on word recognition results, and high phone accuracies on three corpora: WSJ0, BREF and TIMIT are reported."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110673383"
                        ],
                        "name": "Satoshi Takahashi",
                        "slug": "Satoshi-Takahashi",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Takahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satoshi Takahashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734761"
                        ],
                        "name": "S. Sagayama",
                        "slug": "S.-Sagayama",
                        "structuredName": {
                            "firstName": "Shigeki",
                            "lastName": "Sagayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sagayama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20036982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a20f1b6557a3f95a89bdd599e47e7753aaf83101",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the problems with context-dependent HMMs is that a large number of model parameters should be estimated using a limited amount of training data. Parameters that have the same property should be tied in order to represent acoustic models efficiently. This paper proposes four-level tied-structure for phoneme models. The four levels include 1) model level, 2) state level, 3) distribution level, and 4) feature parameter level. Although some techniques have been proposed for the first three levels, feature parameter tying in the fourth level is newly proposed in this paper. We found that feature parameter tying makes it possible to represent 1,600 mean vectors of multivariate Gaussian mixture HMMs by using the combination of 16 representative mean values in each dimension. Experimental results show that feature parameter tying reduces the amount of calculation required for recognition without significant degrading performance. Furthermore, we found that feature parameter tying is also effective for model training."
            },
            "slug": "Four-level-tied-structure-for-efficient-of-acoustic-Takahashi-Sagayama",
            "title": {
                "fragments": [],
                "text": "Four-level tied-structure for efficient representation of acoustic modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is found that feature parameter tying makes it possible to represent 1,600 mean vectors of multivariate Gaussian mixture HMMs by using the combination of 16 representative mean values in each dimension."
            },
            "venue": {
                "fragments": [],
                "text": "1995 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3096615"
                        ],
                        "name": "H. Sameti",
                        "slug": "H.-Sameti",
                        "structuredName": {
                            "firstName": "Hossein",
                            "lastName": "Sameti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sameti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2335161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a53d61e19f8222a3ce1b7c668917545c1ef9b18d",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Transitional speech units for American English are proposed and constructed via assimilation of active articulatory features. The effectiveness of a feature-based system exploiting the transitional speech units is demonstrated in evaluation experiments, where the new system with use of quadratic regressive states is shown to achieve error rate reduction of 21% compared with the system using only static subphonemic units."
            },
            "slug": "Transitional-speech-units-and-their-representation-Deng-Sameti",
            "title": {
                "fragments": [],
                "text": "Transitional speech units and their representation by regressive Markov states: applications to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The effectiveness of a feature-based system exploiting the transitional speech units is demonstrated in evaluation experiments, where the new system with use of quadratic regressive states is shown to achieve error rate reduction of 21% compared with the system using only static subphonemic units."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145800809"
                        ],
                        "name": "J. Kangas",
                        "slug": "J.-Kangas",
                        "structuredName": {
                            "firstName": "Jari",
                            "lastName": "Kangas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kangas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708642"
                        ],
                        "name": "Jorma T. Laaksonen",
                        "slug": "Jorma-T.-Laaksonen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Laaksonen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorma T. Laaksonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "The merging is based on the increase in the weighted-by-counts entropy [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "Context clustering has been combined into both the model-interpolation and quasi-triphone systems to improve the models' trainability [6][7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "This technique can improve the robustness of the models and the weights, balancing the combination, have been determined either by hand-tuning [9] or by using the deleted-interpolation algorithm [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Previous studies have attacked this problem by using model-interpolation [6] and quasi-triphone [7] techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15989268,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2b7024793ff8da6c80df9cfadd2b524b6d6f35e",
            "isKey": true,
            "numCitedBy": 136,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Context-dependent-Phonetic-Hidden-Markov-Models-for-Juang-Kangas",
            "title": {
                "fragments": [],
                "text": "Context-dependent Phonetic Hidden Markov Models for Speaker-independent Continuous Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2467151"
                        ],
                        "name": "John S. Garofolo",
                        "slug": "John-S.-Garofolo",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Garofolo",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John S. Garofolo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145204681"
                        ],
                        "name": "L. Lamel",
                        "slug": "L.-Lamel",
                        "structuredName": {
                            "firstName": "Lori",
                            "lastName": "Lamel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lamel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144982775"
                        ],
                        "name": "W. Fisher",
                        "slug": "W.-Fisher",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Fisher",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3241934"
                        ],
                        "name": "J. Fiscus",
                        "slug": "J.-Fiscus",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Fiscus",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fiscus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786370"
                        ],
                        "name": "D. Pallett",
                        "slug": "D.-Pallett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pallett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pallett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35669756"
                        ],
                        "name": "Nancy L. Dahlgren",
                        "slug": "Nancy-L.-Dahlgren",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Dahlgren",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy L. Dahlgren"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 65148724,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "47128bb3ce4ed00691c0d7d58c02791c3e963ab7",
            "isKey": false,
            "numCitedBy": 2183,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Darpa-Timit-Acoustic-Phonetic-Continuous-Speech-|-Garofolo-Lamel",
            "title": {
                "fragments": [],
                "text": "Darpa Timit Acoustic-Phonetic Continuous Speech Corpus CD-ROM {TIMIT} | NIST"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u201c State clustering in HMM - based continuous speech recognition \u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "Experiments are performed with the TIMIT database (1990 release, [3])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DARPA TIMIT Acousticphonetic continuous speech corpus CD-ROM"
            },
            "venue": {
                "fragments": [],
                "text": "NISTIR 4930,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "Firstly, a tied-mixture structure [4] is introduced to the corresponding states of all the three component models accounting for the triphones of a phone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "In HMM based systems, parametric tying has been excised from states [11] to mixture components [4] and to feature parameters [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phoneme classi cation using semicontinuous hidden Markov models"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE ASSP,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phone recognition performance of the new triphone model on the core test set Merging threshold Corr"
            },
            "venue": {
                "fragments": [],
                "text": "Acc. Sub. Del. Ins"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phoneme classiication using semicontinuous hidden Markov models"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE ASSP"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phone recognition performance of the new triphone model on the complete test set Merging threshold Corr"
            },
            "venue": {
                "fragments": [],
                "text": "Acc. Sub. Del. Ins"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Improved-phone-recognition-using-Bayesian-triphone-Ming-Smith/d6248fce7299e2b2871e78dcd506743ab86c7d27?sort=total-citations"
}