{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076400"
                        ],
                        "name": "B. Caprile",
                        "slug": "B.-Caprile",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Caprile",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caprile"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10243731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "898c01de58eb3b8e790b60e0fe0db2230d88f15b",
            "isKey": false,
            "numCitedBy": 698,
            "numCiting": 152,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning an input-output mapping from a set of examples, of the type that many neural networks have been constructed to perform, can be regarded as synthesizing an approximation of a multi-dimensional function. We develop a theoretical framework for approximation based on regularization techniques that leads to a class of three-layer networks that we call Generalized Radial Basis Functions (GRBF). GRBF networks are not only equivalent to generalized splines, but are also closely related to several pattern recognition methods and neural network algorithms. The paper introduces several extensions and applications of the technique and discusses intriguing analogies with neurobiological data."
            },
            "slug": "Extensions-of-a-Theory-of-Networks-for-and-Learning-Girosi-Poggio",
            "title": {
                "fragments": [],
                "text": "Extensions of a Theory of Networks for Approximation and Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A theoretical framework for approximation based on regularization techniques that leads to a class of three-layer networks that is called Generalized Radial Basis Functions (GRBF), which is not only equivalent to generalized splines, but is closely related to several pattern recognition methods and neural network algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145768864"
                        ],
                        "name": "D. Broomhead",
                        "slug": "D.-Broomhead",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Broomhead",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Broomhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159852"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117200472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5558a34dfd1dbb572895664d38fca04029a99cb",
            "isKey": false,
            "numCitedBy": 2933,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The relationship between 'learning' in adaptive layered networks and the fitting of data with high dimensional surfaces is discussed. This leads naturally to a picture of 'generalization in terms of interpolation between known data points and suggests a rational approach to the theory of such networks. A class of adaptive networks is identified which makes the interpolation scheme explicit. This class has the property that learning is equivalent to the solution of a set of linear equations. These networks thus represent nonlinear relationships while having a guaranteed learning rule. Great Britain."
            },
            "slug": "Radial-Basis-Functions,-Multi-Variable-Functional-Broomhead-Lowe",
            "title": {
                "fragments": [],
                "text": "Radial Basis Functions, Multi-Variable Functional Interpolation and Adaptive Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The relationship between 'learning' in adaptive layered networks and the fitting of data with high dimensional surfaces is discussed, leading naturally to a picture of 'generalization in terms of interpolation between known data points and suggests a rational approach to the theory of such networks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46933679"
                        ],
                        "name": "M. Bertero",
                        "slug": "M.-Bertero",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Bertero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bertero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145730991"
                        ],
                        "name": "V. Torre",
                        "slug": "V.-Torre",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Torre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Torre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14285485,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "31b5a06273e75f159d5d9e42bc5bdfd7fd4b625e",
            "isKey": false,
            "numCitedBy": 855,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "Mathematical results on ill-posed and ill-conditioned problems are reviewed and the formal aspects of regularization theory in the linear case are introduced. Specific topics in early vision and their regularization are then analyzed rigorously, characterizing existence, uniqueness, and stability of solutions. A fundamental difficulty that arises in almost every vision problem is scale, that is, the resolution at which to operate. Methods that have been proposed to deal with the problem include scale-space techniques that consider the behavior of the result across a continuum of scales. From the point of view of regulation theory, the concept of scale is related quite directly to the regularization parameter lambda . It suggested that methods used to obtained the optimal value of lambda may provide, either directly or after suitable modification, the optimal scale associated with the specific instance of certain problems. >"
            },
            "slug": "Ill-posed-problems-in-early-vision-Bertero-Poggio",
            "title": {
                "fragments": [],
                "text": "Ill-posed problems in early vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 39546464,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "4a1b11c68bdc362e60fd49639fa20026e4c00fcc",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Many neural networks can be regarded as attempting to approximate a multivariate function in terms of one-input one-output units. This note considers the problem of an exact representation of nonlinear mappings in terms of simpler functions of fewer variables. We review Kolmogorov's theorem on the representation of functions of several variables in terms of functions of one variable and show that it is irrelevant in the context of networks for learning."
            },
            "slug": "Representation-Properties-of-Networks:-Kolmogorov's-Girosi-Poggio",
            "title": {
                "fragments": [],
                "text": "Representation Properties of Networks: Kolmogorov's Theorem Is Irrelevant"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Kolmogorov's theorem on the representation of functions of several variables in terms of function of one variable is reviewed and it is shown that it is irrelevant in the context of networks for learning."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145016534"
                        ],
                        "name": "J. Moody",
                        "slug": "J.-Moody",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moody",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moody"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319258"
                        ],
                        "name": "C. Darken",
                        "slug": "C.-Darken",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Darken",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Darken"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31251383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e7c4f513f24c3b82a1138b9f22ed87ed00cbe76",
            "isKey": false,
            "numCitedBy": 4527,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a network architecture which uses a single internal layer of locally-tuned processing units to learn both classification tasks and real-valued function approximations (Moody and Darken 1988). We consider training such networks in a completely supervised manner, but abandon this approach in favor of a more computationally efficient hybrid learning method which combines self-organized and supervised learning. Our networks learn faster than backpropagation for two reasons: the local representations ensure that only a few units respond to any given input, thus reducing computational overhead, and the hybrid learning rules are linear rather than nonlinear, thus leading to faster convergence. Unlike many existing methods for data analysis, our network architecture and learning rules are truly adaptive and are thus appropriate for real-time use."
            },
            "slug": "Fast-Learning-in-Networks-of-Locally-Tuned-Units-Moody-Darken",
            "title": {
                "fragments": [],
                "text": "Fast Learning in Networks of Locally-Tuned Processing Units"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This work proposes a network architecture which uses a single internal layer of locally-tuned processing units to learn both classification tasks and real-valued function approximations (Moody and Darken 1988)."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706122"
                        ],
                        "name": "N. Dyn",
                        "slug": "N.-Dyn",
                        "structuredName": {
                            "firstName": "Nira",
                            "lastName": "Dyn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dyn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117038933,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "376ea27808150869d2ed43692ca88f27bfa2430a",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Interpolation-of-scattered-Data-by-radial-Functions-Dyn",
            "title": {
                "fragments": [],
                "text": "Interpolation of scattered Data by radial Functions"
            },
            "venue": {
                "fragments": [],
                "text": "Topics in Multivariate Approximation"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020074"
                        ],
                        "name": "A. Lapedes",
                        "slug": "A.-Lapedes",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Lapedes",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lapedes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542113"
                        ],
                        "name": "R. Farber",
                        "slug": "R.-Farber",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Farber",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Farber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60720876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d981c7637fc39335cf53cfa792a0f8d5b66ec6e",
            "isKey": false,
            "numCitedBy": 626,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The backpropagation learning algorithm for neural networks is developed into a formalism for nonlinear signal processing. We illustrate the method by selecting two common topics in signal processing, prediction and system modelling, and show that nonlinear applications can be handled extremely well by using neural networks. The formalism is a natural, nonlinear extension of the linear Least Mean Squares algorithm commonly used in adaptive signal processing. Simulations are presented that document the additional performance achieved by using nonlinear neural networks. First, we demonstrate that the formalism may be used to predict points in a highly chaotic time series with orders of magnitude increase in accuracy over conventional methods including the Linear Predictive Method and the Gabor-Volterra-Weiner Polynomial Method. Deterministic chaos is thought to be involved in many physical situations including the onset of turbulence in fluids, chemical reactions and plasma physics. Secondly, we demonstrate the use of the formalism in nonlinear system modelling by providing a graphic example in which it is clear that the neural network has accurately modelled the nonlinear transfer function. It is interesting to note that the formalism provides explicit, analytic, global, approximations to the nonlinear maps underlying the various time series. Furthermore, the neural net more\u00a0\u00bb seems to be extremely parsimonious in its requirements for data points from the time series. We show that the neural net is able to perform well because it globally approximates the relevant maps by performing a kind of generalized mode decomposition of the maps. 24 refs., 13 figs. \u00ab\u00a0less"
            },
            "slug": "Nonlinear-signal-processing-using-neural-networks:-Lapedes-Farber",
            "title": {
                "fragments": [],
                "text": "Nonlinear signal processing using neural networks: Prediction and system modelling"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is demonstrated that the backpropagation learning algorithm for neural networks may be used to predict points in a highly chaotic time series with orders of magnitude increase in accuracy over conventional methods including the Linear Predictive Method and the Gabor-Volterra-Weiner Polynomial Method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899177"
                        ],
                        "name": "Ken-ichi Funahashi",
                        "slug": "Ken-ichi-Funahashi",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Funahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ken-ichi Funahashi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10203109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "386cbc45ceb59a7abb844b5078e5c944f17723b4",
            "isKey": false,
            "numCitedBy": 4187,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-approximate-realization-of-continuous-by-Funahashi",
            "title": {
                "fragments": [],
                "text": "On the approximate realization of continuous mappings by neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92579735"
                        ],
                        "name": "Peter Craven",
                        "slug": "Peter-Craven",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Craven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Craven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145733439"
                        ],
                        "name": "G. Wahba",
                        "slug": "G.-Wahba",
                        "structuredName": {
                            "firstName": "Grace",
                            "lastName": "Wahba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wahba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14094416,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b477dd12dd49e44a62c1a303501df5fb6706c7e9",
            "isKey": false,
            "numCitedBy": 3540,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "SummarySmoothing splines are well known to provide nice curves which smooth discrete, noisy data. We obtain a practical, effective method for estimating the optimum amount of smoothing from the data. Derivatives can be estimated from the data by differentiating the resulting (nearly) optimally smoothed spline.We consider the modelyi(ti)+\u03b5i,i=1, 2, ...,n,ti\u2208[0, 1], whereg\u2208W2(m)={f:f,f\u2032, ...,f(m\u22121) abs. cont.,f(m)\u2208\u21122[0,1]}, and the {\u03b5i} are random errors withE\u03b5i=0,E\u03b5i\u03b5j=\u03c32\u03b4ij. The error variance \u03c32 may be unknown. As an estimate ofg we take the solutiongn, \u03bb to the problem: Findf\u2208W2(m) to minimize\n$$\\frac{1}{n}\\sum\\limits_{j = 1}^n {(f(t_j ) - y_j )^2 + \\lambda \\int\\limits_0^1 {(f^{(m)} (u))^2 du} }$$\n. The functiongn, \u03bb is a smoothing polynomial spline of degree 2m\u22121. The parameter \u03bb controls the tradeoff between the \u201croughness\u201d of the solution, as measured by\n$$\\int\\limits_0^1 {[f^{(m)} (u)]^2 du}$$\n, and the infidelity to the data as measured by\n$$\\frac{1}{n}\\sum\\limits_{j = 1}^n {(f(t_j ) - y_j )^2 }$$\n, and so governs the average square errorR(\u03bb; g)=R(\u03bb) defined by\n$$R(\\lambda ) = \\frac{1}{n}\\sum\\limits_{j = 1}^n {(g_{n,\\lambda } (t_j ) - g(t_j ))^2 }$$\n. We provide an estimate\n$$\\hat \\lambda$$\n, called the generalized cross-validation estimate, for the minimizer ofR(\u03bb). The estimate\n$$\\hat \\lambda$$\n is the minimizer ofV(\u03bb) defined by\n$$V(\\lambda ) = \\frac{1}{n}\\parallel (I - A(\\lambda ))y\\parallel ^2 /\\left[ {\\frac{1}{n}{\\text{Trace(}}I - A(\\lambda ))} \\right]^2$$\n, wherey=(y1, ...,yn)t andA(\u03bb) is then\u00d7n matrix satisfying(gn, \u03bb (t1), ...,gn, \u03bb (tn))t=A (\u03bb) y. We prove that there exist a sequence of minimizers\n$$\\tilde \\lambda = \\tilde \\lambda (n)$$\n ofEV(\u03bb), such that as the (regular) mesh{ti}i=1n becomes finer,\n$$\\mathop {\\lim }\\limits_{n \\to \\infty } ER(\\tilde \\lambda )/\\mathop {\\min }\\limits_\\lambda ER(\\lambda ) \\downarrow 1$$\n. A Monte Carlo experiment with several smoothg's was tried withm=2,n=50 and several values of \u03c32, and typical values of\n$$R(\\hat \\lambda )/\\mathop {\\min }\\limits_\\lambda R(\\lambda )$$\n were found to be in the range 1.01\u20131.4. The derivativeg\u2032 ofg can be estimated by\n$$g'_{n,\\hat \\lambda } (t)$$\n. In the Monte Carlo examples tried, the minimizer of\n$$R_D (\\lambda ) = \\frac{1}{n}\\sum\\limits_{j = 1}^n {(g'_{n,\\lambda } (t_j ) - } g'(t_j ))$$\n tended to be close to the minimizer ofR(\u03bb), so that\n$$\\hat \\lambda$$\n was also a good value of the smoothing parameter for estimating the derivative."
            },
            "slug": "Smoothing-noisy-data-with-spline-functions-Craven-Wahba",
            "title": {
                "fragments": [],
                "text": "Smoothing noisy data with spline functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459996"
                        ],
                        "name": "E. Kansa",
                        "slug": "E.-Kansa",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Kansa",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kansa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121196186,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2b37df7dcaef4766969bad8662a53760fb119ba2",
            "isKey": false,
            "numCitedBy": 1817,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multiquadrics\u2014A-scattered-data-approximation-scheme-Kansa",
            "title": {
                "fragments": [],
                "text": "Multiquadrics\u2014A scattered data approximation scheme with applications to computational fluid-dynamics\u2014I surface approximations and partial derivative estimates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416462"
                        ],
                        "name": "G. Cybenko",
                        "slug": "G.-Cybenko",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cybenko",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cybenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10158697,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "21e82ed12c620fba1f5ee42162962aae74a23510",
            "isKey": false,
            "numCitedBy": 4062,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In the paper \"Approximation by Superpositions of a SigmoidaI Function\" [C], the proof given for Lemma i is incorrect since it relies on the erroneous statement that simple functions are dense in L=(R). The author has pointed out that the proof in I'C] can be corrected by changing, at the bottom of page 307 and the top of page 308, the occurrences of L~(R) to L=(J) for a compact interval, J, containing {yrx lx ~ I,}, where y is fLxed. It should also be noted that the reduction of multidimensional density to one-dimensional density as in the proof of Lemma 1 had previously been obtained by Dahmen and Micchelli, using the same techniques, in work on ridge regression (see Lemma 3.2 of [DM]). We thank Raymond T, Melton, who pointed out the error in the proof of Lemma 1 in [C] and supplied a proof, showing that the Fourier transform of the measure /~ must be zero because the/~-measure of every half-plane is zero [M]."
            },
            "slug": "Approximation-by-superpositions-of-a-sigmoidal-Cybenko",
            "title": {
                "fragments": [],
                "text": "Approximation by superpositions of a sigmoidal function"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The reduction of multidimensional density to one-dimensional density as in the proof of Lemma 1 had previously been obtained by Dahmen and Micchelli, using the same techniques, in work on ridge regression."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Control. Signals Syst."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156574"
                        ],
                        "name": "J. Meinguet",
                        "slug": "J.-Meinguet",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Meinguet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Meinguet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122834657,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "398a9f4efcbca25c02bc35188fc9b55d7a9f943b",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The concrete method of \u2018surface spline interpolation\u2019 is closely connected with the classical problem of minimizing a Sobolev seminorm under interpolatory constraints; the intrinsic structure of surface splines is accordingly that of a multivariate extension of natural splines. The proper abstract setting is a Hilbert function space whose reproducing kernel involves no functions more complicated than logarithms and is easily coded. Convenient representation formulas are given, as also a practical multivariate extension of the Peano kernel theorem. Owing to the numerical stability of Cholesky factorization of positive definite symmetric matrices, the whole construction process of a surface spline can be described as a recursive algorithm, the data relative to the various interpolation points being exploited in sequence.R\u00e9sum\u00e9La m\u00e9thode concr\u00e8te d'interpolation par surfaces-spline est \u00e9troitement li\u00e9e au probl\u00e8me classique de la minimisation d'une semi-norme de Soboleff sous des contraintes d'interpolation; la structure intrins\u00e8que des surfaces-spline est d\u00e8s lors celle d'une extension multivari\u00e9e des fonctions-spline naturelles. Le cadre abstrait ad\u00e9quat est un espace fonctionnel hilbertien dont le noyau reproduisant ne fait pas intervenir de fonctions plus compliqu\u00e9es que des logarithmes et est ais\u00e9 \u00e0 programmer. Des formules commodes de repr\u00e9sentation sont donn\u00e9es, ainsi qu'une extension multivari\u00e9e d'int\u00e9r\u00eat pratique du th\u00e9or\u00e8me du noyau de Peano. Gr\u00e2ce \u00e0 la stabilit\u00e9 num\u00e9rique de la factorisation de Cholesky des matrices sym\u00e9triques d\u00e9finies positives, la construction d'une surface-spline peut se faire en exploitant point apr\u00e8s point les donn\u00e9es d'interpolation."
            },
            "slug": "Multivariate-interpolation-at-arbitrary-points-made-Meinguet",
            "title": {
                "fragments": [],
                "text": "Multivariate interpolation at arbitrary points made simple"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2964655"
                        ],
                        "name": "M. Stinchcombe",
                        "slug": "M.-Stinchcombe",
                        "structuredName": {
                            "firstName": "Maxwell",
                            "lastName": "Stinchcombe",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stinchcombe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149702798"
                        ],
                        "name": "H. White",
                        "slug": "H.-White",
                        "structuredName": {
                            "firstName": "Halbert",
                            "lastName": "White",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. White"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14470590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee7f0bc85b339d781c2e0c7e6db8e339b6b9fec2",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "K.M. Hornik, M. Stinchcombe, and H. White (Univ. of California at San Diego, Dept. of Economics Discussion Paper, June 1988; to appear in Neural Networks) showed that multilayer feedforward networks with as few as one hidden layer, no squashing at the output layer, and arbitrary sigmoid activation function at the hidden layer are universal approximators: they are capable of arbitrarily accurate approximation to arbitrary mappings, provided sufficiently many hidden units are available. The present authors obtain identical conclusions but do not require the hidden-unit activation to be sigmoid. Instead, it can be a rather general nonlinear function. Thus, multilayer feedforward networks possess universal approximation capabilities by virtue of the presence of intermediate layers with sufficiently many parallel processors; the properties of the intermediate-layer activation function are not so crucial. In particular, sigmoid activation functions are not necessary for universal approximation.<<ETX>>"
            },
            "slug": "Universal-approximation-using-feedforward-networks-Stinchcombe-White",
            "title": {
                "fragments": [],
                "text": "Universal approximation using feedforward networks with non-sigmoid hidden layer activation functions"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Multilayer feedforward networks possess universal approximation capabilities by virtue of the presence of intermediate layers with sufficiently many parallel processors; the properties of the intermediate-layer activation function are not so crucial."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4361875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50899b2355d6908a304bacb5e406f800f3dde558",
            "isKey": false,
            "numCitedBy": 1019,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "THE visual recognition of three-dimensional (3-D) objects on the basis of their shape poses at least two difficult problems. First, there is the problem of variable illumination, which can be addressed by working with relatively stable features such as intensity edges rather than the raw intensity images1,2. Second, there is the problem of the initially unknown pose of the object relative to the viewer. In one approach to this problem, a hypothesis is first made about the viewpoint, then the appearance of a model object from such a viewpoint is computed and compared with the actual image3\u20137. Such recognition schemes generally employ 3-D models of objects, but the automatic learning of 3-D models is itself a difficult problem8,9. To address this problem in computational vision, we have developed a scheme, based on the theory of approximation of multivariate functions, that learns from a small set of perspective views a function mapping any viewpoint to a standard view. A network equivalent to this scheme will thus 'recognize' the object on which it was trained from any viewpoint."
            },
            "slug": "A-network-that-learns-to-recognize-objects-Poggio-Edelman",
            "title": {
                "fragments": [],
                "text": "A network that learns to recognize three-dimensional objects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A scheme is developed, based on the theory of approximation of multivariate functions, that learns from a small set of perspective views a function mapping any viewpoint to a standard view, and a network equivalent to this scheme will 'recognize' the object on which it was trained from any viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14489533"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7164862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3ac6aee145606abe44d1374d9550a378adf768c",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years many researchers have investigated the use of Markov random fields (MRFs) for computer vision. The computational complexity of the implementation has been a drawback of MRFs. In this paper we derive deterministic approximations to MRFs models. All the theoretical results are obtained in the framework of the mean field theory from statistical mechanics. Because we use MRFs models the mean field equations lead to parallel and iterative algorithms. One of the considered models for image reconstruction is shown to give in a natural way the graduate non-convexity algorithm proposed by Blake and Zisserman."
            },
            "slug": "Parallel-and-deterministic-algorithms-from-MRFs:-Geiger-Girosi",
            "title": {
                "fragments": [],
                "text": "Parallel and deterministic algorithms from MRFs: surface reconstruction and integration"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Deterministic approximations to MRFs models are derived and one of the considered models for image reconstruction is shown to give in a natural way the graduate non-convexity algorithm proposed by Blake and Zisserman."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2630782"
                        ],
                        "name": "J. Marroqu\u00edn",
                        "slug": "J.-Marroqu\u00edn",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Marroqu\u00edn",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Marroqu\u00edn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689724"
                        ],
                        "name": "S. Mitter",
                        "slug": "S.-Mitter",
                        "structuredName": {
                            "firstName": "Sanjoy",
                            "lastName": "Mitter",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mitter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14692859,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "97c12f5ddfdf036eb6cf935a679d1e4ba2fe535f",
            "isKey": false,
            "numCitedBy": 865,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We formulate several problems in early vision as inverse problems. Among the solution methods we review standard regularization theory, discuss its limitations, and present new stochastic (in particular, Bayesian) techniques based on Markov Random Field models for their solution. We derive efficient algorithms and describe parallel implementations on digital parallel SIMD architectures, as well as a new class of parallel hybrid computers that mix digital with analog components."
            },
            "slug": "Probabilistic-Solution-of-Ill-Posed-Problems-in-Marroqu\u00edn-Mitter",
            "title": {
                "fragments": [],
                "text": "Probabilistic Solution of Ill-Posed Problems in Computational Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work derives efficient algorithms and describes parallel implementations on digital parallel SIMD architectures, as well as a new class of parallel hybrid computers that mix digital with analog components."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145627013"
                        ],
                        "name": "J. Stewart",
                        "slug": "J.-Stewart",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Stewart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stewart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120093770,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "400ca5d045588b887ec8949662dff5436bbc2461",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "2 fi COS Xi + i X 6 S i n i = \u00b0i = l ' ' i = l ' Likewise it is easily verified directly that e is p.d. for real \\ , but it is not so straightforward to see that such functions as e~H e~*, and (1 4x)\" ? e p.d. These and other examples are discussed in \u00a7 3. Positive definite functions and their various analogues and generalizations have arisen in diverse parts of mathematics since the beginning of this century. They occur naturally in Fourier analysis, probability theory, operator theory, complex function-theory, moment problems, integral equations, boundary-value problems for partial differential equations, embedding problems, information theory, and other areas. Their history constitutes a good illustration of the words of Hobson [51, p. 290] : \"Not only are special results, obtained independently of one another, frequently seen to be really included in"
            },
            "slug": "Positive-definite-functions-and-generalizations,-an-Stewart",
            "title": {
                "fragments": [],
                "text": "Positive definite functions and generalizations, an historical survey"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074730628"
                        ],
                        "name": "J. Duchon",
                        "slug": "J.-Duchon",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Duchon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Duchon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123055447,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dd573acce51d862cfb576bf9588f7ccad07b7272",
            "isKey": false,
            "numCitedBy": 1451,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We define a family of semi-norms \u2016\u03bc\u2016m,s=(\u222b\u211d n\u2223\u03c4\u22232s\u2223\u2131 Dmu(\u03c4)\u22232 d\u03c4)1/2 Minimizing such semi-norms, subject to some interpolating conditions, leads to functions of very simple forms, providing interpolation methods that: 1\u00b0) preserve polynomials of degree\u2264m\u22121; 2\u00b0) commute with similarities as well as translations and rotations of \u211dn; and 3\u00b0) converge in Sobolev spaces Hm+s(\u03a9)."
            },
            "slug": "Splines-minimizing-rotation-invariant-semi-norms-in-Duchon",
            "title": {
                "fragments": [],
                "text": "Splines minimizing rotation-invariant semi-norms in Sobolev spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A family of semi-norms is defined, subject to some interpolating conditions, providing interpolation methods that preserve polynomials of degree\u2264m\u22121 and converge in Sobolev spaces Hm+s(\u03a9)."
            },
            "venue": {
                "fragments": [],
                "text": "Constructive Theory of Functions of Several Variables"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104537710"
                        ],
                        "name": "J. MacQueen",
                        "slug": "J.-MacQueen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "MacQueen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacQueen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6278891,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ac8ab51a86f1a9ae74dd0e4576d1a019f5e654ed",
            "isKey": false,
            "numCitedBy": 24206,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to describe a process for partitioning an N-dimensional population into k sets on the basis of a sample. The process, which is called 'k-means,' appears to give partitions which are reasonably efficient in the sense of within-class variance. That is, if p is the probability mass function for the population, S = {S1, S2, * *, Sk} is a partition of EN, and ui, i = 1, 2, * , k, is the conditional mean of p over the set Si, then W2(S) = ff=ISi f z u42 dp(z) tends to be low for the partitions S generated by the method. We say 'tends to be low,' primarily because of intuitive considerations, corroborated to some extent by mathematical analysis and practical computational experience. Also, the k-means procedure is easily programmed and is computationally economical, so that it is feasible to process very large samples on a digital computer. Possible applications include methods for similarity grouping, nonlinear prediction, approximating multivariate distributions, and nonparametric tests for independence among several variables. In addition to suggesting practical classification methods, the study of k-means has proved to be theoretically interesting. The k-means concept represents a generalization of the ordinary sample mean, and one is naturally led to study the pertinent asymptotic behavior, the object being to establish some sort of law of large numbers for the k-means. This problem is sufficiently interesting, in fact, for us to devote a good portion of this paper to it. The k-means are defined in section 2.1, and the main results which have been obtained on the asymptotic behavior are given there. The rest of section 2 is devoted to the proofs of these results. Section 3 describes several specific possible applications, and reports some preliminary results from computer experiments conducted to explore the possibilities inherent in the k-means idea. The extension to general metric spaces is indicated briefly in section 4. The original point of departure for the work described here was a series of problems in optimal classification (MacQueen [9]) which represented special"
            },
            "slug": "Some-methods-for-classification-and-analysis-of-MacQueen",
            "title": {
                "fragments": [],
                "text": "Some methods for classification and analysis of multivariate observations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37243943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d20eff70cb168111fb5cc320cb692a11f1adf62",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-capabilities-of-multilayer-perceptrons-Baum",
            "title": {
                "fragments": [],
                "text": "On the capabilities of multilayer perceptrons"
            },
            "venue": {
                "fragments": [],
                "text": "J. Complex."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15659829,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "25406e6733a698bfc4ac836f8e74f458e75dad4f",
            "isKey": false,
            "numCitedBy": 1696,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the question of when a network can be expected to generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples are drawn from the same distribution. Among our results are the following bounds on appropriate sample vs. network size. Assume 0 < \u220a 1/8. We show that if m O(W/\u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 1 \u220a of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with one hidden layer, any learning algorithm using fewer than (W/\u220a) random training examples will, for some distributions of examples consistent with an appropriate weight choice, fail at least some fixed fraction of the time to find a weight choice that will correctly classify more than a 1 \u220a fraction of the future test examples."
            },
            "slug": "What-Size-Net-Gives-Valid-Generalization-Baum-Haussler",
            "title": {
                "fragments": [],
                "text": "What Size Net Gives Valid Generalization?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if m O(W/ \u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 2 \u220a of future test examples drawn from the same distribution."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2634385"
                        ],
                        "name": "W. Madych",
                        "slug": "W.-Madych",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Madych",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Madych"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143758670"
                        ],
                        "name": "S. Nelson",
                        "slug": "S.-Nelson",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Nelson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40802283,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "da041bbf08388c7f83982acfe0c8bfc23b12d4c6",
            "isKey": false,
            "numCitedBy": 562,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We continue an earlier study of certain spaces that provide a variational framework for multivariate interpolation. Using the Fourier transform to analyze these spaces, we obtain error estimates of arbitrarily high order for a class of interpolation methods that includes multiquadrics"
            },
            "slug": "Multivariate-interpolation-and-condi-tionally-Madych-Nelson",
            "title": {
                "fragments": [],
                "text": "Multivariate interpolation and condi-tionally positive definite functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40770452"
                        ],
                        "name": "L. Goddard",
                        "slug": "L.-Goddard",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Goddard",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goddard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4192258,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6bef91d0c32549f07c969322cb6d28f1fd96ec9d",
            "isKey": false,
            "numCitedBy": 515,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Theory of Approximation of Functions of a Real VariableBy A. F. Timan. Translated by J. Berry. English translation edited and editorial preface by J. Cossar. (International Series of Monographs on Pure and Applied Mathematics, Vol. 34.) Pp. xii + 631. (London and New York: Pergamon Press, 1963.) 100s. net."
            },
            "slug": "Approximation-of-Functions-Goddard",
            "title": {
                "fragments": [],
                "text": "Approximation of Functions"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5216020"
                        ],
                        "name": "M. Casdagli",
                        "slug": "M.-Casdagli",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Casdagli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Casdagli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122236599,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "be946457d3f880d9ec836aee3d0d231ffa3bcc9a",
            "isKey": false,
            "numCitedBy": 1398,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonlinear-prediction-of-chaotic-time-series-Casdagli",
            "title": {
                "fragments": [],
                "text": "Nonlinear prediction of chaotic time series"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120971205"
                        ],
                        "name": "M. Brady",
                        "slug": "M.-Brady",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brady"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58521521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "164bde6e0a7211148924b5c7ae8310822baeb7ad",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : In this series of Image Understanding Workshop Proceedings, we have stressed the issue of representation. In particular, we have described the development by Horn and his colleagues of the reflectance map, the albedo image, and the Gaussian image, and we have described the work of the group founded by Marr using the primal sketch, the 2 1/2 D sketch, and axis based 3-D models. In the April, 1981 Proceedings, we reviewed work on computing shape from shading and occluding boundaries, including a local parallel algorithm for doing this due to Ikeuchi and Horn 1981; the detection and perception of motion by computing the optical flow and directional selectivity of zero crossings; the interpolation of curves and surfaces; the real-time convolution of images with a difference-of-Gaussians (DOG) operator; and progress toward computing the full primal sketch. Here we review work on stereo to facilitate the computation of depth information and visible surface characteristics, the detction and interpretation of motion, the interpolation and description of visible surfaces, the description of two- and three-dimensional shapes, real-time convolution, and shape from shading. (Author)"
            },
            "slug": "MIT-Progress-in-Understanding-Images-Brady",
            "title": {
                "fragments": [],
                "text": "MIT Progress in Understanding Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Work on stereo to facilitate the computation of depth information and visible surface characteristics, the detction and interpretation of motion, the interpolation and description of visible surfaces, the description of two- and three-dimensional shapes, real-time convolution, and shape from shading is reviewed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298207"
                        ],
                        "name": "P. Kanerva",
                        "slug": "P.-Kanerva",
                        "structuredName": {
                            "firstName": "Pentti",
                            "lastName": "Kanerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanerva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57931704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcdb9bd64e3d7885c10938291153257b94f3df91",
            "isKey": false,
            "numCitedBy": 1008,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nMotivated by the remarkable fluidity of memory the way in which items are pulled spontaneously and effortlessly from our memory by vague similarities to what is currently occupying our attention Sparse Distributed Memory presents a mathematically elegant theory of human long term memory. \nThe book, which is self contained, begins with background material from mathematics, computers, and neurophysiology; this is followed by a step by step development of the memory model. The concluding chapter describes an autonomous system that builds from experience an internal model of the world and bases its operation on that internal model. Close attention is paid to the engineering of the memory, including comparisons to ordinary computer memories. \nSparse Distributed Memory provides an overall perspective on neural systems. The model it describes can aid in understanding human memory and learning, and a system based on it sheds light on outstanding problems in philosophy and artificial intelligence. Applications of the memory are expected to be found in the creation of adaptive systems for signal processing, speech, vision, motor control, and (in general) robots. Perhaps the most exciting aspect of the memory, in its implications for research in neural networks, is that its realization with neuronlike components resembles the cortex of the cerebellum. \nPentti Kanerva is a scientist at the Research Institute for Advanced Computer Science at the NASA Ames Research Center and a visiting scholar at the Stanford Center for the Study of Language and Information. A Bradford Book."
            },
            "slug": "Sparse-Distributed-Memory-Kanerva",
            "title": {
                "fragments": [],
                "text": "Sparse Distributed Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Pentti Kanerva's Sparse Distributed Memory presents a mathematically elegant theory of human long term memory that resembles the cortex of the cerebellum, and provides an overall perspective on neural systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34915378"
                        ],
                        "name": "R. Rohwer",
                        "slug": "R.-Rohwer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rohwer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rohwer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1709501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33fcc09d5b8fe77f7abe926ffb39e9687f361326",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of a radial basis functions network to a static speech pattern classification problem is described. The radial basis functions network offers training times two to three orders of magnitude faster than backpropagation, when training networks of similar power and generality. Recognition results compare well with those obtained using backpropagation and a vector-quantized hidden Markov model on the same problem. A computationally efficient method of exactly solving linear networks in a noniterative fashion is also described. The method was applied to classification of vowels into 20 classes using three different types of input analysis and varying numbers of radial basis functions. The three types of input vectors consisted of linear-prediction-coding cepstral coefficient; formant tracks with frequency, amplitude, and bandwidth information; and bark-scaled formant tracks. All input analyses were supplemented with duration information. The best test results were obtained using the cepstral coefficients and 170 or more radial basis functions.<<ETX>>"
            },
            "slug": "Phoneme-classification-experiments-using-radial-Renals-Rohwer",
            "title": {
                "fragments": [],
                "text": "Phoneme classification experiments using radial basis functions"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The application of a radial basis functions network to a static speech pattern classification problem is described and recognition results compare well with those obtained using backpropagation and a vector-quantized hidden Markov model on the same problem."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50456127"
                        ],
                        "name": "I. J. Schoenberg",
                        "slug": "I.-J.-Schoenberg",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Schoenberg",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. J. Schoenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18673721,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b9a933d2aaeed93d99064f64a8e58814017695ef",
            "isKey": false,
            "numCitedBy": 758,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "As poo we get the space Em with the distance function maxi-, ... I xi X. Let, furthermore, lP stand for the space of real sequences with the series of pth powers of the absolute values convergent. Similarly let LP denote the space of real measurable functions in the interval (0, 1) which are summable to the pth power, while C shall mean the space of real continuous functions in the same interval. In all these spaces a distance function is assumed to be defined as usual. t L2 is equivalent to the real Hilbert space t. The spaces EmP, IP and LP are metric only if p > 1, but we shall consider them also for positive values of p O). A general theorem of Banach and Mazur ([1], p. 187) states that any separable metric space (5 may be imbedded isometrically in the space C. Furthermore, as a special case of a well known theorem of Urysohn, any such space (E may be imbedded topologically in t. Isometric imbeddability of (E in '& is, however, a much more restricted property of (B. The chief purpose of this paper is to point out the intimate relationship between the problem of isometric imbedding and the concept of positive definite functions, if this concept is properly enlarged. As a first approach to this connection we consider here isometric imbedding in Hilbert space only. It turns out that the possibility of imbedding$ in 6& is very easily expressible in terms of the elementary function e-t2 and the concept of positive definite functions (Theorem 1). The author's previous result ([10]) to the effect that i(,y), (O <,y < 1), which is the space arising from 6& by raising its metric to a"
            },
            "slug": "Metric-spaces-and-positive-definite-functions-Schoenberg",
            "title": {
                "fragments": [],
                "text": "Metric spaces and positive definite functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1938
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145847131"
                        ],
                        "name": "S. Kirkpatrick",
                        "slug": "S.-Kirkpatrick",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Kirkpatrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kirkpatrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5882723"
                        ],
                        "name": "C. D. Gelatt",
                        "slug": "C.-D.-Gelatt",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gelatt",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Gelatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88645967"
                        ],
                        "name": "M. Vecchi",
                        "slug": "M.-Vecchi",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Vecchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vecchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205939,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dd5061631a4d11fa394f4421700ebf7e78dcbc59",
            "isKey": false,
            "numCitedBy": 39635,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods."
            },
            "slug": "Optimization-by-Simulated-Annealing-Kirkpatrick-Gelatt",
            "title": {
                "fragments": [],
                "text": "Optimization by Simulated Annealing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2242935"
                        ],
                        "name": "H. L. Resnikoff",
                        "slug": "H.-L.-Resnikoff",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Resnikoff",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. L. Resnikoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120881172,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "75b9bef055d9c0632ae0b230dfd4f70e8a20d06b",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryCertain mathematical principles for the phenomenological description of data are introduced and applied to establish a new psychophysical function for the sensation of brightness. This function, which is the integral of the lognormal probability density function, has the psychophysical functions of Fechner and Stevens as limiting cases. The predictions of the new function are compared with experimental evidence on the discrimination of light intensity by the human eye, and an estimate of the total number of distinct steps of brightness discrimination is determined."
            },
            "slug": "On-the-psychophysical-function-Resnikoff",
            "title": {
                "fragments": [],
                "text": "On the psychophysical function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1952587"
                        ],
                        "name": "J. Keeler",
                        "slug": "J.-Keeler",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Keeler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Keeler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 18330025,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "af7e334e91ca6d7d01085c1e9ba24216ef6fc957",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "The Sparse, Distributed Memory (SDM) model (Kanerva, 1984) is compared to Hopfield-type, neural-network models. A mathematical framework for comparing the two models is developed, and the capacity of each model is investigated. The capacity of the SDM can be increased independent of the dimension of the stored vectors, whereas the Hopfield capacity is limited to a fraction of this dimension. The stored information is proportional to the number of connections, and it is shown that this proportionality constant is the same for the SDM, the Hopfield model, and higher-order models. The models are also compared in their ability to store and recall temporal sequences of patterns. The SDM also includes time delays so that contextual information can be used to recover sequences. A generalization of the SDM allows storage of correlated patterns."
            },
            "slug": "Comparison-Between-Kanerva's-SDM-and-Hopfield-Type-Keeler",
            "title": {
                "fragments": [],
                "text": "Comparison Between Kanerva's SDM and Hopfield-Type Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The Sparse, Distributed Memory model (Kanerva, 1984) is compared to Hopfield-type, neural-network models, and it is shown that this proportionality constant is the same for the SDM, the Hopfield model, and higher-order models."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145733439"
                        ],
                        "name": "G. Wahba",
                        "slug": "G.-Wahba",
                        "structuredName": {
                            "firstName": "Grace",
                            "lastName": "Wahba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wahba"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122703854,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "ae62ecdc61198743267f3756ad54001e150df453",
            "isKey": false,
            "numCitedBy": 772,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider approximate solutions $f_{n,\\lambda } $ to linear operator equations $\\mathcal{K}f = g$, of the form: $f_{n,\\lambda } $ is the minimizer in $\\mathcal{H}$ of $({1 / n})\\sum _{j = 1}^n {[(\\mathcal{K}h)(t_j ) - y(t_j )]} ^2 + \\lambda \\| h \\|^2 $, where $\\mathcal{H}$ is a Hilbert space, and the data $\\{ {y(t_j )} \\}$ satisfy $y(t_j ) = g(t_j ) + \\varepsilon (t_j )$, the $\\{ {\\varepsilon (t_j )} \\}$ being measurement errors. $f_{n,\\lambda } $ is the so-called regularized solution, and $\\lambda > 0$ is the regularization parameter, to be chosen. It is important to choose $\\lambda $ correctly. The purpose of this paper is to propose the method of weighted cross-validation for choosing $\\lambda $from the data. We suppose that g is very smooth and the errors are white noise. It is shown that the weighted cross-validation estimate $\\hat \\lambda $ estimates the value of $\\lambda $ which minimizes $({1 / n})E\\sum\\nolimits_{j = 1}^n {[(\\mathcal{K}f_{n,\\lambda } )(t_j ) - (\\mathcal{K}f)(t_j )]} ^2 $ . Resul..."
            },
            "slug": "Practical-Approximate-Solutions-to-Linear-Operator-Wahba",
            "title": {
                "fragments": [],
                "text": "Practical Approximate Solutions to Linear Operator Equations When the Data are Noisy"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is shown that the weighted cross-validation estimate of $\\hat \\lambda $ estimates the value of $\\lambda $ which minimizes $({1 / n) E\\sum\\nolimits_{j = 1}^n {[(\\mathcal{K}f_{n,\\lambda } )(t_j ) - (\\mathcal(K)f)(t-j )]} ^2 $ ."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16926,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71339631"
                        ],
                        "name": "R. L. Harder",
                        "slug": "R.-L.-Harder",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Harder",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Harder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69374968"
                        ],
                        "name": "R. N. Desmarais",
                        "slug": "R.-N.-Desmarais",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Desmarais",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. N. Desmarais"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119719484,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "67942e80e20420504cc4fa1c030700a9bbdeeb4e",
            "isKey": false,
            "numCitedBy": 761,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A surface spline is a mathematical tool for interpolating a function of two variables. It is based upon the small deflection equation of an infinite plate. The surface spline depends upon the solution of a system of linear equations, and thus, will ordinarily require the use of a digital computer. The closed form solution involves no functions more complicated than logarithms, and is easily coded. Several modifications which can be incorporated are discussed."
            },
            "slug": "Interpolation-using-surface-splines.-Harder-Desmarais",
            "title": {
                "fragments": [],
                "text": "Interpolation using surface splines."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143915028"
                        ],
                        "name": "R. Franke",
                        "slug": "R.-Franke",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Franke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Franke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8290519,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ada9b35388f4cf3b0aa54109e3e87165066842d1",
            "isKey": false,
            "numCitedBy": 2103,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Absract. This paper is concerned with the evaluation of methods for scattered data interpolation and some of the results of the tests when applied to a number of methods. The process involves evaluation of the methods in terms of timing, storage, accuracy, visual pleasantness of the surface, and ease of implementation. To indicate the flavor of the type of results obtained, we give a summary table and representative perspective plots of several surfaces."
            },
            "slug": "Scattered-data-interpolation:-tests-of-some-methods-Franke",
            "title": {
                "fragments": [],
                "text": "Scattered data interpolation: tests of some methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259367"
                        ],
                        "name": "J. Albus",
                        "slug": "J.-Albus",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Albus",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Albus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7157466,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "baa317e95f76f9286c91b1cc8250665d6aaab7fa",
            "isKey": false,
            "numCitedBy": 2395,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Theory-of-Cerebellar-Function-Albus",
            "title": {
                "fragments": [],
                "text": "A Theory of Cerebellar Function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100859010"
                        ],
                        "name": "V. Tikhomirov",
                        "slug": "V.-Tikhomirov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Tikhomirov",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Tikhomirov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116968444,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "300328d09233d3ada652d6aace66353c3bdb5762",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of this paper is to present a brief proof of the following theorem: Theorem. For any integer n \u2265 2 there are continuous real functions \u03c8 p q (x) on the closed unit interval E 1 = [0;1] such that each continuous real function f(x 1 ,\u2026,x n ) on the n-dimensional unit cube E n is representable as \n \n$$f\\left( {{{x}_{1}}, \\ldots ,{{x}_{n}}} \\right) = \\sum\\limits_{{q = 1}}^{{q = 2n + 1}} {Xq\\left[ {\\sum\\limits_{{p = 1}}^{n} {{{\\psi }^{{pq}}}\\left( {{{x}_{p}}} \\right)} } \\right]} ,$$ \n \n(1) \n \nwhere x q (y) are continuous real functions."
            },
            "slug": "On-the-Representation-of-Continuous-Functions-of-as-Tikhomirov",
            "title": {
                "fragments": [],
                "text": "On the Representation of Continuous Functions of Several Variables as Superpositions of Continuous Functions of one Variable and Addition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681850"
                        ],
                        "name": "T. Flash",
                        "slug": "T.-Flash",
                        "structuredName": {
                            "firstName": "Tamar",
                            "lastName": "Flash",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Flash"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145301291"
                        ],
                        "name": "N. Hogan",
                        "slug": "N.-Hogan",
                        "structuredName": {
                            "firstName": "Neville",
                            "lastName": "Hogan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Hogan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18355250,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7d8ac1ed3dc3fc96538372206da015e7dd4b251e",
            "isKey": false,
            "numCitedBy": 4085,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents studies of the coordination of voluntary human arm movements. A mathematical model is formulated which is shown to predict both the qualitative features and the quantitative details observed experimentally in planar, multijoint arm movements. Coordination is modeled mathematically by defining an objective function, a measure of performance for any possible movement. The unique trajectory which yields the best performance is determined using dynamic optimization theory. In the work presented here, the objective function is the square of the magnitude of jerk (rate of change of acceleration) of the hand integrated over the entire movement. This is equivalent to assuming that a major goal of motor coordination is the production of the smoothest possible movement of the hand. Experimental observations of human subjects performing voluntary unconstrained movements in a horizontal plane are presented. They confirm the following predictions of the mathematical model: unconstrained point-to-point motions are approximately straight with bell-shaped tangential velocity profiles; curved motions (through an intermediate point or around an obstacle) have portions of low curvature joined by portions of high curvature; at points of high curvature, the tangential velocity is reduced; the durations of the low-curvature portions are approximately equal. The theoretical analysis is based solely on the kinematics of movement independent of the dynamics of the musculoskeletal system and is successful only when formulated in terms of the motion of the hand in extracorporal space. The implications with respect to movement organization are discussed."
            },
            "slug": "The-coordination-of-arm-movements:-an-confirmed-Flash-Hogan",
            "title": {
                "fragments": [],
                "text": "The coordination of arm movements: an experimentally confirmed mathematical model"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A mathematical model is formulated which is shown to predict both the qualitative features and the quantitative details observed experimentally in planar, multijoint arm movements, and is successful only when formulated in terms of the motion of the hand in extracorporal space."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207116423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9c60b270f2e3e4fd00d55e68177bf7ec69efe64",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with a versatile pictorial prototype based learning scheme for 3D object recognition. The GRBF scheme seems to be amenable to realization in biophysical hardware because the only kind of computation it involves can be effectively carried out by combining receptive fields. Furthermore, the scheme is computationally attractive because it brings together the old notion of a ``grandmother'''' cell and the rigorous approximation methods of regularization and splines."
            },
            "slug": "Bringing-the-Grandmother-back-into-the-Picture:-A-Edelman-Poggio",
            "title": {
                "fragments": [],
                "text": "Bringing the Grandmother back into the Picture: A Memory-Based View of Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The GRBF scheme seems to be amenable to realization in biophysical hardware because the only kind of computation it involves can be effectively carried out by combining receptive fields."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10ddb646feddc12337b5a755c72e153e37088c02",
            "isKey": false,
            "numCitedBy": 4189,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learnt using it in a reasonable (polynomial) number of steps. We find that inherent algorithmic complexity appears to set serious limits to the range of concepts that can be so learnt. The methodology and results suggest concrete principles for designing realistic learning systems."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '84"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190508"
                        ],
                        "name": "N. Grzywacz",
                        "slug": "N.-Grzywacz",
                        "structuredName": {
                            "firstName": "Norberto",
                            "lastName": "Grzywacz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Grzywacz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39137023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "884886d3c701104083311ce57af00c9091bc1a37",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Tliere are a number of important phenom- ena in motion perception involving colicrcnce. Examples include motion capture and motion cooperativity. We propose a theoretical model, called the motion coherence tlieory, that gives a possible explanation for these effects (Yuille and Grzywacz, 1988a,b). In this framework, the aperture problem can also be thought of as a problem of coherence and given a similar explanation. We propose the concept of a velocity field dcfined everywhere in the image, even where there is no explicit motion information available. Through a cost function, tlie model imposes smoothness on the velocity field in a more general way than previous theories. In this paper, we provide a de- tailed theoretical analysis of the motion coherence theory. We discuss its relations with previous theories and show that some of t1ic.m arc approximations to it. A sccorid pa- per (Grzywacz, Smith, and Yuillc, 1088) provides exten- sions and cletnilcd comparisons to psychophysical plienom- cna. Tlic theory applies to both short-range and long- range motion. It places them in the same computational framework aiid provides a way to define interactions be- twcr:11 the two 1)roccsses."
            },
            "slug": "The-Motion-Coherence-Theory-Yuille-Grzywacz",
            "title": {
                "fragments": [],
                "text": "The Motion Coherence Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes the concept of a velocity field everywhere in the image, even where there is no explicit motion information available, through a cost function, which imposes smoothness on the velocity field in a more general way than previous theories."
            },
            "venue": {
                "fragments": [],
                "text": "[1988 Proceedings] Second International Conference on Computer Vision"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103006272"
                        ],
                        "name": "R. L. Hardy",
                        "slug": "R.-L.-Hardy",
                        "structuredName": {
                            "firstName": "Rolland",
                            "lastName": "Hardy",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Hardy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 129508657,
            "fieldsOfStudy": [
                "Mathematics",
                "Geology"
            ],
            "id": "6d4fe26165974d9364a2a19d1f8fc3bc43ee7396",
            "isKey": false,
            "numCitedBy": 2452,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A new analytical method of representing irregular surfaces that involves the summation of equations of quadric surfaces having unknown coefficients is described. The quadric surfaces are located at significant points throughout the region to be mapped. Procedures are given for solving multiquadric equations of topography that are based on coordinate data. Contoured multiquadric surfaces are compared with topography and other irregular surfaces from which the multiquadric equation was derived."
            },
            "slug": "Multiquadric-equations-of-topography-and-other-Hardy",
            "title": {
                "fragments": [],
                "text": "Multiquadric equations of topography and other irregular surfaces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19356,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687119"
                        ],
                        "name": "E. Wegman",
                        "slug": "E.-Wegman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Wegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Wegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1443781833"
                        ],
                        "name": "Janine Guenther",
                        "slug": "Janine-Guenther",
                        "structuredName": {
                            "firstName": "Janine",
                            "lastName": "Guenther",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Janine Guenther"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60277923,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc4da3622da7eae9d94d8ac82fdda4315d914bae",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The 20th Symposium on the Interface: Computing Science and Statistics was held 20-23 April 1988 in Reston, VA. The theme was computationally intensive methods in statistics. Some 60 invited papers, 128 contributed papers were presented to 425 attendees. There was a special focus on young investigators. Sessions were organized into some 49 technical sessions. This report highlights those sessions and presents abstracts of most of the presentations. Also included is a list of attendees and detailed accounting of expenses. An emerging area which received attention in the contributed sessions was on Information Systems, Databases and Statistics. This meeting was also the first to have a serious technical focus which was Computationally Intensive Statistical Methods. Keywords: Computing science, Statistics, Computational statistics, Computationally intensive, Bootstrapping, Parallel computing, Supercomputing, Neural networks."
            },
            "slug": "Symposium-on-the-Interface:-Computing-Science-and-Wegman-Guenther",
            "title": {
                "fragments": [],
                "text": "Symposium on the Interface: Computing Science and Statistics (20th). Theme: Computationally Intensive Methods in Statistics Held in Reston, Virginia on April 20-23, 1988"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The 20th Symposium on the Interface: Computing Science and Statistics was held 20-23 April 1988 in Reston, VA with a serious technical focus which was Computationally Intensive Statistical Methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748400"
                        ],
                        "name": "J. Harris",
                        "slug": "J.-Harris",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Harris",
                            "middleNames": [
                                "G.",
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Harris"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12373236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "987d2f572b38187a33dc57b7ea59156b8a1570ca",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Reconstructing a surface from sparse sensory data is a well-known problem in computer vision. This paper describes an experimental analog VLSI chip for smooth surface interpolation from sparse depth data. An eight-node ID network was designed in 3\u00b5m CMOS and successfully tested. The network minimizes a second-order or \"thin-plate\" energy of the surface. The circuit directly implements the coupled depth/slope model of surface reconstruction (Harris, 1987). In addition, this chip can provide Gaussian-like smoothing of images."
            },
            "slug": "An-Analog-VLSI-Chip-for-Thin-Plate-Surface-Harris",
            "title": {
                "fragments": [],
                "text": "An Analog VLSI Chip for Thin-Plate Surface Interpolation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes an experimental analog VLSI chip for smooth surface interpolation from sparse depth data and can provide Gaussian-like smoothing of images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708279"
                        ],
                        "name": "C. Micchelli",
                        "slug": "C.-Micchelli",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Micchelli",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Micchelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14461054,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9d700e611ee7ffdf54873684a9e8883d3da0bcd7",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Among other things, we prove that multiquadric surface interpolation is always solvable, thereby settling a conjecture of R. Franke."
            },
            "slug": "Interpolation-of-scattered-data:-Distance-matrices-Micchelli",
            "title": {
                "fragments": [],
                "text": "Interpolation of scattered data: Distance matrices and conditionally positive definite functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727567"
                        ],
                        "name": "R. Solomonoff",
                        "slug": "R.-Solomonoff",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Solomonoff",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Solomonoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1673415,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0453028e68581624ec68cfec70214231da8dbce7",
            "isKey": false,
            "numCitedBy": 397,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In 1964 the author proposed as an explication of {\\em a priori} probability the probability measure induced on output strings by a universal Turing machine with unidirectional output tape and a randomly coded unidirectional input tape. Levin has shown that if tilde{P}'_{M}(x) is an unnormalized form of this measure, and P(x) is any computable probability measure on strings, x , then \\tilde{P}'_{M}\\geqCP(x) where C is a constant independent of x . The corresponding result for the normalized form of this measure, P'_{M} , is directly derivable from Willis' probability measures on nonuniversal machines. If the conditional probabilities of P'_{M} are used to approximate those of P , then the expected value of the total squared error in these conditional probabilities is bounded by -(1/2) \\ln C . With this error criterion, and when used as the basis of a universal gambling scheme, P'_{M} is superior to Cover's measure b\\ast . When H\\ast\\equiv -\\log_{2} P'_{M} is used to define the entropy of a rmite sequence, the equation H\\ast(x,y)= H\\ast(x)+H^{\\ast}_{x}(y) holds exactly, in contrast to Chaitin's entropy definition, which has a nonvanishing error term in this equation."
            },
            "slug": "Complexity-based-induction-systems:-Comparisons-and-Solomonoff",
            "title": {
                "fragments": [],
                "text": "Complexity-based induction systems: Comparisons and convergence theorems"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Levin has shown that if tilde{P}'_{M}(x) is an unnormalized form of this measure, and P( x) is any computable probability measure on strings, x, then \\tilde{M}'_M}\\geqCP (x) where C is a constant independent of x ."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516166"
                        ],
                        "name": "J. Rissanen",
                        "slug": "J.-Rissanen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Rissanen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rissanen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30140639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d382b9c11e5c6a8e173fbeb442545e3be8d3e3a5",
            "isKey": false,
            "numCitedBy": 6261,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modeling-By-Shortest-Data-Description*-Rissanen",
            "title": {
                "fragments": [],
                "text": "Modeling By Shortest Data Description*"
            },
            "venue": {
                "fragments": [],
                "text": "Autom."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69892919"
                        ],
                        "name": "S. Mikhlin",
                        "slug": "S.-Mikhlin",
                        "structuredName": {
                            "firstName": "Solomon",
                            "lastName": "Mikhlin",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mikhlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061216146"
                        ],
                        "name": "A. Feinstein",
                        "slug": "A.-Feinstein",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Feinstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Feinstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120194036,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1547a2b978a37349b11aa5ffe966648598c5363f",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-problem-of-the-minimum-of-a-quadratic-Mikhlin-Feinstein",
            "title": {
                "fragments": [],
                "text": "The problem of the minimum of a quadratic functional"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153281777"
                        ],
                        "name": "D. Marr",
                        "slug": "D.-Marr",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Marr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19906341,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "3c6f34131ad83fda26a3d8ca9892a6705fd40d11",
            "isKey": false,
            "numCitedBy": 3071,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "1. A detailed theory of cerebellar cortex is proposed whose consequence is that the cerebellum learns to perform motor skills. Two forms of input\u2014output relation are described, both consistent with the cortical theory. One is suitable for learning movements (actions), and the other for learning to maintain posture and balance (maintenance reflexes)."
            },
            "slug": "A-theory-of-cerebellar-cortex-Marr",
            "title": {
                "fragments": [],
                "text": "A theory of cerebellar cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "A detailed theory of cerebellar cortex is proposed whose consequence is that the cerebellum learns to perform motor skills and two forms of input\u2014output relation are described, both consistent with the cortical theory."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2928927"
                        ],
                        "name": "C. Stanfill",
                        "slug": "C.-Stanfill",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Stanfill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Stanfill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788375"
                        ],
                        "name": "D. Waltz",
                        "slug": "D.-Waltz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Waltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Waltz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16624499,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "123a726f6feb2bce29708b68ab2db5cdf9fcdaf4",
            "isKey": false,
            "numCitedBy": 1436,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "The intensive use of memory to recall specific episodes from the past\u2014rather than rules\u2014should be the foundation of machine reasoning."
            },
            "slug": "Toward-memory-based-reasoning-Stanfill-Waltz",
            "title": {
                "fragments": [],
                "text": "Toward memory-based reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The intensive use of memory to recall specific episodes from the past\u2014rather than rules\u2014should be the foundation of machine reasoning."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144581972"
                        ],
                        "name": "L. Galway",
                        "slug": "L.-Galway",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Galway",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Galway"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 209955551,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2a596bb05686e46a57bf73272b04fd1278bd8a90",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spline-Models-for-Observational-Data-Galway",
            "title": {
                "fragments": [],
                "text": "Spline Models for Observational Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064415384"
                        ],
                        "name": "A. Tikhonov",
                        "slug": "A.-Tikhonov",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Tikhonov",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tikhonov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121508623,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "16758935de5c84616bd1454ec91a9351ee49dbb6",
            "isKey": false,
            "numCitedBy": 2347,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Solution-of-Incorrectly-Formulated-Problems-and-the-Tikhonov",
            "title": {
                "fragments": [],
                "text": "Solution of Incorrectly Formulated Problems and the Regularization Method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103320437"
                        ],
                        "name": "\u85e4\u7530 \u5b8f",
                        "slug": "\u85e4\u7530-\u5b8f",
                        "structuredName": {
                            "firstName": "\u85e4\u7530",
                            "lastName": "\u5b8f",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u85e4\u7530 \u5b8f"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117783920,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "361480a0342399373ff9e2c25c1246f108a9057b",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "S.G.-Mikhlin:-The-Problem-of-the-Minimum-of-a-INC.,-\u85e4\u7530",
            "title": {
                "fragments": [],
                "text": "S.G. Mikhlin: The Problem of the Minimum of a Quadratic Functional, Holden-Day INC., San Francisco, 1965, 155+ix\u9801, 18\u00d725cm, 3,580\u5186."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88308954"
                        ],
                        "name": "I. M. Gel\u02b9fand",
                        "slug": "I.-M.-Gel\u02b9fand",
                        "structuredName": {
                            "firstName": "Izrail\u02b9",
                            "lastName": "Gel\u02b9fand",
                            "middleNames": [
                                "Moiseevich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. M. Gel\u02b9fand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "95197106"
                        ],
                        "name": "N. Vilenkin",
                        "slug": "N.-Vilenkin",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Vilenkin",
                            "middleNames": [
                                "I\ufe20a\ufe21."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vilenkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32549147"
                        ],
                        "name": "A. Feinstein",
                        "slug": "A.-Feinstein",
                        "structuredName": {
                            "firstName": "Amiel",
                            "lastName": "Feinstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Feinstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 106456265,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e8060f8a0c70e31a8c3c708c226b6b450596efa2",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Applications-of-harmonic-analysis-Gel\u02b9fand-Vilenkin",
            "title": {
                "fragments": [],
                "text": "Applications of harmonic analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145394227"
                        ],
                        "name": "J. D. Farmer",
                        "slug": "J.-D.-Farmer",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Farmer",
                            "middleNames": [
                                "Doyne"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Farmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1452639101"
                        ],
                        "name": "John J. Sidorowichl",
                        "slug": "John-J.-Sidorowichl",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Sidorowichl",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John J. Sidorowichl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59693817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07f3f6d430ffca990dee62cb2649bae40c60b380",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Exploiting-Chaos-to-Predict-the-Future-and-Reduce-Farmer-Sidorowichl",
            "title": {
                "fragments": [],
                "text": "Exploiting Chaos to Predict the Future and Reduce Noise"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11458280"
                        ],
                        "name": "J. Aloimonos",
                        "slug": "J.-Aloimonos",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Aloimonos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aloimonos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57154227,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8df9df16c53c010f1853929e8fb3e5b8c3f9f575",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Unification-and-integration-of-visual-modules:-an-Aloimonos",
            "title": {
                "fragments": [],
                "text": "Unification and integration of visual modules: an extension of the Marr Paradigm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121428947"
                        ],
                        "name": "B. Moore",
                        "slug": "B.-Moore",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27650396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "beda6181d7bc64fff81d3c96e4954bf1da900912",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Representation-properties-of-multilayer-feedforward-Moore-Poggio",
            "title": {
                "fragments": [],
                "text": "Representation properties of multilayer feedforward networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145768864"
                        ],
                        "name": "D. Broomhead",
                        "slug": "D.-Broomhead",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Broomhead",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Broomhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159852"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3686496,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b08ba914037af6d88d16e2657a65cd9dc5cf5da1",
            "isKey": false,
            "numCitedBy": 2307,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multivariable-Functional-Interpolation-and-Adaptive-Broomhead-Lowe",
            "title": {
                "fragments": [],
                "text": "Multivariable Functional Interpolation and Adaptive Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808760"
                        ],
                        "name": "S. Omohundro",
                        "slug": "S.-Omohundro",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Omohundro",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Omohundro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44717168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff80b7820fbc54926946c245e139c382266489ae",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficient-Algorithms-with-Neural-Network-Behavior-Omohundro",
            "title": {
                "fragments": [],
                "text": "Efficient Algorithms with Neural Network Behavior"
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43491035,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "072f3eba9251c60e21935821a2410e77492fb93a",
            "isKey": false,
            "numCitedBy": 1199,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Additive-Regression-and-Other-Nonparametric-Models-Stone",
            "title": {
                "fragments": [],
                "text": "Additive Regression and Other Nonparametric Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120511992,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2f0be7ef09295368bb1b1f01945ff337e0d44b39",
            "isKey": false,
            "numCitedBy": 1405,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-Global-Rates-of-Convergence-for-Regression-Stone",
            "title": {
                "fragments": [],
                "text": "Optimal Global Rates of Convergence for Nonparametric Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085838398"
                        ],
                        "name": "I. Omiaj",
                        "slug": "I.-Omiaj",
                        "structuredName": {
                            "firstName": "I",
                            "lastName": "Omiaj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Omiaj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092794854"
                        ],
                        "name": "O. Grant",
                        "slug": "O.-Grant",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Grant",
                            "middleNames": [
                                "David",
                                "Lester"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Grant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082977778"
                        ],
                        "name": "Eleueit",
                        "slug": "Eleueit",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Eleueit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eleueit"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17910142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "347fd669a5a14967e1fc3692acec33031895111a",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extensions-of-a-Theory-of-Networks-for-and-Learning-Omiaj-Grant",
            "title": {
                "fragments": [],
                "text": "Extensions of a Theory of Networks for Approximation and Learning : dimensionality reduction and clustering"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Methods ofMathematical Physics Interscience"
            },
            "venue": {
                "fragments": [],
                "text": "Methods ofMathematical Physics Interscience"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Radial basis functionsfor multivariableinterpotation : A review"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Poggio and the staff MIT progress in understanding images"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings lmage Understanding Workshop"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "La theorie des equations aux deriveespartielles"
            },
            "venue": {
                "fragments": [],
                "text": "Editions Scientifiques"
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiquadrics - a scattered data approximation scheme with applications to computational fluid dynamicsI"
            },
            "venue": {
                "fragments": [],
                "text": "Computers Math . Appl ."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical learning networks: A unifying view"
            },
            "venue": {
                "fragments": [],
                "text": "Symposium on the Interface"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximation by superposition of a sigmoidal function,"
            },
            "venue": {
                "fragments": [],
                "text": "Math. Control Systems Signals, in press,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A theory of cerebellar functions"
            },
            "venue": {
                "fragments": [],
                "text": "Math. Bio"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Regularizations methodsfor linear inverse problems"
            },
            "venue": {
                "fragments": [],
                "text": "lnverse Problems"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Authorized licensed use limited to: IEEE Xplore"
            },
            "venue": {
                "fragments": [],
                "text": "Authorized licensed use limited to: IEEE Xplore"
            },
            "year": 1495
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A network that learnsto recognize 3D objects"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Poggio and the staff , \u201d MIT progress in understanding images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From lmages to Surfaces"
            },
            "venue": {
                "fragments": [],
                "text": "From lmages to Surfaces"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Authorized licensed use limited to: IEEE Xplore"
            },
            "venue": {
                "fragments": [],
                "text": "Authorized licensed use limited to: IEEE Xplore"
            },
            "year": 1497
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the representation of continuous functions of several variables by superposition of continuous functions of one variable and addition Visual algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Physical and Biological Processing of lmages"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Green's Functions and Boundary Problems"
            },
            "venue": {
                "fragments": [],
                "text": "Green's Functions and Boundary Problems"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical learning networks : A unifying view"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Continuous valued neural networks with two hidden layers are sufficient"
            },
            "venue": {
                "fragments": [],
                "text": "Continuous valued neural networks with two hidden layers are sufficient"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Self-Organized Formation of Correct Feature Maps"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An analog VLSl chip for thinplate surface interpolation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Radial basis functionsfor multivariableinterpotation: A review Algorithms for Approximation"
            },
            "venue": {
                "fragments": [],
                "text": "Radial basis functionsfor multivariableinterpotation: A review Algorithms for Approximation"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Methods for Solving lncorrectly Posed Problems"
            },
            "venue": {
                "fragments": [],
                "text": "Methods for Solving lncorrectly Posed Problems"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast learning in networksof locallytuned processing units On optimal nonlinear associative recall"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation Biological Cybernetics"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Networks for learning: A view from the theory of approximation of functions"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the Genoa Summer School on Neural Networks and Their Applications"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Continuous valued neural networks with two hidden layers are sufficient"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the effectiveness of backpropagation learning in trainable N2 nets, and of other related form of discrimination learning, preprint"
            },
            "venue": {
                "fragments": [],
                "text": "On the effectiveness of backpropagation learning in trainable N2 nets, and of other related form of discrimination learning, preprint"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Regularizations methodsfor linear inverse problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vorlesungen ueber Fouriersche Integrale"
            },
            "venue": {
                "fragments": [],
                "text": "Akademische Verlagsgesellschaft"
            },
            "year": 1932
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The geometry of ill-conditioning"
            },
            "venue": {
                "fragments": [],
                "text": "Complexity"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "COnStr. Approx"
            },
            "venue": {
                "fragments": [],
                "text": "COnStr. Approx"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Spline minimizing rotation-invariant semi-norms in Sobolev spaces Constructive Theory of Functions of Several Variables"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Mathematics"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Associate Member, IEEE) was born in Geona, Italy, in 1947. He received the Ph.D. degree in theoretical physics from the University of Genoa"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Resnikoff, \u201cOn the psychophysical function,"
            },
            "venue": {
                "fragments": [],
                "text": "1. Math. Biol.,"
            },
            "year": 1975
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 96,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/Networks-for-approximation-and-learning-Poggio-Girosi/089a76dbc62a06ad30ae1925530e8733e850268e?sort=total-citations"
}