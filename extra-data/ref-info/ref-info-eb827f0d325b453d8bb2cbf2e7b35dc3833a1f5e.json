{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741887"
                        ],
                        "name": "M. Bar",
                        "slug": "M.-Bar",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Bar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 12 ]) devoted to analysis of scene layout [67],"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Research on the mechanisms underlying contextual inference and scene recognition in humans [48], and its neuralcorrelates[ 12 ], willbegin to addressthesequestions and also, in doing so, have far-reaching implications for computer vision,for which context-basedobject recognition is a fast growing area of research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205499985,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bf12813b219ce0730f123bbd3e9c9227d0934f0b",
            "isKey": false,
            "numCitedBy": 1357,
            "numCiting": 178,
            "paperAbstract": {
                "fragments": [],
                "text": "We see the world in scenes, where visual objects occur in rich surroundings, often embedded in a typical context with other related objects. How does the human brain analyse and use these common associations? This article reviews the knowledge that is available, proposes specific mechanisms for the contextual facilitation of object recognition, and highlights important open questions. Although much has already been revealed about the cognitive and cortical mechanisms that subserve recognition of individual objects, surprisingly little is known about the neural underpinnings of contextual analysis and scene perception. Building on previous findings, we now have the means to address the question of how the brain integrates individual elements to construct the visual experience."
            },
            "slug": "Visual-objects-in-context-Bar",
            "title": {
                "fragments": [],
                "text": "Visual objects in context"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Building on previous findings, the knowledge that is available is reviewed, specific mechanisms for the contextual facilitation of object recognition are proposed, and important open questions are highlighted."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Reviews Neuroscience"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060684"
                        ],
                        "name": "M. Castelhano",
                        "slug": "M.-Castelhano",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Castelhano",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Castelhano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5875815,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b35e4d00d9a9bfae83a8b0914eb1073a77a11d78",
            "isKey": false,
            "numCitedBy": 1566,
            "numCiting": 144,
            "paperAbstract": {
                "fragments": [],
                "text": "Many experiments have shown that the human visual system makes extensive use of contextual information for facilitating object search in natural scenes. However, the question of how to formally model contextual influences is still open. On the basis of a Bayesian framework, the authors present an original approach of attentional guidance by global scene context. The model comprises 2 parallel pathways; one pathway computes local features (saliency) and the other computes global (scene-centered) features. The contextual guidance model of attention combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes."
            },
            "slug": "Contextual-guidance-of-eye-movements-and-attention-Torralba-Oliva",
            "title": {
                "fragments": [],
                "text": "Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An original approach of attentional guidance by global scene context is presented that combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For instance, global features have been used to classify images into those that contain a particular object and those that do not [ 18 ,21,51], and this decision is taken without localizing the object within the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent work in computer vision has shown that the identity of real-world scenes might be inferred from aggregated statistics of low-level features (Box 2) and has highlighted the importance of global scene representations as sources of contextual information [11, 18 ,50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1073705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c99f2391b956dc189855541e49e53c21ae5ec603",
            "isKey": false,
            "numCitedBy": 888,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. In fact, the structure of many real-world scenes is governed by strong configurational rules akin to those that apply to a single object. Here we introduce a simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains. The resulting scheme serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "slug": "Contextual-Priming-for-Object-Detection-Torralba",
            "title": {
                "fragments": [],
                "text": "Contextual Priming for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7160604,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4e8862366617f9ce13d603ac9311d396fb2d2e25",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Models of visual attention have focused predominantly on bottom-up approaches that ignored structured contextual and scene information. I propose a model of contextual cueing for attention guidance based onthe global scene configuration. It is shown that the statistics of low-level features across the whole image can be used to prime the presence or absence of objects in the scene and to predict their location, scale, and appearance before exploring the image. In this scheme, visual context information can become available early in the visual processing chain, which allows modulation of the saliency of image regions and provides an efficient shortcut for object detection and recognition."
            },
            "slug": "Modeling-global-scene-factors-in-attention.-Torralba",
            "title": {
                "fragments": [],
                "text": "Modeling global scene factors in attention."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the statistics of low-level features across the whole image can be used to prime the presence or absence of objects in the scene and to predict their location, scale, and appearance before exploring the image."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics, image science, and vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "classifying an image asbeinga beachscene,streetorlivingroom[ 48 ]).Themain characteristic of global image representations is that the sceneisrepresentedasawhole,ratherthansplitting itinto its constituent objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Research on the mechanisms underlying contextual inference and scene recognition in humans [ 48 ], and its neuralcorrelates[12], willbegin to addressthesequestions and also, in doing so, have far-reaching implications for computer vision,for which context-basedobject recognition is a fast growing area of research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2432623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d94fc289d82738a4d1071470b16ba861ea12169",
            "isKey": false,
            "numCitedBy": 1395,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Building-the-gist-of-a-scene:-the-role-of-global-in-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Building the gist of a scene: the role of global image features in recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Progress in brain research"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156786341"
                        ],
                        "name": "tephen E. Palmer",
                        "slug": "tephen-E.-Palmer",
                        "structuredName": {
                            "firstName": "tephen",
                            "lastName": "Palmer",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "tephen E. Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20646799,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "cc9057f0fc18874314a3c1049d93a6749dc36f73",
            "isKey": false,
            "numCitedBy": 631,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This experiment demonstrates the influence of the prior presentation of visual scenes on the identification of briefly presented drawings of real-world objects. Different pairings of objects and scenes were used to produce three main contextual conditions: appropriate, inappropriate, and no context. Correct responses and confusions with visually similar objects depended strongly on both the contextual condition and the particular target object presented. The probability of being correct was highest in the appropriate context condition and lowest in the inappropriate context condition. Confidence ratings of responses were a function of the perceptual similarity between the stimulus object and the named object; they were not strongly affected by contextual conditions. Morton\u2019s (1970) \u201clogogen\u201d model provided a good quantitative fit to the response probability data."
            },
            "slug": "The-effects-of-contextual-scenes-on-the-of-objects-Palmer",
            "title": {
                "fragments": [],
                "text": "The effects of contextual scenes on the identification of objects"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This experiment demonstrates the influence of the prior presentation of visual scenes on the identification of briefly presented drawings of real-world objects using Morton\u2019s (1970) \u201clogogen\u201d model."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11919476,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "697b45e902c9dd2f31d205f0720e7079f71db200",
            "isKey": false,
            "numCitedBy": 838,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we study the statistical properties of natural images belonging to different categories and their relevance for scene and object categorization tasks. We discuss how second-order statistics are correlated with image categories, scene scale and objects. We propose how scene categorization could be computed in a feedforward manner in order to provide top-down and contextual information very early in the visual processing chain. Results show how visual categorization based directly on low-level features, without grouping or segmentation stages, can benefit object localization and identification. We show how simple image statistics can be used to predict the presence and absence of objects in the scene before exploring the image."
            },
            "slug": "Statistics-of-natural-image-categories-Torralba-Oliva",
            "title": {
                "fragments": [],
                "text": "Statistics of natural image categories"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Results show how visual categorization based directly on low-level features, without grouping or segmentation stages, can benefit object localization and identification."
            },
            "venue": {
                "fragments": [],
                "text": "Network"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "texture-based methods [ 50 ,52,69] or \u2018bag-of-words\u2019 models (a term borrowed from the literature on text analysis)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "spatial layout [ 50 ,53]: the image is first divided into regions, and then each region is treated as a bag of words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent work in computer vision has shown that the identity of real-world scenes might be inferred from aggregated statistics of low-level features (Box 2) and has highlighted the importance of global scene representations as sources of contextual information [11,18, 50 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This illustration shows the general scheme underlying many current global scene representations [ 50 ,52,53,55,69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the scene representation proposed in Ref. [ 50 ], the image is first"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11664336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "869171b2f56cfeaa9b81b2626cb4956fea590a57",
            "isKey": false,
            "numCitedBy": 6523,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "slug": "Modeling-the-Shape-of-the-Scene:-A-Holistic-of-the-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153014854"
                        ],
                        "name": "R. J. Mezzanotte",
                        "slug": "R.-J.-Mezzanotte",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mezzanotte",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J. Mezzanotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117606629"
                        ],
                        "name": "J. C. Rabinowitz",
                        "slug": "J.-C.-Rabinowitz",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Rabinowitz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. Rabinowitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16232587,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a5b309957c0113d45458268f2324b36c52ae3f73",
            "isKey": false,
            "numCitedBy": 982,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scene-perception:-Detecting-and-judging-objects-Biederman-Mezzanotte",
            "title": {
                "fragments": [],
                "text": "Scene perception: Detecting and judging objects undergoing relational violations"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864005"
                        ],
                        "name": "G. Alvarez",
                        "slug": "G.-Alvarez",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Alvarez",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Alvarez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In a recent study, Alvarez and Oliva [ 41 ] observed that participants extracted another summary statistic, the center of mass of distractor elements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The statistical properties currently under active investigation are the mean size and variance of a set of objects [40,42\u201344], the center of mass [ 41 ], texture descriptors [45] and also more complex structural information, such as the amount of clutter in an image[46], in additionto themeandepth anddegreeof perspectiveof a natural scene [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8069529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15c01b23685868d5b0011b2732a42ca91ebdc63c",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The representation of visual information inside the focus of attention is more precise than the representation of information outside the focus of attention. We found that the visual system can compensate for the cost of withdrawing attention by pooling noisy local features and computing summary statistics. The location of an individual object is a local feature, whereas the center of mass of several objects (centroid) is a summary feature representing the mean object location. Three experiments showed that withdrawing attention degraded the representation of individual positions more than the representation of the centroid. It appears that information outside the focus of attention can be represented at an abstract level that lacks local detail, but nevertheless carries a precise statistical summary of the scene. The term ensemble features refers to a broad class of statistical summary features that we propose collectively make up the representation of information outside the focus of attention."
            },
            "slug": "The-Representation-of-Simple-Ensemble-Visual-the-of-Alvarez-Oliva",
            "title": {
                "fragments": [],
                "text": "The Representation of Simple Ensemble Visual Features Outside the Focus of Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It appears that information outside the focus of attention can be represented at an abstract level that lacks local detail, but nevertheless carries a precise statistical summary of the scene."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological science"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1936517"
                        ],
                        "name": "J. Fiser",
                        "slug": "J.-Fiser",
                        "structuredName": {
                            "firstName": "J\u00f3zsef",
                            "lastName": "Fiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3065843"
                        ],
                        "name": "R. Aslin",
                        "slug": "R.-Aslin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Aslin",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Aslin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Implicit learning of contextual cues Fiser and Aslin [ 24 ,25] have shown that humans are good at routinely extracting temporal and spatial statistical regularities between objects and do so from an early age."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2647150,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "085353d7751f8ec2da2ca9668b2ad4a84d7c6b4a",
            "isKey": false,
            "numCitedBy": 673,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Three experiments investigated the ability of human observers to extract the joint and conditional probabilities of shape cooccurrences during passive viewing of complex visual scenes. Results indicated that statistical learning of shape conjunctions was both rapid and automatic, as subjects were not instructed to attend to any particular features of the displays. Moreover, in addition to single-shape frequency, subjects acquired in parallel several different higher-order aspects of the statistical structure of the displays, including absolute shape-position relations in an array, shape-pair arrangements independent of position, and conditional probabilities of shape co-occurrences. Unsupervised learning of these higher-order statistics provides support for Barlow's theory of visual recognition, which posits that detecting \u201csuspicious coincidences\u201d of elements during recognition is a necessary prerequisite for efficient learning of new visual features."
            },
            "slug": "Unsupervised-Statistical-Learning-of-Higher-Order-Fiser-Aslin",
            "title": {
                "fragments": [],
                "text": "Unsupervised Statistical Learning of Higher-Order Spatial Structures from Visual Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Unsupervised learning of higher-order statistics provides support for Barlow's theory of visual recognition, which posits that detecting \u201csuspicious coincidences\u201d of elements during recognition is a necessary prerequisite for efficient learning of new visual features."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological science"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173679"
                        ],
                        "name": "Jodi L. Davenport",
                        "slug": "Jodi-L.-Davenport",
                        "structuredName": {
                            "firstName": "Jodi",
                            "lastName": "Davenport",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jodi L. Davenport"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "in addition to Davenport and Potter [3, 66 ], support the existence of such a mechanism."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "that previous observations of contextual influences were owing to a response bias (for a discussion of those results, see Refs [1, 66 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16862268,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "51946f9a6f2eed5eb6d2d2ddbd16e4d2fde392f5",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "How does context influence the perception of objects in scenes? Objects appear in a given setting with surrounding objects. Do objects in scenes exert contextual influences on each other? Do these influences interact with background consistency? In three experiments, we investigated the role of object-to-object context on object and scene perception. Objects (Experiments 1 and 3) and backgrounds (Experiment 2) were reported more accurately when the objects and their settings were consistent than when they were inconsistent, regardless of the number of foreground objects. In Experiment 3, related objects (from the same setting) were reported more accurately than were unrelated objects (from different settings), independently of consistency with the background. Consistent with an interactive model of scene processing, both object-to-object context and object-background context affect object perception."
            },
            "slug": "Consistency-effects-between-objects-in-scenes-Davenport",
            "title": {
                "fragments": [],
                "text": "Consistency effects between objects in scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Objects and backgrounds were reported more accurately when the objects and their settings were consistent than when they were inconsistent, regardless of the number of foreground objects."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6391156"
                        ],
                        "name": "Mark E. Auckland",
                        "slug": "Mark-E.-Auckland",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Auckland",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark E. Auckland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2725750"
                        ],
                        "name": "K. Cave",
                        "slug": "K.-Cave",
                        "structuredName": {
                            "firstName": "Kyle",
                            "lastName": "Cave",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cave"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34815286"
                        ],
                        "name": "N. Donnelly",
                        "slug": "N.-Donnelly",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Donnelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Donnelly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The results of Auckland and collaborators [ 1 ],"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The most documented effect of context on object recognition is the scene consistency\u2013inconsistency effect [ 1 ,5,7,8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15855482,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "babbb93aca5bc4fe9ac19f9572e17be39ec8599a",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous experiments have shown that objects are recognized more readily in a semantically consistent visual context. However, the benefit from context could be explained by response bias, and may not reflect the influence of context on the perceptual processes of recognition. We conducted a six-alternative forced-choice experiment to measure semantic and perceptual errors. A target object appeared briefly, surrounded by four context objects. The target was more accurately identified when the context consisted of objects semantically related to the target. The large number of semantic errors, which increased when the context presentation preceded the target, showed that response bias did account for a proportion of the context effect. Nevertheless, significant facilitation was still present after a bias correction. Recognition of an object can be affected by context not only when it is embedded in a coherent naturalistic scene, but also when it is simply near other related objects. Materials associated with this article may be accessed at www.psychonomic.org/archive."
            },
            "slug": "Nontarget-objects-can-influence-perceptual-during-Auckland-Cave",
            "title": {
                "fragments": [],
                "text": "Nontarget objects can influence perceptual processes during object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A six-alternative forced-choice experiment to measure semantic and perceptual errors showed that response bias did account for a proportion of the context effect, and significant facilitation was still present after a bias correction."
            },
            "venue": {
                "fragments": [],
                "text": "Psychonomic bulletin & review"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403635503"
                        ],
                        "name": "Barbara Hidalgo-Sotelo",
                        "slug": "Barbara-Hidalgo-Sotelo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Hidalgo-Sotelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barbara Hidalgo-Sotelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A topic of current debate is the extent that context affects the speed at which attention is deployed towards the target [26,34], alters target analysis [ 35 ] or biases response selection [36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6325905,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8a9ae98477a766ff740bf0f9ac7d9d99f89ce63b",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Attention allocation in visual search is known to be influenced by low-level image features, visual scene context and top down task constraints. Here, we investigate the role of Contextual priors in guiding visual search by monitoring eye movements as participants search very familiar scenes for a target object. The goal of the study is to identify which stage of the visual search benefits from contextual priors. Two groups of participants differed in the expectation of target presence associated with a scene. Stronger priors are established when a scene exemplar is always associated with the presence of the target than when the scene is periodically observed with and without the target. In both cases, overall search performance improves over repeated presentations of scenes. An analytic decomposition of the time course of the effect of contextual priors shows a time benefit to the exploration stage of search (scan time) and a decrease in gaze duration on the target. The strength of the contextual relationship modulates the magnitude of gaze duration gain, while the scan time gain constitutes one half of the overall search performance benefit regardless of the probability (50% or 100%) of target presence. These data are discussed in terms of the implications of contextdependent scene processing and its putative role in various stages of visual search."
            },
            "slug": "Human-Learning-of-Contextual-Priors-for-Object-does-Hidalgo-Sotelo-Oliva",
            "title": {
                "fragments": [],
                "text": "Human Learning of Contextual Priors for Object Search: Where does the time go?"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The role of Contextual priors in guiding visual search is investigated by monitoring eye movements as participants search very familiar scenes for a target object by identifying which stage of the visual search benefits from contextual priors."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6387937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a2252ccce2b65abc3759149b5c06587cc318e2f",
            "isKey": false,
            "numCitedBy": 3886,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach to learn and recognize natural scene categories. Unlike previous work, it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a \"theme\". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes."
            },
            "slug": "A-Bayesian-hierarchical-model-for-learning-natural-Fei-Fei-Perona",
            "title": {
                "fragments": [],
                "text": "A Bayesian hierarchical model for learning natural scene categories"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This work proposes a novel approach to learn and recognize natural scene categories by representing the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent work in computer vision has shown that the identity of real-world scenes might be inferred from aggregated statistics of low-level features (Box 2) and has highlighted the importance of global scene representations as sources of contextual information [ 11 ,18,50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6152006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4081e007d7eced95cc618164e976a80d44ff5f4e",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Image understanding requires not only individually estimating elements of the visual world but also capturing the interplay among them. In this paper, we provide a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint. Most object detection methods consider all scales and locations in the image as equally likely. We show that with probabilistic estimates of 3D geometry, both in terms of surfaces and world coordinates, we can put objects into perspective and model the scale and location variance in the image. Our approach reflects the cyclical nature of the problem by allowing probabilistic object hypotheses to refine geometry and vice-versa. Our framework allows painless substitution of almost any object detector and is easily extended to include other aspects of image understanding. Our results confirm the benefits of our integrated approach."
            },
            "slug": "Putting-Objects-in-Perspective-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Putting Objects in Perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper provides a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint by allowing probabilistic object hypotheses to refine geometry and vice-versa."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709721"
                        ],
                        "name": "N. Gronau",
                        "slug": "N.-Gronau",
                        "structuredName": {
                            "firstName": "Nurit",
                            "lastName": "Gronau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gronau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144448112"
                        ],
                        "name": "M. Neta",
                        "slug": "M.-Neta",
                        "structuredName": {
                            "firstName": "Maital",
                            "lastName": "Neta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Neta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741887"
                        ],
                        "name": "M. Bar",
                        "slug": "M.-Bar",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Bar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[68]), and spatial and nonspatial associations [13, 16 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16287131,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "e4dabb31c50a0df713ad8362c4a12d7a9e0e8cb3",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 109,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual context plays a prominent role in everyday perception. Contextual information can facilitate recognition of objects within scenes by providing predictions about objects that are most likely to appear in a specific setting, along with the locations that are most likely to contain objects in the scene. Is such identity-related (semantic) and location-related (spatial) contextual knowledge represented separately or jointly as a bound representation? We conducted a functional magnetic resonance imaging (fMRI) priming experiment whereby semantic and spatial contextual relations between prime and target object pictures were independently manipulated. This method allowed us to determine whether the two contextual factors affect object recognition with or without interacting, supporting a unified versus independent representations, respectively. Results revealed a Semantic Spatial interaction in reaction times for target object recognition. Namely, significant semantic priming was obtained when targets were positioned in expected (congruent), but not in unexpected (incongruent), locations. fMRI results showed corresponding interactive effects in brain regions associated with semantic processing (inferior prefrontal cortex), visual contextual processing (parahippocampal cortex), and object-related processing (lateral occipital complex). In addition, activation in fronto-parietal areas suggests that attention and memory-related processes might also contribute to the contextual effects observed. These findings indicate that object recognition benefits from associative representations that integrate information about objects' identities and their locations, and directly modulate activation in object-processing cortical regions. Such context frames are useful in maintaining a coherent and meaningful representation of the visual world, and in providing a platform from which predictions can be generated to facilitate perception and action."
            },
            "slug": "Integrated-Contextual-Representation-for-Objects'-Gronau-Neta",
            "title": {
                "fragments": [],
                "text": "Integrated Contextual Representation for Objects' Identities and Their Locations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "These findings indicate that object recognition benefits from associative representations that integrate information about objects' identities and their locations, and directly modulate activation in object-processing cortical regions."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48670889"
                        ],
                        "name": "Kao-Ping Chua",
                        "slug": "Kao-Ping-Chua",
                        "structuredName": {
                            "firstName": "Kao-Ping",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kao-Ping Chua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3286262"
                        ],
                        "name": "M. Chun",
                        "slug": "M.-Chun",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Chun",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "But transfer is significantly impaired by changes in viewpoint [ 29 ] or scene identity [30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11775020,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6e177a02c9e3946933a4a3135a68b4ed4b6f927b",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "When novel scenes are encoded, the representations of scene layout are generally viewpoint specific. Past studies of scene recognition have typically required subjects to explicitly study and encode novel scenes, but in everyday visual experience, it is possible that much scene learning occurs incidentally. Here, we examine whether implicitly encoded scene layouts are also viewpoint dependent. We used the contextual cuing paradigm, in which search for a target is facilitated by implicitly learned associations between target locations and novel spatial contexts (Chun & Jiang, 1998). This task was extended to naturalistic search arrays with apparent depth. To test viewpoint dependence, the viewpoint of the scenes was varied from training to testing. Contextual cuing and, hence, scene context learning decreased as the angular rotation from training viewpoint increased. This finding suggests that implicitly acquired representations of scene layout are viewpoint dependent."
            },
            "slug": "Implicit-scene-learning-is-viewpoint-dependent-Chua-Chun",
            "title": {
                "fragments": [],
                "text": "Implicit scene learning is viewpoint dependent"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work used the contextual cuing paradigm, in which search for a target is facilitated by implicitly learned associations between target locations and novel spatial contexts, and this task was extended to naturalistic search arrays with apparent depth to suggest viewpoint dependence."
            },
            "venue": {
                "fragments": [],
                "text": "Perception & psychophysics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796908"
                        ],
                        "name": "D. Ariely",
                        "slug": "D.-Ariely",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ariely",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ariely"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In a crucial paper, Ariely [ 40 ] found that, after presenting observers with a set of circular spots of various sizes for 500 ms, observers could judge the average size of the spots better than the sizes of individuals in the set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6435925,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5494c4ca523c5ef1999941e27c5248cea907c7af",
            "isKey": false,
            "numCitedBy": 728,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Sets of similar objects are common occurrences\u2014a crowd of people, a bunch of bananas, a copse of trees, a shelf of books, a line of cars. Each item in the set may be distinct, highly visible, and discriminable. But when we look away from the set, what information do we have? The current article starts to address this question by introducing the idea of a set representation. This idea was tested using two new paradigms: mean discrimination and member identification. Three experiments using sets of different-sized spots showed that observers know a set's mean quite accurately but know little about the individual items, except their range. Taken together, these results suggest that the visual system represents the overall statistical, and not individual, properties of sets."
            },
            "slug": "Seeing-Sets:-Representation-by-Statistical-Ariely",
            "title": {
                "fragments": [],
                "text": "Seeing Sets: Representation by Statistical Properties"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "Three experiments showed that observers know a set's mean quite accurately but know little about the individual items, except their range, which suggests that the visual system represents the overall statistical, and not individual, properties of sets."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological science"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741887"
                        ],
                        "name": "M. Bar",
                        "slug": "M.-Bar",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Bar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2240829"
                        ],
                        "name": "E. Aminoff",
                        "slug": "E.-Aminoff",
                        "structuredName": {
                            "firstName": "Elissa",
                            "lastName": "Aminoff",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Aminoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 559150,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "46a2d5effc3cc1b6da662d4ab95deeb321eba9fe",
            "isKey": false,
            "numCitedBy": 561,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cortical-Analysis-of-Visual-Context-Bar-Aminoff",
            "title": {
                "fragments": [],
                "text": "Cortical Analysis of Visual Context"
            },
            "venue": {
                "fragments": [],
                "text": "Neuron"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For instance, global features have been used to classify images into those that contain a particular object and those that do not [18, 21 ,51], and this decision is taken without localizing the object within the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In a recent study, Davenport and Potter [3] observed that consistency information influences perception of both the object and the scene background if a scene is presented briefly (80 ms), which suggests a recurrent processing framework, in which objects and their settings influence each other mutually [ 21 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 419324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a4300efb6895695205dfc1b74e124f9fea6aff2",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard approaches to object detection focus on local patches of the image, and try to classify them as background or not. We propose to use the scene context (image as a whole) as an extra source of (global) information, to help resolve local ambiguities. We present a conditional random field for jointly solving the tasks of object detection and scene classification."
            },
            "slug": "Using-the-Forest-to-See-the-Trees:-A-Graphical-and-Murphy-Torralba",
            "title": {
                "fragments": [],
                "text": "Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a conditional random field for jointly solving the tasks of object detection and scene classification, and proposes to use the scene context as an extra source of (global) information, to help resolve local ambiguities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173679"
                        ],
                        "name": "Jodi L. Davenport",
                        "slug": "Jodi-L.-Davenport",
                        "structuredName": {
                            "firstName": "Jodi",
                            "lastName": "Davenport",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jodi L. Davenport"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944906"
                        ],
                        "name": "M. Potter",
                        "slug": "M.-Potter",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Potter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Potter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "in addition to Davenport and Potter [ 3 ,66], support the existence of such a mechanism."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In a recent study, Davenport and Potter [ 3 ] observed that consistency information influences perception of both the object and the scene background if a scene is presented briefly (80 ms), which suggests a recurrent processing framework, in which objects and their settings influence each other mutually [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2092200,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f90116766947c0fcb060551d446e6777dc5cd1f4",
            "isKey": false,
            "numCitedBy": 446,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Does knowledge about which objects and settings tend to co-occur affect how people interpret an image? The effects of consistency on perception were investigated using manipulated photographs containing a foreground object that was either semantically consistent or inconsistent with its setting. In four experiments, participants reported the foreground object, the setting, or both after seeing each picture for 80 ms followed by a mask. In Experiment 1, objects were identified more accurately in a consistent than an inconsistent setting. In Experiment 2, backgrounds were identified more accurately when they contained a consistent rather than an inconsistent foreground object. In Experiment 3, objects were presented without backgrounds and backgrounds without objects; comparison with the other experiments indicated that objects were identified better in isolation than when presented with a background, but there was no difference in accuracy for backgrounds whether they appeared with a foreground object or not. Finally, in Experiment 4, consistency effects remained when both objects and backgrounds were reported. Semantic consistency information is available when a scene is glimpsed briefly and affects both object and background perception. Objects and their settings are processed interactively and not in isolation."
            },
            "slug": "Scene-Consistency-in-Object-and-Background-Davenport-Potter",
            "title": {
                "fragments": [],
                "text": "Scene Consistency in Object and Background Perception"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Comparison with the other experiments indicated that objects were identified better in isolation than when presented with a background, but there was no difference in accuracy for backgrounds whether they appeared with a foreground object or not."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological science"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398995671"
                        ],
                        "name": "Michel Vidal-Naquet",
                        "slug": "Michel-Vidal-Naquet",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Vidal-Naquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Vidal-Naquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35195550"
                        ],
                        "name": "E. Sali",
                        "slug": "E.-Sali",
                        "structuredName": {
                            "firstName": "Erez",
                            "lastName": "Sali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sali"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the same way that the representation of an object can be mediated by features that do not correspond to nameable parts [ 39 ], the representation of the scene context can also be built on elements that do not correspond to objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205441432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d52be22dc0033293d335b6dc5cf3e3588c1fc0bc",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system analyzes shapes and objects in a series of stages in which stimulus features of increasing complexity are extracted and analyzed. The first stages use simple local features, and the image is subsequently represented in terms of larger and more complex features. These include features of intermediate complexity and partial object views. The nature and use of these higher-order representations remains an open question in the study of visual processing by the primate cortex. Here we show that intermediate complexity (IC) features are optimal for the basic visual task of classification. Moderately complex features are more informative for classification than very simple or very complex ones, and so they emerge naturally by the simple coding principle of information maximization with respect to a class of images. Our findings suggest a specific role for IC features in visual processing and a principle for their extraction."
            },
            "slug": "Visual-features-of-intermediate-complexity-and-use-Ullman-Vidal-Naquet",
            "title": {
                "fragments": [],
                "text": "Visual features of intermediate complexity and their use in classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that intermediate complexity (IC) features are optimal for the basic visual task of classification and suggest a specific role for IC features in visual processing and a principle for their extraction."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4910863"
                        ],
                        "name": "A. Hollingworth",
                        "slug": "A.-Hollingworth",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hollingworth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hollingworth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15775747,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0d660cd5e2449f08604e99c6c50d6573679b0341",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Changes to objects that are inconsistent with the scene in which they appear are detected more accurately than changes to consistent objects. In three experiments, we tested whether this inconsistent object advantage derives from the differential retention of conceptual codes generated from a brief view of a real-world scene in accordance with a conceptual short-term memory (CSTM) hypothesis. A scene was presented for 250 msec, followed by a brief mask and a test scene in which a target object was either changed or not changed. In Experiment 1, changes that altered conceptual content (object deletion) were contrasted with visual changes (left-right orientation changes). In Experiment 2, the duration of the mask was manipulated to vary the amount of time available for conceptual consolidation of the initial scene. In Experiment 3, the type of mask was manipulated: Either a meaningless pattern mask or a meaningful, and thus conceptually disruptive, scene was shown. The inconsistent object advantage was obtained in each experiment, yet in none was it modulated in the direction predicted by the CSTM hypothesis. Instead, the inconsistent object advantage is likely to be caused by contextual influence on memory for visual object representations."
            },
            "slug": "Testing-a-conceptual-locus-for-the-inconsistent-in-Hollingworth-Henderson",
            "title": {
                "fragments": [],
                "text": "Testing a conceptual locus for the inconsistent object change detection advantage in real-world scenes."
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The inconsistent object advantage is likely to be caused by contextual influence on memory for visual object representations, and not from the differential retention of conceptual codes generated from a brief view of a real-world scene in accordance with a conceptual short-term memory hypothesis."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1936517"
                        ],
                        "name": "J. Fiser",
                        "slug": "J.-Fiser",
                        "structuredName": {
                            "firstName": "J\u00f3zsef",
                            "lastName": "Fiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3065843"
                        ],
                        "name": "R. Aslin",
                        "slug": "R.-Aslin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Aslin",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Aslin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16586551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d66d6c8944d6e62b018300bd58885017a764896e",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors investigated how human adults encode and remember parts of multielement scenes composed of recursively embedded visual shape combinations. The authors found that shape combinations that are parts of larger configurations are less well remembered than shape combinations of the same kind that are not embedded. Combined with basic mechanisms of statistical learning, this embeddedness constraint enables the development of complex new features for acquiring internal representations efficiently without being computationally intractable. The resulting representations also encode parts and wholes by chunking the visual input into components according to the statistical coherence of their constituents. These results suggest that a bootstrapping approach of constrained statistical learning offers a unified framework for investigating the formation of different internal representations in pattern and scene perception."
            },
            "slug": "Encoding-multielement-scenes:-statistical-learning-Fiser-Aslin",
            "title": {
                "fragments": [],
                "text": "Encoding multielement scenes: statistical learning of visual feature hierarchies."
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The authors found that shape combinations that are parts of larger configurations are less well remembered than shape combinations of the same kind that are not embedded."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. General"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3286262"
                        ],
                        "name": "M. Chun",
                        "slug": "M.-Chun",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Chun",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144648366"
                        ],
                        "name": "Yuhong V. Jiang",
                        "slug": "Yuhong-V.-Jiang",
                        "structuredName": {
                            "firstName": "Yuhong",
                            "lastName": "Jiang",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhong V. Jiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1955059,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "ff1c9b87dfd0663aef303e4ecf1734a6495bb488",
            "isKey": false,
            "numCitedBy": 1748,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "Global context plays an important, but poorly understood, role in visual tasks. This study demonstrates that a robust memory for visual context exists to guide spatial attention. Global context was operationalized as the spatial layout of objects in visual search displays. Half of the configurations were repeated across blocks throughout the entire session, and targets appeared within consistent locations in these arrays. Targets appearing in learned configurations were detected more quickly. This newly discovered form of search facilitation is termed contextual cueing. Contextual cueing is driven by incidentally learned associations between spatial configurations (context) and target locations. This benefit was obtained despite chance performance for recognizing the configurations, suggesting that the memory for context was implicit. The results show how implicit learning and memory of visual context can guide spatial attention towards task-relevant aspects of a scene."
            },
            "slug": "Contextual-Cueing:-Implicit-Learning-and-Memory-of-Chun-Jiang",
            "title": {
                "fragments": [],
                "text": "Contextual Cueing: Implicit Learning and Memory of Visual Context Guides Spatial Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results show how implicit learning and memory of visual context can guide spatial attention towards task-relevant aspects of a scene."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136978"
                        ],
                        "name": "Michelle R. Greene",
                        "slug": "Michelle-R.-Greene",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Greene",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michelle R. Greene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 302409,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d498e66d0d18bc07e6d3188467baa133ed324d3b",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural Scene Categorization from Conjunctions of Ecological Global Properties Michelle R. Greene (mrgreene@mit.edu) Aude Oliva (oliva@mit.edu) Department of Brain and Cognitive Sciences Massachusetts Institute of Technology Cambridge, MA 02139 visual processing, enabling the rapid estimation of scene gist. The behavioral and modeling experiments we propose here are meant to establish the psychological foundation of a scene-centered approach to scene understanding. Beyond the principle of recognizing the \u201cforest before the trees\u201d (Navon, 1977), we propose an operational definition of the global scene properties permitting the categorization of a scene as a \u201cforest\u201d. Faithful to a scene-centered representation which will capture the completeness of the gist of a scene, our selection of a vocabulary of global scene properties was influenced by the requirement to describe structural, functional and surface-based features of an environmental scene. Namely, which properties of a space allow the description of its semantic category, function and affordance? Previous research has shown that global properties of mean depth, openness and expansion describe the spatial layout of a scene well enough to be predictive of its probable semantic category (Oliva & Torralba, 2001). Properties of navigability and camouflage reflect the functionality of the space and the type of actions that can be afforded in outdoor natural scenes. Movement (i.e. the transience of the elements in the scene) and temperature are relevant surface-based properties that influence human\u2019s behavior, and refer to the material and texture qualities of image regions (i.e. rocky and sandy often imply hot and non-moving, while snow implies cold and rushing water implies movement). These properties have been shown in previous work to be available for report with less exposure time than the semantic category of an image (Greene & Oliva, 2005). The seven global properties we describe here are ecological in the sense that they are descriptive of the types of interactions a human could have in an outdoor natural landscape (e.g. can walk through without worry of occluding objects), or are descriptive of the space of a scene (e.g a panoramic environment), which can in turn, guide behavior. It is of note that such a scene-centered representation has no explicit declaration of objects or region segmentation. Outdoor scenes have few objects that can be manipulated and interacted with by a human (e.g. a rock, a flower), but their size is almost entirely local and therefore not captured by global properties. Our principal hypothesis is that the initial image representation that facilitates semantic scene categorization can be built from the conjunctive detection of ecological Abstract Human scene understanding is remarkable: with only a brief glance at an image, an abundance of information is available - spatial layout, scene function, semantic label, etc. Here we propose a scene-centered model of rapid human scene understanding that uses a vocabulary of global, ecological scene properties that combine to categorize natural landscape images. Behaviorally, we show human observers are sensitive to the underlying distributions of these global properties for use in basic-level categorization. An ideal observer trained only on the distributions of these properties predicts human scene categorization performance (r=0.90) and human errors. Introduction Human scene understanding is truly remarkable: with the briefest of glimpses at an image, we instantaneously understand its content and meaning (Potter, 1975; Thorpe et al., 1996). Even more striking is the richness of the variety of information perceived within a glance: a few objects, spatial layout, functional and conceptual properties and even emotional valence (Maljkovic and Martini, 2005) are all available with well under 100 msec of exposure to a novel image. The entirety of this information is termed a scene\u2019s gist (Oliva, 2005). What is the nature of the representation that mediates rapid scene categorization? To the contrary of the traditional ideas of research in scene understanding that treat objects as the atoms of recognition, we consider that real world scenes can be recognized without necessarily identifying the objects they contain (Biederman et al, 1982; Greene and Oliva, 2005; Schyns & Oliva, 1994; Oliva & Schyns, 2000). This scene- centered approach to recognition emphasizes properties describing the structure and the meaning of the whole scene independent of object analysis. Recent computational models of scene recognition have shown indeed that a variety of low level features (color, texture) and spatial layout properties (e.g. its level of openness, perspective) are correlated with the semantic category of environmental scenes at both superordinate and basic level of representation (Fei Fei & Perona, 2005; Oliva & Torralba, 2001; Walker-Renninger and Malik, 2001; Torralba & Oliva, 2003; Vogel & Schiele, 2004). A scene-centered schema would not preclude local object recognition, but would serve as a feed-forward and parallel pathway of"
            },
            "slug": "Natural-Scene-Categorization-from-Conjunctions-of-Greene-Oliva",
            "title": {
                "fragments": [],
                "text": "Natural Scene Categorization from Conjunctions of Ecological Global Properties"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4351871"
                        ],
                        "name": "J. Brockmole",
                        "slug": "J.-Brockmole",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Brockmole",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Brockmole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060684"
                        ],
                        "name": "M. Castelhano",
                        "slug": "M.-Castelhano",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Castelhano",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Castelhano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "But transfer is significantly impaired by changes in viewpoint [29] or scene identity [ 30 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1263714,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "42feb4e431c1f8a6d914658fea20eda0549c7ca8",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In contextual cueing, the position of a target within a group of distractors is learned over repeated exposure to a display with reference to a few nearby items rather than to the global pattern created by the elements. The authors contrasted the role of global and local contexts for contextual cueing in naturalistic scenes. Experiment 1 showed that learned target positions transfer when local information is altered but not when global information is changed. Experiment 2 showed that scene-target covariation is learned more slowly when local, but not global, information is repeated across trials than when global but not local information is repeated. Thus, in naturalistic scenes, observers are biased to associate target locations with global contexts."
            },
            "slug": "Contextual-cueing-in-naturalistic-scenes:-Global-Brockmole-Castelhano",
            "title": {
                "fragments": [],
                "text": "Contextual cueing in naturalistic scenes: Global and local contexts."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The authors contrasted the role of global and local contexts for contextual cueing in naturalistic scenes to show that learned target positions transfer when local information is altered but not when global information is changed."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Learning, memory, and cognition"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7326223"
                        ],
                        "name": "L. Itti",
                        "slug": "L.-Itti",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Itti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Itti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2329233,
            "fieldsOfStudy": [
                "Psychology",
                "Biology",
                "Computer Science"
            ],
            "id": "320b36777d57e772d88d278ceeccd1f5e746304c",
            "isKey": false,
            "numCitedBy": 4166,
            "numCiting": 164,
            "paperAbstract": {
                "fragments": [],
                "text": "Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention."
            },
            "slug": "Computational-modelling-of-visual-attention-Itti-Koch",
            "title": {
                "fragments": [],
                "text": "Computational modelling of visual attention"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment, providing a framework for a computational and neurobiological understanding of visual attention."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Reviews Neuroscience"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149808992"
                        ],
                        "name": "C. Green",
                        "slug": "C.-Green",
                        "structuredName": {
                            "firstName": "Collin",
                            "lastName": "Green",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725887"
                        ],
                        "name": "J. Hummel",
                        "slug": "J.-Hummel",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hummel",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hummel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Green and Hummel [ 23 ] found that mechanisms of object perception are sensitive to the relative pose of pairs of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16175828,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d55423713384567ce0f1aa5912b7628c87e10e26",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Identification of objects in a scene may be influenced by functional relations among those objects. In this study, observers indicated whether a target object matched a label. Each target was presented with a distractor object, and these were sometimes arranged to interact (as if being used together) and sometimes not to interact. When the distractor was semantically related to the label, identification was more accurate for targets arranged to interact with that distractor. This effect depended on observers' ability to perceptually integrate the stimulus objects, suggesting that it was perceptual in nature. The effect was not attributable to attentional cuing and did not depend on expectation of certain object pairs. These data suggest that familiar functional groupings of objects are perceptually grouped."
            },
            "slug": "Familiar-interacting-object-pairs-are-perceptually-Green-Hummel",
            "title": {
                "fragments": [],
                "text": "Familiar interacting object pairs are perceptually grouped."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "In this study, observers indicated whether a target object matched a label, which suggests that familiar functional groupings of objects are perceptually grouped."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This illustration shows the general scheme underlying many current global scene representations [50,52, 53 ,55,69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "spatial layout [50, 53 ]: the image is first divided into regions, and then each region is treated as a bag of words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "the patch into 4 4 regions and computing the histogram of local image gradients within each region) [52, 53 ,55]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": true,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34854785"
                        ],
                        "name": "Russell A. Epstein",
                        "slug": "Russell-A.-Epstein",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Epstein",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Russell A. Epstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1931482"
                        ],
                        "name": "N. Kanwisher",
                        "slug": "N.-Kanwisher",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Kanwisher",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kanwisher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 920141,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "46ec521e3f4c89218db0292a097f0f44d17c753d",
            "isKey": false,
            "numCitedBy": 2725,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Medial temporal brain regions such as the hippocampal formation and parahippocampal cortex have been generally implicated in navigation and visual memory. However, the specific function of each of these regions is not yet clear. Here we present evidence that a particular area within human parahippocampal cortex is involved in a critical component of navigation: perceiving the local visual environment. This region, which we name the \u2018parahippocampal place area\u2019 (PPA), responds selectively and automatically in functional magnetic resonance imaging (fMRI) to passively viewed scenes, but only weakly to single objects and not at all to faces. The critical factor for this activation appears to be the presence in the stimulus of information about the layout of local space. The response in the PPA to scenes with spatial layout but no discrete objects (empty rooms) is as strong as the response to complex meaningful scenes containing multiple objects (the same rooms furnished) and over twice as strong as the response to arrays of multiple objects without three-dimensional spatial context (the furniture from these rooms on a blank background). This response is reduced if the surfaces in the scene are rearranged so that they no longer define a coherent space. We propose that the PPA represents places by encoding the geometry of the local environment."
            },
            "slug": "A-cortical-representation-of-the-local-visual-Epstein-Kanwisher",
            "title": {
                "fragments": [],
                "text": "A cortical representation of the local visual environment"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Evidence is presented that a particular area within human parahippocampal cortex is involved in a critical component of navigation: perceiving the local visual environment, and it is proposed that the PPA represents places by encoding the geometry of the local environment."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070049014"
                        ],
                        "name": "R. D. Gordon",
                        "slug": "R.-D.-Gordon",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gordon",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. D. Gordon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24734207,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "266443d51bdad64d8c1bc4a8d2897b55dad4b681",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic influences on attention during the 1st fixation on a scene were explored in 3 experiments. Subjects viewed briefly presented scenes; following scene presentation, a spatial probe was presented at the location of an object whose identity was consistent or inconsistent with the scene category. Responses to the probe served as an index of attention. The results of Experiment 1 suggest that within approximately 150 ms of scene onset, subjects attend preferentially to inconsistent objects. The results of Experiment 2, in which additional scene durations were used, confirm the presence of an inconsistent-object advantage that emerges within approximately 150 ms. Finally, the results of Experiment 3 demonstrate that the inconsistent-object advantage does not reflect strategic allocation of attention to likely probe locations. Implications of the results for scene perception and exploration are discussed."
            },
            "slug": "Attentional-allocation-during-the-perception-of-Gordon",
            "title": {
                "fragments": [],
                "text": "Attentional allocation during the perception of scenes."
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Semantic influences on attention during the 1st fixation on a scene were explored in 3 experiments and it is suggested that within approximately 150 ms of scene onset, subjects attend preferentially to inconsistent objects."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2827898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b7c4096ed697696a5f4fc8f3a6a750dc0cdecfe",
            "isKey": false,
            "numCitedBy": 6727,
            "numCiting": 410,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a review of 200 references in content-based image retrieval. The paper starts with discussing the working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss computational steps for image retrieval systems. Step one of the review is image processing for retrieval sorted by color, texture, and local geometry. Features for retrieval are discussed next, sorted by: accumulative and global features, salient points, object and shape features, signs, and structural combinations thereof. Similarity of pictures and objects in pictures is reviewed for each of the feature types, in close connection to the types and means of feedback the user of the systems is capable of giving by interaction. We briefly discuss aspects of system engineering: databases, system architecture, and evaluation. In the concluding section, we present our view on: the driving force of the field, the heritage from computer vision, the influence on computer vision, the role of similarity and of interaction, the need for databases, the problem of evaluation, and the role of the semantic gap."
            },
            "slug": "Content-Based-Image-Retrieval-at-the-End-of-the-Smeulders-Worring",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval at the End of the Early Years"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap are discussed, as well as aspects of system engineering: databases, system architecture, and evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727853"
                        ],
                        "name": "John K. Tsotsos",
                        "slug": "John-K.-Tsotsos",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tsotsos",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John K. Tsotsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2888197"
                        ],
                        "name": "Sean M. Culhane",
                        "slug": "Sean-M.-Culhane",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Culhane",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean M. Culhane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676061"
                        ],
                        "name": "W. Y. Wai",
                        "slug": "W.-Y.-Wai",
                        "structuredName": {
                            "firstName": "Winky",
                            "lastName": "Wai",
                            "middleNames": [
                                "Yan",
                                "Kei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Y. Wai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399956386"
                        ],
                        "name": "Yuzhong Lai",
                        "slug": "Yuzhong-Lai",
                        "structuredName": {
                            "firstName": "Yuzhong",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuzhong Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070037776"
                        ],
                        "name": "Neal Davis",
                        "slug": "Neal-Davis",
                        "structuredName": {
                            "firstName": "Neal",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neal Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397804046"
                        ],
                        "name": "Fernando Nuflo",
                        "slug": "Fernando-Nuflo",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Nuflo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Nuflo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 32094988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8930f62a4b5eb1cbabf224cf84aa009ea798cfee",
            "isKey": false,
            "numCitedBy": 1211,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modeling-Visual-Attention-via-Selective-Tuning-Tsotsos-Culhane",
            "title": {
                "fragments": [],
                "text": "Modeling Visual Attention via Selective Tuning"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40538579"
                        ],
                        "name": "J. Vogel",
                        "slug": "J.-Vogel",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12322757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e264e1e55433f158bf8aa8b260bf430d76d5fa28",
            "isKey": false,
            "numCitedBy": 429,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel image representation that renders it possible to access natural scenes by local semantic description. Our work is motivated by the continuing effort in content-based image retrieval to extract and to model the semantic content of images. The basic idea of the semantic modeling is to classify local image regions into semantic concept classes such as water, rocks, or foliage. Images are represented through the frequency of occurrence of these local concepts. Through extensive experiments, we demonstrate that the image representation is well suited for modeling the semantic content of heterogenous scene categories, and thus for categorization and retrieval.The image representation also allows us to rank natural scenes according to their semantic similarity relative to certain scene categories. Based on human ranking data, we learn a perceptually plausible distance measure that leads to a high correlation between the human and the automatically obtained typicality ranking. This result is especially valuable for content-based image retrieval where the goal is to present retrieval results in descending semantic similarity from the query."
            },
            "slug": "Semantic-Modeling-of-Natural-Scenes-for-Image-Vogel-Schiele",
            "title": {
                "fragments": [],
                "text": "Semantic Modeling of Natural Scenes for Content-Based Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A novel image representation is presented that renders it possible to access natural scenes by local semantic description by using a perceptually plausible distance measure that leads to a high correlation between the human and the automatically obtained typicality ranking."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2389950"
                        ],
                        "name": "I. Olson",
                        "slug": "I.-Olson",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Olson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Olson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3286262"
                        ],
                        "name": "M. Chun",
                        "slug": "M.-Chun",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Chun",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A simple model quantifying this effect, by Brady and Chun [31], suggests that learning only the relationships between the locations of the local distractors and the target location is sufficient to demonstrate many of the major properties of contextual cueing: a small but robust effect of set size [26], the ability to recombine displays that cue the same location [28], and strong cueing from only the local configuration [ 33 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8425756,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "98cf6a4ef72de1354664be70f902bb2acffb08df",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Invariant spatial relationships of objects may provide a rich source of contextual information. Visual context can assist localization of individual objects via an implicit learning mechanism, as revealed in the contextual cueing paradigm (Chun & Jiang, 1998). What defines a visual context? How robust is contextual learning? And is it perceptually constrained? Here we investigate whether both local context that surround a target, and long-range context that does not spatially coincide with a target, can influence target localization. In the contextual cueing task, participants implicitly learned a context by repeated exposure to items arranged in invariant patterns. Experiments 1 and 2 suggest that only local context facilitates target localization. However, Experiment 3 showed that long range context can prime target location when target and context are not separated by random information. Experiment 4 showed that grouping by colour does not affect contextual cueing, suggesting that spatial features play a more important role than surface features in spatial contextual cueing. In separate analyses, visual hemifield differences were found for learning and performance. In sum, the results indicate that implicit learning of spatial context is robust across noise and biased towards spatially grouped information."
            },
            "slug": "Perceptual-constraints-on-implicit-learning-of-Olson-Chun",
            "title": {
                "fragments": [],
                "text": "Perceptual constraints on implicit learning of spatial context"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results indicate that implicit learning of spatial context is robust across noise and biased towards spatially grouped information."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303774"
                        ],
                        "name": "L. Renninger",
                        "slug": "L.-Renninger",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Renninger",
                            "middleNames": [
                                "Walker"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Renninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This illustration shows the general scheme underlying many current global scene representations [50,52,53,55, 69 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "complex features such as textons [ 69 ] or vector-quantized SIFT features (SIFT descriptors encode a local image patch by dividing"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "texture-based methods [50,52, 69 ] or \u2018bag-of-words\u2019 models (a term borrowed from the literature on text analysis)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14694860,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d0632c640086bdde66066542a4670d5e165ef381",
            "isKey": true,
            "numCitedBy": 251,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "When-is-scene-identification-just-texture-Renninger-Malik",
            "title": {
                "fragments": [],
                "text": "When is scene identification just texture recognition?"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To illustrate the form of the conditional distribution between target and reference objects, LabelMe [ 65 ], a large database of annotated objects, is used to search for all images containing the reference object in the pose specified."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In this illustration, each image has been created by averaging hundreds of pictures containing a particular object in the center (a face, keyboard and fire hydrant) at a fixed scale and pose. Images come from the LabelMe dataset [ 65 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1900911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "092c275005ae49dc1303214f6d02d134457c7053",
            "isKey": false,
            "numCitedBy": 3076,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.\n"
            },
            "slug": "LabelMe:-A-Database-and-Web-Based-Tool-for-Image-Russell-Torralba",
            "title": {
                "fragments": [],
                "text": "LabelMe: A Database and Web-Based Tool for Image Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A web-based tool that allows easy image annotation and instant sharing of such annotations is developed and a large dataset that spans many object categories, often containing multiple instances over a wide variety of images is collected."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4910863"
                        ],
                        "name": "A. Hollingworth",
                        "slug": "A.-Hollingworth",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hollingworth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hollingworth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16828504,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ef61f89c9af3152f81106403e06437311b5565b3",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "The conclusion that scene knowledge interacts with object perception depends on evidence that object detection is facilitated by consistent scene context. Experiment 1 replicated the I. Biederman, R. J. Mezzanotte, and J. C. Rabinowitz (1982) object-detection paradigm. Detection performance was higher for semantically consistent versus inconsistent objects. However, when the paradigm was modified to control for response bias (Experiments 2 and 3) or when response bias was eliminated by means of a forced-choice procedure (Experiment 4), no such advantage obtained. When an additional source of biasing information was eliminated by presenting the object label after the scene (Experiments 3 and 4), there was either no effect of consistency (Experiment 4) or an inconsistent object advantage (Experiment 3). These results suggest that object perception is not facilitated by consistent scene context."
            },
            "slug": "Does-consistent-scene-context-facilitate-object-Hollingworth-Henderson",
            "title": {
                "fragments": [],
                "text": "Does consistent scene context facilitate object perception?"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The conclusion that scene knowledge interacts with object perception depends on evidence that object detection is facilitated by consistent scene context, but results suggest that object perception is not facilitated by consistency."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. General"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2723195"
                        ],
                        "name": "H. Hock",
                        "slug": "H.-Hock",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Hock",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116656619"
                        ],
                        "name": "Gregory P. Gordon",
                        "slug": "Gregory-P.-Gordon",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Gordon",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory P. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121209465"
                        ],
                        "name": "Robert M. Whitehurst",
                        "slug": "Robert-M.-Whitehurst",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Whitehurst",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert M. Whitehurst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Hock et al. [ 17 ] and Biederman and collaborators [2] observed that both semantic (object presence, position and size) and physical (consistent support and interposition with other objects) object\u2013scene relationships have an impact on the detection of a target object within the temporal window of a glance (<200 ms)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 144065958,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "55f1ef00415e867e1c59824d24c7d104845c1332",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Individual differences were obtained in a task requiring the same-different comparison of multiobject scenes. For some Ss, performance depended only on whether the objects were in a physically plausible arrangement. It was inferred that these Ss used internalized rule systems to interrelate arrays of objects into organized scenes. For the other Ss, performance depended on whether the objects belonged together, and whether their arrangement was familiar. It was inferred that these Ss dealt with each object on an individual basis, using information concerning belongingness and familiarity of arrangement to anticipate which objects would be present and where they would be located."
            },
            "slug": "Contextual-relations:-The-influence-of-familiarity,-Hock-Gordon",
            "title": {
                "fragments": [],
                "text": "Contextual relations: The influence of familiarity, physical plausibility, and belongingness"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3286262"
                        ],
                        "name": "M. Chun",
                        "slug": "M.-Chun",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Chun",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47240989"
                        ],
                        "name": "Yuhong Jiang",
                        "slug": "Yuhong-Jiang",
                        "structuredName": {
                            "firstName": "Yuhong",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhong Jiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Chun and Jiang[ 22 ] showed that people can learn the contingencies between novel objects, predicting the presence of one object on the basis of another, over the course of only 30 min."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17388284,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science",
                "Biology"
            ],
            "id": "83e74b0a256168d871d1f00f64937a53e951f6ef",
            "isKey": false,
            "numCitedBy": 466,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The visual environment is extremely rich and complex, producing information overload for the visual system. But the environment also embodies structure in the form of redundancies and regularities that may serve to reduce complexity. How do perceivers internalize this complex informational structure? We present new evidence of visual learning that illustrates how observers learn how objects and events covary in the visual world. This information serves to guide visual processes such as object recognition and search. Our first experiment demonstrates that search and object recognition are facilitated by learned associations (covariation) between novel visual shapes. Our second experiment shows that regularities in dynamic visual environments can also be learned to guide search behavior. In both experiments, learning occurred incidentally and the memory representations were implicit. These experiments show how top-down visual knowledge, acquired through implicit learning, constrains what to expect and guides where to attend and look."
            },
            "slug": "Top-Down-Attentional-Guidance-Based-on-Implicit-of-Chun-Jiang",
            "title": {
                "fragments": [],
                "text": "Top-Down Attentional Guidance Based on Implicit Learning of Visual Covariation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "These experiments show how top-down visual knowledge, acquired through implicit learning, constrains what to expect and guides where to attend and look and shows that regularities in dynamic visual environments can also be learned to guide search behavior."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895768"
                        ],
                        "name": "M. Eckstein",
                        "slug": "M.-Eckstein",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Eckstein",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Eckstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31424920"
                        ],
                        "name": "Barbara A. Drescher",
                        "slug": "Barbara-A.-Drescher",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Drescher",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barbara A. Drescher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4531450"
                        ],
                        "name": "S. Shimozaki",
                        "slug": "S.-Shimozaki",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Shimozaki",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shimozaki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Saliency models can be enhanced by introducing task constraints and a context model [9,10, 19 , 20,60,63] .I n Ref.[9], a scene is analyzed by two parallel pathways (Figure 4). The local pathway represents each spatial location independently and is used to compute image saliency and perform object recognition on the basis of local appearance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "a mug or bicycle), contextual information will provide additional cues in cases of image degradation, such as noise, heavy occlusions or poor resolution, resulting in an increase in detection [ 19 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, the scene content will have an immediate effect in the planning of subsequent eye movements [9, 19 ,60,61], overriding salient regions that would otherwise attract attention."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16351923,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "567948ffbf25f0838ad07d6812a135a8f16ea112",
            "isKey": true,
            "numCitedBy": 158,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Performance finding a target improves when artificial cues direct covert attention to the target's probable location or locations, but how do predictive cues help observers search for objects in real scenes? Controlling for target detectability and retinal eccentricity, we recorded observers' first saccades during search for objects that appeared in expected and unexpected locations within real scenes. As has been found with synthetic images and cues, accuracy of first saccades was significantly higher when the target appeared at an expected location rather than an unexpected location. Observers' saccades with target-absent images make it possible to distinguish two mechanisms that might mediate this effect: limited attentional resources versus differential weighting of information (Bayesian priors). Endpoints of first saccades in target-absent images were significantly closer to the expected than the unexpected locations, a result consistent with the differential-weighting model and inconsistent with limited resources being the sole mechanism underlying the effect."
            },
            "slug": "Attentional-cues-in-real-scenes,-saccadic-and-Eckstein-Drescher",
            "title": {
                "fragments": [],
                "text": "Attentional cues in real scenes, saccadic targeting, and Bayesian priors."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Endpoints of first saccades in target-absent images were significantly closer to the expected than the unexpected locations, a result consistent with the differential-weighting model and inconsistent with limited resources being the sole mechanism underlying the effect."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48927140"
                        ],
                        "name": "J. Najemnik",
                        "slug": "J.-Najemnik",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Najemnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Najemnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2966196"
                        ],
                        "name": "W. Geisler",
                        "slug": "W.-Geisler",
                        "structuredName": {
                            "firstName": "Wilson",
                            "lastName": "Geisler",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Geisler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Contextual effects on eye movements When exploring a scene for an object, an ideal observer will fixate the image locations that have the highest posterior probability of containing the target object according to the available image information [ 57 ]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 68669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2207d3952e4823280d297513226c2e075a3ff04c",
            "isKey": false,
            "numCitedBy": 566,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "To perform visual search, humans, like many mammals, encode a large field of view with retinas having variable spatial resolution, and then use high-speed eye movements to direct the highest-resolution region, the fovea, towards potential target locations. Good search performance is essential for survival, and hence mammals may have evolved efficient strategies for selecting fixation locations. Here we address two questions: what are the optimal eye movement strategies for a foveated visual system faced with the problem of finding a target in a cluttered environment, and do humans employ optimal eye movement strategies during a search? We derive the ideal bayesian observer for search tasks in which a target is embedded at an unknown location within a random background that has the spectral characteristics of natural scenes. Our ideal searcher uses precise knowledge about the statistics of the scenes in which the target is embedded, and about its own visual system, to make eye movements that gain the most information about target location. We find that humans achieve nearly optimal search performance, even though humans integrate information poorly across fixations. Analysis of the ideal searcher reveals that there is little benefit from perfect integration across fixations\u2014much more important is efficient processing of information on each fixation. Apparently, evolution has exploited this fact to achieve efficient eye movement strategies with minimal neural resources devoted to memory."
            },
            "slug": "Optimal-eye-movement-strategies-in-visual-search-Najemnik-Geisler",
            "title": {
                "fragments": [],
                "text": "Optimal eye movement strategies in visual search"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work derives the ideal bayesian observer for search tasks in which a target is embedded at an unknown location within a random background that has the spectral characteristics of natural scenes and finds that humans achieve nearly optimal search performance, even though humans integrate information poorly across fixations."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2184984"
                        ],
                        "name": "M. Peterson",
                        "slug": "M.-Peterson",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Peterson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Peterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172224901"
                        ],
                        "name": "A. Kramer",
                        "slug": "A.-Kramer",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Kramer",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kramer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A topic of current debate is the extent that context affects the speed at which attention is deployed towards the target [26, 34 ], alters target analysis [35] or biases response selection [36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 23751261,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "dbba65fb065d0fd9c2b418128db4a592e046559a",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Contextual cuing is a memory-based phenomenon in which previously encountered global pattern information in a display can automatically guide attention to the location of a target (Chun& Jiang, 1998), leading to rapid and accurate responses. What is not clear is how contextual cuing works. By monitoring eye movements, we investigated the roles that recognition and guidance play in contextual cuing. Recognition does not appear to occur on every trial and sometimes does not have its effects until later in the search process. When recognition does occur, attention is guided straight to the target rather than in the general direction. In Experiment 2, we investigated the interaction between memorydriven search (contextual cuing) and stimulus-driven attentional capture by abrupt onsets. Contextual cuing was able to override capture by abrupt onsets. In contrast, onsets had almost no effect on the degree of contextual cuing. These data are discussed in terms of the role of top-down and bottom-up factors in the guidance of attention in visual search."
            },
            "slug": "Attentional-guidance-of-the-eyes-by-contextual-and-Peterson-Kramer",
            "title": {
                "fragments": [],
                "text": "Attentional guidance of the eyes by contextual information and abrupt onsets."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "By monitoring eye movements, this work investigated the roles that recognition and guidance play in contextual cuing and the interaction between memorydriven search (contextual cuing) and stimulus-driven attentional capture by abrupt onsets."
            },
            "venue": {
                "fragments": [],
                "text": "Perception & psychophysics"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4910863"
                        ],
                        "name": "A. Hollingworth",
                        "slug": "A.-Hollingworth",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hollingworth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hollingworth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 146605582,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e31d0b6fd7df61fac734ab7544a9bffbbe97f8a8",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Changes to objects that are inconsistent with the scene in which they appear are detected more accurately than changes to consistent objects. In three experiments, we tested whether this inconsistent object advantage derives from the differential retention of conceptual codes generated from a brief view of a real-world scene in accordance with a conceptual short-term memory (CSTM) hypothesis. A scene was presented for 250 msec, followed by a brief mask and a test scene in which a target object was either changed or not changed. In Experiment 1, changes that altered conceptual content (object deletion) were contrasted with visual changes (left-right orientation changes). In Experiment 2, the duration of the mask was manipulated to vary the amount of time available for conceptual consolidation of the initial scene. In Experiment 3, the type of mask was manipulated: Either a meaningless pattern mask or a meaningful, and thus conceptually disruptive, scene was shown. The inconsistent object advantage was obtained in each experiment, yet in none was it modulated in the direction predicted by the CSTM hypothesis. Instead, the inconsistent object advantage is likely to be caused by contextual influence on memory for visual object representations."
            },
            "slug": "Testing-a-conceptual-locus-Hollingworth-Henderson",
            "title": {
                "fragments": [],
                "text": "Testing a conceptual locus"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39073328"
                        ],
                        "name": "A. Friedman",
                        "slug": "A.-Friedman",
                        "structuredName": {
                            "firstName": "Alinda",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Friedman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24546846,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bb70dfeab27c1be01ba4ef24162718b545f5e54b",
            "isKey": false,
            "numCitedBy": 698,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In general, frame theories are theories about the representation and use of knowledge for pattern recognition. In the present article, the general properties of frame theories are discussed with regard to their implications for psychological processes, and an experiment is presented which tests whether this approach yields viable predictions about the manner in which people comprehend and remember pictures of real-world scenes. Normative ratings were used to construct six target pictures, each of which contained both expected and unexpected objects. Eye movements were then recorded as subjects who anticipated a difficult recognition test viewed the targets for 30 sec each. Then, the subjects were asked to discriminate the target pictures from distractors in which either expected or unexpected objects had been changed. One consequence of the embeddedness of frame systems is that global frames may function as \"semantic pattern detectors,\" so that the perceptual knowledge in them could be used for relatively automatic pattern recognition and comprehension. Thus, subjects might be able to identify expected objects by using automatized encoding procedures that operate on global physical features. In contrast, identification of unexpected objects (i.e., objects not represented in the currently active frame) should generally require more analysis of local visual details. These hypotheses were confirmed with the fixation duration data: First fixations to the unexpected objects were approximately twice as long as first fixations to the expected objects. On the recognition test, subjects generally noticed only the changes that had been made to the unexpected objects, despite the fact that the proportions of correct rejections were made conditional on whether the target objects had been fixated. These data are again consistent with the idea that local visual details of objects represented in the frame are not neccesary for identification and are thus not generally encoded. Further, since subjects usually did not notice when expected objects were deleted or replaced with different expected objects, it was concluded that if two events instantiate the same frame, they may often be indistinguishable, as long as any differences between them are represented as arguments in the frame. Thus, for the most part, the only information about an event that is episodically \"tagged\" is information which distinguishes that particular event from others of the same general class. The data reinforce the utility of a frame theory approach to perception and memory."
            },
            "slug": "Framing-pictures:-the-role-of-knowledge-in-encoding-Friedman",
            "title": {
                "fragments": [],
                "text": "Framing pictures: the role of knowledge in automatized encoding and memory for gist."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An experiment is presented which tests whether this approach to frame theories yields viable predictions about the manner in which people comprehend and remember pictures of real-world scenes, and it is concluded that if two events instantiate the same frame, they may often be indistinguishable."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. General"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717172"
                        ],
                        "name": "J. Wolfe",
                        "slug": "J.-Wolfe",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wolfe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3628059"
                        ],
                        "name": "Helga C. Arsenio",
                        "slug": "Helga-C.-Arsenio",
                        "structuredName": {
                            "firstName": "Helga",
                            "lastName": "Arsenio",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helga C. Arsenio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "a nightstand will predict the presence of an alarm clock) level; contextual associations can be definite or probabilistic; and observers might act on an object in a consistent manner, or not, [37] and might choose to rely on memory search, instead of visual search, when looking for objects in familiar scenes [ 38 ] .T he respective roles of all these factors in explaining contextual influences constitute a challenging area for future"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 470704,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3855cf6e964c89a447201245ffcd38a0e0a27215",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "How do observers search through familiar scenes? A novel panoramic search method is used to study the interaction of memory and vision in natural search behavior. In panoramic search, observers see part of an unchanging scene larger than their current field of view. A target object can be visible, present in the display but hidden from view, or absent. Visual search efficiency does not change after hundreds of trials through an unchanging scene (Experiment 1). Memory search, in contrast, begins inefficiently but becomes efficient with practice. Given a choice between vision and memory, observers choose vision (Experiments 2 and 3). However, if forced to use their memory on some trials, they learn to use memory on all trials, even when reliable visual information remains available (Experiment 4). The results suggest that observers make a pragmatic choice between vision and memory, with a strong bias toward visual search even for memorized stimuli."
            },
            "slug": "Panoramic-search:-the-interaction-of-memory-and-in-Oliva-Wolfe",
            "title": {
                "fragments": [],
                "text": "Panoramic search: the interaction of memory and vision in search through a familiar scene."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results suggest that observers make a pragmatic choice between vision and memory, with a strong bias toward visual search even for memorized stimuli."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1920282"
                        ],
                        "name": "S. C. Chong",
                        "slug": "S.-C.-Chong",
                        "structuredName": {
                            "firstName": "Sang",
                            "lastName": "Chong",
                            "middleNames": [
                                "Chul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. C. Chong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11768948,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5c285034d2fd56d88a7b9a6647563ee7b3c6a12d",
            "isKey": false,
            "numCitedBy": 506,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Representation-of-statistical-properties-Chong-Treisman",
            "title": {
                "fragments": [],
                "text": "Representation of statistical properties"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 49 ]). However, contextual information can be used in conjunction with local approaches to improve performance, efficiency and tolerance to image degradation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53924538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "787827850b614135f6b432603afc90b58a8cc665",
            "isKey": false,
            "numCitedBy": 4098,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThe accessible presentation of this book gives both a general view of the entire computer vision enterprise and also offers sufficient detail to be able to build useful applications. Users learn techniques that have proven to be useful by first-hand experience and a wide range of mathematical methods. A CD-ROM with every copy of the text contains source code for programming practice, color images, and illustrative movies. Comprehensive and up-to-date, this book includes essential topics that either reflect practical significance or are of theoretical importance. Topics are discussed in substantial and increasing depth. Application surveys describe numerous important application areas such as image based rendering and digital libraries. Many important algorithms broken down and illustrated in pseudo code. Appropriate for use by engineers as a comprehensive reference to the computer vision enterprise."
            },
            "slug": "Computer-Vision:-A-Modern-Approach-Forsyth-Ponce",
            "title": {
                "fragments": [],
                "text": "Computer Vision: A Modern Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Comprehensive and up-to-date, this book includes essential topics that either reflect practical significance or are of theoretical importance and describes numerous important application areas such as image based rendering and digital libraries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2184661"
                        ],
                        "name": "M. Neider",
                        "slug": "M.-Neider",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Neider",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Neider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696991"
                        ],
                        "name": "G. Zelinsky",
                        "slug": "G.-Zelinsky",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Zelinsky",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zelinsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12885169,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "f6b95f0db5c14493c2c68e0e318b24fcd9917017",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scene-context-guides-eye-movements-during-visual-Neider-Zelinsky",
            "title": {
                "fragments": [],
                "text": "Scene context guides eye movements during visual search"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38986620"
                        ],
                        "name": "Joo-Hyun Song",
                        "slug": "Joo-Hyun-Song",
                        "structuredName": {
                            "firstName": "Joo-Hyun",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joo-Hyun Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47240989"
                        ],
                        "name": "Yuhong Jiang",
                        "slug": "Yuhong-Jiang",
                        "structuredName": {
                            "firstName": "Yuhong",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhong Jiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "At a more local level, recent work has demonstrated similar magnitudes of contextual cueing when only two items surrounding the target are repeated or when the entire display is repeated [31, 32 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11303571,
            "fieldsOfStudy": [
                "Psychology",
                "Biology",
                "Computer Science"
            ],
            "id": "0bed2be3ceaf6b6b906340aab2e17ddcc0f08728",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Extensive cognitive research has been devoted to the sensitivity of the visual system to invariant statistical information. For example, many studies have shown that performance improves when a visual display is presented repeatedly. But what allows humans to connect the current visual input to previous memory? Is the connection made only when the entire incoming display matches with a previous memory, or can retrieval rely on an incomplete match between the input and a learned display? Using a visual search task, we show that (1) once a repeated display is learned, subjects can retrieve it even when an incoming display only matches it in 3-4 locations; (2) however, early during learning, repetition of a small proportion of a display is not enough to establish a strong memory trace for the repeated locations. We suggest that the retrieval of a well-established visual memory can proceed even if an incoming display partly matches the previous memory."
            },
            "slug": "Connecting-the-past-with-the-present:-how-do-humans-Song-Jiang",
            "title": {
                "fragments": [],
                "text": "Connecting the past with the present: how do humans match an incoming visual display with visual memory?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is suggested that the retrieval of a well-established visual memory can proceed even if an incoming display partly matches the previous memory."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2250837"
                        ],
                        "name": "C. Chubb",
                        "slug": "C.-Chubb",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Chubb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chubb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054961655"
                        ],
                        "name": "Jong-Ho Nam",
                        "slug": "Jong-Ho-Nam",
                        "structuredName": {
                            "firstName": "Jong-Ho",
                            "lastName": "Nam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jong-Ho Nam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6503527"
                        ],
                        "name": "Daniel Bindman",
                        "slug": "Daniel-Bindman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bindman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Bindman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145251723"
                        ],
                        "name": "G. Sperling",
                        "slug": "G.-Sperling",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Sperling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sperling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The statistical properties currently under active investigation are the mean size and variance of a set of objects [40,42\u201344], the center of mass [41], texture descriptors [ 45 ] and also more complex structural information, such as the amount of clutter in an image[46], in additionto themeandepth anddegreeof perspectiveof a natural scene [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1877828,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "670e23f8beb110fcc6f9e2e94aa83531f4eb0565",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-three-dimensions-of-human-visual-sensitivity-to-Chubb-Nam",
            "title": {
                "fragments": [],
                "text": "The three dimensions of human visual sensitivity to first-order contrast statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1831021"
                        ],
                        "name": "Timothy F. Brady",
                        "slug": "Timothy-F.-Brady",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Brady",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy F. Brady"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3286262"
                        ],
                        "name": "M. Chun",
                        "slug": "M.-Chun",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Chun",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14932042,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "0ccaa91bd4e79c9786d3510394ff4c306f51cbb1",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Predictive visual context facilitates visual search, a benefit termed contextual cuing (M. M. Chun & Y. Jiang, 1998). In the original task, search arrays were repeated across blocks such that the spatial configuration (context) of all of the distractors in a display predicted an embedded target location. The authors modeled existing results using a connectionist architecture and then designed new behavioral experiments to test the model's assumptions. The modeling and behavioral results indicate that learning may be restricted to the local context even when the entire configuration is predictive of target location. Local learning constrains how much guidance is produced by contextual cuing. The modeling and new data also demonstrate that local learning requires that the local context maintain its location in the overall global context."
            },
            "slug": "Spatial-constraints-on-learning-in-visual-search:-Brady-Chun",
            "title": {
                "fragments": [],
                "text": "Spatial constraints on learning in visual search: modeling contextual cuing."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The authors modeled existing results using a connectionist architecture and designed new behavioral experiments to test the model's assumptions, indicating that learning may be restricted to the local context even when the entire configuration is predictive of target location and that local learning constrains how much guidance is produced by contextual cuing."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739475"
                        ],
                        "name": "J. Goh",
                        "slug": "J.-Goh",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Goh",
                            "middleNames": [
                                "Oon",
                                "Soo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5625075"
                        ],
                        "name": "Soon Chun Siong",
                        "slug": "Soon-Chun-Siong",
                        "structuredName": {
                            "firstName": "Soon",
                            "lastName": "Siong",
                            "middleNames": [
                                "Chun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soon Chun Siong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116006908"
                        ],
                        "name": "Denise C. Park",
                        "slug": "Denise-C.-Park",
                        "structuredName": {
                            "firstName": "Denise",
                            "lastName": "Park",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denise C. Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3028161"
                        ],
                        "name": "A. Gutchess",
                        "slug": "A.-Gutchess",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Gutchess",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gutchess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2405278"
                        ],
                        "name": "A. Hebrank",
                        "slug": "A.-Hebrank",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hebrank",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hebrank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145154233"
                        ],
                        "name": "M. Chee",
                        "slug": "M.-Chee",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Chee",
                            "middleNames": [
                                "W.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6716245,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "bd4bb3ca028e35c54deb08c212ad0fe0bbffec03",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work has suggested that object and place processing are neuroanatomically dissociated in ventral visual areas under conditions of passive viewing. It has also been shown that the hippocampus and parahippocampal gyrus mediate the integration of objects with background scenes in functional imaging studies, but only when encoding or retrieval processes have been directed toward the relevant stimuli. Using functional magnetic resonance adaptation, we demonstrated that object, background scene, and contextual integration of selectively repeated objects and background scenes could be dissociated during the passive viewing of naturalistic pictures involving object-scene pairings. Specifically, bilateral fusiform areas showed adaptation to object repetition, regardless of whether the associated scene was novel or repeated, suggesting sensitivity to object processing. Bilateral parahippocampal regions showed adaptation to background scene repetition, regardless of whether the focal object was novel or repeated, suggesting selectivity for background scene processing. Finally, bilateral parahippocampal regions distinct from those involved in scene processing and the right hippocampus showed adaptation only when the unique pairing of object with background scene was repeated, suggesting that these regions perform binding operations."
            },
            "slug": "Cortical-Areas-Involved-in-Object,-Background,-and-Goh-Siong",
            "title": {
                "fragments": [],
                "text": "Cortical Areas Involved in Object, Background, and Object-Background Processing Revealed with Functional Magnetic Resonance Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Using functional magnetic resonance adaptation, it is demonstrated that object, background scene, and contextual integration of selectively repeated objects and background scenes could be dissociated during the passive viewing of naturalistic pictures involving object-scene pairings."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of Neuroscience"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180590"
                        ],
                        "name": "S. Thorpe",
                        "slug": "S.-Thorpe",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Thorpe",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thorpe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50780533"
                        ],
                        "name": "D. Fize",
                        "slug": "D.-Fize",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Fize",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fize"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3677347"
                        ],
                        "name": "Catherine Marlot",
                        "slug": "Catherine-Marlot",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Marlot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Marlot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4303570,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "addbd39fc775c12aa453ebd0cb77ea1bd3389572",
            "isKey": false,
            "numCitedBy": 2548,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speed-of-processing-in-the-human-visual-system-Thorpe-Fize",
            "title": {
                "fragments": [],
                "text": "Speed of processing in the human visual system"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1920282"
                        ],
                        "name": "S. C. Chong",
                        "slug": "S.-C.-Chong",
                        "structuredName": {
                            "firstName": "Sang",
                            "lastName": "Chong",
                            "middleNames": [
                                "Chul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. C. Chong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 43 ], this result suggests that a statistical summary of ensemble featuresis computedautomatically and outside of the focus of attention."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 292245,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5defd218a3a478a49b9541044a49427a35c98610",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We tested the hypothesis that distributing attention over an array of similar items makes its statistical properties automatically available. We found that extracting the mean size of sets of circles was easier to combine with tasks requiring distributed or global attention than with tasks requiring focused attention. One explanation may be that extracting the statistical descriptors requires parallel access to all the information in the array. Consistent with this claim, we found an advantage for simultaneous over successive presentation when the total time available was matched. However, the advantage was small; parallel access facilitates statistical processing without being essential. Evidence that statistical processing is automatic when attention is distributed over a display came from the finding that there was no decrement in accuracy relative to single-task performance when mean judgments were made concurrently with another task that required distributed or global attention."
            },
            "slug": "Attentional-spread-in-the-statistical-processing-of-Chong-Treisman",
            "title": {
                "fragments": [],
                "text": "Attentional spread in the statistical processing of visual displays"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Evidence that statistical processing is automatic when attention is distributed over a display came from the finding that there was no decrement in accuracy relative to single-task performance when mean judgments were made concurrently with another task that required distributed or global attention."
            },
            "venue": {
                "fragments": [],
                "text": "Perception & psychophysics"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144423856"
                        ],
                        "name": "Anna Bosch",
                        "slug": "Anna-Bosch",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Bosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna Bosch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062941326"
                        ],
                        "name": "X. Mu\u00f1oz",
                        "slug": "X.-Mu\u00f1oz",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Mu\u00f1oz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Mu\u00f1oz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "the patch into 4 4 regions and computing the histogram of local image gradients within each region) [52,53, 55 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This illustration shows the general scheme underlying many current global scene representations [50,52,53, 55 ,69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1260607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15d2aa6511bd0a8de5cb690bf406d90eef902ff1",
            "isKey": false,
            "numCitedBy": 859,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of images of scenes containing multiple object categories (e.g. grass, roads, buildings) our objective is to discover these objects in each image in an unsupervised manner, and to use this object distribution to perform scene classification. We achieve this discovery using probabilistic Latent Semantic Analysis (pLSA), a generative model from the statistical text literature, here applied to a bag of visual words representation for each image. The scene classification on the object distribution is carried out by a k-nearest neighbour classifier. \n \nWe investigate the classification performance under changes in the visual vocabulary and number of latent topics learnt, and develop a novel vocabulary using colour SIFT descriptors. Classification performance is compared to the supervised approaches of Vogel & Schiele [19] and Oliva & Torralba [11], and the semi-supervised approach of Fei Fei & Perona [3] using their own datasets and testing protocols. In all cases the combination of (unsupervised) pLSA followed by (supervised) nearest neighbour classification achieves superior results. We show applications of this method to image retrieval with relevance feedback and to scene classification in videos."
            },
            "slug": "Scene-Classification-Via-pLSA-Bosch-Zisserman",
            "title": {
                "fragments": [],
                "text": "Scene Classification Via pLSA"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The classification performance under changes in the visual vocabulary and number of latent topics learnt is investigated, and a novel vocabulary using colour SIFT descriptors is developed using probabilistic Latent Semantic Analysis."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680975"
                        ],
                        "name": "R. Rosenholtz",
                        "slug": "R.-Rosenholtz",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Rosenholtz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenholtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2549090"
                        ],
                        "name": "Yuanzhen Li",
                        "slug": "Yuanzhen-Li",
                        "structuredName": {
                            "firstName": "Yuanzhen",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuanzhen Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6716540"
                        ],
                        "name": "L. Nakano",
                        "slug": "L.-Nakano",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Nakano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Nakano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The statistical properties currently under active investigation are the mean size and variance of a set of objects [40,42\u201344], the center of mass [41], texture descriptors [45] and also more complex structural information, such as the amount of clutter in an image[ 46 ], in additionto themeandepth anddegreeof perspectiveof a natural scene [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10847280,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "c8318039383ab2963c3b7778db5f71fcb4a00f32",
            "isKey": false,
            "numCitedBy": 607,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual clutter concerns designers of user interfaces and information visualizations. This should not surprise visual perception researchers because excess and/or disorganized display items can cause crowding, masking, decreased recognition performance due to occlusion, greater difficulty at both segmenting a scene and performing visual search, and so on. Given a reliable measure of the visual clutter in a display, designers could optimize display clutter. Furthermore, a measure of visual clutter could help generalize models like Guided Search (J. M. Wolfe, 1994) by providing a substitute for \"set size\" more easily computable on more complex and natural imagery. In this article, we present and test several measures of visual clutter, which operate on arbitrary images as input. The first is a new version of the Feature Congestion measure of visual clutter presented in R. Rosenholtz, Y. Li, S. Mansfield, and Z. Jin (2005). This Feature Congestion measure of visual clutter is based on the analogy that the more cluttered a display or scene is, the more difficult it would be to add a new item that would reliably draw attention. A second measure of visual clutter, Subband Entropy, is based on the notion that clutter is related to the visual information in the display. Finally, we test a third measure, Edge Density, used by M. L. Mack and A. Oliva (2004) as a measure of subjective visual complexity. We explore the use of these measures as stand-ins for set size in visual search models and demonstrate that they correlate well with search performance in complex imagery. This includes the search-in-clutter displays of J. M. Wolfe, A. Oliva, T. S. Horowitz, S. Butcher, and A. Bompas (2002) and Bravo and Farid (2004), as well as new search experiments. An additional experiment suggests that color variability, accounted for by Feature Congestion but not the Edge Density measure or the Subband Entropy measure, does matter for visual clutter."
            },
            "slug": "Measuring-visual-clutter.-Rosenholtz-Li",
            "title": {
                "fragments": [],
                "text": "Measuring visual clutter."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Several measures of visual clutter are presented and used as stand-ins for set size in visual search models and demonstrate that they correlate well with search performance in complex imagery."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2236483"
                        ],
                        "name": "M. Adjouadi",
                        "slug": "M.-Adjouadi",
                        "structuredName": {
                            "firstName": "Malek",
                            "lastName": "Adjouadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Adjouadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054023969"
                        ],
                        "name": "Marie L. Lucas",
                        "slug": "Marie-L.-Lucas",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Lucas",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marie L. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171174"
                        ],
                        "name": "Emanuel L. Pozo",
                        "slug": "Emanuel-L.-Pozo",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Pozo",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emanuel L. Pozo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110580137"
                        ],
                        "name": "Hien Nguyen",
                        "slug": "Hien-Nguyen",
                        "structuredName": {
                            "firstName": "Hien",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hien Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060218799"
                        ],
                        "name": "Kevin Maynard",
                        "slug": "Kevin-Maynard",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Maynard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Maynard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108680852"
                        ],
                        "name": "S. Thomas",
                        "slug": "S.-Thomas",
                        "structuredName": {
                            "firstName": "Stacey",
                            "lastName": "Thomas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145205532"
                        ],
                        "name": "A. Barreto",
                        "slug": "A.-Barreto",
                        "structuredName": {
                            "firstName": "Armando",
                            "lastName": "Barreto",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barreto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35704377"
                        ],
                        "name": "Scott Graham",
                        "slug": "Scott-Graham",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719172"
                        ],
                        "name": "N. Rishe",
                        "slug": "N.-Rishe",
                        "structuredName": {
                            "firstName": "Naphtali",
                            "lastName": "Rishe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Rishe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 225264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7bc258ace482873f61f9bf5fe822b0d6da9dbea",
            "isKey": false,
            "numCitedBy": 647,
            "numCiting": 265,
            "paperAbstract": {
                "fragments": [],
                "text": "With today\u2019s large increase in digital images and automatically generated imagery, such as videos and stills generated from surveillance equipment, the need for efficient image retrieval and indexing has become fundamental. Since text-based information retrieval has been shown to perform very poorly when searching through images, research has been active in the field of content-based image retrieval (CBIR). CBIR systems make use of the properties of images in order to compare them and extract content by matching the query image. Comparing features \u2013 such as color, texture, and shape \u2013 allows for better retrieval accuracy; however, the algorithms used are still very limited. This paper will provide a survey of CBIR systems and explain the fundamental properties and techniques used in these systems. First, the history of CBIR systems will be discussed together with some typical CBIR systems. After this, the paper will touch on text-based information retrieval and explain why it does not work for searching through collections of images. The latter portion of this document will provides an overview of a typical CBIR system and the main techniques involved in querying such a system. Finally, image features and indexing schemes will be described."
            },
            "slug": "Content-Based-Image-Retrieval-Adjouadi-Lucas",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A survey of CBIR systems is provided and the fundamental properties and techniques used in these systems are explained, including text-based information retrieval and why it does not work for searching through collections of images."
            },
            "venue": {
                "fragments": [],
                "text": "Enterprise Information Systems and Web Technologies"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40466012"
                        ],
                        "name": "M. Land",
                        "slug": "M.-Land",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Land",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Land"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2848854"
                        ],
                        "name": "M. Hayhoe",
                        "slug": "M.-Hayhoe",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hayhoe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hayhoe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "a nightstand will predict the presence of an alarm clock) level; contextual associations can be definite or probabilistic; and observers might act on an object in a consistent manner, or not, [ 37 ] and might choose to rely on memory search, instead of visual search, when looking for objects in familiar scenes [38] .T he respective roles of all these factors in explaining contextual influences constitute a challenging area for future"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1789011,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5302f7e69537e9abc2e81173f044a8651259609d",
            "isKey": false,
            "numCitedBy": 824,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "In-what-ways-do-eye-movements-contribute-to-Land-Hayhoe",
            "title": {
                "fragments": [],
                "text": "In what ways do eye movements contribute to everyday activities?"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15065442,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "c411f93539714f512e437c45a7a9d0a6d5a7675e",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-image-classification:-city-images-vs.-landscapes-Vailaya-Jain",
            "title": {
                "fragments": [],
                "text": "On image classification: city images vs. landscapes"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2240829"
                        ],
                        "name": "E. Aminoff",
                        "slug": "E.-Aminoff",
                        "structuredName": {
                            "firstName": "Elissa",
                            "lastName": "Aminoff",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Aminoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709721"
                        ],
                        "name": "N. Gronau",
                        "slug": "N.-Gronau",
                        "structuredName": {
                            "firstName": "Nurit",
                            "lastName": "Gronau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gronau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741887"
                        ],
                        "name": "M. Bar",
                        "slug": "M.-Bar",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Bar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17698813,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "8249b2cb637129c496198a12190d90038cfc6d11",
            "isKey": false,
            "numCitedBy": 307,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "The parahippocampal cortex (PHC) has been implicated in the processing of place-related information. It has also been implicated in episodic memory, even for items that are not related to unique places. How could the same cortical region mediate such seemingly different cognitive processes? Both processes rely on contextual associations, and we therefore propose that the PHC should be viewed not as exclusively dedicated for analyzing place-related information, or as solely processing episodic memories, but instead as more generally playing a central role in contextual associative processing. To test this proposal, we created a novel learning paradigm to form new associations among meaningless visual patterns. These new associations were created to emulate either spatial or nonspatial contexts. Both spatial and nonspatial associations activated the PHC more than noncontextual items. Moreover, items from spatial contexts activated the posterior part of the PHC, whereas items from nonspatial contexts activated the anterior PHC. Therefore, we show that the PHC plays a role of processing contextual associations in general, and that these associations are not restricted to spatial information. By modifying the existing view of the PHC function accordingly, the seemingly contradicting processes that activate it can be reconciled under one overarching framework."
            },
            "slug": "The-parahippocampal-cortex-mediates-spatial-and-Aminoff-Gronau",
            "title": {
                "fragments": [],
                "text": "The parahippocampal cortex mediates spatial and nonspatial associations."
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It is shown that the parahippocampal cortex plays a role of processing contextual associations in general, and that these associations are not restricted to spatial information."
            },
            "venue": {
                "fragments": [],
                "text": "Cerebral cortex"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144648366"
                        ],
                        "name": "Yuhong V. Jiang",
                        "slug": "Yuhong-V.-Jiang",
                        "structuredName": {
                            "firstName": "Yuhong",
                            "lastName": "Jiang",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhong V. Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24368896"
                        ],
                        "name": "Laura C. Wagner",
                        "slug": "Laura-C.-Wagner",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Wagner",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laura C. Wagner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For instance, transfer between learned and novel displays is effective for geometric transformations that preserve the relative ordering of items across the whole display, such as stretching [ 28 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A simple model quantifying this effect, by Brady and Chun [31], suggests that learning only the relationships between the locations of the local distractors and the target location is sufficient to demonstrate many of the major properties of contextual cueing: a small but robust effect of set size [26], the ability to recombine displays that cue the same location [ 28 ], and strong cueing from only the local configuration [33]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27668,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6bbbdbd97465749f16e38788d8cec1061d72343d",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "With the use of spatial contextual cuing, we tested whether subjects learned to associate target locations with overall configurations of distractors or with individual locations of distractors. In Experiment 1, subjects were trained on 36 visual search displays that contained 36 sets of distractor locations and 18 target locations. Each target location was paired with two sets of distractor locations on separate trials. After training, the subjects showed perfect transfer to recombined displays, which were created by combining half of one trained distractor set with half of another trained distractor set. This result suggests that individual distractor locations were sufficient to cue the target location. In Experiment 2, the subjects showed good transfer from trained displays to rescaled, displaced, and perceptually regrouped displays, suggesting that the relative locations among items were also learned. Thus, both individual target-distractor associations and configural associations are learned in contextual cuing."
            },
            "slug": "What-is-learned-in-spatial-contextual-cuing\u2014-or-Jiang-Wagner",
            "title": {
                "fragments": [],
                "text": "What is learned in spatial contextual cuing\u2014 configuration or individual locations?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Both individual target-distractor associations and configural associations are learned in contextual cuing, suggesting that the relative locations among items were also learned."
            },
            "venue": {
                "fragments": [],
                "text": "Perception & psychophysics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143615083"
                        ],
                        "name": "R. Peters",
                        "slug": "R.-Peters",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Peters",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7326223"
                        ],
                        "name": "L. Itti",
                        "slug": "L.-Itti",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Itti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Itti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Saliency models can be enhanced by introducing task constraints and a context model [9,10,19,  20 ,60,63] .I n Ref.[9], a scene is analyzed by two parallel pathways (Figure 4). The local pathway represents each spatial location independently and is used to compute image saliency and perform object recognition on the basis of local appearance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14612945,
            "fieldsOfStudy": [
                "Psychology",
                "Biology",
                "Business"
            ],
            "id": "c3ddbf19ad25c3fd2818bbd7d414f08b38d1db5b",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Next-generation immersive virtual environments and video games will require virtual agents with human-like visual attention and gaze behaviors. A critical step is to devise efficient visual processing heuristics to select locations that would attract human gaze in complex dynamic environments. One promising approach to designing such heuristics draws on ideas from computational neuroscience. We compared several such heuristics with eye movement recordings from five observers playing video games, and found that heuristics which detect outliers from the global distribution of visual features were better predictors of human gaze than were purely local heuristics. Heuristics sensitive to dynamic events performed best overall. Further, heuristic prediction power differed more between games than between different human observers. Our findings suggest simple neurally-inspired algorithmic methods to predict where humans look while playing video games."
            },
            "slug": "Computational-mechanisms-for-gaze-direction-in-Peters-Itti",
            "title": {
                "fragments": [],
                "text": "Computational mechanisms for gaze direction in interactive visual environments"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work compared several neurally-inspired algorithmic methods to predict where humans look while playing video games and found that heuristics which detect outliers from the global distribution of visual features were better predictors of human gaze than were purely local heuristic."
            },
            "venue": {
                "fragments": [],
                "text": "ETRA '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152342369"
                        ],
                        "name": "E. Over",
                        "slug": "E.-Over",
                        "structuredName": {
                            "firstName": "Eelco",
                            "lastName": "Over",
                            "middleNames": [
                                "A.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Over"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144126239"
                        ],
                        "name": "I. Hooge",
                        "slug": "I.-Hooge",
                        "structuredName": {
                            "firstName": "Ignace",
                            "lastName": "Hooge",
                            "middleNames": [
                                "Th.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Hooge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2980410"
                        ],
                        "name": "B. Vlaskamp",
                        "slug": "B.-Vlaskamp",
                        "structuredName": {
                            "firstName": "Bj\u00f6rn",
                            "lastName": "Vlaskamp",
                            "middleNames": [
                                "N.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Vlaskamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078499"
                        ],
                        "name": "C. Erkelens",
                        "slug": "C.-Erkelens",
                        "structuredName": {
                            "firstName": "Casper",
                            "lastName": "Erkelens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Erkelens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 2267478,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "60656054d9a3500dbb58f2642d876a6acc4479fd",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Coarse-to-fine-eye-movement-strategy-in-visual-Over-Hooge",
            "title": {
                "fragments": [],
                "text": "Coarse-to-fine eye movement strategy in visual search"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5734059"
                        ],
                        "name": "Melina A Kunar",
                        "slug": "Melina-A-Kunar",
                        "structuredName": {
                            "firstName": "Melina",
                            "lastName": "Kunar",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Melina A Kunar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116339"
                        ],
                        "name": "S. Flusberg",
                        "slug": "S.-Flusberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Flusberg",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Flusberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6122551"
                        ],
                        "name": "T. Horowitz",
                        "slug": "T.-Horowitz",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Horowitz",
                            "middleNames": [
                                "Steven"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717172"
                        ],
                        "name": "J. Wolfe",
                        "slug": "J.-Wolfe",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wolfe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A topic of current debate is the extent that context affects the speed at which attention is deployed towards the target [26,34], alters target analysis [35] or biases response selection [ 36 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16755654,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "05b06ece3e3ef5422ee6dfb2103b21c02473553e",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Contextual cuing experiments show that when displays are repeated, reaction times to find a target decrease over time even when observers are not aware of the repetition. It has been thought that the context of the display guides attention to the target. The authors tested this hypothesis by comparing the effects of guidance in a standard search task with the effects of contextual cuing. First, in standard search, an improvement in guidance causes search slopes (derived from Reaction Time x Set Size functions) to decrease. In contrast, the authors found that search slopes in contextual cuing did not become more efficient over time (Experiment 1). Second, when guidance was optimal (e.g., in easy feature search), they still found a small but reliable contextual cuing effect (Experiments 2a and 2b), suggesting that other factors, such as response selection, contribute to the effect. Experiment 3 supported this hypothesis by showing that the contextual cuing effect disappeared when the authors added interference to the response selection process. Overall, the data suggest that the relationship between guidance and contextual cuing is weak and that response selection can account for part of the effect."
            },
            "slug": "Does-contextual-cuing-guide-the-deployment-of-Kunar-Flusberg",
            "title": {
                "fragments": [],
                "text": "Does contextual cuing guide the deployment of attention?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The data suggest that the relationship between guidance and contextual cuing is weak and that response selection can account for part of the effect."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1920282"
                        ],
                        "name": "S. C. Chong",
                        "slug": "S.-C.-Chong",
                        "structuredName": {
                            "firstName": "Sang",
                            "lastName": "Chong",
                            "middleNames": [
                                "Chul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. C. Chong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1967986,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "6b2e7dc31e117039b675512a814750a58a1d35bd",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-processing:-computing-the-average-size-Chong-Treisman",
            "title": {
                "fragments": [],
                "text": "Statistical processing: computing the average size in perceptual groups"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068362865"
                        ],
                        "name": "P. A. Weeks",
                        "slug": "P.-A.-Weeks",
                        "structuredName": {
                            "firstName": "Phillip",
                            "lastName": "Weeks",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. A. Weeks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4910863"
                        ],
                        "name": "A. Hollingworth",
                        "slug": "A.-Hollingworth",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hollingworth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hollingworth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143994016,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d223589f8f170363d71e70d7aac18020814bd464",
            "isKey": false,
            "numCitedBy": 676,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-effects-of-semantic-consistency-on-eye-during-Henderson-Weeks",
            "title": {
                "fragments": [],
                "text": "The effects of semantic consistency on eye movements during complex scene viewing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944906"
                        ],
                        "name": "M. Potter",
                        "slug": "M.-Potter",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Potter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Potter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35385513,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "29c5af8f630bb688ad627e6f750ba5c10fc8b86c",
            "isKey": false,
            "numCitedBy": 584,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Viewers briefly glimpsed pictures presented in a sequence at rates up to eight per second. They recognized a target picture as accurately and almost as rapidly when they knew only its meaning given by a name (for example, a boat) as when they had seen the picture itself in advance."
            },
            "slug": "Meaning-in-visual-search.-Potter",
            "title": {
                "fragments": [],
                "text": "Meaning in visual search."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Viewers briefly glimpsed pictures presented in a sequence at rates up to eight per second and recognized a target picture as accurately and almost as rapidly when they knew only its meaning given by a name."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861321"
                        ],
                        "name": "L. Jim\u00e9nez",
                        "slug": "L.-Jim\u00e9nez",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Jim\u00e9nez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jim\u00e9nez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141595236,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "d1631619cb6f7ea737514893eccbac0ff642e0f7",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Acknowledgement 2. Contributors 3. Introduction: Attention to implicit learning (by Jimenez, Luis) 4. Part 1. The cognitive debate 5. Attention and awareness in \"implicit\" sequence learning (by Shanks, David R.) 6. Intention, attention, and consciousness in probabilistic sequence learning (by Jimenez, Luis) 7. Part 2. Neuroscientific and computational approaches 8. Neural structures that support implicit sequence learning (by Hazeltine, Eliot) 9. The cognitive neuroscience of implicit category learning (by Ashby, F. Gregory) 10. Structure and function in sequence learning: Evidence from experimental, neuropsychological and simulation studies (by Dominey, Peter F.) 11. Temporal effects in sequence learning (by Destrebecqz, Arnaud) 12. Implicit and explicit learning in a unified architecture of cognition (by Wallach, Dieter) 13. Part 3. Reciprocal influences: Implicit learning, attention, and beyond 14. Visual orienting, learning and conscious awareness (by Lambert, Tony) 15. Contextual cueing: Reciprocal influences between attention and implicit learning (by Jiang, Yuhong) 16. Attention and implicit memory (by Mulligan, Neil W.) 17. The route from implicit learning to verbal expression of what has been learned: Verbal report of incidentally experienced environmental regularity (by Frensch, Peter A.) 18. Author index 19. Subject index"
            },
            "slug": "Attention-and-implicit-learning-Jim\u00e9nez",
            "title": {
                "fragments": [],
                "text": "Attention and implicit learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This chapter discusses the cognitive neuroscience of implicit category learning and the route from implicit learning to verbal expression of what has been learned: Verbal report of incidentally experienced environmental regularity."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724448"
                        ],
                        "name": "Kari-Jouko R\u00e4ih\u00e4",
                        "slug": "Kari-Jouko-R\u00e4ih\u00e4",
                        "structuredName": {
                            "firstName": "Kari-Jouko",
                            "lastName": "R\u00e4ih\u00e4",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kari-Jouko R\u00e4ih\u00e4"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2245673"
                        ],
                        "name": "A. Duchowski",
                        "slug": "A.-Duchowski",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Duchowski",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Duchowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60892812,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0eba30c4437bf7db84a42278f588af38aecb6e85",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "ETRA 2008 is the fifth bi-ennial symposium in a series focused on all aspects of eye movement research across a wide range of disciplines. The goal of ETRA is to bring together computer scientists, engineers and behavioral scientists in support of a common vision of enhancing eye tracking research and applications. \n \nThis year's themes included the following: \n \n\u2022Advances in Eye-Tracking Technology: Eye-tracking systems, software, and algorithms, eye movement analysis techniques and predictive models. \n \n\u2022Visual Attention and Eye Movement Control: Studies of eye movement guidance during natural stimuli and behaviors, driving, web surfing, usability studies. \n \n\u2022Eye Tracking Applications: Gaze-contingent displays, attentive user interfaces, human computer interfaces, assistive technologies. \n \n\u2022Special Theme: Usability and Ubiquity: Eye tracking has become a fairly popular though still expensive option in usability studies. Meanwhile, several approaches have recently been developed for inexpensive do-it-yourself (DIY) eye tracking systems. Webcam-based solutions for course-grained analysis are quite plausible on commonly available systems (e.g., Apple's MacBook Pro with built-in iSight). Submissions were invited that explored new methodological approaches, demonstrating significant improvement over existing ones. Results from usability perspectives as well as novel strategies for ubiquitous eye tracking deployment were also welcomed. \n \nTwo categories of submissions were sought: Full Papers and Late-Breaking Results (LBR papers). Full papers conform to the ACM SIGGRAPH proceedings category 2 format and are a maximum length of eight pages. New for 2008, Late-Breaking Results conform to the ACM SIGGRAPH proceedings category 3 format (\"upgraded\" from category 4 in 2006). Late-Breaking Results consist of a 1-4 page short paper (extended abstract). \n \nAnswering the Call For Participation, 44 papers were submitted by international authors working in diverse research areas. The final Proceedings contains 18 papers, selected by peer review (41% acceptance rate). The 18 full papers have been grouped into 6 generally related themes of 3 papers each. These groupings were determined after the paper selection process was completed. \n \nThis year's paper selection process continued to strive for impartiality and rigor, requiring at least two reviews of each paper. All papers were reviewed by three reviewers, and a few were reviewed by four. The final paper selections were made by the program Co-Chairs following review rankings of all papers. Prior to this process, authors were encouraged to submit their work in final proceedings format and reviewers were instructed to consider each paper for publication as-is, with no changes required. Authors of accepted papers were, however, instructed to respond to the criticisms of their reviewers before submitting the final camera-ready copy for publication. \n \nForty individuals, considered to possess expertise in the field of eye tracking, eye movement research, psychology, or human-computer interaction, were selected by the program Co-Chairs as paper reviewers. Paper reviews were assigned to reviewers following reviewers' self-assessment of reviewing competency/expertise based on previews of paper abstracts. Reviews of papers were prohibited from committee members where the review would present a conflict of interest. \n \nThis year the four-page short papers were also peer-reviewed by reviewers selected by the general Co-Chair (serving as the interim LBR Chair). Each LBR submission was peer-reviewed by two reviewers. From the 44 original submissions, 22 papers were invited for re-submission as LBR papers (of which 18 accepted the invitation and 4 declined), 4 papers were rejected without an invitation to re-submit. In addition to the 18 invited papers, 20 more LBR submissions were received. From the 38 LBR submissions, the 18 invited papers were automatically accepted for poster presentations, 6 of the 20 new submissions were rejected, resulting in acceptance of 32 LBR short papers. Of these, 6 were selected for oral presentation in addition to the poster."
            },
            "slug": "Proceedings-of-the-2008-symposium-on-Eye-tracking-&-R\u00e4ih\u00e4-Duchowski",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 2008 symposium on Eye tracking research & applications"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This year's themes included the following:    \u2022Advances in Eye-Tracking Technology: Eye-tracking systems, software, and algorithms, eye movement analysis techniques and predictive models, and \u2022Visual Attention and Eye Movement Control: Studies of eye movement guidance during natural stimuli and behaviors, driving, web surfing, usability studies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3265562"
                        ],
                        "name": "K. Aoki",
                        "slug": "K.-Aoki",
                        "structuredName": {
                            "firstName": "Katsumi",
                            "lastName": "Aoki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Aoki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2539728"
                        ],
                        "name": "N. Fujisawa",
                        "slug": "N.-Fujisawa",
                        "structuredName": {
                            "firstName": "Nobuyuki",
                            "lastName": "Fujisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fujisawa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 595585,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "3c4c90cdc6b83b53b2104bf07bbbed68a862ba00",
            "isKey": false,
            "numCitedBy": 618,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "It is our great pleasure to publish the Journal of Visualization Volume 7 Number 1 to all of our reader in the world. This Journal aims at an interdisciplinary imaging science devoted to making the invisible visible through the techniques of experimental and computer-aided visualization. Recent development of flow visualization technique also contributes to the quantification of such invisible phenomenon in experimental field, that is the measurement of scientific physical properties of heat and fluid flows in engineering and scientific field. In the present issue of Journal of Visualization, we are happy to present some recent developments of experimental and computer-aided techniques. The first 6 papers are invited papers from The third Japan-Korean Joint Seminar on PIV at Fukuoka (2002-12), which deals with the recent developments in particle image velocimetry (PIV), laser-induced fluorescence (LIF) and pressure sensitive paint (PSP). These experimental technique allows the multi-points measurement of velocity, concentration and pressure in the field of interests and they are visualized in beautiful color pictures. The remaining 4 papers are researching into the unique engineering topic using the experimental and computer-aided flow visualization techniques, which allows deep insight into the invisible phenomenon of fluids and acoustic fields of interests. All of these articles contribute to the new development of visualization in engineering and scientific field in the world. We acknowledge all the authors, reviewers, and related people, who have made great efforts for publishing this issue possible."
            },
            "slug": "Recent-development-of-flow-visualization-Aoki-Fujisawa",
            "title": {
                "fragments": [],
                "text": "Recent development of flow visualization"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The first 6 papers are invited papers from The third Japan-Korean Joint Seminar on PIV at Fukuoka (2002-12), which deals with the recent developments in particle image velocimetry (PIV), laser-induced fluorescence and pressure sensitive paint (PSP)."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3299879"
                        ],
                        "name": "L. Chalupa",
                        "slug": "L.-Chalupa",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Chalupa",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chalupa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8493495"
                        ],
                        "name": "J. Werner",
                        "slug": "J.-Werner",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Werner",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Werner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4421019"
                        ],
                        "name": "C. Barnstable",
                        "slug": "C.-Barnstable",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Barnstable",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Barnstable"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141896166,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "a9d01339fd63e07d0e8ac6881b0309f94d287fcc",
            "isKey": false,
            "numCitedBy": 988,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Historical foundations developmental processes retinal mechanisms and processes organization of visual pathways subcortical processing processing in primary visual cortex detection and sampling brightness and colour from, shape and object recognition motion, depth and spatial relationships eye movements attention and cognition theoretical and computational perspectives."
            },
            "slug": "The-visual-neurosciences-Chalupa-Werner",
            "title": {
                "fragments": [],
                "text": "The visual neurosciences"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Historical foundations developmental processes retinal mechanisms and processes organization of visual pathways subcortical processing processing in primary visual cortex detection and sampling brightness and colour from, shape and object recognition motion, depth and spatial relationships eye movements attention and cognition theoretical and computational perspectives."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47240989"
                        ],
                        "name": "Yuhong Jiang",
                        "slug": "Yuhong-Jiang",
                        "structuredName": {
                            "firstName": "Yuhong",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhong Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3286262"
                        ],
                        "name": "M. Chun",
                        "slug": "M.-Chun",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Chun",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 148082288,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6ff672d68b25db90cbd565e8da552caca02460a6",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Contextual-cueing:-Reciprocal-influences-between-Jiang-Chun",
            "title": {
                "fragments": [],
                "text": "Contextual cueing: Reciprocal influences between attention and implicit learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1663821290"
                        ],
                        "name": "K. Upton",
                        "slug": "K.-Upton",
                        "structuredName": {
                            "firstName": "Kaitlyn",
                            "lastName": "Upton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Upton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 140113693,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d6eaded1be8ddd10cbc1e5afb8e7b1225d8d2cd6",
            "isKey": false,
            "numCitedBy": 596,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-modern-approach-Upton",
            "title": {
                "fragments": [],
                "text": "A modern approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48726084"
                        ],
                        "name": "Christopher M. Brown",
                        "slug": "Christopher-M.-Brown",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher M. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 195995446,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e26162d70f04da2091d1aa011f6999b76cbddff",
            "isKey": false,
            "numCitedBy": 4640,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-Ballard-Brown",
            "title": {
                "fragments": [],
                "text": "Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistics of natural images categories"
            },
            "venue": {
                "fragments": [],
                "text": "Network Comput. Neural Syst"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modeling visual-attention via selective"
            },
            "venue": {
                "fragments": [],
                "text": "Attention. Nat. Rev. Neurosci"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "eds), pp. 1179\u20131189"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextual cueing: Implicit learning andmemory of visual context guides spatial attention.Cognit"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The ventral visual object pathway in humans: evidence from fMRI"
            },
            "venue": {
                "fragments": [],
                "text": "In The Visual Neurosciences (Chalupa,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Effects of semantic consistency on eye movements during scene viewing"
            },
            "venue": {
                "fragments": [],
                "text": "J . Exp . Psychol . Hum . Percept . Perform ."
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextual cueing in naturalistic scenes: globaland local contexts.J.Exp.Psychol.Learn.Mem.Cogn.32"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational Modeling of Visual Attention"
            },
            "venue": {
                "fragments": [],
                "text": "Nat . Rev . Neurosci"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Cortical Representation"
            },
            "venue": {
                "fragments": [],
                "text": "Mem. Cognit"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual objects in context.Nat"
            },
            "venue": {
                "fragments": [],
                "text": "Rev. Neurosci"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextual guidance of attention in natural scenes : the role of global features on object search"
            },
            "venue": {
                "fragments": [],
                "text": "Psychol . Rev ."
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Five things you might not know about Elsevier 1"
            },
            "venue": {
                "fragments": [],
                "text": "Five things you might not know about Elsevier 1"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Meaning in visual scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The online archive of Elsevier's premier Cell Press journal collection became freely available in Free access to the recent archive, including Cell"
            },
            "venue": {
                "fragments": [],
                "text": "is available on ScienceDirect and the Cell Press journal sites 12 months after articles are first published"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Testing a conceptual"
            },
            "venue": {
                "fragments": [],
                "text": "tuning. Artif. Intell"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The ventral visual object pathway in humans : evidence from fMRI"
            },
            "venue": {
                "fragments": [],
                "text": "The Visual Neurosciences"
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 35,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 93,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/The-role-of-context-in-object-recognition-Oliva-Torralba/eb827f0d325b453d8bb2cbf2e7b35dc3833a1f5e?sort=total-citations"
}