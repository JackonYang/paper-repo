{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710604"
                        ],
                        "name": "R. Memisevic",
                        "slug": "R.-Memisevic",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Memisevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Memisevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Memisevic and Hinton (2007) and Memisevic (2008) describe experiments showing that the unfactored model is capable of learning more general transformations, such as split-screen transformations (i.e., simultaneous, independent\ntransformations in two different parts of an image), superresolution, or\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Memisevic and Hinton (2007) describe a convolutional version of the unfactored model, which can be used to model sets of large images with possibly variable sizes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 91
                            }
                        ],
                        "text": "To be able to capture all possible correlations among input, output, and hidden variables, Memisevic and Hinton (2007) suggest using the following three-way energy function in order to define the conditional distribution:\n\u2212E( y, h; x) = \u2211 i jk wi jk xi yj hk + \u2211 k whk hk + \u2211 j w y j yj ,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Memisevic and Hinton (2007) show how conditioning an RBM using multiplicative interactions among hidden, visible, and conditioning variables leads to a type of higher-order Boltzmann machine that retains the computational benefits of RBMs, like being amenable to contrastive divergence training and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 270
                            }
                        ],
                        "text": "\u2026to model, we can still perform invariant recognition using a system that can learn about allowable transformations from training examples, as suggested, for example, by Rao and Ruderman (1999), Olshausen, Cadieu, Culpepper, and Warland (2007), Miao and Rao (2007), and Memisevic and Hinton (2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 104
                            }
                        ],
                        "text": "We used the broadcast TV database introduced by van Hateren and Ruderman (1998), which was used also by Memisevic and Hinton (2007) (with much smaller patch sizes)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 38
                            }
                        ],
                        "text": "As a partial solution to this problem Memisevic and Hinton (2007) suggest adding a preprocessing layer to the model that can reduce the dimensionality of the input image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Memisevic and Hinton (2007) describe how gated RBMs can be used to infer motion from image pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 87
                            }
                        ],
                        "text": "In general, a higher-order\nBoltzmann machine can also contain higher-order bias terms (Memisevic & Hinton, 2007), but we do not use these in this letter."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 157
                            }
                        ],
                        "text": "An example is the generalization of the model to use exponential family distributions for hidden and observed variables (Welling, Rosen-Zvi, & Hinton, 2005; Memisevic & Hinton, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 219
                            }
                        ],
                        "text": "In contrast to the well-known task of learning static structure from independent images (e.g., Olshausen & Field, 1996; Bell & Sejnowski, 1997), the goal here is to learn about structure in how images change over time (Memisevic & Hinton, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 178
                            }
                        ],
                        "text": "(2.3)\nNote that normalization is over yand h, thus defining the conditional distribution p( y, h | x) rather than the joint p( y, h, x), which simplifies inference and learning (Memisevic & Hinton, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 50
                            }
                        ],
                        "text": "Miao and Rao (2007), Olshausen et al. (2007), and Memisevic and Hinton (2007) overcome this issue by conditioning transformed images on untransformed ones rather than trying to simultaneously model both the images and the transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 119
                            }
                        ],
                        "text": "To allow the hidden units of a restricted Boltzmann machine to model the transformation between two successive images, Memisevic and Hinton (2007) introduced three-way multiplicative interactions that use the intensity of a pixel in the first image as a multiplicative gain on a learned, symmetric\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 182
                            }
                        ],
                        "text": "Alternatively, the model can be viewed as an RBM whose connections are modulated by input pixels, which can consequently \u201cvote\u201d for linear filters that jointly model the output image (Memisevic & Hinton, 2007)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7778133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ac91e028cdc602695b46bd1f372c03b4d2776cf",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a probabilistic model for learning rich, distributed representations of image transformations. The basic model is defined as a gated conditional random field that is trained to predict transformations of its inputs using a factorial set of latent variables. Inference in the model consists in extracting the transformation, given a pair of images, and can be performed exactly and efficiently. We show that, when trained on natural videos, the model develops domain specific motion features, in the form of fields of locally transformed edge filters. When trained on affine, or more general, transformations of still images, the model develops codes for these transformations, and can subsequently perform recognition tasks that are invariant under these transformations. It can also fantasize new transformations on previously unseen images. We describe several variations of the basic model and provide experimental results that demonstrate its applicability to a variety of tasks."
            },
            "slug": "Unsupervised-Learning-of-Image-Transformations-Memisevic-Hinton",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Image Transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A probabilistic model for learning rich, distributed representations of image transformations that develops domain specific motion features, in the form of fields of locally transformed edge filters, and can fantasize new transformations on previously unseen images."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9068522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2c04849a3802715d5a9d89179c9f161014d6c2a",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning a generative model of natural images is a useful way of extracting features that capture interesting regularities. Previous work on learning such models has focused on methods in which the latent features are used to determine the mean and variance of each pixel independently, or on methods in which the hidden units determine the covariance matrix of a zero-mean Gaussian distribution. In this work, we propose a probabilistic model that combines these two approaches into a single framework. We represent each image using one set of binary latent features that model the image-specific covariance and a separate set that model the mean. We show that this approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset."
            },
            "slug": "Modeling-pixel-means-and-covariances-using-machines-Ranzato-Hinton",
            "title": {
                "fragments": [],
                "text": "Modeling pixel means and covariances using factorized third-order boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067854159"
                        ],
                        "name": "Xu Miao",
                        "slug": "Xu-Miao",
                        "structuredName": {
                            "firstName": "Xu",
                            "lastName": "Miao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xu Miao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143615848"
                        ],
                        "name": "Rajesh P. N. Rao",
                        "slug": "Rajesh-P.-N.-Rao",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Rao",
                            "middleNames": [
                                "P.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajesh P. N. Rao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Miao and Rao (2007), Olshausen et al. (2007), and Memisevic and Hinton (2007) overcome this issue by conditioning transformed images on untransformed ones rather than trying to simultaneously model both the images and the transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 245
                            }
                        ],
                        "text": "\u2026to model, we can still perform invariant recognition using a system that can learn about allowable transformations from training examples, as suggested, for example, by Rao and Ruderman (1999), Olshausen, Cadieu, Culpepper, and Warland (2007), Miao and Rao (2007), and Memisevic and Hinton (2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5298023,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c12769a1986b4299e43f03fe4b69dc5b3b450801",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "A fundamental problem in biological and machine vision is visual invariance: How are objects perceived to be the same despite transformations such as translations, rotations, and scaling? In this letter, we describe a new, unsupervised approach to learning invariances based on Lie group theory. Unlike traditional approaches that sacrifice information about transformations to achieve invariance, the Lie group approach explicitly models the effects of transformations in images. As a result, estimates of transformations are available for other purposes, such as pose estimation and visuomotor control. Previous approaches based on first-order Taylor series expansions of images can be regarded as special cases of the Lie group approach, which utilizes a matrix-exponential-based generative model of images and can handle arbitrarily large transformations. We present an unsupervised expectation-maximization algorithm for learning Lie transformation operators directly from image data containing examples of transformations. Our experimental results show that the Lie operators learned by the algorithm from an artificial data set containing six types of affine transformations closely match the analytically predicted affine operators. We then demonstrate that the algorithm can also recover novel transformation operators from natural image sequences. We conclude by showing that the learned operators can be used to both generate and estimate transformations in images, thereby providing a basis for achieving visual invariance."
            },
            "slug": "Learning-the-Lie-Groups-of-Visual-Invariance-Miao-Rao",
            "title": {
                "fragments": [],
                "text": "Learning the Lie Groups of Visual Invariance"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This letter presents an unsupervised expectation-maximization algorithm for learning Lie transformation operators directly from image data containing examples of transformations, and shows that the learned operators can be used to both generate and estimate transformations in images, thereby providing a basis for achieving visual invariance."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143615848"
                        ],
                        "name": "Rajesh P. N. Rao",
                        "slug": "Rajesh-P.-N.-Rao",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Rao",
                            "middleNames": [
                                "P.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajesh P. N. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829021"
                        ],
                        "name": "D. Ruderman",
                        "slug": "D.-Ruderman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ruderman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ruderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 196
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 170
                            }
                        ],
                        "text": "\u2026to model, we can still perform invariant recognition using a system that can learn about allowable transformations from training examples, as suggested, for example, by Rao and Ruderman (1999), Olshausen, Cadieu, Culpepper, and Warland (2007), Miao and Rao (2007), and Memisevic and Hinton (2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 943839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebc5e3ad799032bb6da8ab0d02c7d2a3323c33dc",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most important problems in visual perception is that of visual invariance: how are objects perceived to be the same despite undergoing transformations such as translations, rotations or scaling? In this paper, we describe a Bayesian method for learning invariances based on Lie group theory. We show that previous approaches based on first-order Taylor series expansions of inputs can be regarded as special cases of the Lie group approach, the latter being capable of handling in principle arbitrarily large transfonnations. Using a matrix-exponential based generative model of images, we derive an unsupervised algorithm for learning Lie group operators from input data containing infinitesimal transfonnations. The on-line unsupervised learning algorithm maximizes the posterior probability of generating the training data. We provide experimental results suggesting that the proposed method can learn Lie group operators for handling reasonably large 1-D translations and 2-D rotations."
            },
            "slug": "Learning-Lie-Groups-for-Invariant-Visual-Perception-Rao-Ruderman",
            "title": {
                "fragments": [],
                "text": "Learning Lie Groups for Invariant Visual Perception"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A Bayesian method for learning invariances based on Lie group theory and experimental results suggest that the proposed method can learn Lie group operators for handling reasonably large 1-D translations and 2-D rotations."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3202046"
                        ],
                        "name": "C. Cadieu",
                        "slug": "C.-Cadieu",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Cadieu",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cadieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31922487"
                        ],
                        "name": "Jack Culpepper",
                        "slug": "Jack-Culpepper",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Culpepper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jack Culpepper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125505"
                        ],
                        "name": "D. Warland",
                        "slug": "D.-Warland",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warland",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Warland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 151
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 21
                            }
                        ],
                        "text": "Miao and Rao (2007), Olshausen et al. (2007), and Memisevic and Hinton (2007) overcome this issue by conditioning transformed images on untransformed ones rather than trying to simultaneously model both the images and the transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 20
                            }
                        ],
                        "text": "(More specifically, Olshausen et al., 2007, discuss both a conditional and a bilinear model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 152
                            }
                        ],
                        "text": "Bilinear models contain exactly two groups of hidden variables: a \u201cwhat\u201d component accounts for the images and a \u201cwhere\u201d component for the transformations (Olshausen et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13902635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9daca9d6076c93dab31e1f366a0e594761d44d8c",
            "isKey": true,
            "numCitedBy": 53,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work on unsupervised learning has shown that it is possible to learn Gabor-like feature representations, similar to those employed in the primary visual cortex, from the statistics of natural images. However, such representations are still not readily suited for object recognition or other high-level visual tasks because they can change drastically as the image changes to due object motion, variations in viewpoint, lighting, and other factors. In this paper, we describe how bilinear image models can be used to learn independent representations of the invariances, and their transformations, in natural image sequences. These models provide the foundation for learning higher-order feature representations that could serve as models of higher stages of processing in the cortex, in addition to having practical merit for computer vision tasks."
            },
            "slug": "Bilinear-models-of-natural-images-Olshausen-Cadieu",
            "title": {
                "fragments": [],
                "text": "Bilinear models of natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Binear image models can be used to learn independent representations of the invariances, and their transformations, in natural image sequences that provide the foundation for learning higher-order feature representations that could serve as models of higher stages of processing in the cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 89
                            }
                        ],
                        "text": "Unlike the common unsupervised approaches to learning image filters, like sparse coding (Olshausen & Field, 1996), ICA (Bell & Sejnowski, 1997), and others, here it is the relationship between images that filters need to account for, not the structure within a single image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 140
                            }
                        ],
                        "text": "Imposing sparsity constraints on hidden variables has been a common way of obtaining localized filters in static image coding models (e.g., Olshausen & Field, 1996) and recently also in bilinear models of transformations (e.g., Grimes & Rao, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 95
                            }
                        ],
                        "text": "In contrast to the well-known task of learning static structure from independent images (e.g., Olshausen & Field, 1996; Bell & Sejnowski, 1997), the goal here is to learn about structure in how images change over time (Memisevic & Hinton, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4358477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8012c4a1e2ca663f1a04e80cbb19631a00cbab27",
            "isKey": false,
            "numCitedBy": 5639,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1\u20134 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7\u201312. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13\u201318, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs."
            },
            "slug": "Emergence-of-simple-cell-receptive-field-properties-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784782"
                        ],
                        "name": "D. Grimes",
                        "slug": "D.-Grimes",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grimes",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Grimes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143615848"
                        ],
                        "name": "Rajesh P. N. Rao",
                        "slug": "Rajesh-P.-N.-Rao",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Rao",
                            "middleNames": [
                                "P.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajesh P. N. Rao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 218
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 228
                            }
                        ],
                        "text": "Imposing sparsity constraints on hidden variables has been a common way of obtaining localized filters in static image coding models (e.g., Olshausen & Field, 1996) and recently also in bilinear models of transformations (e.g., Grimes & Rao, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 379,
                                "start": 365
                            }
                        ],
                        "text": "When transformations are not known a priori, are not stationary, or are difficult to model, we can still perform invariant recognition using a system that can learn about allowable transformations from training examples, as suggested, for example, by Rao and Ruderman (1999), Olshausen, Cadieu, Culpepper, and Warland (2007), Miao and Rao (2007), and Memisevic and Hinton (2007). An early approach to learning image transformations in a biologically plausible way, using temporal coherence, is described in Foldiak (1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6022678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1805b56d1edcf2fbaa72b31aac0aac15ec525e99",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent algorithms for sparse coding and independent component analysis (ICA) have demonstrated how localized features can be learned from natural images. However, these approaches do not take image transformations into account. We describe an unsupervised algorithm for learning both localized features and their transformations directly from images using a sparse bilinear generative model. We show that from an arbitrary set of natural images, the algorithm produces oriented basis filters that can simultaneously represent features in an image and their transformations. The learned generative model can be used to translate features to different locations, thereby reducing the need to learn the same feature at multiple locations, a limitation of previous approaches to sparse coding and ICA. Our results suggest that by explicitly modeling the interaction between local image features and their transformations, the sparse bilinear approach can provide a basis for achieving transformation-invariant vision."
            },
            "slug": "Bilinear-Sparse-Coding-for-Invariant-Vision-Grimes-Rao",
            "title": {
                "fragments": [],
                "text": "Bilinear Sparse Coding for Invariant Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work describes an unsupervised algorithm for learning both localized features and their transformations directly from images using a sparse bilinear generative model and shows that from an arbitrary set of natural images, the algorithm produces oriented basis filters that can simultaneously represent features in an image and their transformation."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5569557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "923d8dd5d36dd5ab68aadbe2e3eecb57de88d859",
            "isKey": false,
            "numCitedBy": 328,
            "numCiting": 124,
            "paperAbstract": {
                "fragments": [],
                "text": "Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many AI related tasks, including object recognition, speech perception, and language understanding. Theoretical and biological arguments strongly suggest that building such systems requires models with deep architectures that involve many layers of nonlinear processing. \nThe aim of the thesis is to demonstrate that deep generative models that contain many layers of latent variables and millions of parameters can be learned efficiently, and that the learned high-level feature representations can be successfully applied in a wide spectrum of application domains, including visual object recognition, information retrieval, and classification and regression tasks. In addition, similar methods can be used for nonlinear dimensionality reduction. \nThe first part of the thesis focuses on analysis and applications of probabilistic generative models called Deep Belief Networks. We show that these deep hierarchical models can learn useful feature representations from a large supply of unlabeled sensory inputs. The learned high-level representations capture a lot of structure in the input data, which is useful for subsequent problem-specific tasks, such as classification, regression or information retrieval, even though these tasks are unknown when the generative model is being trained. \nIn the second part of the thesis, we introduce a new learning algorithm for a different type of hierarchical probabilistic model, which we call a Deep Boltzmann Machine. Like Deep Belief Networks, Deep Boltzmann Machines have the potential of learning internal representations that become increasingly complex at higher layers, which is a promising way of solving object and speech recognition problems. Unlike Deep Belief Networks and many existing models with deep architectures, the approximate inference procedure, in addition to a fast bottom-up pass, can incorporate top-down feedback. This allows Deep Boltzmann Machines to better propagate uncertainty about ambiguous inputs."
            },
            "slug": "Learning-deep-generative-models-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "Learning deep generative models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The aim of the thesis is to demonstrate that deep generative models that contain many layers of latent variables and millions of parameters can be learned efficiently, and that the learned high-level feature representations can be successfully applied in a wide spectrum of application domains, including visual object recognition, information retrieval, and classification and regression tasks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710604"
                        ],
                        "name": "R. Memisevic",
                        "slug": "R.-Memisevic",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Memisevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Memisevic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 194
                            }
                        ],
                        "text": "In particular, we found that training the factored model on split-screen data yields filters that specialize to specific areas of an image, similar to the mapping units in the unfactored model (Memisevic, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Memisevic (2008), for example, discusses various nonprobabilistic formulations of the unfactored version of the model, and similar formulations would be possible for the factored model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 32
                            }
                        ],
                        "text": "Memisevic and Hinton (2007) and Memisevic (2008) describe experiments showing that the unfactored model is capable of learning more general transformations, such as split-screen transformations (i.e., simultaneous, independent\ntransformations in two different parts of an image), superresolution, or\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 251
                            }
                        ],
                        "text": "When transformations are not known a priori, are not stationary, or are difficult to model, we can still perform invariant recognition using a system that can learn about allowable transformations from training examples, as suggested, for example, by Rao and Ruderman (1999), Olshausen, Cadieu, Culpepper, and Warland (2007), Miao and Rao (2007), and Memisevic and Hinton (2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30087891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61eb977ee0041a0213dfebc13161888b5f9a909b",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "Real world data is not random: The variability in the data-sets that arise in computer vision, signal processing and other areas is often highly constrained and governed by a number of degrees of freedom that is much smaller than the superficial dimensionality of the data. Unsupervised learning methods can be used to automatically discover the \u201ctrue\u201d, underlying structure in such data-sets and are therefore a central component in many systems that deal with high-dimensional data. \nIn this thesis we develop several new approaches to modeling the low-dimensional structure in data. We introduce a new non-parametric framework for latent variable modelling, that in contrast to previous methods generalizes learned embeddings beyond the training data and its latent representatives. We show that the computational complexity for learning and applying the model is much smaller than that of existing methods, and we illustrate its applicability on several problems. \nWe also show how we can introduce supervision signals into latent variable models using conditioning. Supervision signals make it possible to attach \u201cmeaning\u201d to the axes of a latent representation and to untangle the factors that contribute to the variability in the data. We develop a model that uses conditional latent variables to extract rich distributed representations of image transformations, and we describe a new model for learning transformation features in structured supervised learning problems."
            },
            "slug": "Non-linear-latent-factor-models-for-revealing-in-Memisevic",
            "title": {
                "fragments": [],
                "text": "Non-linear latent factor models for revealing structure in high-dimensional data"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new non-parametric framework for latent variable modelling is introduced that in contrast to previous methods generalizes learned embeddings beyond the training data and its latent representatives, and the computational complexity for learning and applying the model is much smaller than that of existing methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143615848"
                        ],
                        "name": "Rajesh P. N. Rao",
                        "slug": "Rajesh-P.-N.-Rao",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Rao",
                            "middleNames": [
                                "P.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajesh P. N. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 175
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2343001,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "851d26c51856888085e4fd8fd89c1e6fc7a4447d",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "The receptive fields of neurons in the mammalian primary visual cortex are oriented not only in the domain of space, but in most cases, also in the domain of space-time. While the orientation of a receptive field in space determines the selectivity of the neuron to image structures at a particular orientation, a receptive fieldUs orientation in space-time characterizes important additional properties such as velocity and direction selectivity. Previous studies have focused on explaining the spatial receptive field properties of visual neurons by relating them to the statistical structure of static natural images. In this report, we examine the possibility that the distinctive spatiotemporal properties of visual cortical neurons can be understood in terms of a statistically efficient strategy for encoding natural time varying images. We describe an artificial neural network that attempts to accurately reconstruct its spatiotemporal input data while simultaneously reducing the statistical dependencies between its outputs. The network utilizes spatiotemporally summating neurons and learns efficient sparse distributed representations of its spatiotemporal input stream by using recurrent lateral inhibition and a simple threshold nonlinearity for rectification of neural responses. When exposed to natural time varying images, neurons in a simulated network developed localized receptive fields oriented in both space and space-time, similar to the receptive fields of neurons in the primary visual cortex."
            },
            "slug": "Efficient-Encoding-of-Natural-Time-Varying-Images-Rao-Ballard",
            "title": {
                "fragments": [],
                "text": "Efficient Encoding of Natural Time Varying Images Produces Oriented Space-Time Receptive Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An artificial neural network is described that attempts to accurately reconstruct its spatiotemporal input data while simultaneously reducing the statistical dependencies between its outputs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35959543"
                        ],
                        "name": "Urs M. Bergmann",
                        "slug": "Urs-M.-Bergmann",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "Bergmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs M. Bergmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 454398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53aac0e5b736ee5c77892459a7c523a5a6a335cd",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model for the emergence of ordered fiber projections that may serve as a basis for invariant recognition. After invariance transformations are self-organized, so-called control units competitively activate fiber projections for different transformation parameters. The model builds on a well-known ontogenetic mechanism, activity-based development of retinotopy, and it employs activity blobs of varying position and size to install different transformations. We provide a detailed analysis for the case of 1D input and output fields for schematic input patterns that shows how the model is able to develop specific mappings. We discuss results that show that the proposed learning scheme is stable for complex, biologically more realistic input patterns. Finally, we show that the model generalizes to 2D neuronal fields driven by simulated retinal waves."
            },
            "slug": "Self-Organization-of-Topographic-Bilinear-Networks-Bergmann-Malsburg",
            "title": {
                "fragments": [],
                "text": "Self-Organization of Topographic Bilinear Networks for Invariant Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A model for the emergence of ordered fiber projections that may serve as a basis for invariant recognition, and it is shown that the model generalizes to 2D neuronal fields driven by simulated retinal waves."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9200297"
                        ],
                        "name": "M. Alex O. Vasilescu",
                        "slug": "M.-Alex-O.-Vasilescu",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Vasilescu",
                            "middleNames": [
                                "Alex",
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Alex O. Vasilescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 268
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12793247,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "048bfc88b9f54512304433bb2eeb68a3172159a8",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural images are the composite consequence of multiple factors related to scene structure, illumination, and imaging. Multilinear algebra, the algebra of higher-order tensors, offers a potent mathematical framework for analyzing the multifactor structure of image ensembles and for addressing the difficult problem of disentangling the constituent factors or modes. Our multilinear modeling technique employs a tensor extension of the conventional matrix singular value decomposition (SVD), known as the N-mode SVD. As a concrete example, we consider the multilinear analysis of ensembles of facial images that combine several modes, including different facial geometries (people), expressions, head poses, and lighting conditions. Our resulting \"TensorFaces\" representation has several advantages over conventional eigenfaces. More generally, multilinear analysis shows promise as a unifying framework for a variety of computer vision problems."
            },
            "slug": "Multilinear-Analysis-of-Image-Ensembles:-Vasilescu-Terzopoulos",
            "title": {
                "fragments": [],
                "text": "Multilinear Analysis of Image Ensembles: TensorFaces"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work considers the multilinear analysis of ensembles of facial images that combine several modes, including different facial geometries (people), expressions, head poses, and lighting conditions, and concludes that the resulting \"TensorFaces\" representation has several advantages over conventional eigenfaces."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 120
                            }
                        ],
                        "text": "Unlike the common unsupervised approaches to learning image filters, like sparse coding (Olshausen & Field, 1996), ICA (Bell & Sejnowski, 1997), and others, here it is the relationship between images that filters need to account for, not the structure within a single image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 120
                            }
                        ],
                        "text": "In contrast to the well-known task of learning static structure from independent images (e.g., Olshausen & Field, 1996; Bell & Sejnowski, 1997), the goal here is to learn about structure in how images change over time (Memisevic & Hinton, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6219133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca1d23be869380ac9e900578c601c2d1febcc0c9",
            "isKey": false,
            "numCitedBy": 2373,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-\u201cindependent-components\u201d-of-natural-scenes-are-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "The \u201cindependent components\u201d of natural scenes are edge filters"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 118
                            }
                        ],
                        "text": "We used the broadcast TV database introduced by van Hateren and Ruderman (1998), which was used also by Memisevic and Hinton (2007) (with much smaller patch sizes)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 60
                            }
                        ],
                        "text": "In our experiments, we use contrastive divergence learning (Hinton, 2002), which amounts to performing each gradient update by starting the Gibbs sampler at the training observations, y\u03b1 , followed by performing a single Gibbs iteration."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 14
                            }
                        ],
                        "text": "Memisevic and Hinton (2007) describe how gated RBMs can be used to infer motion from image pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 173
                            }
                        ],
                        "text": "Each weight update is proportional to the difference between the correlation of a visible and a hidden unit when the hidden units are driven by data and by reconstructions (Hinton, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 133
                            }
                        ],
                        "text": "To allow the hidden units of a restricted Boltzmann machine to model the transformation between two successive images, Memisevic and Hinton (2007) introduced three-way multiplicative interactions that use the intensity of a pixel in the first image as a multiplicative gain on a learned, symmetric weight between a pixel in the second image and a hidden unit."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 59
                            }
                        ],
                        "text": "In our experiments, we use contrastive divergence learning (Hinton, 2002), which amounts to performing each gradient update by starting the Gibbs sampler at the training observations, y , followed by performing a single Gibbs iteration."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 325,
                                "start": 276
                            }
                        ],
                        "text": "When transformations are not known a priori, are not stationary, or are difficult to model, we can still perform invariant recognition using a system that can learn about allowable transformations from training examples, as suggested, for example, by Rao and Ruderman (1999), Olshausen, Cadieu, Culpepper, and Warland (2007), Miao and Rao (2007), and Memisevic and Hinton (2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 502,
                                "start": 138
                            }
                        ],
                        "text": ", Olshausen & Field, 1996; Bell & Sejnowski, 1997), the goal here is to learn about structure in how images change over time (Memisevic & Hinton, 2007). As in the case of still images, transformations of images in, say, natural video, can be highly structured and regular, which suggests that hidden variables can be used to discover and represent these transformations efficiently. To be able to capture all possible correlations among input, output, and hidden variables, Memisevic and Hinton (2007) suggest using the following three-way energy function in order to define the conditional distribution:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1037,
                                "start": 173
                            }
                        ],
                        "text": "Each weight update is proportional to the difference between the correlation of a visible and a hidden unit when the hidden units are driven by data and by reconstructions (Hinton, 2002). These three properties are all preserved when the hidden and visible units receive additional, conditioning inputs from previous states of the visible units (Taylor, Hinton, & Roweis, 2007). The conditioning inputs have the effect of dynamically changing the biases of the units, and the weights on these inputs can be learned by using the derivatives for the biases, provided that the previous states of the visible units are not changed when the data are reconstructed. A much more powerful way of conditioning on previous visible states is to allow them to have multiplicative effects on the weights of the RBM rather than additive effects on the biases. Boltzmann machines that contain multiplicative interactions between more than two units are known in general as higher-order Boltzmann machines (Sejnowski, 1987). Memisevic and Hinton (2007) show how conditioning an RBM using multiplicative interactions among hidden, visible, and conditioning variables leads to a type of higher-order Boltzmann machine that retains the computational benefits of RBMs, like being amenable to contrastive divergence training and allowing for efficient inference schemes that use alternating Gibbs sampling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1844,
                                "start": 173
                            }
                        ],
                        "text": "Each weight update is proportional to the difference between the correlation of a visible and a hidden unit when the hidden units are driven by data and by reconstructions (Hinton, 2002). These three properties are all preserved when the hidden and visible units receive additional, conditioning inputs from previous states of the visible units (Taylor, Hinton, & Roweis, 2007). The conditioning inputs have the effect of dynamically changing the biases of the units, and the weights on these inputs can be learned by using the derivatives for the biases, provided that the previous states of the visible units are not changed when the data are reconstructed. A much more powerful way of conditioning on previous visible states is to allow them to have multiplicative effects on the weights of the RBM rather than additive effects on the biases. Boltzmann machines that contain multiplicative interactions between more than two units are known in general as higher-order Boltzmann machines (Sejnowski, 1987). Memisevic and Hinton (2007) show how conditioning an RBM using multiplicative interactions among hidden, visible, and conditioning variables leads to a type of higher-order Boltzmann machine that retains the computational benefits of RBMs, like being amenable to contrastive divergence training and allowing for efficient inference schemes that use alternating Gibbs sampling. Unfortunately, the model suffers from an explosion in the number of parameters, which scales as the product of conditioning, hidden, and visible variables. In particular, when image transformations are modeled, the number of variables in each of these three groups of units is approximately equal to the number of pixels in an image, which restricts the applicability to small image patches. As a partial solution to this problem Memisevic and Hinton (2007) suggest adding a preprocessing layer to the model that can reduce the dimensionality of the input image."
                    },
                    "intents": []
                }
            ],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": false,
            "numCitedBy": 4572,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 107
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Tenenbaum and Freeman (2000) demonstrate an analogy-making approach based on a bilinear model using letter images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 153
                            }
                        ],
                        "text": "Unfortunately, the presence of two or more groups of hidden variables leads to a chicken-and-egg problem that can make learning and inference difficult (Tenenbaum & Freeman, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9492646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e85f7d59e37972ec52cbabfef0512588d87f125",
            "isKey": false,
            "numCitedBy": 860,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "Perceptual systems routinely separate content from style, classifying familiar words spoken in an unfamiliar accent, identifying a font or handwriting style across letters, or recognizing a familiar face or object seen under unfamiliar viewing conditions. Yet a general and tractable computational model of this ability to untangle the underlying factors of perceptual observations remains elusive (Hofstadter, 1985). Existing factor models (Mardia, Kent, & Bibby, 1979; Hinton & Zemel, 1994; Ghahramani, 1995; Bell & Sejnowski, 1995; Hinton, Dayan, Frey, & Neal, 1995; Dayan, Hinton, Neal, & Zemel, 1995; Hinton & Ghahramani, 1997) are either insufficiently rich to capture the complex interactions of perceptually meaningful factors such as phoneme and speaker accent or letter and font, or do not allow efficient learning algorithms. We present a general framework for learning to solve two-factor tasks using bilinear models, which provide sufficiently expressive representations of factor interactions but can nonetheless be fit to data using efficient algorithms based on the singular value decomposition and expectation-maximization. We report promising results on three different tasks in three different perceptual domains: spoken vowel classification with a benchmark multi-speaker database, extrapolation of fonts to unseen letters, and translation of faces to novel illuminants."
            },
            "slug": "Separating-Style-and-Content-with-Bilinear-Models-Tenenbaum-Freeman",
            "title": {
                "fragments": [],
                "text": "Separating Style and Content with Bilinear Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A general framework for learning to solve two-factor tasks using bilinear models, which provide sufficiently expressive representations of factor interactions but can nonetheless be fit to data using efficient algorithms based on the singular value decomposition and expectation-maximization are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1858054"
                        ],
                        "name": "P. F\u00f6ldi\u00e1k",
                        "slug": "P.-F\u00f6ldi\u00e1k",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "F\u00f6ldi\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. F\u00f6ldi\u00e1k"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 127
                            }
                        ],
                        "text": "An early approach to learning image transformations in a biologically plausible way, using temporal coherence, is described in Foldiak (1991). More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 127
                            }
                        ],
                        "text": "An early approach to learning image transformations in a biologically plausible way, using temporal coherence, is described in Foldiak (1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1022,
                                "start": 127
                            }
                        ],
                        "text": "An early approach to learning image transformations in a biologically plausible way, using temporal coherence, is described in Foldiak (1991). More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002). The idea behind these approaches is to use multiple independent groups of hidden variables in order to model the multiple independent latent factors that contribute to the variability in the data. Bilinear models contain exactly two groups of hidden variables: a \u201cwhat\u201d component accounts for the images and a \u201cwhere\u201d component for the transformations (Olshausen et al., 2007). Unfortunately, the presence of two or more groups of hidden variables leads to a chicken-and-egg problem that can make learning and inference difficult (Tenenbaum & Freeman, 2000). Miao and Rao (2007), Olshausen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1047,
                                "start": 127
                            }
                        ],
                        "text": "An early approach to learning image transformations in a biologically plausible way, using temporal coherence, is described in Foldiak (1991). More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002). The idea behind these approaches is to use multiple independent groups of hidden variables in order to model the multiple independent latent factors that contribute to the variability in the data. Bilinear models contain exactly two groups of hidden variables: a \u201cwhat\u201d component accounts for the images and a \u201cwhere\u201d component for the transformations (Olshausen et al., 2007). Unfortunately, the presence of two or more groups of hidden variables leads to a chicken-and-egg problem that can make learning and inference difficult (Tenenbaum & Freeman, 2000). Miao and Rao (2007), Olshausen et al. (2007), and Memisevic and Hinton (2007) overcome this issue by conditioning transformed images on untransformed ones rather than trying to simultaneously model both the images and the transformations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2175819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2da4e9984a75ffe28c5364662807996ac5bb2662",
            "isKey": true,
            "numCitedBy": 698,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The visual system can reliably identify objects even when the retinal image is transformed considerably by commonly occurring changes in the environment. A local learning rule is proposed, which allows a network to learn to generalize across such transformations. During the learning phase, the network is exposed to temporal sequences of patterns undergoing the transformation. An application of the algorithm is presented in which the network learns invariance to shift in retinal position. Such a principle may be involved in the development of the characteristic shift invariance property of complex cells in the primary visual cortex, and also in the development of more complicated invariance properties of neurons in higher visual areas."
            },
            "slug": "Learning-Invariance-from-Transformation-Sequences-F\u00f6ldi\u00e1k",
            "title": {
                "fragments": [],
                "text": "Learning Invariance from Transformation Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An application of the algorithm is presented in which the network learns invariance to shift in retinal position, which may be involved in the development of the characteristic shift invariance property of complex cells in the primary visual cortex and also in theDevelopment of more complicated invariance properties of neurons in higher visual areas."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Comput."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 134
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115232085,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b5b31f5beaf5697875c3c6cd5386ee2e5dc68233",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis presents a biologically plausible model of an attentional mechanism for forming position- and scale-invariant representations of objects in the visual world. The model relies on a set of control neurons to dynamically modify the synaptic strengths of intra-cortical connections so that information from a windowed region of primary visual cortex (V1) is selectively routed to higher cortical areas. Local spatial relationships (i.e., topography) within the attentional window are preserved as information is routed through the cortex, thus enabling attended objects to be represented in higher cortical areas within an object-centered reference frame that is position and scale invariant. The representation in V1 is modeled as a multiscale stack of sample nodes with progressively lower resolution at higher eccentricities. Large changes in the size of the attentional window are accomplished by switching between different levels of the multiscale stack, while positional shifts and small changes in scale are accomplished by translating and rescaling the window within a single level of the stack. The control signals for setting the position and size of the attentional window are hypothesized to originate from neurons in the pulvinar and in the deep layers of visual cortex. The dynamics of these control neurons are governed by simple differential equations that can be realized by neurobiologically plausible circuits. In pre-attentive mode, the control neurons receive their input from a low-level \"saliency map\" representing potentially interesting regions of a scene. During the pattern recognition phase, control neurons are driven by the interaction between top-down (memory) and bottom-up (retinal input) sources. The model respects key neurophysiological, neuroanatomical, and psychophysical data relating to attention, and it makes a variety of experimentally testable predictions."
            },
            "slug": "Neural-routing-circuits-for-forming-invariant-of-Olshausen",
            "title": {
                "fragments": [],
                "text": "Neural routing circuits for forming invariant representations of visual objects"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This thesis presents a biologically plausible model of an attentional mechanism for forming position- and scale-invariant representations of objects in the visual world that respects key neurophysiological, neuroanatomical, and psychophysical data relating to attention, and it makes a variety of experimentally testable predictions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080632378"
                        ],
                        "name": "B. Victorri",
                        "slug": "B.-Victorri",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Victorri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Victorri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 52
                            }
                        ],
                        "text": "We used the broadcast TV database introduced by van Hateren and Ruderman (1998), which was used also by Memisevic and Hinton (2007) (with much smaller patch sizes)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62640908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99c6d1a3e73e454184f81e77563a4cb5810dc430",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "In many machine learning applications, one has not only training data but also some high-level information about certain invariances that the system should exhibit. In character recognition, for example, the answer should be invariant with respect to small spatial distortions in the input images (translations, rotations, scale changes, etcetera). The authors have implemented a scheme that minimizes the derivative of the classifier outputs with respect to distortion operators. This not only produces tremendous speed advantages, but also provides a powerful language for specifying what generalizations the network can perform.<<ETX>>"
            },
            "slug": "An-efficient-algorithm-for-learning-invariance-in-Simard-LeCun",
            "title": {
                "fragments": [],
                "text": "An efficient algorithm for learning invariance in adaptive classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The authors have implemented a scheme that minimizes the derivative of the classifier outputs with respect to distortion operators, which produces tremendous speed advantages, but also provides a powerful language for specifying what generalizations the network can perform."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145039030"
                        ],
                        "name": "J. Platt",
                        "slug": "J.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153379696"
                        ],
                        "name": "T. Hofmann",
                        "slug": "T.-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hofmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125256517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "576104ba976841628c67d2d794c9a64ba876eb87",
            "isKey": false,
            "numCitedBy": 307,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \u201cvisible\u201d variables that represent joint angles. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. Such an architecture makes on-line inference efficient and allows us to use a simple approximate learning procedure. After training, the model finds a single set of parameters that simultaneously capture several different kinds of motion. We demonstrate the power of our approach by synthesizing various motion sequences and by performing on-line filling in of data lost during motion capture."
            },
            "slug": "Modeling-Human-Motion-Using-Binary-Latent-Variables-Sch\u00f6lkopf-Platt",
            "title": {
                "fragments": [],
                "text": "Modeling Human Motion Using Binary Latent Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \u201cvisible\u201d variables that represent joint angles that makes on-line inference efficient and allows for a simple approximate learning procedure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474176"
                        ],
                        "name": "J. H. Hateren",
                        "slug": "J.-H.-Hateren",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hateren",
                            "middleNames": [
                                "H.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Hateren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829021"
                        ],
                        "name": "D. Ruderman",
                        "slug": "D.-Ruderman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ruderman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ruderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 242
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 52
                            }
                        ],
                        "text": "We used the broadcast TV database introduced by van Hateren and Ruderman (1998), which was used also by Memisevic and Hinton (2007) (with much smaller patch sizes)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7968298,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "ece53e8ec1afa622f261cd30516a18491bfc8d08",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Simple cells in the primary visual cortex process incoming visual information with receptive \u00a2elds localized in space and time, bandpass in spatial and temporal frequency, tuned in orientation, and commonly selective for the direction of movement. It is shown that performing independent component analysis (ICA) on video sequences of natural scenes produces results with qualitatively similar spatio-temporal properties. Whereas the independent components of video resemble moving edges or bars, the independent component \u00a2lters, i.e. the analogues of receptive \u00a2elds, resemble moving sinusoids windowed by steady Gaussian envelopes. Contrary to earlier ICA results on static images, which gave only \u00a2lters at the \u00a2nest possible spatial scale, the spatio-temporal analysis yields \u00a2lters at a range of spatial and temporal scales. Filters centred at low spatial frequencies are generally tuned to faster movement than those at high spatial frequencies."
            },
            "slug": "Independent-component-analysis-of-natural-image-to-Hateren-Ruderman",
            "title": {
                "fragments": [],
                "text": "Independent component analysis of natural image sequences yields spatio-temporal \u00aelters similar to simple cells in primary visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398315116"
                        ],
                        "name": "M. Rosen-Zvi",
                        "slug": "M.-Rosen-Zvi",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Rosen-Zvi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosen-Zvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2388827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2184fb6d32bc46f252b940035029273563c4fc82",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Directed graphical models with one layer of observed random variables and one or more layers of hidden random variables have been the dominant modelling paradigm in many research fields. Although this approach has met with considerable success, the causal semantics of these models can make it difficult to infer the posterior distribution over the hidden variables. In this paper we propose an alternative two-layer model based on exponential family distributions and the semantics of undirected models. Inference in these \"exponential family harmoniums\" is fast while learning is performed by minimizing contrastive divergence. A member of this family is then studied as an alternative probabilistic model for latent semantic indexing. In experiments it is shown that they perform well on document retrieval tasks and provide an elegant solution to searching with keywords."
            },
            "slug": "Exponential-Family-Harmoniums-with-an-Application-Welling-Rosen-Zvi",
            "title": {
                "fragments": [],
                "text": "Exponential Family Harmoniums with an Application to Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An alternative two-layer model based on exponential family distributions and the semantics of undirected models is proposed, which performs well on document retrieval tasks and provides an elegant solution to searching with keywords."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50222622"
                        ],
                        "name": "D. Hofstadter",
                        "slug": "D.-Hofstadter",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Hofstadter",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hofstadter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 80
                            }
                        ],
                        "text": "Our approach bears some loose resemblances to the Copycat project introduced by Hofstadter (1984), which is also a stochastic, sampling-based approach to analogy making."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57414867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27b7eb6239ea48386e2fbcd71faf858f6c5e5637",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A micro-world is described, in which many analogies involving strikingly different concepts and levels of subtlety can be made. The question 'What differentiates the good ones from the bad ones? is discussed, and then the problem of how to implement a computational model of the human ability to come up with such analogies (and to have a sense for their quality) is considered. A key part of the proposed system, now under development, is its dependence on statistically emergent properties of stochastically interacting 'codelets' (small pieces of ready-to-run code created by the system, and selected at random to run with probability proportional to heuristically assigned 'urgencies'). Another key element is a network of linked concepts of varying levels of 'semanticity', in which activation spreads and indirectly controls the urgencies of new codelets. There is pressure in the system toward maximizing the degree of 'semanticity' or 'intensionality' of descriptions of structures, but many such pressures, often conflicting, must interact with one another, and compromises must be made."
            },
            "slug": "The-Copycat-Project:-An-Experiment-in-and-Creative-Hofstadter",
            "title": {
                "fragments": [],
                "text": "The Copycat Project: An Experiment in Nondeterminism and Creative Analogies"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A micro-world is described, in which many analogies involving strikingly different concepts and levels of subtlety can be made, and the problem of how to implement a computational model of the human ability to come up with such analogies is considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 145
                            }
                        ],
                        "text": "Boltzmann machines that contain multiplicative interactions between more than two units are known in general as higher-order Boltzmann machines (Sejnowski, 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117579368,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "2ab4641653283557000c94bc444b1be3fbc6ee78",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The Boltzmann machine is a nonlinear network of stochastic binary processing units that interact pairwise through symmetric connection strengths. In a third\u2010order Boltzmann machine, triples of units interact through symmetric conjunctive interactions. The Boltzmann learning algorithm is generalized to higher\u2010order Boltzmann machine should be much faster than for a second\u2010order Boltzmann machine based on pairwise interactions."
            },
            "slug": "Higher\u2010order-Boltzmann-machines-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Higher\u2010order Boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The Boltzmann learning algorithm is generalized to higher\u2010order Boltzman machine, which should be much faster than for a second\u2010order Bolzmann machine based on pairwise interactions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 151
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 21
                            }
                        ],
                        "text": "Miao and Rao (2007), Olshausen et al. (2007), and Memisevic and Hinton (2007) overcome this issue by conditioning transformed images on untransformed ones rather than trying to simultaneously model both the images and the transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 20
                            }
                        ],
                        "text": "(More specifically, Olshausen et al., 2007, discuss both a conditional and a bilinear model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 152
                            }
                        ],
                        "text": "Bilinear models contain exactly two groups of hidden variables: a \u201cwhat\u201d component accounts for the images and a \u201cwhere\u201d component for the transformations (Olshausen et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bilinear models of natural images. In SPIE Proceedings: Human Vision Electronic Imaging XII"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 20
                            }
                        ],
                        "text": "(More specifically, Olshausen et al., 2007, discuss both a conditional and a bilinear model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 152
                            }
                        ],
                        "text": "Bilinear models contain exactly two groups of hidden variables: a \u201cwhat\u201d component accounts for the images and a \u201cwhere\u201d component for the transformations (Olshausen et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 155
                            }
                        ],
                        "text": "Bi-linear models contain exactly two groups of hidden variables: A \u201cwhat\u201d-component accounts for the images and a \u201cwhere\u201dcomponent for the transformations (Olshausen et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 151
                            }
                        ],
                        "text": "More recently, several multilinear and spatiotemporal filtering models were suggested for this task (e.g., Tenenbaum & Freeman, 2000; Olshausen, 1994; Olshausen et al., 2007; Rao & Ballard, 1997; Rao & Ruderman, 1999; Grimes & Rao, 2005; van Hateren & Ruderman, 1998; Vasilescu & Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 21
                            }
                        ],
                        "text": "Miao and Rao (2007), Olshausen et al. (2007), and Memisevic and Hinton (2007) overcome this issue by conditioning transformed images on untransformed ones rather than trying to simultaneously model both the images and the transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 101
                            }
                        ],
                        "text": "More recently, several multilinear and spatio-temporal filtering models were suggested for this task (for example, Tenenbaum and Freeman, 2000; Olshausen et al., 2007; Olshausen, 1994; Grimes and Rao, 2005; Rao and Ballard, 1997; van Hateren and Ruderman, 1998; Vasilescu and Terzopoulos, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bilinear models of natural images. In SPIE Proceedings: Human Vision Electronic Imaging XII, San Jose"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "LETTER Communicated by Dana Ballard"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An efficient algorithm for learning invariances in adaptive classifiers The Hague"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 11th IAPR International Conference on Pattern Recognition. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 18
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-to-Represent-Spatial-Transformations-with-Memisevic-Hinton/0eb2e4a205a628ab059cab41d3b772f614ad29f2?sort=total-citations"
}